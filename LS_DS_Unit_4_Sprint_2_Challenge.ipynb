{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2*\n",
    "\n",
    "# Sprint Challenge - Neural Network Foundations\n",
    "\n",
    "Table of Problems\n",
    "\n",
    "1. [Defining Neural Networks](#Q1)\n",
    "2. [Perceptron on XOR Gates](#Q2)\n",
    "3. [Multilayer Perceptron](#Q3)\n",
    "4. [Keras MMP](#Q4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Q1\"></a>\n",
    "## 1. Define the following terms:\n",
    "\n",
    "- **Neuron:** An artificial neuron is essentially a function. It recieves input from neurons or data input, sums all of its weighted inputs and bias, applies an activation function to the weighted sum, and then outputs the result of the activation function. This output is supposed to represent the extent to which the neuron is \"activated.\"\n",
    "- **Input Layer:** The first layer of an ANN that provides the initial data to be processed \n",
    "- **Hidden Layer:** Intermediary layers between input and output with neurons that take a set of weighted inputs and produce an output through an activation function\n",
    "- **Output Layer:** The final layer of an ANN that transmits the prediction in an appropriately sized vector\n",
    "- **Activation:** Activation Function: An activation is a function that transforms a continuous quantity (the weighted sums plus the bias) that can be anywhere on the number line into a value that represents the extent to which a neuron is activated.\n",
    "- **Backpropagation:** the backwards propagation of errors. An artificial neural network has an error funciton that calculates how different the output values are from the desired output values. Through the use of gradient descent and the chain rule, we can calculate the gradient of the loss function with respect to the weights and adjust them accordingly\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Perceptron on XOR Gates <a id=\"Q2\"></a>\n",
    "\n",
    "The XOr, or “exclusive or”, problem is a classic problem in ANN research. It is the problem of using a neural network to predict the outputs of XOr logic gates given two binary inputs. An XOr function should return a true value if the two inputs are not equal and a false value if they are equal. Create a perceptron class that can model the behavior of an AND gate. You can use the following table as your training data:\n",
    "\n",
    "|x1\t|x2 | y |\n",
    "|---|---|---|\n",
    "| 0 | 0 | 0 |\n",
    "| 0 | 1 | 1 |\n",
    "| 1 | 1 | 0 |\n",
    "| 1 | 0 | 1 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data and targets\n",
    "train = np.array([[0,0],[0,1],[1,1],[1,0]])\n",
    "target = np.array([[0],[1],[0],[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "class Perceptron():\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Set up architecture\n",
    "        self.learning_rate = 0.1\n",
    "        self.inputLayer = 2\n",
    "        self.hiddenLayer = 2\n",
    "        self.outputLayer = 1\n",
    "\n",
    "        # Initialize weights and biases\n",
    "        self.hidden_weights = np.random.uniform(size=(inputLayer,hiddenLayer))\n",
    "        self.hidden_bias =np.random.uniform(size=(1,hiddenLayer))\n",
    "        self.output_weights = np.random.uniform(size=(hiddenLayer,outputLayer))\n",
    "        self.output_bias = np.random.uniform(size=(1,outputLayer))\n",
    "        \n",
    "    def sigmoid (self, x):\n",
    "        return 1/(1 + np.exp(-x))\n",
    "    \n",
    "    def sigmoid_derivative(self, x):\n",
    "        return x * (1 - x)\n",
    "\n",
    "    def feed_forward(self, train):\n",
    "        # Forward Propagation to calculate NN inference\n",
    "        hidden_layer_activation = np.dot(train,self.hidden_weights)\n",
    "        hidden_layer_activation += self.hidden_bias\n",
    "        hidden_layer_output = sigmoid(hidden_layer_activation)\n",
    "\n",
    "        output_layer_activation = np.dot(hidden_layer_output,self.output_weights)\n",
    "        output_layer_activation += self.output_bias\n",
    "        predicted_output = sigmoid(output_layer_activation)\n",
    "        return predicted_output, hidden_layer_output\n",
    "    \n",
    "    def backprop(self, train, target, o, hidden_layer_output):\n",
    "        error = target - o\n",
    "        d_predicted_output = error * sigmoid_derivative(o)\n",
    "    \n",
    "        error_hidden_layer = d_predicted_output.dot(self.output_weights.T)\n",
    "        d_hidden_layer = error_hidden_layer * sigmoid_derivative(hidden_layer_output)\n",
    "\n",
    "        #Updating Weights and Biases\n",
    "        self.output_weights += hidden_layer_output.T.dot(d_predicted_output) * learning_rate\n",
    "        self.output_bias += np.sum(d_predicted_output,axis=0,keepdims=True) * learning_rate\n",
    "        self.hidden_weights += train.T.dot(d_hidden_layer) * learning_rate\n",
    "        self.hidden_bias += np.sum(d_hidden_layer,axis=0,keepdims=True) * learning_rate\n",
    "        \n",
    "    def train(self, train, target, epochs):\n",
    "        for _ in range(epochs):\n",
    "            o, hl_out = self.feed_forward(train)\n",
    "            self.backprop(train, target, o, hl_out)\n",
    "    \n",
    "    def print_results(self):\n",
    "        print(\"Final hidden weights: \",end='')\n",
    "        print(*hidden_weights)\n",
    "        print(\"Final hidden bias: \",end='')\n",
    "        print(*hidden_bias)\n",
    "        print(\"Final output weights: \",end='')\n",
    "        print(*output_weights)\n",
    "        print(\"Final output bias: \",end='')\n",
    "        print(*output_bias)\n",
    "\n",
    "        print(\"\\nOutput from neural network: \",end='')\n",
    "        print(*predicted_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final hidden weights: [6.71192937 4.84296007] [6.71162415 4.84288494]\n",
      "Final hidden bias: [-3.01402014 -7.42793911]\n",
      "Final output weights: [10.31080769] [-11.00564752]\n",
      "Final output bias: [-4.80376289]\n",
      "\n",
      "Output from neural network: [0.01302485] [0.98886121] [0.01146408] [0.98886143]\n"
     ]
    }
   ],
   "source": [
    "nn = Perceptron()\n",
    "nn.train(train, target, 10000)\n",
    "nn.print_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Multilayer Perceptron <a id=\"Q3\"></a>\n",
    "\n",
    "Implement a Neural Network Multilayer Perceptron class that uses backpropagation to update the network's weights.\n",
    "Your network must have one hidden layer.\n",
    "You do not have to update weights via gradient descent. You can use something like the derivative of the sigmoid function to update weights.\n",
    "Train your model on the Heart Disease dataset from UCI:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>pain</th>\n",
       "      <th>BP</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>ecg</th>\n",
       "      <th>maxhr</th>\n",
       "      <th>eiang</th>\n",
       "      <th>eist</th>\n",
       "      <th>slope</th>\n",
       "      <th>vessels</th>\n",
       "      <th>thal</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  sex  pain     BP   chol  fbs  ecg  maxhr  eiang  eist  slope vessels  \\\n",
       "0  63.0  1.0   1.0  145.0  233.0  1.0  2.0  150.0    0.0   2.3    3.0     0.0   \n",
       "1  67.0  1.0   4.0  160.0  286.0  0.0  2.0  108.0    1.0   1.5    2.0     3.0   \n",
       "2  67.0  1.0   4.0  120.0  229.0  0.0  2.0  129.0    1.0   2.6    2.0     2.0   \n",
       "3  37.0  1.0   3.0  130.0  250.0  0.0  0.0  187.0    0.0   3.5    3.0     0.0   \n",
       "4  41.0  0.0   2.0  130.0  204.0  0.0  2.0  172.0    0.0   1.4    1.0     0.0   \n",
       "\n",
       "  thal  diagnosis  \n",
       "0  6.0          0  \n",
       "1  3.0          2  \n",
       "2  7.0          1  \n",
       "3  3.0          0  \n",
       "4  3.0          0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import heart diesase\n",
    "header_row = ['age','sex','pain','BP','chol','fbs','ecg','maxhr','eiang','eist','slope','vessels','thal','diagnosis']\n",
    "df = pd.read_csv('processed.cleveland.data', names=header_row)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    164\n",
       "1     55\n",
       "2     36\n",
       "3     35\n",
       "4     13\n",
       "Name: diagnosis, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['diagnosis'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(303, 14)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age          float64\n",
       "sex          float64\n",
       "pain         float64\n",
       "BP           float64\n",
       "chol         float64\n",
       "fbs          float64\n",
       "ecg          float64\n",
       "maxhr        float64\n",
       "eiang        float64\n",
       "eist         float64\n",
       "slope        float64\n",
       "vessels       object\n",
       "thal          object\n",
       "diagnosis      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    176\n",
       "1.0     65\n",
       "2.0     38\n",
       "3.0     20\n",
       "?        4\n",
       "Name: vessels, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['vessels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0    166\n",
       "7.0    117\n",
       "6.0     18\n",
       "?        2\n",
       "Name: thal, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['thal'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>pain</th>\n",
       "      <th>BP</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>ecg</th>\n",
       "      <th>maxhr</th>\n",
       "      <th>eiang</th>\n",
       "      <th>eist</th>\n",
       "      <th>slope</th>\n",
       "      <th>vessels</th>\n",
       "      <th>thal</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>?</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>43.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>?</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>58.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>?</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>?</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  sex  pain     BP   chol  fbs  ecg  maxhr  eiang  eist  slope  \\\n",
       "166  52.0  1.0   3.0  138.0  223.0  0.0  0.0  169.0    0.0   0.0    1.0   \n",
       "192  43.0  1.0   4.0  132.0  247.0  1.0  2.0  143.0    1.0   0.1    2.0   \n",
       "287  58.0  1.0   2.0  125.0  220.0  0.0  0.0  144.0    0.0   0.4    2.0   \n",
       "302  38.0  1.0   3.0  138.0  175.0  0.0  0.0  173.0    0.0   0.0    1.0   \n",
       "\n",
       "    vessels thal  diagnosis  \n",
       "166       ?  3.0          0  \n",
       "192       ?  7.0          1  \n",
       "287       ?  7.0          0  \n",
       "302       ?  3.0          0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['vessels']=='?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    176\n",
       "1.0     65\n",
       "2.0     38\n",
       "3.0     20\n",
       "0.0      4\n",
       "Name: vessels, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['vessels'] = df['vessels'].apply(lambda x: 0.0 if x=='?' else x)\n",
    "df['vessels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0    166\n",
       "7.0    117\n",
       "6.0     18\n",
       "3.0      2\n",
       "Name: thal, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['thal'] = df['thal'].apply(lambda x: 3.0 if x=='?' else x)\n",
    "df['thal'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['vessels'] = df['vessels'].astype(float)\n",
    "df['thal'] = df['thal'].astype(float)\n",
    "df['diagnosis'] = df['diagnosis'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age          float64\n",
       "sex          float64\n",
       "pain         float64\n",
       "BP           float64\n",
       "chol         float64\n",
       "fbs          float64\n",
       "ecg          float64\n",
       "maxhr        float64\n",
       "eiang        float64\n",
       "eist         float64\n",
       "slope        float64\n",
       "vessels      float64\n",
       "thal         float64\n",
       "diagnosis    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>pain</th>\n",
       "      <th>BP</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>ecg</th>\n",
       "      <th>maxhr</th>\n",
       "      <th>eiang</th>\n",
       "      <th>eist</th>\n",
       "      <th>slope</th>\n",
       "      <th>vessels</th>\n",
       "      <th>thal</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  sex  pain     BP   chol  fbs  ecg  maxhr  eiang  eist  slope  \\\n",
       "0  63.0  1.0   1.0  145.0  233.0  1.0  2.0  150.0    0.0   2.3    3.0   \n",
       "1  67.0  1.0   4.0  160.0  286.0  0.0  2.0  108.0    1.0   1.5    2.0   \n",
       "2  67.0  1.0   4.0  120.0  229.0  0.0  2.0  129.0    1.0   2.6    2.0   \n",
       "3  37.0  1.0   3.0  130.0  250.0  0.0  0.0  187.0    0.0   3.5    3.0   \n",
       "4  41.0  0.0   2.0  130.0  204.0  0.0  2.0  172.0    0.0   1.4    1.0   \n",
       "\n",
       "   vessels  thal  diagnosis  \n",
       "0      0.0   6.0        0.0  \n",
       "1      3.0   3.0        2.0  \n",
       "2      2.0   7.0        1.0  \n",
       "3      0.0   3.0        0.0  \n",
       "4      0.0   3.0        0.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    164\n",
       "1.0     55\n",
       "2.0     36\n",
       "3.0     35\n",
       "4.0     13\n",
       "Name: diagnosis, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['diagnosis'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.values[:,0:13]\n",
    "y = df.values[:,13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the means and standard deviations of features\n",
    "means = X.mean(axis=0)\n",
    "std = X.std(axis=0)\n",
    "\n",
    "#subtract the means and divide by stddev to standardize\n",
    "# values now represent # of stddevs from the mean\n",
    "X = X - means\n",
    "X = X / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = keras.utils.to_categorical(y, num_classes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(303, 13)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(303, 5)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "class MLP():\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Set up architecture\n",
    "        self.learning_rate = 0.1\n",
    "        self.inputLayer = 13\n",
    "        self.hiddenLayer = 10\n",
    "        self.outputLayer = 5\n",
    "        self.final_predicted_output = 0\n",
    "\n",
    "        # Initialize weights and biases\n",
    "        self.hidden_weights = np.random.uniform(size=(self.inputLayer,self.hiddenLayer))\n",
    "        self.hidden_bias = np.random.uniform(size=(1,self.hiddenLayer))\n",
    "        self.output_weights = np.random.uniform(size=(self.hiddenLayer,self.outputLayer))\n",
    "        self.output_bias = np.random.uniform(size=(1,self.outputLayer))\n",
    "        \n",
    "    def sigmoid (self, x):\n",
    "        return 1/(1 + np.exp(-x))\n",
    "    \n",
    "    def sigmoid_derivative(self, x):\n",
    "        return x * (1 - x)\n",
    "        \n",
    "    \n",
    "    def feed_forward(self, train):\n",
    "        # Forward Propagation to calculate NN inference\n",
    "        hidden_layer_activation = np.dot(train,self.hidden_weights)\n",
    "        hidden_layer_activation += self.hidden_bias\n",
    "        hidden_layer_output = self.sigmoid(hidden_layer_activation)\n",
    "\n",
    "        output_layer_activation = np.dot(hidden_layer_output,self.output_weights)\n",
    "        output_layer_activation += self.output_bias\n",
    "        predicted_output = self.sigmoid(output_layer_activation)\n",
    "        return predicted_output, hidden_layer_output\n",
    "    \n",
    "    def backprop(self, train, target, o, hidden_layer_output):\n",
    "        #target = target.reshape((target.shape[0], 1))\n",
    "        error = target - o\n",
    "        d_predicted_output = error * self.sigmoid_derivative(o)\n",
    "    \n",
    "        error_hidden_layer = d_predicted_output.dot(self.output_weights.T)\n",
    "        d_hidden_layer = error_hidden_layer * self.sigmoid_derivative(hidden_layer_output)\n",
    "\n",
    "        #Updating Weights and Biases\n",
    "        self.output_weights += hidden_layer_output.T.dot(d_predicted_output) * self.learning_rate\n",
    "        self.output_bias += np.sum(d_predicted_output,axis=0,keepdims=True) * self.learning_rate\n",
    "        self.hidden_weights += train.T.dot(d_hidden_layer) * self.learning_rate\n",
    "        self.hidden_bias += np.sum(d_hidden_layer,axis=0,keepdims=True) * self.learning_rate\n",
    "        \n",
    "    def train(self, train, target, epochs):\n",
    "        for _ in range(epochs):\n",
    "            for data, label in zip(train, target):\n",
    "                # ideally the reshaping should happen in backprop()\n",
    "                # but i'm already running out of time\n",
    "                data = data.reshape((data.shape[0], 1)).T\n",
    "                label = label.reshape((label.shape[0], 1)).T\n",
    "                o, hl_out = self.feed_forward(data)\n",
    "                self.backprop(data, label, o, hl_out)\n",
    "        self.final_predicted_output = o\n",
    "    \n",
    "    def print_results(self):\n",
    "        print(\"Final hidden weights: \",end='')\n",
    "        print(*self.hidden_weights)\n",
    "        print(\"Final hidden bias: \",end='')\n",
    "        print(*self.hidden_bias)\n",
    "        print(\"Final output weights: \",end='')\n",
    "        print(*self.output_weights)\n",
    "        print(\"Final output bias: \",end='')\n",
    "        print(*self.output_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final hidden weights: [ 1.37787504 -0.49844539  0.47731552  0.65161254  0.14453156 -0.02964934\n",
      "  0.78391619  1.75074824 -0.94101907  1.72263395] [-1.20545763  0.5846483   0.47799282  0.55398245  0.23405722 -0.43513067\n",
      "  0.80206002  1.13361561  1.24980555  0.81630973] [ 1.08553325  2.79463517 -0.10518525  1.04446676  0.77782481  1.74556135\n",
      "  1.42082233  1.00210397 -0.1323946   1.02506538] [ 0.29174792  0.39082944 -0.35975876 -0.91198436 -0.40318775  1.17095343\n",
      "  0.74041174  0.81734936  0.11044539  0.8296546 ] [-0.16854416 -1.18749883 -0.23805793 -0.44666334  0.42560774  0.33816394\n",
      "  0.55380831  1.91382159 -0.37439738  0.01290689] [ 1.05247044 -0.52351098 -0.16787493  1.41657503  0.7919179  -0.71996999\n",
      "  0.8582332   1.13656483  0.68841229 -0.99445122] [0.42375985 0.15783985 0.47337341 2.00529046 0.84668143 1.60158976\n",
      " 0.34901066 0.15655724 1.06533607 1.373829  ] [ 1.57565952 -1.20405117  0.97792348  0.42450316  0.28662414 -0.11942514\n",
      "  0.75768213 -1.26763007  0.5770717   0.88842714] [-0.49983823  1.19613841 -0.49475042  0.05425896  0.86073895  0.44716525\n",
      "  0.62484403  0.74153813 -1.09187672  0.441864  ] [ 1.2669606   1.47073674 -0.42711395  0.84711986  0.3884267   0.33297571\n",
      "  0.59376738 -0.86700305  0.82639621 -1.47247112] [ 0.86381698  0.32831775 -0.43255012 -0.2111852   0.33149575 -0.34736613\n",
      "  0.60487207 -0.84379853  1.55046024  0.36211642] [-0.76563925  1.43764106 -0.73679662  0.72300214  1.81218246 -0.01771573\n",
      "  0.39119574  0.97003496  3.18758106  1.22938863] [-1.43126081  1.05722347 -0.77641469  0.39621913  0.89814042 -0.43854807\n",
      "  0.67446052 -0.60489599  0.96334604  0.28921934]\n",
      "Final hidden bias: [ 1.59845123 -0.15515946  1.70017703  1.74327118 -0.54728781  0.25159586\n",
      "  0.54573138  0.23723899 -0.11297864  0.88831745]\n",
      "Final output weights: [ 1.35247559 -1.83441445  1.18044991 -1.02606092  0.52129029] [-2.6729828   0.53001678  2.3368056   1.24587084  0.35385622] [ 1.35646137  0.71091393 -1.11297778 -1.79457641 -1.11614488] [ 1.65259459 -1.43514116 -1.26060024  0.88471811 -0.18201818] [-0.79050279 -0.78200236  0.66138177  1.26554318  0.12984604] [-9.77997845e-01  1.25362399e+00 -9.92530564e-01  7.40974450e-01\n",
      " -6.00288080e-04] [ 7.70589806e-01  3.08788864e-01 -3.70544917e-02  6.40591648e-04\n",
      "  9.91756318e-02] [-1.82730742  0.01557273  2.22474837 -2.03804905 -0.36001192] [-3.05975505  0.83437807  0.48629542  1.05237536  0.80728978] [-0.67675869  1.26331172 -2.01066541  0.32762182  0.72348346]\n",
      "Final output bias: [ 1.19244088 -1.96775658 -2.78152177 -2.85858326 -3.39402193]\n",
      "\n",
      "Output from neural network: [0.92457217 0.17668239 0.02179459 0.00980246 0.01532636]\n"
     ]
    }
   ],
   "source": [
    "hnn = MLP()\n",
    "hnn.train(X, y, 100)\n",
    "hnn.print_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.87209663, 0.024983  , 0.05668932, 0.04094132, 0.050406  ]]),\n",
       " array([[0.99790946, 0.00291566, 0.81942023, 0.99552801, 0.55565545,\n",
       "         0.01309479, 0.96197002, 0.25406394, 0.9986804 , 0.20782387]]))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hnn.feed_forward(X[0].reshape((X[0].shape[0], 1)).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Keras MMP <a id=\"Q4\"></a>\n",
    "\n",
    "Implement a Multilayer Perceptron architecture of your choosing using the Keras library. Train your model and report its baseline accuracy. Then hyperparameter tune at least two parameters and report your model's accuracy.\n",
    "Use the Heart Disease Dataset (binary classification)\n",
    "Use an appropriate loss function for a binary classification task\n",
    "Use an appropriate activation function on the final layer of your network.\n",
    "Train your model using verbose output for ease of grading.\n",
    "Use GridSearchCV to hyperparameter tune your model. (for at least two hyperparameters)\n",
    "When hyperparameter tuning, show you work by adding code cells for each new experiment.\n",
    "Report the accuracy for each combination of hyperparameters as you test them so that we can easily see which resulted in the highest accuracy.\n",
    "You must hyperparameter tune at least 5 parameters in order to get a 3 on this section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "source": [
    "## Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('framingham.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>26.97</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>28.73</td>\n",
       "      <td>95.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>127.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>25.34</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>28.58</td>\n",
       "      <td>65.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>23.10</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   male  age  education  currentSmoker  cigsPerDay  BPMeds  prevalentStroke  \\\n",
       "0     1   39        4.0              0         0.0     0.0                0   \n",
       "1     0   46        2.0              0         0.0     0.0                0   \n",
       "2     1   48        1.0              1        20.0     0.0                0   \n",
       "3     0   61        3.0              1        30.0     0.0                0   \n",
       "4     0   46        3.0              1        23.0     0.0                0   \n",
       "\n",
       "   prevalentHyp  diabetes  totChol  sysBP  diaBP    BMI  heartRate  glucose  \\\n",
       "0             0         0    195.0  106.0   70.0  26.97       80.0     77.0   \n",
       "1             0         0    250.0  121.0   81.0  28.73       95.0     76.0   \n",
       "2             0         0    245.0  127.5   80.0  25.34       75.0     70.0   \n",
       "3             1         0    225.0  150.0   95.0  28.58       65.0    103.0   \n",
       "4             0         0    285.0  130.0   84.0  23.10       85.0     85.0   \n",
       "\n",
       "   TenYearCHD  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           1  \n",
       "4           0  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4240, 16)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['male', 'age', 'education', 'currentSmoker', 'cigsPerDay',\n",
       "       'BPMeds', 'prevalentStroke', 'prevalentHyp', 'diabetes', 'totChol',\n",
       "       'sysBP', 'diaBP', 'BMI', 'heartRate', 'glucose', 'TenYearCHD'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male                 int64\n",
       "age                  int64\n",
       "education          float64\n",
       "currentSmoker        int64\n",
       "cigsPerDay         float64\n",
       "BPMeds             float64\n",
       "prevalentStroke      int64\n",
       "prevalentHyp         int64\n",
       "diabetes             int64\n",
       "totChol            float64\n",
       "sysBP              float64\n",
       "diaBP              float64\n",
       "BMI                float64\n",
       "heartRate          float64\n",
       "glucose            float64\n",
       "TenYearCHD           int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "list = ['male', 'age', 'currentSmoker', 'prevalentStroke', 'prevalentHyp', 'diabetes', 'TenYearCHD']\n",
    "for item in list:\n",
    "    df2[item] = df2[item].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into input (X) and output (Y) variables\n",
    "dataset = df2.values\n",
    "X = dataset[:,0:15]\n",
    "Y = dataset[:,15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the means and standard deviations of features\n",
    "means = X.mean(axis=0)\n",
    "std = X.std(axis=0)\n",
    "\n",
    "#subtract the means and divide by stddev to standardize\n",
    "# values now represent # of stddevs from the mean\n",
    "X = X - means\n",
    "X = X / std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "import numpy\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4240/4240 [==============================] - 1s 148us/sample - loss: nan - acc: 0.8481\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a39261278>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# baseline model\n",
    "def create_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=15, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, verbose=1)\n",
    "model.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2826/2826 [==============================] - 1s 358us/sample - loss: nan - acc: 0.8503\n",
      "Epoch 2/20\n",
      "2826/2826 [==============================] - 0s 164us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 3/20\n",
      "2826/2826 [==============================] - 1s 202us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 4/20\n",
      "2826/2826 [==============================] - 1s 306us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 5/20\n",
      "2826/2826 [==============================] - 0s 162us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 6/20\n",
      "2826/2826 [==============================] - 0s 176us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 7/20\n",
      "2826/2826 [==============================] - 0s 170us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 8/20\n",
      "2826/2826 [==============================] - 1s 235us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 9/20\n",
      "2826/2826 [==============================] - 0s 172us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 10/20\n",
      "2826/2826 [==============================] - 1s 179us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 11/20\n",
      "2826/2826 [==============================] - 0s 173us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 12/20\n",
      "2826/2826 [==============================] - 1s 246us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 13/20\n",
      "2826/2826 [==============================] - 1s 200us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 14/20\n",
      "2826/2826 [==============================] - 0s 175us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 15/20\n",
      "2826/2826 [==============================] - 0s 175us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 16/20\n",
      "2826/2826 [==============================] - 0s 177us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 17/20\n",
      "2826/2826 [==============================] - 1s 201us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 18/20\n",
      "2826/2826 [==============================] - 1s 181us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 19/20\n",
      "2826/2826 [==============================] - 0s 177us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 20/20\n",
      "2826/2826 [==============================] - 1s 194us/sample - loss: nan - acc: 0.8521\n",
      "1414/1414 [==============================] - 0s 136us/sample - loss: nan - acc: 0.8402\n",
      "Epoch 1/20\n",
      "2827/2827 [==============================] - 1s 242us/sample - loss: nan - acc: 0.8429\n",
      "Epoch 2/20\n",
      "2827/2827 [==============================] - 1s 203us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 3/20\n",
      "2827/2827 [==============================] - 1s 188us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 4/20\n",
      "2827/2827 [==============================] - 1s 185us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 5/20\n",
      "2827/2827 [==============================] - 1s 194us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 6/20\n",
      "2827/2827 [==============================] - 1s 201us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 7/20\n",
      "2827/2827 [==============================] - 1s 184us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 8/20\n",
      "2827/2827 [==============================] - 1s 209us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 9/20\n",
      "2827/2827 [==============================] - 1s 184us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 10/20\n",
      "2827/2827 [==============================] - 1s 328us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 11/20\n",
      "2827/2827 [==============================] - 1s 287us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 12/20\n",
      "2827/2827 [==============================] - 1s 212us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 13/20\n",
      "2827/2827 [==============================] - 1s 223us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 14/20\n",
      "2827/2827 [==============================] - 1s 233us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 15/20\n",
      "2827/2827 [==============================] - 1s 205us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 16/20\n",
      "2827/2827 [==============================] - 1s 230us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 17/20\n",
      "2827/2827 [==============================] - 1s 188us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 18/20\n",
      "2827/2827 [==============================] - 1s 196us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 19/20\n",
      "2827/2827 [==============================] - 1s 233us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 20/20\n",
      "2827/2827 [==============================] - 1s 379us/sample - loss: nan - acc: 0.8447\n",
      "1413/1413 [==============================] - 1s 371us/sample - loss: nan - acc: 0.8549\n",
      "Epoch 1/20\n",
      "2827/2827 [==============================] - 1s 380us/sample - loss: nan - acc: 0.8454\n",
      "Epoch 2/20\n",
      "2827/2827 [==============================] - 1s 186us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 3/20\n",
      "2827/2827 [==============================] - 1s 192us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 4/20\n",
      "2827/2827 [==============================] - 1s 230us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 5/20\n",
      "2827/2827 [==============================] - 1s 205us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 6/20\n",
      "2827/2827 [==============================] - 1s 222us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 7/20\n",
      "2827/2827 [==============================] - 0s 163us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 8/20\n",
      "2827/2827 [==============================] - 1s 331us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 9/20\n",
      "2827/2827 [==============================] - 1s 194us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 10/20\n",
      "2827/2827 [==============================] - 0s 170us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 11/20\n",
      "2827/2827 [==============================] - 0s 157us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 12/20\n",
      "2827/2827 [==============================] - 0s 162us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 13/20\n",
      "2827/2827 [==============================] - 1s 178us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 14/20\n",
      "2827/2827 [==============================] - 0s 168us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 15/20\n",
      "2827/2827 [==============================] - 0s 158us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 16/20\n",
      "2827/2827 [==============================] - 0s 160us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 17/20\n",
      "2827/2827 [==============================] - 1s 179us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 18/20\n",
      "2827/2827 [==============================] - 0s 166us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 19/20\n",
      "2827/2827 [==============================] - 0s 159us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 20/20\n",
      "2827/2827 [==============================] - 0s 162us/sample - loss: nan - acc: 0.8475\n",
      "1413/1413 [==============================] - 0s 131us/sample - loss: nan - acc: 0.8493\n",
      "Epoch 1/20\n",
      "2826/2826 [==============================] - 0s 84us/sample - loss: nan - acc: 0.8344\n",
      "Epoch 2/20\n",
      "2826/2826 [==============================] - 0s 19us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 3/20\n",
      "2826/2826 [==============================] - 0s 19us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 4/20\n",
      "2826/2826 [==============================] - 0s 19us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 5/20\n",
      "2826/2826 [==============================] - 0s 20us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 6/20\n",
      "2826/2826 [==============================] - 0s 20us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 7/20\n",
      "2826/2826 [==============================] - 0s 19us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 8/20\n",
      "2826/2826 [==============================] - 0s 19us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 9/20\n",
      "2826/2826 [==============================] - 0s 19us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 10/20\n",
      "2826/2826 [==============================] - 0s 19us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 11/20\n",
      "2826/2826 [==============================] - 0s 18us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 12/20\n",
      "2826/2826 [==============================] - 0s 18us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 13/20\n",
      "2826/2826 [==============================] - 0s 19us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 14/20\n",
      "2826/2826 [==============================] - 0s 21us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 15/20\n",
      "2826/2826 [==============================] - 0s 19us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 16/20\n",
      "2826/2826 [==============================] - 0s 18us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 17/20\n",
      "2826/2826 [==============================] - 0s 19us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 18/20\n",
      "2826/2826 [==============================] - 0s 19us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 19/20\n",
      "2826/2826 [==============================] - 0s 18us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 20/20\n",
      "2826/2826 [==============================] - 0s 18us/sample - loss: nan - acc: 0.8521\n",
      "1414/1414 [==============================] - 0s 85us/sample - loss: nan - acc: 0.8402\n",
      "Epoch 1/20\n",
      "2827/2827 [==============================] - 0s 87us/sample - loss: nan - acc: 0.8440\n",
      "Epoch 2/20\n",
      "2827/2827 [==============================] - 0s 24us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 3/20\n",
      "2827/2827 [==============================] - 0s 19us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 4/20\n",
      "2827/2827 [==============================] - 0s 22us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 5/20\n",
      "2827/2827 [==============================] - 0s 22us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 6/20\n",
      "2827/2827 [==============================] - 0s 22us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 7/20\n",
      "2827/2827 [==============================] - 0s 24us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 8/20\n",
      "2827/2827 [==============================] - 0s 23us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 9/20\n",
      "2827/2827 [==============================] - 0s 20us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 10/20\n",
      "2827/2827 [==============================] - 0s 19us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 11/20\n",
      "2827/2827 [==============================] - 0s 19us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 12/20\n",
      "2827/2827 [==============================] - 0s 24us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 13/20\n",
      "2827/2827 [==============================] - 0s 24us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 14/20\n",
      "2827/2827 [==============================] - 0s 22us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 15/20\n",
      "2827/2827 [==============================] - 0s 21us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 16/20\n",
      "2827/2827 [==============================] - 0s 20us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 17/20\n",
      "2827/2827 [==============================] - 0s 19us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 18/20\n",
      "2827/2827 [==============================] - 0s 24us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 19/20\n",
      "2827/2827 [==============================] - 0s 19us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 20/20\n",
      "2827/2827 [==============================] - 0s 25us/sample - loss: nan - acc: 0.8447\n",
      "1413/1413 [==============================] - 0s 94us/sample - loss: nan - acc: 0.8549\n",
      "Epoch 1/20\n",
      "2827/2827 [==============================] - 0s 91us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 2/20\n",
      "2827/2827 [==============================] - 0s 22us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 3/20\n",
      "2827/2827 [==============================] - 0s 21us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 4/20\n",
      "2827/2827 [==============================] - 0s 20us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 5/20\n",
      "2827/2827 [==============================] - 0s 24us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 6/20\n",
      "2827/2827 [==============================] - 0s 22us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 7/20\n",
      "2827/2827 [==============================] - 0s 20us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 8/20\n",
      "2827/2827 [==============================] - 0s 26us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 9/20\n",
      "2827/2827 [==============================] - 0s 20us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 10/20\n",
      "2827/2827 [==============================] - 0s 22us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 11/20\n",
      "2827/2827 [==============================] - 0s 19us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 12/20\n",
      "2827/2827 [==============================] - 0s 21us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 13/20\n",
      "2827/2827 [==============================] - 0s 21us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 14/20\n",
      "2827/2827 [==============================] - 0s 23us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 15/20\n",
      "2827/2827 [==============================] - 0s 24us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 16/20\n",
      "2827/2827 [==============================] - 0s 21us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 17/20\n",
      "2827/2827 [==============================] - 0s 20us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 18/20\n",
      "2827/2827 [==============================] - 0s 29us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 19/20\n",
      "2827/2827 [==============================] - 0s 31us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 20/20\n",
      "2827/2827 [==============================] - 0s 25us/sample - loss: nan - acc: 0.8475\n",
      "1413/1413 [==============================] - 0s 98us/sample - loss: nan - acc: 0.8493\n",
      "Epoch 1/20\n",
      "2826/2826 [==============================] - 0s 79us/sample - loss: nan - acc: 0.6479\n",
      "Epoch 2/20\n",
      "2826/2826 [==============================] - 0s 5us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 3/20\n",
      "2826/2826 [==============================] - 0s 6us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 4/20\n",
      "2826/2826 [==============================] - 0s 6us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 5/20\n",
      "2826/2826 [==============================] - 0s 5us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 6/20\n",
      "2826/2826 [==============================] - 0s 4us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 7/20\n",
      "2826/2826 [==============================] - 0s 5us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 8/20\n",
      "2826/2826 [==============================] - 0s 6us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 9/20\n",
      "2826/2826 [==============================] - 0s 5us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 10/20\n",
      "2826/2826 [==============================] - 0s 6us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 11/20\n",
      "2826/2826 [==============================] - 0s 5us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 12/20\n",
      "2826/2826 [==============================] - 0s 6us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 13/20\n",
      "2826/2826 [==============================] - 0s 8us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 14/20\n",
      "2826/2826 [==============================] - 0s 4us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 15/20\n",
      "2826/2826 [==============================] - 0s 4us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 16/20\n",
      "2826/2826 [==============================] - 0s 5us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 17/20\n",
      "2826/2826 [==============================] - 0s 4us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 18/20\n",
      "2826/2826 [==============================] - 0s 5us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 19/20\n",
      "2826/2826 [==============================] - 0s 4us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 20/20\n",
      "2826/2826 [==============================] - 0s 5us/sample - loss: nan - acc: 0.8521\n",
      "1414/1414 [==============================] - 0s 97us/sample - loss: nan - acc: 0.8402\n",
      "Epoch 1/20\n",
      "2827/2827 [==============================] - 0s 78us/sample - loss: nan - acc: 0.6360\n",
      "Epoch 2/20\n",
      "2827/2827 [==============================] - 0s 5us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 3/20\n",
      "2827/2827 [==============================] - 0s 7us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 4/20\n",
      "2827/2827 [==============================] - 0s 4us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 5/20\n",
      "2827/2827 [==============================] - 0s 5us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 6/20\n",
      "2827/2827 [==============================] - 0s 5us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 7/20\n",
      "2827/2827 [==============================] - 0s 5us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 8/20\n",
      "2827/2827 [==============================] - 0s 5us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 9/20\n",
      "2827/2827 [==============================] - 0s 5us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 10/20\n",
      "2827/2827 [==============================] - 0s 6us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 11/20\n",
      "2827/2827 [==============================] - 0s 5us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 12/20\n",
      "2827/2827 [==============================] - 0s 7us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 13/20\n",
      "2827/2827 [==============================] - 0s 6us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 14/20\n",
      "2827/2827 [==============================] - 0s 4us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 15/20\n",
      "2827/2827 [==============================] - 0s 4us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 16/20\n",
      "2827/2827 [==============================] - 0s 4us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 17/20\n",
      "2827/2827 [==============================] - 0s 5us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 18/20\n",
      "2827/2827 [==============================] - 0s 4us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 19/20\n",
      "2827/2827 [==============================] - 0s 8us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 20/20\n",
      "2827/2827 [==============================] - 0s 4us/sample - loss: nan - acc: 0.8447\n",
      "1413/1413 [==============================] - 0s 83us/sample - loss: nan - acc: 0.8549\n",
      "Epoch 1/20\n",
      "2827/2827 [==============================] - 0s 76us/sample - loss: nan - acc: 0.8458\n",
      "Epoch 2/20\n",
      "2827/2827 [==============================] - 0s 8us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 3/20\n",
      "2827/2827 [==============================] - 0s 5us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 4/20\n",
      "2827/2827 [==============================] - 0s 5us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 5/20\n",
      "2827/2827 [==============================] - 0s 5us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 6/20\n",
      "2827/2827 [==============================] - 0s 4us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 7/20\n",
      "2827/2827 [==============================] - 0s 6us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 8/20\n",
      "2827/2827 [==============================] - 0s 6us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 9/20\n",
      "2827/2827 [==============================] - 0s 5us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 10/20\n",
      "2827/2827 [==============================] - 0s 5us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 11/20\n",
      "2827/2827 [==============================] - 0s 7us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 12/20\n",
      "2827/2827 [==============================] - 0s 8us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 13/20\n",
      "2827/2827 [==============================] - 0s 13us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 14/20\n",
      "2827/2827 [==============================] - 0s 6us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 15/20\n",
      "2827/2827 [==============================] - 0s 4us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 16/20\n",
      "2827/2827 [==============================] - 0s 5us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 17/20\n",
      "2827/2827 [==============================] - 0s 6us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 18/20\n",
      "2827/2827 [==============================] - 0s 7us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 19/20\n",
      "2827/2827 [==============================] - 0s 5us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 20/20\n",
      "2827/2827 [==============================] - 0s 22us/sample - loss: nan - acc: 0.8475\n",
      "1413/1413 [==============================] - 0s 89us/sample - loss: nan - acc: 0.8493\n",
      "Epoch 1/20\n",
      "4240/4240 [==============================] - 1s 247us/sample - loss: nan - acc: 0.8462\n",
      "Epoch 2/20\n",
      "4240/4240 [==============================] - 1s 178us/sample - loss: nan - acc: 0.8481\n",
      "Epoch 3/20\n",
      "4240/4240 [==============================] - 1s 186us/sample - loss: nan - acc: 0.8481\n",
      "Epoch 4/20\n",
      "4240/4240 [==============================] - 1s 180us/sample - loss: nan - acc: 0.8481\n",
      "Epoch 5/20\n",
      "4240/4240 [==============================] - 1s 179us/sample - loss: nan - acc: 0.8481\n",
      "Epoch 6/20\n",
      "4240/4240 [==============================] - 1s 230us/sample - loss: nan - acc: 0.8481\n",
      "Epoch 7/20\n",
      "4240/4240 [==============================] - 1s 237us/sample - loss: nan - acc: 0.8481\n",
      "Epoch 8/20\n",
      "4240/4240 [==============================] - 1s 189us/sample - loss: nan - acc: 0.8481\n",
      "Epoch 9/20\n",
      "4240/4240 [==============================] - 1s 185us/sample - loss: nan - acc: 0.8481\n",
      "Epoch 10/20\n",
      "4240/4240 [==============================] - 1s 179us/sample - loss: nan - acc: 0.8481\n",
      "Epoch 11/20\n",
      "4240/4240 [==============================] - 1s 235us/sample - loss: nan - acc: 0.8481\n",
      "Epoch 12/20\n",
      "4240/4240 [==============================] - 1s 208us/sample - loss: nan - acc: 0.8481\n",
      "Epoch 13/20\n",
      "4240/4240 [==============================] - 1s 189us/sample - loss: nan - acc: 0.8481\n",
      "Epoch 14/20\n",
      "4240/4240 [==============================] - 1s 200us/sample - loss: nan - acc: 0.8481\n",
      "Epoch 15/20\n",
      "4240/4240 [==============================] - 1s 312us/sample - loss: nan - acc: 0.8481\n",
      "Epoch 16/20\n",
      "4240/4240 [==============================] - 1s 270us/sample - loss: nan - acc: 0.8481\n",
      "Epoch 17/20\n",
      "4240/4240 [==============================] - 1s 264us/sample - loss: nan - acc: 0.8481\n",
      "Epoch 18/20\n",
      "4240/4240 [==============================] - 1s 227us/sample - loss: nan - acc: 0.8481\n",
      "Epoch 19/20\n",
      "4240/4240 [==============================] - 1s 205us/sample - loss: nan - acc: 0.8481\n",
      "Epoch 20/20\n",
      "4240/4240 [==============================] - 1s 207us/sample - loss: nan - acc: 0.8481\n",
      "Best: 0.848113 using {'batch_size': 10, 'epochs': 20}\n",
      "0.848113 (0.006076) with: {'batch_size': 10, 'epochs': 20}\n",
      "0.848113 (0.006076) with: {'batch_size': 100, 'epochs': 20}\n",
      "0.848113 (0.006076) with: {'batch_size': 1000, 'epochs': 20}\n"
     ]
    }
   ],
   "source": [
    "# Function to create model, required for KerasClassifier\n",
    "def create_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=15, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "# load dataset\n",
    "dataset = df2.values\n",
    "\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:15]\n",
    "Y = dataset[:,15]\n",
    "\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, verbose=1)\n",
    "\n",
    "# define the grid search parameters\n",
    "\n",
    "param_grid = {'batch_size': [10, 100, 1000],\n",
    "              'epochs': [20]}\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1)\n",
    "grid_result = grid.fit(X, Y)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(optimizer='adam'):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=15, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2826/2826 [==============================] - 1s 424us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 2/20\n",
      "2826/2826 [==============================] - 1s 187us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 3/20\n",
      "2826/2826 [==============================] - 1s 232us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 4/20\n",
      "2826/2826 [==============================] - 1s 240us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 5/20\n",
      "2826/2826 [==============================] - 0s 175us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 6/20\n",
      "2826/2826 [==============================] - 1s 197us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 7/20\n",
      "2826/2826 [==============================] - 1s 179us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 8/20\n",
      "2826/2826 [==============================] - 1s 222us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 9/20\n",
      "2826/2826 [==============================] - 1s 180us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 10/20\n",
      "2826/2826 [==============================] - 0s 163us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 11/20\n",
      "2826/2826 [==============================] - 0s 175us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 12/20\n",
      "2826/2826 [==============================] - 0s 162us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 13/20\n",
      "2826/2826 [==============================] - 0s 166us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 14/20\n",
      "2826/2826 [==============================] - 0s 168us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 15/20\n",
      "2826/2826 [==============================] - 1s 185us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 16/20\n",
      "2826/2826 [==============================] - 0s 175us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 17/20\n",
      "2826/2826 [==============================] - 0s 172us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 18/20\n",
      "2826/2826 [==============================] - 0s 169us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 19/20\n",
      "2826/2826 [==============================] - 1s 184us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 20/20\n",
      "2826/2826 [==============================] - 0s 166us/sample - loss: nan - acc: 0.8521\n",
      "1414/1414 [==============================] - 0s 195us/sample - loss: nan - acc: 0.8402\n",
      "Epoch 1/20\n",
      "2827/2827 [==============================] - 1s 255us/sample - loss: nan - acc: 0.8419\n",
      "Epoch 2/20\n",
      "2827/2827 [==============================] - 1s 195us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 3/20\n",
      "2827/2827 [==============================] - 1s 202us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 4/20\n",
      "2827/2827 [==============================] - 1s 181us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 5/20\n",
      "2827/2827 [==============================] - 1s 233us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 6/20\n",
      "2827/2827 [==============================] - 1s 285us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 7/20\n",
      "2827/2827 [==============================] - 1s 279us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 8/20\n",
      "2827/2827 [==============================] - 1s 247us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 9/20\n",
      "2827/2827 [==============================] - 1s 189us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 10/20\n",
      "2827/2827 [==============================] - 1s 178us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 11/20\n",
      "2827/2827 [==============================] - 0s 177us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 12/20\n",
      "2827/2827 [==============================] - 1s 227us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 13/20\n",
      "2827/2827 [==============================] - 1s 184us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 14/20\n",
      "2827/2827 [==============================] - 0s 175us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 15/20\n",
      "2827/2827 [==============================] - 1s 185us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 16/20\n",
      "2827/2827 [==============================] - 1s 179us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 17/20\n",
      "2827/2827 [==============================] - 1s 188us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 18/20\n",
      "2827/2827 [==============================] - 1s 199us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 19/20\n",
      "2827/2827 [==============================] - 1s 191us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 20/20\n",
      "2827/2827 [==============================] - 1s 186us/sample - loss: nan - acc: 0.8447\n",
      "1413/1413 [==============================] - 0s 195us/sample - loss: nan - acc: 0.8549\n",
      "Epoch 1/20\n",
      "2827/2827 [==============================] - 1s 245us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 2/20\n",
      "2827/2827 [==============================] - 1s 253us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 3/20\n",
      "2827/2827 [==============================] - 1s 286us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 4/20\n",
      "2827/2827 [==============================] - 1s 193us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 5/20\n",
      "2827/2827 [==============================] - 1s 177us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 6/20\n",
      "2827/2827 [==============================] - 1s 183us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 7/20\n",
      "2827/2827 [==============================] - 1s 184us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 8/20\n",
      "2827/2827 [==============================] - 1s 216us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 9/20\n",
      "2827/2827 [==============================] - 1s 211us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 10/20\n",
      "2827/2827 [==============================] - 1s 198us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 11/20\n",
      "2827/2827 [==============================] - 1s 190us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 12/20\n",
      "2827/2827 [==============================] - 1s 183us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 13/20\n",
      "2827/2827 [==============================] - 1s 190us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 14/20\n",
      "2827/2827 [==============================] - 1s 181us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 15/20\n",
      "2827/2827 [==============================] - 0s 176us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 16/20\n",
      "2827/2827 [==============================] - 1s 179us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 17/20\n",
      "2827/2827 [==============================] - 1s 221us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 18/20\n",
      "2827/2827 [==============================] - 1s 212us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 19/20\n",
      "2827/2827 [==============================] - 1s 233us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 20/20\n",
      "2827/2827 [==============================] - 1s 192us/sample - loss: nan - acc: 0.8475\n",
      "1413/1413 [==============================] - 0s 201us/sample - loss: nan - acc: 0.8493\n",
      "Epoch 1/20\n",
      "2826/2826 [==============================] - 1s 352us/sample - loss: nan - acc: 0.8503\n",
      "Epoch 2/20\n",
      "2826/2826 [==============================] - 1s 233us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 3/20\n",
      "2826/2826 [==============================] - 1s 265us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 4/20\n",
      "2826/2826 [==============================] - 1s 273us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 5/20\n",
      "2826/2826 [==============================] - 1s 208us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 6/20\n",
      "2826/2826 [==============================] - 1s 213us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 7/20\n",
      "2826/2826 [==============================] - 1s 200us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 8/20\n",
      "2826/2826 [==============================] - 1s 228us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 9/20\n",
      "2826/2826 [==============================] - 1s 228us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 10/20\n",
      "2826/2826 [==============================] - 1s 228us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 11/20\n",
      "2826/2826 [==============================] - 1s 200us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 12/20\n",
      "2826/2826 [==============================] - 1s 213us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 13/20\n",
      "2826/2826 [==============================] - 1s 223us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 14/20\n",
      "2826/2826 [==============================] - 1s 206us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 15/20\n",
      "2826/2826 [==============================] - 1s 214us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 16/20\n",
      "2826/2826 [==============================] - 1s 224us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 17/20\n",
      "2826/2826 [==============================] - 1s 207us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 18/20\n",
      "2826/2826 [==============================] - 1s 285us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 19/20\n",
      "2826/2826 [==============================] - 1s 297us/sample - loss: nan - acc: 0.8521\n",
      "Epoch 20/20\n",
      "2826/2826 [==============================] - 1s 329us/sample - loss: nan - acc: 0.8521\n",
      "1414/1414 [==============================] - 0s 213us/sample - loss: nan - acc: 0.8402\n",
      "Epoch 1/20\n",
      "2827/2827 [==============================] - 1s 294us/sample - loss: nan - acc: 0.8398\n",
      "Epoch 2/20\n",
      "2827/2827 [==============================] - 1s 217us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 3/20\n",
      "2827/2827 [==============================] - 1s 244us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 4/20\n",
      "2827/2827 [==============================] - 1s 213us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 5/20\n",
      "2827/2827 [==============================] - 1s 206us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 6/20\n",
      "2827/2827 [==============================] - 1s 223us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 7/20\n",
      "2827/2827 [==============================] - 1s 228us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 8/20\n",
      "2827/2827 [==============================] - 1s 213us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 9/20\n",
      "2827/2827 [==============================] - 1s 221us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 10/20\n",
      "2827/2827 [==============================] - 1s 210us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 11/20\n",
      "2827/2827 [==============================] - 1s 212us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 12/20\n",
      "2827/2827 [==============================] - 1s 215us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 13/20\n",
      "2827/2827 [==============================] - 1s 206us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 14/20\n",
      "2827/2827 [==============================] - 1s 211us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 15/20\n",
      "2827/2827 [==============================] - 1s 210us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 16/20\n",
      "2827/2827 [==============================] - 1s 205us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 17/20\n",
      "2827/2827 [==============================] - 1s 221us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 18/20\n",
      "2827/2827 [==============================] - 1s 213us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 19/20\n",
      "2827/2827 [==============================] - 1s 212us/sample - loss: nan - acc: 0.8447\n",
      "Epoch 20/20\n",
      "2827/2827 [==============================] - 1s 222us/sample - loss: nan - acc: 0.8447\n",
      "1413/1413 [==============================] - 0s 217us/sample - loss: nan - acc: 0.8549\n",
      "Epoch 1/20\n",
      "2827/2827 [==============================] - 1s 303us/sample - loss: nan - acc: 0.8472\n",
      "Epoch 2/20\n",
      "2827/2827 [==============================] - 1s 232us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 3/20\n",
      "2827/2827 [==============================] - 1s 270us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 4/20\n",
      "2827/2827 [==============================] - 1s 246us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 5/20\n",
      "2827/2827 [==============================] - 1s 231us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 6/20\n",
      "2827/2827 [==============================] - 1s 222us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 7/20\n",
      "2827/2827 [==============================] - 1s 254us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 8/20\n",
      "2827/2827 [==============================] - 1s 256us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 9/20\n",
      "2827/2827 [==============================] - 1s 334us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 10/20\n",
      "2827/2827 [==============================] - 1s 337us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 11/20\n",
      "2827/2827 [==============================] - 1s 239us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 12/20\n",
      "2827/2827 [==============================] - 1s 228us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 13/20\n",
      "2827/2827 [==============================] - 1s 271us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 14/20\n",
      "2827/2827 [==============================] - 1s 282us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 15/20\n",
      "2827/2827 [==============================] - 1s 232us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 16/20\n",
      "2827/2827 [==============================] - 1s 210us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 17/20\n",
      "2827/2827 [==============================] - 1s 223us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 18/20\n",
      "2827/2827 [==============================] - 1s 293us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 19/20\n",
      "2827/2827 [==============================] - 1s 295us/sample - loss: nan - acc: 0.8475\n",
      "Epoch 20/20\n",
      "2827/2827 [==============================] - 1s 221us/sample - loss: nan - acc: 0.8475\n",
      "1413/1413 [==============================] - 0s 223us/sample - loss: nan - acc: 0.8493\n",
      "Epoch 1/20\n",
      "4240/4240 [==============================] - 2s 440us/sample - loss: nan - acc: 0.8469\n",
      "Epoch 2/20\n",
      "4240/4240 [==============================] - 1s 266us/sample - loss: nan - acc: 0.8481\n",
      "Epoch 3/20\n",
      "4240/4240 [==============================] - 1s 203us/sample - loss: nan - acc: 0.8481\n",
      "Epoch 4/20\n",
      "4240/4240 [==============================] - 1s 227us/sample - loss: nan - acc: 0.8481\n",
      "Epoch 5/20\n",
      "4240/4240 [==============================] - 1s 211us/sample - loss: nan - acc: 0.8481\n",
      "Epoch 6/20\n",
      "4240/4240 [==============================] - 1s 196us/sample - loss: nan - acc: 0.8481\n",
      "Epoch 7/20\n",
      "4240/4240 [==============================] - 1s 196us/sample - loss: nan - acc: 0.8481\n",
      "Epoch 8/20\n",
      "4240/4240 [==============================] - 1s 197us/sample - loss: nan - acc: 0.8481\n",
      "Epoch 9/20\n",
      "4240/4240 [==============================] - 1s 193us/sample - loss: nan - acc: 0.8481\n",
      "Epoch 10/20\n",
      "4240/4240 [==============================] - 1s 209us/sample - loss: nan - acc: 0.8481\n",
      "Epoch 11/20\n",
      "4240/4240 [==============================] - 1s 204us/sample - loss: nan - acc: 0.8481\n",
      "Epoch 12/20\n",
      "4240/4240 [==============================] - 1s 201us/sample - loss: nan - acc: 0.8481\n",
      "Epoch 13/20\n",
      "4240/4240 [==============================] - 1s 202us/sample - loss: nan - acc: 0.8481\n",
      "Epoch 14/20\n",
      "4240/4240 [==============================] - 1s 235us/sample - loss: nan - acc: 0.8481\n",
      "Epoch 15/20\n",
      "4240/4240 [==============================] - 1s 253us/sample - loss: nan - acc: 0.8481\n",
      "Epoch 16/20\n",
      "4240/4240 [==============================] - 1s 277us/sample - loss: nan - acc: 0.8481\n",
      "Epoch 17/20\n",
      "4240/4240 [==============================] - 1s 192us/sample - loss: nan - acc: 0.8481\n",
      "Epoch 18/20\n",
      "4240/4240 [==============================] - 1s 201us/sample - loss: nan - acc: 0.8481\n",
      "Epoch 19/20\n",
      "4240/4240 [==============================] - 1s 199us/sample - loss: nan - acc: 0.8481\n",
      "Epoch 20/20\n",
      "4240/4240 [==============================] - 1s 204us/sample - loss: nan - acc: 0.8481\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=20, batch_size=10, verbose=1)\n",
    "# define the grid search parameters\n",
    "optimizer = ['sgd', 'adam']\n",
    "param_grid = dict(optimizer=optimizer)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1)\n",
    "grid_result = grid.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.8481131927865856 using {'optimizer': 'sgd'}\n",
      "Means: 0.8481131927865856, Stdev: 0.006075599508848612 with: {'optimizer': 'sgd'}\n",
      "Means: 0.8481131927865856, Stdev: 0.006075599508848612 with: {'optimizer': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "U4-S2-NNF (Python 3.6)",
   "language": "python",
   "name": "u4-s2-nnf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nteract": {
   "version": "0.14.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
