{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2*\n",
    "\n",
    "# Sprint Challenge - Neural Network Foundations\n",
    "\n",
    "Table of Problems\n",
    "\n",
    "1. [Defining Neural Networks](#Q1)\n",
    "2. [Perceptron on XOR Gates](#Q2)\n",
    "3. [Multilayer Perceptron](#Q3)\n",
    "4. [Keras MMP](#Q4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Q1\"></a>\n",
    "## 1. Define the following terms:\n",
    "\n",
    "- **Neuron:** \n",
    "- **Input Layer:**  Receives input, data that is exposed, correlates to number of features\n",
    "- **Hidden Layer:** Anything between input and output, data cannot be seen. Inside network they perform function\n",
    "- **Output Layer:** Outputs vector values for whatever you need to address, helps with activation value one can interpret\n",
    "- **Activation:** a logistic or sigmoid function, needs to produce a probability instead of output value, could be step functions, soft-max, relu\n",
    "- **Backpropagation:** is the algorithmn that adds all the changes in weights and biases over all output neurons \n",
    "in the second to last layer to get less error\n",
    "these changes are applied to weights and biases that determine the second to last layer, and the layer before that\n",
    "the backpropagation routine is done for every other training example - recording how each would like to change weights and biases the changes are the negative gradient of the cost function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Perceptron on XOR Gates <a id=\"Q2\"></a>\n",
    "\n",
    "The XOr, or “exclusive or”, problem is a classic problem in ANN research. It is the problem of using a neural network to predict the outputs of XOr logic gates given two binary inputs. An XOr function should return a true value if the two inputs are not equal and a false value if they are equal. Create a perceptron class that can model the behavior of an AND gate. You can use the following table as your training data:\n",
    "\n",
    "|x1\t|x2 | y |\n",
    "|---|---|---|\n",
    "| 0 | 0 | 0 |\n",
    "| 0 | 1 | 1 |\n",
    "| 1 | 1 | 0 |\n",
    "| 1 | 0 | 1 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x1  x2  y\n",
       "0   0   0  0\n",
       "1   0   1  1\n",
       "2   1   1  0\n",
       "3   1   0  1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = {\n",
    "    'x1': [0,0,1,1],\n",
    "    'x2': [0,1,1,0],\n",
    "    'y': [0,1,0,1]\n",
    "}\n",
    "df= pd.DataFrame.from_dict(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize our weights\n",
    "\n",
    "#calculate weighted sum of inputs and weights\n",
    "\n",
    "#output the activated value for the end of 1 training epoch\n",
    "\n",
    "class Perceptron(object):\n",
    "  def __init__(self, rate = 0.01, niter = 10):\n",
    "    self.rate = rate#learning rate\n",
    "    self.niter = niter#number of iterations\n",
    "\n",
    "  def fit(self, X, y):\n",
    "    \"\"\"Fit training data\n",
    "    X : Training vectors, X.shape : [#samples, #features]\n",
    "    y : Target values, y.shape : [#samples]\n",
    "    \"\"\"\n",
    "\n",
    "    # weights\n",
    "    self.weight = np.zeros(1 + X.shape[1])\n",
    "\n",
    "    # Number of misclassifications\n",
    "    self.errors = []  # Number of misclassifications\n",
    "\n",
    "    for i in range(self.niter):\n",
    "      err = 0\n",
    "      for xi, target in zip(X, y):\n",
    "        delta_w = self.rate * (target - self.predict(xi))#calculate sum of weights\n",
    "        self.weight[1:] += delta_w * xi#update the weights\n",
    "        self.weight[0] += delta_w\n",
    "        err += int(delta_w != 0.0)\n",
    "      self.errors.append(err)#update the error\n",
    "    return self#return the whole thing\n",
    "\n",
    "  def net_input(self, X):\n",
    "    \"\"\"Calculate net input\"\"\"\n",
    "    return np.dot(X, self.weight[1:]) + self.weight[0]\n",
    "\n",
    "  def predict(self, X):\n",
    "    \"\"\"Return class label after unit step\"\"\"\n",
    "    return np.where(self.net_input(X) >= 0.0, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  1, -1,  1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "y = df['y'].values\n",
    "y = np.where(y == 0, -1, 1)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.iloc[0:100, [0, 2]].values\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pn = Perceptron(0.1, 10)\n",
    "pn.fit(X, y)\n",
    "plt.plot(range(1, len(pn.errors) + 1), pn.errors, marker='o')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Number of misclassifications')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n",
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "def plot_decision_regions(X, y, classifier, resolution=0.02):\n",
    "  # setup marker generator and color map\n",
    "  markers = ('s', 'x', 'o', '^', 'v')\n",
    "  colors = ('red', 'blue', 'lightgreen', 'gray', 'cyan')\n",
    "  cmap = ListedColormap(colors[:len(np.unique(y))])\n",
    "\n",
    "  # plot the decision surface\n",
    "  x1_min, x1_max = X[:,  0].min() - 1, X[:, 0].max() + 1\n",
    "  x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "  xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),\n",
    "  np.arange(x2_min, x2_max, resolution))\n",
    "  Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)\n",
    "  Z = Z.reshape(xx1.shape)\n",
    "  plt.contourf(xx1, xx2, Z, alpha=0.4, cmap=cmap)\n",
    "  plt.xlim(xx1.min(), xx1.max())\n",
    "  plt.ylim(xx2.min(), xx2.max())\n",
    "\n",
    "  # plot class samples\n",
    "  for idx, cl in enumerate(np.unique(y)):\n",
    "    plt.scatter(x=X[y == cl, 0], y=X[y == cl, 1],\n",
    "    alpha=0.8, c=cmap(idx),\n",
    "    marker=markers[idx], label=cl)\n",
    "    \n",
    "plot_decision_regions(X, y, classifier=pn)\n",
    "plt.xlabel('x1, x2')\n",
    "plt.ylabel('y')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Multilayer Perceptron <a id=\"Q3\"></a>\n",
    "\n",
    "Implement a Neural Network Multilayer Perceptron class that uses backpropagation to update the network's weights.\n",
    "Your network must have one hidden layer.\n",
    "You do not have to update weights via gradient descent. You can use something like the derivative of the sigmoid function to update weights.\n",
    "Train your model on the Heart Disease dataset from UCI:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/ryanleeallred/datasets/master/heart.csv')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(303, 13)\n",
      "[[63.  1.  3. ...  0.  0.  1.]\n",
      " [37.  1.  2. ...  0.  0.  2.]\n",
      " [41.  0.  1. ...  2.  0.  2.]\n",
      " ...\n",
      " [68.  1.  0. ...  1.  2.  3.]\n",
      " [57.  1.  0. ...  1.  1.  3.]\n",
      " [57.  0.  1. ...  1.  1.  2.]]\n"
     ]
    }
   ],
   "source": [
    "X = df.values[:,0:13]\n",
    "print(X.shape)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(303, 1)\n",
      "[[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "y = np.array(df['target'].tolist())[np.newaxis]\n",
    "y = np.transpose(y)\n",
    "print(y.shape)\n",
    "print(y.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 63.    1.    3.  145.  233.    1.    0.  150.    0.    2.3   0.    0.\n",
      "   1. ]\n",
      "output [0.9420966]\n"
     ]
    }
   ],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self):\n",
    "        self.inputs = 13 # Set up Architecture of Neural Network\n",
    "        self.hiddenNodes = 3\n",
    "        self.outputNodes = 1\n",
    "        \n",
    "        self.weights1 = np.random.randn(self.inputs, self.hiddenNodes)#initalize weights, 2x3  matrix array for first layer\n",
    "        \n",
    "        #3x1 Matrix Array for Hidden to Output \n",
    "        self.weights2 = np.random.randn(self.hiddenNodes, self.outputNodes)\n",
    "        \n",
    "        #need sigmoid for activation functions\n",
    "        #need bias terms and fixed function error metric\n",
    "    def sigmoid(self, s):\n",
    "        return 1 / (1+np.exp(-s))\n",
    "    \n",
    "    def feed_forward(self, X):\n",
    "        \"\"\"\n",
    "        Calculate the NN inference using feed forward pass.\n",
    "        \"\"\"\n",
    "#input to hidden, hidden to output        \n",
    "        #Weighted sum of inputs and hidden layers, dot product of X and self weights1\n",
    "        self.hidden_sum = np.dot(X, self.weights1)#with hidden sum, we calculate and return for activation function \n",
    "        \n",
    "        #Activation of the weighted sum\n",
    "        self.activated_hidden = self.sigmoid(self.hidden_sum)#activated hidden to the output layer\n",
    "        \n",
    "        #Weighted sum of the hidden layer to output layer\n",
    "        self.output_sum = np.dot(self.activated_hidden, self.weights2)\n",
    "        \n",
    "        #Final Activation of Output\n",
    "        self.activated_output = self.sigmoid(self.output_sum)\n",
    "        \n",
    "        return self.activated_output\n",
    "    \n",
    "nn = NeuralNetwork()\n",
    "\n",
    "print(X[0])\n",
    "output = nn.feed_forward(X[0])#make a feedforward pass\n",
    "print(\"output\", output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.41309998],\n",
       "       [1.37623174],\n",
       "       [0.86875541]])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NeuralNetwork:\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Set up Architecture of Neural Network\n",
    "        self.inputs = 13\n",
    "        self.hiddenNodes =  3\n",
    "        self.outputNodes = 1\n",
    "\n",
    "        # Initial Weights\n",
    "        # 2x3 Matrix Array for the First Layer\n",
    "        self.weights1 = np.random.randn(self.inputs, self.hiddenNodes)\n",
    "       \n",
    "        # 3x1 Matrix Array for Hidden to Output\n",
    "        self.weights2 = np.random.randn(self.hiddenNodes, self.outputNodes)\n",
    "\n",
    "    def sigmoid(self, s):\n",
    "        return 1 / (1+np.exp(-s))\n",
    "\n",
    "    def sigmoidPrime(self, s):\n",
    "        return s * (1-s)\n",
    "\n",
    "    def feed_forward(self, X):\n",
    "        \"\"\"\n",
    "        Calculate the NN inference using feed forward pass.\n",
    "        \"\"\"\n",
    "        #Weighted sum of inputs and hidden layer\n",
    "        self.hidden_sum = np.dot(X, self.weights1)\n",
    "\n",
    "        #Activation of the weighted sum\n",
    "        self.activated_hidden = self.sigmoid(self.hidden_sum)\n",
    "\n",
    "        #Weighted sum of hidden layer to output layer\n",
    "        self.output_sum = np.dot(self.activated_hidden, self.weights2)\n",
    "\n",
    "        #Final Activation of Output\n",
    "        self.activated_output = self.sigmoid(self.output_sum)\n",
    "\n",
    "        return self.activated_output\n",
    "\n",
    "    #sigmoid needed at this step, will take input matrix, outputs and some other term for error\n",
    "    def backward(self, X, y, o):\n",
    "        #this is our backward pass\n",
    "        #updating weights by fixed amount which we calculated using gradient derivative of our error\n",
    "        self.o_error = y - o#error in output\n",
    "\n",
    "        #delta gives us the adjustment from the output to the hidden\n",
    "        #derivative of error\n",
    "        #Size of Adjustment from hidden =>output\n",
    "        self.o_delta = self.o_error * self.sigmoidPrime(o) #apply derivative of sigmoid to error#basically the gradient\n",
    "        #the z2 error is how much we need to change the weights by\n",
    "        #delta is constant for the backward propagation pass, then gets smaller for every other pass hopefully\n",
    "\n",
    "        self.z2_error = self.o_delta.dot(self.weights2.T)#How much the hidden layer interprets as the error\n",
    "        self.z2_delta = self.z2_error * self.sigmoidPrime(self.activated_hidden)#this is where you might scale down the learning rate\n",
    "        #we are updating the weights a fixed amount by travelling up the gradient\n",
    "        \n",
    "        #going from right to left\n",
    "        #Adjustments from the hidden to the ouput weights\n",
    "        self.weights2 += self.activated_hidden.T.dot(self.o_delta)\n",
    "\n",
    "        #Adjustment from input => hidden weights\n",
    "        #taking how much we get wrong from the z2 error and z2 delta\n",
    "        #weights1 is the first hidden error, we are working backwards\n",
    "        self.weights1 += X.T.dot(self.z2_delta)#update the weights of the first layer by taking the dot products \n",
    "        #with self.z2_delta which is representative of a variable value of how much we need to update the weights.\n",
    "\n",
    "        #we are not using gradient descent, we are updating the weights a fixed amount that we calculated using just the \n",
    "        #gradient derivative of our error\n",
    "    def train(self, X, y):\n",
    "        o = self.feed_forward(X)#calculate a forward path\n",
    "        self.backward(X, y, o )#make a backwards pass\n",
    "        \n",
    "#Since you're never passing back a function, it only matters if you can find the derivative of the activation function\n",
    "#we only care about the derivative of the activation function, the chain rule for the backprop inputs will always be a constant.\n",
    "nn.weights2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00286472,  0.00165537,  0.00110363])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We want activated that correspond to negative weights to be lower\n",
    "# And we want more higher activation for positivie weights\n",
    "error = y[0] - output #actual activation - ouput\n",
    "error\n",
    "\n",
    "nn = NeuralNetwork()\n",
    "o_delta = error * nn.sigmoidPrime(output)\n",
    "\n",
    "z2_error = o_delta.dot(nn.weights2.T)\n",
    "z2_error#set this error aside, calculate this error for the next layer, take the error all at once, then update the weights\n",
    "#based on the size of the updates\n",
    "#we want the array this outputs to be the same shape as our weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backward\n",
      " <bound method NeuralNetwork.backward of <__main__.NeuralNetwork object at 0x000001970C472D30>> \n",
      "---------\n",
      "feed_forward\n",
      " <bound method NeuralNetwork.feed_forward of <__main__.NeuralNetwork object at 0x000001970C472D30>> \n",
      "---------\n",
      "hiddenNodes\n",
      " 3 \n",
      "---------\n",
      "inputs\n",
      " 13 \n",
      "---------\n",
      "outputNodes\n",
      " 1 \n",
      "---------\n",
      "sigmoid\n",
      " <bound method NeuralNetwork.sigmoid of <__main__.NeuralNetwork object at 0x000001970C472D30>> \n",
      "---------\n",
      "sigmoidPrime\n",
      " <bound method NeuralNetwork.sigmoidPrime of <__main__.NeuralNetwork object at 0x000001970C472D30>> \n",
      "---------\n",
      "train\n",
      " <bound method NeuralNetwork.train of <__main__.NeuralNetwork object at 0x000001970C472D30>> \n",
      "---------\n",
      "weights1\n",
      " [[ 0.03011605  1.86919794 -1.06497881]\n",
      " [-0.94262663 -0.04693264 -0.22230485]\n",
      " [-1.04273611  1.00479357 -0.13959945]\n",
      " [ 0.16613525  0.11837814 -1.29777201]\n",
      " [-1.26999334  1.27027721 -0.42763613]\n",
      " [ 1.09521598 -2.41843496 -0.20105174]\n",
      " [-1.28432486 -0.81128073  0.87169386]\n",
      " [-0.08395461  1.525439   -1.44665636]\n",
      " [-1.22990549  1.27168021 -1.77029132]\n",
      " [-1.60808234 -1.23458345 -0.13461669]\n",
      " [ 1.29281053 -1.54690831 -0.35626543]\n",
      " [-0.06619702  1.89781232  0.90106296]\n",
      " [-0.54355361  1.90818777  0.06687276]] \n",
      "---------\n",
      "weights2\n",
      " [[-0.90693929]\n",
      " [ 0.52407413]\n",
      " [ 0.34939914]] \n",
      "---------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributes = ['weights1', 'hidden_sum', 'activated_hidden', 'weights2', 'output+']\n",
    "[print(i+'\\n', getattr(nn,i), '\\n'+'---'*3) for i in dir(nn) if i[:2]!= '__']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------EPOCH 1---------+\n",
      "Input: \n",
      " [[63.  1.  3. ...  0.  0.  1.]\n",
      " [37.  1.  2. ...  0.  0.  2.]\n",
      " [41.  0.  1. ...  2.  0.  2.]\n",
      " ...\n",
      " [68.  1.  0. ...  1.  2.  3.]\n",
      " [57.  1.  0. ...  1.  1.  3.]\n",
      " [57.  0.  1. ...  1.  1.  2.]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      "Predicted Output: \n",
      " [[0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.63744374]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39223786]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39222977]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39222364]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]\n",
      " [0.39221776]]\n",
      "Loss: \n",
      " 0.27043589499468373\n",
      "+---------EPOCH 2---------+\n",
      "Input: \n",
      " [[63.  1.  3. ...  0.  0.  1.]\n",
      " [37.  1.  2. ...  0.  0.  2.]\n",
      " [41.  0.  1. ...  2.  0.  2.]\n",
      " ...\n",
      " [68.  1.  0. ...  1.  2.  3.]\n",
      " [57.  1.  0. ...  1.  1.  3.]\n",
      " [57.  0.  1. ...  1.  1.  2.]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      "Predicted Output: \n",
      " [[0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999052]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.9999894 ]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99998894]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999073]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99997258]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99997258]\n",
      " [0.99999095]\n",
      " [0.9999903 ]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999095]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99998901]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99997258]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99997492]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99997258]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999055]\n",
      " [0.99997258]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999091]\n",
      " [0.99997671]\n",
      " [0.99999096]\n",
      " [0.99997258]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.9999814 ]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99997258]\n",
      " [0.99999096]\n",
      " [0.99998363]\n",
      " [0.9999726 ]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99997258]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99997258]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999079]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99997259]\n",
      " [0.99999096]\n",
      " [0.99997258]\n",
      " [0.99999096]\n",
      " [0.99997643]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99997258]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99997258]\n",
      " [0.99999096]\n",
      " [0.99999095]\n",
      " [0.99997258]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99997258]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99997259]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99997343]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99997258]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99997258]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]\n",
      " [0.99999096]]\n",
      "Loss: \n",
      " 0.4554344587317874\n",
      "+---------EPOCH 3---------+\n",
      "Input: \n",
      " [[63.  1.  3. ...  0.  0.  1.]\n",
      " [37.  1.  2. ...  0.  0.  2.]\n",
      " [41.  0.  1. ...  2.  0.  2.]\n",
      " ...\n",
      " [68.  1.  0. ...  1.  2.  3.]\n",
      " [57.  1.  0. ...  1.  1.  3.]\n",
      " [57.  0.  1. ...  1.  1.  2.]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      "Predicted Output: \n",
      " [[0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.999988  ]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99998331]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99997997]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999092]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99998914]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99997253]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99997253]\n",
      " [0.99999078]\n",
      " [0.99998681]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999085]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99998139]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99997253]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99997284]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99997253]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99998637]\n",
      " [0.99997253]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99998995]\n",
      " [0.99997326]\n",
      " [0.99999093]\n",
      " [0.99997253]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99997415]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99997253]\n",
      " [0.99999093]\n",
      " [0.9999755 ]\n",
      " [0.99997254]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99997253]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99997253]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99998952]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99997253]\n",
      " [0.99999093]\n",
      " [0.99997253]\n",
      " [0.99999093]\n",
      " [0.99997298]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99997253]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99997253]\n",
      " [0.99999093]\n",
      " [0.99999088]\n",
      " [0.99997253]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99997253]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99997253]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99997261]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99997253]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99997253]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]\n",
      " [0.99999093]]\n",
      "Loss: \n",
      " 0.4554341514272888\n",
      "+---------EPOCH 4---------+\n",
      "Input: \n",
      " [[63.  1.  3. ...  0.  0.  1.]\n",
      " [37.  1.  2. ...  0.  0.  2.]\n",
      " [41.  0.  1. ...  2.  0.  2.]\n",
      " ...\n",
      " [68.  1.  0. ...  1.  2.  3.]\n",
      " [57.  1.  0. ...  1.  1.  3.]\n",
      " [57.  0.  1. ...  1.  1.  2.]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      "Predicted Output: \n",
      " [[0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.9999802 ]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.9999909 ]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999081]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.9999756 ]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99997361]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999079]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.9999909 ]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99998225]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99997249]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99997249]\n",
      " [0.99998901]\n",
      " [0.99997843]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999028]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99997437]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99997249]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99997253]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99997249]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99997589]\n",
      " [0.99997249]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.9999808 ]\n",
      " [0.9999726 ]\n",
      " [0.99999091]\n",
      " [0.99997249]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99997269]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99997249]\n",
      " [0.99999091]\n",
      " [0.99997298]\n",
      " [0.99997249]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99997249]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99997249]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.9999909 ]\n",
      " [0.99998332]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99997249]\n",
      " [0.99999091]\n",
      " [0.99997249]\n",
      " [0.99999091]\n",
      " [0.99997253]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99997249]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99997249]\n",
      " [0.99999091]\n",
      " [0.99999047]\n",
      " [0.99997249]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99997249]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99997249]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99997249]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99997249]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99997249]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]\n",
      " [0.99999091]]\n",
      "Loss: \n",
      " 0.4554338014817731\n",
      "+---------EPOCH 5---------+\n",
      "Input: \n",
      " [[63.  1.  3. ...  0.  0.  1.]\n",
      " [37.  1.  2. ...  0.  0.  2.]\n",
      " [41.  0.  1. ...  2.  0.  2.]\n",
      " ...\n",
      " [68.  1.  0. ...  1.  2.  3.]\n",
      " [57.  1.  0. ...  1.  1.  3.]\n",
      " [57.  0.  1. ...  1.  1.  2.]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      "Predicted Output: \n",
      " [[0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99997362]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999076]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99998461]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99997281]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99997251]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99998843]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999077]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99997399]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99997244]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99997244]\n",
      " [0.99997729]\n",
      " [0.99997325]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99998536]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99997261]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99997244]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99997244]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99997244]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99997263]\n",
      " [0.99997244]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99997283]\n",
      " [0.99997245]\n",
      " [0.99999088]\n",
      " [0.99997244]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99997245]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99997244]\n",
      " [0.99999088]\n",
      " [0.99997249]\n",
      " [0.99997244]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99997244]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99997244]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999055]\n",
      " [0.9999743 ]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99997244]\n",
      " [0.99999088]\n",
      " [0.99997244]\n",
      " [0.99999088]\n",
      " [0.99997244]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99997244]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99997244]\n",
      " [0.99999088]\n",
      " [0.99998619]\n",
      " [0.99997244]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99997244]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99997244]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99997244]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99997244]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99997244]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]\n",
      " [0.99999088]]\n",
      "Loss: \n",
      " 0.4554334505192032\n",
      "+---------EPOCH 200---------+\n",
      "Input: \n",
      " [[63.  1.  3. ...  0.  0.  1.]\n",
      " [37.  1.  2. ...  0.  0.  2.]\n",
      " [41.  0.  1. ...  2.  0.  2.]\n",
      " ...\n",
      " [68.  1.  0. ...  1.  2.  3.]\n",
      " [57.  1.  0. ...  1.  1.  3.]\n",
      " [57.  0.  1. ...  1.  1.  2.]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      "Predicted Output: \n",
      " [[0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992585]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.9999231 ]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99997235]\n",
      " [0.99992039]\n",
      " [0.9999654 ]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99997235]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99997234]\n",
      " [0.99992042]\n",
      " [0.99997235]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99997235]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992255]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992045]\n",
      " [0.99992039]\n",
      " [0.99992597]\n",
      " [0.99997235]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99997235]\n",
      " [0.99992039]\n",
      " [0.99992041]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99997226]\n",
      " [0.9999204 ]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99997115]\n",
      " [0.99997203]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99997235]\n",
      " [0.99992039]\n",
      " [0.99992043]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992325]\n",
      " [0.99997235]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99997235]\n",
      " [0.99997235]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992312]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992053]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99996986]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99997235]\n",
      " [0.99992069]\n",
      " [0.99992069]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992041]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99997233]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99997235]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.9999205 ]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]\n",
      " [0.99992039]]\n",
      "Loss: \n",
      " 0.4553737203042252\n",
      "+---------EPOCH 400---------+\n",
      "Input: \n",
      " [[63.  1.  3. ...  0.  0.  1.]\n",
      " [37.  1.  2. ...  0.  0.  2.]\n",
      " [41.  0.  1. ...  2.  0.  2.]\n",
      " ...\n",
      " [68.  1.  0. ...  1.  2.  3.]\n",
      " [57.  1.  0. ...  1.  1.  3.]\n",
      " [57.  0.  1. ...  1.  1.  2.]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      "Predicted Output: \n",
      " [[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "Loss: \n",
      " 0.45544554451762886\n",
      "+---------EPOCH 600---------+\n",
      "Input: \n",
      " [[63.  1.  3. ...  0.  0.  1.]\n",
      " [37.  1.  2. ...  0.  0.  2.]\n",
      " [41.  0.  1. ...  2.  0.  2.]\n",
      " ...\n",
      " [68.  1.  0. ...  1.  2.  3.]\n",
      " [57.  1.  0. ...  1.  1.  3.]\n",
      " [57.  0.  1. ...  1.  1.  2.]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      "Predicted Output: \n",
      " [[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "Loss: \n",
      " 0.4554455445176286\n",
      "+---------EPOCH 800---------+\n",
      "Input: \n",
      " [[63.  1.  3. ...  0.  0.  1.]\n",
      " [37.  1.  2. ...  0.  0.  2.]\n",
      " [41.  0.  1. ...  2.  0.  2.]\n",
      " ...\n",
      " [68.  1.  0. ...  1.  2.  3.]\n",
      " [57.  1.  0. ...  1.  1.  3.]\n",
      " [57.  0.  1. ...  1.  1.  2.]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      "Predicted Output: \n",
      " [[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "Loss: \n",
      " 0.4554455445176286\n",
      "+---------EPOCH 1000---------+\n",
      "Input: \n",
      " [[63.  1.  3. ...  0.  0.  1.]\n",
      " [37.  1.  2. ...  0.  0.  2.]\n",
      " [41.  0.  1. ...  2.  0.  2.]\n",
      " ...\n",
      " [68.  1.  0. ...  1.  2.  3.]\n",
      " [57.  1.  0. ...  1.  1.  3.]\n",
      " [57.  0.  1. ...  1.  1.  2.]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      "Predicted Output: \n",
      " [[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "Loss: \n",
      " 0.4554455445176283\n"
     ]
    }
   ],
   "source": [
    "nn = NeuralNetwork()\n",
    "for i in range(1000):#1000 iterations on our model\n",
    "    if (i+1 in [1,2,3,4,5]) or ((i+1) % 200 ==0):\n",
    "        print('+' + '---' * 3 + f'EPOCH {i+1}' + '---'*3 + '+')\n",
    "        print('Input: \\n', X)\n",
    "        print('Actual Output: \\n', y)\n",
    "        print('Predicted Output: \\n', str(nn.feed_forward(X)))\n",
    "        print(\"Loss: \\n\", str(np.mean(np.square(y - nn.feed_forward(X)))))\n",
    "    nn.train(X,y)\n",
    "    \n",
    "#some neurons in the hidden layer are more highlighted than others because with backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import optimize\n",
    "class trainer(object):\n",
    "    def __init__(self, N):\n",
    "        #Make Local reference to network:\n",
    "        self.N = N\n",
    "        \n",
    "    def callbackF(self, params):\n",
    "        self.N.setParams(params)\n",
    "        self.J.append(self.N.costFunction(self.X, self.y))   \n",
    "        \n",
    "    def costFunctionWrapper(self, params, X, y):\n",
    "        self.N.setParams(params)\n",
    "        cost = self.N.costFunction(X, y)\n",
    "        grad = self.N.computeGradients(X,y)\n",
    "        \n",
    "        return cost, grad\n",
    "        \n",
    "    def train(self, X, y):\n",
    "        #Make an internal variable for the callback function:\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "        #Make empty list to store costs:\n",
    "        self.J = []\n",
    "        \n",
    "        params0 = self.N.getParams()\n",
    "\n",
    "        options = {'maxiter': 200, 'disp' : True}\n",
    "        _res = optimize.minimize(self.costFunctionWrapper, params0, jac=True, method='BFGS', \\\n",
    "                                 args=(X, y), options=options, callback=self.callbackF)#optimize or minimize my cost function\n",
    "\n",
    "        self.N.setParams(_res.x)\n",
    "        self.optimizationResults = _res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neural_Network(object):\n",
    "    def __init__(self):        \n",
    "        #Define Hyperparameters\n",
    "        self.inputLayerSize = 13\n",
    "        self.outputLayerSize = 1\n",
    "        self.hiddenLayerSize = 3\n",
    "        \n",
    "        #Weights (parameters)\n",
    "        self.W1 = np.random.randn(self.inputLayerSize,self.hiddenLayerSize)\n",
    "        self.W2 = np.random.randn(self.hiddenLayerSize,self.outputLayerSize)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        #Propogate inputs though network\n",
    "        self.z2 = np.dot(X, self.W1)\n",
    "        self.a2 = self.sigmoid(self.z2)\n",
    "        self.z3 = np.dot(self.a2, self.W2)\n",
    "        yHat = self.sigmoid(self.z3) \n",
    "        return yHat\n",
    "        \n",
    "    def sigmoid(self, z):\n",
    "        #Apply sigmoid activation function to scalar, vector, or matrix\n",
    "        return 1/(1+np.exp(-z))\n",
    "    \n",
    "    def sigmoidPrime(self,z):\n",
    "        #Gradient of sigmoid\n",
    "        return np.exp(-z)/((1+np.exp(-z))**2)\n",
    "    \n",
    "    def costFunction(self, X, y):\n",
    "        #Compute cost for given X,y, use weights already stored in class.\n",
    "        self.yHat = self.forward(X)\n",
    "        J = 0.5*sum((y-self.yHat)**2)\n",
    "        return J\n",
    "        \n",
    "    def costFunctionPrime(self, X, y):\n",
    "        #Compute derivative with respect to W and W2 for a given X and y:\n",
    "        self.yHat = self.forward(X)\n",
    "        \n",
    "        delta3 = np.multiply(-(y-self.yHat), self.sigmoidPrime(self.z3))\n",
    "        dJdW2 = np.dot(self.a2.T, delta3)\n",
    "        \n",
    "        delta2 = np.dot(delta3, self.W2.T)*self.sigmoidPrime(self.z2)\n",
    "        dJdW1 = np.dot(X.T, delta2)  \n",
    "        \n",
    "        return dJdW1, dJdW2\n",
    "    \n",
    "    #Helper Functions for interacting with other classes:\n",
    "    def getParams(self):\n",
    "        #Get W1 and W2 unrolled into vector:\n",
    "        params = np.concatenate((self.W1.ravel(), self.W2.ravel()))\n",
    "        return params\n",
    "    \n",
    "    def setParams(self, params):\n",
    "        #Set W1 and W2 using single paramater vector.\n",
    "        W1_start = 0\n",
    "        W1_end = self.hiddenLayerSize * self.inputLayerSize\n",
    "        self.W1 = np.reshape(params[W1_start:W1_end], (self.inputLayerSize , self.hiddenLayerSize))\n",
    "        W2_end = W1_end + self.hiddenLayerSize*self.outputLayerSize\n",
    "        self.W2 = np.reshape(params[W1_end:W2_end], (self.hiddenLayerSize, self.outputLayerSize))\n",
    "        \n",
    "    def computeGradients(self, X, y):\n",
    "        dJdW1, dJdW2 = self.costFunctionPrime(X, y)\n",
    "        return np.concatenate((dJdW1.ravel(), dJdW2.ravel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 36.890215\n",
      "         Iterations: 9\n",
      "         Function evaluations: 31\n",
      "         Gradient evaluations: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lilyx\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:26: RuntimeWarning: overflow encountered in square\n",
      "C:\\Users\\lilyx\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in true_divide\n",
      "C:\\Users\\lilyx\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:26: RuntimeWarning: overflow encountered in square\n",
      "C:\\Users\\lilyx\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "NN = Neural_Network()\n",
    "T = trainer(NN)#pass our neural network to our trainer\n",
    "T.train(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(T.J)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Cost')\n",
    "plt.show()     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Keras MMP <a id=\"Q4\"></a>\n",
    "\n",
    "Implement a Multilayer Perceptron architecture of your choosing using the Keras library. Train your model and report its baseline accuracy. Then hyperparameter tune at least two parameters and report your model's accuracy.\n",
    "Use the Heart Disease Dataset (binary classification)\n",
    "Use an appropriate loss function for a binary classification task\n",
    "Use an appropriate activation function on the final layer of your network.\n",
    "Train your model using verbose output for ease of grading.\n",
    "Use GridSearchCV to hyperparameter tune your model. (for at least two hyperparameters)\n",
    "When hyperparameter tuning, show you work by adding code cells for each new experiment.\n",
    "Report the accuracy for each combination of hyperparameters as you test them so that we can easily see which resulted in the highest accuracy.\n",
    "You must hyperparameter tune at least 5 parameters in order to get a 3 on this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential#define model keras support two types of models - supporting class for more complicated or sequences like here\n",
    "from tensorflow.keras.layers import Dense #columns of nodes\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(812)\n",
    "model = Sequential()\n",
    "model.add(Dense(1,input_dim=13,activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(303,)\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "y = df.values[:,-1]#column 8 is our target\n",
    "print(y.shape)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "303/303 [==============================] - 0s 490us/sample - loss: 39.5986 - acc: 0.4554\n",
      "Epoch 2/150\n",
      "303/303 [==============================] - 0s 59us/sample - loss: 36.3733 - acc: 0.4554\n",
      "Epoch 3/150\n",
      "303/303 [==============================] - 0s 61us/sample - loss: 33.2189 - acc: 0.4554\n",
      "Epoch 4/150\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 30.0582 - acc: 0.4554\n",
      "Epoch 5/150\n",
      "303/303 [==============================] - 0s 56us/sample - loss: 26.8874 - acc: 0.4554\n",
      "Epoch 6/150\n",
      "303/303 [==============================] - 0s 56us/sample - loss: 23.6735 - acc: 0.4554\n",
      "Epoch 7/150\n",
      "303/303 [==============================] - 0s 56us/sample - loss: 20.5046 - acc: 0.4554\n",
      "Epoch 8/150\n",
      "303/303 [==============================] - 0s 50us/sample - loss: 17.3152 - acc: 0.4554\n",
      "Epoch 9/150\n",
      "303/303 [==============================] - 0s 53us/sample - loss: 14.0674 - acc: 0.4554\n",
      "Epoch 10/150\n",
      "303/303 [==============================] - 0s 50us/sample - loss: 10.9955 - acc: 0.4554\n",
      "Epoch 11/150\n",
      "303/303 [==============================] - 0s 56us/sample - loss: 7.8207 - acc: 0.4554\n",
      "Epoch 12/150\n",
      "303/303 [==============================] - 0s 53us/sample - loss: 4.6658 - acc: 0.4554\n",
      "Epoch 13/150\n",
      "303/303 [==============================] - 0s 63us/sample - loss: 1.7469 - acc: 0.5248\n",
      "Epoch 14/150\n",
      "303/303 [==============================] - 0s 63us/sample - loss: 1.0595 - acc: 0.5380\n",
      "Epoch 15/150\n",
      "303/303 [==============================] - 0s 63us/sample - loss: 1.1508 - acc: 0.5743\n",
      "Epoch 16/150\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.9593 - acc: 0.5677\n",
      "Epoch 17/150\n",
      "303/303 [==============================] - 0s 53us/sample - loss: 0.9470 - acc: 0.6007\n",
      "Epoch 18/150\n",
      "303/303 [==============================] - 0s 63us/sample - loss: 0.9356 - acc: 0.5941\n",
      "Epoch 19/150\n",
      "303/303 [==============================] - 0s 69us/sample - loss: 0.9139 - acc: 0.6106\n",
      "Epoch 20/150\n",
      "303/303 [==============================] - 0s 59us/sample - loss: 0.9086 - acc: 0.6040\n",
      "Epoch 21/150\n",
      "303/303 [==============================] - 0s 59us/sample - loss: 0.8988 - acc: 0.6139\n",
      "Epoch 22/150\n",
      "303/303 [==============================] - 0s 50us/sample - loss: 0.8959 - acc: 0.6073\n",
      "Epoch 23/150\n",
      "303/303 [==============================] - 0s 63us/sample - loss: 0.8830 - acc: 0.6139\n",
      "Epoch 24/150\n",
      "303/303 [==============================] - 0s 53us/sample - loss: 0.8746 - acc: 0.6106\n",
      "Epoch 25/150\n",
      "303/303 [==============================] - 0s 49us/sample - loss: 0.8683 - acc: 0.6073\n",
      "Epoch 26/150\n",
      "303/303 [==============================] - 0s 56us/sample - loss: 0.8588 - acc: 0.6238\n",
      "Epoch 27/150\n",
      "303/303 [==============================] - 0s 50us/sample - loss: 0.8508 - acc: 0.6205\n",
      "Epoch 28/150\n",
      "303/303 [==============================] - 0s 59us/sample - loss: 0.8452 - acc: 0.6205\n",
      "Epoch 29/150\n",
      "303/303 [==============================] - 0s 59us/sample - loss: 0.8345 - acc: 0.6238\n",
      "Epoch 30/150\n",
      "303/303 [==============================] - 0s 76us/sample - loss: 0.8269 - acc: 0.6370\n",
      "Epoch 31/150\n",
      "303/303 [==============================] - 0s 66us/sample - loss: 0.8193 - acc: 0.6304\n",
      "Epoch 32/150\n",
      "303/303 [==============================] - 0s 66us/sample - loss: 0.8111 - acc: 0.6370\n",
      "Epoch 33/150\n",
      "303/303 [==============================] - 0s 53us/sample - loss: 0.8050 - acc: 0.6469\n",
      "Epoch 34/150\n",
      "303/303 [==============================] - 0s 59us/sample - loss: 0.7961 - acc: 0.6436\n",
      "Epoch 35/150\n",
      "303/303 [==============================] - 0s 56us/sample - loss: 0.7909 - acc: 0.6502\n",
      "Epoch 36/150\n",
      "303/303 [==============================] - 0s 49us/sample - loss: 0.7819 - acc: 0.6502\n",
      "Epoch 37/150\n",
      "303/303 [==============================] - 0s 59us/sample - loss: 0.7749 - acc: 0.6469\n",
      "Epoch 38/150\n",
      "303/303 [==============================] - 0s 56us/sample - loss: 0.7702 - acc: 0.6568\n",
      "Epoch 39/150\n",
      "303/303 [==============================] - 0s 56us/sample - loss: 0.7654 - acc: 0.6535\n",
      "Epoch 40/150\n",
      "303/303 [==============================] - 0s 56us/sample - loss: 0.7559 - acc: 0.6535\n",
      "Epoch 41/150\n",
      "303/303 [==============================] - 0s 59us/sample - loss: 0.7518 - acc: 0.6568\n",
      "Epoch 42/150\n",
      "303/303 [==============================] - 0s 59us/sample - loss: 0.7460 - acc: 0.6667\n",
      "Epoch 43/150\n",
      "303/303 [==============================] - 0s 50us/sample - loss: 0.7426 - acc: 0.6634\n",
      "Epoch 44/150\n",
      "303/303 [==============================] - 0s 50us/sample - loss: 0.7331 - acc: 0.6700\n",
      "Epoch 45/150\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.6353 - acc: 0.750 - 0s 59us/sample - loss: 0.7256 - acc: 0.6634\n",
      "Epoch 46/150\n",
      "303/303 [==============================] - 0s 53us/sample - loss: 0.7192 - acc: 0.6700\n",
      "Epoch 47/150\n",
      "303/303 [==============================] - 0s 56us/sample - loss: 0.7148 - acc: 0.6700\n",
      "Epoch 48/150\n",
      "303/303 [==============================] - 0s 63us/sample - loss: 0.7131 - acc: 0.6667\n",
      "Epoch 49/150\n",
      "303/303 [==============================] - 0s 59us/sample - loss: 0.7023 - acc: 0.6766\n",
      "Epoch 50/150\n",
      "303/303 [==============================] - 0s 50us/sample - loss: 0.7001 - acc: 0.6799\n",
      "Epoch 51/150\n",
      "303/303 [==============================] - 0s 66us/sample - loss: 0.6926 - acc: 0.6832\n",
      "Epoch 52/150\n",
      "303/303 [==============================] - 0s 50us/sample - loss: 0.6919 - acc: 0.6832\n",
      "Epoch 53/150\n",
      "303/303 [==============================] - 0s 53us/sample - loss: 0.6824 - acc: 0.6799\n",
      "Epoch 54/150\n",
      "303/303 [==============================] - 0s 40us/sample - loss: 0.6811 - acc: 0.6898\n",
      "Epoch 55/150\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.6731 - acc: 0.6931\n",
      "Epoch 56/150\n",
      "303/303 [==============================] - 0s 50us/sample - loss: 0.6700 - acc: 0.6931\n",
      "Epoch 57/150\n",
      "303/303 [==============================] - 0s 40us/sample - loss: 0.6636 - acc: 0.6931\n",
      "Epoch 58/150\n",
      "303/303 [==============================] - 0s 59us/sample - loss: 0.6615 - acc: 0.7096\n",
      "Epoch 59/150\n",
      "303/303 [==============================] - 0s 56us/sample - loss: 0.6569 - acc: 0.7030\n",
      "Epoch 60/150\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.6505 - acc: 0.6997\n",
      "Epoch 61/150\n",
      "303/303 [==============================] - 0s 53us/sample - loss: 0.6464 - acc: 0.6997\n",
      "Epoch 62/150\n",
      "303/303 [==============================] - 0s 59us/sample - loss: 0.6438 - acc: 0.6964\n",
      "Epoch 63/150\n",
      "303/303 [==============================] - 0s 53us/sample - loss: 0.6407 - acc: 0.6997\n",
      "Epoch 64/150\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6426 - acc: 0.7195\n",
      "Epoch 65/150\n",
      "303/303 [==============================] - 0s 49us/sample - loss: 0.6387 - acc: 0.7228\n",
      "Epoch 66/150\n",
      "303/303 [==============================] - 0s 53us/sample - loss: 0.6302 - acc: 0.6997\n",
      "Epoch 67/150\n",
      "303/303 [==============================] - 0s 49us/sample - loss: 0.6228 - acc: 0.7294\n",
      "Epoch 68/150\n",
      "303/303 [==============================] - 0s 53us/sample - loss: 0.6205 - acc: 0.7195\n",
      "Epoch 69/150\n",
      "303/303 [==============================] - 0s 63us/sample - loss: 0.6149 - acc: 0.7129\n",
      "Epoch 70/150\n",
      "303/303 [==============================] - 0s 59us/sample - loss: 0.6155 - acc: 0.6997\n",
      "Epoch 71/150\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.6105 - acc: 0.7228\n",
      "Epoch 72/150\n",
      "303/303 [==============================] - 0s 56us/sample - loss: 0.6052 - acc: 0.7162\n",
      "Epoch 73/150\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6104 - acc: 0.7228\n",
      "Epoch 74/150\n",
      "303/303 [==============================] - 0s 53us/sample - loss: 0.6099 - acc: 0.7129\n",
      "Epoch 75/150\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.5918 - acc: 0.7096\n",
      "Epoch 76/150\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.5979 - acc: 0.7228\n",
      "Epoch 77/150\n",
      "303/303 [==============================] - 0s 40us/sample - loss: 0.5875 - acc: 0.7327\n",
      "Epoch 78/150\n",
      "303/303 [==============================] - 0s 53us/sample - loss: 0.5886 - acc: 0.7162\n",
      "Epoch 79/150\n",
      "303/303 [==============================] - 0s 53us/sample - loss: 0.5885 - acc: 0.7360\n",
      "Epoch 80/150\n",
      "303/303 [==============================] - 0s 56us/sample - loss: 0.5766 - acc: 0.7327\n",
      "Epoch 81/150\n",
      "303/303 [==============================] - 0s 50us/sample - loss: 0.5754 - acc: 0.7195\n",
      "Epoch 82/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 0s 53us/sample - loss: 0.5743 - acc: 0.7228\n",
      "Epoch 83/150\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.5682 - acc: 0.7360\n",
      "Epoch 84/150\n",
      "303/303 [==============================] - 0s 63us/sample - loss: 0.5651 - acc: 0.7195\n",
      "Epoch 85/150\n",
      "303/303 [==============================] - 0s 56us/sample - loss: 0.5613 - acc: 0.7261\n",
      "Epoch 86/150\n",
      "303/303 [==============================] - 0s 69us/sample - loss: 0.5580 - acc: 0.7261\n",
      "Epoch 87/150\n",
      "303/303 [==============================] - 0s 63us/sample - loss: 0.5545 - acc: 0.7261\n",
      "Epoch 88/150\n",
      "303/303 [==============================] - 0s 56us/sample - loss: 0.5523 - acc: 0.7261\n",
      "Epoch 89/150\n",
      "303/303 [==============================] - 0s 56us/sample - loss: 0.5525 - acc: 0.7393\n",
      "Epoch 90/150\n",
      "303/303 [==============================] - 0s 56us/sample - loss: 0.5457 - acc: 0.7360\n",
      "Epoch 91/150\n",
      "303/303 [==============================] - 0s 56us/sample - loss: 0.5422 - acc: 0.7294\n",
      "Epoch 92/150\n",
      "303/303 [==============================] - 0s 56us/sample - loss: 0.5396 - acc: 0.7393\n",
      "Epoch 93/150\n",
      "303/303 [==============================] - 0s 53us/sample - loss: 0.5374 - acc: 0.7327\n",
      "Epoch 94/150\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.5342 - acc: 0.7294\n",
      "Epoch 95/150\n",
      "303/303 [==============================] - 0s 53us/sample - loss: 0.5309 - acc: 0.7261\n",
      "Epoch 96/150\n",
      "303/303 [==============================] - 0s 59us/sample - loss: 0.5299 - acc: 0.7426\n",
      "Epoch 97/150\n",
      "303/303 [==============================] - 0s 59us/sample - loss: 0.5255 - acc: 0.7393\n",
      "Epoch 98/150\n",
      "303/303 [==============================] - 0s 69us/sample - loss: 0.5227 - acc: 0.7393\n",
      "Epoch 99/150\n",
      "303/303 [==============================] - 0s 53us/sample - loss: 0.5196 - acc: 0.7327\n",
      "Epoch 100/150\n",
      "303/303 [==============================] - 0s 53us/sample - loss: 0.5189 - acc: 0.7426\n",
      "Epoch 101/150\n",
      "303/303 [==============================] - 0s 63us/sample - loss: 0.5154 - acc: 0.7360\n",
      "Epoch 102/150\n",
      "303/303 [==============================] - 0s 53us/sample - loss: 0.5173 - acc: 0.7459\n",
      "Epoch 103/150\n",
      "303/303 [==============================] - 0s 53us/sample - loss: 0.5121 - acc: 0.7492\n",
      "Epoch 104/150\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.5076 - acc: 0.7393\n",
      "Epoch 105/150\n",
      "303/303 [==============================] - 0s 53us/sample - loss: 0.5055 - acc: 0.7525\n",
      "Epoch 106/150\n",
      "303/303 [==============================] - 0s 53us/sample - loss: 0.5048 - acc: 0.7459\n",
      "Epoch 107/150\n",
      "303/303 [==============================] - 0s 53us/sample - loss: 0.5036 - acc: 0.7591\n",
      "Epoch 108/150\n",
      "303/303 [==============================] - 0s 53us/sample - loss: 0.4996 - acc: 0.7492\n",
      "Epoch 109/150\n",
      "303/303 [==============================] - 0s 49us/sample - loss: 0.5053 - acc: 0.7459\n",
      "Epoch 110/150\n",
      "303/303 [==============================] - 0s 40us/sample - loss: 0.4965 - acc: 0.7525\n",
      "Epoch 111/150\n",
      "303/303 [==============================] - 0s 40us/sample - loss: 0.4946 - acc: 0.7393\n",
      "Epoch 112/150\n",
      "303/303 [==============================] - 0s 56us/sample - loss: 0.4918 - acc: 0.7525\n",
      "Epoch 113/150\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.4845 - acc: 0.7525\n",
      "Epoch 114/150\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.4877 - acc: 0.7624\n",
      "Epoch 115/150\n",
      "303/303 [==============================] - 0s 50us/sample - loss: 0.4840 - acc: 0.7426\n",
      "Epoch 116/150\n",
      "303/303 [==============================] - 0s 53us/sample - loss: 0.4781 - acc: 0.7558\n",
      "Epoch 117/150\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.4772 - acc: 0.7591\n",
      "Epoch 118/150\n",
      "303/303 [==============================] - 0s 59us/sample - loss: 0.4772 - acc: 0.7492\n",
      "Epoch 119/150\n",
      "303/303 [==============================] - 0s 50us/sample - loss: 0.4744 - acc: 0.7591\n",
      "Epoch 120/150\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.4733 - acc: 0.7492\n",
      "Epoch 121/150\n",
      "303/303 [==============================] - 0s 56us/sample - loss: 0.4723 - acc: 0.7525\n",
      "Epoch 122/150\n",
      "303/303 [==============================] - 0s 53us/sample - loss: 0.4666 - acc: 0.7624\n",
      "Epoch 123/150\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.4659 - acc: 0.7624\n",
      "Epoch 124/150\n",
      "303/303 [==============================] - 0s 59us/sample - loss: 0.4631 - acc: 0.7591\n",
      "Epoch 125/150\n",
      "303/303 [==============================] - 0s 53us/sample - loss: 0.4639 - acc: 0.7624\n",
      "Epoch 126/150\n",
      "303/303 [==============================] - 0s 53us/sample - loss: 0.4598 - acc: 0.7690\n",
      "Epoch 127/150\n",
      "303/303 [==============================] - 0s 56us/sample - loss: 0.4569 - acc: 0.7657\n",
      "Epoch 128/150\n",
      "303/303 [==============================] - 0s 69us/sample - loss: 0.4594 - acc: 0.7690\n",
      "Epoch 129/150\n",
      "303/303 [==============================] - 0s 63us/sample - loss: 0.4522 - acc: 0.7690\n",
      "Epoch 130/150\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.4514 - acc: 0.7690\n",
      "Epoch 131/150\n",
      "303/303 [==============================] - 0s 56us/sample - loss: 0.4517 - acc: 0.7690\n",
      "Epoch 132/150\n",
      "303/303 [==============================] - 0s 56us/sample - loss: 0.4485 - acc: 0.7723\n",
      "Epoch 133/150\n",
      "303/303 [==============================] - 0s 56us/sample - loss: 0.4491 - acc: 0.7690\n",
      "Epoch 134/150\n",
      "303/303 [==============================] - 0s 49us/sample - loss: 0.4454 - acc: 0.7723\n",
      "Epoch 135/150\n",
      "303/303 [==============================] - 0s 63us/sample - loss: 0.4436 - acc: 0.7756\n",
      "Epoch 136/150\n",
      "303/303 [==============================] - 0s 55us/sample - loss: 0.4435 - acc: 0.7690\n",
      "Epoch 137/150\n",
      "303/303 [==============================] - 0s 59us/sample - loss: 0.4433 - acc: 0.7756\n",
      "Epoch 138/150\n",
      "303/303 [==============================] - 0s 61us/sample - loss: 0.4393 - acc: 0.7855\n",
      "Epoch 139/150\n",
      "303/303 [==============================] - 0s 56us/sample - loss: 0.4485 - acc: 0.7690\n",
      "Epoch 140/150\n",
      "303/303 [==============================] - 0s 56us/sample - loss: 0.4389 - acc: 0.7756\n",
      "Epoch 141/150\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.4389 - acc: 0.7822\n",
      "Epoch 142/150\n",
      "303/303 [==============================] - 0s 56us/sample - loss: 0.4325 - acc: 0.7789\n",
      "Epoch 143/150\n",
      "303/303 [==============================] - 0s 66us/sample - loss: 0.4359 - acc: 0.7855\n",
      "Epoch 144/150\n",
      "303/303 [==============================] - 0s 56us/sample - loss: 0.4348 - acc: 0.7855\n",
      "Epoch 145/150\n",
      "303/303 [==============================] - 0s 59us/sample - loss: 0.4329 - acc: 0.7822\n",
      "Epoch 146/150\n",
      "303/303 [==============================] - 0s 53us/sample - loss: 0.4274 - acc: 0.7789\n",
      "Epoch 147/150\n",
      "303/303 [==============================] - 0s 53us/sample - loss: 0.4283 - acc: 0.7888\n",
      "Epoch 148/150\n",
      "303/303 [==============================] - 0s 59us/sample - loss: 0.4304 - acc: 0.7855\n",
      "Epoch 149/150\n",
      "303/303 [==============================] - 0s 56us/sample - loss: 0.4274 - acc: 0.7822\n",
      "Epoch 150/150\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.4246 - acc: 0.8053\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1970c68b0b8>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,y, epochs = 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 0s 102us/sample - loss: 0.4218 - acc: 0.7921\n",
      "acc: 79.2079210281372\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X,y)#just the feed forward portion of model to calculate just accuracy\n",
    "print(f\"{model.metrics_names[1]}: {scores[1]*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras \n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "batch_size = 50\n",
    "num_class = 10\n",
    "epochs = 150\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_20 (Dense)             (None, 16)                224       \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 10)                170       \n",
      "=================================================================\n",
      "Total params: 666\n",
      "Trainable params: 666\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Input to Hidden\n",
    "model.add(Dense(16, input_dim=13, activation='relu'))#first hidden layer has 16 neurons\n",
    "model.add(Dense(16, activation='relu'))\n",
    "# Output Layer\n",
    "model.add(Dense(10, activation='softmax'))#10 classes\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "                    optimizer='adam', \n",
    "                    metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 190 samples, validate on 22 samples\n",
      "Epoch 1/150\n",
      "190/190 [==============================] - 0s 984us/sample - loss: 24.6872 - acc: 0.0000e+00 - val_loss: 17.0108 - val_acc: 0.0000e+00\n",
      "Epoch 2/150\n",
      "190/190 [==============================] - 0s 74us/sample - loss: 14.5473 - acc: 0.1368 - val_loss: 10.2712 - val_acc: 0.4091\n",
      "Epoch 3/150\n",
      "190/190 [==============================] - 0s 63us/sample - loss: 11.4446 - acc: 0.5158 - val_loss: 8.2644 - val_acc: 0.5000\n",
      "Epoch 4/150\n",
      "190/190 [==============================] - 0s 100us/sample - loss: 8.3672 - acc: 0.5105 - val_loss: 4.9375 - val_acc: 0.4091\n",
      "Epoch 5/150\n",
      "190/190 [==============================] - 0s 89us/sample - loss: 4.4461 - acc: 0.4000 - val_loss: 2.6083 - val_acc: 0.3182\n",
      "Epoch 6/150\n",
      "190/190 [==============================] - 0s 95us/sample - loss: 2.4725 - acc: 0.4579 - val_loss: 3.3864 - val_acc: 0.5000\n",
      "Epoch 7/150\n",
      "190/190 [==============================] - 0s 100us/sample - loss: 2.6505 - acc: 0.4789 - val_loss: 2.6413 - val_acc: 0.5455\n",
      "Epoch 8/150\n",
      "190/190 [==============================] - 0s 89us/sample - loss: 1.7838 - acc: 0.5421 - val_loss: 1.6479 - val_acc: 0.5455\n",
      "Epoch 9/150\n",
      "190/190 [==============================] - 0s 79us/sample - loss: 1.7749 - acc: 0.5579 - val_loss: 1.4756 - val_acc: 0.5909\n",
      "Epoch 10/150\n",
      "190/190 [==============================] - 0s 79us/sample - loss: 1.4964 - acc: 0.5526 - val_loss: 1.3856 - val_acc: 0.5000\n",
      "Epoch 11/150\n",
      "190/190 [==============================] - 0s 84us/sample - loss: 1.3216 - acc: 0.5632 - val_loss: 1.3544 - val_acc: 0.6818\n",
      "Epoch 12/150\n",
      "190/190 [==============================] - 0s 79us/sample - loss: 1.1937 - acc: 0.5737 - val_loss: 1.0707 - val_acc: 0.6364\n",
      "Epoch 13/150\n",
      "190/190 [==============================] - 0s 89us/sample - loss: 1.1156 - acc: 0.5895 - val_loss: 0.9623 - val_acc: 0.6364\n",
      "Epoch 14/150\n",
      "190/190 [==============================] - 0s 84us/sample - loss: 1.0580 - acc: 0.5789 - val_loss: 0.9050 - val_acc: 0.6364\n",
      "Epoch 15/150\n",
      "190/190 [==============================] - 0s 89us/sample - loss: 1.0006 - acc: 0.5947 - val_loss: 0.7927 - val_acc: 0.6364\n",
      "Epoch 16/150\n",
      "190/190 [==============================] - 0s 111us/sample - loss: 0.9734 - acc: 0.5737 - val_loss: 0.7508 - val_acc: 0.6818\n",
      "Epoch 17/150\n",
      "190/190 [==============================] - 0s 89us/sample - loss: 0.9598 - acc: 0.5737 - val_loss: 0.6956 - val_acc: 0.6364\n",
      "Epoch 18/150\n",
      "190/190 [==============================] - 0s 84us/sample - loss: 0.9699 - acc: 0.5526 - val_loss: 0.6952 - val_acc: 0.6364\n",
      "Epoch 19/150\n",
      "190/190 [==============================] - 0s 89us/sample - loss: 0.9863 - acc: 0.5737 - val_loss: 0.6729 - val_acc: 0.6364\n",
      "Epoch 20/150\n",
      "190/190 [==============================] - 0s 89us/sample - loss: 0.9523 - acc: 0.5632 - val_loss: 0.7218 - val_acc: 0.7727\n",
      "Epoch 21/150\n",
      "190/190 [==============================] - 0s 116us/sample - loss: 0.9096 - acc: 0.5789 - val_loss: 0.6698 - val_acc: 0.6364\n",
      "Epoch 22/150\n",
      "190/190 [==============================] - 0s 105us/sample - loss: 0.9057 - acc: 0.5789 - val_loss: 0.6681 - val_acc: 0.6364\n",
      "Epoch 23/150\n",
      "190/190 [==============================] - 0s 105us/sample - loss: 0.9215 - acc: 0.6000 - val_loss: 0.6950 - val_acc: 0.7727\n",
      "Epoch 24/150\n",
      "190/190 [==============================] - 0s 142us/sample - loss: 0.9062 - acc: 0.5789 - val_loss: 0.6695 - val_acc: 0.5909\n",
      "Epoch 25/150\n",
      "190/190 [==============================] - 0s 111us/sample - loss: 0.8877 - acc: 0.5947 - val_loss: 0.6837 - val_acc: 0.7727\n",
      "Epoch 26/150\n",
      "190/190 [==============================] - 0s 100us/sample - loss: 0.8825 - acc: 0.5947 - val_loss: 0.6570 - val_acc: 0.6364\n",
      "Epoch 27/150\n",
      "190/190 [==============================] - 0s 89us/sample - loss: 0.8962 - acc: 0.6105 - val_loss: 0.6516 - val_acc: 0.5909\n",
      "Epoch 28/150\n",
      "190/190 [==============================] - 0s 100us/sample - loss: 0.8390 - acc: 0.6105 - val_loss: 0.6688 - val_acc: 0.7727\n",
      "Epoch 29/150\n",
      "190/190 [==============================] - 0s 111us/sample - loss: 0.8394 - acc: 0.6053 - val_loss: 0.6278 - val_acc: 0.6364\n",
      "Epoch 30/150\n",
      "190/190 [==============================] - 0s 84us/sample - loss: 0.8294 - acc: 0.5947 - val_loss: 0.6128 - val_acc: 0.6364\n",
      "Epoch 31/150\n",
      "190/190 [==============================] - 0s 89us/sample - loss: 0.8502 - acc: 0.5947 - val_loss: 0.6338 - val_acc: 0.7727\n",
      "Epoch 32/150\n",
      "190/190 [==============================] - 0s 89us/sample - loss: 0.8216 - acc: 0.6158 - val_loss: 0.6005 - val_acc: 0.6364\n",
      "Epoch 33/150\n",
      "190/190 [==============================] - 0s 84us/sample - loss: 0.8074 - acc: 0.6158 - val_loss: 0.6219 - val_acc: 0.7727\n",
      "Epoch 34/150\n",
      "190/190 [==============================] - 0s 84us/sample - loss: 0.8319 - acc: 0.6053 - val_loss: 0.5995 - val_acc: 0.6364\n",
      "Epoch 35/150\n",
      "190/190 [==============================] - 0s 84us/sample - loss: 0.7920 - acc: 0.6211 - val_loss: 0.6214 - val_acc: 0.7727\n",
      "Epoch 36/150\n",
      "190/190 [==============================] - 0s 79us/sample - loss: 0.7793 - acc: 0.6105 - val_loss: 0.6011 - val_acc: 0.6364\n",
      "Epoch 37/150\n",
      "190/190 [==============================] - 0s 100us/sample - loss: 0.7651 - acc: 0.6158 - val_loss: 0.5955 - val_acc: 0.6364\n",
      "Epoch 38/150\n",
      "190/190 [==============================] - 0s 89us/sample - loss: 0.7759 - acc: 0.6316 - val_loss: 0.5915 - val_acc: 0.7273\n",
      "Epoch 39/150\n",
      "190/190 [==============================] - 0s 100us/sample - loss: 0.7643 - acc: 0.6368 - val_loss: 0.5942 - val_acc: 0.7727\n",
      "Epoch 40/150\n",
      "190/190 [==============================] - 0s 84us/sample - loss: 0.7516 - acc: 0.6158 - val_loss: 0.5796 - val_acc: 0.6364\n",
      "Epoch 41/150\n",
      "190/190 [==============================] - 0s 111us/sample - loss: 0.7404 - acc: 0.6158 - val_loss: 0.5851 - val_acc: 0.6818\n",
      "Epoch 42/150\n",
      "190/190 [==============================] - 0s 111us/sample - loss: 0.7287 - acc: 0.6263 - val_loss: 0.5865 - val_acc: 0.7727\n",
      "Epoch 43/150\n",
      "190/190 [==============================] - 0s 89us/sample - loss: 0.7226 - acc: 0.6368 - val_loss: 0.5753 - val_acc: 0.7727\n",
      "Epoch 44/150\n",
      "190/190 [==============================] - 0s 95us/sample - loss: 0.7110 - acc: 0.6105 - val_loss: 0.5696 - val_acc: 0.5909\n",
      "Epoch 45/150\n",
      "190/190 [==============================] - 0s 84us/sample - loss: 0.7043 - acc: 0.6105 - val_loss: 0.5717 - val_acc: 0.5909\n",
      "Epoch 46/150\n",
      "190/190 [==============================] - 0s 100us/sample - loss: 0.7085 - acc: 0.6158 - val_loss: 0.5727 - val_acc: 0.6364\n",
      "Epoch 47/150\n",
      "190/190 [==============================] - 0s 95us/sample - loss: 0.7121 - acc: 0.6737 - val_loss: 0.5747 - val_acc: 0.6364\n",
      "Epoch 48/150\n",
      "190/190 [==============================] - 0s 89us/sample - loss: 0.6996 - acc: 0.6526 - val_loss: 0.5984 - val_acc: 0.7727\n",
      "Epoch 49/150\n",
      "190/190 [==============================] - 0s 89us/sample - loss: 0.6666 - acc: 0.6737 - val_loss: 0.5767 - val_acc: 0.6364\n",
      "Epoch 50/150\n",
      "190/190 [==============================] - 0s 89us/sample - loss: 0.6540 - acc: 0.6895 - val_loss: 0.5663 - val_acc: 0.7273\n",
      "Epoch 51/150\n",
      "190/190 [==============================] - 0s 110us/sample - loss: 0.6369 - acc: 0.6579 - val_loss: 0.5522 - val_acc: 0.6818\n",
      "Epoch 52/150\n",
      "190/190 [==============================] - 0s 89us/sample - loss: 0.6217 - acc: 0.6947 - val_loss: 0.5531 - val_acc: 0.6818\n",
      "Epoch 53/150\n",
      "190/190 [==============================] - 0s 84us/sample - loss: 0.6136 - acc: 0.6947 - val_loss: 0.5466 - val_acc: 0.6364\n",
      "Epoch 54/150\n",
      "190/190 [==============================] - 0s 84us/sample - loss: 0.6088 - acc: 0.6789 - val_loss: 0.5581 - val_acc: 0.7273\n",
      "Epoch 55/150\n",
      "190/190 [==============================] - 0s 90us/sample - loss: 0.6071 - acc: 0.7000 - val_loss: 0.5413 - val_acc: 0.6818\n",
      "Epoch 56/150\n",
      "190/190 [==============================] - 0s 89us/sample - loss: 0.5892 - acc: 0.7053 - val_loss: 0.5429 - val_acc: 0.6818\n",
      "Epoch 57/150\n",
      "190/190 [==============================] - 0s 84us/sample - loss: 0.5835 - acc: 0.7105 - val_loss: 0.5398 - val_acc: 0.6818\n",
      "Epoch 58/150\n",
      "190/190 [==============================] - 0s 79us/sample - loss: 0.5731 - acc: 0.7211 - val_loss: 0.5381 - val_acc: 0.6818\n",
      "Epoch 59/150\n",
      "190/190 [==============================] - 0s 68us/sample - loss: 0.5704 - acc: 0.7105 - val_loss: 0.5361 - val_acc: 0.6818\n",
      "Epoch 60/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190/190 [==============================] - 0s 79us/sample - loss: 0.5670 - acc: 0.7368 - val_loss: 0.5340 - val_acc: 0.6818\n",
      "Epoch 61/150\n",
      "190/190 [==============================] - 0s 63us/sample - loss: 0.5556 - acc: 0.7421 - val_loss: 0.5310 - val_acc: 0.7273\n",
      "Epoch 62/150\n",
      "190/190 [==============================] - 0s 74us/sample - loss: 0.5738 - acc: 0.7053 - val_loss: 0.5360 - val_acc: 0.6818\n",
      "Epoch 63/150\n",
      "190/190 [==============================] - 0s 79us/sample - loss: 0.5508 - acc: 0.7474 - val_loss: 0.5337 - val_acc: 0.7273\n",
      "Epoch 64/150\n",
      "190/190 [==============================] - 0s 89us/sample - loss: 0.5414 - acc: 0.7632 - val_loss: 0.5396 - val_acc: 0.6818\n",
      "Epoch 65/150\n",
      "190/190 [==============================] - 0s 100us/sample - loss: 0.5379 - acc: 0.7632 - val_loss: 0.5471 - val_acc: 0.7727\n",
      "Epoch 66/150\n",
      "190/190 [==============================] - 0s 84us/sample - loss: 0.5352 - acc: 0.7474 - val_loss: 0.5312 - val_acc: 0.7273\n",
      "Epoch 67/150\n",
      "190/190 [==============================] - 0s 84us/sample - loss: 0.5273 - acc: 0.7526 - val_loss: 0.5342 - val_acc: 0.7273\n",
      "Epoch 68/150\n",
      "190/190 [==============================] - 0s 79us/sample - loss: 0.5207 - acc: 0.7579 - val_loss: 0.5365 - val_acc: 0.7273\n",
      "Epoch 69/150\n",
      "190/190 [==============================] - 0s 74us/sample - loss: 0.5198 - acc: 0.7526 - val_loss: 0.5300 - val_acc: 0.7273\n",
      "Epoch 70/150\n",
      "190/190 [==============================] - 0s 84us/sample - loss: 0.5195 - acc: 0.7947 - val_loss: 0.5322 - val_acc: 0.6818\n",
      "Epoch 71/150\n",
      "190/190 [==============================] - 0s 84us/sample - loss: 0.5153 - acc: 0.7474 - val_loss: 0.5282 - val_acc: 0.7273\n",
      "Epoch 72/150\n",
      "190/190 [==============================] - 0s 95us/sample - loss: 0.5109 - acc: 0.7789 - val_loss: 0.5298 - val_acc: 0.6818\n",
      "Epoch 73/150\n",
      "190/190 [==============================] - 0s 111us/sample - loss: 0.5035 - acc: 0.7632 - val_loss: 0.5360 - val_acc: 0.6818\n",
      "Epoch 74/150\n",
      "190/190 [==============================] - 0s 105us/sample - loss: 0.5056 - acc: 0.7684 - val_loss: 0.5249 - val_acc: 0.6818\n",
      "Epoch 75/150\n",
      "190/190 [==============================] - 0s 95us/sample - loss: 0.5021 - acc: 0.7789 - val_loss: 0.5453 - val_acc: 0.7727\n",
      "Epoch 76/150\n",
      "190/190 [==============================] - 0s 95us/sample - loss: 0.5099 - acc: 0.7737 - val_loss: 0.5313 - val_acc: 0.7273\n",
      "Epoch 77/150\n",
      "190/190 [==============================] - 0s 147us/sample - loss: 0.4919 - acc: 0.7737 - val_loss: 0.5540 - val_acc: 0.7727\n",
      "Epoch 78/150\n",
      "190/190 [==============================] - 0s 100us/sample - loss: 0.4926 - acc: 0.7789 - val_loss: 0.5293 - val_acc: 0.7273\n",
      "Epoch 79/150\n",
      "190/190 [==============================] - 0s 95us/sample - loss: 0.4947 - acc: 0.7474 - val_loss: 0.5397 - val_acc: 0.6818\n",
      "Epoch 80/150\n",
      "190/190 [==============================] - 0s 100us/sample - loss: 0.4803 - acc: 0.7842 - val_loss: 0.5276 - val_acc: 0.7273\n",
      "Epoch 81/150\n",
      "190/190 [==============================] - 0s 84us/sample - loss: 0.4848 - acc: 0.7737 - val_loss: 0.5312 - val_acc: 0.6818\n",
      "Epoch 82/150\n",
      "190/190 [==============================] - 0s 74us/sample - loss: 0.4784 - acc: 0.7842 - val_loss: 0.5313 - val_acc: 0.6818\n",
      "Epoch 83/150\n",
      "190/190 [==============================] - 0s 74us/sample - loss: 0.4765 - acc: 0.7842 - val_loss: 0.5297 - val_acc: 0.6818\n",
      "Epoch 84/150\n",
      "190/190 [==============================] - 0s 90us/sample - loss: 0.4814 - acc: 0.7842 - val_loss: 0.5444 - val_acc: 0.7727\n",
      "Epoch 85/150\n",
      "190/190 [==============================] - 0s 84us/sample - loss: 0.4784 - acc: 0.7737 - val_loss: 0.5221 - val_acc: 0.7273\n",
      "Epoch 86/150\n",
      "190/190 [==============================] - 0s 84us/sample - loss: 0.4765 - acc: 0.7789 - val_loss: 0.5244 - val_acc: 0.7273\n",
      "Epoch 87/150\n",
      "190/190 [==============================] - 0s 90us/sample - loss: 0.4873 - acc: 0.7737 - val_loss: 0.5253 - val_acc: 0.7273\n",
      "Epoch 88/150\n",
      "190/190 [==============================] - 0s 84us/sample - loss: 0.4937 - acc: 0.7579 - val_loss: 0.5479 - val_acc: 0.7273\n",
      "Epoch 89/150\n",
      "190/190 [==============================] - 0s 84us/sample - loss: 0.4694 - acc: 0.7684 - val_loss: 0.5241 - val_acc: 0.7273\n",
      "Epoch 90/150\n",
      "190/190 [==============================] - 0s 89us/sample - loss: 0.4603 - acc: 0.7947 - val_loss: 0.5279 - val_acc: 0.7273\n",
      "Epoch 91/150\n",
      "190/190 [==============================] - 0s 84us/sample - loss: 0.4699 - acc: 0.7737 - val_loss: 0.5448 - val_acc: 0.7273\n",
      "Epoch 92/150\n",
      "190/190 [==============================] - 0s 95us/sample - loss: 0.4687 - acc: 0.7895 - val_loss: 0.5194 - val_acc: 0.7727\n",
      "Epoch 93/150\n",
      "190/190 [==============================] - 0s 111us/sample - loss: 0.4564 - acc: 0.7842 - val_loss: 0.5282 - val_acc: 0.7273\n",
      "Epoch 94/150\n",
      "190/190 [==============================] - 0s 95us/sample - loss: 0.4576 - acc: 0.8053 - val_loss: 0.5188 - val_acc: 0.7273\n",
      "Epoch 95/150\n",
      "190/190 [==============================] - 0s 89us/sample - loss: 0.4479 - acc: 0.8053 - val_loss: 0.5195 - val_acc: 0.7273\n",
      "Epoch 96/150\n",
      "190/190 [==============================] - 0s 105us/sample - loss: 0.4475 - acc: 0.8105 - val_loss: 0.5230 - val_acc: 0.7273\n",
      "Epoch 97/150\n",
      "190/190 [==============================] - 0s 89us/sample - loss: 0.4434 - acc: 0.8158 - val_loss: 0.5152 - val_acc: 0.7273\n",
      "Epoch 98/150\n",
      "190/190 [==============================] - 0s 100us/sample - loss: 0.4461 - acc: 0.7947 - val_loss: 0.5223 - val_acc: 0.7273\n",
      "Epoch 99/150\n",
      "190/190 [==============================] - 0s 74us/sample - loss: 0.4480 - acc: 0.8158 - val_loss: 0.5252 - val_acc: 0.7727\n",
      "Epoch 100/150\n",
      "190/190 [==============================] - 0s 79us/sample - loss: 0.4386 - acc: 0.8000 - val_loss: 0.5080 - val_acc: 0.7727\n",
      "Epoch 101/150\n",
      "190/190 [==============================] - 0s 79us/sample - loss: 0.4430 - acc: 0.8000 - val_loss: 0.5151 - val_acc: 0.7727\n",
      "Epoch 102/150\n",
      "190/190 [==============================] - 0s 79us/sample - loss: 0.4387 - acc: 0.7895 - val_loss: 0.5028 - val_acc: 0.7727\n",
      "Epoch 103/150\n",
      "190/190 [==============================] - 0s 79us/sample - loss: 0.4400 - acc: 0.8105 - val_loss: 0.5016 - val_acc: 0.7727\n",
      "Epoch 104/150\n",
      "190/190 [==============================] - 0s 100us/sample - loss: 0.4321 - acc: 0.8105 - val_loss: 0.5017 - val_acc: 0.7273\n",
      "Epoch 105/150\n",
      "190/190 [==============================] - 0s 113us/sample - loss: 0.4343 - acc: 0.8000 - val_loss: 0.4931 - val_acc: 0.7727\n",
      "Epoch 106/150\n",
      "190/190 [==============================] - 0s 95us/sample - loss: 0.4331 - acc: 0.8000 - val_loss: 0.4898 - val_acc: 0.7727\n",
      "Epoch 107/150\n",
      "190/190 [==============================] - 0s 79us/sample - loss: 0.4277 - acc: 0.8158 - val_loss: 0.4949 - val_acc: 0.7727\n",
      "Epoch 108/150\n",
      "190/190 [==============================] - 0s 79us/sample - loss: 0.4278 - acc: 0.8105 - val_loss: 0.4916 - val_acc: 0.7273\n",
      "Epoch 109/150\n",
      "190/190 [==============================] - 0s 74us/sample - loss: 0.4385 - acc: 0.7789 - val_loss: 0.4874 - val_acc: 0.7727\n",
      "Epoch 110/150\n",
      "190/190 [==============================] - 0s 79us/sample - loss: 0.4258 - acc: 0.8211 - val_loss: 0.4863 - val_acc: 0.7727\n",
      "Epoch 111/150\n",
      "190/190 [==============================] - 0s 95us/sample - loss: 0.4304 - acc: 0.8105 - val_loss: 0.4842 - val_acc: 0.8182\n",
      "Epoch 112/150\n",
      "190/190 [==============================] - 0s 79us/sample - loss: 0.4422 - acc: 0.8105 - val_loss: 0.5161 - val_acc: 0.7727\n",
      "Epoch 113/150\n",
      "190/190 [==============================] - 0s 79us/sample - loss: 0.4146 - acc: 0.8053 - val_loss: 0.5019 - val_acc: 0.7727\n",
      "Epoch 114/150\n",
      "190/190 [==============================] - 0s 84us/sample - loss: 0.4604 - acc: 0.7737 - val_loss: 0.5092 - val_acc: 0.7727\n",
      "Epoch 115/150\n",
      "190/190 [==============================] - 0s 84us/sample - loss: 0.4400 - acc: 0.7737 - val_loss: 0.5298 - val_acc: 0.7273\n",
      "Epoch 116/150\n",
      "190/190 [==============================] - 0s 63us/sample - loss: 0.4467 - acc: 0.7947 - val_loss: 0.5087 - val_acc: 0.7727\n",
      "Epoch 117/150\n",
      "190/190 [==============================] - 0s 79us/sample - loss: 0.4300 - acc: 0.7895 - val_loss: 0.5254 - val_acc: 0.7273\n",
      "Epoch 118/150\n",
      "190/190 [==============================] - 0s 74us/sample - loss: 0.4164 - acc: 0.8105 - val_loss: 0.4983 - val_acc: 0.7727\n",
      "Epoch 119/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190/190 [==============================] - 0s 68us/sample - loss: 0.4421 - acc: 0.7947 - val_loss: 0.5260 - val_acc: 0.6818\n",
      "Epoch 120/150\n",
      "190/190 [==============================] - 0s 84us/sample - loss: 0.4225 - acc: 0.8211 - val_loss: 0.5006 - val_acc: 0.8182\n",
      "Epoch 121/150\n",
      "190/190 [==============================] - 0s 84us/sample - loss: 0.4192 - acc: 0.8105 - val_loss: 0.4941 - val_acc: 0.7727\n",
      "Epoch 122/150\n",
      "190/190 [==============================] - 0s 100us/sample - loss: 0.4074 - acc: 0.8474 - val_loss: 0.4981 - val_acc: 0.8182\n",
      "Epoch 123/150\n",
      "190/190 [==============================] - 0s 105us/sample - loss: 0.4072 - acc: 0.8158 - val_loss: 0.4975 - val_acc: 0.8182\n",
      "Epoch 124/150\n",
      "190/190 [==============================] - 0s 110us/sample - loss: 0.4028 - acc: 0.8368 - val_loss: 0.4895 - val_acc: 0.7727\n",
      "Epoch 125/150\n",
      "190/190 [==============================] - 0s 111us/sample - loss: 0.4253 - acc: 0.8053 - val_loss: 0.5241 - val_acc: 0.6364\n",
      "Epoch 126/150\n",
      "190/190 [==============================] - 0s 89us/sample - loss: 0.3989 - acc: 0.8474 - val_loss: 0.4922 - val_acc: 0.7727\n",
      "Epoch 127/150\n",
      "190/190 [==============================] - 0s 105us/sample - loss: 0.4409 - acc: 0.7895 - val_loss: 0.5452 - val_acc: 0.6364\n",
      "Epoch 128/150\n",
      "190/190 [==============================] - 0s 100us/sample - loss: 0.4128 - acc: 0.8316 - val_loss: 0.4842 - val_acc: 0.7727\n",
      "Epoch 129/150\n",
      "190/190 [==============================] - 0s 105us/sample - loss: 0.4009 - acc: 0.8158 - val_loss: 0.4907 - val_acc: 0.8182\n",
      "Epoch 130/150\n",
      "190/190 [==============================] - 0s 74us/sample - loss: 0.3983 - acc: 0.7947 - val_loss: 0.4930 - val_acc: 0.8182\n",
      "Epoch 131/150\n",
      "190/190 [==============================] - 0s 89us/sample - loss: 0.3965 - acc: 0.8211 - val_loss: 0.4851 - val_acc: 0.7727\n",
      "Epoch 132/150\n",
      "190/190 [==============================] - 0s 89us/sample - loss: 0.3951 - acc: 0.8263 - val_loss: 0.4948 - val_acc: 0.7727\n",
      "Epoch 133/150\n",
      "190/190 [==============================] - 0s 100us/sample - loss: 0.3886 - acc: 0.8316 - val_loss: 0.4836 - val_acc: 0.7727\n",
      "Epoch 134/150\n",
      "190/190 [==============================] - 0s 95us/sample - loss: 0.3893 - acc: 0.8158 - val_loss: 0.4971 - val_acc: 0.7727\n",
      "Epoch 135/150\n",
      "190/190 [==============================] - 0s 84us/sample - loss: 0.3945 - acc: 0.8421 - val_loss: 0.4781 - val_acc: 0.7727\n",
      "Epoch 136/150\n",
      "190/190 [==============================] - 0s 68us/sample - loss: 0.3972 - acc: 0.8421 - val_loss: 0.4919 - val_acc: 0.7727\n",
      "Epoch 137/150\n",
      "190/190 [==============================] - 0s 79us/sample - loss: 0.3981 - acc: 0.8158 - val_loss: 0.4705 - val_acc: 0.8182\n",
      "Epoch 138/150\n",
      "190/190 [==============================] - 0s 89us/sample - loss: 0.3859 - acc: 0.8263 - val_loss: 0.4756 - val_acc: 0.8182\n",
      "Epoch 139/150\n",
      "190/190 [==============================] - 0s 89us/sample - loss: 0.3869 - acc: 0.8579 - val_loss: 0.4734 - val_acc: 0.8182\n",
      "Epoch 140/150\n",
      "190/190 [==============================] - 0s 79us/sample - loss: 0.3916 - acc: 0.8158 - val_loss: 0.4733 - val_acc: 0.7727\n",
      "Epoch 141/150\n",
      "190/190 [==============================] - 0s 74us/sample - loss: 0.3891 - acc: 0.8316 - val_loss: 0.4675 - val_acc: 0.8182\n",
      "Epoch 142/150\n",
      "190/190 [==============================] - 0s 84us/sample - loss: 0.3840 - acc: 0.8421 - val_loss: 0.4596 - val_acc: 0.8182\n",
      "Epoch 143/150\n",
      "190/190 [==============================] - 0s 90us/sample - loss: 0.3827 - acc: 0.8158 - val_loss: 0.4720 - val_acc: 0.7727\n",
      "Epoch 144/150\n",
      "190/190 [==============================] - 0s 79us/sample - loss: 0.3844 - acc: 0.8632 - val_loss: 0.4543 - val_acc: 0.7727\n",
      "Epoch 145/150\n",
      "190/190 [==============================] - 0s 84us/sample - loss: 0.3842 - acc: 0.8368 - val_loss: 0.4543 - val_acc: 0.8182\n",
      "Epoch 146/150\n",
      "190/190 [==============================] - 0s 89us/sample - loss: 0.3816 - acc: 0.8105 - val_loss: 0.4610 - val_acc: 0.8182\n",
      "Epoch 147/150\n",
      "190/190 [==============================] - 0s 89us/sample - loss: 0.3851 - acc: 0.8368 - val_loss: 0.4523 - val_acc: 0.7727\n",
      "Epoch 148/150\n",
      "190/190 [==============================] - 0s 111us/sample - loss: 0.3907 - acc: 0.8211 - val_loss: 0.4567 - val_acc: 0.8182\n",
      "Epoch 149/150\n",
      "190/190 [==============================] - 0s 89us/sample - loss: 0.3842 - acc: 0.8158 - val_loss: 0.4714 - val_acc: 0.7273\n",
      "Epoch 150/150\n",
      "190/190 [==============================] - 0s 95us/sample - loss: 0.3842 - acc: 0.8263 - val_loss: 0.4484 - val_acc: 0.8182\n",
      "91/91 [==============================] - 0s 77us/sample - loss: 0.4243 - acc: 0.8352\n",
      "acc: 83.51648449897766\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=.3, verbose=1)\n",
    "scores = model.evaluate(X_test, y_test)\n",
    "print(f'{model.metrics_names[1]}: {scores[1]*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.9521966   0.68100522  1.97312292 ... -2.27457861 -0.71442887\n",
      "  -2.14887271]\n",
      " [-1.91531289  0.68100522  1.00257707 ... -2.27457861 -0.71442887\n",
      "  -0.51292188]\n",
      " [-1.47415758 -1.46841752  0.03203122 ...  0.97635214 -0.71442887\n",
      "  -0.51292188]\n",
      " ...\n",
      " [ 1.50364073  0.68100522 -0.93851463 ... -0.64911323  1.24459328\n",
      "   1.12302895]\n",
      " [ 0.29046364  0.68100522 -0.93851463 ... -0.64911323  0.26508221\n",
      "   1.12302895]\n",
      " [ 0.29046364 -1.46841752  0.03203122 ... -0.64911323  0.26508221\n",
      "  -0.51292188]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lilyx\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.6435643633206686 using {'batch_size': 10, 'epochs': 20}\n",
      "Means: 0.6435643633206686, Stdev: 0.09801480023980266 with: {'batch_size': 10, 'epochs': 20}\n",
      "Means: 0.6072607239087423, Stdev: 0.1838731048446351 with: {'batch_size': 20, 'epochs': 20}\n",
      "Means: 0.5742574234803518, Stdev: 0.19249725088068645 with: {'batch_size': 40, 'epochs': 20}\n",
      "Means: 0.6303630371888479, Stdev: 0.10236345271677881 with: {'batch_size': 60, 'epochs': 20}\n",
      "Means: 0.5643564462661743, Stdev: 0.13599603069479688 with: {'batch_size': 80, 'epochs': 20}\n",
      "Means: 0.6072607437769572, Stdev: 0.17040701058847882 with: {'batch_size': 100, 'epochs': 20}\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=13, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "\n",
    "# define the grid search parameters\n",
    "# batch_size = [10, 20, 40, 60, 80, 100]\n",
    "# param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "\n",
    "# define the grid search parameters\n",
    "param_grid = {'batch_size': [10, 20, 40, 60, 80, 100],\n",
    "              'epochs': [20]}\n",
    "\n",
    "# Create Grid Search\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1)\n",
    "grid_result = grid.fit(X, y)\n",
    "\n",
    "# Report Results\n",
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.7392739256223043 using {'batch_size': 80, 'epochs': 40}\n",
      "Means: 0.6237623890240988, Stdev: 0.11113833164922167 with: {'batch_size': 10, 'epochs': 20}\n",
      "Means: 0.6831683119138082, Stdev: 0.09323067008817769 with: {'batch_size': 10, 'epochs': 40}\n",
      "Means: 0.6501650214195251, Stdev: 0.0890477711927088 with: {'batch_size': 10, 'epochs': 60}\n",
      "Means: 0.6996699571609497, Stdev: 0.0567810333488688 with: {'batch_size': 10, 'epochs': 200}\n",
      "Means: 0.5082508126894633, Stdev: 0.2133249113268889 with: {'batch_size': 80, 'epochs': 20}\n",
      "Means: 0.7392739256223043, Stdev: 0.048728797331330224 with: {'batch_size': 80, 'epochs': 40}\n",
      "Means: 0.6105610728263855, Stdev: 0.12242399790778163 with: {'batch_size': 80, 'epochs': 60}\n",
      "Means: 0.669966995716095, Stdev: 0.07511424016599029 with: {'batch_size': 80, 'epochs': 200}\n"
     ]
    }
   ],
   "source": [
    "# define the grid search parameters\n",
    "param_grid = {'batch_size': [10,80],\n",
    "              'epochs': [20, 40, 60,200]}\n",
    "\n",
    "# Create Grid Search\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1)\n",
    "grid_result = grid.fit(X, y)\n",
    "\n",
    "# Report Results\n",
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.7227722803751627 using {'batch_size': 120, 'epochs': 40}\n",
      "Means: 0.4422442118326823, Stdev: 0.17901057088182598 with: {'batch_size': 50, 'epochs': 30}\n",
      "Means: 0.5841584304968516, Stdev: 0.11230825014069684 with: {'batch_size': 50, 'epochs': 40}\n",
      "Means: 0.603960394859314, Stdev: 0.14025432510167354 with: {'batch_size': 50, 'epochs': 60}\n",
      "Means: 0.5775577674309412, Stdev: 0.248556707560995 with: {'batch_size': 80, 'epochs': 30}\n",
      "Means: 0.5775577624638876, Stdev: 0.10519722816230292 with: {'batch_size': 80, 'epochs': 40}\n",
      "Means: 0.7194719513257345, Stdev: 0.030606009653565885 with: {'batch_size': 80, 'epochs': 60}\n",
      "Means: 0.5148515005906423, Stdev: 0.13790484396786407 with: {'batch_size': 120, 'epochs': 30}\n",
      "Means: 0.7227722803751627, Stdev: 0.029147743940335084 with: {'batch_size': 120, 'epochs': 40}\n",
      "Means: 0.7029703060785929, Stdev: 0.06907079559684301 with: {'batch_size': 120, 'epochs': 60}\n"
     ]
    }
   ],
   "source": [
    "# define the grid search parameters\n",
    "param_grid = {'batch_size': [50, 80, 120],\n",
    "              'epochs': [30, 40, 60]}\n",
    "\n",
    "# Create Grid Search\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1)\n",
    "grid_result = grid.fit(X, y)\n",
    "\n",
    "# Report Results\n",
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.7986798683802286 using {'batch_size': 120, 'epochs': 30}\n",
      "Means: 0.6039604047934214, Stdev: 0.35339740137832026 with: {'batch_size': 100, 'epochs': 30}\n",
      "Means: 0.6600660085678101, Stdev: 0.053826764654122956 with: {'batch_size': 100, 'epochs': 40}\n",
      "Means: 0.5049504935741425, Stdev: 0.18646135389123386 with: {'batch_size': 100, 'epochs': 80}\n",
      "Means: 0.7986798683802286, Stdev: 0.112114124532204 with: {'batch_size': 120, 'epochs': 30}\n",
      "Means: 0.6468646824359894, Stdev: 0.11211411108029981 with: {'batch_size': 120, 'epochs': 40}\n",
      "Means: 0.6204620599746704, Stdev: 0.06584138563353711 with: {'batch_size': 120, 'epochs': 80}\n",
      "Means: 0.4587458868821462, Stdev: 0.1756941592688734 with: {'batch_size': 160, 'epochs': 30}\n",
      "Means: 0.5973597466945648, Stdev: 0.2339279890957002 with: {'batch_size': 160, 'epochs': 40}\n",
      "Means: 0.6336633563041687, Stdev: 0.14370654534443086 with: {'batch_size': 160, 'epochs': 80}\n"
     ]
    }
   ],
   "source": [
    "# define the grid search parameters\n",
    "param_grid = {'batch_size': [100, 120, 160],\n",
    "              'epochs': [30, 40, 80]}\n",
    "\n",
    "# Create Grid Search\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1)\n",
    "grid_result = grid.fit(X, y)\n",
    "\n",
    "# Report Results\n",
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nteract": {
   "version": "0.14.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
