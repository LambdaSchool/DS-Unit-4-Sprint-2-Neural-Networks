{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "nteract": {
      "version": "0.22.4"
    },
    "colab": {
      "name": "DAVID_DODDS_LS_DS_Unit_4_Sprint_Challenge_2_DS12.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ddodds42/DS-Unit-4-Sprint-2-Neural-Networks/blob/master/DAVID_DODDS_LS_DS_Unit_4_Sprint_Challenge_2_DS12.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omT98aVQqS3o",
        "colab_type": "text"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "## *Data Science Unit 4 Sprint 2*\n",
        "\n",
        "# Sprint Challenge - Neural Network Foundations\n",
        "\n",
        "Table of Problems\n",
        "\n",
        "1. [Defining Neural Networks](#Q1)\n",
        "2. [Simple Perceptron](#Q2)\n",
        "    - Perceptron\n",
        "    - Multilayer Perceptron\n",
        "    - Analyze and Compare\n",
        "4. [Keras MMP](#Q3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ucxg_gOoqS3x",
        "colab_type": "text"
      },
      "source": [
        "<a id=\"Q1\"></a>\n",
        "## 1. Defining Neural Networks \n",
        "\n",
        "Write *your own* definitions for the following terms:\n",
        "\n",
        "- **Neuron:** also known as a node, this is a function within a neural network which recieves input values either from the raw original data, or from one or more previous nodes. It applies weight coefficients and a bias intercept to those input values, and the sum of those weights and biases applied to each prior input are run through an activation function to relativize the output of the node compared to all other outputs in its layer. This final relativized output is the activation value, which is then input to one or many subsequent nodes, or is interpreted as an output value of the neural network in the case of the output layer.\n",
        "\n",
        "- **Input Layer:** the first layer of nodes in a neural network, recieving the normalized or transformed version of the original data, which enters the neural network as a vector. Each node corresponds to a feature of the observation. The input layer does itself have weights, biases, and an activation function, but it only outputs activation values to the next layer. It does not recieve activation values. It only recieves the vectorized raw data.\n",
        "\n",
        "- **Hidden Layer:** a layer of nodes which does not recieve inputs from the original data. It only recieves activation values from previous nodes of the neural network. However, nodes in a hidden layer also do not present a final output value from the neural network. They recieve activation values, and must also pass activation values on to other nodes in subsequent layers. Hidden layer nodes are therefore intermediating nodes. They also have weights, biases, and an activation function.\n",
        "\n",
        "- **Output Layer:** a layer of nodes which does not recive input activation values from the original data, but from previous nodes in the neural network; but unlike a hidden layer, it's output activation values are the final outputs of the neural network. These output activation values are interpreted as probablilities, each node either representing a class within the target, a target itself, or some medley of the two. Nodes in the output layer also have wights, biases, and activation functions, but their output activation values are the final interpretation of the neural network upon that data observation. No further nodes recieve activation values from the output layer.\n",
        "\n",
        "- **Activation Function:**  a function which relates the nodes that are members of the same layer. Each node being a function that presents to the activation function its weighted sum, the activation function then returns to the node an activation value that is calculated relative to all of the other nodes encapsulated by that activation function. It is that activation value that is then passed from one node to the next layer, or as an output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1XIMrAiqS31",
        "colab_type": "text"
      },
      "source": [
        "Explain how back propagation works as if you were explaining it to a five year-old. Use your own words, but feel free to reference external materials for this question. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1D3lklprVYU",
        "colab_type": "text"
      },
      "source": [
        "# Do you remember a few years ago, when you were 2, and the only thing that came out of your mouth was a question about this or that? Well... sometimes, you would point at blue or green things, and ask... RED? And I would have to kindly tell you... \"No... silly! that's green!\" Or \"No, that's blue\", or \"Yes, red!\" if it was actually red. Anyway, you and I kept doing this until you finally understood that cardinals, stop signs, fire hydrants, fire fighters, and bricks were red... and that grass, violets, the midday sky, and your eyes were not red. That's what back propagation is. It's a neural network, in the computer's brain, changing its guesses about the world when it gets it wrong."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrXJq6eDqS4N",
        "colab_type": "text"
      },
      "source": [
        "Remember our Simple Perceptron Class from Monday. In a simple prediction describe the process of making a prediction. How do you go from inputs to predicted output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q96jwLvAs41c",
        "colab_type": "text"
      },
      "source": [
        "# Ok, I'm going to explain this like you're 15 and know a little bit more about the world. Particularly math.\n",
        "\n",
        "1] The raw data is vectorized, usually into a float value from between 1 and 0\n",
        "\n",
        "2] A single observation is fed into the input layer as a vector, usually with each utilized feature being passed to a single input node.\n",
        "\n",
        "3] Input nodes take the input value, multipy it by a weight, add a bias to that product, and pass that weighted sum into the activation function for the input layer.\n",
        "\n",
        "4] The acivation function of the input layer uses a compression-type function to compress sometimes radically varying input values to within 1 and 0, relative to the range of other weighted sums it recieves from nodes of that layer. It then returns to the respective node its \"squishified\", or [1,0] compressed weighted sum (the activation value).\n",
        "\n",
        "5] The node then passes its activation value on to other nodes in the next layer, as an input to that node's weight/bias function.\n",
        "\n",
        "6] If the next node in the network, recieving that prior activation value, is a hidden layer node, steps 3-5 are repeated for that node and that layer, and it's activation value is passed onto one or many nodes in the subsequent layer.\n",
        "\n",
        "7] If the next node in the network, recieving that prior activation value, is an output layer node, steps 3-5 are repeated for that node and that layer, but it's activation value is not passed into another node. It is output to us, the consumer of that data, assigned to a target or target class, as a probability that the observation it came from represents a result in that target or that target class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohbt69Q_qS4g",
        "colab_type": "text"
      },
      "source": [
        "<a id=\"Q2\"></a>\n",
        "## 2. Simple Perceptron\n",
        "\n",
        "In this question, you will build two neural networks using Tensorflow Keras. After you build these two models, compare the results of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqPgfKkCqS4l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Our Dataset\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "\n",
        "xx, yy = np.meshgrid(np.linspace(-3, 3, 50),\n",
        "                     np.linspace(-3, 3, 50))\n",
        "rng = np.random.RandomState(0)\n",
        "\n",
        "\"Use this X & y in the following 2 models\"\n",
        "X = rng.randn(300, 2)\n",
        "y = np.array(np.logical_xor(X[:, 0] > 0, X[:, 1] > 0), \n",
        "             dtype=int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETIj79oqY4O1",
        "colab_type": "text"
      },
      "source": [
        "## Just to take a peak at these arrays..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5GYxCbRui7a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "28966b73-37b9-4bf2-c695-9667d23f3eef"
      },
      "source": [
        "X[:2]"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.76405235, 0.40015721],\n",
              "       [0.97873798, 2.2408932 ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfxWWh0BulJ6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4e8e6788-979d-47e1-8c5f-4bdf0531dbd4"
      },
      "source": [
        "y[:2]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rF6IdDkJupCH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6bbec548-ff03-416f-b28a-f49484e8ed45"
      },
      "source": [
        "X.shape, y.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((300, 2), (300,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoz5A-RrqS4s",
        "colab_type": "text"
      },
      "source": [
        "### Simple Perceptron\n",
        "Construct a simple perceptron using Keras. You model should have 1 dense layer with a single neuron and a sigmoid activation function. Your model should be called `model1` and make sure to save the results of your fit statement to a variable called `h1`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HThqz-AYqS4t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "outputId": "8952a526-8a29-47b8-b33c-a62bf30890bb"
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "\n",
        "stop = EarlyStopping(monitor='accuracy', min_delta=0.01, patience=8)\n",
        "\n",
        "model1 = Sequential([\n",
        "      Dense(1,activation='sigmoid', input_dim=2)\n",
        "])\n",
        "\n",
        "model1.compile(optimizer='sgd', loss='binary_crossentropy', metrics='accuracy')\n",
        "\n",
        "h1 = model1.fit(X,y,epochs=100,callbacks=[stop])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7939 - accuracy: 0.4733\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7843 - accuracy: 0.4733\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7776 - accuracy: 0.4700\n",
            "Epoch 4/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7715 - accuracy: 0.4733\n",
            "Epoch 5/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7606 - accuracy: 0.4633\n",
            "Epoch 6/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7603 - accuracy: 0.4600\n",
            "Epoch 7/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7569 - accuracy: 0.4600\n",
            "Epoch 8/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7624 - accuracy: 0.4600\n",
            "Epoch 9/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7543 - accuracy: 0.4500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0Y6YSEvwWhP",
        "colab_type": "text"
      },
      "source": [
        "# 47.33% accuracy. Eww. It must not be a linear decision boundary."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "821Qn8LQqS43",
        "colab_type": "text"
      },
      "source": [
        "### Multi-Layer Perceptron\n",
        "Now construct a multi-layer perceptron using Keras. Here are some architecture suggestions: \n",
        "- 2 Hidden Layers\n",
        "- 5-32 Neurons in the Hidden Layers\n",
        "- Your pick of activation function and optimizer\n",
        "- Incorporate the Callback function below into your model\n",
        "\n",
        "Your model should be called `model2` and make sure to save the results of your fit statement to a variable called `h2`. You must also monitor the metric 'accuracy'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxYR_S2gqS44",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class myCallback(tf.keras.callbacks.Callback): \n",
        "    def on_epoch_end(self, epoch, logs={}): \n",
        "        if(logs.get('accuracy') > .99999):   \n",
        "            self.model.stop_training = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOQJlkYtZMEu",
        "colab_type": "text"
      },
      "source": [
        "## So relieved that the callback function fit in seemlessly..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYF2wyg0qS5A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "60309f84-7edd-4641-f667-36283acb6619"
      },
      "source": [
        "model2 = Sequential([\n",
        "      Dense(32,activation='relu', input_dim=2),\n",
        "      Dense(8,activation='relu'),\n",
        "      Dense(1,activation='sigmoid')\n",
        "])\n",
        "\n",
        "model2.compile(optimizer='adam', loss='binary_crossentropy', metrics='accuracy')\n",
        "\n",
        "h2 = model2.fit(X,y,epochs=100,callbacks=[myCallback()])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6949 - accuracy: 0.5567\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6760 - accuracy: 0.6067\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6575 - accuracy: 0.6800\n",
            "Epoch 4/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6417 - accuracy: 0.7633\n",
            "Epoch 5/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6277 - accuracy: 0.8033\n",
            "Epoch 6/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6086 - accuracy: 0.8567\n",
            "Epoch 7/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5902 - accuracy: 0.9033\n",
            "Epoch 8/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5738 - accuracy: 0.9233\n",
            "Epoch 9/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5593 - accuracy: 0.9367\n",
            "Epoch 10/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5429 - accuracy: 0.9367\n",
            "Epoch 11/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5315 - accuracy: 0.9433\n",
            "Epoch 12/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5103 - accuracy: 0.9433\n",
            "Epoch 13/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.4955 - accuracy: 0.9467\n",
            "Epoch 14/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.4750 - accuracy: 0.9467\n",
            "Epoch 15/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.4524 - accuracy: 0.9400\n",
            "Epoch 16/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.4409 - accuracy: 0.9433\n",
            "Epoch 17/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.4114 - accuracy: 0.9433\n",
            "Epoch 18/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.3972 - accuracy: 0.9433\n",
            "Epoch 19/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.3788 - accuracy: 0.9467\n",
            "Epoch 20/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.3664 - accuracy: 0.9500\n",
            "Epoch 21/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.3513 - accuracy: 0.9500\n",
            "Epoch 22/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.3400 - accuracy: 0.9533\n",
            "Epoch 23/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.3274 - accuracy: 0.9567\n",
            "Epoch 24/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.3139 - accuracy: 0.9567\n",
            "Epoch 25/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2959 - accuracy: 0.9567\n",
            "Epoch 26/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2861 - accuracy: 0.9600\n",
            "Epoch 27/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2716 - accuracy: 0.9600\n",
            "Epoch 28/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2702 - accuracy: 0.9633\n",
            "Epoch 29/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2586 - accuracy: 0.9633\n",
            "Epoch 30/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2417 - accuracy: 0.9633\n",
            "Epoch 31/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.9633\n",
            "Epoch 32/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2372 - accuracy: 0.9633\n",
            "Epoch 33/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2267 - accuracy: 0.9633\n",
            "Epoch 34/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2166 - accuracy: 0.9633\n",
            "Epoch 35/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2207 - accuracy: 0.9700\n",
            "Epoch 36/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2091 - accuracy: 0.9700\n",
            "Epoch 37/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2023 - accuracy: 0.9733\n",
            "Epoch 38/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1953 - accuracy: 0.9767\n",
            "Epoch 39/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1926 - accuracy: 0.9767\n",
            "Epoch 40/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1942 - accuracy: 0.9767\n",
            "Epoch 41/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1767 - accuracy: 0.9767\n",
            "Epoch 42/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1727 - accuracy: 0.9700\n",
            "Epoch 43/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1769 - accuracy: 0.9767\n",
            "Epoch 44/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1686 - accuracy: 0.9767\n",
            "Epoch 45/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1675 - accuracy: 0.9800\n",
            "Epoch 46/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1737 - accuracy: 0.9800\n",
            "Epoch 47/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1593 - accuracy: 0.9800\n",
            "Epoch 48/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1535 - accuracy: 0.9800\n",
            "Epoch 49/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1513 - accuracy: 0.9800\n",
            "Epoch 50/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1490 - accuracy: 0.9833\n",
            "Epoch 51/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1435 - accuracy: 0.9833\n",
            "Epoch 52/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1425 - accuracy: 0.9900\n",
            "Epoch 53/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1433 - accuracy: 0.9900\n",
            "Epoch 54/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1351 - accuracy: 0.9867\n",
            "Epoch 55/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1353 - accuracy: 0.9867\n",
            "Epoch 56/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1296 - accuracy: 0.9833\n",
            "Epoch 57/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1351 - accuracy: 0.9833\n",
            "Epoch 58/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1252 - accuracy: 0.9833\n",
            "Epoch 59/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1257 - accuracy: 0.9900\n",
            "Epoch 60/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1237 - accuracy: 0.9900\n",
            "Epoch 61/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1218 - accuracy: 0.9900\n",
            "Epoch 62/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1172 - accuracy: 0.9900\n",
            "Epoch 63/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1183 - accuracy: 0.9933\n",
            "Epoch 64/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1146 - accuracy: 0.9933\n",
            "Epoch 65/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1217 - accuracy: 0.9933\n",
            "Epoch 66/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1127 - accuracy: 0.9933\n",
            "Epoch 67/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1083 - accuracy: 0.9933\n",
            "Epoch 68/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1109 - accuracy: 0.9933\n",
            "Epoch 69/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1062 - accuracy: 0.9933\n",
            "Epoch 70/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1044 - accuracy: 0.9933\n",
            "Epoch 71/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1021 - accuracy: 0.9933\n",
            "Epoch 72/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1007 - accuracy: 0.9933\n",
            "Epoch 73/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1004 - accuracy: 0.9933\n",
            "Epoch 74/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0976 - accuracy: 0.9967\n",
            "Epoch 75/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0976 - accuracy: 0.9967\n",
            "Epoch 76/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1019 - accuracy: 0.9967\n",
            "Epoch 77/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0972 - accuracy: 0.9967\n",
            "Epoch 78/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0940 - accuracy: 0.9967\n",
            "Epoch 79/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0984 - accuracy: 0.9933\n",
            "Epoch 80/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0916 - accuracy: 0.9967\n",
            "Epoch 81/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0864 - accuracy: 0.9967\n",
            "Epoch 82/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0889 - accuracy: 0.9967\n",
            "Epoch 83/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0866 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0L59_64ZbeF",
        "colab_type": "text"
      },
      "source": [
        "## 100% accuracy in 83 epochs. I can live with that."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "886zuuk9qS5L",
        "colab_type": "text"
      },
      "source": [
        "### Analyze and Compare\n",
        "\n",
        "**Before you Start**: You will need to install an additional library for this next segment. Install the package `mlxtend` into the environment you are using for the sprint challenge.\n",
        "\n",
        "\n",
        "The cells below generate decision boundary plots of your models (`model1` & `model2`). Review the plots."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weQqwfxNqS34",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import mlxtend"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DQLJVWHqS5M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "outputId": "8b914f21-30fe-485f-e523-15550973277e"
      },
      "source": [
        "# Do Not change anything in this cell\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from mlxtend.plotting import plot_decision_regions\n",
        "\n",
        "h = .02  # step size in the mesh\n",
        "\n",
        "# create a mesh to plot in\n",
        "x_min, x_max = X[:, 0].min() - .2, X[:, 0].max() + .2\n",
        "y_min, y_max = X[:, 1].min() - .2, X[:, 1].max() + .2\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
        "                     np.arange(y_min, y_max, h))\n",
        "\n",
        "fig = plt.figure(figsize=(12,6))\n",
        "\n",
        "\n",
        "for clf, hist, name, grd in zip([model1,model2], [h1, h2],['Perceptron', 'Multi-Layer Perceptron'],[1,2]):\n",
        "\n",
        "    ax = plt.subplot(1,2, grd)\n",
        "    fig = plot_decision_regions(X=X, y=y, clf=clf, legend=2)\n",
        "    title = f\"{name} with {hist.history['accuracy'][-1]:,.2f} Accuracy\"\n",
        "    plt.title(title)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/mlxtend/plotting/decision_regions.py:244: MatplotlibDeprecationWarning: Passing unsupported keyword arguments to axis() will raise a TypeError in 3.3.\n",
            "  ax.axis(xmin=xx.min(), xmax=xx.max(), y_min=yy.min(), y_max=yy.max())\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsEAAAF1CAYAAAAJAjeKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOydd5hTZfbHP2+S6TMMDEOvUmyAKPaG2AVRQV0U22JFFHctq6s/3V133RV2XdsKIooNKaIiymJvFMVVRBRsWBApMgzTe0ve3x/3ZshkUibJzSSZnM/z5JnJLe99b5L7veee97znKK01giAIgiAIgpBM2GLdAUEQBEEQBEFob8QIFgRBEARBEJIOMYIFQRAEQRCEpEOMYEEQBEEQBCHpECNYEARBEARBSDrECBYEQRAEQRCSDjGChbhHKXWxUurtAOvHKKV2tGefBEGIX5RSWik1JMD6r5VSY9qxS0KMUEr1V0pVKaXsAbYJ+HsROi5iBLcjSqmtSqla84LcrZR6RimVHet+uVFK3a2UWhDrfnijtV6otT7N/T5SwVJKpSmlnlJKVSilCpRSN7dxv/fMYzs8lnl+p1WBjHWPfe422zky3HMQhI6IeT01KKXyvZZvMK+ZgWG0+YxS6u+ey7TWw7TWK/1sP9D7Oo8HzPNoMHWmRCn1jlJq/1j3y028OiO01tu01tlaayeAUmqlUuqqcNtTSg1XSr2llCpSSgUttKCUOlgptV4pVWP+PdhjnVJK/VMpVWy+/qmUUkHa20cp5VJKzQn3HIS9iBHc/pyltc4GRgGHAXeFsrN50cTke4vlsS3mbmAoMAA4EbhNKXVGoB2UUhcDKX5Wn2WKbLanse6nHQVcBpSYf9uNeLupC4IffgYmu98opUYAmbHrTvsT4Fr9l3n/6AsUAs9Y2HbU6SAa1Ai8AFwZbEOlVCrwKrAA6AI8C7xqLge4BpgAjAQOAs4CpgZp9jKgFLhAKZUWzgmESyBvesKitZZXO72ArcApHu/vA1aY/x8FrAXKgC+BMR7brQT+AXwE1AJDgGHAOxjG1G7g/8xtbcDtwE9AMcbFmmeuGwhojAvvV2AX8Adz3RlAA8YFXgV8GeDYxwDrgHLz7zFefb3H3L4SeBvI9/N5rALOM/8/1uzbmeb7k4EvzP+nAB+a/682t6s2+3kBMAbYAdyCcWPYBVwe4Hv4FTjN4/09wPMBts8Fvje/Iw04/H2nbfgNjDY/x4vN7yfVY10GcD/wi/nZfghkmOuO8/h9bAemeHzeV3m00fxZme81cD3wA/Czuexhs40KYD1wvMf2duD/zN9Ppbm+HzAbuN/rXJYDN8X6upJXx3mZ19NdwDqPZf8G7jR/ywPNZW353Q/B0LpGDG2rAv7rcRyf1y17ddLhY90RwMfmdbgLmOW+hoNdI0BvYCmwB8PQ/53HdncDL2EYSxWe5+axzTPA3z3enwlUhdM2kAc8jaGFpcArHtuPB74wz3EtcJDX93MH8I2539NAOpCFoWsu83OuMvvk69i9zc+lBPgRuNqrry8A8zH052vgMD/f01+BR8z/UzDuCfeZ7zOAOvM8m79PjHuZ01xXBczy+L1ci6GTZeZ3qYL8VocAOsg2pwE7PdsCtgFnmP+vBa7xWHcl8L8A7SkMbZ6Gcd8/32v9OeZ3V2Fu5z6Oz+8br+vG89rx+M3NAV43P99TMH53G8xjbAfu9tq/1b0KONzsr91ju3Mx7YyYak6sO5BMLzyEF8Ow+BrDAOuDYRCNwzBiTzXfdzO3XWleOMPMCzkHQ4BvwRCgHOBIc9vfA//D8BSkAXOBxeY6txgsxhCtERii6e7T3cACrz57H7uHeRFdar6fbL7v6rH9T8C+GEK0Epjp5/P4G3tFzG14/dNj3cPm/y0uVM+L1Hw/Bmgy90kxP8caoIuPY3Yx9+/hsex8YFOA7202cBM+bo7md7rb/BzfBkYG+Q08iSHyKeZ3fJ7XcVaavwc7xsNGGobHutL8rFOArsDBHp93MGPgHQwRdBvUl5htODB+QwVAurnuVmATsB+G4I40tz0CQ0Bt5nb55mfcI9D5ykteobzM6+kUYDNwgHkd7DCvgZCNYPP/Z/AwHj2P46cPra5zj3WHYjwMO8ztvgVuNNf5vUYwdH098GcgFRgEbAFON7e9G8NYn2Bum+Hj2M3nAWQDi4A14bQNvAYswdDDFOAEc9tDMBwJR5qf/W/NzyrN43P7CuP+lYfh7HD3aQyww6vPvo69GngU4951MIZ2nuSxfR2GhtuBGfgxCoGTMHUbQyt/Aj7xWPelr+8Tr9+Ox+9lBdAZ6G/26Ywgv9W2GME3AW94LVsB3GL+X4557zbfHwZUBmjveKDe/N4ewXyo8/j9lWPYDzaM+8j+5jp/3/cUghvB5RhOKpv5nY3BsB1sGN7r3cAEc/tA96pvgLEex1nm/hxi+eoIQ9uJxitKqTIML98q4F4Mo+R1rfXrWmuX1vod4DMMIXDzjNb6a611E8aTeoHW+n6tdZ3WulJr/Ym53bXAnVrrHVrregxROd9rGOqvWutqrfUmjKfDyQTG89inAT9orZ/TWjdprRcD32EM47h5Wmv9vda6FsPgO9hHm5jnf4L5/2gMwXO/P8Fc31Yagb9prRu11q9jPOXv52M7dwx2uceycowHiVYopQ7DEIBH/Bz3YgyRHQB8ALyllOrsp61M4DfAIq11I4aH5DJznQ24Avi91nqn1tqptV5rfocXAe9qrReb51estf7CT398MUNrXWJ+H2itF5htNGmt78cwtN2f1VXAXVrrzdrgS3PbT83P6WRzuwuBlVrr3SH0QxDaynMY18apGIbmzth2x0BrvV5r/T/z2tmK4WQ4wVwX6Bo5HMOp8TetdYPWegvwhLmNm4+11q+Y94BaP134g3n/+BFDy6aE2jaGoTcWuFZrXWpqiltrrwHmaq0/MTXoWQyj6yiPtmZprbdrrUswPKvB7h+ex87H0NM/mveuL4B5tAwN+9C8Fzoxfgcj/bULDFVKdcW4fzwJ9DHn2YR6/wDDWVOmtd6GoeX+7luhkE3Lew20vN94ry8HsgPEBf8Ww6guxXgIOkMp1d1cdyXwlNb6HfM3tFNr/Z1Sqhf+v++28KrW+iOzzTqt9Uqt9Sbz/UYMp5r7vh3oXvUshq2DUioPON08h5giRnD7M0Fr3VlrPUBrfZ0pdgOA3yilytwvjCGFXh77bff4vx/GU68vBgDLPNr5FmP4p4eftn7BGJ4KhOf2vc19PPkF46nTTYHH/zXsNTy9+RjYVynVA0Nw5gP9zEkxR2B4DNpKsWmkBztulfm3k8eyThhPry0wDdNHMQzTJu/1AKY41Gqta7TWMzCGgI7308eJGB7r1833C4GxSqluGDeHdHx/r4G+77bg+f2hlPqDUupbpVS5+RvJNY8f7FjNImb+fS6CPglCIJ7DuKFOwdCFqOExqbVKKdU/yLb7KqVWmBNqKzCcGJ6T+PxdIwOA3l4a/3/412V//Nu8f/TUWp+ttf4pjLb7ASWmIeXNAOAWr7b60fIeEen9o0Rr7am3we4f6b5iic1752cYBthoDKN3LYaRHY4R3Nb7VihU0fJeAy3vN97rO2GEuGjvhpRSGRhOlIUAWuuPMUZpLzI38afdgb7vtuB9/zhSKfWBUmqPUqocw/HWlvvHAuAspVQWMAlYo7XeFWafLEOM4PhgO/CcKW7uV5bWeqbHNtpr+0EB2hrr1Va61trTk9LP4//+GEN43sfwxHP5rxhC6Ul/wvDUaK1rMIbxfg98pbVuwBCxm4GftNZFobbZhmOWYoSSeHoXRmKEpnjTCWN4aolSqgAj/hlgh1LKn6GrMcIIfPFbDGHdZrb3IsaQ0UVAEcYw4GAf+233sxyMOC3PSUM9/fQJALPft2GIUBetdWcM74O7z4GOtQA4Ryk1EmOo+hU/2wlCRGitf8GIbR0HvOxjk7b87pubC3KsbI/XtiBdm4Mx8jVUa90Jw9j0vN79XSPbMWLyPXU5R2vtOdoXsJ8BCLXt7UCenxGr7cA/vNrK1MaIn5tI7x95SinPkbew7h8mqzBCHw7B0OdVGB7GQE6UcD/ncPgaOMjLs3sQe+83X9O2exEYTpROwKPmQ1gBxsPDb831/rQ70Pfd4jpSSgW8f5gswojp7qe1zgUeow33D9MG+RgjFvhS4sSJIkZwfOB+QjpdKWVXSqWb6Wb6+tl+BdBLKXWjMtJ95ai96bYeA/6hlBoAoJTqppQ6x2v/PymlMpVSw4DLMWKFwIjtGRgkA8TrGN7bi5RSDqXUBcCBZp/CYRUwnb1P7Su93vtiN/4fAtrCfOAupVQXZaQYuhrfs6zLMTwXB5sv903lUOATZeSfPFYplWp+Z7diPBF/5N2QUqoPxjDpeI/2RgL/BC4zhwqfAh5QSvU2fwdHm7N/FwKnKKUmmZ95V7U3zc4XwLnm9zmE4DOWczC80XsAh1Lqz7T0RMwD7lFKDTWzgRxkDjeitd6BcaN5DlgaYMhWEKzgSoxY0Wof60L53YerF2nmde1+2TCunwqgytSOaZ47BLhGPgUqlVJ/VEplmNf3cKXU4WH0y5uQ2ja9b29gGFNdlFIpSqnR5uongGtNb59SSmUppc70MlqvV0r1NYe076Tl/aOrUirXX0e11tsxHB0zzM/0IIzvLtzUnKswQim+MZ0oKzFCun7WWu/xs09E9w/zc0nHiL/GPA9/WRpWYozE/s68V083l79v/p0P3KyU6qOU6o0xR+MZP239FuMeMYK995BjgZHKyKDyJHC5UupkpZTNbHP/IN/3l8AwZaRxS8cInwxGDoZnuU4pdQR7PdEQ+F7lPt/bzHPw9XDb7ogRHAeYwnAOhldhD8bT1K34+X7MoaRTMeJwCzBmtJ5orn4Y4yntbaVUJcYkOe98tKswYsrewxhec+e2fdH8W6yU+tzPsYsxDLlbMCZ23QaMj8Bruwrjolrt570v7gaeVcZw3aQwjvkXjCGbX8zj3ae1fhNaJFbvrw0K3C+M7wZgtym4ORieoVIMT8YZGF74Yh/HvBQj28XbXm3+B8NTMBz4A8aktHUYM6f/iTHJZhuGAX6LufwL9noPHsSY+b4bYyh2YZBzfwt4EyPbxS8Y3mfP4a4HMOK438a42T+JMZnFzbMYAhYXT/FCx0Vr/ZPW+jM/q0P53T8JHGjqRSijF1UYGQ/cr5MwrtGLMIazn2CvAehJq2vEjG91PwD/jDHyMw8jFCkiwmz7Uox5FN9hTIS70WzrMwynwCwMXfsRIyTFk0UY+rAFQ0f/bu77HUZ86Bbzs/YXJjEZYx7FrxiTo/6itX63refrxVr2TrYDY/JVHYHvHw9jzJMpVUr9J4xjDsD4Pbg9trUYEzkBUEq9oZT6PwDzPjEBw1Avw5j3McFcDkZM+X8xdP8rjAlsc70P6OFEecjz/qG1Xo+h57/VRkz65RjXRjnGvc09auvv+/4eY0L5uxh2xIdtOP/rgL+Z9sWfMe4XmO0FuleB8X0PAJaZI8ExR/kIPRE6KMpINP8zkOIvxlUQAmF6EBYAA3zFrQlCstORrxGl1FaMzArhGq1CkqOU+gmYGi+/IfEEC4LQJpRSKRjx2/M62s1dEKxArhFB8I9S6jyMGOP3g23bXogRLAhCUJRSB2AM5/UCHopxdwQh7pBrRBD8o5RaiRE+eL05ByYukHAIQRAEQRAEIekQT7AgCIIgCIKQdIgRLAiCIAiCICQdraqwtAdPrN4iMRiCICQkV48e5K8YSsfli8WaGstr1wgC9y75mOwz/khGls/K9YIQMcP75HL04K4+dVs8wYIgCIIgCELSIUawIAiCIAiCkHSIESwIgiAIgiAkHWIEC4IgCIIgCElHTCbG+UKhyU1xkW4HpeJv3onWmjonlDfa0MRf/wRBENoTF4pqex5ORzrErSZq7E11ZDlLsCHzsQVBaEncGMG5KS46Z6XjUg6IQyMYrUnXTVBdR1mjPda9EQRBiCnV9jxSsjuTrZxxKdkAWkO9Tqe6CnKcxbHujiAIcUbchEOk24lfAxhAKVzKQbrYv4IgCDgd6aTFsQEMxu0kTTlNb7UgCEJL4sYIVkrFrwHsRqm4DNUQBEFof1TcSza4bysJ0FFBENqduDGC44XPPnyfK886jsvHHc2SeY/EujuCIAhCAN5cs579xk1jyOnXMPOJl2LdHUEQEggxgj1wOp3M/sf/8fdHF/L4q6tY+cYr/PLT5lh3SxAEQfCB0+nk+r/P5Y25f+Gb/85m8eur+ebHbbHuliAICULcTIwLhd9fNpHyiopWy3M7deLh+cvCbnfzpg306j+QXv0GAHDC2HP4+IO3GDB4v7DbFARBSHaOuOROisprWy3Pz83g0wX/CLvdTzf9wJD+vRjUrycAF449nlff/4QDh/QPu01BEJKHhDSCyysqGHrNrFbLf3h8ekTtFhcW0K1nn+b3+T16sXnjhojaFARBSHaKymsZNvXBVsu/nntTRO3u3F1Mv575ze/79sznk40yeicIQtuQcAhBEARBEAQh6YjYCFZKpSulPlVKfamU+lop9VcrOhYLunbvyZ6Cnc3vi3bvomuPnjHskSAIgvV0FN3u06Mr2wuKmt/vKCiiT/euMeyRIAiJhBWe4HrgJK31SOBg4Ayl1FEWtNvu7Df8YH795WcKdmyjsbGBVW+8ylFjTo91twRBEKymQ+j24cOH8sMvv/LzjgIaGhp5/o01nH3ikbHuliAICULEMcFaaw1UmW9TzFdC1qe0Oxxc93/3cue1k3E5nZw28UIGDpFJcYIgdCw6im47HHZm3TmV06++G6fLxRUTT2HYUJkUJwhC27BkYpxSyg6sB4YAs7XWn1jRrj9yO3XyOQkut1OniNs+YvTJHDH65IjbEQRBiGfaU7fzczN8ToLLz82IuO1xJxzGuBMOi7gdQRCSD0uMYK21EzhYKdUZWKaUGq61/spzG6XUNcA1AJfc8ndGnz057ONFkgZNEARBCK7bnpo9964ruWbsyLCPFUkaNEEQhGhhaYo0rXWZUuoD4AzgK691jwOPAzyxekvCDbsJgiB0RPzptqdm88ViTU2R7wYEQRASFCuyQ3QzPQkopTKAU4HvIm1XEARBiA6i24IgCNZ4gnsBz5rxZTbgBa31CgvaFQRBEKKD6LYgCEmPFdkhNgKHWNAXQRAEoR0Q3RYEQZCKcYIgCIIgCEISIkawBw/86SYuOGE4UyeOiXVXBEEQhCBccefDdD/uUoaf3TplpiAIQjDECPbg1HMm8fc5i2LdDUEQBKENTJl4Mm8+fnesuyEIQoKS0EZweWkx//jdJVSUlVjS3ojDjiYnt4slbQmCIAgtKSqt4Lzpf6O4rMKS9kYfNpy83GxL2hIEIflIaCP4/VcW4vr1S95btiDWXREEQRCCMP/ltyjd+SPPLn0r1l0RBEFIXCO4vLSYDe+8xEPn9mXDOy9Z5g0WBEEQrKeotIIV73zAnHN7sOKdDyzzBguCIIRLwhrB77+ykLOGwNAeGZw1BPEGC4IgxDHzX36L8YMV+/VIZ/xgJd5gQRBiTkIawW4v8EWH5gJw0aG54g0WBEGIU9xe4MsO7QTAZYd2Em+wIAgxJyGNYLcXuGt2CmD8tcIbPOO2adx0yXh2bP2JS04exZsvS6YIQRCESHF7gfOzjfpM+dkOS7zBk/9wH0dPvo3NW3fS98TLeXLp21Z0VxCEJMGKssntzqZP17BmVx2LN+5osbzznjVMvPx3Ybd7x7/mRNo1QRAEwYuVn37Jr7vqWbRpV4vlvYu+5OYrfxN2u4v/fWukXRMEIYlJSCP4z3NejHUXBEEQhDayfO7fY90FQRCEViRkOIQgCIIgCIIgRIIYwYIgCIIgCELSETdGsNYatI51NwKjtdFPQRCEpEfHvWSD+7aSAB0VBKHdiRsjuM4JNt0Uv4aw1th0E3XOWHdEEAQh9tib6qjX9riVbDBuJ/Xajr2pLtZdEfwQz78foeMTNxPjyhttUF1Huh2UUrHuTiu01tQ5zX4KgiAkOVnOEqqroM6RDsSfZhto7E2VZDklh3w8E4/3fCE5iBsjWKMoa7RDY6x7IgiCIATDhibHWQwyOiZEgJZQFSGGiFtTiBmVZSU8ceeVVJWXxrorgiAIQhCKyqo47/bHKC6vtrhl8QQLsUGMYCFmrHtjCY7dm/j09edj3RVBEAQhCPNfW0tpwXaeXfGRZW1KTLAQS8QIFmJCZVkJm1cv4/6Jfdi8epl4gwVBEOKYorIqVqxax5xz81mxap1l3mCNlphgIWaIESzEhHVvLOGsoTCkewZnDUW8wYIgCHHM/NfWMn6Ijf26pzF+iM1SbzBiBAsxQoxgod1xe4Enj8oFYPKoXPEGC4IgxCluL/Blo7IAuGxUlqXeYEGIFWIEC+2O2wvcNSsFMP6KN1gQBCE+cXuB87ONhFL52Q7LvMESEyzEkrhJkSYkDz9s+IgNhXUs2bijxfLsgo84afK0GPVKEARB8MXKz7/n18J6Fm0qbLG89+7vufni0yJqW2uJCRZihxjBQrsz9V8LItq/sqyE5++7lcm3/Zvs3C4W9UoQBEHwxfL7p0e0f1FZFVNnLuDxOy6la25Wq/VKUqQJMUKMYCHh8Eytliie4xnTJ1NVVdlqeXZ2DnfMWhyDHgmCILQPnqnVvD3H8RoOIZqdHIgRLCQU7kl1syf24foVyzhi3IUJ4Q2uqqpk0FWPtFq+Zd4NMeiNIAhC++CZWm3ainX8dvyxLbzBGuKyVoZodnIgE+OEhEJSqwmCICQObUmtJjHBQqwQI1hIGCS1miAIQuLQltRqOl7jIYSkQIxgIWGQ1GqCIAiJQ1tSq2mNFMsQYobEBAsJg6RWEwRBSByimVpNEKxAjGAhYYg0tVosyc7O8TmhIjs7Jwa9EQRBiD5tSa2mtY7LFGmi2cmBGMGC0A5ISh1BEITWGNEQ8WcEi2YnBxITHEMqy0p44s4rZWKXIAhCglBUVsV5tz/WYnKXIAiJiXiCY0giFn3oSEgydEEQQiVQ4QchdEJNDiG6LVhJxEawUqofMB/ogTGy8bjW+uFI2+3oJGrRh46EJEMXkhXR7fAIVvhBCB2NDik7hOi2YCVWhEM0AbdorQ8EjgKuV0odaEG7HRop+iAIQgwR3Q6DthR+EEInHmOCheQgYiNYa71La/25+X8l8C3QJ9J2OzJS9EEQhFgiuh06bSn8IISOFMsQYomlE+OUUgOBQ4BPfKy7Rin1mVLqs9XLkztuJ9KiD9GaUNfeE/VkYqAgxB5/uu2p2Y8vfS8WXYsr2lL4wR/RmkzX3pP0onI8LZ5gIXZYZgQrpbKBpcCNWusK7/Va68e11odprQ8bffZkqw6bkPyw4SOWbKzj+Nk7ml9LNtbxw4a2Da15TqizknDajcSQjdZ5CILQNgLptqdmX3PeybHpYByx8vPvWbSpnsNmFza/Fm2qZ+Xn3wfd13MynZWE024khmxUzkMMYCGGWJIdQimVgiGkC7XWLwfbfvUTf2LYWdfStWdyjr5FUvQhWhPqwm033AwX8TAxMNGTocssaSESQtXtZKcthR98Ea3JdOG2G252i3iZFJjIui2aHX9YkR1CAU8C32qtH2jLPnMvH8W/l83mY1cPRp1zDWnpGZF2I2loOaGu2rL0auG0G4khG63zCIVEFx2ZJS2ESzi6LYRHy8l0dZalVgun3UgM2WidR6gksm6LZscfVoRDHAtcCpyklPrCfI0LtENmeip/nnwsd5+cx1fz7+Krla9IcHwbiNaEunDbDTfDhffxJo3M5tOX57B7+88RnYcgCG0mZN0WQidak+nCbTfc7Ba+jvfq+58y/pZZEZ+L3PmFWGJFdogPtdZKa32Q1vpg8/V6W/bt3zOPx647iYnddrJmzq3s+H5TpN3p0EQ6oc7KdiMxyL2Pl9FUyTmDnSx/9O6IzkMQhLYRiW4LbSeSyXRWtxuJQe7reCf0aeCnLb9ImjghoYmLinFjRg7k+OH9efzNV1jz4TJGTryOTl3yY92tuOOHDR+xobCOJRt3tFieXfBRRKEE4bQbyHAO1hfP47lcLqrLisjLUBTVraeqvFSKhgiC0CFY+fn3/FpYz6JNhS2W9979fUShBOG0G8hwDtYX7+O5XJo9pZXs1y2VFaukaIiQuMSFEQxgt9uYduYoJlfWMGPpfWzOHsohZ16GIyU11l2LGyKZUGd1u5EY5J7He3/xHPbdtYzpx+cza01R2LHBMuFAEIR4I9zJdNFoNxKD3Pt4Dyx8G3au5+bRuTywujys+OAjps2mqLKektIyUt8b37xcNFtoT+LGCHbTOSeTf04ZzTe/7Obf826n66Fnsu8Rkp4n3rDCIHeHVPzlgr0hFRctCS9TRDJOOEjkWdKCILQvVhnk7rCKFyYZOnPZqCwmvRC6N7iosp5hV9/Pt++9SP5JVzUvF80W2pO4M4LdHDigB09O786rH3/JS4+9y/5nXk2PfoNi3S3BQiIJqYiEjuI1TqS+CoLQMYgkrCJcRLOFaBG3RjAYVWQmHLMfYw8bxEPLn+GjVTkcMuFaMuWpqUNgVYxzZVkJ9UXbaawpJyUzN+j2Hclr3FFuDoIgJAZWxDkXlVVRVrSbhprW2uUL0WwhWsS1EewmLTWFP55/JAXFFcx48W809hrFyNMuwGaztOqz0M5YFeO87o0l7JNdT/nnr5N/XHJVI+xINwdBEOIfK8Iq5r+2lgHZjexe/7YFPUosRLPji4SyInt27cTDV4/ht4Mr+HDOH9j61SfBdxJaEUmp43g7jjuu+O4Ts9DfvUNjTXnUjiUIghArIil3HG/HWLFqHX89MZOa71bjbKiP2rEEIRgJZQS7OfKAvsz/3UkM3fM+q5/4M6WFu2LdpYTCs9Rxoh/HHVc8OD+VcT2L+XnutWyZd0PzSyYcCILQEfAsd5zoxxg/xMbQ/BTG9iymcP0botlCzEiIcAhfKKWYcupBnH9sPfe9/B822/sw6uyrSE1Lj3XX4ppISh3H23E8s0t0zcrn+q6NfFRezqUzn5Ncw4IgdBgiKXccj8d4YVIO+dm5/KlrE6/8uJsbHxbNFmJDwhrBbrIz0/jrJcfx86/FzDjZlZcAACAASURBVHz2TjIOOJEDjzsTpVSsuxaXtCx1XB21TAztcZxws0tImhpBEBKJluWO66KSiaE9j+GZWWLfPNFsIXYkvBHsZp/eXZl73Um8s/4nnnn0NvYdezm9Bx0Y627FFVbm5Y2H44SbXaIjzcCVm4MgdGysyssb62OA78wSO0uc9Nkgmi2aHRuU1rr9j7r2kagetKnJyZzXNrCu0MHBE6eR0zkvmodLGDyrs7mZtaaI73tNtNRL+/rT9zPwxwXcfta+2Oz2qB1HEGLB1aMHJd8w0xeLNTVFse5FUuJZna152epy6HOoZZ7ae55cQcX3HzHj7D447LaoHMMftz29mqGX/jOqxxCSm+F9cjl6cFefut1hPMGeOBx2bjjnMEoqqpnx0ky+73IAI8degsOREuuuxRSr8vIGY+PKFawrqeblzZtpamokq1MXbDZb2MepLCvh+ftuZfJt/5a4MUEQkgor8vIGY+kHn1NcXMsrm7fT0OSka24WNpuK6BhFZVVMnbmAx++41PLYYkGwig5pBLvJ65TFfVecwMYtu3jw8T/S/agJDBk1OtbdihlW5eUNRGVZCbmZKcyeNIyLnttB/1wHA0+5OCIj2zPLhHiSBUFIJqwqd+yPorIq8jLtLJk0gAnP7aFvrp2zTjs2YgPbM9NEoLZiMRgtCG46tBHs5qBBvXjqhp68tOYTXp37BgeOn0q3PgNj3a0OiXuyWpcsBzlUcc/J3bltdfjxwO2VzSKZkQpGgpC8uCerdc20k6bruefkLvx5VWTxwKFkmhAbOHREs60jKYxgMFKq/Wb0gZx1ZCMPvjKPtfV5jJpwDemZ2bHuWofBc0Lci+sKuWhEKr1Taxg/KCVsL24kWSaSRSgiPU+pYCQIyYnnhLj5n5Vz8YgUuqXWM3ZQRkTZIULJNOGdySkZdFs0O35IGiPYTXpaCndccDS/7inn3sV3Q/8jGXHyeVKC2QLcBivAu98U8/z5Wbi0i7OHuLjm7dC9uJFmmUgWoUiW8xQEwVrcxirAiq8reOH8TJq0ZtxgzQ3vhOcNjjTTRDLoWTKcY6KQdEawm97dcpk19UQ+/Gobc+fcysCTLqb/AaNi3a2Exj3x7smP9nD+UCiubgIgM6WWs4bmhOwNDjcPcDyRDF4NQRASE/eku1lryzhnCBTWOAFIdTQyfkhaWN5gX7mAxw+x+W0rJhmqAiCanVwkrRHs5rjh/TnmwL489dbrrFq7nIMmXEfnrt1j3a2ExD3xbu5tl/BmwTbefN1zbV3I2SHaK5tFNJEnfkEQ4hX3pLuzb5nFmt1FrGmh2fVhZYcINZtFvBW2Es1OLpLeCAaw2WxcNfYQLqiuY+bSB9icOoBRZ19BSmparLuWkFiVhaI9sllEC7c3obSokJ1bf2hebrfb6dlvUAx7JgiC0BIrM1CE2lY8eYJnTJ/cSrPB0G2hYyJGsAc5Wen847Lj+WHHHv751B10GnEq+x9zRtw9qQrxj9ubsHHWNNLy+zcvry/aFsNe+aatFYxkmFAQBKuJp/trVVUlKdl5LTQb4k+3RbOtQ4xgHwzt241500/m9U83s3DOB+w37kp6Ddwv1t0SQiSQUHQkcYi0DGdbz1eGCQVBsBpvP7A/Pass2cOdU8a3Wi6a7R/R7OCIERyAcUcM5dRRg5j130V8uCqdQ869jqyc3OA7JihWV2aLdaW3QEJx55TxEYmDFUa0VYZ4ot0ABEGwhmhUZWvvSm/e0RD+9Ew0W4gGYgQHIcVh56aJR7CntJJ7l/6duu4jOPj0i7F1wBghqyuzdeRKb219wranZ/LrMzc2v2+sKqE+vzvZ2TnylC4IQkS0tSpbrNsMRHtFQ4Sr2WDodr+Bg0WzOyCSHLeNdOuSw4NXjeHq/etZ+9itbPnio1h3yVLcOXnvn9iHzauXUVVeGlftJSrDrrqfg6bPaX51ye/OP55ZIZ4AQRAiwrMq24pV6ygur47LNoMTPzHB0Fqz3botmt0xEU9wiIzatzfPDO3F8ys/5LXH32DYWdeS36tvrLsVMZFUZrOqvViHT1hJpDFfgiAIgQilKlu02mzv0IloI7qdfIgRHAZKKSafOJwJxzTw75fn8LGzG6POuYa0jMxYdy0sAlVm01qHbJiGW+mtI4VPhOs1KNi+hdKiwlYTQOJh8ofcIAQhPghUlU1rHZZhGk6lt/YOnYg24WpseXFRXE7aE80OjhjBEZCRlsqfJh/D9t2lzFjwJxyDj2X4iRPjKuVLWwhUmQ0I2TANp9Kb23CePbEP168IvcRyqMSrODidTlKy81rFncVDzFmsjXBBEAwCVWUDwjJMQ6305hk6MW1FeCWWAXSr/BC+iVfNBnBpV1zGCotmB0eMYAvo16MLj047iZVfbmXeo39g8KlT6LvviFh3q834q8yWvmMlttrSkA3TcCq9WR2OEYxIxcEKQfbVRmlRIen5iR9eIwhC9PBXla3bzm+pr60KyzANtdKbVeEYqo0xwfGq2QBKuyLqmxA7VEyqtax9JH5KxFiM0+niibe+YO0OzcgJ19EpLz/WXQqb9xfPYd9dy5h+fD6z1hTxfa+JUTFMK8tKWHDHhSy6IJeuWSkUVzdy0ZJyLp25xK/RvWvbFh69+QKmP/gCPfrtY3mfIiGSNDqB0gD945kVlvVRCJ+rRw9KrKEeK/hisaamKNa9EILwwMK3Yed6bh6dywOry6HPoVEJUygqq2LSbQ/zwqQc8rMdFFU1MemFSl6870a/RvfmX3Zzxu8f5u1HbmRov+7Ny//w9Ifsd+kMy/sYCpGmPhPdjm+G98nl6MFdfeq2ZIewGLvdxrXjRvHIRQey5/V/s27ZEzQ1NsS6WyHjDk+YPGpvXK9nlofKshKeuPNKS7I+BAvH8MWKOX+lj6Oc5Y/eHfHxrcadRsf75UtkBUEQrMAdnnDZKMMIvWxUVosMD0VlVZx3+2OWZHwIFo7hi9tnv0Seo5bbHnkx4uNbjWh28iJGcJTIzc5g5pTjuekIO+vm3c7mT96NdZdCIphh6jmJLVJ+2PARSzbWcfzsHc2vJRvr+GGDb0HdtW0LRZs/5YkJORRt/pTd23+OuA+CIAiJTDDD1HMSW6Ss/Px7Fm2q57DZhc2vRZvqWfn59z633/zLbjZ99xNPT8hi03c/8cP2Qp/bCUJ7IzHBUeaAAT14cnp3ln+8kRfnvMv+Z15Nj/6DY92toASK6z187AWWTmKb+q8FIW2/Ys5fuXCYnZwUFxcOs7P80bu5esazYR8/1ngOxZUXF7F+5gWAEWfWuVtPID4mfwiCEL8Eium97MxjLJnE5mb5/dND2v722S9x4TAHmSmaC4c5uO2RF1n2r+uB1mWTEwHv8Am3bntqNohuJwJiBLcDSinOOWY/xh4+mIdffZaPVmVzyMRpZMbxBTL1Xwv85u19f/Gcdp3E5onbC3zhpHRcThcXDkvh+RcMb7CVscFWlcdsC4GqEEk8mSAIbWH5/dP95u19YOHblucUbituL/A9k9JxOg0jeMILhjfYMzY4UkSzhXAQI7gdSU1xcOv5R7K7pIJ7X/wbTb0O4aBTL4jbEsy+8vaGmwPYKtxe4FS7i/65Nn4pi443OJTymN7iW1pUyMZZ07CnZzLsqvst65MgCEIgfOXtDSf/r5W4vcApdkzNdrbyBltBqCWNPXXbrdmA6HaSYYkRrJR6ChgPFGqth1vRZkemR14nHr56DJ98u4PZj91K39GT2GfEUbHuVgv85e0NJwewlWzfvImn6utZsgmyUqCqQVPTCCp9U9SP7Q9v8S3YvgWn00nB83e1EOBYDY21p4dESAxEszse/vL2hpr/12o2bN7O/+oaWLypnqwU1azZ6Rnbo37sQHjqtluzgRa6HctwBtHt9sEqT/AzwCxgvkXtJQVHHtCXI/bvw3PvfcDbj7/GiAnTyOveu92OH6hMsb+8veHkALaSW596lwV3XMhz52ejSreTmQonPVPFFQ8vDbhfewpKz36DAKjP7x4XQ2OhekiEpOAZRLMTjkBliv3l7Q01/6/VfPbsXUy67WEWnpdNRWkRWakw5plq3ph1c8D9YqHZILqdbFhiBGutVyulBlrRVrKhlOKyUw7ivGPrue/lWfxP9WLUOVeTmpYe9WP7K1McKOQh1ElsVuM2zjOaKklLh+7ZDiYPdwQNhxBBEYS9iGYnJv7KFAcKeQh1EpvVuI1z1VRLbrqiZ7adi4bvDYfwV6pANFtoD9otJlgpdQ1wDcDc2y7gmnOOba9DJwRZGWncffGxbN1VzIxn7yR9/zEMO3581EowBypTbEXIQyAvcyT8sOEj1hfUMG9lEfmZNuw2cLqgsHY9VeWl7RKXbDXxXA40VGQIr+PQQrPvupJrxo6McY+Sm0Bliq0IeQjkZY6ElZ9/z46COh5cWUG3TBs2G7hcsKf2Z4rLq6N2j4smotkdh3YzgrXWjwOPAx26YlykDOzVlbnXncS7n2/hmUdvZegZl9N78DDLj+Mr3OHwsRfw/H230lhbzYaSyEIe/HmZI2Xqvxa0qGTnZtaaIkuP5UvkyouL0K4m7pwyvtXySIiV0JQXF7U6F4hM/MR703FoodlSMS7m+Ap3uOzMY5g6cwE1tfXsKYks5MGflzlSlt8/vUUlOzcPrC43cxZbY3CHotmRGqux0uyC7VsoLSr0eT6i2eEh2SHilFNGDWLMQQN47PWlrFn9CgdPnEZO5zxL2vYX7lBfV4tj9yYGn3x5RMZkIC9zpP1+/r5baaipYkNpdOOSfQmKv9KYn8/4TUJ6BVzaldTiJwiJgr9wh+q6BkoLtjP+1BMiMlwDeZkj7ffUmQuorqmnqNS3kT50+CERHwdC0+wt825ISG+u0+kkJTuv1TmJZoePGMEWEK1hJIfDzvSzD6WkopoZL81kc+f9OXjcpTgcKRG16yvcYfwgF8+9tZhFl/aN2HD1N6kuUtze5UiNdKvp3K1nXEyk8Ic/sVfaFYPeCEJ8EC3djga+wh3GDoKn3lzLK5d2i9hw9Tepzop+BzPSb3k68gp24RDvQ/2+dLu0qJD0/L4x6lHHxKoUaYuBMUC+UmoH8Bet9ZNWtJ0IRGsYyU1epyzuu+IENm0p4IHH/0j3I89hyKEnhN2ed4aHJqeTkqIienRyRGy4RiuPcKTe5UR86g9EKHFc/sTeVyiEkBwku2ZD9HXbSrwzPDQ5XezYU0nPTpEbrtHKIxypdzmZNRsCebYlh7GVWJUdYrIV7SQi0RpG8sWIQT156oYeLF2zjlfmvsmBZ15Dt76hV0nzzvDw+tP388tbT3D6CCPcwtNw1VqHNMEtWnmEI/UuR/Opv2xPgeWxtcFI9jguITKSWbOhfXXbCrwzPNzz5ApeeeN9JoxobbhqrUPycEcrj3Ck3uVoe2rbe0KYaHZ8IuEQERKtYSR/KKU4f/QBjD+ykQdffYq1qzszasJU0jOzfW4fLEtDZVkJ3763hMfHZfKnD0qZcmzPFoYrENIEN6vzCFeWlfDcvb+H8l/5y+TWRno8ZIPQyibiZtLRvDdCx6S9dTsUgoVpFJVVsfSdj5k1LoM/f1DNdcc5WxiuQEge7mjkEd78y27mvvQOq6YZQ/eBvMuxmiUvRqlBsmu2GMEREMtylOlpKdwx6Sh+3VPOvYvvhn6HM+KU32Cz2VpsFyxLw5plT3Na7yq6pGdwSA8Y/eBmamtryc/Pp1OPldjqSkMKQbA6j/C6N5ZQ/fMGJozIpmtWD8C/dznaT/b+xMKmbD62jn+iIX7xHmcnCLEuIxyMYGEac5au5ITeDeSlpzGyB4x8cBuVNQ3065ZDnx3f0lhXFZKHOxp5hG+f/RLjBwONtUCKX+/yEdNms3lbIWnvbWyxf7Q1Ozs7x+e9It4RzbYeMYIjINblKAF6d8tl1tQTWfv1NubMuZUBJ17MgANHAcHjaN1e4FtPSyUrN49rz+jM899+y9A8hX3Avgw+6Cj23bXM8glubcXd/16d7Cz8rIxXftzWwsj39i5H+8m+o8XWJrv4CclJPOi2P4KFabi9wI+d5iAvN5s7z+jOi99tY0iejf4DenH8yKGwc31MPdxFZVV89vXPbEnXvPDNbrp1qcVmM3IBe3uXiyrryT/0DLqddGWLNqKt2ZCYui2abT1iBEdArMtRenLMsP4cdUBfnn77DVaufZWDJlzH5++8HDCOds2ypxnbr5aDemeyrayM0oYMMqjn8bOzOP/FT6nd8wt/uaQbEJsQBHcc8PTjhzFrTRHf95oYV1khBEFIPOJJt70JFqYxZ+lKTu7XyMG9M/ilrJqmxlRSdRNPnJ3JpJd+YndhMcsv6QzEzsM9/7W13HRCV24encsDq8uhz6Ex/1wFwR9iBEdArMtRemOz2bjyjIOZVF3HXxbO5KM3P+T2q/sDvo3YjStXsKmykVW/VFJR56K0tpypoxwcmG/jvP0VXxaV0DWrN2DdBLe2Eq0sE96EG0LhuV9pUSEbZxmfiT09k2HtMHs32eO4BCFc4k233bQlTGPpB59TU9HEql+qqKjTlNZVcvUhhmZP3M/OV0VV5GcbRYRi4eFuj1ATKzQb9uq2aHZyI0ZwByQnK52+WS4uHmHn6TU7OXSfzpw+rEsLI7ayrITczBQWXT6CrlkpfLa1kmnPfce0o7JxpDo4/4AmXnyplqMe2ordbqO6opSsTl3oFMYEt3BKKEcry4Q3niEUX8+7BWddDQClRT81D5f5ElfP/Qq2b8HpdBr/P39Xs9BFU9xCGRZL9rKYgpAIBAvTKCqrIi/TzrtTBpKf7eB/P9dw4XPbueHoTNJT7Zx3gJMXXqrhoId24bDbKC6vpmtuFn3D8HCHm0O5PUJNrNBs2Kvbnprt3jcaiGbHJ2IEt5FESqwO7iE/wzB7bXMBN728k5ycbLr2NYxYbyNz9gc7uPigFLpnGPsf2j+LSw7WvNM4lMEHHcUv7z3NgJMvDssADaeEstVZJtqCs66G3lMeAqC+aBt9Bg4Fgsen9ew3qPn/+vzubS6c0V5CJ7OghWQkMTXbf5iGt4H5zw+KufigFPLTje2O6p/Obw92sqmpJ8ePHMqKd1Yx/tRjwzI+w82hHFaoiQ4/P0S4mg17dVs0O7kRI7iNJFJidWg95NfY5GT2fz9nQ0ka1RVlrYzM3buq+Gyr5skNDdhs9ub9XI4vaSrbFXaRinCLXISTZSLU2vGxfqIWoROE6JHomu2Nt4G5ZVcNH2+FpzaUt5gw7EjZRnlZWdg5kCPJoRxqqEl+ThqbP3+Lyp+/bF4mmi20J2IE+8Dbg5AIidWDeT1SHHZunHg4RWVVzHjpXg4/4VRGnn4xdkfgn8D7i+dElCEiWJGLcEIl/NHW2vFfz7uF0q3G0Fnxrh2UzLgAAO1ysv3p3wOgbA76XD8rov4IgtB+eGqg1jrhNdubthqYDyx8O6IMEcEm51npYf90zvXc9PRaDrz0H83LRLOF9kSMYB94exDiObG6m7Z6PfI7Z3P/VSew4YdfeWjubfQ+5lwGHXKcz20jnZzWlv3DCZUIRrBJa866Gnpe+Hf6DBxK2UNX0fsKQzgbCn8mtbtRge/Xp6yZPBNo+EwQBOvw1ECgw2h2KEQ6Ma0t+1vdb3cwhFsrPTUbDN0WzRaihRjBXnh7fccff3BcJ1aH8IavDhnam2d+14slK9eyYu4bDDv7WvJ79WuxTaST04LtH26oRDA8h6x2bv2BtHwjQ8avz9zYalulFLqpwXynm/9XSgU8Rltn+srwmSBEH08NvObVT3FpzbKLjIfvjqLZbSHSiWltmZxndb/dSuvWSk/Nhta6LZotWIkYwV54e33/OOvFuE2s7iZcT7VSigtPHMY5xzRw/7LH+LixG6MmXENaRiYQ3uQ0z/CGYPsHC5VoD+x2BympaQA0onBV7AbAVVsRMMtDrGPT3LRlooak5hE6Op4aeEKfUjbtdpKf3RXoWJodjHAmpnmGN7R1cl4sPeyi2YKViBHsga+hoLmztvLzjgwWbapvsW08JFYHa/IyZqSlcteFx7B9dykzFvwJx+BjGX7ixLAmp3mGNwTa3+o8wP5CIFzKTt/fti0HpN3haJ5dHMqM4XCxQuja4rWIF/EXhGjgrYFnDoEFG2o5+D8FOOx7J4x1JM32Rzg5kD3DGwLtb3W/j5g2m6LKeopLy0l778tm3RbNFs1uT2zBN0kefA0FTT0mj8vOPI7Pnru7xSteEq4HGr4KlX49uvDotJM4r+cuVj/6B7Z/vzH4Th64Ddv7J/Zh8+plVJWX+t02UKhEOFRVVZJ5+k2knfI7up1/N13G3UyXcTfTVFHIjmdvob5oG41VJWyZdwONVSXY7fbgjUaZO2Yt9imeVVWVzJg+OQY9EoTEw1sDj9y3J9OP79ZKtzuiZkeKZ3jDilXrKC6v9rut1f0uqqxn2NX3Yxt8TAvdbqooZNu861votmi2EC3EE+xBPJfT9Ec0+nzCQQM5blh/5r29nDUfvsLICdfRKS8/6H6hhDe4QyUWf7GtuRCHzWaLKA+w0+kkLb8/jQ31KEcqAPbsPGzaSZ+BQ5s9BTOmT6bqrQfZAjRVFvHLrMsAsCkb9V2N82yvYSeJPxOEyEg03Y6n/oYS3uDu94IvdzcX4rDZVMT9dmndQrft2Xn0u/xhfn3mxmbdzs7OEc0WooIYwR7Ei6fAH75S0zz1pylRSQhvt9uYOvYQLqyqZebSf/Nd5iBGjZ+CIyXV5/ahhje4QyXeXzynTYU4QkmlpqB5soR2NtFYV8mWeTc0i2R7DjVJbJcgRJd41u321Oxw+hZKeIP7c35g4dttLsTRlnRqyuOvbmpAO5tajNy1d35g0ezkQozgBMJXahp/6WqsyuWYm53BjN8ez3e/7Oa+ebfT5ZCx7HfUqa22CyeTRCjZIYKlUnM5m6h6dzaOs+/EkdmpebnDkUJ2BLFikVYIktguQUheYqHZofQt1EnfoWaHCJROzel0snHhP9COfLTLicOc7OZwpLQYuQsV0WwhFMQIjiJWipov8QmUEN7qXI77D+jBkzf0YPnHm3hhzrvsN+5qeg4Y0rw+lEwSbq9u3yHD2hQ+4c9Y9vQOu2rKGJBZT+FXb5J5xCQAmhrqaWpqpLSopEX1oVA8C76Gvgq2b2H7wjvioqJRW70WUoteEILTkTQ7GKGEZbg/l4OH9m1z+IS/83d/vg01VfSxV1DirEc31qPSMps1e+fWHygtKmzW2GTUbBDdbg/ECI4iVoqaZ+zWmH41nDr9QSaOOdinIEWzwt3ZR+/HGYcN5t4lT/CPuz7hmpnz6danf0iZJNa9sQR7wZds+Gkj9147EAgcPuEv1tjtHV6z9Ck66Sp+P8rGzW/Op2TjSmyOVJqaGrGlZ+MC0k75XXN725+/ixnTJ3PHrMVhiYzT6SQlO6+V0MYiJiySGwPs7bOIrSB0TM32xNPIDyWMZP5raynZtY1FP21jzdSeQPDwCV/xxgClBduZ/eIHZFLDjYekcPXyr9n57E3YUzOaNdvWqQcqPadZt5NRs0F0uz0QIzhKWClqRWVVvPzeJ3SxVfPbQ7NRrkZUbQULXvuIj67rBbQUpGjnckxNcdBJ1dHXXsKbD0xn+CkXMPK0C7G1Yfau26v7r5OzuHl5YXM8WNesFE7u7+SRG3/DDQ+92GwI+4s1PvDY05u9wxc99zyXHd2Tb4sKGdrVxg8VRaTk96e0qAQXYM/o1CL5ekp2XrNwWDHJ4et5t+Csq6GxKnSPc7zEn8lkDyHZ6cia7SYcI9/9udxzcibTl5c2F6XIz3Ywph+cOv1B3pl1U4vPyle88XmLjSIm887NZ8Jza7n26C4UNjrplV1NcV0xaZ0GNmt2wcLbWui2aLZvRLcjR4zgKGGlqM1/bS3dUuoor27k0Q+L+eDHah48PY2r/1vXQpDGD7Ex+8UPWPnpl1GtcOcWuCcndWfaiiLO7VXI/Mdupe/oSewz4qiA+7q9ur0zGjhpoJ2TH/mR7Byjr1WVlXRPrWsRFuEv1vi/c/7KWUOhS5aDHKoY3SeTe75x8cSETkx8vpor7nmE//zpBtJO+V0LAzgYBdu34HQ6m4fiSosK2fbjN4DC7jAuF2dTEw2VJXw975bmMsy9pzxEfdG25pyVYAhRsCd1eVoXhPigI2s2hG/kuz+XHhn1nDjQxuGP7CAvJwOAkspa8lKaWn1WvuKNT+jTwKbdTrpm5pKm6zm6dwZ/fqeCaw9P5z/rmrjWQs3eufUHXE1N2Lw0e+Osac1lmEWzBRAjOCpYnVT8rU++5Ydfa3lkbBrXv1bGGUMcdE5XnD7Y3kKQAJpc67lsZGpUKtz5iwvbuHkrz/7uVBa8v5K3nniNEedMI69771b7e3p1u2blc22XRlaXl3PpzCVorVlwx4XMHp/VIu7XV6yxy+Wisnw9k286gBfXFXLRiFTe/bqYM4faObB7CpOHO1j+6N1hnaM7zZp76GzjrGkoWwqOzj32VilqqMee3QVnXU3AtkoKd1FcuIsek+5psVwBVSsfbbW9DG0JQmzo6Jr9+B2XhmXke34u+dm53NmliS9fqOTF+25Ea82k2x5mzvjMVka1d7yxy6XZU1rJ8B6pzP+snItHpPDa1xWcOdTOoC52Th+kLdXstPz+1BRsaTam3Zrde8pDrcowe1JeXERJYQHdJ/3Na41m59J7Wm0vmp34iBEcBSKt3+7N6UcewOl9azjtoBzO+3kbnbMzOWhod/7cq4mvTEFyi8/Zt8xi0aaiqOSgDBYXdunJIzj3mHrue/kR/qd6M+qcq0lNS2/eP1iBDF9xv75ijd9fPId9dy2ja1YKa3+qYGdpAxW1TTw7MZNvdtVw6kDF/GVrKXHl0r2pidrCbSibjfT8viGfsz09k91L7sKWkYPDYfS7qakRe0YnaKwNuK8GHDn5pHbfp8XyhsKffW4vQ1uCEBs6smaXFmzn0Zc+4INPQvc2ByuQOC6F+gAAIABJREFU4c+o9o43fmDh27BzPTePzuXsedvYVtpAWa2T+RMz+XpPI4f0gLc/sk6zf33mRuor9pDWqRvgodlBcGkXtszcVprdWLQdl3a12l40O/ERIzgKWJkM3fNJvLi8iisOSeWGN6q57jinT6Fu62SHUGdBB4oL8+xDVkYad198HFt3FTNz/p2k7TuaYaPPRinFDxs+Yt2uama/v5MuXTo3VwBK374SW11pm3MMt/QO51DVBOcf2Ei3zpk0NDrpsU9/fnNUCfM+r6doxf0ouwNnVSmpOXmAIZLQ4Pdc64p2NA+deWJPz2TYVfc3D78VPH9XcwW6+qJtzefjjjdDg7OqhF3PGp4HlZpJz8n3Bv2so0E8xbEJQrzRkTV7zrn5XLDoY84bnhmykb/y8+/ZtquWf75fRK+8rOYy1F13fEtjXVWbjeqWn286FU7NxAPt9Oqcxk/lDeicnvzmqMaoa7Y7/zDQQrPB0G2Xy4mqrWjWbDB0u+up4RVwihTR7egjRnAUsDIZuueT+A+ldSgFI3vQYkgtHKEOdYJEoLgwX30Y2Ksrj007ifc2/MzTj97KkNOnMPVfCzyKY1zSHPfr6dmF4DmGvb3Dc2+7hDcLtvHmq1BWXIYj+1cAsvN7kzdmWrPBmp3u/rk3NIuIt8iUFhWiNaTk9aH3xTMAqC3chqNzD/Ys+iMAPfsNAvbWqr9zyvgWcWXueLOagp/A5iDVHJLzFNb2JpEmewhCe9ORNXu/7mmcOsDJ059V8OrmxhbbBOvH8vunexTHOK55W7dnt61Gtbehf/Yts1izu4g1y2Hr7lp0WhEZ6WmWaTZATcEWyt78D7BXs8HQbaCFZoOh2z0m3QM2e7Nmg+h2R0eM4ChgZZqd1h4KB+Bg+OD8sCslhTpBIlBcWLAbxsmH7MMJI/oz942Xeeed5/n284953Cvfbyg5hn1x0f/9pzlf8IzfX0pfj+GpZq+sH7xF5s4p46mqa2ohpsHwFiK3Zxjd5iZijsSvCclMR9ZsgD+e2pv1pW3T7LYcN1LP+fL7pzd7tnfWpNDpxKvpMnwMEBvNBkwPcQKJNqLbViBGsMVYne8xGiVBQ50gEWq8nPewncNh5/qzDqX0yRWUqmI+/MHFuMGOgHG/baWyrITZN02iu62sObbYk0CzgH2RnZ1DadFPhhFrol2NNJbsbC7j6bkt+BblPgOHsu3Hb1HKRoPZljs0oqmyiAGD9g37nAVBsA7RbP+hFv6OG8k5Nk+w3rcvpQXbaapXuBrrm9dbodlgTED21mz39r6MxzunjMfuSMGladZsMHR795K7sNE6JlhIfMQItphI0uy0R9nMcGZBh/rU7+lVuezMY5g6cwEzrjuX9z/5khcu6sHuKicPriln/ZcLOGLchWitmz25/som++PDl5+Gsu3c85ue3LZ6GS6nLaT9vblj1uJW4Q1umkIs46kA7dw7/Ki1C1d1KakOh08RlqEtQWh/RLP9a7a/43pWfgv1vOe/tpbdO39h6dbtLLkon5Mf20FTdXlIbXgSSLMbQ9Rsu92Os76+xTKtXdiVou8+rdsXzU58xAi2kEjT7LRH2cxwZkGH8tTv7VWprmugtGA7f5z1YvNx87MdPHF+Ple+sIcFf55CrwOOwLF7E5++/jyHj72ABfcaMViX3vlwQKO4sqyEDW8/z1Wj0uidWsO4gXZmry7gx7nTsNmN8/OetNae9BtyQIv3Td17BRRkK4e2JHWPIARHNLttmu19XKDFeW/+ZTdn/P5h3n7kRob26x70WMcPSKWhvpYBne2cMUixaNVCqr9bA8RWsz1jh90E0m3R7MRHjGALaatY+fIetFfZTCtnQfvC06sydlANT725llcu7cbZT23l5x0ZLNrU8ik7L7eG795/iVP3TWftB0upr6vFvusLyutcfifGufnw5afJoYorRnXCpV2M61/D4lQnI086jbGX3wzg10Pgibf4lO0pYP3MC7ApG7ld85uXt7W2e9meAjb8c3KLff3tHy0kdY8gBEc0O3TNdmeG8Dzv22e/RJ6jltseeZFl/7o+4LHG9IOV39fwyNg0dhSWMnF/O69t1dz28HNk53aJiWYDVJbsialXVzQ7NogRbCFtFStf3oP2KpsZjXg1N95elXGDYeFn9eRnOZh6TB70ObTVOblnGU8+OIvJCwtYs+xpnhrv4N4PnXz9/kt+06S5vcBTR6SSn2WjyQklVbVcfkgaT761mOPPvbzNoRWBxCfYUFpVVSWZp9+E0+lsXtYDjJnN8gQvCHGNaHb4mu0+738veItN3/3Ey5OyOPeFn/hhe6FPb7D7WCf2aWT8UAdDuzrYvKeO/bqlcmCXGta8/HSz8yIYVms2QKlodlIiRrCFtEWsfHkPtNaWViuKFZ5elcYmFw5nHRePSOHZdWVcdlhuq3NqmXXCwawzszj72UKe35jCoT0dbC4v55Ebf8MND73YyqBds+xp0hsrWPKVnRe+LsfldFFV70TZbGSn7fUiV5bsYf3MC1r11WFTQc+nvLioRV15N95C6XQ6KXprDq6GvTOatYbtW39ixvTJADLMJQhxiGh2+JoNxnkfM2stpwxQHNjdwYXDHJx2w4N89uxdrT6HOUtXcmiXKj7drtlV0chzX9ZTWe/CqaG6UZGz8r+MvfzmdtPstPz+7Fx4R7NuuzX7zinjqSzZQ05et6DtCO2Ly+Wirqaa2qoKaqsrqa2qpKG6lKaachqqymmoLgdnAw6c2NA4lBMbLnKPH83Rg6/x2aYYwe2ML+8BYFm1ovaYqOEPT69KRXUdNDXQKV3Ru1M1N4/p2uqcvAVYNdZw5SGpNDg1+dnw3Bel9M4p9+kh2LhyBfUNmlpbOqkZmVRXFZGfmULvzmk8eOGQ5mIbOXndwh5icmlXm/d1NdSQP/4PaHdVIZfhZdj+0t0o7WLUHS+2qR2JCxOE+EI027dmA2SnwNh9QKEoqnYyaZiDRRurueep13jopkktjrX0g88pLq4lIyOd7Ixsiqoq6JZpp2uWnTEHdGPpTylUlZe2m2YDNJb+urdEsqnZdoeDkoV3tLkd0ey209TYQE1VBbVVlearDGdNOY3VZdRXl9NYW4UDF3ZcOJQLm3biUMZ7G8b/uRmpdM5OY5+sVLpmp9C5WwadczLIzcomN7sbqSk+zNpeB7ReZiJGcDvibxJGano2RaXWxHxZNVEjmDD7Wu/pVTn7llnsKNjDnvJqXClpHDa7sNU5eQpweVUtrsY6OqcpumQonpmYzje7U/i8wMVHrzzFUeMvoks3o1RzZVkJuZkpzJ40jOtXVDPwiDMYUfom04/fGwvmWY65vdDa1Zxk3dXYgFKQkp3XXKGoLUhcmCDED8mm2b8WFuFyab4sqGbUI7ux2ZRfzQYoLKkkhSYO6GanrNaJHc3lB6cw9+2P+dMVZ7bwIOdl2lkyaQDTVtRw4pEjySrexM2jc9lT1cTTXzTERLPxpdmpaejgTudmkkWztdbU1VRR02zAVtBQU0ZTdVkLL6wd43dgx4ldubBrl7nMRXqKokt2Gn2z0+iSlUrXrFQ698ggNyuD3Oye5GSmN1ejbS8sMYKVUmcADwN2YJ7WeqYV7SYSbXma9zcJgz4HWBJLZuVEjWDCHGx9y0pDxwasIlRUVsWIyXeTaVc0afi5zMWhcyvplAb9Otk4a5Bm2d+v5qjfXMsBx45j3RtLOGsoDOmewVlDq3lu5XK+US6fxTaSFUndIwQj2XVbNLslbj0OpNuemj115gK276kkxQHbK1yMW1hNoxO6ZSmyU+DRpR/wpyvGNx/b05s+//31OGyaRZsKcbk0Oyua6JLbSTQ7iprd1NhAbXWlhye2AmdNmeGFrSqnsbYSu9sL62nAKsMLa8dFp4wU8rLTGZiVSpesFPLy08kdkEHnnGxys/JJS02xpK/tScRGsFLKDswGTgV2AOuUUsu1/n/27j2+6fp6/PjrnUubtGlLb1xaQEBRGV7R6abidc45Ubwr6hCd6PCyi2xsDqfb1yleJupA8cLPCxMR52U6vDsVHThRvICIonK/lDa9p02a2+f3R5qQtEmaNp/c2vN8PHjMhjR56/B4enLe52hfJvvauSSRn+bTecs3mYsaPQXmRAJ3b4L7A8++S6HJx4tTKxk/opQvtjRyxqI6Xr64iGKLot6Tz3Vv1vMD1vLPe99g3ZrPuPnSwMWLKRNK+Pc3zfzs9qVRL8JF6w/rKlbwUVrs4ejBj8Ca6+14n7oBtMBMYHeXge3u1gY0b+yd96kiH8OJeCRuS8yOVS1O5HnBWb/DBll464ohlFgMfPj1Dn7/pouXLiqmxuHj4pc+4OpzTojaP73sW39oe53H62P64m84+uKZQOpiNgTidjBmK2VE8/tx27cRvinOiwItsLlu/BV393gWvcSL2Zqm0eFsw+noTGLbWnG3NeF2NOFtb8HtaELzdoSqsN1aCTQf+UYoLbJQbcuntNBMeWE+JRUWBtmslNiGUFQwEoMhuTn7uUiPSvARwLeapm0EUEo9DUwGBkwwTTRwpPOWbzIXNXoKzIkE7kSDu73JwZLXV3LFYXmYfC5cbi9427n4IDPLvnZz3Q+tNDe4OHWMlR07dnHkUD/+Ta089l8flx8zjPJCc+hjtERWLEcTDD6tTQ0RSzviBePwj8Bqtm1k53O3oZQBc9nwwJYMAv9jtJXibbX36VxCpNCAjtsSs2NXi3t6XtdZv4OsBmobW9mrRHH2OBNPfOriuh9aOWlEOw889w6F+Xlx+6ffWL2R0hG926DZl5gNgbh96O+XULNtIz6fj11LZgNaKG4rAGXAWDgo7urm3vJ5vZ2tBMEqbDOe9mY8jibcbc142lswaD6M7ElcTZ19sMEqbJHFTJktnxG2fMoKzZSWWSgZYenshy3Dkp97VdhsoEcSXA1sC/t6O3CkDq+bM9I1KieRMyR7UaOnwJxI4O76nB8MdnHRkje4b9nnEQPQK4ryufCYseTj5tkvNR79xEOHvx2v1wuAX4On1nlpcWlg8rB/3QYAdrYa2djk5ImPvkKZzBTbCimqWRE1Ce5aMfD7vHgadzFoePc5lB+9ujS0tOPEKTPifjwVfhFi6Igx1NtK2L30T5iKyiGsp8mQV4BC5WRrQtf/wCT7PJFVBnTclpgdu1r8zPlFrN9Sx+HlXqZ2idvBmH3qGMVbX7n4us7DP7/aSrvLjd/vRwN8fsXdH7hxef0Yv1xBsa2ANkcbd73X3FkfUBgU2Gyr2NJmxlW2H4dN3pO8pipmhwsuxdil+aldeiPGwtKIuK1M+bhb6/j24avBr6FpfjTNj8Vi5atPVuLraMPncuBtb8HZVMeutx9DaRqKYA1Eo6Oxhi8X/REjPvKMUFKYz+DCPMo6k9hBVVZKbFYG2copLqzGaEy+CpvoJctMXsbMNmm7GKeUuhK4EuChWRdw5eSj0/XWKaXnT/PJ0Otju/DAvH5LHV6fnwOLXRww9U6sRSU4W5u5cF83FbZAshMtcHcN7kV5cN73h/CmcSIjJp4Teq81D/6aZcs/4q2rRlJhM2F3eDl6/jasxSWYwgJCcT5UDa6IWpX57Nud3PvKeob+4Kyofz9dP2J6e8kCtvznMfY67qSIx1ubGvj6vRe4/6xqrlkWmCwR7+OprhWH8Vfczce3X0j5T3+N0RT5r1Xt0psSXt2ZTb28Xf8Dk+zzeiLJdHaJiNk3/pwrTz04wyfSh8TsyJjt7HBjb2rj3qffYmyxlze/cfLF1nbajSUMK9X4zlBK0cjxaMCXq19j7q4azj/QyknjKzlJwUMfdzCovARvWyMGgwGDQWE0GChSCtvgkVx155Nomobm9+PX/Gg+Px6PG4PBQL61oNtFqBvmL8HZ1kqHsx2fz8eKfz3B9hXPMuzAg9n27Xr8Pi8+r5fW5kY+fvUprj2ymHkvP0lx5RBOP+8ivG4XPnc7vg4XPrcTr9uFAY0PFt2Gs3E3u99+FDRQaJjMebjbWrDucySGsBFsBqXQNtby6zMmUGQxY7OYKcw3UZhvpNi8ioKiPGzWfIoLLax6pZSG7/7b7e9jv5GDuefy9OY5iV6yTNdlzFygRxK8AxgR9vXwzsciaJr2MPAwACvnaV1/P1fp9dN8svT62C48MO+wt2C2lQFm8iqGMH7qn1mz6M88/cV63q+JHbi7Bvcd9lbMNjOqeG1EEuxudzDpUEvEP7tYA9pjOWSfKh67bhjPLP+Afz/0GuPPuIqKYSOjPrdrovu9o0/h3w/dypRZf+t22a4vCV2erRSjydRt21FHl81x8WRLL2+0HwpiLS1J5HmJ0CuZFgnpMW5HxOzPlmi094+2nv4es40Fpfj9VrSCQZQddS6b/rOYhaubWfJl4L6C1lmrtNpWs8Y1FEO+lfziMt76dDcdrYo3tnpwNHvJK/KjlBVTsZHKk34OQNOat/j5UcURk3ja/HY2DDsj7r+zSimU0YgBI5jAnJ8f9XlfffAabWvfZHiZhRJrHi63m2+Xv8rlE/J5fOUL/Hi4k6WvfcAvLziJdz9ez8nDXRxWaeK0UR4M61/k8jOOwZpv7vxVijV/MJY8cyhBffft/zD+pD3/DRr/o3N5Z94syr9/OgeOHhJxlnWPrOPGC4/q8Z//6oeyYwqE3n3fiUjH2vBU0yMJ/ggYq5QaTSCIXghcpMPr5oRUX5xIt/DAPOaSuYyfHnkx4KCpf2bdIzP5+B975vYeMeN+vtjdwZhL5oY9s5iKonxWLbgm6usAeDucPLVW9fjP7ogZ92Nv7ej67dQ1NFNZVhL62u/38/Jrb2DKs3DTY69hKYj8F7trovvvBX/BVLee9597lM0fvc7NFwRea8qEktCcYU3TkqpOetqa6bBvw9HcmFPVzUR/KNDjhwfQN5kWCRmwcTsXY3abs4PdDa3sbmxle0M7uxqd1DS14/IbGDX+MIYfYMKjGfn6uX9TccgZmGylmGxldBSWstfUu9n2zM3c8sQrodcLXux95Z3waQxGbJVjuGH+EmZPm8SIKGO/tI42lq7JizqJJ/zf+3iriWMtobjgimvYq+FDfnn1iaHH5y5+g+mHF3D9sSUYDc0s//AzrJ5Gvtm8g282buKZ88uosJnYf3Ae5z/zDVWXn4amaaHqpDU/rzf/mAFwt7Xw1b/mQZeNctlOz77vRKRrbXiqJZ0Ea5rmVUpdC7xOYNTOo5qmrUv6ZDkilRcncoW9tSMiyV2/tRavT+Pzp29kzCVz2WFvwb9pNyajYtzIPes0iyqGRiTTib5+0Btzpkd9/PMFv+Krp27GMPqHHHji2SilQklWMNE9/2Ab/7h/FQ9ctA8znn2anx1WQnlh4GJB+GU7IGp1MlrbgrfVTu3SmyIqv95WO2OK3Kx65Wm+f+oFOfFxf9d/VuE/FISfO9HnJUKvZFokZiDH7WyJ2e0uNzX1Ld0S2w6fwoMJrwokth7NhCG/AGvZEPIG7YWtopLi/SoZWVLWrfXqxbc/ZMjEKd3eS6nIftOus22DF8W2PX0js6dNotFey47N32A0GkP9swDmir2YmUBrV6zZuatvvyDmTN26j1/mtqv2tA90bVuZcnABD9z/HU9eXMVlz67k8sNsUav5QMzqZEVRPusemRnxmK+1kd3P/AlDWeB9nK3NDDW30mIYlDMf9/el7zve8xKRDX31etClJ1jTtFeAV3p8ohgQvD4Na+VwzLZSxk+/k9p5s7BWDsdZt73nb9aByWTi/l+cwHtrt/DwA79lzEk/45tPP+D0sYQSXau3lSkHmPhoUws25WTRKh/PrIscZWbZ/i4GZyN/nzyMSxctYPwxP2HIiNFA7NvJ4VqbGnjyhgu5f9Iwrln2Ai2NDWxbsyLqBrxsEkxIo/1QEJ6YJvq8nuiZTIvESdzWX7vLHajYNrSwo6GdnY1OapqduLwEEltMeDHixoghrxBr6WDyB42nsGIwxftWMGJQGSZT+m/5B9cIm21ljLliHmvmzyC/YiQdXUY+plJRnoroq+3atqK8Ti46wMTKTU7ycfPIqhaWdonZlTvW0+F08PfJ5Zyz6E1OP/YQxo7YU3hZteCauImtvcnB+bPuY8GkEcxY1s7fnnyDDz/fwAPPvsOfft7z6LZMSbTFJ12XMXOJbIwTCVvxyM24XU48jpaI1odddY2Mj/N9eRYr2x77DR5HI4aK4tDjFUXR+8KCgm0QwUpyUNeKclc+n49z/vAgD9/wMxZdN4L/9/oyHnvpVT4ywtI1Lvx+P21NdioKDFQNauGfV43joqXdZw2/vWQB++56gaq8dibv7eOlB/7M9DlPRLxXvD7W8OrmpDGtPPz6EsaWwqevL2Hi2ZfF7LHNdLX4m09X8Gmtq8ePPBN9Xk/0SqaFSAVnRyCxralvYWejM5DYNrXj9NJZrQ1PbAuwlg4hr+R7gcR2bAXDS8szkthCYNatz9WOx9EQcZm3qa4m7vcZLQXsfPzXeBwNdFTsibU9XdANtkEEK8mh1+tSUe7K7/Oy7M33uPGcQ0JJVHjbit+vUdfYQmWBgeGD2njrqpGc/0xraNZw0NzFb8CO1VTkuZm0N8ya909euPOaiPeK18caXt08dUw79722kr1L4anXVnL1uSckvIkv3RJt8UnFZUzIXF+9HiQJzmGxemWDvbjJ6vrRUZu9hWEX/rVbErpjzvS4r3P09L8AsO6RmWx88vqIs0f2EUeePdgGEawkB/VUUXa3O2isaQr9Czn91EM5f+L+3PHcx9RZR9Pc7mZc7b+jrlkOJl3B6uSN59pwNW7jl0cV8K/HVzHvN1O47M8PYCspjdvH2rW6OWmMl3/8t4M5Jxdz9cuOmNXgvlwO0ztxvurOJ3V9Xk/0SqaFSJSmabS0udhV38JOezPbG5xsrW+jsc2DV5nwYsaDCQ9GMFuxlg4lf9A4CssGU7xPJdV9TGxj9crabEW6XIrt2qblstcy9MK/dktCV99+QdzXCS6J2LjwutBkm+DZu07GCT97sA0iWEkO6qmi7G9vwuNviUiiwttWgsnt9cfuuQPSNekKVicXn2OjudHOb46ycPzj3/HjX97HkluuiBgXF62PtWt189TRsOB9L3ecbOMXLztjVoP7cjlM78Q50RafVFzGDJfNffWxSBKcw2L1ynbteeqrron0mEvmMr7LDdpERKsg77C3MOLiW0PJdHgfsfWUP+FXRnx+Px3f7MTj9eHs8AAKa378P7LuthbyfW0sOLs6IsiV2KzcdulEvt5ay4+vf5QP/H6e/twZ8fFbeNIVrE5ava3kW2CwzcQZ+yoe//SjUAIbr481vLrp8/mweJu55CAzH2z1cNGBeTwUVg0OJrGnXzW7T5fDcn2qgl7JtBCaptHU6mRXfTPb7S1sb3Cyrb6NVpcPD2a8KtBj69ZMGAuKsJYNw1o2juK9h1ByRCWDC2zdRl3pKVavbLSxiH3RNZGePW1St2k1iYhWQW6011J98ZxQMh3eR3zNaYejKQN+vw/Tt+vxej143B0owJQX/xM/T1szNl8Lp37PxrLl0T9STyTpClYnlddJiUUx1Gbk9H0NPP7pxlACG6+PNby66fH6Q0ubVm71cPGBZh4NqwYHk9g5V5/dp8thuT5VIVv66vUgSbBImsGgIhLvXfYWzLZS8ixWANwuJyMuuwdn3fZQEl07bxZeX9iqyrA+YoBRl93Dpkevx1xWhbGgiJrFv0fzeTGbjKG2ijyD1i3hd7Y2c+E4c8xm/f1GDmbLszfx7/9t4OlVu9j/tOkM3av7fyS++XQFq2vaWfhuoG3CoKDe4WZUiWL1q09x6I/OitvHuv6jd3lv4w6WfNZOR7sDj8vBkEID1cUaj5xZzFNrWyKSadPutfx7wV96fTlMpiqIgUDTNBpa2tlpb2aHPXCRbHtDG61uDS8mPH4j7s7LZKaCQVgrhmEtPZDi/QZTVjaYqoLc6lNMNYMyRCTejfZazLYyjJYCAHyudqqm3UuHfWsoiV4zfwa+sIkJ4X3EAFXT7mXbY7/CXFaN0VpMzeJZaD4vJpM51FZhMnRfHORttfOzcWYKC81MqlBRE8NEkq53P9nA9hoX97wbaJtQCuocXvYqUTz58gouOPmIuH2sb65az5ff1fPk5y5a21y0u1wMKTQwvNjAo2faWLzWEZFMN9Zs4/fz/9nry2H9ZapCfyFJsEjasLKiUJsDhLdpOFj3yEw8jhacddsxGSMrLB6vl7Wdvb5urw/P7u24Whu7VWL2uvhWINAGceDoIVHbKqAzKPvaOGt/K+u31DF1QmnMZv3Tf7AvPzl8b/7+0pOseK+AQ8+cQUHRnn7lq+58MtQTfO3ECrZsr+H653dw20n5XP5SKy/cNztuH+u47x9PQcsm9jrpYj58bSk/2cvDpkYvf5hoob7Ny4mjjLz07kscc9Y0vn7vBf4+eRhTH1vFTybuDyR+OUymKohc5vf7sTe3scvewvb6VrbXt7OjsR2H249XM+E1mHF39tyai8opKBtKfumhDBo/mMrywVTnWzL9t5CTSsorIhb47GnTcLNx4XWBpNW+NWLDJ4DP6wn1+vq8Xpy1W3G3NkRsWwOovngOQCiJjtZWAYFeYJuvhTP3L+CZL5q5/ujqPl+weunuayPaJtZta2TG83ZuO8nCz19y8Zt7no7bx3ryEePoaK5l0slHs+iVD5i0j59zv2fm/951saHewwmjDDz39mpmnHM8y5Z/xN8nl3PmY99xxxWBcduJXg7rL1MV+gtJgoXuEm2j0FCBqREdXkyahsFkxlhYiq+tEWeHB03rvlNl/dbAQPjwtopgn3Lxlvc52fc+w0aW4qrb1mOzvtlkZObZR1Db2Mptz96Ce+jBHPzjKRg6A3+wV3XJZ1tptO/m4gNMlFkVp+9r5Ik1q1lSWxm1j/X7p14QUZ0tLhvCy5ubqTR7ufBFsBUVAoWUDRkeSmKr8tqZcoCJt9Y1sM/x1QldDpOpCiKZerVyAAAgAElEQVRb+Xx+6poc7KpvZpvdwfYGJzsb2mj3qUDlVjN29tyayC+uwFpWhbWsikEHD2FoWQXmHj5CF/pKvI1ChXp93R0ulMmMsXAQvrZGPO4O0LRucbtm20Ya7bURbRXBPmXTlg85w/cWQ0eW4V+7PukLVsG2iSc/3832uiYuPsAcitmL1mxiV20xT62NvEdTtXsDU087KqI6O7R8EO/v1njxWyeDTBqXvOSjrKiQkUPL97RN5Lm56AATy750cP3g/ITO3p+mKvQXkgSLhC/YRZuxGHw8OZ1BU6lQRUGZ8lB5VnYtmonZFEhKPY5GAAorqhjfedkufPxa46a1LG3pYOkXNXgcrVRXBF6rfPt6VqzdGPMSwuDSIu6dfjwff72Dvz84i+pjzmXMwT8M9aq++ujdfPvGQn5/XDEVhQZ+O9HPm5tb2OeEs6Nebnt7yYKI6uzaQUdgcDVy/6RCrlnWFppCERyhdvMFJbgat/OTvU1MfWE3i9Z4QxWYeJfDZKqCSDev18fuxtZA5bbBwfZ6Jzsb23D5DHgx4daMgYkJyox10GAspaMoKB9GyahKqksrMJl7v7xARJfIJbtUr2FXyhAZs/MLqfnHzNClQY+jAQBLxXDGdF62Cx+/5t70Cc+0uHjmi5002d2srg/0/PYUs2MJtk3838JlPP/aO8w+rpCKQgN/mGjmrc0Ozjrx+1Evt81d/EZEdZbqcUw97ajOcWkFzFjWzj/v+jWapnH+rPt45vwiGhsbOGUfEz97oZFFazyYjIFZzPEuh/WnqQr9hSTBOUyvpDTWBbu3brs8VHHd1dCK3x9IVg2aj2GVpaH36sskijyLldpn/kRLcTkerw8NUEYTKq8ACATOoef/BVp2h9ZZBv9egwlwVwdN/XPor8O32s1d/AbL3lzeY6A5fL9qnti3isXvvMdrj7zCAWfMoHxIFZ8t/zdnjDJS3+alvi3w3GA7Q9ckOFp1dtGDgWUcXVsWIpLYwtFUAlPr7WwYdlZCSaxMVRDpcvOzn7G9pg6vIR/roEryS8dgKx9GyZjBjCyt6La0QUSnZ1Ia7ZLduoUzadz8HbOnTaK53o5f8wOgND+DKoeG3qsvkyiMlgJ2P/Mn8osDG9+8Xk/3mD3lNty1mxi5zzhgz4W/YALc1cif3RX66+a7zufjf/wZSDxmx/L8O6s5YZSB2nYfte2BPuZgO0PXJDhWdbatw92tbQEIJbEVtsGMBa61N0P1YQmdsz9NVegvJHLlMD3GoMXjV8ZQcuzftDs0pmzbY79h/PQ7gdiTKI6YcT9rt9jx+zW8Hjdbbw3snkcDs9nIsLIinCYjJ1x3J2s37caHAb8/ELBrFs9i2/2XgubHbDKGNvlUFOVHrVjH09tLCEopLjnxAM4+ys1dz83nA4YyqGIYr9X4ee0V8Pp8NDU2UVo6iLJhw7t9f9fqLEARDs7Yp3PrUVjLQrJJrExVEOly0FnXMbzN3fMTRVx6jEGLx+dqZ+iFf6V61Fh2bP4m1Lqw8/FfhxLmWJMo5lw7hR1bNuHX/Pg9bupvOxcApYHRZKakvAK30cxB1y4AYOu3X6IMgThXs3gW2++/NPBCfh/eIcOAQMIdrVodjx4Xx0YOLef93RrvvwJen59dDW0MKytk5LDybs+NVp09fgQ898YHvHVFoAATTIzzLDbsjX1PYvvTVIX+QpJgkRJrN9bg6fzjpUx7PgLVfG7waWx88vqIGcG2yqrQXzeXDuGE6+4MXYALtmsEF2fUzpsFEJo+EU/X4ecnX3cPb877TY9BtcCSx80XH82WmgbmtFSRP/YCxh83mXeefpAt/3mMvU66JGqi2jWxdbS2cu5YIwU4gciWBUlihRDZwuFoxevzopRChc1A1jQ/XreTWx9fFjEj2Ggyh5Ls/NKhoeQ4eAkufHHGmvl7YqW7pS7uOfoas8N1nTG87M3lTDr5mKiJarTqbEOrk3P2U93aFqgeJxXbfkaSYJEQj9cHHR48zbW4Wht5455ABdjX3sSYS+Z2a4vwKyODz7+FvIoREa+z89Hr8LtagD3tHMGRakFdk9vwdo2uFel42+i6fsz1073hoRX1vVqBudfQMh6ccSJvf7aJBff+ii8+/5xHz4s9jqxrYvvQrEt4rWYrr70IsKfiKy0LQohU87o78DTvxt1azyf3XgEEYva1p/+A6r1Gd6tMK6UYfs2iiMf8Hjc7HrociGznCI5VA0Kj1cIF2zXCK9IAm+dfGnUbnSU/T5eYHS6RqnK06uwZM+fzzk47h98vbQv9nSTBAtizrCKcz+9n/dZaxo0cHOjZNeWBpmG0lVF16T0AdNRuZvzYql4t6PD5/RFVYJ/Hg6+5HmPnxQKPo5E35kwnz9B9OoTJqEIb4zyORgZbfGCBisrKbu0hwcsOweHnJp+LKw7L44k4KzBjOfGQ0XyydgNsdvD8J15OHGlJ6AKaVHuFEKnQXG+PWE0MgT5dn9cb+lojMGPZaCtj2KX3AuCxb8NgAMdbf0/8zTS6bYrze9y4m+tQRiMeR0NoC53JEDkuzWg0RmyMU2jYLCZsFXtHJOEfLLq128KKZGI29H0cmbQtDBySBA8gsaZA1DU04148O6IaC6AMxm6JcV/VLJmN5m7H72xB06DWFZh+kGexYik1UjFpZugCXFC0xDp8XbOhojhiPnFX4R9ztbS5wOum2KLIx9frCxf2JgevvP8xz5xfgdGguPU/jax44VG+Wr2CqX+aF7EuuTcrjPVeeSyE6D/iTYDQ/F7ql0Wunfc7WwlN29FBzZI/4u8I3AZ2uPYk10ZLAfmlQymfdH23UWpde47D1zUDdFQMjphRHGRA/5jd9cLbOUtW8fYnG3jipssi1iX3ZoWx3iuPRWZJEpyFEh1Z1tvX2GFvobCiiqO7TFfYM3XhzojHVzxyM7uevhFDRTG1u5vAYEDz+zENGoLbvg0I/FQfS/2r94E/cDPX52hg8AV/DXyt+SmpGg0EWhpSJfjTvL3JERprU2EzYXd4ez2bsevlib+dXkGbawdL16xi2UO3cuGsvwG9X2Gc6yuPhRCJjSvry+uEb3IbHzZhYePC6xhUOTTqdIi6Z/+Ct2IwzfV2vD4PaGAaNBRPMGYbDIA/5hlqlvwRzd0OhMVtnxeDOR9LRaAVbefjv0747ylRBvwpjdkVNhPHVbv559ot3dYl92aFca6vPBaRJAnOQrFGlvWm5SDaa/g37ca+LPKxFY/cTJs90KMbvHAGgQrt0dP/ErqcNuaSuYyffjfvzJvFiGl7xtoEWxO68nk80FKHsbAs8jeMJvB5Ev770IMesxm7Xp7w+zXqGts5dJiZ2jXv8MZ91zP25J/1aoWxrDwWon+INq4MYk9iSPR1gv204UnnuoUzcdkDcSj8wlkwUQ7fzjZ72iQcLi9Vl0bG/fD2hKDWhjo0vx9vw/aIuK2UAWNZNb7m2m7foydDWGKeupjdyn6VeSxbHkioNU3r1SQKWXnc/0gSnCHxqr3p5HY5GXbhXwFCF85Ahwqt0cjgc/8cSHoB+0t3YioZgrdxJ6DifmtXyc5D1mM2Y9cesfD1nHPfa8Zb6ea9xbdQ5q9nSPGghJZWyMpjIXJHvGpvOgXHoAERF86Src4WlVViOq4z/oTFbc3nwdtc28uo3fuZyAa151PFdMTs8Lm/ifYMy8rj/keS4AzRo9qbTsFE1NfayMZ500KPGwwKQ1lRt4TUaDCQV14dGo+mjCYMnduilCFyH31Pkp2HrPclh+i9ZqvxaxoLTh/Eg29vpbzEylfLn49Z3ZWVx0LkFr2qvelksxXRVPcNW+ZPjXjcoAxU7zW62/ONZjOG4iERcRuDkUCfce/S4N7ORDZoeyrB6YnZq/BrGi9cVBJ6LF7Lhaw87p8kCR5gXC31vBPW9uBqbWTXv+7EkGdhyE9/GXrc42hk3SMzQ8lteCIarYptb+3giBn3J5Swan5fxIQHg+Zj9zN/YjeEttJBYDNdtPFr6db1IkSsXrO1u30cMKycO0+z8OFWFy9+Xserj/2N8359a7fXlJXHQohEuVvqQq0P7tYGdv/rjs55vvlUnvYrILCieOPC6yIqreGJaNdKtsPRyuxpkxLuW9b83lAbhcfRgNL87HrqBmq6FDWU5mfOtVN6nwQr/S709SZmV9jKQ4/Fa7mQlcf9kyTBA4jJGPhJvmLSnmqz2+sjr6wa+1O/i5jOEG/yQl+q2CqvgF1P/AZvix2T0UB150zfg0fvGW0W7DvuzeumQ9eLENE+qqttbMPjI2KupKaZaF+7nPcW3sSBk6+mtHNtKcjKYyFEz4LjxTSgfFIgHvu8XvLKqjHl5bPz8V+HpjPEmroQ1JdKtsoroHbpjYBCKSjtnOs7YlRgvNnsaZN0q44b4lzW662+xmyI3XIhK4/7J0mCs1CyPbDxXsNsMkYku2s37caan6o/BgrNG1i1OvS8mwHY/uDPIxLfbBftIkRvP6pztHdwx/P3scFYzYQzpmPOz485P7i1qYFHZv9cRqYJkUN62//a29cxGc2hZHfH5m8w5aXu7oiCUNwect6f2bXoejRXayjxTRW9kmA9YnY0sV7D3uTgnD88KCPTcpQkwVlIjwQx1muEL6mAPcsngu0PQcle0DNoPuxP/a7b42al5UwCDMldhAj/SO6WS47hux127njijxR+7wTGHX0aSnXvsZORaULkHr2Sw1ivE7GuOGz5RLAFApK/oGezFbHt6RtDW+CC8m0lWG3WlCbAAErTpx1Cr5jdm1FsMjItd0kSnCHhldpddY34VaCvymBQoUQ1Hb2wweUTPS2e6K0DxwyNPv0irCWgr/SYo5yIZC9CdA2Oe1dX8PDVJ/L66u9Y9MAsxv7kcqr3Hhd6voxMEyJ7hVdpm+pq0FRgw6VBGUJJam/nAvdF+PKJnlogeuOG+UtiTMBw6zIBo6dZynpUgvWO2Ym+n4xMy12SBGdIeLKWrb2wiVjxyM24XU4API6WiARez6Q66IgZ9/P5prpu2+3yLFZodST9+uGVgGQuQsQLjqcctjcnHTyKB15+hv/+18whZ87AVlKa0Mg02TAnRGaEJ7d69sKm27qFM/G52kNfexwNvbog1xdzrp3Cts3fdasyGy0F4GjF6/WQbzL06bXTEbNjSaTqLBvmspskwQOM3v3GbfaW0Jxhk1GFKst9SeAjquMNraFJEcEpERComg+bMidipjF0zjW29PotuwmvBCRzEaKn4GgyGfnl5MOpb25jzrNzqLOO4qvlL3DzhYOA2CPTpF1CiIFHj57j4Gu47LWhOcMQaK8YOmJMnxL48HM119vxd445U5o/ojrucLQy9MK/Rsw1hs7ZxhYTbqeTQou51+8P6YvZXSVadZZ2iewmSfAAE69dINE2g25V7LCLdnqdLVZ1fMec6RFfO+p24vf7cbU2ssNBUq0kXSsB/7zr1336yT34OovPsfHt9jouOmQQFz0bvbJQXlLI335+HL/9+3MUdNSxfmcex4wtiToyTdolhBiYYlVo51w7JaJfOChaVTf49expk0KX7PQ8V2+q4y77djS/H3drA40O+L8Z56HaG3nhndW9ituZiNlBiVSdpV0i+0kSPEAkkuBmYoFHtHPtqmvEoyn8m3ZHPB4c8RbO7/eTVzECk62MoadfH0rI+3JmvbYBBV9HeZ34PG7wOHv8SG7Dll24NBMz/7WdVtdWioqKyDObIkamyYY5IQaOnnpoITMLPGKdq6F2F/mbv+n2eHO9nZLyiojHNL8fc8UIjLZSBp8+k3KbFXZ8iv2jF3t1lkzG7ESqzrJhLvtJEjxAZOuGumjnqp03C7/X163lIbhgIyXn0HEb0LufbGB7jYt73m2hzGqgwdlOZWkxw+N8JBc+fsfZ4WbuC6v51l3GhDOvAmTDnBADTbZuqIt1rvrbzu3W7gCEWiTi8bld5Jt7N5Eom2J2qs8nUkeS4CygR59uqsWqJO+qa2R82NfBi3Lhl+Qg+ckNjrqd+Lw+fH4/u168M7DFE8CUz7CLbkPzeaNWihOl5zagl+6+ttueeqoPS/h1rPl5zL7wh+yoa+K2p27GMPoH1O2ulQ1zQmQJveYCp1Ksim1TXU3E18GLcsELckHJXpQLtjz4/T4a7bUYXrwTTdMwmC2UnXINmteN5vNiNBrxe5wYzXm9ev1sitmpPp9IHUmCs0AuzM2NVUnedceVEZfZPF4fg8+/BYWG3xT442UyKuyv35HU+/v9fvLKqjAWDmLY5D1rn7c/9UfsT82i0GYLXcrrCz23AelVAaiuHMT9vziB97/YwkUPL+IDAyxd44p4jmyYEyL9Uj0GTQ+xKraf3jEl4jKb1+dhyPm3ABpGU+CHbKPRiOP1e5J6/1DLQ8Egqs75Iz6fD4Cap2+k7tk/Y7aVkW8rYeiIMTR/+zGmvN7dbM7GmJ2q84nUkSRYJGVYWVFoFNqYS+ZS6zJSMmyviOc467bT2+E3ypwfmPjQydXaiNFaTKHNFrHxbpfBwAnX3dnn8wfH1zx202W6fUSldwVg4gF7seWfs3n09c9ZvtXLQWdezaDyvif8QoiBq6S8IjRbePa0SThcXgqGjol4TnAZR6/4fIFpD53crQ0YbaUYzJZus42BiARd87gwFiQef+1NDsxmE6/P/50ucTsVVVs9ttSJ1JMkWITEa8uI1gqRSkNP+1VEsvvOvFlUTJoZ8RgElosk00qSivE1qagANLS08+ryD7n7V+fx8Gtz2WAdzaGTpmFO4fpUIUR2i9eWEa0VIpUM5jwOunZB6Os182dQNe3eqAl113N3OJpw5BmoKrcl9F56x+1UxGyZD5wbJAnOMX3dlpZI33G87++6blkv0c7la21k9zN/wlC2p7/O42iJ2vMbXolOVDA4/e6SU5j71Js8O3UIf/yPfhcWUlEBCAb9599ezW2X/pgN22q589EbGHTwKez7gx9HXcEshMi8RKY8RJNI33G87482Ok0Psc5lMqiIxz2OBjrsWzEajd2e2/Xcn7yyiD8eaWDEkNiXfO1NDi675QncHh/tjmYW6jh2LJUxW3qAs5skwTmmr1MesrXvuKdzhSf9NS/+jeCVjjyLlaOn/6VP7xkMTjPu+AcjbD5WbnIyaR9T1garaLMm9x0xmIXXnsSyD9fz9INvs9+pP2foqH0zfVQhRBd9nfKQrX3HPZ0rPOmvXxYontQS2A43/oru/+0C8LqcFFrjT7lZ9PJK7Du3YHd4OaDKyn6Dy7N27JjMB84dkgSLhCQ6wSLPYo3o5QXwOBo5eHRln943mPQbttbi9Wmhx3c9fSPrHpnZ6wkaweB076RSznh0G0+ea+Omd1p48LwqfpGlwSrerMlJR47llMPG8PeXFrPi/QIOOfMXFBaVZPjEQohMS3SChdFSENHLC4Eq7ohRe/fpfYNJf822jaHLcBC4ELdx4XVRJ2h4XW0UWmIvXbI3OXjx7VXcdKyJP7/tYXezi/o2X9aOHZP5wLlDkmCRkEQqyRVF+dDq6La+uKKyMulKdNfJD4aK4l63QcCe4FRAGxcfZGbVNi+TxppY9qUjohqcLf1cidxaNpuMzDz7CGobW5nz3K10DD6Qg0+5CEOUjyGFEANDIpVkm60IHK1giUwFbBV7J12JDr8MB4ELccELeV35PG7yzLHTkUUvr+S4ajcHDTZwzvdMfLBd44mPmrj++PKIC2zZELdlPnBuSSoJVkqdB/wZGAccoWnax3ocSuSmRBLdvvY06yF8NWZ9XSuXH2LmJ4vbueVEK398u5HiIhsjOy9CZEs/V29uLQ8uLeKeK45j9YYd3Pfg76g65lz2PvioHt+jtamBp+/6HVNm/U0WbwwAErdFUCKJbl97mnvDoPwx7zUEq8B3HOPDlqc4di8jz37ZwX3vN7BojQeT0RC6wJYNcTsd84GzIdnvL5KtBH8BnA08pMNZxACQyc114asxK2wm0DTO2M/M0vWKaydWhoajZ1M/V19uLR+2bzVPjK3iqXfe49WHX+GAM2ZQPrQ65nt89OpSTLvXyuKNgUPitkhYOjbXGYm9VS5YBR5VasTp1Si1GPjJWDNr681MPPaYUBzMlridjvnA2ZDs9xdJJcGapq0H5GZ6mFRXOnNhu1y2Cgane99rxef149f8lFkVtW0eNjnMEVXgbOnn6uutZaUUF594IGcd5eZvL9zP/7ShHHrGdPIt1ojnBdcx339WNdcskzXMA4HE7UiprnTmwna5TDOgxfy9dz/ZwGdft/H/Vu2J2Q1ODU158X2yJ7HMlrid6vnA2ZLs9xfSE6yzVFc6s3XKQ6romfSHB6dYKzL7Wz9XgSWPm6YczdaaBm5bdCN5YydywPGTQwnQR68u5fSxsM9gK6ePbUuqGixtFSIXpbrSma1THlKlL0m/IU4lOBi346017m9xOx49k31pq6DnRV5KqbeUUl9E+TW5N2+klLpSKfWxUurjh19c0fcTC5GkYMCcOiHwL/3UCYUsW/4R9c1tcfu5Un2mc/7wIPXNbSl5/ZFDy3jw6hM5q3I7yx/4Hdu/WRuqAk+ZEJgmMWVCCV+/9wKO5sY+vUd4W4XILD3idnjMfvP5xak8ruhHbpi/JGrC63C0MufaKVG/J14lGOLHbIjfh5sqqY7Zsd4z3j+H3gpvqxioeqwEa5r2Iz3eSNO0h4GHAVg5L/6feCE6paKyHitgPvDsOyx86b9oPg9Pfu7CYNjzcXGq972nq8frhENGc+yBe/HQq//isQVrOHGkl/JCMwDlhWZOH0ufqsHSVpFd9Ijb4TH7udXbtYY2d9LnEgNDb6vrBhU/JYgXsz/8cjNrv91OuS2fp9ZGtiKmMm5noi9Xz0t30lYRIO0QIimJ9ECHP2dXXSM75kwHAiuPh3Vuheva3hD8nh32FvybdoceNxlVt3FpvRXr4oJX+4QCg49BBUbO++nRaQts6Q5GRqOBqydN4N9vvs/iD+t48qMmSooKQy0StpoVvU6C9WyrEEKkTiI90OHPaaqrYfXtFwBgUAZKyitCz4/12o32WnZs/ib0uNFo7DYyLZxRi90OAfFjdkdbK1UFql/H7CA9L91lSw91piU7Iu0sYB5QCbyslPpM07RTdDmZyAmJVGrDnzO+y3NizfoNfk/tvFlYK4eHHnfWbU/6zNEuLtibHJx5/T3Y/BqzJ5q5/Z1VaQtsmQpGr973KwDWbd7N3176gsrvT2Ls90/s9esEq8A3X7CnreKipVINzlYStwe2RKq08Z4Ta9Zv+PetmT+D/IqRocc77Fvjnsmg4ifBErMD9Lp0N5B6qHuS7HSIF4AXdDpLvyDTG+JbH7b5bZe9hTGXzGVXXSMYTaGqMMAOewtNj9zc4+vpNY1j0csrqTS7mDjKzKHDTBxX5U5LYMuGYDR+1BAevW4wL37wGc8++Cb7nzadIXGqNl0Fq8B6tFWI1JO4HUmmN8QXvvmt0V7L7GmTaKqrQRlMoapwUFNdTbSXiBCtEt3RWMPKVZ9KzE6TdMwyzhXSDqGzgTa9obe8Pi1U2TXbShk//U5q582iYtJMxo/eszbTv2k39mXR98yH06Nn2N7k4Pn/fIixo4OpBxdSYlX8dLSH3/eismBvcjDtlsdRKB6/aVrCwTBbgpFSijOP2o9TDx/DvS89zorlRUw46xdYC3tOBL75dAWf1rpYuiaySt+Xtgoh0m2gTW/oLZ/PF6rqmm1loUpv+aTrqR41NuK5wbaJeKJVme3/WYh90/8SPpMeMTv4Or2N29kSs5ORjlnGuUKSYKG79Vtr2dFZ5QVCfb0mY+/nkuZZrGx77Dehrz2ORgwVxX2urEcbCRNeUagoDAxMGVVq7FVlYdHLK/lu4xYGWVSvgmG2BaP8PDO/P/dIaupbmPPM/+GtmsBBJ1+AwRB7kMxVdz6ZxhMKIfRWs21jqMoLhHp6jX1cvW60FLDz8V+HvvY4GuioGIzNVhS1H5k40yFSFbODr9PbuJ1tMbsvUj3LOJdIEix05/VpoSovEOrr7Us/79HT/xLxdbw+4kREu9H77icb+Giri1Vb/dz9gSv0XKPRwCFtPQe2YFWi3Nr73rTwYJRNMxuHlhdz3/Tj+d/67dy/4LeMPO5CRh1wREbPJIRIDZ/PF6ryAqGe3p56eWMZf0Xkp3PhvcTBRDtI8/tQcX7ITkXMhr7H7WyN2aJvJAkWSYnWA73L3kJhRVXo62A11+MIzJ8120pDj8diMio8jsZur51Mb3WsG73J/lSsV29aNq7C/MG44Ry5fzWPv/Uf3n5kGQdOnkHp4GGZPpYQoo+i9UA32muxVOy5gBys5HocDUCgDSL4eDwGZeh1f7XP7cKUl48vyu+lKmaDPnE7G2O26B1JgkVSovVAj7lkLuPDKrjBam4woQ1WiOMZN3Iw/oripKq+XaXiRq+evWnZOrNRKcVlJx/EeUd3cNfzf+drYzUTzriCvHxLpo8mhOilaD3Qs6dNYkxY9TZYyQ0mtNEmRURTUl4Rd3pENH5PB0Zz9OJGqqYw6HUPJFtjtkicJMEiraJVjn2tjex+5k8Yyoq6Pbcvrxfte1N1o1fP3rRsn9loK8jnL5ccw8ad9dz+xGwKxp3A9445LTRfWAjR/0SrHHtb7dQuvYmOLtMhEpmo0fX1fB43Blczo6vKI56XyikMet0DyfaYLXomSbBIK72nZyT6eqm60atXb1oujdwZU1XOw1efyJurv+PxB2Yx9ieXUb339zJ9LCFECug9PaPr623/7ivG7XyRC084IOLxVE5h0OMeSC7FbBGbJMEDhF7zdBORjbOSU3WjV6/etEyO3Onr5Y6TD9ubEw4exYKX/8n775k49OyrZTmGEDpJZLObXjI5K9ntcmKzdE9FUjmFQY97IJkekyaX8vQhSfAAocc83Z4km2inMlHP5pEwmR65k8zlDpPJyHWTD6ehpY05z95Oa+n+HHLqzzCaJLQIkYxENrvpIZlkW49E3eVD458AABmNSURBVN3hpMjSfRSbxOz45FKePuS/VEI3ySba6UjUs1Emg71elzvKigu56/JjWbNxF3MfmsWQH57JPhOOTcGJhRB6SibZ1iNR97kcFObYRtVMJ+hyKU8/kgSLqFLdPhHt9YOrkrvOBhapo/fljoPGDOOxXw7l2fdX8a+HXuOA06+iomovHU8shIgm1e0T0V6/0V7LuoUzu80F7g2fu51Ca16yxxtQ5FKefiQJFlH1tip7xIz72WFvoXberIjH8yxWBiX4+omuShb60OtyR9feNKUU5x07jtOP9DD3XwtZ2VHKhDOvwlIglQohUqW3VdlgUttor2XN/D3rzY2WgqhJbbTX37H5G+qXzU3q3H5XOwUWSYITlaq4PVBJEix6tOKRm3G7nAB4HHvWIQcvutlbO9hhb6H83L+QVxZckqGw5psCK49lnGxW0utyR6zeNEu+mT9e8AN21DUxZ8nNqL2O5IATz4m7glkIkbx1C2fic7UDgZXFwS1twYtuweR36IV/pdLrxVxWjQJMefkR647TweNqpyDfltb3zGWpjtsDjSTBA0QyExvcLicjLrsHAGfddsaPHgKEL7+4m9p5s1AGI8oU+Ile87r1OrpIET0udyTSm1ZdOYj5V53Af7/YykMLfseoEy9m5LgJuv19CNEfJTOxwedqp2ravQB02LdSPWosELn8Irga2Vm7FWXKy1jM9rraKLSW9/xEAaQvbg8UkgQPEHqPQYvGYDDgtm8DAvvgMRnxOBqpqKxM6PtTsSpZxKbneLdEetOOOWAkR31vOI++/grLV77EQWdezaDywUmfQYj+SO8xaLEogwGPfRua34vfZMLjaGDjwusSSraNRmPo+eF6M1rN53FhzTf3+twDVbrjdn8nSbCIa8UjN+NqbaRl93YgkNyu3bQbk7H7ljBbZVXor5112zlw9BAMFcUJJ+CpWJWcDOmZiq8vvWkGg4ErTj2U89uc3PHcXL7OH8WE0y/DnCc/6Aihh3ULZ+JubcBZuxUAze9lx+ZvMBq7jyEDsFQMB/ZUjDsqBie8+njoiDG09+L50SjNr9vWSYnZPZNFH5EkCc5RqZ7eEGyfaLO3YLQWYx40pPN3Ar2+zrrtJNPZmY0LNbqSnqn4kulNKy60cuvUiWzYVsudj95AyUE/Zr8fniIrmEW/lerpDcH2CZe9FoO1CFNnzA72+nbYt+ry+tEeT4YRLanvDycxu2fZsOgjm0gSnKNSPVM3mEiPuWQutS5jjx9X5VmsgUtwnTyORgwVxTGT2nS0ZySjp54pqTjo05u274jBLLz2JF7+8CueWvA2+/305wwbtV8qjitERqV6+UUwkZ49bRIOl7fHT1eMloKIS3AeRwMdFYNjJrWpas8wKL8uryMxOzHZsOgjm0gSLHrUNcGFQJJ78OhAr++6R2YGxqCFTYGoqKzM+kQ3nng9U/YmBz/+5b2UqPYB+9Mz6Dsw/rQjx/Ljw8Yw/99PseI9C4ecdTWFRSW6vb4QA0nXBBcCSe6IUXsDgcTbChC2rthWsXfa+pDDGTR9kmCJ2YnJ9KKPbCNJsOhRtOUV6x6ZqXuSm+oWj0T11DP1wLPv0tJYzy2nWrnznVUDtpdKb2aTkd+cdQR1ja3c9txfcQ0+kENOuRhDjF5GIUR00eb8blx4ne5Jrh4tHgaST4IlZou+koGdImsEWzy6/oqWGMd9nSYH5/zhQeqb2/p0jng9U/YmB0teX8kF402MLtGYOCxQcRD6qSwt4p4rjmf6/h2sfPB3bPxM/vkKkY2CLR5df0VLjGMxKonZInOkEiziysQFtvVba/H69lyW2GUPLOhItCKc7OWIeD1TDqebPJ+L0/fNZ0SJgZ+M8jFbKgspMWHfKh4fO4yn3/0vLz/8KuNP/wUVw4Zn+lhCZLVUXWCLp2bbRnw+X+jrRnsts6dNSqgirDS/xGyRMZIE56h0JaeZ6Ov1+jSslXuSHbOtlPHT70zo0p8eQ8Bj9UzZmxxMnH4b5+xnZNQgA4V5ir1KVKiyMJD7zFJFKcWUEw5g8g/d3P3CAj7wD2bCGdPJtxZk+mhC9Eq6ktNM9PX6fD7yK0aGvjbbyhhzxbyELv11dLSz7H8Ss0VmSBKco7Ll0lm29PEGpXII+KKXV2Lyu3niMw+vbPBiUODxa9jb4aCW9RJQU6jAksefphzF1poG5jz5J/L2OYbxx58pI9VEzshEchpNqke19dbXX3/HZInZIkMkCRZJSfWotl6dJcVDwN/9ZANtPiPnjldMP2xPxf2xz7wMO2hc0q8vejZyaBkLZpzIu59vZuEDv2Xvk6cxfN8DM30sIXJGqke19UZrUwObN29i6qTATGOJ2SLdJAkWWSPY4rHL3oLZVhp6PM9iTej7Uz0E/KW7r+WMmfN5f7ed918J/x0TVd6BOWMxU44/eBQTDxjJw6/9i/f/+wIHn3U1xaUVmT6WEANKsMWj0V6L2VYWetxoSaxd6aNXlzK2TEnMFhkjSbDIGuELOsZPv7PX39/TEHA9hqXLjMXsYTQamHHaBKa0tnP7c3/jq8K9mTDpUkzmvEwfTYgBIXxBR7Tqck82fPJfdu72cvj9sRc3JBu3JWaLeCQJFlmnr5f+egp2slKzfxpUVMDt0yby5Zbd/G3hHyib8FP2O/JHmT6WEANGXy/9XXbLQupfuoWbLzo65nMkbotUkiRYZJ1UXKjr7dQIWbGZe7631xD+37WDefGDz3l2wVvsf9p0hozcO9PHEqLf6+uFOrerHZvFHPP3exO3JWaLvpAkWCQlE3OE+6K3UyOk+pCblFKcedT+/PT7+3Dfi0/w3+U2Jpw1g4IUzkgVIpdkYo5wLB1OJ+WW2GlIb+K2xGzRF5IEi6Rky6i2eHo7NUKPWcMis/LMJn537pHsbmjhtn/+H55hEzj45PNlBbMY8LJlVBuAu8NJYX70SnBv4rbEbNFXsjZZ9HvxpkbEe36g+hD7eSL7DSkr5r7px3Pp3i2sePB3bP7iw0wfSQjRye10YrNGr8X1Jm5LzBZ9JZVg0e/1NDUiXKpnDYvMOHLccI7Yv5pFb73Nmw8v46Azr6Z08LBMH0uIAa2jw0lRfvRPZxKN2xKzRTIkCRb9Xm9G5KR61rDIHKUUl558EOce08Gdz/2dr43VTDjjCvLyLZk+mhADks/loLA0+kjDROO2xGyRDEmCBwg91xtn26pkPfWmaixyU6E1n79ccgybdtZz+xOzsex/POMnTpIVzCKr6LneONtWJQf5O9oosCQ311titkhGUkmwUuou4HTADXwHXKZpWpMeBxP60nO9cTatStabDFYfOEZXlfPQ1Sfy1icbeeyBWex76mVUjflepo+VchK3c4Oe642zaVVyOG9HO4VJJsESs0Uykr0Y9yZwgKZpBwEbgBuSP5IQQqTPjyaM4YlrJlL+1bO8/9ittDY1ZPpIqSZxW2QFX4cz6UqwEMlIKgnWNO0NTdO8nV/+Dxie/JGEECK9TCYj155xGPdeMJZdL93Oxy89is/r7fkbc5DEbZEtPK62pCvBQiRDzxFplwOvxvpNpdSVSqmPlVIfP/yijC8RQi/2Jgfn/OFB6pvbMn2UnFdWXMhdlx/HtYdofPjwLL5dvTzTR0q1mHE7PGa/+fziNB9LDAReV/uArARLzM4ePSbBSqm3lFJfRPk1Oew5swEvEDNSapr2sKZph2uadviVk2PvCRdC9E74piShjwPHDOXR607k+x0fsfyhG6jbsTnTR+oVPeJ2eMw++eyL03V0MZD4fRiNA29dgcTs7NHjxThN034U7/eVUtOAScBJmqZpOp1L6EzP9ca5sip5IJBNSamjlOLcY8cx6UgP9/xrISs7Splw5lWZPlZCJG7nPj3XG2fTquRwRjXw/uhJzM4uKpn4p5T6CTAXOE7TtLqEv3HlvIH3J1+IFJi7+A3YsZrrjy1h7nvNUH2YjAVKkZ11zdz2/CfMf+L5nJ6l1pe4/dzq7VpDmzu1BxMDzoeL/srCyw/N9DHSSmJ2Bgw7BEZPjBq3k/0cYj5QBLyplPpMKfVgkq8nhEhQsKIwdUKgijB1QiHLln8kfWYpUlVZwvyrTsj0MfQgcVtkBQMDqx4mMTv7JDsdYh9N00ZomnZI569f6HUwIUR88TYlCRGLxG2RLQz4M32EtJKYnX1kY5zIiP68dS5dZFOSECJdUrF1bqBVgiVmZx9JgkXKxEt0+/PWuXSRTUlCCD3FS3RTsXXOoAZWJVhidvaRJFikjCS6QgiRO9K9XtmgDawkWGSfgTegTwghhBAZZxiAI9JEdpEkWAghhBBpJ5VgkWmSBAshhBAi7QbadAiRfaQnWGSEbJ0TQojcoffWOU3TpB1CZJwkwSJl4iW6MgZNCCGyS7xEt69j0GLxut1YzUZdX1OI3pIkWKSMJLpCCJE79E504+lwtVNoMaft/YSIRnqChRBCCJFW7g4nNkmCRYZJEiyEEEKItOpwOimyyIfRIrMkCRZCCCFEWrk7nBTmSxIsMkuSYCGEEEKkldvppMgiF+NEZkkSLIQQQoi08nS0YbPmZfoYYoCTJFgIIYQQaeXvaKMgX5JgkVmSBAshhBAirXyudgqlEiwyTJJgITLI3uTgnD88SH1zW6aPIoQQaePN0UqwxOz+RZJgITJo0csraazZxhPLVmT6KEIIkTbeHK0ES8zuXyQJFiJD7E0Oli3/iAVnV7Bs+UdSWRBCDBgeVzsFltxKgiVm9z+SBAuRIYteXsmkfQzsNzifSfsYpLIghBg4fB7MptwakSYxu/+RJFiIFInXOxasKEydUAjA1AmFUlkQQgwYBqVl+gjdSMweeCQJFiJF4vWOBSsKFbbAxqQKm0kqC0KIAcOIP9NH6EZi9sAjOwuFSIHw3rEZyz7i0klHU15SGPr9dz/ZwM7aDp5aWxvxfVW7N3D9xT9O93GFECKtDGRXJVhi9sAkSbAQKRDZO+biiWUrIgLlS3dfm8HTCSFEZhmyrBIsMXtgknYIIXQWrXfsxbdXMWnmfOkfE0IIsqsnOFa/74attTITuJ+TJFiIMHoMQo/WO3ZctZvvNm6R/jEhhAAMmj6V4FTF7En7GPj9/H/KTOB+TtohhAgTfjGir31eXXvH/H6NusZW9qvMY9ny7r1mQggx0OhVCU5FzIbOuN1Uz1tXVUftERb9gyTBQnTq6WJEorr2js1d/AbsWM31x5Yw973mpIK1EEL0B3r0BKcqZsOeuB2rR1j0D9IOIUSnVAxCl9mSQgjRnR5JcKqWV0jcHjgkCRaC1AU9mS0phBDdKS25dohUJqoStwcOaYcQgvhBL5mPwGS2pBBCdJdsJThVMRskbg8kkgQLQeqCnsyWFEKISF6PG4s5uQ+iU5moStweOCQJFgIJekIIkS5ul4uCfHNSryExW+hBeoKFEEIIkTbuDidFluSSYCH0IEmwEEIIIdKmw9VOoUU+iBaZl1QSrJS6RSm1Rin1mVLqDaVUlV4HE0IIoT+J2yLT3C4XNkmCRRZIthJ8l6ZpB2madgiwDLhJhzMJIYRIHYnbIqPcrnZs+cZMH0OI5C7GaZrWEvZlIaDPHkQxoBwx437srR3dHq8oymfVgmsycCIh+i+J2yJZc66dgsPR2u1xm62IG+Yv6fH73S4nRVbpCRaZl/TnEUqpW4GpQDNwQpznXQlcCfDQrAu4cvLRyb616CfsrR2Mn353t8fXPTIzA6cRov9LJG6Hx+yr/ng7h51yXvoOKLKaw9HKmCvmdXt848LrEvp+v8tBYVme3scSotd6bIdQSr2llPoiyq/JAJqmzdY0bQSwGIg5s0TTtIc1TTtc07TDJQEWQojU0SNuh8fsk8++OJ3HF/2cz91OQb4kwSLzeqwEa5r2owRfazHwCnBzUicSQgiRFInbIpv5XG0UWCQJFpmX7HSIsWFfTga+Su44QgghUknitsg0j6udQqskwSLzku0Jvl0ptR/gB7YAv0j+SEIIIVJI4rbIKG9HOwX5QzJ9DCGSng5xjl4HEQNXRVF+1EtwFUX5GTiNEP2bxG2RLJutKOolOJutKKHv93k6yM+TOcEi8+RPocg4GYMmhBC5I5ExaPEY8KOU0uk0QvSdrE0WQgghRNoY8Wf6CEIAkgQLIYQQIo0k8RDZQv4sCiGEECJtDFIJFllCkmAhhBBCpI0kwSJbSBIshBBCiLQxKC3TRxACkCRYCCGEEGlk1KQSLLKDJMFCCCGESBuFVIJFdpAkWAghhBBpY1RSCRbZQZJgIYQQQqSNQSrBIktIEiyEEEKItFGaL9NHEAKQJFgIIYQQaeLzejEZZGWyyA6SBAshhBAiLdwdTmwWc6aPIQQgSbAQQggh0qTD5aTIKkmwyA6SBAshhBAiLdzOdqkEi6whSbAQQggh0qLD5cRmMWX6GEIAkgQLIYQQIk3crnZs+cZMH0MIQJJgIYQQQqSJ2+WkSNohRJaQJFgIIYQQaeF3OSiQJFhkCUmChRBCCJEW3o42bNb8TB9DCECSYCGEEEKkia+jjQJLXqaPIQQgSbAQQggh0sTrclJolSRYZAdJgoUQQgiRFl5XG4VSCRZZQpJgIYQQQqSFz+MmzyxzgkV2kCRYCCGEEGlhVBpKqUwfQwhAkmAhhBBCpIkBX6aPIESIJMFCCCGESAsDWqaPIESIJMFCCCGESAsD/kwfQYgQSYKFEEIIkRZGJZVgkT0kCRZCCCFEWhilHUJkEUmChRBCCJEW0hMssokkwUIIIYRICyXTIUQWkSRYCCGEEGkhF+NENpEkWAghhBBpoTRphxDZQ5ckWCk1UymlKaUq9Hg9IYQQqSVxW2SCVIJFNkk6CVZKjQB+DGxN/jhCCCFSTeK2yASvx43FLB9Ai+yhx5/Ge4BZIFc+hRAiR0jcFmnX4XJSaDFn+hhChCSVBCulJgM7NE37XKfzCCGESCGJ2yJT3M52bPmSBIvs0WMSrJR6Syn1RZRfk4E/Ajcl8kZKqSuVUh8rpT5++MUVyZ5bCCFEDHrE7fCY/ebzi1N/aNHvuTtc2KymTB9DiBCl9fGmplLqQOA/QHvnQ8OBncARmqbVxP3mz5fKR3BCiNx08AUq00foq77G7be/2q01Oz1pOKHoz3Zu2ci+dW9z8hHjMn0UMZBU7gtVh0aN231Ogru9kFKbgcM1TbPr8oI6UUpdqWnaw5k+R09y4ZxyRv3kwjlz4YyQO+fMRtkYt3Pl/89cOGcunBFy45xyRv1k0zkHwjXNKzN9gATlwjnljPrJhXPmwhkhd84pEpMr/3/mwjlz4YyQG+eUM+ona86pW3OOpmmj9HotIYQQqSdxWwgxkA2ESrAQQgghhBARBkISnBV9JwnIhXPKGfWTC+fMhTNC7pxTJCZX/v/MhXPmwhkhN84pZ9RP1pxTt4txQgghhBBC5IqBUAkWQgghhBAiwoBIgpVStyil1iilPlNKvaGUqsr0mbpSSt2llPqq85wvKKUGZfpM0SilzlNKrVNK+ZVSh2f6POGUUj9RSn2tlPpWKfWHTJ8nGqXUo0qpWqXUF5k+SyxKqRFKqXeUUl92/n/9q0yfqSullEUptUop9XnnGf+S6TMJ/eRCzIbciNsSs5MjMVsf2RqzB0Q7hFKqWNO0ls6//iXwPU3TfpHhY0VQSv0YeFvTNK9S6g4ATdN+n+FjdaOUGgf4gYeA32qa9nGGjwSAUsoIbABOBrYDHwFTNE37MqMH60IpdSzgABZpmnZAps8TjVJqGDBM07RPlFJFwGrgzGz6Z6mUUkChpmkOpZQZ+C/wK03T/vf/27uDEJviOIrj30NILFkNxUJ2YjMrC0WRZLJTNrKysLCyoChlK2U9ymIiNRYWFEqxGSkpaigpIVGkyEKjY/GuemOeMfPm6X/v3POpW/N/3cXpTff0mzv3/17haDEATehsaEZvp7MXJp09GHXt7FbcCf5dppVVQO0mf9u3bU9Vywk63+RUO7Ynbb8onaOHYeCl7Ve2fwBXgZHCmWawfR/4XDrHbGy/t/24+vkrMAkMlU01nTu+Vctl1VG76zr604TOhmb0djp7YdLZg1HXzm7FEAwg6ZykN8Ah4HTpPP9wBLhVOkTDDAFvutZvqVkJNJGkDcA24GHZJDNJWirpCfARuGO7dhmjfw3rbEhvz1c6+z9IZ8/PohmCJd2V9KzHMQJg+5Tt9cAYcKyOGatzTgFTVc4i5pIzFj9Jq4Fx4Pgfd+ZqwfZP21vp3H0bllTLf1VGb03o7LnkrM4p2tvp7IB0dj8G9o1xpdneNcdTx4CbwJn/GKenf2WUdBjYB+x0wYe15/Fe1sk7YH3Xel31WvShemZrHBizfb10ntnY/iLpHrAHqO3mlZiuCZ0NzejtdHaks/uzaO4Ez0bSpq7lCPC8VJa/kbQHOAHst/29dJ4GegRskrRR0nLgIHCjcKZGqjYwjAKTts+XztOLpLW/d+JLWklnc03truvoTxM6G9LbC5TOHpB0dv/a8ukQ48BmOjtkXwNHbdfqL05JL4EVwKfqpYma7oY+AFwE1gJfgCe2d5dN1SFpL3ABWApcsn2ucKQZJF0BdgBrgA/AGdujRUP9QdJ24AHwlM41A3DS9s1yqaaTtAW4TOd3vQS4Zvts2VQxKE3obGhGb6ezFyadPRh17exWDMEREREREd1a8ThERERERES3DMERERER0ToZgiMiIiKidTIER0RERETrZAiOiIiIiNbJEBwRERERrZMhOCIiIiJaJ0NwRERERLTOL//moKn+vp+iAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 864x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEQyI6NvqS5Y",
        "colab_type": "text"
      },
      "source": [
        "Why does the Perceptron (`model1`) only achieve ~70% accuracy? What is the architectural property of the Multi-Layer Perceptron that allows it more accurately learn the relationship between X and y? \n",
        "\n",
        "Why might this property be useful in more complex data such as images?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6FW_VXQzbO2",
        "colab_type": "text"
      },
      "source": [
        "# 70%???? Cheez whizz I only got 47% from model1!!!!\n",
        "\n",
        "# Anyway, the SLP performs much worse than the MLP because it is unable to learn or apply meta-linear decision boundaries to the dataset, which is clearly quadrant in its characteristic.\n",
        "\n",
        "# The ability of the MLP to recognize meta-linear and multi-linear decision boundaries is useful for image classification because in natural images there are many lines... so many lines... lines all over the place... AND CURVES!... curves galore! Don't even get me started on all of the curves. Atop this there's the color dimension. Nauseating complexity. That's why meta-linear boundaries are needed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PukZ4c7V81XG"
      },
      "source": [
        "## 3. Keras MMP <a id=\"Q3\"></a>\n",
        "\n",
        "Implement a Multilayer Perceptron architecture of your choosing using the Keras library. \n",
        "- [x] Train your model and report its baseline accuracy.\n",
        "- [x] Then hyperparameter tune at least two parameters and report your model's accuracy.\n",
        "- [x] Use the Heart Disease Dataset (binary classification)\n",
        "- [x] Use an appropriate loss function for a binary classification task\n",
        "- [x] Use an appropriate activation function on the final layer of your network\n",
        "- [x] Train your model using verbose output for ease of grading.\n",
        "- [x] Use GridSearchCV or RandomSearchCV to hyperparameter tune your model. (for at least two hyperparameters)\n",
        "- [x] When hyperparameter tuning, show you work by adding code cells for each new experiment.\n",
        "- [x] Report the accuracy for each combination of hyperparameters as you test them so that we can easily see which resulted in the highest accuracy.\n",
        "- [ ] You must hyperparameter tune at least 3 parameters in order to get a 3 on this section."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "inputHidden": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "outputHidden": false,
        "id": "mOcV8zUuqS5f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "5854b8f7-0c23-4dbc-a1e9-22f4514edb42"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/ryanleeallred/datasets/master/heart.csv')\n",
        "df = df.sample(frac=1)\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(303, 14)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>129</th>\n",
              "      <td>74</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>120</td>\n",
              "      <td>269</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>121</td>\n",
              "      <td>1</td>\n",
              "      <td>0.2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>280</th>\n",
              "      <td>42</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>136</td>\n",
              "      <td>315</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>125</td>\n",
              "      <td>1</td>\n",
              "      <td>1.8</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>52</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>118</td>\n",
              "      <td>186</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>190</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>49</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>130</td>\n",
              "      <td>266</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>171</td>\n",
              "      <td>0</td>\n",
              "      <td>0.6</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>193</th>\n",
              "      <td>60</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>145</td>\n",
              "      <td>282</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>142</td>\n",
              "      <td>1</td>\n",
              "      <td>2.8</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     age  sex  cp  trestbps  chol  fbs  ...  exang  oldpeak  slope  ca  thal  target\n",
              "129   74    0   1       120   269    0  ...      1      0.2      2   1     2       1\n",
              "280   42    1   0       136   315    0  ...      1      1.8      1   0     1       0\n",
              "62    52    1   3       118   186    0  ...      0      0.0      1   0     1       1\n",
              "12    49    1   1       130   266    0  ...      0      0.6      2   0     2       1\n",
              "193   60    1   0       145   282    0  ...      1      2.8      1   2     3       0\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8Esy7OIqS5Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "b193604e-b9e2-4eac-e732-f55778cc8a6e"
      },
      "source": [
        "df.target.value_counts(normalize=True)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    0.544554\n",
              "0    0.455446\n",
              "Name: target, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfMGaaLq3ROR",
        "colab_type": "text"
      },
      "source": [
        "# Dummy baseline: MUST.. BEAT... 55%!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrniXOJPqS58",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4d8qRrNbaHE4",
        "colab_type": "text"
      },
      "source": [
        "## Make sure these sets are in the right shape..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkQAWnV54wss",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bc602683-f878-4673-c01c-a56ad11d7b75"
      },
      "source": [
        "X = df.drop(columns='target')\n",
        "y = df['target']\n",
        "X.shape,y.shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((303, 13), (303,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_n2ED1e4TFC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=8\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xt5Q4sDiFM4x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "03dc62e9-2ce3-4a47-ffc2-73dd4421b97f"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(242,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcIMaFIOaP4k",
        "colab_type": "text"
      },
      "source": [
        "## Target was indeed detected and lopped off the X sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YO36zR8q4pfc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "outputId": "62def7c5-5378-41bb-8980-5ac39084bbcc"
      },
      "source": [
        "X_train.head()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>105</th>\n",
              "      <td>68</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>120</td>\n",
              "      <td>211</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>115</td>\n",
              "      <td>0</td>\n",
              "      <td>1.5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>208</th>\n",
              "      <td>49</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>120</td>\n",
              "      <td>188</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>139</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>51</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>125</td>\n",
              "      <td>213</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>125</td>\n",
              "      <td>1</td>\n",
              "      <td>1.4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>227</th>\n",
              "      <td>35</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>120</td>\n",
              "      <td>198</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>130</td>\n",
              "      <td>1</td>\n",
              "      <td>1.6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>218</th>\n",
              "      <td>65</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>135</td>\n",
              "      <td>254</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>127</td>\n",
              "      <td>0</td>\n",
              "      <td>2.8</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     age  sex  cp  trestbps  chol  ...  exang  oldpeak  slope  ca  thal\n",
              "105   68    0   2       120   211  ...      0      1.5      1   0     2\n",
              "208   49    1   2       120   188  ...      0      2.0      1   3     3\n",
              "34    51    1   3       125   213  ...      1      1.4      2   1     2\n",
              "227   35    1   0       120   198  ...      1      1.6      1   0     3\n",
              "218   65    1   0       135   254  ...      0      2.8      1   1     3\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rqyn6zXaWrQ",
        "colab_type": "text"
      },
      "source": [
        "## Scale and vectorize the data so it tastes better to the NN..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QWoo1gE5T1G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "ea7f6d3f-dd34-42ef-fdcf-260056b061fb"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X_train_std = scaler.fit_transform(X_train)\n",
        "X_test_std = scaler.transform(X_test)\n",
        "print(X_train_std[:2])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 1.53962979 -1.50674161  1.0212897  -0.66803275 -0.66975521 -0.44499416\n",
            "  -1.01891157 -1.50786247 -0.69617712  0.46818543 -0.68117412 -0.74288354\n",
            "  -0.47096058]\n",
            " [-0.57230869  0.6636838   1.0212897  -0.66803275 -1.11434167 -0.44499416\n",
            "   0.89253495 -0.46016954 -0.69617712  0.91495543 -0.68117412  2.15675867\n",
            "   1.11199026]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yclwen2WFYxJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ba29a111-547f-43ec-ac7e-2eac5e20b22f"
      },
      "source": [
        "X_train_std.shape"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(242, 13)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5jEAPlHahGe",
        "colab_type": "text"
      },
      "source": [
        "## Validation set for an initial baseline of the net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLMoEoMz5kD-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train0, X_val, y_train0, y_val = train_test_split(\n",
        "    X_train, y_train, test_size=0.2, random_state=8\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7o5TyQOpqS4R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a23a1fa4-fb56-4fdf-9ecb-b5f85916501b"
      },
      "source": [
        "stop = EarlyStopping(monitor='val_accuracy', min_delta=0.01, patience=16)\n",
        "\n",
        "model3 = Sequential([\n",
        "      Dense(32,activation='relu', input_dim=13),\n",
        "      Dense(64,activation='relu'),\n",
        "      Dense(16,activation='relu'),\n",
        "      Dense(4,activation='relu'),\n",
        "      Dense(1,activation='sigmoid')\n",
        "])\n",
        "\n",
        "model3.compile(optimizer='adam', loss='binary_crossentropy', metrics='accuracy')\n",
        "\n",
        "result3 = model3.fit(\n",
        "    X_train0,y_train0,\n",
        "    validation_data=(X_val,y_val),\n",
        "    epochs=100 #,callbacks=[stop]\n",
        "    )"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 2.5368 - accuracy: 0.4870 - val_loss: 1.1002 - val_accuracy: 0.4286\n",
            "Epoch 2/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.7974 - accuracy: 0.5751 - val_loss: 0.9665 - val_accuracy: 0.4286\n",
            "Epoch 3/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.7219 - accuracy: 0.5699 - val_loss: 0.6893 - val_accuracy: 0.5306\n",
            "Epoch 4/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.7527 - accuracy: 0.5751 - val_loss: 0.6386 - val_accuracy: 0.6327\n",
            "Epoch 5/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.6323 - accuracy: 0.6321 - val_loss: 0.7531 - val_accuracy: 0.4286\n",
            "Epoch 6/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.6441 - accuracy: 0.5699 - val_loss: 0.8446 - val_accuracy: 0.4286\n",
            "Epoch 7/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.7738 - accuracy: 0.5751 - val_loss: 0.7906 - val_accuracy: 0.4286\n",
            "Epoch 8/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.7018 - accuracy: 0.6114 - val_loss: 0.6754 - val_accuracy: 0.5714\n",
            "Epoch 9/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.7210 - accuracy: 0.5751 - val_loss: 0.6446 - val_accuracy: 0.6735\n",
            "Epoch 10/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.6613 - accuracy: 0.6269 - val_loss: 0.6968 - val_accuracy: 0.4694\n",
            "Epoch 11/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.7489 - accuracy: 0.6010 - val_loss: 0.7692 - val_accuracy: 0.4286\n",
            "Epoch 12/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.7203 - accuracy: 0.5751 - val_loss: 0.7003 - val_accuracy: 0.4694\n",
            "Epoch 13/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.6397 - accuracy: 0.6425 - val_loss: 0.6633 - val_accuracy: 0.6122\n",
            "Epoch 14/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.6788 - accuracy: 0.6269 - val_loss: 0.6713 - val_accuracy: 0.6327\n",
            "Epoch 15/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.6930 - accuracy: 0.6425 - val_loss: 0.6648 - val_accuracy: 0.6122\n",
            "Epoch 16/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.6795 - accuracy: 0.6218 - val_loss: 0.6611 - val_accuracy: 0.6327\n",
            "Epoch 17/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.6449 - accuracy: 0.6425 - val_loss: 0.6581 - val_accuracy: 0.6122\n",
            "Epoch 18/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.6761 - accuracy: 0.6425 - val_loss: 0.6917 - val_accuracy: 0.4694\n",
            "Epoch 19/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.6247 - accuracy: 0.6632 - val_loss: 0.6807 - val_accuracy: 0.5510\n",
            "Epoch 20/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.6689 - accuracy: 0.6477 - val_loss: 0.7109 - val_accuracy: 0.4490\n",
            "Epoch 21/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.6097 - accuracy: 0.5699 - val_loss: 0.7964 - val_accuracy: 0.4286\n",
            "Epoch 22/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.7312 - accuracy: 0.5751 - val_loss: 0.7266 - val_accuracy: 0.4490\n",
            "Epoch 23/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.6465 - accuracy: 0.6891 - val_loss: 0.6560 - val_accuracy: 0.6122\n",
            "Epoch 24/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.6130 - accuracy: 0.6528 - val_loss: 0.6792 - val_accuracy: 0.5510\n",
            "Epoch 25/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.7006 - accuracy: 0.6632 - val_loss: 0.7103 - val_accuracy: 0.4490\n",
            "Epoch 26/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.6086 - accuracy: 0.6736 - val_loss: 0.6524 - val_accuracy: 0.6327\n",
            "Epoch 27/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.6180 - accuracy: 0.6373 - val_loss: 0.6323 - val_accuracy: 0.7551\n",
            "Epoch 28/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.6090 - accuracy: 0.6269 - val_loss: 0.6360 - val_accuracy: 0.6735\n",
            "Epoch 29/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.6465 - accuracy: 0.6788 - val_loss: 0.6919 - val_accuracy: 0.5306\n",
            "Epoch 30/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.5763 - accuracy: 0.6425 - val_loss: 0.7775 - val_accuracy: 0.4490\n",
            "Epoch 31/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.6465 - accuracy: 0.6062 - val_loss: 0.6970 - val_accuracy: 0.5102\n",
            "Epoch 32/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.5705 - accuracy: 0.6632 - val_loss: 0.6186 - val_accuracy: 0.7143\n",
            "Epoch 33/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.6489 - accuracy: 0.6010 - val_loss: 0.6202 - val_accuracy: 0.7551\n",
            "Epoch 34/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.6767 - accuracy: 0.6477 - val_loss: 0.6448 - val_accuracy: 0.6122\n",
            "Epoch 35/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.5872 - accuracy: 0.6632 - val_loss: 0.6712 - val_accuracy: 0.5510\n",
            "Epoch 36/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.5888 - accuracy: 0.6839 - val_loss: 0.6839 - val_accuracy: 0.5102\n",
            "Epoch 37/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.5542 - accuracy: 0.6788 - val_loss: 0.6540 - val_accuracy: 0.5714\n",
            "Epoch 38/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.5624 - accuracy: 0.6736 - val_loss: 0.6976 - val_accuracy: 0.5306\n",
            "Epoch 39/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.5368 - accuracy: 0.6632 - val_loss: 0.7084 - val_accuracy: 0.5102\n",
            "Epoch 40/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.5869 - accuracy: 0.6788 - val_loss: 0.6664 - val_accuracy: 0.5306\n",
            "Epoch 41/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.6055 - accuracy: 0.7047 - val_loss: 0.6891 - val_accuracy: 0.4898\n",
            "Epoch 42/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.6056 - accuracy: 0.6580 - val_loss: 0.8119 - val_accuracy: 0.4490\n",
            "Epoch 43/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.6553 - accuracy: 0.6736 - val_loss: 0.6726 - val_accuracy: 0.5306\n",
            "Epoch 44/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.5890 - accuracy: 0.6839 - val_loss: 0.6727 - val_accuracy: 0.5306\n",
            "Epoch 45/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.5391 - accuracy: 0.6373 - val_loss: 0.8218 - val_accuracy: 0.4898\n",
            "Epoch 46/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.5734 - accuracy: 0.6373 - val_loss: 0.6834 - val_accuracy: 0.4898\n",
            "Epoch 47/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.5181 - accuracy: 0.6995 - val_loss: 0.6821 - val_accuracy: 0.4898\n",
            "Epoch 48/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.5057 - accuracy: 0.7202 - val_loss: 0.6830 - val_accuracy: 0.5714\n",
            "Epoch 49/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.5495 - accuracy: 0.7306 - val_loss: 0.7105 - val_accuracy: 0.4898\n",
            "Epoch 50/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.4846 - accuracy: 0.6839 - val_loss: 0.7434 - val_accuracy: 0.4898\n",
            "Epoch 51/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.4949 - accuracy: 0.6943 - val_loss: 0.7069 - val_accuracy: 0.4898\n",
            "Epoch 52/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.5243 - accuracy: 0.6995 - val_loss: 0.6882 - val_accuracy: 0.5918\n",
            "Epoch 53/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.6187 - accuracy: 0.6943 - val_loss: 0.7148 - val_accuracy: 0.4898\n",
            "Epoch 54/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.6397 - accuracy: 0.6632 - val_loss: 0.8267 - val_accuracy: 0.4490\n",
            "Epoch 55/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.5265 - accuracy: 0.7306 - val_loss: 0.6789 - val_accuracy: 0.7143\n",
            "Epoch 56/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.6535 - accuracy: 0.7098 - val_loss: 0.7224 - val_accuracy: 0.4898\n",
            "Epoch 57/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.6971 - accuracy: 0.7150 - val_loss: 0.7106 - val_accuracy: 0.4898\n",
            "Epoch 58/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.7939 - accuracy: 0.6788 - val_loss: 0.8459 - val_accuracy: 0.4694\n",
            "Epoch 59/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.6026 - accuracy: 0.7254 - val_loss: 0.6672 - val_accuracy: 0.7143\n",
            "Epoch 60/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.6059 - accuracy: 0.6684 - val_loss: 0.6687 - val_accuracy: 0.5306\n",
            "Epoch 61/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.6907 - accuracy: 0.6684 - val_loss: 0.7986 - val_accuracy: 0.4694\n",
            "Epoch 62/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.5159 - accuracy: 0.6943 - val_loss: 0.6346 - val_accuracy: 0.6939\n",
            "Epoch 63/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.5520 - accuracy: 0.7098 - val_loss: 0.6541 - val_accuracy: 0.5714\n",
            "Epoch 64/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.5513 - accuracy: 0.6995 - val_loss: 0.7456 - val_accuracy: 0.4694\n",
            "Epoch 65/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.5213 - accuracy: 0.6684 - val_loss: 0.6796 - val_accuracy: 0.5306\n",
            "Epoch 66/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.5373 - accuracy: 0.7202 - val_loss: 0.6732 - val_accuracy: 0.7143\n",
            "Epoch 67/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.5475 - accuracy: 0.7254 - val_loss: 0.7724 - val_accuracy: 0.4694\n",
            "Epoch 68/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.5350 - accuracy: 0.6580 - val_loss: 0.7986 - val_accuracy: 0.4490\n",
            "Epoch 69/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.5408 - accuracy: 0.6891 - val_loss: 0.6881 - val_accuracy: 0.5714\n",
            "Epoch 70/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.5534 - accuracy: 0.7617 - val_loss: 0.7604 - val_accuracy: 0.4898\n",
            "Epoch 71/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.5616 - accuracy: 0.6528 - val_loss: 0.8786 - val_accuracy: 0.4694\n",
            "Epoch 72/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.5421 - accuracy: 0.6736 - val_loss: 0.6963 - val_accuracy: 0.6327\n",
            "Epoch 73/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.5606 - accuracy: 0.7098 - val_loss: 0.6973 - val_accuracy: 0.5918\n",
            "Epoch 74/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.7084 - accuracy: 0.6736 - val_loss: 0.8598 - val_accuracy: 0.4694\n",
            "Epoch 75/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.4794 - accuracy: 0.6891 - val_loss: 0.6780 - val_accuracy: 0.6735\n",
            "Epoch 76/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.5527 - accuracy: 0.7098 - val_loss: 0.6730 - val_accuracy: 0.6735\n",
            "Epoch 77/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.5155 - accuracy: 0.7150 - val_loss: 0.6766 - val_accuracy: 0.5918\n",
            "Epoch 78/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.8807 - accuracy: 0.7358 - val_loss: 0.7641 - val_accuracy: 0.4694\n",
            "Epoch 79/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.6645 - accuracy: 0.5959 - val_loss: 1.3058 - val_accuracy: 0.4286\n",
            "Epoch 80/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 1.0092 - accuracy: 0.5751 - val_loss: 0.9507 - val_accuracy: 0.4286\n",
            "Epoch 81/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.6581 - accuracy: 0.5751 - val_loss: 0.7201 - val_accuracy: 0.4286\n",
            "Epoch 82/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.6601 - accuracy: 0.5751 - val_loss: 0.6949 - val_accuracy: 0.4286\n",
            "Epoch 83/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.6562 - accuracy: 0.5959 - val_loss: 0.6952 - val_accuracy: 0.4286\n",
            "Epoch 84/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.6743 - accuracy: 0.5803 - val_loss: 0.7035 - val_accuracy: 0.4286\n",
            "Epoch 85/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.6576 - accuracy: 0.5803 - val_loss: 0.7051 - val_accuracy: 0.4286\n",
            "Epoch 86/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.6561 - accuracy: 0.5803 - val_loss: 0.7008 - val_accuracy: 0.4286\n",
            "Epoch 87/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.6164 - accuracy: 0.6062 - val_loss: 0.6948 - val_accuracy: 0.4694\n",
            "Epoch 88/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.6551 - accuracy: 0.6062 - val_loss: 0.7033 - val_accuracy: 0.4490\n",
            "Epoch 89/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.5947 - accuracy: 0.6321 - val_loss: 0.6990 - val_accuracy: 0.4694\n",
            "Epoch 90/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.6074 - accuracy: 0.6528 - val_loss: 0.7112 - val_accuracy: 0.4898\n",
            "Epoch 91/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.6088 - accuracy: 0.6684 - val_loss: 0.7149 - val_accuracy: 0.4490\n",
            "Epoch 92/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.5757 - accuracy: 0.7098 - val_loss: 0.7077 - val_accuracy: 0.5102\n",
            "Epoch 93/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.5935 - accuracy: 0.7098 - val_loss: 0.7389 - val_accuracy: 0.4898\n",
            "Epoch 94/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.6090 - accuracy: 0.7047 - val_loss: 0.7340 - val_accuracy: 0.4898\n",
            "Epoch 95/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.5317 - accuracy: 0.7306 - val_loss: 0.7107 - val_accuracy: 0.5102\n",
            "Epoch 96/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.5262 - accuracy: 0.7202 - val_loss: 0.7336 - val_accuracy: 0.5102\n",
            "Epoch 97/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.5506 - accuracy: 0.7098 - val_loss: 0.7493 - val_accuracy: 0.5102\n",
            "Epoch 98/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.5363 - accuracy: 0.7150 - val_loss: 0.7780 - val_accuracy: 0.4898\n",
            "Epoch 99/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.5955 - accuracy: 0.7202 - val_loss: 0.7539 - val_accuracy: 0.5102\n",
            "Epoch 100/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.5141 - accuracy: 0.7202 - val_loss: 0.7560 - val_accuracy: 0.5102\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Skz062s29bQg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7bfe223c-ba28-41e4-c17d-13a04e6c2e4c"
      },
      "source": [
        "max(result3.history['val_accuracy'])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7551020383834839"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3NR1ilk-YK_",
        "colab_type": "text"
      },
      "source": [
        "## 75.51% accuracy. Baseline Net beats dummy baseline by 20%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPDUxAt--Rrb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXStz3VKawBO",
        "colab_type": "text"
      },
      "source": [
        "## Hyperparameter tuning with GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_i3TqvTo-xm7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0751bfe2-05ca-4b8f-c039-118bfdf704ca"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam, SGD, Nadam, Adadelta\n",
        "np.random.seed(8)\n",
        "\n",
        "def create_model(learning_rate=0.01, optimizer=Adam()):\n",
        "  model = Sequential()\n",
        "  model.add(Dense(32,activation='relu', input_dim=13))\n",
        "  # model.add(Dense(32,activation='relu'))\n",
        "  model.add(Dense(64,activation='relu'))\n",
        "  model.add(Dense(16,activation='relu'))\n",
        "  model.add(Dense(4,activation='relu'))\n",
        "  model.add(Dense(1,activation='relu'))\n",
        "  optim = optimizer(learning_rate=learning_rate)\n",
        "  model.compile(optimizer=optim, loss='binary_crossentropy', metrics='accuracy')\n",
        "  return model\n",
        "\n",
        "model4 = KerasClassifier(build_fn=create_model, verbose=0)\n",
        "\n",
        "para_grid = {\n",
        "    'batch_size': [8, 16, 32, 64], 'epochs': [20],\n",
        "    'learning_rate': [0.001, 0.01, 0.1, 1],\n",
        "    'optimizer': [Adam, SGD, Nadam, Adadelta],\n",
        "    }\n",
        "\n",
        "grid = GridSearchCV(estimator=model4, param_grid=para_grid, n_jobs=1)\n",
        "grid_result = grid.fit(X_train_std, y_train)\n",
        "\n",
        "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\") "
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best: 0.8060374140739441 using {'batch_size': 8, 'epochs': 20, 'learning_rate': 0.001, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.nadam.Nadam'>}\n",
            "Means: 0.7238945603370667, Stdev: 0.09917628670246556 with: {'batch_size': 8, 'epochs': 20, 'learning_rate': 0.001, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>}\n",
            "Means: 0.7193877458572387, Stdev: 0.09600222082713292 with: {'batch_size': 8, 'epochs': 20, 'learning_rate': 0.001, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.gradient_descent.SGD'>}\n",
            "Means: 0.8060374140739441, Stdev: 0.07005140016116233 with: {'batch_size': 8, 'epochs': 20, 'learning_rate': 0.001, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.nadam.Nadam'>}\n",
            "Means: 0.44991496205329895, Stdev: 0.07468600550116017 with: {'batch_size': 8, 'epochs': 20, 'learning_rate': 0.001, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adadelta.Adadelta'>}\n",
            "Means: 0.5415816247463227, Stdev: 0.18662716242649874 with: {'batch_size': 8, 'epochs': 20, 'learning_rate': 0.01, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>}\n",
            "Means: 0.7192176938056946, Stdev: 0.11771811381162876 with: {'batch_size': 8, 'epochs': 20, 'learning_rate': 0.01, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.gradient_descent.SGD'>}\n",
            "Means: 0.5520408153533936, Stdev: 0.17245048745823616 with: {'batch_size': 8, 'epochs': 20, 'learning_rate': 0.01, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.nadam.Nadam'>}\n",
            "Means: 0.46224490404129026, Stdev: 0.08184602743382084 with: {'batch_size': 8, 'epochs': 20, 'learning_rate': 0.01, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adadelta.Adadelta'>}\n",
            "Means: 0.4663265228271484, Stdev: 0.07631601782862762 with: {'batch_size': 8, 'epochs': 20, 'learning_rate': 0.1, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>}\n",
            "Means: 0.5336734712123871, Stdev: 0.07631602444342245 with: {'batch_size': 8, 'epochs': 20, 'learning_rate': 0.1, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.gradient_descent.SGD'>}\n",
            "Means: 0.4959183633327484, Stdev: 0.0833149355905474 with: {'batch_size': 8, 'epochs': 20, 'learning_rate': 0.1, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.nadam.Nadam'>}\n",
            "Means: 0.474914962053299, Stdev: 0.05736361348173891 with: {'batch_size': 8, 'epochs': 20, 'learning_rate': 0.1, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adadelta.Adadelta'>}\n",
            "Means: 0.5336734712123871, Stdev: 0.07631602444342245 with: {'batch_size': 8, 'epochs': 20, 'learning_rate': 1, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>}\n",
            "Means: 0.5336734712123871, Stdev: 0.07631602444342245 with: {'batch_size': 8, 'epochs': 20, 'learning_rate': 1, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.gradient_descent.SGD'>}\n",
            "Means: 0.4959183633327484, Stdev: 0.0833149355905474 with: {'batch_size': 8, 'epochs': 20, 'learning_rate': 1, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.nadam.Nadam'>}\n",
            "Means: 0.6068027257919312, Stdev: 0.17107069654812934 with: {'batch_size': 8, 'epochs': 20, 'learning_rate': 1, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adadelta.Adadelta'>}\n",
            "Means: 0.6734693884849549, Stdev: 0.1825470641028649 with: {'batch_size': 16, 'epochs': 20, 'learning_rate': 0.001, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>}\n",
            "Means: 0.619812935590744, Stdev: 0.10044616663660969 with: {'batch_size': 16, 'epochs': 20, 'learning_rate': 0.001, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.gradient_descent.SGD'>}\n",
            "Means: 0.7393707513809205, Stdev: 0.1285516330929233 with: {'batch_size': 16, 'epochs': 20, 'learning_rate': 0.001, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.nadam.Nadam'>}\n",
            "Means: 0.4581632733345032, Stdev: 0.07554812323171135 with: {'batch_size': 16, 'epochs': 20, 'learning_rate': 0.001, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adadelta.Adadelta'>}\n",
            "Means: 0.7278911590576171, Stdev: 0.134734235423411 with: {'batch_size': 16, 'epochs': 20, 'learning_rate': 0.01, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>}\n",
            "Means: 0.7393707394599914, Stdev: 0.18925484123939082 with: {'batch_size': 16, 'epochs': 20, 'learning_rate': 0.01, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.gradient_descent.SGD'>}\n",
            "Means: 0.7318027257919312, Stdev: 0.10014878043545831 with: {'batch_size': 16, 'epochs': 20, 'learning_rate': 0.01, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.nadam.Nadam'>}\n",
            "Means: 0.4665816366672516, Stdev: 0.07234370506559203 with: {'batch_size': 16, 'epochs': 20, 'learning_rate': 0.01, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adadelta.Adadelta'>}\n",
            "Means: 0.4836734712123871, Stdev: 0.08180148353231598 with: {'batch_size': 16, 'epochs': 20, 'learning_rate': 0.1, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>}\n",
            "Means: 0.4459183633327484, Stdev: 0.06350759659861098 with: {'batch_size': 16, 'epochs': 20, 'learning_rate': 0.1, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.gradient_descent.SGD'>}\n",
            "Means: 0.5163265228271484, Stdev: 0.08180148100434716 with: {'batch_size': 16, 'epochs': 20, 'learning_rate': 0.1, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.nadam.Nadam'>}\n",
            "Means: 0.46241496205329896, Stdev: 0.11927262447046628 with: {'batch_size': 16, 'epochs': 20, 'learning_rate': 0.1, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adadelta.Adadelta'>}\n",
            "Means: 0.5163265228271484, Stdev: 0.08180148100434714 with: {'batch_size': 16, 'epochs': 20, 'learning_rate': 1, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>}\n",
            "Means: 0.5459183633327485, Stdev: 0.06963865420283638 with: {'batch_size': 16, 'epochs': 20, 'learning_rate': 1, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.gradient_descent.SGD'>}\n",
            "Means: 0.4459183633327484, Stdev: 0.06350759659861098 with: {'batch_size': 16, 'epochs': 20, 'learning_rate': 1, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.nadam.Nadam'>}\n",
            "Means: 0.6776360511779785, Stdev: 0.18957940283388053 with: {'batch_size': 16, 'epochs': 20, 'learning_rate': 1, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adadelta.Adadelta'>}\n",
            "Means: 0.8018707394599914, Stdev: 0.041585896969912356 with: {'batch_size': 32, 'epochs': 20, 'learning_rate': 0.001, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>}\n",
            "Means: 0.5370748281478882, Stdev: 0.1189024788778012 with: {'batch_size': 32, 'epochs': 20, 'learning_rate': 0.001, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.gradient_descent.SGD'>}\n",
            "Means: 0.6320578217506408, Stdev: 0.18715474172319113 with: {'batch_size': 32, 'epochs': 20, 'learning_rate': 0.001, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.nadam.Nadam'>}\n",
            "Means: 0.4540816307067871, Stdev: 0.06963864590571883 with: {'batch_size': 32, 'epochs': 20, 'learning_rate': 0.001, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adadelta.Adadelta'>}\n",
            "Means: 0.7103741526603699, Stdev: 0.18001348951079685 with: {'batch_size': 32, 'epochs': 20, 'learning_rate': 0.01, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>}\n",
            "Means: 0.6749149680137634, Stdev: 0.14028102384267596 with: {'batch_size': 32, 'epochs': 20, 'learning_rate': 0.01, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.gradient_descent.SGD'>}\n",
            "Means: 0.7320578336715698, Stdev: 0.13694605380855654 with: {'batch_size': 32, 'epochs': 20, 'learning_rate': 0.01, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.nadam.Nadam'>}\n",
            "Means: 0.4580782353878021, Stdev: 0.08657515770162046 with: {'batch_size': 32, 'epochs': 20, 'learning_rate': 0.01, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adadelta.Adadelta'>}\n",
            "Means: 0.5459183633327485, Stdev: 0.06963865420283638 with: {'batch_size': 32, 'epochs': 20, 'learning_rate': 0.1, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>}\n",
            "Means: 0.5540816307067871, Stdev: 0.0635075968859212 with: {'batch_size': 32, 'epochs': 20, 'learning_rate': 0.1, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.gradient_descent.SGD'>}\n",
            "Means: 0.4836734712123871, Stdev: 0.08180148353231598 with: {'batch_size': 32, 'epochs': 20, 'learning_rate': 0.1, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.nadam.Nadam'>}\n",
            "Means: 0.4540816307067871, Stdev: 0.06963864590571883 with: {'batch_size': 32, 'epochs': 20, 'learning_rate': 0.1, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adadelta.Adadelta'>}\n",
            "Means: 0.46632652878761294, Stdev: 0.09568741084835132 with: {'batch_size': 32, 'epochs': 20, 'learning_rate': 1, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>}\n",
            "Means: 0.5663265228271485, Stdev: 0.05058487928017347 with: {'batch_size': 32, 'epochs': 20, 'learning_rate': 1, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.gradient_descent.SGD'>}\n",
            "Means: 0.5459183633327485, Stdev: 0.06963865420283638 with: {'batch_size': 32, 'epochs': 20, 'learning_rate': 1, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.nadam.Nadam'>}\n",
            "Means: 0.8016156554222107, Stdev: 0.04481913941419346 with: {'batch_size': 32, 'epochs': 20, 'learning_rate': 1, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adadelta.Adadelta'>}\n",
            "Means: 0.6724489748477935, Stdev: 0.1501476780292913 with: {'batch_size': 64, 'epochs': 20, 'learning_rate': 0.001, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>}\n",
            "Means: 0.5411564588546753, Stdev: 0.10648396853905416 with: {'batch_size': 64, 'epochs': 20, 'learning_rate': 0.001, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.gradient_descent.SGD'>}\n",
            "Means: 0.7606292486190795, Stdev: 0.07015126797488423 with: {'batch_size': 64, 'epochs': 20, 'learning_rate': 0.001, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.nadam.Nadam'>}\n",
            "Means: 0.45841836333274844, Stdev: 0.08272388679835295 with: {'batch_size': 64, 'epochs': 20, 'learning_rate': 0.001, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adadelta.Adadelta'>}\n",
            "Means: 0.657227897644043, Stdev: 0.19546366143923977 with: {'batch_size': 64, 'epochs': 20, 'learning_rate': 0.01, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>}\n",
            "Means: 0.7113095283508301, Stdev: 0.11737467585257622 with: {'batch_size': 64, 'epochs': 20, 'learning_rate': 0.01, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.gradient_descent.SGD'>}\n",
            "Means: 0.784948980808258, Stdev: 0.08951395150104713 with: {'batch_size': 64, 'epochs': 20, 'learning_rate': 0.01, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.nadam.Nadam'>}\n",
            "Means: 0.4540816307067871, Stdev: 0.06963864590571883 with: {'batch_size': 64, 'epochs': 20, 'learning_rate': 0.01, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adadelta.Adadelta'>}\n",
            "Means: 0.5459183633327485, Stdev: 0.06963865420283638 with: {'batch_size': 64, 'epochs': 20, 'learning_rate': 0.1, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>}\n",
            "Means: 0.4836734712123871, Stdev: 0.08180148353231598 with: {'batch_size': 64, 'epochs': 20, 'learning_rate': 0.1, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.gradient_descent.SGD'>}\n",
            "Means: 0.6651360511779785, Stdev: 0.14471620217895223 with: {'batch_size': 64, 'epochs': 20, 'learning_rate': 0.1, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.nadam.Nadam'>}\n",
            "Means: 0.48316327333450315, Stdev: 0.17043871407960307 with: {'batch_size': 64, 'epochs': 20, 'learning_rate': 0.1, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adadelta.Adadelta'>}\n",
            "Means: 0.4959183633327484, Stdev: 0.0833149355905474 with: {'batch_size': 64, 'epochs': 20, 'learning_rate': 1, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>}\n",
            "Means: 0.5459183633327485, Stdev: 0.06963865420283638 with: {'batch_size': 64, 'epochs': 20, 'learning_rate': 1, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.gradient_descent.SGD'>}\n",
            "Means: 0.4836734712123871, Stdev: 0.08180148353231598 with: {'batch_size': 64, 'epochs': 20, 'learning_rate': 1, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.nadam.Nadam'>}\n",
            "Means: 0.6947278857231141, Stdev: 0.15051044406945666 with: {'batch_size': 64, 'epochs': 20, 'learning_rate': 1, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adadelta.Adadelta'>}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfdKJE6JUoAl",
        "colab_type": "text"
      },
      "source": [
        "# This GridSearch CV alleges that Nadam is the best optimizer. It returns an accuracy of 80.604% at a learning rate of 0.001, and a batch size of 8. I will settle on Nadam and hone in on the batch sizes and learning rate from here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Du9AU71AALj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "outputId": "c9d01578-c739-46bd-b0d5-c5e30e133a57"
      },
      "source": [
        "def create_model(learning_rate=0.01, optimizer=Nadam()):\n",
        "  model = Sequential()\n",
        "  model.add(Dense(32,activation='relu', input_dim=13))\n",
        "  # model.add(Dense(32,activation='relu'))\n",
        "  model.add(Dense(64,activation='relu'))\n",
        "  model.add(Dense(16,activation='relu'))\n",
        "  model.add(Dense(4,activation='relu'))\n",
        "  model.add(Dense(1,activation='relu'))\n",
        "  optim = Nadam(learning_rate=learning_rate)\n",
        "  model.compile(optimizer=optim, loss='binary_crossentropy', metrics='accuracy')\n",
        "  return model\n",
        "\n",
        "model4 = KerasClassifier(build_fn=create_model, verbose=0)\n",
        "\n",
        "para_grid = {\n",
        "    'batch_size': [4, 8, 10, 12, 14], 'epochs': [20],\n",
        "    'learning_rate': [0.0001, 0.0005, 0.001, 0.005, 0.01],\n",
        "    }\n",
        "\n",
        "grid = GridSearchCV(estimator=model4, param_grid=para_grid, n_jobs=1)\n",
        "grid_result = grid.fit(X_train_std, y_train)\n",
        "\n",
        "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\") "
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best: 0.8059523820877075 using {'batch_size': 8, 'epochs': 20, 'learning_rate': 0.001}\n",
            "Means: 0.6286564588546752, Stdev: 0.08252312425152392 with: {'batch_size': 4, 'epochs': 20, 'learning_rate': 0.0001}\n",
            "Means: 0.7351190447807312, Stdev: 0.18555582743646312 with: {'batch_size': 4, 'epochs': 20, 'learning_rate': 0.0005}\n",
            "Means: 0.7226190447807312, Stdev: 0.11608329578753646 with: {'batch_size': 4, 'epochs': 20, 'learning_rate': 0.001}\n",
            "Means: 0.6957482933998108, Stdev: 0.16264421077784727 with: {'batch_size': 4, 'epochs': 20, 'learning_rate': 0.005}\n",
            "Means: 0.5520408153533936, Stdev: 0.17389353611155559 with: {'batch_size': 4, 'epochs': 20, 'learning_rate': 0.01}\n",
            "Means: 0.5207482933998108, Stdev: 0.10256998270991621 with: {'batch_size': 8, 'epochs': 20, 'learning_rate': 0.0001}\n",
            "Means: 0.7687925219535827, Stdev: 0.041004905614769084 with: {'batch_size': 8, 'epochs': 20, 'learning_rate': 0.0005}\n",
            "Means: 0.8059523820877075, Stdev: 0.04545989179140975 with: {'batch_size': 8, 'epochs': 20, 'learning_rate': 0.001}\n",
            "Means: 0.730867350101471, Stdev: 0.1834686453203376 with: {'batch_size': 8, 'epochs': 20, 'learning_rate': 0.005}\n",
            "Means: 0.6656462669372558, Stdev: 0.1272395992216065 with: {'batch_size': 8, 'epochs': 20, 'learning_rate': 0.01}\n",
            "Means: 0.5443877577781677, Stdev: 0.14868400958293543 with: {'batch_size': 10, 'epochs': 20, 'learning_rate': 0.0001}\n",
            "Means: 0.689455783367157, Stdev: 0.10085141319932171 with: {'batch_size': 10, 'epochs': 20, 'learning_rate': 0.0005}\n",
            "Means: 0.7977040767669678, Stdev: 0.04535941036590477 with: {'batch_size': 10, 'epochs': 20, 'learning_rate': 0.001}\n",
            "Means: 0.7977891325950622, Stdev: 0.056492676619921404 with: {'batch_size': 10, 'epochs': 20, 'learning_rate': 0.005}\n",
            "Means: 0.6561224460601807, Stdev: 0.19597017943599457 with: {'batch_size': 10, 'epochs': 20, 'learning_rate': 0.01}\n",
            "Means: 0.4788265347480774, Stdev: 0.09638537126904906 with: {'batch_size': 12, 'epochs': 20, 'learning_rate': 0.0001}\n",
            "Means: 0.6282312929630279, Stdev: 0.16787845388675002 with: {'batch_size': 12, 'epochs': 20, 'learning_rate': 0.0005}\n",
            "Means: 0.6653061151504517, Stdev: 0.17923637291931324 with: {'batch_size': 12, 'epochs': 20, 'learning_rate': 0.001}\n",
            "Means: 0.8017857193946838, Stdev: 0.07424029947859187 with: {'batch_size': 12, 'epochs': 20, 'learning_rate': 0.005}\n",
            "Means: 0.5817176818847656, Stdev: 0.19349683818357177 with: {'batch_size': 12, 'epochs': 20, 'learning_rate': 0.01}\n",
            "Means: 0.5618197202682496, Stdev: 0.13043718232326604 with: {'batch_size': 14, 'epochs': 20, 'learning_rate': 0.0001}\n",
            "Means: 0.6749149560928345, Stdev: 0.13966084664929448 with: {'batch_size': 14, 'epochs': 20, 'learning_rate': 0.0005}\n",
            "Means: 0.6904762029647827, Stdev: 0.17646801891668593 with: {'batch_size': 14, 'epochs': 20, 'learning_rate': 0.001}\n",
            "Means: 0.68630952835083, Stdev: 0.22162389149522593 with: {'batch_size': 14, 'epochs': 20, 'learning_rate': 0.005}\n",
            "Means: 0.7609693884849549, Stdev: 0.11966810264678056 with: {'batch_size': 14, 'epochs': 20, 'learning_rate': 0.01}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKChW2B4YMGD",
        "colab_type": "text"
      },
      "source": [
        "# Doesn't beat the last run with the same hyperparameters. Wonder why...\n",
        "\n",
        "# 80.595% accuracy\n",
        "#Optimizer = Nadam\n",
        "#batch = 8\n",
        "#learn rate = 0.001"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftEKbeQwba2X",
        "colab_type": "text"
      },
      "source": [
        "## Anyway, here's for the final test accuracy..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1daVDZYLYJ4k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a3cc40e2-2143-45c3-bc92-5fd600a9d6dd"
      },
      "source": [
        "stop = EarlyStopping(monitor='val_accuracy', min_delta=0.01, patience=16)\n",
        "\n",
        "model4 = Sequential([\n",
        "      Dense(32,activation='relu', input_dim=13),\n",
        "      Dense(64,activation='relu'),\n",
        "      Dense(16,activation='relu'),\n",
        "      Dense(4,activation='relu'),\n",
        "      Dense(1,activation='sigmoid')\n",
        "])\n",
        "\n",
        "optim = Nadam(learning_rate=0.001)\n",
        "\n",
        "model4.compile(optimizer=optim, loss='binary_crossentropy', metrics='accuracy')\n",
        "\n",
        "result4 = model3.fit(\n",
        "    X_train,y_train, batch_size=8, \n",
        "    validation_data=(X_test,y_test),\n",
        "    epochs=100 ,callbacks=[stop]\n",
        "    )"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.6064 - accuracy: 0.7066 - val_loss: 0.6108 - val_accuracy: 0.6393\n",
            "Epoch 2/100\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.6072 - accuracy: 0.6942 - val_loss: 0.6010 - val_accuracy: 0.7049\n",
            "Epoch 3/100\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.5883 - accuracy: 0.7314 - val_loss: 0.5979 - val_accuracy: 0.7213\n",
            "Epoch 4/100\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.6004 - accuracy: 0.7355 - val_loss: 0.5978 - val_accuracy: 0.7049\n",
            "Epoch 5/100\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.6004 - accuracy: 0.6818 - val_loss: 0.6159 - val_accuracy: 0.6393\n",
            "Epoch 6/100\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.6038 - accuracy: 0.6860 - val_loss: 0.5998 - val_accuracy: 0.6885\n",
            "Epoch 7/100\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.5839 - accuracy: 0.7149 - val_loss: 0.6356 - val_accuracy: 0.6557\n",
            "Epoch 8/100\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.5799 - accuracy: 0.7231 - val_loss: 0.5895 - val_accuracy: 0.6721\n",
            "Epoch 9/100\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.5871 - accuracy: 0.7107 - val_loss: 0.5846 - val_accuracy: 0.7213\n",
            "Epoch 10/100\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.5814 - accuracy: 0.7025 - val_loss: 0.6049 - val_accuracy: 0.6721\n",
            "Epoch 11/100\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.5728 - accuracy: 0.7107 - val_loss: 0.5833 - val_accuracy: 0.7213\n",
            "Epoch 12/100\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.5698 - accuracy: 0.7273 - val_loss: 0.5840 - val_accuracy: 0.7049\n",
            "Epoch 13/100\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.5775 - accuracy: 0.7025 - val_loss: 0.5848 - val_accuracy: 0.7049\n",
            "Epoch 14/100\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.5849 - accuracy: 0.7231 - val_loss: 0.5780 - val_accuracy: 0.7049\n",
            "Epoch 15/100\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.5793 - accuracy: 0.7231 - val_loss: 0.6339 - val_accuracy: 0.7049\n",
            "Epoch 16/100\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.5884 - accuracy: 0.7190 - val_loss: 0.5744 - val_accuracy: 0.7049\n",
            "Epoch 17/100\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.5824 - accuracy: 0.6777 - val_loss: 0.5793 - val_accuracy: 0.7377\n",
            "Epoch 18/100\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.5721 - accuracy: 0.7107 - val_loss: 0.5739 - val_accuracy: 0.7213\n",
            "Epoch 19/100\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.5523 - accuracy: 0.7355 - val_loss: 0.5806 - val_accuracy: 0.7049\n",
            "Epoch 20/100\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.5798 - accuracy: 0.7273 - val_loss: 0.5726 - val_accuracy: 0.7213\n",
            "Epoch 21/100\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.5667 - accuracy: 0.7190 - val_loss: 0.5726 - val_accuracy: 0.7213\n",
            "Epoch 22/100\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.5540 - accuracy: 0.7355 - val_loss: 0.5687 - val_accuracy: 0.7213\n",
            "Epoch 23/100\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.5523 - accuracy: 0.7355 - val_loss: 0.5717 - val_accuracy: 0.7213\n",
            "Epoch 24/100\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.5627 - accuracy: 0.7231 - val_loss: 0.5750 - val_accuracy: 0.7049\n",
            "Epoch 25/100\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.5496 - accuracy: 0.7355 - val_loss: 0.5643 - val_accuracy: 0.7213\n",
            "Epoch 26/100\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.5387 - accuracy: 0.7438 - val_loss: 0.6056 - val_accuracy: 0.6885\n",
            "Epoch 27/100\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.5528 - accuracy: 0.7273 - val_loss: 0.5438 - val_accuracy: 0.7049\n",
            "Epoch 28/100\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.5594 - accuracy: 0.7149 - val_loss: 0.5588 - val_accuracy: 0.7213\n",
            "Epoch 29/100\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.5769 - accuracy: 0.7149 - val_loss: 0.5580 - val_accuracy: 0.7213\n",
            "Epoch 30/100\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.5451 - accuracy: 0.7314 - val_loss: 0.5653 - val_accuracy: 0.7049\n",
            "Epoch 31/100\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.5438 - accuracy: 0.7314 - val_loss: 0.5631 - val_accuracy: 0.7377\n",
            "Epoch 32/100\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.5444 - accuracy: 0.7645 - val_loss: 0.5484 - val_accuracy: 0.7377\n",
            "Epoch 33/100\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.5331 - accuracy: 0.7479 - val_loss: 0.5463 - val_accuracy: 0.7213\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9eVYnHkboz_",
        "colab_type": "text"
      },
      "source": [
        "# 73% test accuracy after 17 epochs using Nadam optimizer, learning rate of 0.001, batch size of 8."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7G4NOG6qS5e",
        "colab_type": "text"
      },
      "source": [
        "## 3. Keras MMP <a id=\"Q3\"></a>\n",
        "\n",
        "Implement a Multilayer Perceptron architecture of your choosing using the Keras library. \n",
        "- [ ] Train your model and report its baseline accuracy.\n",
        "- [ ] Then hyperparameter tune at least two parameters and report your model's accuracy.\n",
        "- [ ] Use the Heart Disease Dataset (binary classification)\n",
        "- [ ] Use an appropriate loss function for a binary classification task\n",
        "- [ ] Use an appropriate activation function on the final layer of your network\n",
        "- [ ] Train your model using verbose output for ease of grading.\n",
        "- [ ] Use GridSearchCV or RandomSearchCV to hyperparameter tune your model. (for at least two hyperparameters)\n",
        "- [ ] When hyperparameter tuning, show you work by adding code cells for each new experiment.\n",
        "- [ ] Report the accuracy for each combination of hyperparameters as you test them so that we can easily see which resulted in the highest accuracy.\n",
        "- [ ] You must hyperparameter tune at least 3 parameters in order to get a 3 on this section."
      ]
    }
  ]
}