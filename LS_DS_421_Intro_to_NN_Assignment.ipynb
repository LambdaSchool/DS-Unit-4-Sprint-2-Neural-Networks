{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dVfaLrjLvxvQ"
   },
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "# Neural Networks\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2 Assignment 1*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wxtoY12mwmih"
   },
   "source": [
    "## Define the Following:\n",
    "You can add image, diagrams, whatever you need to ensure that you understand the concepts below.\n",
    "\n",
    "### Input Layer: feature or value\n",
    "### Hidden Layer:  unaccessable node in a NN\n",
    "### Output Layer: Result after function applied, wieghts and bias\n",
    "### Neuron: A node in a NN\n",
    "### Weight: Arbitrary Value that scales the input layer value that is later changed as a result of back propigation or hand tuned.\n",
    "### Activation Function: A function that decides on whether a node/nueron should be acitvated or not such as a sigmoid, linear, etc \n",
    "### Node Map: Schematic of the stream of information in a NN\n",
    "### Perceptron: A binary classifier is a function which can decide whether or not an input, represented by a vector of numbers, belongs to some specific class.[1] It is a type of linear classifier, i.e. a classification algorithm that makes its predictions based on a linear predictor function combining a set of weights with the feature vector. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NXuy9WcWzxa4"
   },
   "source": [
    "## Inputs -> Outputs\n",
    "\n",
    "### Explain the flow of information through a neural network from inputs to outputs. Be sure to include: inputs, weights, bias, and activation functions. How does it all flow from beginning to end?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PlSwIJMC0A8F"
   },
   "source": [
    "Information goes in as the input layer. It is then scaled by the weight and all terms of that node are added together as well as the bias. The activaion function then determines a value that corresponds to if successive nodes will be acivated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6sWR43PTwhSk"
   },
   "source": [
    "## Write your own perceptron code that can correctly classify a NAND gate. \n",
    "\n",
    "| x1 | x2 | y |\n",
    "|----|----|---|\n",
    "| 0  | 0  | 1 |\n",
    "| 1  | 0  | 1 |\n",
    "| 0  | 1  | 1 |\n",
    "| 1  | 1  | 0 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights after training\n",
      "[[-3.80750942]\n",
      " [-3.80606903]\n",
      " [11.69648812]]\n",
      "Output after training\n",
      "[[9.99991676e-01]\n",
      " [9.99625251e-01]\n",
      " [9.99625790e-01]\n",
      " [4.93507449e-04]]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(812)\n",
    "\n",
    "inputs = np.array([\n",
    "    [0,0,1],\n",
    "    [1,0,1],\n",
    "    [0,1,1],\n",
    "    [1,1,0]\n",
    "])\n",
    "\n",
    "correct_outputs = [[1], [1], [1], [0]]\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    sx = sigmoid(x)\n",
    "    return sx * (1-sx)\n",
    "\n",
    "errors = []\n",
    "\n",
    "weights = 2 * np.random.random((3,1)) - 1\n",
    "\n",
    "for iteration in range(10000):\n",
    "\n",
    "    \n",
    "    # Weighted sum of inputs / weights\n",
    "    weighted_sum = np.dot(inputs, weights)\n",
    "    \n",
    "    # Activate!\n",
    "    activated_output = sigmoid(weighted_sum)\n",
    "    \n",
    "    # Cac error\n",
    "    error = correct_outputs - activated_output\n",
    "    \n",
    "    adjustments = error * sigmoid_derivative(activated_output)\n",
    "\n",
    "    # Update the Weights\n",
    "    weights += np.dot(inputs.T, adjustments)\n",
    "    \n",
    "print(\"Weights after training\")\n",
    "print(weights)\n",
    "\n",
    "print(\"Output after training\")\n",
    "print(activated_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0]: -0.022950675649091312 -> 0\n",
      "[0 1]: 0.8106926382306658 -> 1\n",
      "[1 0]: 0.19468705056726954 -> 1\n",
      "[1 1]: 1.0283303644470265 -> 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29cbb8ce320>]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from random import choice\n",
    "\n",
    "unit_step = lambda x: 0 if x < 0 else 1\n",
    "\n",
    "training_data = [\n",
    "    (np.array([0,0,1]), 0),\n",
    "    (np.array([0,1,1]), 1),\n",
    "    (np.array([1,0,1]), 1),\n",
    "    (np.array([1,1,1]), 1),\n",
    "]\n",
    "\n",
    "w = random.rand(3)\n",
    "errors = []\n",
    "eta = 0.2\n",
    "n = 100\n",
    "\n",
    "for i in range(n):\n",
    "    x, expected = choice(training_data)\n",
    "    result = np.dot(w, x)\n",
    "    error = expected - unit_step(result)\n",
    "    errors.append(error)\n",
    "    w += eta * error * x\n",
    "\n",
    "for x, _ in training_data:\n",
    "    result = dot(x, w)\n",
    "    print(\"{}: {} -> {}\".format(x[:2], result, unit_step(result)))\n",
    "plot(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xf7sdqVs0s4x"
   },
   "source": [
    "## Implement your own Perceptron Class and use it to classify a binary dataset like: \n",
    "- [The Pima Indians Diabetes dataset](https://raw.githubusercontent.com/ryanleeallred/datasets/master/diabetes.csv) \n",
    "- [Titanic](https://raw.githubusercontent.com/ryanleeallred/datasets/master/titanic.csv)\n",
    "- [A two-class version of the Iris dataset](https://raw.githubusercontent.com/ryanleeallred/datasets/master/Iris.csv)\n",
    "\n",
    "You may need to search for other's implementations in order to get inspiration for your own. There are *lots* of perceptron implementations on the internet with varying levels of sophistication and complexity. Whatever your approach, make sure you understand **every** line of your implementation and what its purpose is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-W0tiX1F1hh2"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#AND gate predictor\n",
    "class Perceptron(object):\n",
    "\n",
    "    def __init__(self, no_of_inputs, threshold=100, learning_rate=0.01):\n",
    "        self.threshold = threshold\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weights = np.zeros(no_of_inputs + 1)\n",
    "           \n",
    "    def predict(self, inputs):\n",
    "        summation = np.dot(inputs, self.weights[1:]) + self.weights[0]\n",
    "        if summation > 0:\n",
    "          activation = 1\n",
    "        else:\n",
    "          activation = 0            \n",
    "        return activation\n",
    "\n",
    "    def train(self, training_inputs, labels):\n",
    "        for _ in range(self.threshold):\n",
    "            for inputs, label in zip(training_inputs, labels):\n",
    "                prediction = self.predict(inputs)\n",
    "                self.weights[1:] += self.learning_rate * (label - prediction) * inputs\n",
    "                self.weights[0] += self.learning_rate * (label - prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "training_inputs = []\n",
    "training_inputs.append(np.array([1, 1]))\n",
    "training_inputs.append(np.array([1, 0]))\n",
    "training_inputs.append(np.array([0, 1]))\n",
    "training_inputs.append(np.array([0, 0]))\n",
    "\n",
    "labels = np.array([1, 0, 0, 0])\n",
    "\n",
    "perceptron = Perceptron(2)\n",
    "perceptron.train(training_inputs, labels)\n",
    "\n",
    "inputs = np.array([1, 1])\n",
    "print(perceptron.predict(inputs)) \n",
    "#=> 1\n",
    "\n",
    "inputs = np.array([0, 1])\n",
    "print(perceptron.predict(inputs)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/ryanleeallred/datasets/master/diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "763           10      101             76             48      180  32.9   \n",
       "764            2      122             70             27        0  36.8   \n",
       "765            5      121             72             23      112  26.2   \n",
       "766            1      126             60              0        0  30.1   \n",
       "767            1       93             70             31        0  30.4   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  \n",
       "763                     0.171   63        0  \n",
       "764                     0.340   27        0  \n",
       "765                     0.245   30        0  \n",
       "766                     0.349   47        1  \n",
       "767                     0.315   23        0  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "labels = np.array(df.Outcome)\n",
    "for i in range(len(df)):\n",
    "    x = df.Pregnancies[i]\n",
    "    y = df.Glucose[i]\n",
    "    z = df.BloodPressure[i]\n",
    "    p = df.SkinThickness[i]\n",
    "    d = df.Insulin[i]\n",
    "    q = df.BMI[i]\n",
    "    r = df.Age[i]  \n",
    "    X.append(np.array([x,y,z,p,d,q,r]))\n",
    "    \n",
    "#print(X[0])\n",
    "#labels[0]\n",
    "\n",
    "perceptron_two = Perceptron(7)\n",
    "\n",
    "perceptron_two.train(X, labels)\n",
    " \n",
    "print(perceptron_two.predict([1,93,70,31,0,30.4,23]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron(object):\n",
    "    \"\"\"The Paul Method of Perceptron estimator with early stopping.\n",
    "    \n",
    "    :param learning_rate: float Estimator learning rate. Default == 0.01\n",
    "    :param epochs: int Number of epochs to run Perceptron. Default = 1000\n",
    "    :param early_stopping: int Number of epochs without imoprovement at which to stop estimator. Default = 10\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, learning_rate=0.01, epochs=1000, early_stopping=10):\n",
    "        self.lr = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.early_stopping = early_stopping\n",
    "        \n",
    "    def predict(self,row):\n",
    "        \"\"\"Apply weights and add bias to inputs.\n",
    "        \n",
    "        Return 1 if output is greater or equal zero, else zero for each element in input row.\"\"\"\n",
    "        \n",
    "        return (np.dot(row, self.weight[1:]) + self.weight[0]) >= 0\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit training data\n",
    "        \n",
    "        Initialize with random weights.\n",
    "        Update weights and bias with each row based on previous iteration's error.\n",
    "        Store number of errors for each epoch.\n",
    "        Stop if no errors in number of `early_stopping` epochs.\"\"\"\n",
    "        self.weight = binomial(1, .5, X.shape[1] + 1).astype(np.float)\n",
    "        \n",
    "        # Initialize bias at zero.\n",
    "        self.weight[0] = 0.0\n",
    "\n",
    "        self.errors = []\n",
    "        \n",
    "        for _ in range(self.epochs):\n",
    "            error = 0\n",
    "            for row, label in zip(X, y):\n",
    "                adjustment = self.lr * (label - self.predict(row))\n",
    "                self.weight[1:] += adjustment * row\n",
    "                self.weight[0] += adjustment\n",
    "                error += adjustment != 0.0\n",
    "            self.errors.append(error)\n",
    "\n",
    "            if sum(self.errors[-self.early_stopping:]) == 0:\n",
    "                print('Stopped Early')\n",
    "                break\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6QR4oAW1xdyu"
   },
   "source": [
    "## Stretch Goals:\n",
    "\n",
    "- Research \"backpropagation\" to learn how weights get updated in neural networks (tomorrow's lecture). \n",
    "- Implement a multi-layer perceptron. (for non-linearly separable classes)\n",
    "- Try and implement your own backpropagation algorithm.\n",
    "- What are the pros and cons of the different activation functions? How should you decide between them for the different layers of a neural network?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_431_Intro_to_NN_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
