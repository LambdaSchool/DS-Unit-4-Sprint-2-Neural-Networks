{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DS_Unit_4_Sprint_3_Neural_Nets_Spring_Challenge.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6SKlgYrpcym",
        "colab_type": "text"
      },
      "source": [
        "# Neural Networks Sprint Challenge"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrEbRrjVphPM",
        "colab_type": "text"
      },
      "source": [
        "## 1) Define the following terms:\n",
        "\n",
        "- Neuron\n",
        "- Input Layer\n",
        "- Hidden Layer\n",
        "- Output Layer\n",
        "- Activation\n",
        "- Backpropagation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5EksLqnp4oB",
        "colab_type": "text"
      },
      "source": [
        "###Neuron: \n",
        "Neuron is a call. It has nucleus, dendrite and axon. Dendrite is input and axon is output. To explain the process of how it works: Neurons sends out axons to a bunch of neurons. Whichever neurons receives that and has the signal to push it forward over a certain threshold to other neurons connected to it down the line.\n",
        "\n",
        "###Input Layer:\n",
        "The visible layer that is directly connected to the data and receives data as input, is called Input Layer. Input layeer can have one or many nodes. The number of nodes is determined by number of features/columns/inputs dataset has that will be passed to the network.\n",
        "\n",
        "###Hidden Layer:\n",
        "The layer between input and output is called Hidden layer. It access data only through Input layer and there is not other way to interact with them directly.\n",
        "\n",
        "###Output Layer (Copied from Lecture notebook since there is no better way to explain this):\n",
        "The final layer is called the Output Layer. The purpose of the output layer is to output a vector of values that is in a format that is suitable for the type of problem that we're trying to address. Typically the output value is modified by an \"activation function\" to transform it into a format that makes sense for our context, here's a couple of examples:\n",
        "\n",
        "NNs applied to a regression problem might have a single output node with no activation function because what we want is an unbounded continuous value.\n",
        "\n",
        "NNS applied to a binary classification problem might use a sigmoid function as its activation function in order to squishify values down to represent a probability. Outputs in this case would represent the probability of predicting the primary class of interest. We can turn this into a class-specific prediction by rounding the outputted sigmoid probability up to 1 or down to 0.\n",
        "\n",
        "NNS applied to multiclass classification problems might have multiple output nodes in the output layer, one for each class that we're trying to predict. This output layer would probably employ what's called a \"softmax function\" for accomplishing this. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ri_gRA2Jp728",
        "colab_type": "text"
      },
      "source": [
        "## 2) Create a perceptron class that can model the behavior of an AND gate. You can use the following table as your training data:\n",
        "\n",
        "| x1 | x2 | x3 | y |\n",
        "|----|----|----|---|\n",
        "| 1  | 1  | 1  | 1 |\n",
        "| 1  | 0  | 1  | 0 |\n",
        "| 0  | 1  | 1  | 0 |\n",
        "| 0  | 0  | 1  | 0 |"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ig6ZTH8tpQ19",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "eb3ea9c2-e356-49e4-88c1-2e971913efc3"
      },
      "source": [
        "import numpy as np\n",
        "inputs = np.array([[1,1,1], \n",
        "                  [1,0,1], \n",
        "                  [0,1,1], \n",
        "                  [0,0,1]])\n",
        "\n",
        "correct_outputs = [[1], \n",
        "                    [0], \n",
        "                    [0], \n",
        "                    [0]]\n",
        "\n",
        "weights = 2 * np.random.random((3,1)) - 1\n",
        "weights"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.11307909],\n",
              "       [ 0.73832821],\n",
              "       [-0.22307166]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BEcYp8w7tt0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoid(x):\n",
        "  return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "  return sigmoid(x) * (1 - sigmoid(x))\n",
        "\n",
        "for iteration in range(10000):\n",
        "  \n",
        "    # Weighted sum of inputs and weights\n",
        "    weighted_sum = np.dot(inputs, weights)\n",
        "\n",
        "    # Activate with sigmoid function\n",
        "    activated_output = sigmoid(weighted_sum)\n",
        "\n",
        "    # Calculate Error\n",
        "    error = correct_outputs - activated_output\n",
        "\n",
        "    # Calculate weight adjustments with sigmoid_derivative\n",
        "    adjustments = error * sigmoid_derivative(activated_output)\n",
        "\n",
        "    # Update weights\n",
        "    weights += np.dot(inputs.T, adjustments)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mFwsM3O7yZp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "59c57208-e046-44e8-af47-12fd08108107"
      },
      "source": [
        "print('optimized weights after training: ')\n",
        "print(weights)\n",
        "\n",
        "print(\"Output After Training:\")\n",
        "print(activated_output)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "optimized weights after training: \n",
            "[[ 11.84046989]\n",
            " [ 11.84046989]\n",
            " [-18.04901407]]\n",
            "Output After Training:\n",
            "[[9.96430754e-01]\n",
            " [2.00832526e-03]\n",
            " [2.00832526e-03]\n",
            " [1.45058644e-08]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86HyRi8Osr3U",
        "colab_type": "text"
      },
      "source": [
        "## 3) Implement a Neural Network Multilayer Perceptron class that uses backpropagation to update the network's weights. \n",
        "- Your network must have one hidden layer. \n",
        "- You do not have to update weights via gradient descent. You can use something like the derivative of the sigmoid function to update weights.\n",
        "- Train your model on the Heart Disease dataset from UCI:\n",
        "\n",
        "[Github Dataset](https://github.com/ryanleeallred/datasets/blob/master/heart.csv)\n",
        "\n",
        "[Raw File on Github](https://raw.githubusercontent.com/ryanleeallred/datasets/master/heart.csv)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNfiajv3v4Ed",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "496d656e-a4ac-4cbc-fe63-bf2bf2256a4a"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/ryanleeallred/datasets/master/heart.csv\")\n",
        "df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>63</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>145</td>\n",
              "      <td>233</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>150</td>\n",
              "      <td>0</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>37</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>130</td>\n",
              "      <td>250</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>187</td>\n",
              "      <td>0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>41</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>130</td>\n",
              "      <td>204</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>172</td>\n",
              "      <td>0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>56</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>120</td>\n",
              "      <td>236</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>178</td>\n",
              "      <td>0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>57</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>120</td>\n",
              "      <td>354</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>163</td>\n",
              "      <td>1</td>\n",
              "      <td>0.6</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age  sex  cp  trestbps  chol  fbs  ...  exang  oldpeak  slope  ca  thal  target\n",
              "0   63    1   3       145   233    1  ...      0      2.3      0   0     1       1\n",
              "1   37    1   2       130   250    0  ...      0      3.5      0   0     2       1\n",
              "2   41    0   1       130   204    0  ...      0      1.4      2   0     2       1\n",
              "3   56    1   1       120   236    0  ...      0      0.8      2   0     2       1\n",
              "4   57    0   0       120   354    0  ...      1      0.6      2   0     2       1\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24UeVqdm8fAa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5389
        },
        "outputId": "a2401e89-85d9-4fcb-adde-e8473c2082d8"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X = df.drop(columns=['target'])\n",
        "y = df['target']\n",
        "\n",
        "# Scale inputs\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "X = X.reshape(-1,13)\n",
        "y = np.array(y).reshape(-1,1)\n",
        "\n",
        "print(X)\n",
        "print(y)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.9521966   0.68100522  1.97312292 ... -2.27457861 -0.71442887\n",
            "  -2.14887271]\n",
            " [-1.91531289  0.68100522  1.00257707 ... -2.27457861 -0.71442887\n",
            "  -0.51292188]\n",
            " [-1.47415758 -1.46841752  0.03203122 ...  0.97635214 -0.71442887\n",
            "  -0.51292188]\n",
            " ...\n",
            " [ 1.50364073  0.68100522 -0.93851463 ... -0.64911323  1.24459328\n",
            "   1.12302895]\n",
            " [ 0.29046364  0.68100522 -0.93851463 ... -0.64911323  0.26508221\n",
            "   1.12302895]\n",
            " [ 0.29046364 -1.46841752  0.03203122 ... -0.64911323  0.26508221\n",
            "  -0.51292188]]\n",
            "[[1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dblkUmr8z_T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Neural_Network(object):\n",
        "  def __init__(self):\n",
        "    self.inputs = 13\n",
        "    self.hiddenNodes = 7\n",
        "    self.outputNodes = 1\n",
        "    \n",
        "    # Initialize Weights\n",
        "    self.L1_weights = np.random.randn(self.inputs, self.hiddenNodes) # (13x7)\n",
        "    self.L2_weights = np.random.randn(self.hiddenNodes, self.outputNodes) # (7x1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uk6p_JXS83EJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "outputId": "91e70222-faf5-4275-8fdb-f1b842e36879"
      },
      "source": [
        "NN = Neural_Network()\n",
        "\n",
        "print(\"Layer 1 weights: \\n\", NN.L1_weights)\n",
        "print(\"Layer 2 weights: \\n\", NN.L2_weights)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Layer 1 weights: \n",
            " [[ 8.74515486e-01  2.83019217e+00  5.31337081e-01 -7.24818651e-01\n",
            "  -2.19344027e-01 -8.53516711e-01 -6.65236681e-01]\n",
            " [-5.20615373e-01 -2.68619168e+00  7.65625897e-01 -6.70071419e-01\n",
            "   1.98879523e+00  2.27772184e+00 -4.94376581e-01]\n",
            " [ 7.28345862e-01 -1.02727122e-01  1.00667370e+00 -1.60193326e+00\n",
            "  -3.58041664e-01  1.90414204e-01  6.44004116e-01]\n",
            " [-1.19381731e+00 -3.67928915e-01 -5.01541648e-02 -1.14438224e+00\n",
            "  -1.32705773e-01  9.27063202e-01 -1.85713866e+00]\n",
            " [ 1.58508023e+00  4.48130030e-01  2.03581634e+00 -1.00741172e-01\n",
            "  -2.32976554e-01  1.63527266e-01 -3.89841559e-01]\n",
            " [ 5.38997752e-01 -9.34350459e-01  2.33539227e-01 -1.69281098e+00\n",
            "   9.04033565e-01  1.74380845e-01  1.37998899e+00]\n",
            " [-1.01976024e+00  8.63970843e-01 -9.32296938e-01 -9.01645949e-02\n",
            "   9.07221209e-01 -1.58795349e+00  1.18134369e+00]\n",
            " [-3.80233628e-01 -5.36058134e-01  2.59230186e+00 -2.78353830e-01\n",
            "  -1.25767462e+00 -7.73448702e-01 -5.53701370e-02]\n",
            " [ 1.14010948e+00 -1.31965865e+00  4.61048492e-02  3.15814244e-01\n",
            "   4.33514634e-01  4.04617270e-01  1.46979075e+00]\n",
            " [ 8.77504190e-01  1.04239598e+00 -7.80832652e-01  8.93909155e-01\n",
            "  -1.71833420e+00 -2.50149897e-01  1.11627922e+00]\n",
            " [ 4.17908310e-01  2.38355023e-03  9.89968067e-01 -1.27634021e+00\n",
            "  -1.09164572e+00  8.23214453e-01 -7.62053406e-01]\n",
            " [ 6.53802508e-01 -6.88566229e-01 -1.41477930e+00 -9.88187041e-01\n",
            "  -4.46343146e-01 -1.37375561e-01  1.72240290e+00]\n",
            " [-3.49818652e-01 -9.39370529e-01  8.62219439e-01 -2.46547851e-01\n",
            "   1.27826575e+00  4.45067094e-01  8.19971777e-02]]\n",
            "Layer 2 weights: \n",
            " [[ 1.46171184]\n",
            " [ 0.16541723]\n",
            " [ 0.48911516]\n",
            " [-0.31488178]\n",
            " [-0.51435825]\n",
            " [ 0.32779244]\n",
            " [-0.88955383]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hl27TGIo86JR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Neural_Network(object):\n",
        "  def __init__(self):\n",
        "    self.inputs = 13\n",
        "    self.hiddenNodes = 7\n",
        "    self.outputNodes = 1\n",
        "\n",
        "    # Initlize Weights\n",
        "    self.L1_weights = np.random.randn(self.inputs, self.hiddenNodes) # (13x7)\n",
        "    self.L2_weights = np.random.randn(self.hiddenNodes, self.outputNodes) # (7x1)\n",
        "\n",
        "  def feed_forward(self, X):\n",
        "    # Weighted sum between inputs and hidden layer\n",
        "    self.hidden_sum = np.dot(X, self.L1_weights)\n",
        "    # Activations of weighted sum\n",
        "    self.activated_hidden = self.sigmoid(self.hidden_sum)\n",
        "    # Weighted sum between hidden and output\n",
        "    self.output_sum = np.dot(self.activated_hidden, self.L2_weights)\n",
        "    # final activation of output\n",
        "    self.activated_output = self.sigmoid(self.output_sum)\n",
        "    return self.activated_output\n",
        "    \n",
        "  def sigmoid(self, s):\n",
        "    return 1/(1+np.exp(-s))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvqH1Ahu8-kg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "910c1f94-e49a-4377-8660-419dec10d9db"
      },
      "source": [
        "NN = Neural_Network()\n",
        "output = NN.feed_forward(X[0])\n",
        "print(\"output: \", output)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "output:  [0.1591926]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOYr-sqo9CBP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2142
        },
        "outputId": "60ba9b5c-3f90-4c04-b94a-7eafa914113e"
      },
      "source": [
        "class Neural_Network(object):\n",
        "  def __init__(self):\n",
        "    self.inputs = 13\n",
        "    self.hiddenNodes = 7\n",
        "    self.outputNodes = 1\n",
        "\n",
        "    # Initialize Weights:\n",
        "    self.L1_weights = np.random.randn(self.inputs, self.hiddenNodes) \n",
        "    self.L2_weights = np.random.randn(self.hiddenNodes, self.outputNodes) \n",
        "\n",
        "  def feed_forward(self, X):\n",
        "    \n",
        "    # Weighted sum between inputs and hidden layer:\n",
        "    self.hidden_sum = np.dot(X, self.L1_weights)\n",
        "    \n",
        "    # Activations of weighted sum:\n",
        "    self.activated_hidden = self.sigmoid(self.hidden_sum)\n",
        "    \n",
        "    # Weighted sum between hidden and output:\n",
        "    self.output_sum = np.dot(self.activated_hidden, self.L2_weights)\n",
        "    \n",
        "    # final activation of output:\n",
        "    self.activated_output = self.sigmoid(self.output_sum)\n",
        "    \n",
        "    return self.activated_output\n",
        "    \n",
        "  def sigmoid(self, s):\n",
        "    return 1/(1+np.exp(-s))\n",
        "  \n",
        "  #sigmoid derivative  \n",
        "  def sigmoidPrime(self, s):\n",
        "    return s * (1 - s)\n",
        "  \n",
        " #dCost/dWeights =    \n",
        "    \n",
        "  def backward(self, X, y, output):\n",
        "    # backward propgate through the network\n",
        "    \n",
        "    # error in output:\n",
        "    self.output_error = y - output \n",
        "    \n",
        "    # applying derivative of sigmoid to error:\n",
        "    self.output_delta = self.output_error * self.sigmoidPrime(output) \n",
        "    \n",
        "    # z2 error: how much our hidden layer weights contributed to output error:\n",
        "    self.z2_error = self.output_delta.dot(self.L2_weights.T)\n",
        "    \n",
        "    # applying derivative of sigmoid to z2 error:\n",
        "    self.z2_delta = self.z2_error*self.sigmoidPrime(self.activated_hidden) \n",
        "    \n",
        "    # adjusting first set (input --> hidden) weights:\n",
        "    self.L1_weights += X.T.dot(self.z2_delta) \n",
        "    \n",
        "    # adjusting second set (hidden --> output) weights:\n",
        "    self.L2_weights += self.activated_hidden.T.dot(self.output_delta) \n",
        "    \n",
        "  def train (self, X, y):\n",
        "    output = self.feed_forward(X)\n",
        "    self.backward(X, y, output)\n",
        "    \n",
        "NN = Neural_Network()\n",
        "for i in range(1000): # trains the NN 1,000 times\n",
        "  if i+1 in [1,2,3,4,5] or (i+1) % 50 == 0:\n",
        "    print('+---------- EPOCH', i+1, '-----------+')\n",
        "\n",
        "    print(\"Loss: \\n\" + str(np.mean(np.square(y - NN.feed_forward(X))))) # mean sum squared loss\n",
        "    print(\"\\n\")\n",
        "  NN.train(X, y)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------- EPOCH 1 -----------+\n",
            "Loss: \n",
            "0.24528657582047464\n",
            "\n",
            "\n",
            "+---------- EPOCH 2 -----------+\n",
            "Loss: \n",
            "0.5477374393035964\n",
            "\n",
            "\n",
            "+---------- EPOCH 3 -----------+\n",
            "Loss: \n",
            "0.5445924377433831\n",
            "\n",
            "\n",
            "+---------- EPOCH 4 -----------+\n",
            "Loss: \n",
            "0.5442757489472025\n",
            "\n",
            "\n",
            "+---------- EPOCH 5 -----------+\n",
            "Loss: \n",
            "0.5440909042000018\n",
            "\n",
            "\n",
            "+---------- EPOCH 50 -----------+\n",
            "Loss: \n",
            "0.0946269315986476\n",
            "\n",
            "\n",
            "+---------- EPOCH 100 -----------+\n",
            "Loss: \n",
            "0.09315983550191415\n",
            "\n",
            "\n",
            "+---------- EPOCH 150 -----------+\n",
            "Loss: \n",
            "0.0863889605691415\n",
            "\n",
            "\n",
            "+---------- EPOCH 200 -----------+\n",
            "Loss: \n",
            "0.07976850924036089\n",
            "\n",
            "\n",
            "+---------- EPOCH 250 -----------+\n",
            "Loss: \n",
            "0.06755424998008024\n",
            "\n",
            "\n",
            "+---------- EPOCH 300 -----------+\n",
            "Loss: \n",
            "0.06297721140832371\n",
            "\n",
            "\n",
            "+---------- EPOCH 350 -----------+\n",
            "Loss: \n",
            "0.05870723049116404\n",
            "\n",
            "\n",
            "+---------- EPOCH 400 -----------+\n",
            "Loss: \n",
            "0.05655102666790822\n",
            "\n",
            "\n",
            "+---------- EPOCH 450 -----------+\n",
            "Loss: \n",
            "0.056441540151430866\n",
            "\n",
            "\n",
            "+---------- EPOCH 500 -----------+\n",
            "Loss: \n",
            "0.05638673082653251\n",
            "\n",
            "\n",
            "+---------- EPOCH 550 -----------+\n",
            "Loss: \n",
            "0.05634815813937396\n",
            "\n",
            "\n",
            "+---------- EPOCH 600 -----------+\n",
            "Loss: \n",
            "0.05631776407662824\n",
            "\n",
            "\n",
            "+---------- EPOCH 650 -----------+\n",
            "Loss: \n",
            "0.05629140823998897\n",
            "\n",
            "\n",
            "+---------- EPOCH 700 -----------+\n",
            "Loss: \n",
            "0.05626248873401387\n",
            "\n",
            "\n",
            "+---------- EPOCH 750 -----------+\n",
            "Loss: \n",
            "0.05622777914694551\n",
            "\n",
            "\n",
            "+---------- EPOCH 800 -----------+\n",
            "Loss: \n",
            "0.05620292905854761\n",
            "\n",
            "\n",
            "+---------- EPOCH 850 -----------+\n",
            "Loss: \n",
            "0.05618680485613868\n",
            "\n",
            "\n",
            "+---------- EPOCH 900 -----------+\n",
            "Loss: \n",
            "0.05617581087291077\n",
            "\n",
            "\n",
            "+---------- EPOCH 950 -----------+\n",
            "Loss: \n",
            "0.05616790439529946\n",
            "\n",
            "\n",
            "+---------- EPOCH 1000 -----------+\n",
            "Loss: \n",
            "0.056161928324621795\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnMCevC49b7U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGT1oRzXw3H9",
        "colab_type": "text"
      },
      "source": [
        "## 4) Implement a Multilayer Perceptron architecture of your choosing using the Keras library. Train your model and report its baseline accuracy. Then hyperparameter tune at least two parameters and report your model's accuracy. \n",
        "\n",
        "- Use the Heart Disease Dataset (binary classification)\n",
        "- Use an appropriate loss function for a binary classification task\n",
        "- Use an appropriate activation function on the final layer of your network. \n",
        "- Train your model using verbose output for ease of grading.\n",
        "- Use GridSearchCV to hyperparameter tune your model. (for at least two hyperparameters)\n",
        "- When hyperparameter tuning, show you work by adding code cells for each new experiment. \n",
        "- Report the accuracy for each combination of hyperparameters as you test them so that we can easily see which resulted in the highest accuracy.\n",
        "- You must hyperparameter tune at least 5 parameters in order to get a 3 on this section."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWw4IYxLxKwH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5117
        },
        "outputId": "037da2dd-6b50-481b-cf96-feb9e4ebbf4e"
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "# Function to create model, required for KerasClassifier\n",
        "def create_model():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(13, input_dim=13, activation='relu'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    # Compile model\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# create model\n",
        "model = KerasClassifier(build_fn=create_model, verbose=1)\n",
        "\n",
        "history = model.fit(X, y, epochs=150)\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "303/303 [==============================] - 6s 21ms/step - loss: 0.6964 - acc: 0.5875\n",
            "Epoch 2/150\n",
            "303/303 [==============================] - 0s 108us/step - loss: 0.6654 - acc: 0.6370\n",
            "Epoch 3/150\n",
            "303/303 [==============================] - 0s 106us/step - loss: 0.6374 - acc: 0.6733\n",
            "Epoch 4/150\n",
            "303/303 [==============================] - 0s 122us/step - loss: 0.6132 - acc: 0.7063\n",
            "Epoch 5/150\n",
            "303/303 [==============================] - 0s 108us/step - loss: 0.5916 - acc: 0.7195\n",
            "Epoch 6/150\n",
            "303/303 [==============================] - 0s 108us/step - loss: 0.5725 - acc: 0.7327\n",
            "Epoch 7/150\n",
            "303/303 [==============================] - 0s 117us/step - loss: 0.5536 - acc: 0.7426\n",
            "Epoch 8/150\n",
            "303/303 [==============================] - 0s 115us/step - loss: 0.5376 - acc: 0.7624\n",
            "Epoch 9/150\n",
            "303/303 [==============================] - 0s 151us/step - loss: 0.5236 - acc: 0.7690\n",
            "Epoch 10/150\n",
            "303/303 [==============================] - 0s 128us/step - loss: 0.5106 - acc: 0.7723\n",
            "Epoch 11/150\n",
            "303/303 [==============================] - 0s 126us/step - loss: 0.4985 - acc: 0.7723\n",
            "Epoch 12/150\n",
            "303/303 [==============================] - 0s 131us/step - loss: 0.4878 - acc: 0.7756\n",
            "Epoch 13/150\n",
            "303/303 [==============================] - 0s 115us/step - loss: 0.4778 - acc: 0.7822\n",
            "Epoch 14/150\n",
            "303/303 [==============================] - 0s 141us/step - loss: 0.4684 - acc: 0.7921\n",
            "Epoch 15/150\n",
            "303/303 [==============================] - 0s 120us/step - loss: 0.4605 - acc: 0.7921\n",
            "Epoch 16/150\n",
            "303/303 [==============================] - 0s 126us/step - loss: 0.4525 - acc: 0.7954\n",
            "Epoch 17/150\n",
            "303/303 [==============================] - 0s 134us/step - loss: 0.4446 - acc: 0.7987\n",
            "Epoch 18/150\n",
            "303/303 [==============================] - 0s 126us/step - loss: 0.4380 - acc: 0.8020\n",
            "Epoch 19/150\n",
            "303/303 [==============================] - 0s 143us/step - loss: 0.4314 - acc: 0.8119\n",
            "Epoch 20/150\n",
            "303/303 [==============================] - 0s 123us/step - loss: 0.4256 - acc: 0.8185\n",
            "Epoch 21/150\n",
            "303/303 [==============================] - 0s 125us/step - loss: 0.4194 - acc: 0.8251\n",
            "Epoch 22/150\n",
            "303/303 [==============================] - 0s 127us/step - loss: 0.4142 - acc: 0.8251\n",
            "Epoch 23/150\n",
            "303/303 [==============================] - 0s 120us/step - loss: 0.4090 - acc: 0.8251\n",
            "Epoch 24/150\n",
            "303/303 [==============================] - 0s 118us/step - loss: 0.4041 - acc: 0.8218\n",
            "Epoch 25/150\n",
            "303/303 [==============================] - 0s 137us/step - loss: 0.3999 - acc: 0.8317\n",
            "Epoch 26/150\n",
            "303/303 [==============================] - 0s 122us/step - loss: 0.3958 - acc: 0.8350\n",
            "Epoch 27/150\n",
            "303/303 [==============================] - 0s 144us/step - loss: 0.3916 - acc: 0.8350\n",
            "Epoch 28/150\n",
            "303/303 [==============================] - 0s 131us/step - loss: 0.3878 - acc: 0.8350\n",
            "Epoch 29/150\n",
            "303/303 [==============================] - 0s 154us/step - loss: 0.3842 - acc: 0.8383\n",
            "Epoch 30/150\n",
            "303/303 [==============================] - 0s 113us/step - loss: 0.3813 - acc: 0.8350\n",
            "Epoch 31/150\n",
            "303/303 [==============================] - 0s 138us/step - loss: 0.3779 - acc: 0.8350\n",
            "Epoch 32/150\n",
            "303/303 [==============================] - 0s 127us/step - loss: 0.3749 - acc: 0.8350\n",
            "Epoch 33/150\n",
            "303/303 [==============================] - 0s 125us/step - loss: 0.3720 - acc: 0.8350\n",
            "Epoch 34/150\n",
            "303/303 [==============================] - 0s 119us/step - loss: 0.3697 - acc: 0.8416\n",
            "Epoch 35/150\n",
            "303/303 [==============================] - 0s 118us/step - loss: 0.3669 - acc: 0.8416\n",
            "Epoch 36/150\n",
            "303/303 [==============================] - 0s 126us/step - loss: 0.3642 - acc: 0.8416\n",
            "Epoch 37/150\n",
            "303/303 [==============================] - 0s 120us/step - loss: 0.3620 - acc: 0.8416\n",
            "Epoch 38/150\n",
            "303/303 [==============================] - 0s 161us/step - loss: 0.3597 - acc: 0.8416\n",
            "Epoch 39/150\n",
            "303/303 [==============================] - 0s 128us/step - loss: 0.3574 - acc: 0.8449\n",
            "Epoch 40/150\n",
            "303/303 [==============================] - 0s 123us/step - loss: 0.3556 - acc: 0.8482\n",
            "Epoch 41/150\n",
            "303/303 [==============================] - 0s 132us/step - loss: 0.3532 - acc: 0.8482\n",
            "Epoch 42/150\n",
            "303/303 [==============================] - 0s 123us/step - loss: 0.3513 - acc: 0.8482\n",
            "Epoch 43/150\n",
            "303/303 [==============================] - 0s 136us/step - loss: 0.3495 - acc: 0.8548\n",
            "Epoch 44/150\n",
            "303/303 [==============================] - 0s 110us/step - loss: 0.3478 - acc: 0.8581\n",
            "Epoch 45/150\n",
            "303/303 [==============================] - 0s 128us/step - loss: 0.3459 - acc: 0.8581\n",
            "Epoch 46/150\n",
            "303/303 [==============================] - 0s 131us/step - loss: 0.3439 - acc: 0.8581\n",
            "Epoch 47/150\n",
            "303/303 [==============================] - 0s 113us/step - loss: 0.3422 - acc: 0.8614\n",
            "Epoch 48/150\n",
            "303/303 [==============================] - 0s 130us/step - loss: 0.3407 - acc: 0.8647\n",
            "Epoch 49/150\n",
            "303/303 [==============================] - 0s 127us/step - loss: 0.3387 - acc: 0.8680\n",
            "Epoch 50/150\n",
            "303/303 [==============================] - 0s 136us/step - loss: 0.3373 - acc: 0.8680\n",
            "Epoch 51/150\n",
            "303/303 [==============================] - 0s 132us/step - loss: 0.3357 - acc: 0.8713\n",
            "Epoch 52/150\n",
            "303/303 [==============================] - 0s 125us/step - loss: 0.3343 - acc: 0.8713\n",
            "Epoch 53/150\n",
            "303/303 [==============================] - 0s 130us/step - loss: 0.3328 - acc: 0.8746\n",
            "Epoch 54/150\n",
            "303/303 [==============================] - 0s 150us/step - loss: 0.3310 - acc: 0.8746\n",
            "Epoch 55/150\n",
            "303/303 [==============================] - 0s 125us/step - loss: 0.3297 - acc: 0.8746\n",
            "Epoch 56/150\n",
            "303/303 [==============================] - 0s 123us/step - loss: 0.3284 - acc: 0.8746\n",
            "Epoch 57/150\n",
            "303/303 [==============================] - 0s 141us/step - loss: 0.3270 - acc: 0.8746\n",
            "Epoch 58/150\n",
            "303/303 [==============================] - 0s 137us/step - loss: 0.3256 - acc: 0.8779\n",
            "Epoch 59/150\n",
            "303/303 [==============================] - 0s 123us/step - loss: 0.3244 - acc: 0.8779\n",
            "Epoch 60/150\n",
            "303/303 [==============================] - 0s 132us/step - loss: 0.3229 - acc: 0.8779\n",
            "Epoch 61/150\n",
            "303/303 [==============================] - 0s 125us/step - loss: 0.3216 - acc: 0.8779\n",
            "Epoch 62/150\n",
            "303/303 [==============================] - 0s 139us/step - loss: 0.3203 - acc: 0.8746\n",
            "Epoch 63/150\n",
            "303/303 [==============================] - 0s 124us/step - loss: 0.3191 - acc: 0.8746\n",
            "Epoch 64/150\n",
            "303/303 [==============================] - 0s 125us/step - loss: 0.3180 - acc: 0.8746\n",
            "Epoch 65/150\n",
            "303/303 [==============================] - 0s 140us/step - loss: 0.3169 - acc: 0.8746\n",
            "Epoch 66/150\n",
            "303/303 [==============================] - 0s 123us/step - loss: 0.3157 - acc: 0.8746\n",
            "Epoch 67/150\n",
            "303/303 [==============================] - 0s 130us/step - loss: 0.3145 - acc: 0.8746\n",
            "Epoch 68/150\n",
            "303/303 [==============================] - 0s 132us/step - loss: 0.3135 - acc: 0.8746\n",
            "Epoch 69/150\n",
            "303/303 [==============================] - 0s 129us/step - loss: 0.3125 - acc: 0.8746\n",
            "Epoch 70/150\n",
            "303/303 [==============================] - 0s 136us/step - loss: 0.3115 - acc: 0.8746\n",
            "Epoch 71/150\n",
            "303/303 [==============================] - 0s 119us/step - loss: 0.3107 - acc: 0.8746\n",
            "Epoch 72/150\n",
            "303/303 [==============================] - 0s 144us/step - loss: 0.3095 - acc: 0.8746\n",
            "Epoch 73/150\n",
            "303/303 [==============================] - 0s 128us/step - loss: 0.3083 - acc: 0.8746\n",
            "Epoch 74/150\n",
            "303/303 [==============================] - 0s 128us/step - loss: 0.3076 - acc: 0.8746\n",
            "Epoch 75/150\n",
            "303/303 [==============================] - 0s 127us/step - loss: 0.3064 - acc: 0.8746\n",
            "Epoch 76/150\n",
            "303/303 [==============================] - 0s 131us/step - loss: 0.3056 - acc: 0.8746\n",
            "Epoch 77/150\n",
            "303/303 [==============================] - 0s 138us/step - loss: 0.3048 - acc: 0.8746\n",
            "Epoch 78/150\n",
            "303/303 [==============================] - 0s 158us/step - loss: 0.3041 - acc: 0.8779\n",
            "Epoch 79/150\n",
            "303/303 [==============================] - 0s 127us/step - loss: 0.3029 - acc: 0.8779\n",
            "Epoch 80/150\n",
            "303/303 [==============================] - 0s 130us/step - loss: 0.3021 - acc: 0.8779\n",
            "Epoch 81/150\n",
            "303/303 [==============================] - 0s 126us/step - loss: 0.3012 - acc: 0.8779\n",
            "Epoch 82/150\n",
            "303/303 [==============================] - 0s 130us/step - loss: 0.3004 - acc: 0.8779\n",
            "Epoch 83/150\n",
            "303/303 [==============================] - 0s 128us/step - loss: 0.2996 - acc: 0.8779\n",
            "Epoch 84/150\n",
            "303/303 [==============================] - 0s 137us/step - loss: 0.2986 - acc: 0.8779\n",
            "Epoch 85/150\n",
            "303/303 [==============================] - 0s 120us/step - loss: 0.2980 - acc: 0.8779\n",
            "Epoch 86/150\n",
            "303/303 [==============================] - 0s 128us/step - loss: 0.2970 - acc: 0.8779\n",
            "Epoch 87/150\n",
            "303/303 [==============================] - 0s 141us/step - loss: 0.2960 - acc: 0.8779\n",
            "Epoch 88/150\n",
            "303/303 [==============================] - 0s 129us/step - loss: 0.2953 - acc: 0.8779\n",
            "Epoch 89/150\n",
            "303/303 [==============================] - 0s 134us/step - loss: 0.2942 - acc: 0.8812\n",
            "Epoch 90/150\n",
            "303/303 [==============================] - 0s 128us/step - loss: 0.2935 - acc: 0.8845\n",
            "Epoch 91/150\n",
            "303/303 [==============================] - 0s 119us/step - loss: 0.2925 - acc: 0.8845\n",
            "Epoch 92/150\n",
            "303/303 [==============================] - 0s 122us/step - loss: 0.2917 - acc: 0.8845\n",
            "Epoch 93/150\n",
            "303/303 [==============================] - 0s 133us/step - loss: 0.2909 - acc: 0.8845\n",
            "Epoch 94/150\n",
            "303/303 [==============================] - 0s 133us/step - loss: 0.2901 - acc: 0.8845\n",
            "Epoch 95/150\n",
            "303/303 [==============================] - 0s 130us/step - loss: 0.2893 - acc: 0.8878\n",
            "Epoch 96/150\n",
            "303/303 [==============================] - 0s 124us/step - loss: 0.2884 - acc: 0.8845\n",
            "Epoch 97/150\n",
            "303/303 [==============================] - 0s 132us/step - loss: 0.2876 - acc: 0.8878\n",
            "Epoch 98/150\n",
            "303/303 [==============================] - 0s 140us/step - loss: 0.2867 - acc: 0.8911\n",
            "Epoch 99/150\n",
            "303/303 [==============================] - 0s 115us/step - loss: 0.2859 - acc: 0.8911\n",
            "Epoch 100/150\n",
            "303/303 [==============================] - 0s 119us/step - loss: 0.2852 - acc: 0.8911\n",
            "Epoch 101/150\n",
            "303/303 [==============================] - 0s 120us/step - loss: 0.2844 - acc: 0.8911\n",
            "Epoch 102/150\n",
            "303/303 [==============================] - 0s 130us/step - loss: 0.2836 - acc: 0.8911\n",
            "Epoch 103/150\n",
            "303/303 [==============================] - 0s 122us/step - loss: 0.2830 - acc: 0.8911\n",
            "Epoch 104/150\n",
            "303/303 [==============================] - 0s 112us/step - loss: 0.2821 - acc: 0.8944\n",
            "Epoch 105/150\n",
            "303/303 [==============================] - 0s 128us/step - loss: 0.2813 - acc: 0.8944\n",
            "Epoch 106/150\n",
            "303/303 [==============================] - 0s 137us/step - loss: 0.2805 - acc: 0.8944\n",
            "Epoch 107/150\n",
            "303/303 [==============================] - 0s 145us/step - loss: 0.2799 - acc: 0.8944\n",
            "Epoch 108/150\n",
            "303/303 [==============================] - 0s 114us/step - loss: 0.2794 - acc: 0.8944\n",
            "Epoch 109/150\n",
            "303/303 [==============================] - 0s 121us/step - loss: 0.2789 - acc: 0.8944\n",
            "Epoch 110/150\n",
            "303/303 [==============================] - 0s 103us/step - loss: 0.2781 - acc: 0.8977\n",
            "Epoch 111/150\n",
            "303/303 [==============================] - 0s 107us/step - loss: 0.2773 - acc: 0.8977\n",
            "Epoch 112/150\n",
            "303/303 [==============================] - 0s 108us/step - loss: 0.2767 - acc: 0.9010\n",
            "Epoch 113/150\n",
            "303/303 [==============================] - 0s 102us/step - loss: 0.2761 - acc: 0.9010\n",
            "Epoch 114/150\n",
            "303/303 [==============================] - 0s 106us/step - loss: 0.2755 - acc: 0.9010\n",
            "Epoch 115/150\n",
            "303/303 [==============================] - 0s 121us/step - loss: 0.2751 - acc: 0.9010\n",
            "Epoch 116/150\n",
            "303/303 [==============================] - 0s 107us/step - loss: 0.2743 - acc: 0.9043\n",
            "Epoch 117/150\n",
            "303/303 [==============================] - 0s 107us/step - loss: 0.2734 - acc: 0.9043\n",
            "Epoch 118/150\n",
            "303/303 [==============================] - 0s 103us/step - loss: 0.2730 - acc: 0.9043\n",
            "Epoch 119/150\n",
            "303/303 [==============================] - 0s 117us/step - loss: 0.2722 - acc: 0.9043\n",
            "Epoch 120/150\n",
            "303/303 [==============================] - 0s 125us/step - loss: 0.2718 - acc: 0.9010\n",
            "Epoch 121/150\n",
            "303/303 [==============================] - 0s 103us/step - loss: 0.2714 - acc: 0.8977\n",
            "Epoch 122/150\n",
            "303/303 [==============================] - 0s 122us/step - loss: 0.2706 - acc: 0.9010\n",
            "Epoch 123/150\n",
            "303/303 [==============================] - 0s 105us/step - loss: 0.2699 - acc: 0.9010\n",
            "Epoch 124/150\n",
            "303/303 [==============================] - 0s 112us/step - loss: 0.2693 - acc: 0.9010\n",
            "Epoch 125/150\n",
            "303/303 [==============================] - 0s 112us/step - loss: 0.2687 - acc: 0.9010\n",
            "Epoch 126/150\n",
            "303/303 [==============================] - 0s 115us/step - loss: 0.2678 - acc: 0.9043\n",
            "Epoch 127/150\n",
            "303/303 [==============================] - 0s 108us/step - loss: 0.2674 - acc: 0.9043\n",
            "Epoch 128/150\n",
            "303/303 [==============================] - 0s 108us/step - loss: 0.2667 - acc: 0.9043\n",
            "Epoch 129/150\n",
            "303/303 [==============================] - 0s 124us/step - loss: 0.2662 - acc: 0.9043\n",
            "Epoch 130/150\n",
            "303/303 [==============================] - 0s 109us/step - loss: 0.2657 - acc: 0.9043\n",
            "Epoch 131/150\n",
            "303/303 [==============================] - 0s 128us/step - loss: 0.2649 - acc: 0.9043\n",
            "Epoch 132/150\n",
            "303/303 [==============================] - 0s 108us/step - loss: 0.2644 - acc: 0.9043\n",
            "Epoch 133/150\n",
            "303/303 [==============================] - 0s 105us/step - loss: 0.2639 - acc: 0.9043\n",
            "Epoch 134/150\n",
            "303/303 [==============================] - 0s 104us/step - loss: 0.2633 - acc: 0.9043\n",
            "Epoch 135/150\n",
            "303/303 [==============================] - 0s 100us/step - loss: 0.2626 - acc: 0.9043\n",
            "Epoch 136/150\n",
            "303/303 [==============================] - 0s 117us/step - loss: 0.2621 - acc: 0.9043\n",
            "Epoch 137/150\n",
            "303/303 [==============================] - 0s 127us/step - loss: 0.2616 - acc: 0.9043\n",
            "Epoch 138/150\n",
            "303/303 [==============================] - 0s 118us/step - loss: 0.2609 - acc: 0.9043\n",
            "Epoch 139/150\n",
            "303/303 [==============================] - 0s 109us/step - loss: 0.2602 - acc: 0.9043\n",
            "Epoch 140/150\n",
            "303/303 [==============================] - 0s 107us/step - loss: 0.2597 - acc: 0.9043\n",
            "Epoch 141/150\n",
            "303/303 [==============================] - 0s 104us/step - loss: 0.2593 - acc: 0.9043\n",
            "Epoch 142/150\n",
            "303/303 [==============================] - 0s 103us/step - loss: 0.2589 - acc: 0.9043\n",
            "Epoch 143/150\n",
            "303/303 [==============================] - 0s 107us/step - loss: 0.2582 - acc: 0.9043\n",
            "Epoch 144/150\n",
            "303/303 [==============================] - 0s 109us/step - loss: 0.2578 - acc: 0.9076\n",
            "Epoch 145/150\n",
            "303/303 [==============================] - 0s 111us/step - loss: 0.2570 - acc: 0.9076\n",
            "Epoch 146/150\n",
            "303/303 [==============================] - 0s 106us/step - loss: 0.2565 - acc: 0.9109\n",
            "Epoch 147/150\n",
            "303/303 [==============================] - 0s 120us/step - loss: 0.2562 - acc: 0.9076\n",
            "Epoch 148/150\n",
            "303/303 [==============================] - 0s 118us/step - loss: 0.2555 - acc: 0.9076\n",
            "Epoch 149/150\n",
            "303/303 [==============================] - 0s 108us/step - loss: 0.2551 - acc: 0.9043\n",
            "Epoch 150/150\n",
            "303/303 [==============================] - 0s 113us/step - loss: 0.2545 - acc: 0.9076\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uyj4PQN1iyeJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 9217
        },
        "outputId": "a01716ec-4609-472e-adfc-d3d665e776b2"
      },
      "source": [
        "# Gridsearch on batch size\n",
        "\n",
        "# Function to create model, required for KerasClassifier\n",
        "def create_model():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(13, input_dim=13, activation='relu'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    # Compile model\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# create model\n",
        "model = KerasClassifier(build_fn=create_model, verbose=1)\n",
        "\n",
        "# define the grid search parameters\n",
        "batch_size = [20,40,60,80]\n",
        "epochs = [20]\n",
        "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
        "\n",
        "# Create Grid Search\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1)\n",
        "grid_result = grid.fit(X, y)\n",
        "\n",
        "# Report Results\n",
        "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
        "print()\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
            "  warnings.warn(CV_WARNING, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "202/202 [==============================] - 7s 34ms/step - loss: 0.6157 - acc: 0.6881\n",
            "Epoch 2/20\n",
            "202/202 [==============================] - 0s 160us/step - loss: 0.5938 - acc: 0.7079\n",
            "Epoch 3/20\n",
            "202/202 [==============================] - 0s 168us/step - loss: 0.5743 - acc: 0.7327\n",
            "Epoch 4/20\n",
            "202/202 [==============================] - 0s 208us/step - loss: 0.5546 - acc: 0.7376\n",
            "Epoch 5/20\n",
            "202/202 [==============================] - 0s 172us/step - loss: 0.5371 - acc: 0.7574\n",
            "Epoch 6/20\n",
            "202/202 [==============================] - 0s 172us/step - loss: 0.5199 - acc: 0.7772\n",
            "Epoch 7/20\n",
            "202/202 [==============================] - 0s 157us/step - loss: 0.5041 - acc: 0.7772\n",
            "Epoch 8/20\n",
            "202/202 [==============================] - 0s 168us/step - loss: 0.4894 - acc: 0.7871\n",
            "Epoch 9/20\n",
            "202/202 [==============================] - 0s 182us/step - loss: 0.4747 - acc: 0.7921\n",
            "Epoch 10/20\n",
            "202/202 [==============================] - 0s 163us/step - loss: 0.4610 - acc: 0.8069\n",
            "Epoch 11/20\n",
            "202/202 [==============================] - 0s 162us/step - loss: 0.4475 - acc: 0.8119\n",
            "Epoch 12/20\n",
            "202/202 [==============================] - 0s 170us/step - loss: 0.4358 - acc: 0.8119\n",
            "Epoch 13/20\n",
            "202/202 [==============================] - 0s 176us/step - loss: 0.4261 - acc: 0.8218\n",
            "Epoch 14/20\n",
            "202/202 [==============================] - 0s 161us/step - loss: 0.4160 - acc: 0.8218\n",
            "Epoch 15/20\n",
            "202/202 [==============================] - 0s 186us/step - loss: 0.4061 - acc: 0.8317\n",
            "Epoch 16/20\n",
            "202/202 [==============================] - 0s 177us/step - loss: 0.3977 - acc: 0.8317\n",
            "Epoch 17/20\n",
            "202/202 [==============================] - 0s 178us/step - loss: 0.3893 - acc: 0.8366\n",
            "Epoch 18/20\n",
            "202/202 [==============================] - 0s 165us/step - loss: 0.3818 - acc: 0.8515\n",
            "Epoch 19/20\n",
            "202/202 [==============================] - 0s 170us/step - loss: 0.3757 - acc: 0.8515\n",
            "Epoch 20/20\n",
            "202/202 [==============================] - 0s 164us/step - loss: 0.3692 - acc: 0.8465\n",
            "101/101 [==============================] - 3s 27ms/step\n",
            "Epoch 1/20\n",
            "202/202 [==============================] - 7s 32ms/step - loss: 1.2535 - acc: 0.3267\n",
            "Epoch 2/20\n",
            "202/202 [==============================] - 0s 161us/step - loss: 1.1822 - acc: 0.3465\n",
            "Epoch 3/20\n",
            "202/202 [==============================] - 0s 220us/step - loss: 1.1231 - acc: 0.3614\n",
            "Epoch 4/20\n",
            "202/202 [==============================] - 0s 168us/step - loss: 1.0682 - acc: 0.3713\n",
            "Epoch 5/20\n",
            "202/202 [==============================] - 0s 165us/step - loss: 1.0185 - acc: 0.3762\n",
            "Epoch 6/20\n",
            "202/202 [==============================] - 0s 177us/step - loss: 0.9719 - acc: 0.3861\n",
            "Epoch 7/20\n",
            "202/202 [==============================] - 0s 174us/step - loss: 0.9281 - acc: 0.4109\n",
            "Epoch 8/20\n",
            "202/202 [==============================] - 0s 170us/step - loss: 0.8879 - acc: 0.4158\n",
            "Epoch 9/20\n",
            "202/202 [==============================] - 0s 178us/step - loss: 0.8496 - acc: 0.4257\n",
            "Epoch 10/20\n",
            "202/202 [==============================] - 0s 158us/step - loss: 0.8163 - acc: 0.4554\n",
            "Epoch 11/20\n",
            "202/202 [==============================] - 0s 206us/step - loss: 0.7860 - acc: 0.4653\n",
            "Epoch 12/20\n",
            "202/202 [==============================] - 0s 169us/step - loss: 0.7582 - acc: 0.4752\n",
            "Epoch 13/20\n",
            "202/202 [==============================] - 0s 168us/step - loss: 0.7324 - acc: 0.5000\n",
            "Epoch 14/20\n",
            "202/202 [==============================] - 0s 170us/step - loss: 0.7088 - acc: 0.5347\n",
            "Epoch 15/20\n",
            "202/202 [==============================] - 0s 180us/step - loss: 0.6865 - acc: 0.5644\n",
            "Epoch 16/20\n",
            "202/202 [==============================] - 0s 170us/step - loss: 0.6662 - acc: 0.6040\n",
            "Epoch 17/20\n",
            "202/202 [==============================] - 0s 174us/step - loss: 0.6472 - acc: 0.6485\n",
            "Epoch 18/20\n",
            "202/202 [==============================] - 0s 168us/step - loss: 0.6288 - acc: 0.6683\n",
            "Epoch 19/20\n",
            "202/202 [==============================] - 0s 174us/step - loss: 0.6110 - acc: 0.6733\n",
            "Epoch 20/20\n",
            "202/202 [==============================] - 0s 166us/step - loss: 0.5967 - acc: 0.6832\n",
            "101/101 [==============================] - 3s 27ms/step\n",
            "Epoch 1/20\n",
            "202/202 [==============================] - 7s 33ms/step - loss: 0.4949 - acc: 0.8168\n",
            "Epoch 2/20\n",
            "202/202 [==============================] - 0s 163us/step - loss: 0.4640 - acc: 0.8465\n",
            "Epoch 3/20\n",
            "202/202 [==============================] - 0s 160us/step - loss: 0.4368 - acc: 0.8564\n",
            "Epoch 4/20\n",
            "202/202 [==============================] - 0s 162us/step - loss: 0.4143 - acc: 0.8663\n",
            "Epoch 5/20\n",
            "202/202 [==============================] - 0s 158us/step - loss: 0.3952 - acc: 0.8762\n",
            "Epoch 6/20\n",
            "202/202 [==============================] - 0s 166us/step - loss: 0.3797 - acc: 0.8762\n",
            "Epoch 7/20\n",
            "202/202 [==============================] - 0s 160us/step - loss: 0.3670 - acc: 0.8713\n",
            "Epoch 8/20\n",
            "202/202 [==============================] - 0s 172us/step - loss: 0.3559 - acc: 0.8812\n",
            "Epoch 9/20\n",
            "202/202 [==============================] - 0s 194us/step - loss: 0.3458 - acc: 0.8812\n",
            "Epoch 10/20\n",
            "202/202 [==============================] - 0s 173us/step - loss: 0.3375 - acc: 0.8812\n",
            "Epoch 11/20\n",
            "202/202 [==============================] - 0s 160us/step - loss: 0.3298 - acc: 0.8812\n",
            "Epoch 12/20\n",
            "202/202 [==============================] - 0s 200us/step - loss: 0.3229 - acc: 0.8762\n",
            "Epoch 13/20\n",
            "202/202 [==============================] - 0s 169us/step - loss: 0.3171 - acc: 0.8762\n",
            "Epoch 14/20\n",
            "202/202 [==============================] - 0s 157us/step - loss: 0.3111 - acc: 0.8812\n",
            "Epoch 15/20\n",
            "202/202 [==============================] - 0s 155us/step - loss: 0.3059 - acc: 0.8812\n",
            "Epoch 16/20\n",
            "202/202 [==============================] - 0s 159us/step - loss: 0.3017 - acc: 0.8812\n",
            "Epoch 17/20\n",
            "202/202 [==============================] - 0s 204us/step - loss: 0.2974 - acc: 0.8861\n",
            "Epoch 18/20\n",
            "202/202 [==============================] - 0s 175us/step - loss: 0.2940 - acc: 0.8861\n",
            "Epoch 19/20\n",
            "202/202 [==============================] - 0s 192us/step - loss: 0.2904 - acc: 0.8861\n",
            "Epoch 20/20\n",
            "202/202 [==============================] - 0s 190us/step - loss: 0.2867 - acc: 0.8911\n",
            "101/101 [==============================] - 3s 28ms/step\n",
            "Epoch 1/20\n",
            "202/202 [==============================] - 7s 33ms/step - loss: 0.7346 - acc: 0.5842\n",
            "Epoch 2/20\n",
            "202/202 [==============================] - 0s 112us/step - loss: 0.7058 - acc: 0.6188\n",
            "Epoch 3/20\n",
            "202/202 [==============================] - 0s 116us/step - loss: 0.6790 - acc: 0.6386\n",
            "Epoch 4/20\n",
            "202/202 [==============================] - 0s 115us/step - loss: 0.6552 - acc: 0.6485\n",
            "Epoch 5/20\n",
            "202/202 [==============================] - 0s 109us/step - loss: 0.6337 - acc: 0.6634\n",
            "Epoch 6/20\n",
            "202/202 [==============================] - 0s 105us/step - loss: 0.6155 - acc: 0.6832\n",
            "Epoch 7/20\n",
            "202/202 [==============================] - 0s 120us/step - loss: 0.5979 - acc: 0.6931\n",
            "Epoch 8/20\n",
            "202/202 [==============================] - 0s 103us/step - loss: 0.5815 - acc: 0.6980\n",
            "Epoch 9/20\n",
            "202/202 [==============================] - 0s 113us/step - loss: 0.5667 - acc: 0.6980\n",
            "Epoch 10/20\n",
            "202/202 [==============================] - 0s 125us/step - loss: 0.5519 - acc: 0.7129\n",
            "Epoch 11/20\n",
            "202/202 [==============================] - 0s 121us/step - loss: 0.5388 - acc: 0.7178\n",
            "Epoch 12/20\n",
            "202/202 [==============================] - 0s 126us/step - loss: 0.5270 - acc: 0.7277\n",
            "Epoch 13/20\n",
            "202/202 [==============================] - 0s 133us/step - loss: 0.5162 - acc: 0.7277\n",
            "Epoch 14/20\n",
            "202/202 [==============================] - 0s 115us/step - loss: 0.5072 - acc: 0.7277\n",
            "Epoch 15/20\n",
            "202/202 [==============================] - 0s 112us/step - loss: 0.4981 - acc: 0.7376\n",
            "Epoch 16/20\n",
            "202/202 [==============================] - 0s 111us/step - loss: 0.4895 - acc: 0.7475\n",
            "Epoch 17/20\n",
            "202/202 [==============================] - 0s 120us/step - loss: 0.4816 - acc: 0.7525\n",
            "Epoch 18/20\n",
            "202/202 [==============================] - 0s 108us/step - loss: 0.4731 - acc: 0.7673\n",
            "Epoch 19/20\n",
            "202/202 [==============================] - 0s 120us/step - loss: 0.4652 - acc: 0.7673\n",
            "Epoch 20/20\n",
            "202/202 [==============================] - 0s 98us/step - loss: 0.4580 - acc: 0.7723\n",
            "101/101 [==============================] - 3s 28ms/step\n",
            "Epoch 1/20\n",
            "202/202 [==============================] - 7s 33ms/step - loss: 0.6690 - acc: 0.6040\n",
            "Epoch 2/20\n",
            "202/202 [==============================] - 0s 115us/step - loss: 0.6534 - acc: 0.5990\n",
            "Epoch 3/20\n",
            "202/202 [==============================] - 0s 113us/step - loss: 0.6393 - acc: 0.6040\n",
            "Epoch 4/20\n",
            "202/202 [==============================] - 0s 106us/step - loss: 0.6247 - acc: 0.6287\n",
            "Epoch 5/20\n",
            "202/202 [==============================] - 0s 118us/step - loss: 0.6123 - acc: 0.6535\n",
            "Epoch 6/20\n",
            "202/202 [==============================] - 0s 109us/step - loss: 0.5999 - acc: 0.6634\n",
            "Epoch 7/20\n",
            "202/202 [==============================] - 0s 108us/step - loss: 0.5891 - acc: 0.6832\n",
            "Epoch 8/20\n",
            "202/202 [==============================] - 0s 110us/step - loss: 0.5786 - acc: 0.6931\n",
            "Epoch 9/20\n",
            "202/202 [==============================] - 0s 109us/step - loss: 0.5687 - acc: 0.7129\n",
            "Epoch 10/20\n",
            "202/202 [==============================] - 0s 114us/step - loss: 0.5585 - acc: 0.7178\n",
            "Epoch 11/20\n",
            "202/202 [==============================] - 0s 114us/step - loss: 0.5484 - acc: 0.7426\n",
            "Epoch 12/20\n",
            "202/202 [==============================] - 0s 129us/step - loss: 0.5392 - acc: 0.7525\n",
            "Epoch 13/20\n",
            "202/202 [==============================] - 0s 132us/step - loss: 0.5295 - acc: 0.7624\n",
            "Epoch 14/20\n",
            "202/202 [==============================] - 0s 114us/step - loss: 0.5208 - acc: 0.7723\n",
            "Epoch 15/20\n",
            "202/202 [==============================] - 0s 137us/step - loss: 0.5124 - acc: 0.7871\n",
            "Epoch 16/20\n",
            "202/202 [==============================] - 0s 122us/step - loss: 0.5050 - acc: 0.7970\n",
            "Epoch 17/20\n",
            "202/202 [==============================] - 0s 111us/step - loss: 0.4983 - acc: 0.8218\n",
            "Epoch 18/20\n",
            "202/202 [==============================] - 0s 112us/step - loss: 0.4917 - acc: 0.8168\n",
            "Epoch 19/20\n",
            "202/202 [==============================] - 0s 111us/step - loss: 0.4846 - acc: 0.8218\n",
            "Epoch 20/20\n",
            "202/202 [==============================] - 0s 104us/step - loss: 0.4774 - acc: 0.8267\n",
            "101/101 [==============================] - 3s 28ms/step\n",
            "Epoch 1/20\n",
            "202/202 [==============================] - 7s 33ms/step - loss: 0.9119 - acc: 0.5050\n",
            "Epoch 2/20\n",
            "202/202 [==============================] - 0s 116us/step - loss: 0.8687 - acc: 0.5347\n",
            "Epoch 3/20\n",
            "202/202 [==============================] - 0s 103us/step - loss: 0.8310 - acc: 0.5446\n",
            "Epoch 4/20\n",
            "202/202 [==============================] - 0s 111us/step - loss: 0.7946 - acc: 0.5594\n",
            "Epoch 5/20\n",
            "202/202 [==============================] - 0s 114us/step - loss: 0.7610 - acc: 0.5990\n",
            "Epoch 6/20\n",
            "202/202 [==============================] - 0s 105us/step - loss: 0.7306 - acc: 0.6089\n",
            "Epoch 7/20\n",
            "202/202 [==============================] - 0s 109us/step - loss: 0.7025 - acc: 0.6238\n",
            "Epoch 8/20\n",
            "202/202 [==============================] - 0s 104us/step - loss: 0.6771 - acc: 0.6386\n",
            "Epoch 9/20\n",
            "202/202 [==============================] - 0s 118us/step - loss: 0.6524 - acc: 0.6436\n",
            "Epoch 10/20\n",
            "202/202 [==============================] - 0s 110us/step - loss: 0.6269 - acc: 0.6535\n",
            "Epoch 11/20\n",
            "202/202 [==============================] - 0s 122us/step - loss: 0.6067 - acc: 0.6584\n",
            "Epoch 12/20\n",
            "202/202 [==============================] - 0s 106us/step - loss: 0.5891 - acc: 0.6832\n",
            "Epoch 13/20\n",
            "202/202 [==============================] - 0s 109us/step - loss: 0.5719 - acc: 0.6931\n",
            "Epoch 14/20\n",
            "202/202 [==============================] - 0s 130us/step - loss: 0.5544 - acc: 0.7079\n",
            "Epoch 15/20\n",
            "202/202 [==============================] - 0s 142us/step - loss: 0.5370 - acc: 0.7129\n",
            "Epoch 16/20\n",
            "202/202 [==============================] - 0s 139us/step - loss: 0.5213 - acc: 0.7277\n",
            "Epoch 17/20\n",
            "202/202 [==============================] - 0s 112us/step - loss: 0.5058 - acc: 0.7426\n",
            "Epoch 18/20\n",
            "202/202 [==============================] - 0s 146us/step - loss: 0.4920 - acc: 0.7525\n",
            "Epoch 19/20\n",
            "202/202 [==============================] - 0s 133us/step - loss: 0.4786 - acc: 0.7723\n",
            "Epoch 20/20\n",
            "202/202 [==============================] - 0s 151us/step - loss: 0.4671 - acc: 0.7772\n",
            "101/101 [==============================] - 3s 28ms/step\n",
            "Epoch 1/20\n",
            "202/202 [==============================] - 7s 34ms/step - loss: 0.6562 - acc: 0.6881\n",
            "Epoch 2/20\n",
            "202/202 [==============================] - 0s 100us/step - loss: 0.6409 - acc: 0.6881\n",
            "Epoch 3/20\n",
            "202/202 [==============================] - 0s 89us/step - loss: 0.6251 - acc: 0.6980\n",
            "Epoch 4/20\n",
            "202/202 [==============================] - 0s 91us/step - loss: 0.6100 - acc: 0.6980\n",
            "Epoch 5/20\n",
            "202/202 [==============================] - 0s 92us/step - loss: 0.5965 - acc: 0.6980\n",
            "Epoch 6/20\n",
            "202/202 [==============================] - 0s 113us/step - loss: 0.5821 - acc: 0.6881\n",
            "Epoch 7/20\n",
            "202/202 [==============================] - 0s 92us/step - loss: 0.5706 - acc: 0.6881\n",
            "Epoch 8/20\n",
            "202/202 [==============================] - 0s 90us/step - loss: 0.5572 - acc: 0.6881\n",
            "Epoch 9/20\n",
            "202/202 [==============================] - 0s 93us/step - loss: 0.5461 - acc: 0.6980\n",
            "Epoch 10/20\n",
            "202/202 [==============================] - 0s 95us/step - loss: 0.5350 - acc: 0.7030\n",
            "Epoch 11/20\n",
            "202/202 [==============================] - 0s 116us/step - loss: 0.5244 - acc: 0.7079\n",
            "Epoch 12/20\n",
            "202/202 [==============================] - 0s 113us/step - loss: 0.5153 - acc: 0.7129\n",
            "Epoch 13/20\n",
            "202/202 [==============================] - 0s 104us/step - loss: 0.5059 - acc: 0.7079\n",
            "Epoch 14/20\n",
            "202/202 [==============================] - 0s 99us/step - loss: 0.4975 - acc: 0.7228\n",
            "Epoch 15/20\n",
            "202/202 [==============================] - 0s 96us/step - loss: 0.4891 - acc: 0.7376\n",
            "Epoch 16/20\n",
            "202/202 [==============================] - 0s 103us/step - loss: 0.4822 - acc: 0.7574\n",
            "Epoch 17/20\n",
            "202/202 [==============================] - 0s 105us/step - loss: 0.4751 - acc: 0.7624\n",
            "Epoch 18/20\n",
            "202/202 [==============================] - 0s 114us/step - loss: 0.4676 - acc: 0.7723\n",
            "Epoch 19/20\n",
            "202/202 [==============================] - 0s 91us/step - loss: 0.4618 - acc: 0.7772\n",
            "Epoch 20/20\n",
            "202/202 [==============================] - 0s 102us/step - loss: 0.4553 - acc: 0.7871\n",
            "101/101 [==============================] - 3s 29ms/step\n",
            "Epoch 1/20\n",
            "202/202 [==============================] - 7s 34ms/step - loss: 0.7844 - acc: 0.4851\n",
            "Epoch 2/20\n",
            "202/202 [==============================] - 0s 104us/step - loss: 0.7683 - acc: 0.5000\n",
            "Epoch 3/20\n",
            "202/202 [==============================] - 0s 95us/step - loss: 0.7520 - acc: 0.5248\n",
            "Epoch 4/20\n",
            "202/202 [==============================] - 0s 91us/step - loss: 0.7364 - acc: 0.5297\n",
            "Epoch 5/20\n",
            "202/202 [==============================] - 0s 91us/step - loss: 0.7209 - acc: 0.5495\n",
            "Epoch 6/20\n",
            "202/202 [==============================] - 0s 93us/step - loss: 0.7060 - acc: 0.5545\n",
            "Epoch 7/20\n",
            "202/202 [==============================] - 0s 102us/step - loss: 0.6926 - acc: 0.5693\n",
            "Epoch 8/20\n",
            "202/202 [==============================] - 0s 95us/step - loss: 0.6788 - acc: 0.5792\n",
            "Epoch 9/20\n",
            "202/202 [==============================] - 0s 95us/step - loss: 0.6665 - acc: 0.5842\n",
            "Epoch 10/20\n",
            "202/202 [==============================] - 0s 88us/step - loss: 0.6544 - acc: 0.5990\n",
            "Epoch 11/20\n",
            "202/202 [==============================] - 0s 107us/step - loss: 0.6428 - acc: 0.6089\n",
            "Epoch 12/20\n",
            "202/202 [==============================] - 0s 98us/step - loss: 0.6321 - acc: 0.6188\n",
            "Epoch 13/20\n",
            "202/202 [==============================] - 0s 89us/step - loss: 0.6216 - acc: 0.6238\n",
            "Epoch 14/20\n",
            "202/202 [==============================] - 0s 95us/step - loss: 0.6116 - acc: 0.6485\n",
            "Epoch 15/20\n",
            "202/202 [==============================] - 0s 92us/step - loss: 0.6020 - acc: 0.6535\n",
            "Epoch 16/20\n",
            "202/202 [==============================] - 0s 98us/step - loss: 0.5923 - acc: 0.6535\n",
            "Epoch 17/20\n",
            "202/202 [==============================] - 0s 94us/step - loss: 0.5837 - acc: 0.6683\n",
            "Epoch 18/20\n",
            "202/202 [==============================] - 0s 93us/step - loss: 0.5755 - acc: 0.6832\n",
            "Epoch 19/20\n",
            "202/202 [==============================] - 0s 100us/step - loss: 0.5672 - acc: 0.6832\n",
            "Epoch 20/20\n",
            "202/202 [==============================] - 0s 109us/step - loss: 0.5594 - acc: 0.6931\n",
            "101/101 [==============================] - 3s 30ms/step\n",
            "Epoch 1/20\n",
            "202/202 [==============================] - 7s 35ms/step - loss: 0.7979 - acc: 0.4257\n",
            "Epoch 2/20\n",
            "202/202 [==============================] - 0s 99us/step - loss: 0.7783 - acc: 0.4505\n",
            "Epoch 3/20\n",
            "202/202 [==============================] - 0s 87us/step - loss: 0.7560 - acc: 0.4752\n",
            "Epoch 4/20\n",
            "202/202 [==============================] - 0s 86us/step - loss: 0.7351 - acc: 0.5149\n",
            "Epoch 5/20\n",
            "202/202 [==============================] - 0s 88us/step - loss: 0.7156 - acc: 0.5396\n",
            "Epoch 6/20\n",
            "202/202 [==============================] - 0s 93us/step - loss: 0.6959 - acc: 0.5792\n",
            "Epoch 7/20\n",
            "202/202 [==============================] - 0s 90us/step - loss: 0.6767 - acc: 0.6188\n",
            "Epoch 8/20\n",
            "202/202 [==============================] - 0s 85us/step - loss: 0.6588 - acc: 0.6485\n",
            "Epoch 9/20\n",
            "202/202 [==============================] - 0s 95us/step - loss: 0.6415 - acc: 0.6782\n",
            "Epoch 10/20\n",
            "202/202 [==============================] - 0s 96us/step - loss: 0.6242 - acc: 0.7079\n",
            "Epoch 11/20\n",
            "202/202 [==============================] - 0s 107us/step - loss: 0.6086 - acc: 0.7228\n",
            "Epoch 12/20\n",
            "202/202 [==============================] - 0s 104us/step - loss: 0.5933 - acc: 0.7277\n",
            "Epoch 13/20\n",
            "202/202 [==============================] - 0s 93us/step - loss: 0.5788 - acc: 0.7475\n",
            "Epoch 14/20\n",
            "202/202 [==============================] - 0s 96us/step - loss: 0.5646 - acc: 0.7822\n",
            "Epoch 15/20\n",
            "202/202 [==============================] - 0s 100us/step - loss: 0.5516 - acc: 0.8020\n",
            "Epoch 16/20\n",
            "202/202 [==============================] - 0s 108us/step - loss: 0.5391 - acc: 0.8119\n",
            "Epoch 17/20\n",
            "202/202 [==============================] - 0s 133us/step - loss: 0.5272 - acc: 0.8020\n",
            "Epoch 18/20\n",
            "202/202 [==============================] - 0s 109us/step - loss: 0.5155 - acc: 0.8119\n",
            "Epoch 19/20\n",
            "202/202 [==============================] - 0s 107us/step - loss: 0.5052 - acc: 0.8218\n",
            "Epoch 20/20\n",
            "202/202 [==============================] - 0s 102us/step - loss: 0.4940 - acc: 0.8317\n",
            "101/101 [==============================] - 3s 29ms/step\n",
            "Epoch 1/20\n",
            "202/202 [==============================] - 7s 34ms/step - loss: 0.7324 - acc: 0.5842\n",
            "Epoch 2/20\n",
            "202/202 [==============================] - 0s 81us/step - loss: 0.7159 - acc: 0.5990\n",
            "Epoch 3/20\n",
            "202/202 [==============================] - 0s 82us/step - loss: 0.6990 - acc: 0.6089\n",
            "Epoch 4/20\n",
            "202/202 [==============================] - 0s 85us/step - loss: 0.6823 - acc: 0.6188\n",
            "Epoch 5/20\n",
            "202/202 [==============================] - 0s 110us/step - loss: 0.6664 - acc: 0.6287\n",
            "Epoch 6/20\n",
            "202/202 [==============================] - 0s 86us/step - loss: 0.6508 - acc: 0.6386\n",
            "Epoch 7/20\n",
            "202/202 [==============================] - 0s 82us/step - loss: 0.6366 - acc: 0.6436\n",
            "Epoch 8/20\n",
            "202/202 [==============================] - 0s 90us/step - loss: 0.6225 - acc: 0.6485\n",
            "Epoch 9/20\n",
            "202/202 [==============================] - 0s 80us/step - loss: 0.6094 - acc: 0.6584\n",
            "Epoch 10/20\n",
            "202/202 [==============================] - 0s 87us/step - loss: 0.5972 - acc: 0.6584\n",
            "Epoch 11/20\n",
            "202/202 [==============================] - 0s 91us/step - loss: 0.5858 - acc: 0.6683\n",
            "Epoch 12/20\n",
            "202/202 [==============================] - 0s 82us/step - loss: 0.5745 - acc: 0.6881\n",
            "Epoch 13/20\n",
            "202/202 [==============================] - 0s 97us/step - loss: 0.5647 - acc: 0.6832\n",
            "Epoch 14/20\n",
            "202/202 [==============================] - 0s 92us/step - loss: 0.5547 - acc: 0.7079\n",
            "Epoch 15/20\n",
            "202/202 [==============================] - 0s 91us/step - loss: 0.5454 - acc: 0.7228\n",
            "Epoch 16/20\n",
            "202/202 [==============================] - 0s 95us/step - loss: 0.5370 - acc: 0.7376\n",
            "Epoch 17/20\n",
            "202/202 [==============================] - 0s 104us/step - loss: 0.5290 - acc: 0.7475\n",
            "Epoch 18/20\n",
            "202/202 [==============================] - 0s 97us/step - loss: 0.5210 - acc: 0.7475\n",
            "Epoch 19/20\n",
            "202/202 [==============================] - 0s 90us/step - loss: 0.5140 - acc: 0.7426\n",
            "Epoch 20/20\n",
            "202/202 [==============================] - 0s 89us/step - loss: 0.5071 - acc: 0.7426\n",
            "101/101 [==============================] - 3s 29ms/step\n",
            "Epoch 1/20\n",
            "202/202 [==============================] - 7s 35ms/step - loss: 0.7830 - acc: 0.4653\n",
            "Epoch 2/20\n",
            "202/202 [==============================] - 0s 69us/step - loss: 0.7676 - acc: 0.4802\n",
            "Epoch 3/20\n",
            "202/202 [==============================] - 0s 76us/step - loss: 0.7519 - acc: 0.4901\n",
            "Epoch 4/20\n",
            "202/202 [==============================] - 0s 78us/step - loss: 0.7366 - acc: 0.5050\n",
            "Epoch 5/20\n",
            "202/202 [==============================] - 0s 84us/step - loss: 0.7211 - acc: 0.5198\n",
            "Epoch 6/20\n",
            "202/202 [==============================] - 0s 80us/step - loss: 0.7067 - acc: 0.5297\n",
            "Epoch 7/20\n",
            "202/202 [==============================] - 0s 85us/step - loss: 0.6921 - acc: 0.5396\n",
            "Epoch 8/20\n",
            "202/202 [==============================] - 0s 74us/step - loss: 0.6778 - acc: 0.5594\n",
            "Epoch 9/20\n",
            "202/202 [==============================] - 0s 81us/step - loss: 0.6652 - acc: 0.5693\n",
            "Epoch 10/20\n",
            "202/202 [==============================] - 0s 79us/step - loss: 0.6523 - acc: 0.5842\n",
            "Epoch 11/20\n",
            "202/202 [==============================] - 0s 67us/step - loss: 0.6405 - acc: 0.5990\n",
            "Epoch 12/20\n",
            "202/202 [==============================] - 0s 105us/step - loss: 0.6292 - acc: 0.6040\n",
            "Epoch 13/20\n",
            "202/202 [==============================] - 0s 80us/step - loss: 0.6175 - acc: 0.6386\n",
            "Epoch 14/20\n",
            "202/202 [==============================] - 0s 117us/step - loss: 0.6074 - acc: 0.6634\n",
            "Epoch 15/20\n",
            "202/202 [==============================] - 0s 93us/step - loss: 0.5970 - acc: 0.6782\n",
            "Epoch 16/20\n",
            "202/202 [==============================] - 0s 107us/step - loss: 0.5875 - acc: 0.6881\n",
            "Epoch 17/20\n",
            "202/202 [==============================] - 0s 85us/step - loss: 0.5778 - acc: 0.6931\n",
            "Epoch 18/20\n",
            "202/202 [==============================] - 0s 95us/step - loss: 0.5689 - acc: 0.7178\n",
            "Epoch 19/20\n",
            "202/202 [==============================] - 0s 114us/step - loss: 0.5601 - acc: 0.7277\n",
            "Epoch 20/20\n",
            "202/202 [==============================] - 0s 86us/step - loss: 0.5519 - acc: 0.7475\n",
            "101/101 [==============================] - 3s 30ms/step\n",
            "Epoch 1/20\n",
            "202/202 [==============================] - 7s 35ms/step - loss: 0.9990 - acc: 0.2376\n",
            "Epoch 2/20\n",
            "202/202 [==============================] - 0s 77us/step - loss: 0.9765 - acc: 0.2574\n",
            "Epoch 3/20\n",
            "202/202 [==============================] - 0s 81us/step - loss: 0.9528 - acc: 0.2673\n",
            "Epoch 4/20\n",
            "202/202 [==============================] - 0s 85us/step - loss: 0.9289 - acc: 0.2822\n",
            "Epoch 5/20\n",
            "202/202 [==============================] - 0s 80us/step - loss: 0.9053 - acc: 0.3069\n",
            "Epoch 6/20\n",
            "202/202 [==============================] - 0s 80us/step - loss: 0.8829 - acc: 0.3218\n",
            "Epoch 7/20\n",
            "202/202 [==============================] - 0s 83us/step - loss: 0.8608 - acc: 0.3564\n",
            "Epoch 8/20\n",
            "202/202 [==============================] - 0s 79us/step - loss: 0.8394 - acc: 0.3762\n",
            "Epoch 9/20\n",
            "202/202 [==============================] - 0s 80us/step - loss: 0.8192 - acc: 0.4109\n",
            "Epoch 10/20\n",
            "202/202 [==============================] - 0s 81us/step - loss: 0.7996 - acc: 0.4406\n",
            "Epoch 11/20\n",
            "202/202 [==============================] - 0s 78us/step - loss: 0.7806 - acc: 0.4703\n",
            "Epoch 12/20\n",
            "202/202 [==============================] - 0s 81us/step - loss: 0.7625 - acc: 0.4901\n",
            "Epoch 13/20\n",
            "202/202 [==============================] - 0s 93us/step - loss: 0.7449 - acc: 0.5050\n",
            "Epoch 14/20\n",
            "202/202 [==============================] - 0s 92us/step - loss: 0.7280 - acc: 0.5446\n",
            "Epoch 15/20\n",
            "202/202 [==============================] - 0s 80us/step - loss: 0.7114 - acc: 0.5644\n",
            "Epoch 16/20\n",
            "202/202 [==============================] - 0s 93us/step - loss: 0.6954 - acc: 0.5941\n",
            "Epoch 17/20\n",
            "202/202 [==============================] - 0s 94us/step - loss: 0.6797 - acc: 0.6040\n",
            "Epoch 18/20\n",
            "202/202 [==============================] - 0s 86us/step - loss: 0.6647 - acc: 0.6287\n",
            "Epoch 19/20\n",
            "202/202 [==============================] - 0s 78us/step - loss: 0.6500 - acc: 0.6782\n",
            "Epoch 20/20\n",
            "202/202 [==============================] - 0s 100us/step - loss: 0.6360 - acc: 0.7030\n",
            "101/101 [==============================] - 3s 30ms/step\n",
            "Epoch 1/20\n",
            "303/303 [==============================] - 7s 23ms/step - loss: 0.8114 - acc: 0.4092\n",
            "Epoch 2/20\n",
            "303/303 [==============================] - 0s 102us/step - loss: 0.7778 - acc: 0.4521\n",
            "Epoch 3/20\n",
            "303/303 [==============================] - 0s 104us/step - loss: 0.7446 - acc: 0.5083\n",
            "Epoch 4/20\n",
            "303/303 [==============================] - 0s 99us/step - loss: 0.7159 - acc: 0.5479\n",
            "Epoch 5/20\n",
            "303/303 [==============================] - 0s 103us/step - loss: 0.6875 - acc: 0.5743\n",
            "Epoch 6/20\n",
            "303/303 [==============================] - 0s 101us/step - loss: 0.6627 - acc: 0.5842\n",
            "Epoch 7/20\n",
            "303/303 [==============================] - 0s 96us/step - loss: 0.6404 - acc: 0.6238\n",
            "Epoch 8/20\n",
            "303/303 [==============================] - 0s 101us/step - loss: 0.6182 - acc: 0.6568\n",
            "Epoch 9/20\n",
            "303/303 [==============================] - 0s 111us/step - loss: 0.5991 - acc: 0.7030\n",
            "Epoch 10/20\n",
            "303/303 [==============================] - 0s 111us/step - loss: 0.5804 - acc: 0.7360\n",
            "Epoch 11/20\n",
            "303/303 [==============================] - 0s 105us/step - loss: 0.5640 - acc: 0.7492\n",
            "Epoch 12/20\n",
            "303/303 [==============================] - 0s 103us/step - loss: 0.5479 - acc: 0.7558\n",
            "Epoch 13/20\n",
            "303/303 [==============================] - 0s 97us/step - loss: 0.5338 - acc: 0.7690\n",
            "Epoch 14/20\n",
            "303/303 [==============================] - 0s 98us/step - loss: 0.5202 - acc: 0.7921\n",
            "Epoch 15/20\n",
            "303/303 [==============================] - 0s 123us/step - loss: 0.5081 - acc: 0.7921\n",
            "Epoch 16/20\n",
            "303/303 [==============================] - 0s 102us/step - loss: 0.4967 - acc: 0.7888\n",
            "Epoch 17/20\n",
            "303/303 [==============================] - 0s 118us/step - loss: 0.4858 - acc: 0.7954\n",
            "Epoch 18/20\n",
            "303/303 [==============================] - 0s 109us/step - loss: 0.4764 - acc: 0.7987\n",
            "Epoch 19/20\n",
            "303/303 [==============================] - 0s 113us/step - loss: 0.4673 - acc: 0.8020\n",
            "Epoch 20/20\n",
            "303/303 [==============================] - 0s 110us/step - loss: 0.4594 - acc: 0.8053\n",
            "Best: 0.6864686566020789 using {'batch_size': 40, 'epochs': 20}\n",
            "\n",
            "Means: 0.603960400760764, Stdev: 0.07796048089537798 with: {'batch_size': 20, 'epochs': 20}\n",
            "Means: 0.6864686566020789, Stdev: 0.0687546705316214 with: {'batch_size': 40, 'epochs': 20}\n",
            "Means: 0.6600660082727375, Stdev: 0.07640817623637769 with: {'batch_size': 60, 'epochs': 20}\n",
            "Means: 0.5742574332177443, Stdev: 0.10129379866065591 with: {'batch_size': 80, 'epochs': 20}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uY1wcxaXhRU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 48181
        },
        "outputId": "3259f802-2aac-4dac-f951-4d310c17df19"
      },
      "source": [
        "# Gridsearch on epochs\n",
        "\n",
        "# Function to create model, required for KerasClassifier\n",
        "def create_model():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(12, input_dim=13, activation='relu'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    # Compile model\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# create model\n",
        "model = KerasClassifier(build_fn=create_model, verbose=1)\n",
        "\n",
        "# define the grid search parameters\n",
        "batch_size = [40]\n",
        "epochs = [10,20,40,60,80,100,150]\n",
        "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
        "\n",
        "# Create Grid Search\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1)\n",
        "grid_result = grid.fit(X, y)\n",
        "\n",
        "# Report Results\n",
        "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
        "print()\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\")\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
            "  warnings.warn(CV_WARNING, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "202/202 [==============================] - 1s 6ms/step - loss: 1.0955 - acc: 0.3564\n",
            "Epoch 2/10\n",
            "202/202 [==============================] - 0s 67us/step - loss: 1.0598 - acc: 0.3663\n",
            "Epoch 3/10\n",
            "202/202 [==============================] - 0s 70us/step - loss: 1.0228 - acc: 0.3713\n",
            "Epoch 4/10\n",
            "202/202 [==============================] - 0s 71us/step - loss: 0.9887 - acc: 0.3762\n",
            "Epoch 5/10\n",
            "202/202 [==============================] - 0s 64us/step - loss: 0.9565 - acc: 0.3911\n",
            "Epoch 6/10\n",
            "202/202 [==============================] - 0s 67us/step - loss: 0.9259 - acc: 0.4158\n",
            "Epoch 7/10\n",
            "202/202 [==============================] - 0s 60us/step - loss: 0.8994 - acc: 0.4653\n",
            "Epoch 8/10\n",
            "202/202 [==============================] - 0s 64us/step - loss: 0.8744 - acc: 0.4851\n",
            "Epoch 9/10\n",
            "202/202 [==============================] - 0s 61us/step - loss: 0.8488 - acc: 0.4901\n",
            "Epoch 10/10\n",
            "202/202 [==============================] - 0s 70us/step - loss: 0.8266 - acc: 0.5000\n",
            "101/101 [==============================] - 0s 4ms/step\n",
            "Epoch 1/10\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.7724 - acc: 0.5248\n",
            "Epoch 2/10\n",
            "202/202 [==============================] - 0s 77us/step - loss: 0.7490 - acc: 0.5396\n",
            "Epoch 3/10\n",
            "202/202 [==============================] - 0s 64us/step - loss: 0.7291 - acc: 0.5495\n",
            "Epoch 4/10\n",
            "202/202 [==============================] - 0s 78us/step - loss: 0.7102 - acc: 0.5594\n",
            "Epoch 5/10\n",
            "202/202 [==============================] - 0s 61us/step - loss: 0.6920 - acc: 0.5644\n",
            "Epoch 6/10\n",
            "202/202 [==============================] - 0s 72us/step - loss: 0.6759 - acc: 0.5891\n",
            "Epoch 7/10\n",
            "202/202 [==============================] - 0s 69us/step - loss: 0.6606 - acc: 0.6188\n",
            "Epoch 8/10\n",
            "202/202 [==============================] - 0s 76us/step - loss: 0.6461 - acc: 0.6188\n",
            "Epoch 9/10\n",
            "202/202 [==============================] - 0s 67us/step - loss: 0.6325 - acc: 0.6485\n",
            "Epoch 10/10\n",
            "202/202 [==============================] - 0s 77us/step - loss: 0.6193 - acc: 0.6584\n",
            "101/101 [==============================] - 0s 4ms/step\n",
            "Epoch 1/10\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.8674 - acc: 0.3911\n",
            "Epoch 2/10\n",
            "202/202 [==============================] - 0s 72us/step - loss: 0.8236 - acc: 0.4455\n",
            "Epoch 3/10\n",
            "202/202 [==============================] - 0s 68us/step - loss: 0.7855 - acc: 0.4554\n",
            "Epoch 4/10\n",
            "202/202 [==============================] - 0s 71us/step - loss: 0.7482 - acc: 0.5149\n",
            "Epoch 5/10\n",
            "202/202 [==============================] - 0s 67us/step - loss: 0.7184 - acc: 0.5495\n",
            "Epoch 6/10\n",
            "202/202 [==============================] - 0s 69us/step - loss: 0.6897 - acc: 0.5941\n",
            "Epoch 7/10\n",
            "202/202 [==============================] - 0s 70us/step - loss: 0.6622 - acc: 0.6287\n",
            "Epoch 8/10\n",
            "202/202 [==============================] - 0s 74us/step - loss: 0.6375 - acc: 0.6584\n",
            "Epoch 9/10\n",
            "202/202 [==============================] - 0s 68us/step - loss: 0.6131 - acc: 0.6881\n",
            "Epoch 10/10\n",
            "202/202 [==============================] - 0s 72us/step - loss: 0.5918 - acc: 0.7030\n",
            "101/101 [==============================] - 0s 4ms/step\n",
            "Epoch 1/20\n",
            "202/202 [==============================] - 1s 6ms/step - loss: 0.6939 - acc: 0.5545\n",
            "Epoch 2/20\n",
            "202/202 [==============================] - 0s 77us/step - loss: 0.6709 - acc: 0.5743\n",
            "Epoch 3/20\n",
            "202/202 [==============================] - 0s 65us/step - loss: 0.6494 - acc: 0.6040\n",
            "Epoch 4/20\n",
            "202/202 [==============================] - 0s 68us/step - loss: 0.6307 - acc: 0.6287\n",
            "Epoch 5/20\n",
            "202/202 [==============================] - 0s 70us/step - loss: 0.6133 - acc: 0.6634\n",
            "Epoch 6/20\n",
            "202/202 [==============================] - 0s 68us/step - loss: 0.5976 - acc: 0.6832\n",
            "Epoch 7/20\n",
            "202/202 [==============================] - 0s 68us/step - loss: 0.5824 - acc: 0.7178\n",
            "Epoch 8/20\n",
            "202/202 [==============================] - 0s 70us/step - loss: 0.5681 - acc: 0.7525\n",
            "Epoch 9/20\n",
            "202/202 [==============================] - 0s 65us/step - loss: 0.5546 - acc: 0.7574\n",
            "Epoch 10/20\n",
            "202/202 [==============================] - 0s 68us/step - loss: 0.5425 - acc: 0.7871\n",
            "Epoch 11/20\n",
            "202/202 [==============================] - 0s 70us/step - loss: 0.5315 - acc: 0.8069\n",
            "Epoch 12/20\n",
            "202/202 [==============================] - 0s 63us/step - loss: 0.5218 - acc: 0.8020\n",
            "Epoch 13/20\n",
            "202/202 [==============================] - 0s 68us/step - loss: 0.5123 - acc: 0.8020\n",
            "Epoch 14/20\n",
            "202/202 [==============================] - 0s 69us/step - loss: 0.5030 - acc: 0.8218\n",
            "Epoch 15/20\n",
            "202/202 [==============================] - 0s 71us/step - loss: 0.4940 - acc: 0.8218\n",
            "Epoch 16/20\n",
            "202/202 [==============================] - 0s 75us/step - loss: 0.4857 - acc: 0.8267\n",
            "Epoch 17/20\n",
            "202/202 [==============================] - 0s 72us/step - loss: 0.4776 - acc: 0.8267\n",
            "Epoch 18/20\n",
            "202/202 [==============================] - 0s 90us/step - loss: 0.4699 - acc: 0.8366\n",
            "Epoch 19/20\n",
            "202/202 [==============================] - 0s 67us/step - loss: 0.4624 - acc: 0.8416\n",
            "Epoch 20/20\n",
            "202/202 [==============================] - 0s 61us/step - loss: 0.4550 - acc: 0.8465\n",
            "101/101 [==============================] - 0s 4ms/step\n",
            "Epoch 1/20\n",
            "202/202 [==============================] - 1s 6ms/step - loss: 0.8015 - acc: 0.5050\n",
            "Epoch 2/20\n",
            "202/202 [==============================] - 0s 85us/step - loss: 0.7756 - acc: 0.5347\n",
            "Epoch 3/20\n",
            "202/202 [==============================] - 0s 74us/step - loss: 0.7497 - acc: 0.5545\n",
            "Epoch 4/20\n",
            "202/202 [==============================] - 0s 75us/step - loss: 0.7267 - acc: 0.5842\n",
            "Epoch 5/20\n",
            "202/202 [==============================] - 0s 68us/step - loss: 0.7061 - acc: 0.6089\n",
            "Epoch 6/20\n",
            "202/202 [==============================] - 0s 74us/step - loss: 0.6880 - acc: 0.6238\n",
            "Epoch 7/20\n",
            "202/202 [==============================] - 0s 75us/step - loss: 0.6716 - acc: 0.6337\n",
            "Epoch 8/20\n",
            "202/202 [==============================] - 0s 68us/step - loss: 0.6562 - acc: 0.6634\n",
            "Epoch 9/20\n",
            "202/202 [==============================] - 0s 65us/step - loss: 0.6408 - acc: 0.6634\n",
            "Epoch 10/20\n",
            "202/202 [==============================] - 0s 67us/step - loss: 0.6269 - acc: 0.6832\n",
            "Epoch 11/20\n",
            "202/202 [==============================] - 0s 75us/step - loss: 0.6134 - acc: 0.7079\n",
            "Epoch 12/20\n",
            "202/202 [==============================] - 0s 71us/step - loss: 0.6001 - acc: 0.7228\n",
            "Epoch 13/20\n",
            "202/202 [==============================] - 0s 76us/step - loss: 0.5872 - acc: 0.7376\n",
            "Epoch 14/20\n",
            "202/202 [==============================] - 0s 69us/step - loss: 0.5750 - acc: 0.7525\n",
            "Epoch 15/20\n",
            "202/202 [==============================] - 0s 81us/step - loss: 0.5630 - acc: 0.7574\n",
            "Epoch 16/20\n",
            "202/202 [==============================] - 0s 72us/step - loss: 0.5510 - acc: 0.7673\n",
            "Epoch 17/20\n",
            "202/202 [==============================] - 0s 71us/step - loss: 0.5402 - acc: 0.7723\n",
            "Epoch 18/20\n",
            "202/202 [==============================] - 0s 70us/step - loss: 0.5297 - acc: 0.7822\n",
            "Epoch 19/20\n",
            "202/202 [==============================] - 0s 74us/step - loss: 0.5200 - acc: 0.7822\n",
            "Epoch 20/20\n",
            "202/202 [==============================] - 0s 67us/step - loss: 0.5112 - acc: 0.7772\n",
            "101/101 [==============================] - 0s 5ms/step\n",
            "Epoch 1/20\n",
            "202/202 [==============================] - 1s 6ms/step - loss: 0.9476 - acc: 0.3515\n",
            "Epoch 2/20\n",
            "202/202 [==============================] - 0s 80us/step - loss: 0.9133 - acc: 0.3911\n",
            "Epoch 3/20\n",
            "202/202 [==============================] - 0s 60us/step - loss: 0.8802 - acc: 0.4208\n",
            "Epoch 4/20\n",
            "202/202 [==============================] - 0s 74us/step - loss: 0.8503 - acc: 0.4505\n",
            "Epoch 5/20\n",
            "202/202 [==============================] - 0s 70us/step - loss: 0.8215 - acc: 0.4653\n",
            "Epoch 6/20\n",
            "202/202 [==============================] - 0s 69us/step - loss: 0.7956 - acc: 0.4851\n",
            "Epoch 7/20\n",
            "202/202 [==============================] - 0s 70us/step - loss: 0.7697 - acc: 0.5198\n",
            "Epoch 8/20\n",
            "202/202 [==============================] - 0s 73us/step - loss: 0.7470 - acc: 0.5396\n",
            "Epoch 9/20\n",
            "202/202 [==============================] - 0s 71us/step - loss: 0.7259 - acc: 0.5644\n",
            "Epoch 10/20\n",
            "202/202 [==============================] - 0s 68us/step - loss: 0.7073 - acc: 0.5743\n",
            "Epoch 11/20\n",
            "202/202 [==============================] - 0s 77us/step - loss: 0.6894 - acc: 0.5842\n",
            "Epoch 12/20\n",
            "202/202 [==============================] - 0s 82us/step - loss: 0.6720 - acc: 0.6139\n",
            "Epoch 13/20\n",
            "202/202 [==============================] - 0s 84us/step - loss: 0.6547 - acc: 0.6188\n",
            "Epoch 14/20\n",
            "202/202 [==============================] - 0s 72us/step - loss: 0.6373 - acc: 0.6337\n",
            "Epoch 15/20\n",
            "202/202 [==============================] - 0s 79us/step - loss: 0.6217 - acc: 0.6634\n",
            "Epoch 16/20\n",
            "202/202 [==============================] - 0s 95us/step - loss: 0.6077 - acc: 0.6782\n",
            "Epoch 17/20\n",
            "202/202 [==============================] - 0s 81us/step - loss: 0.5933 - acc: 0.6832\n",
            "Epoch 18/20\n",
            "202/202 [==============================] - 0s 84us/step - loss: 0.5792 - acc: 0.7030\n",
            "Epoch 19/20\n",
            "202/202 [==============================] - 0s 87us/step - loss: 0.5648 - acc: 0.7030\n",
            "Epoch 20/20\n",
            "202/202 [==============================] - 0s 80us/step - loss: 0.5518 - acc: 0.7129\n",
            "101/101 [==============================] - 0s 5ms/step\n",
            "Epoch 1/40\n",
            "202/202 [==============================] - 1s 6ms/step - loss: 0.6730 - acc: 0.6089\n",
            "Epoch 2/40\n",
            "202/202 [==============================] - 0s 88us/step - loss: 0.6560 - acc: 0.6188\n",
            "Epoch 3/40\n",
            "202/202 [==============================] - 0s 71us/step - loss: 0.6396 - acc: 0.6238\n",
            "Epoch 4/40\n",
            "202/202 [==============================] - 0s 69us/step - loss: 0.6249 - acc: 0.6287\n",
            "Epoch 5/40\n",
            "202/202 [==============================] - 0s 69us/step - loss: 0.6098 - acc: 0.6337\n",
            "Epoch 6/40\n",
            "202/202 [==============================] - 0s 65us/step - loss: 0.5963 - acc: 0.6535\n",
            "Epoch 7/40\n",
            "202/202 [==============================] - 0s 66us/step - loss: 0.5833 - acc: 0.6782\n",
            "Epoch 8/40\n",
            "202/202 [==============================] - 0s 70us/step - loss: 0.5702 - acc: 0.6931\n",
            "Epoch 9/40\n",
            "202/202 [==============================] - 0s 70us/step - loss: 0.5579 - acc: 0.7030\n",
            "Epoch 10/40\n",
            "202/202 [==============================] - 0s 69us/step - loss: 0.5470 - acc: 0.7079\n",
            "Epoch 11/40\n",
            "202/202 [==============================] - 0s 70us/step - loss: 0.5362 - acc: 0.7129\n",
            "Epoch 12/40\n",
            "202/202 [==============================] - 0s 71us/step - loss: 0.5253 - acc: 0.7228\n",
            "Epoch 13/40\n",
            "202/202 [==============================] - 0s 71us/step - loss: 0.5159 - acc: 0.7277\n",
            "Epoch 14/40\n",
            "202/202 [==============================] - 0s 66us/step - loss: 0.5063 - acc: 0.7376\n",
            "Epoch 15/40\n",
            "202/202 [==============================] - 0s 78us/step - loss: 0.4987 - acc: 0.7525\n",
            "Epoch 16/40\n",
            "202/202 [==============================] - 0s 68us/step - loss: 0.4912 - acc: 0.7624\n",
            "Epoch 17/40\n",
            "202/202 [==============================] - 0s 77us/step - loss: 0.4841 - acc: 0.7624\n",
            "Epoch 18/40\n",
            "202/202 [==============================] - 0s 76us/step - loss: 0.4772 - acc: 0.7772\n",
            "Epoch 19/40\n",
            "202/202 [==============================] - 0s 78us/step - loss: 0.4704 - acc: 0.7822\n",
            "Epoch 20/40\n",
            "202/202 [==============================] - 0s 90us/step - loss: 0.4643 - acc: 0.7871\n",
            "Epoch 21/40\n",
            "202/202 [==============================] - 0s 100us/step - loss: 0.4587 - acc: 0.7822\n",
            "Epoch 22/40\n",
            "202/202 [==============================] - 0s 89us/step - loss: 0.4530 - acc: 0.7822\n",
            "Epoch 23/40\n",
            "202/202 [==============================] - 0s 111us/step - loss: 0.4479 - acc: 0.7921\n",
            "Epoch 24/40\n",
            "202/202 [==============================] - 0s 87us/step - loss: 0.4425 - acc: 0.7921\n",
            "Epoch 25/40\n",
            "202/202 [==============================] - 0s 75us/step - loss: 0.4379 - acc: 0.7921\n",
            "Epoch 26/40\n",
            "202/202 [==============================] - 0s 71us/step - loss: 0.4336 - acc: 0.7921\n",
            "Epoch 27/40\n",
            "202/202 [==============================] - 0s 82us/step - loss: 0.4288 - acc: 0.8020\n",
            "Epoch 28/40\n",
            "202/202 [==============================] - 0s 72us/step - loss: 0.4244 - acc: 0.8069\n",
            "Epoch 29/40\n",
            "202/202 [==============================] - 0s 75us/step - loss: 0.4205 - acc: 0.8119\n",
            "Epoch 30/40\n",
            "202/202 [==============================] - 0s 86us/step - loss: 0.4165 - acc: 0.8168\n",
            "Epoch 31/40\n",
            "202/202 [==============================] - 0s 105us/step - loss: 0.4128 - acc: 0.8168\n",
            "Epoch 32/40\n",
            "202/202 [==============================] - 0s 75us/step - loss: 0.4095 - acc: 0.8168\n",
            "Epoch 33/40\n",
            "202/202 [==============================] - 0s 72us/step - loss: 0.4062 - acc: 0.8218\n",
            "Epoch 34/40\n",
            "202/202 [==============================] - 0s 89us/step - loss: 0.4028 - acc: 0.8267\n",
            "Epoch 35/40\n",
            "202/202 [==============================] - 0s 87us/step - loss: 0.3998 - acc: 0.8267\n",
            "Epoch 36/40\n",
            "202/202 [==============================] - 0s 83us/step - loss: 0.3970 - acc: 0.8267\n",
            "Epoch 37/40\n",
            "202/202 [==============================] - 0s 77us/step - loss: 0.3945 - acc: 0.8267\n",
            "Epoch 38/40\n",
            "202/202 [==============================] - 0s 68us/step - loss: 0.3923 - acc: 0.8267\n",
            "Epoch 39/40\n",
            "202/202 [==============================] - 0s 82us/step - loss: 0.3907 - acc: 0.8366\n",
            "Epoch 40/40\n",
            "202/202 [==============================] - 0s 74us/step - loss: 0.3890 - acc: 0.8515\n",
            "101/101 [==============================] - 1s 5ms/step\n",
            "Epoch 1/40\n",
            "202/202 [==============================] - 1s 7ms/step - loss: 0.9630 - acc: 0.3861\n",
            "Epoch 2/40\n",
            "202/202 [==============================] - 0s 74us/step - loss: 0.9380 - acc: 0.4158\n",
            "Epoch 3/40\n",
            "202/202 [==============================] - 0s 72us/step - loss: 0.9139 - acc: 0.4307\n",
            "Epoch 4/40\n",
            "202/202 [==============================] - 0s 73us/step - loss: 0.8886 - acc: 0.4356\n",
            "Epoch 5/40\n",
            "202/202 [==============================] - 0s 77us/step - loss: 0.8662 - acc: 0.4703\n",
            "Epoch 6/40\n",
            "202/202 [==============================] - 0s 76us/step - loss: 0.8442 - acc: 0.4752\n",
            "Epoch 7/40\n",
            "202/202 [==============================] - 0s 72us/step - loss: 0.8227 - acc: 0.4950\n",
            "Epoch 8/40\n",
            "202/202 [==============================] - 0s 66us/step - loss: 0.8029 - acc: 0.5000\n",
            "Epoch 9/40\n",
            "202/202 [==============================] - 0s 83us/step - loss: 0.7851 - acc: 0.5050\n",
            "Epoch 10/40\n",
            "202/202 [==============================] - 0s 66us/step - loss: 0.7676 - acc: 0.5248\n",
            "Epoch 11/40\n",
            "202/202 [==============================] - 0s 79us/step - loss: 0.7506 - acc: 0.5446\n",
            "Epoch 12/40\n",
            "202/202 [==============================] - 0s 77us/step - loss: 0.7343 - acc: 0.5446\n",
            "Epoch 13/40\n",
            "202/202 [==============================] - 0s 93us/step - loss: 0.7190 - acc: 0.5644\n",
            "Epoch 14/40\n",
            "202/202 [==============================] - 0s 77us/step - loss: 0.7034 - acc: 0.5644\n",
            "Epoch 15/40\n",
            "202/202 [==============================] - 0s 68us/step - loss: 0.6878 - acc: 0.5842\n",
            "Epoch 16/40\n",
            "202/202 [==============================] - 0s 71us/step - loss: 0.6731 - acc: 0.6188\n",
            "Epoch 17/40\n",
            "202/202 [==============================] - 0s 79us/step - loss: 0.6595 - acc: 0.6337\n",
            "Epoch 18/40\n",
            "202/202 [==============================] - 0s 69us/step - loss: 0.6463 - acc: 0.6485\n",
            "Epoch 19/40\n",
            "202/202 [==============================] - 0s 80us/step - loss: 0.6327 - acc: 0.6683\n",
            "Epoch 20/40\n",
            "202/202 [==============================] - 0s 78us/step - loss: 0.6196 - acc: 0.6881\n",
            "Epoch 21/40\n",
            "202/202 [==============================] - 0s 87us/step - loss: 0.6080 - acc: 0.6980\n",
            "Epoch 22/40\n",
            "202/202 [==============================] - 0s 101us/step - loss: 0.5963 - acc: 0.6980\n",
            "Epoch 23/40\n",
            "202/202 [==============================] - 0s 109us/step - loss: 0.5842 - acc: 0.7030\n",
            "Epoch 24/40\n",
            "202/202 [==============================] - 0s 82us/step - loss: 0.5735 - acc: 0.7079\n",
            "Epoch 25/40\n",
            "202/202 [==============================] - 0s 88us/step - loss: 0.5639 - acc: 0.7277\n",
            "Epoch 26/40\n",
            "202/202 [==============================] - 0s 69us/step - loss: 0.5539 - acc: 0.7327\n",
            "Epoch 27/40\n",
            "202/202 [==============================] - 0s 72us/step - loss: 0.5437 - acc: 0.7426\n",
            "Epoch 28/40\n",
            "202/202 [==============================] - 0s 70us/step - loss: 0.5347 - acc: 0.7376\n",
            "Epoch 29/40\n",
            "202/202 [==============================] - 0s 72us/step - loss: 0.5262 - acc: 0.7426\n",
            "Epoch 30/40\n",
            "202/202 [==============================] - 0s 67us/step - loss: 0.5181 - acc: 0.7673\n",
            "Epoch 31/40\n",
            "202/202 [==============================] - 0s 68us/step - loss: 0.5119 - acc: 0.7673\n",
            "Epoch 32/40\n",
            "202/202 [==============================] - 0s 70us/step - loss: 0.5048 - acc: 0.7673\n",
            "Epoch 33/40\n",
            "202/202 [==============================] - 0s 75us/step - loss: 0.4983 - acc: 0.7723\n",
            "Epoch 34/40\n",
            "202/202 [==============================] - 0s 73us/step - loss: 0.4924 - acc: 0.7871\n",
            "Epoch 35/40\n",
            "202/202 [==============================] - 0s 66us/step - loss: 0.4862 - acc: 0.7871\n",
            "Epoch 36/40\n",
            "202/202 [==============================] - 0s 82us/step - loss: 0.4802 - acc: 0.7772\n",
            "Epoch 37/40\n",
            "202/202 [==============================] - 0s 87us/step - loss: 0.4744 - acc: 0.7822\n",
            "Epoch 38/40\n",
            "202/202 [==============================] - 0s 71us/step - loss: 0.4685 - acc: 0.7921\n",
            "Epoch 39/40\n",
            "202/202 [==============================] - 0s 84us/step - loss: 0.4631 - acc: 0.8020\n",
            "Epoch 40/40\n",
            "202/202 [==============================] - 0s 86us/step - loss: 0.4572 - acc: 0.8020\n",
            "101/101 [==============================] - 1s 6ms/step\n",
            "Epoch 1/40\n",
            "202/202 [==============================] - 1s 7ms/step - loss: 0.7879 - acc: 0.3515\n",
            "Epoch 2/40\n",
            "202/202 [==============================] - 0s 82us/step - loss: 0.7615 - acc: 0.3911\n",
            "Epoch 3/40\n",
            "202/202 [==============================] - 0s 63us/step - loss: 0.7371 - acc: 0.4455\n",
            "Epoch 4/40\n",
            "202/202 [==============================] - 0s 71us/step - loss: 0.7138 - acc: 0.4653\n",
            "Epoch 5/40\n",
            "202/202 [==============================] - 0s 85us/step - loss: 0.6931 - acc: 0.5050\n",
            "Epoch 6/40\n",
            "202/202 [==============================] - 0s 65us/step - loss: 0.6734 - acc: 0.5396\n",
            "Epoch 7/40\n",
            "202/202 [==============================] - 0s 87us/step - loss: 0.6547 - acc: 0.5842\n",
            "Epoch 8/40\n",
            "202/202 [==============================] - 0s 66us/step - loss: 0.6372 - acc: 0.6139\n",
            "Epoch 9/40\n",
            "202/202 [==============================] - 0s 83us/step - loss: 0.6205 - acc: 0.6634\n",
            "Epoch 10/40\n",
            "202/202 [==============================] - 0s 75us/step - loss: 0.6046 - acc: 0.6832\n",
            "Epoch 11/40\n",
            "202/202 [==============================] - 0s 76us/step - loss: 0.5897 - acc: 0.7277\n",
            "Epoch 12/40\n",
            "202/202 [==============================] - 0s 79us/step - loss: 0.5755 - acc: 0.7574\n",
            "Epoch 13/40\n",
            "202/202 [==============================] - 0s 72us/step - loss: 0.5619 - acc: 0.7871\n",
            "Epoch 14/40\n",
            "202/202 [==============================] - 0s 77us/step - loss: 0.5495 - acc: 0.8069\n",
            "Epoch 15/40\n",
            "202/202 [==============================] - 0s 71us/step - loss: 0.5371 - acc: 0.8168\n",
            "Epoch 16/40\n",
            "202/202 [==============================] - 0s 84us/step - loss: 0.5253 - acc: 0.8168\n",
            "Epoch 17/40\n",
            "202/202 [==============================] - 0s 76us/step - loss: 0.5148 - acc: 0.8119\n",
            "Epoch 18/40\n",
            "202/202 [==============================] - 0s 84us/step - loss: 0.5041 - acc: 0.8218\n",
            "Epoch 19/40\n",
            "202/202 [==============================] - 0s 74us/step - loss: 0.4934 - acc: 0.8317\n",
            "Epoch 20/40\n",
            "202/202 [==============================] - 0s 71us/step - loss: 0.4831 - acc: 0.8465\n",
            "Epoch 21/40\n",
            "202/202 [==============================] - 0s 71us/step - loss: 0.4730 - acc: 0.8515\n",
            "Epoch 22/40\n",
            "202/202 [==============================] - 0s 64us/step - loss: 0.4627 - acc: 0.8465\n",
            "Epoch 23/40\n",
            "202/202 [==============================] - 0s 74us/step - loss: 0.4524 - acc: 0.8663\n",
            "Epoch 24/40\n",
            "202/202 [==============================] - 0s 80us/step - loss: 0.4433 - acc: 0.8713\n",
            "Epoch 25/40\n",
            "202/202 [==============================] - 0s 81us/step - loss: 0.4345 - acc: 0.8812\n",
            "Epoch 26/40\n",
            "202/202 [==============================] - 0s 77us/step - loss: 0.4254 - acc: 0.8861\n",
            "Epoch 27/40\n",
            "202/202 [==============================] - 0s 74us/step - loss: 0.4168 - acc: 0.8911\n",
            "Epoch 28/40\n",
            "202/202 [==============================] - 0s 75us/step - loss: 0.4082 - acc: 0.8911\n",
            "Epoch 29/40\n",
            "202/202 [==============================] - 0s 72us/step - loss: 0.3999 - acc: 0.9010\n",
            "Epoch 30/40\n",
            "202/202 [==============================] - 0s 73us/step - loss: 0.3923 - acc: 0.9010\n",
            "Epoch 31/40\n",
            "202/202 [==============================] - 0s 70us/step - loss: 0.3844 - acc: 0.9059\n",
            "Epoch 32/40\n",
            "202/202 [==============================] - 0s 80us/step - loss: 0.3775 - acc: 0.9059\n",
            "Epoch 33/40\n",
            "202/202 [==============================] - 0s 82us/step - loss: 0.3705 - acc: 0.9059\n",
            "Epoch 34/40\n",
            "202/202 [==============================] - 0s 74us/step - loss: 0.3641 - acc: 0.9059\n",
            "Epoch 35/40\n",
            "202/202 [==============================] - 0s 75us/step - loss: 0.3579 - acc: 0.9059\n",
            "Epoch 36/40\n",
            "202/202 [==============================] - 0s 72us/step - loss: 0.3522 - acc: 0.9158\n",
            "Epoch 37/40\n",
            "202/202 [==============================] - 0s 83us/step - loss: 0.3468 - acc: 0.9109\n",
            "Epoch 38/40\n",
            "202/202 [==============================] - 0s 74us/step - loss: 0.3418 - acc: 0.9109\n",
            "Epoch 39/40\n",
            "202/202 [==============================] - 0s 140us/step - loss: 0.3368 - acc: 0.9109\n",
            "Epoch 40/40\n",
            "202/202 [==============================] - 0s 74us/step - loss: 0.3322 - acc: 0.9109\n",
            "101/101 [==============================] - 1s 6ms/step\n",
            "Epoch 1/60\n",
            "202/202 [==============================] - 1s 7ms/step - loss: 0.8396 - acc: 0.5198\n",
            "Epoch 2/60\n",
            "202/202 [==============================] - 0s 76us/step - loss: 0.8092 - acc: 0.5396\n",
            "Epoch 3/60\n",
            "202/202 [==============================] - 0s 71us/step - loss: 0.7824 - acc: 0.5594\n",
            "Epoch 4/60\n",
            "202/202 [==============================] - 0s 75us/step - loss: 0.7588 - acc: 0.5644\n",
            "Epoch 5/60\n",
            "202/202 [==============================] - 0s 65us/step - loss: 0.7360 - acc: 0.5941\n",
            "Epoch 6/60\n",
            "202/202 [==============================] - 0s 87us/step - loss: 0.7140 - acc: 0.6188\n",
            "Epoch 7/60\n",
            "202/202 [==============================] - 0s 69us/step - loss: 0.6942 - acc: 0.6238\n",
            "Epoch 8/60\n",
            "202/202 [==============================] - 0s 78us/step - loss: 0.6768 - acc: 0.6337\n",
            "Epoch 9/60\n",
            "202/202 [==============================] - 0s 109us/step - loss: 0.6586 - acc: 0.6535\n",
            "Epoch 10/60\n",
            "202/202 [==============================] - 0s 76us/step - loss: 0.6428 - acc: 0.6832\n",
            "Epoch 11/60\n",
            "202/202 [==============================] - 0s 85us/step - loss: 0.6286 - acc: 0.7030\n",
            "Epoch 12/60\n",
            "202/202 [==============================] - 0s 86us/step - loss: 0.6157 - acc: 0.7178\n",
            "Epoch 13/60\n",
            "202/202 [==============================] - 0s 88us/step - loss: 0.6037 - acc: 0.7178\n",
            "Epoch 14/60\n",
            "202/202 [==============================] - 0s 76us/step - loss: 0.5930 - acc: 0.7129\n",
            "Epoch 15/60\n",
            "202/202 [==============================] - 0s 81us/step - loss: 0.5830 - acc: 0.7277\n",
            "Epoch 16/60\n",
            "202/202 [==============================] - 0s 77us/step - loss: 0.5742 - acc: 0.7376\n",
            "Epoch 17/60\n",
            "202/202 [==============================] - 0s 76us/step - loss: 0.5660 - acc: 0.7376\n",
            "Epoch 18/60\n",
            "202/202 [==============================] - 0s 79us/step - loss: 0.5578 - acc: 0.7327\n",
            "Epoch 19/60\n",
            "202/202 [==============================] - 0s 80us/step - loss: 0.5492 - acc: 0.7426\n",
            "Epoch 20/60\n",
            "202/202 [==============================] - 0s 66us/step - loss: 0.5420 - acc: 0.7426\n",
            "Epoch 21/60\n",
            "202/202 [==============================] - 0s 73us/step - loss: 0.5350 - acc: 0.7475\n",
            "Epoch 22/60\n",
            "202/202 [==============================] - 0s 71us/step - loss: 0.5282 - acc: 0.7574\n",
            "Epoch 23/60\n",
            "202/202 [==============================] - 0s 60us/step - loss: 0.5209 - acc: 0.7574\n",
            "Epoch 24/60\n",
            "202/202 [==============================] - 0s 72us/step - loss: 0.5134 - acc: 0.7624\n",
            "Epoch 25/60\n",
            "202/202 [==============================] - 0s 89us/step - loss: 0.5064 - acc: 0.7624\n",
            "Epoch 26/60\n",
            "202/202 [==============================] - 0s 95us/step - loss: 0.5004 - acc: 0.7673\n",
            "Epoch 27/60\n",
            "202/202 [==============================] - 0s 79us/step - loss: 0.4949 - acc: 0.7723\n",
            "Epoch 28/60\n",
            "202/202 [==============================] - 0s 84us/step - loss: 0.4904 - acc: 0.7772\n",
            "Epoch 29/60\n",
            "202/202 [==============================] - 0s 78us/step - loss: 0.4856 - acc: 0.7772\n",
            "Epoch 30/60\n",
            "202/202 [==============================] - 0s 77us/step - loss: 0.4813 - acc: 0.7723\n",
            "Epoch 31/60\n",
            "202/202 [==============================] - 0s 80us/step - loss: 0.4764 - acc: 0.7822\n",
            "Epoch 32/60\n",
            "202/202 [==============================] - 0s 79us/step - loss: 0.4720 - acc: 0.7822\n",
            "Epoch 33/60\n",
            "202/202 [==============================] - 0s 87us/step - loss: 0.4682 - acc: 0.7822\n",
            "Epoch 34/60\n",
            "202/202 [==============================] - 0s 112us/step - loss: 0.4647 - acc: 0.7871\n",
            "Epoch 35/60\n",
            "202/202 [==============================] - 0s 69us/step - loss: 0.4608 - acc: 0.7921\n",
            "Epoch 36/60\n",
            "202/202 [==============================] - 0s 88us/step - loss: 0.4563 - acc: 0.7921\n",
            "Epoch 37/60\n",
            "202/202 [==============================] - 0s 88us/step - loss: 0.4521 - acc: 0.7921\n",
            "Epoch 38/60\n",
            "202/202 [==============================] - 0s 70us/step - loss: 0.4482 - acc: 0.7970\n",
            "Epoch 39/60\n",
            "202/202 [==============================] - 0s 76us/step - loss: 0.4448 - acc: 0.7921\n",
            "Epoch 40/60\n",
            "202/202 [==============================] - 0s 107us/step - loss: 0.4412 - acc: 0.7921\n",
            "Epoch 41/60\n",
            "202/202 [==============================] - 0s 75us/step - loss: 0.4377 - acc: 0.7921\n",
            "Epoch 42/60\n",
            "202/202 [==============================] - 0s 79us/step - loss: 0.4345 - acc: 0.7921\n",
            "Epoch 43/60\n",
            "202/202 [==============================] - 0s 77us/step - loss: 0.4315 - acc: 0.7921\n",
            "Epoch 44/60\n",
            "202/202 [==============================] - 0s 68us/step - loss: 0.4284 - acc: 0.7921\n",
            "Epoch 45/60\n",
            "202/202 [==============================] - 0s 75us/step - loss: 0.4256 - acc: 0.7921\n",
            "Epoch 46/60\n",
            "202/202 [==============================] - 0s 113us/step - loss: 0.4232 - acc: 0.7970\n",
            "Epoch 47/60\n",
            "202/202 [==============================] - 0s 113us/step - loss: 0.4203 - acc: 0.8020\n",
            "Epoch 48/60\n",
            "202/202 [==============================] - 0s 77us/step - loss: 0.4180 - acc: 0.8069\n",
            "Epoch 49/60\n",
            "202/202 [==============================] - 0s 83us/step - loss: 0.4151 - acc: 0.8119\n",
            "Epoch 50/60\n",
            "202/202 [==============================] - 0s 76us/step - loss: 0.4123 - acc: 0.8119\n",
            "Epoch 51/60\n",
            "202/202 [==============================] - 0s 87us/step - loss: 0.4097 - acc: 0.8168\n",
            "Epoch 52/60\n",
            "202/202 [==============================] - 0s 77us/step - loss: 0.4069 - acc: 0.8168\n",
            "Epoch 53/60\n",
            "202/202 [==============================] - 0s 67us/step - loss: 0.4043 - acc: 0.8168\n",
            "Epoch 54/60\n",
            "202/202 [==============================] - 0s 94us/step - loss: 0.4016 - acc: 0.8168\n",
            "Epoch 55/60\n",
            "202/202 [==============================] - 0s 83us/step - loss: 0.3993 - acc: 0.8218\n",
            "Epoch 56/60\n",
            "202/202 [==============================] - 0s 77us/step - loss: 0.3970 - acc: 0.8218\n",
            "Epoch 57/60\n",
            "202/202 [==============================] - 0s 73us/step - loss: 0.3946 - acc: 0.8267\n",
            "Epoch 58/60\n",
            "202/202 [==============================] - 0s 93us/step - loss: 0.3920 - acc: 0.8267\n",
            "Epoch 59/60\n",
            "202/202 [==============================] - 0s 93us/step - loss: 0.3900 - acc: 0.8267\n",
            "Epoch 60/60\n",
            "202/202 [==============================] - 0s 91us/step - loss: 0.3878 - acc: 0.8267\n",
            "101/101 [==============================] - 1s 6ms/step\n",
            "Epoch 1/60\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.6919 - acc: 0.5743\n",
            "Epoch 2/60\n",
            "202/202 [==============================] - 0s 102us/step - loss: 0.6737 - acc: 0.5891\n",
            "Epoch 3/60\n",
            "202/202 [==============================] - 0s 81us/step - loss: 0.6591 - acc: 0.6089\n",
            "Epoch 4/60\n",
            "202/202 [==============================] - 0s 75us/step - loss: 0.6465 - acc: 0.6139\n",
            "Epoch 5/60\n",
            "202/202 [==============================] - 0s 74us/step - loss: 0.6342 - acc: 0.6188\n",
            "Epoch 6/60\n",
            "202/202 [==============================] - 0s 79us/step - loss: 0.6233 - acc: 0.6188\n",
            "Epoch 7/60\n",
            "202/202 [==============================] - 0s 72us/step - loss: 0.6126 - acc: 0.6287\n",
            "Epoch 8/60\n",
            "202/202 [==============================] - 0s 73us/step - loss: 0.6027 - acc: 0.6386\n",
            "Epoch 9/60\n",
            "202/202 [==============================] - 0s 74us/step - loss: 0.5929 - acc: 0.6535\n",
            "Epoch 10/60\n",
            "202/202 [==============================] - 0s 77us/step - loss: 0.5844 - acc: 0.6683\n",
            "Epoch 11/60\n",
            "202/202 [==============================] - 0s 81us/step - loss: 0.5759 - acc: 0.6832\n",
            "Epoch 12/60\n",
            "202/202 [==============================] - 0s 78us/step - loss: 0.5672 - acc: 0.6980\n",
            "Epoch 13/60\n",
            "202/202 [==============================] - 0s 77us/step - loss: 0.5587 - acc: 0.7030\n",
            "Epoch 14/60\n",
            "202/202 [==============================] - 0s 119us/step - loss: 0.5508 - acc: 0.7079\n",
            "Epoch 15/60\n",
            "202/202 [==============================] - 0s 81us/step - loss: 0.5429 - acc: 0.7228\n",
            "Epoch 16/60\n",
            "202/202 [==============================] - 0s 83us/step - loss: 0.5351 - acc: 0.7327\n",
            "Epoch 17/60\n",
            "202/202 [==============================] - 0s 83us/step - loss: 0.5276 - acc: 0.7376\n",
            "Epoch 18/60\n",
            "202/202 [==============================] - 0s 79us/step - loss: 0.5204 - acc: 0.7475\n",
            "Epoch 19/60\n",
            "202/202 [==============================] - 0s 79us/step - loss: 0.5138 - acc: 0.7475\n",
            "Epoch 20/60\n",
            "202/202 [==============================] - 0s 87us/step - loss: 0.5070 - acc: 0.7475\n",
            "Epoch 21/60\n",
            "202/202 [==============================] - 0s 101us/step - loss: 0.5006 - acc: 0.7525\n",
            "Epoch 22/60\n",
            "202/202 [==============================] - 0s 89us/step - loss: 0.4944 - acc: 0.7525\n",
            "Epoch 23/60\n",
            "202/202 [==============================] - 0s 102us/step - loss: 0.4886 - acc: 0.7525\n",
            "Epoch 24/60\n",
            "202/202 [==============================] - 0s 83us/step - loss: 0.4831 - acc: 0.7525\n",
            "Epoch 25/60\n",
            "202/202 [==============================] - 0s 87us/step - loss: 0.4778 - acc: 0.7525\n",
            "Epoch 26/60\n",
            "202/202 [==============================] - 0s 72us/step - loss: 0.4724 - acc: 0.7624\n",
            "Epoch 27/60\n",
            "202/202 [==============================] - 0s 76us/step - loss: 0.4672 - acc: 0.7673\n",
            "Epoch 28/60\n",
            "202/202 [==============================] - 0s 76us/step - loss: 0.4624 - acc: 0.7723\n",
            "Epoch 29/60\n",
            "202/202 [==============================] - 0s 83us/step - loss: 0.4580 - acc: 0.7723\n",
            "Epoch 30/60\n",
            "202/202 [==============================] - 0s 73us/step - loss: 0.4537 - acc: 0.7772\n",
            "Epoch 31/60\n",
            "202/202 [==============================] - 0s 68us/step - loss: 0.4487 - acc: 0.7723\n",
            "Epoch 32/60\n",
            "202/202 [==============================] - 0s 92us/step - loss: 0.4447 - acc: 0.7772\n",
            "Epoch 33/60\n",
            "202/202 [==============================] - 0s 99us/step - loss: 0.4407 - acc: 0.7772\n",
            "Epoch 34/60\n",
            "202/202 [==============================] - 0s 83us/step - loss: 0.4368 - acc: 0.7871\n",
            "Epoch 35/60\n",
            "202/202 [==============================] - 0s 83us/step - loss: 0.4330 - acc: 0.7921\n",
            "Epoch 36/60\n",
            "202/202 [==============================] - 0s 150us/step - loss: 0.4293 - acc: 0.7921\n",
            "Epoch 37/60\n",
            "202/202 [==============================] - 0s 76us/step - loss: 0.4257 - acc: 0.7871\n",
            "Epoch 38/60\n",
            "202/202 [==============================] - 0s 83us/step - loss: 0.4222 - acc: 0.7871\n",
            "Epoch 39/60\n",
            "202/202 [==============================] - 0s 82us/step - loss: 0.4191 - acc: 0.7970\n",
            "Epoch 40/60\n",
            "202/202 [==============================] - 0s 78us/step - loss: 0.4156 - acc: 0.7970\n",
            "Epoch 41/60\n",
            "202/202 [==============================] - 0s 83us/step - loss: 0.4122 - acc: 0.8069\n",
            "Epoch 42/60\n",
            "202/202 [==============================] - 0s 70us/step - loss: 0.4092 - acc: 0.8119\n",
            "Epoch 43/60\n",
            "202/202 [==============================] - 0s 89us/step - loss: 0.4060 - acc: 0.8168\n",
            "Epoch 44/60\n",
            "202/202 [==============================] - 0s 108us/step - loss: 0.4032 - acc: 0.8168\n",
            "Epoch 45/60\n",
            "202/202 [==============================] - 0s 75us/step - loss: 0.3999 - acc: 0.8317\n",
            "Epoch 46/60\n",
            "202/202 [==============================] - 0s 75us/step - loss: 0.3970 - acc: 0.8317\n",
            "Epoch 47/60\n",
            "202/202 [==============================] - 0s 82us/step - loss: 0.3944 - acc: 0.8317\n",
            "Epoch 48/60\n",
            "202/202 [==============================] - 0s 79us/step - loss: 0.3915 - acc: 0.8267\n",
            "Epoch 49/60\n",
            "202/202 [==============================] - 0s 87us/step - loss: 0.3886 - acc: 0.8267\n",
            "Epoch 50/60\n",
            "202/202 [==============================] - 0s 80us/step - loss: 0.3858 - acc: 0.8267\n",
            "Epoch 51/60\n",
            "202/202 [==============================] - 0s 93us/step - loss: 0.3834 - acc: 0.8267\n",
            "Epoch 52/60\n",
            "202/202 [==============================] - 0s 101us/step - loss: 0.3809 - acc: 0.8317\n",
            "Epoch 53/60\n",
            "202/202 [==============================] - 0s 89us/step - loss: 0.3785 - acc: 0.8366\n",
            "Epoch 54/60\n",
            "202/202 [==============================] - 0s 73us/step - loss: 0.3761 - acc: 0.8366\n",
            "Epoch 55/60\n",
            "202/202 [==============================] - 0s 80us/step - loss: 0.3734 - acc: 0.8366\n",
            "Epoch 56/60\n",
            "202/202 [==============================] - 0s 74us/step - loss: 0.3713 - acc: 0.8366\n",
            "Epoch 57/60\n",
            "202/202 [==============================] - 0s 68us/step - loss: 0.3689 - acc: 0.8317\n",
            "Epoch 58/60\n",
            "202/202 [==============================] - 0s 66us/step - loss: 0.3668 - acc: 0.8317\n",
            "Epoch 59/60\n",
            "202/202 [==============================] - 0s 70us/step - loss: 0.3646 - acc: 0.8317\n",
            "Epoch 60/60\n",
            "202/202 [==============================] - 0s 94us/step - loss: 0.3626 - acc: 0.8416\n",
            "101/101 [==============================] - 1s 6ms/step\n",
            "Epoch 1/60\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.8615 - acc: 0.4604\n",
            "Epoch 2/60\n",
            "202/202 [==============================] - 0s 80us/step - loss: 0.8300 - acc: 0.5000\n",
            "Epoch 3/60\n",
            "202/202 [==============================] - 0s 74us/step - loss: 0.8014 - acc: 0.5248\n",
            "Epoch 4/60\n",
            "202/202 [==============================] - 0s 67us/step - loss: 0.7737 - acc: 0.5594\n",
            "Epoch 5/60\n",
            "202/202 [==============================] - 0s 64us/step - loss: 0.7454 - acc: 0.5990\n",
            "Epoch 6/60\n",
            "202/202 [==============================] - 0s 69us/step - loss: 0.7202 - acc: 0.6188\n",
            "Epoch 7/60\n",
            "202/202 [==============================] - 0s 66us/step - loss: 0.6945 - acc: 0.6535\n",
            "Epoch 8/60\n",
            "202/202 [==============================] - 0s 63us/step - loss: 0.6705 - acc: 0.6832\n",
            "Epoch 9/60\n",
            "202/202 [==============================] - 0s 67us/step - loss: 0.6484 - acc: 0.6931\n",
            "Epoch 10/60\n",
            "202/202 [==============================] - 0s 61us/step - loss: 0.6270 - acc: 0.7030\n",
            "Epoch 11/60\n",
            "202/202 [==============================] - 0s 71us/step - loss: 0.6073 - acc: 0.7079\n",
            "Epoch 12/60\n",
            "202/202 [==============================] - 0s 70us/step - loss: 0.5876 - acc: 0.7178\n",
            "Epoch 13/60\n",
            "202/202 [==============================] - 0s 93us/step - loss: 0.5695 - acc: 0.7277\n",
            "Epoch 14/60\n",
            "202/202 [==============================] - 0s 78us/step - loss: 0.5514 - acc: 0.7376\n",
            "Epoch 15/60\n",
            "202/202 [==============================] - 0s 72us/step - loss: 0.5345 - acc: 0.7475\n",
            "Epoch 16/60\n",
            "202/202 [==============================] - 0s 66us/step - loss: 0.5183 - acc: 0.7475\n",
            "Epoch 17/60\n",
            "202/202 [==============================] - 0s 76us/step - loss: 0.5030 - acc: 0.7624\n",
            "Epoch 18/60\n",
            "202/202 [==============================] - 0s 74us/step - loss: 0.4898 - acc: 0.7772\n",
            "Epoch 19/60\n",
            "202/202 [==============================] - 0s 70us/step - loss: 0.4764 - acc: 0.7772\n",
            "Epoch 20/60\n",
            "202/202 [==============================] - 0s 86us/step - loss: 0.4647 - acc: 0.7970\n",
            "Epoch 21/60\n",
            "202/202 [==============================] - 0s 84us/step - loss: 0.4534 - acc: 0.8020\n",
            "Epoch 22/60\n",
            "202/202 [==============================] - 0s 81us/step - loss: 0.4434 - acc: 0.8020\n",
            "Epoch 23/60\n",
            "202/202 [==============================] - 0s 73us/step - loss: 0.4339 - acc: 0.8168\n",
            "Epoch 24/60\n",
            "202/202 [==============================] - 0s 77us/step - loss: 0.4251 - acc: 0.8218\n",
            "Epoch 25/60\n",
            "202/202 [==============================] - 0s 64us/step - loss: 0.4175 - acc: 0.8317\n",
            "Epoch 26/60\n",
            "202/202 [==============================] - 0s 91us/step - loss: 0.4097 - acc: 0.8366\n",
            "Epoch 27/60\n",
            "202/202 [==============================] - 0s 85us/step - loss: 0.4022 - acc: 0.8366\n",
            "Epoch 28/60\n",
            "202/202 [==============================] - 0s 75us/step - loss: 0.3951 - acc: 0.8366\n",
            "Epoch 29/60\n",
            "202/202 [==============================] - 0s 71us/step - loss: 0.3878 - acc: 0.8366\n",
            "Epoch 30/60\n",
            "202/202 [==============================] - 0s 73us/step - loss: 0.3809 - acc: 0.8366\n",
            "Epoch 31/60\n",
            "202/202 [==============================] - 0s 89us/step - loss: 0.3748 - acc: 0.8366\n",
            "Epoch 32/60\n",
            "202/202 [==============================] - 0s 77us/step - loss: 0.3692 - acc: 0.8366\n",
            "Epoch 33/60\n",
            "202/202 [==============================] - 0s 69us/step - loss: 0.3637 - acc: 0.8465\n",
            "Epoch 34/60\n",
            "202/202 [==============================] - 0s 72us/step - loss: 0.3581 - acc: 0.8515\n",
            "Epoch 35/60\n",
            "202/202 [==============================] - 0s 70us/step - loss: 0.3528 - acc: 0.8465\n",
            "Epoch 36/60\n",
            "202/202 [==============================] - 0s 93us/step - loss: 0.3488 - acc: 0.8465\n",
            "Epoch 37/60\n",
            "202/202 [==============================] - 0s 79us/step - loss: 0.3445 - acc: 0.8564\n",
            "Epoch 38/60\n",
            "202/202 [==============================] - 0s 72us/step - loss: 0.3404 - acc: 0.8564\n",
            "Epoch 39/60\n",
            "202/202 [==============================] - 0s 70us/step - loss: 0.3366 - acc: 0.8564\n",
            "Epoch 40/60\n",
            "202/202 [==============================] - 0s 91us/step - loss: 0.3331 - acc: 0.8614\n",
            "Epoch 41/60\n",
            "202/202 [==============================] - 0s 74us/step - loss: 0.3296 - acc: 0.8663\n",
            "Epoch 42/60\n",
            "202/202 [==============================] - 0s 73us/step - loss: 0.3259 - acc: 0.8663\n",
            "Epoch 43/60\n",
            "202/202 [==============================] - 0s 71us/step - loss: 0.3223 - acc: 0.8663\n",
            "Epoch 44/60\n",
            "202/202 [==============================] - 0s 89us/step - loss: 0.3188 - acc: 0.8663\n",
            "Epoch 45/60\n",
            "202/202 [==============================] - 0s 80us/step - loss: 0.3152 - acc: 0.8713\n",
            "Epoch 46/60\n",
            "202/202 [==============================] - 0s 93us/step - loss: 0.3122 - acc: 0.8663\n",
            "Epoch 47/60\n",
            "202/202 [==============================] - 0s 102us/step - loss: 0.3093 - acc: 0.8663\n",
            "Epoch 48/60\n",
            "202/202 [==============================] - 0s 79us/step - loss: 0.3067 - acc: 0.8663\n",
            "Epoch 49/60\n",
            "202/202 [==============================] - 0s 84us/step - loss: 0.3037 - acc: 0.8663\n",
            "Epoch 50/60\n",
            "202/202 [==============================] - 0s 80us/step - loss: 0.3012 - acc: 0.8713\n",
            "Epoch 51/60\n",
            "202/202 [==============================] - 0s 68us/step - loss: 0.2987 - acc: 0.8713\n",
            "Epoch 52/60\n",
            "202/202 [==============================] - 0s 84us/step - loss: 0.2962 - acc: 0.8713\n",
            "Epoch 53/60\n",
            "202/202 [==============================] - 0s 68us/step - loss: 0.2942 - acc: 0.8713\n",
            "Epoch 54/60\n",
            "202/202 [==============================] - 0s 91us/step - loss: 0.2919 - acc: 0.8713\n",
            "Epoch 55/60\n",
            "202/202 [==============================] - 0s 78us/step - loss: 0.2899 - acc: 0.8713\n",
            "Epoch 56/60\n",
            "202/202 [==============================] - 0s 72us/step - loss: 0.2878 - acc: 0.8713\n",
            "Epoch 57/60\n",
            "202/202 [==============================] - 0s 77us/step - loss: 0.2859 - acc: 0.8713\n",
            "Epoch 58/60\n",
            "202/202 [==============================] - 0s 109us/step - loss: 0.2841 - acc: 0.8713\n",
            "Epoch 59/60\n",
            "202/202 [==============================] - 0s 112us/step - loss: 0.2823 - acc: 0.8713\n",
            "Epoch 60/60\n",
            "202/202 [==============================] - 0s 89us/step - loss: 0.2805 - acc: 0.8713\n",
            "101/101 [==============================] - 1s 6ms/step\n",
            "Epoch 1/80\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.7063 - acc: 0.5644\n",
            "Epoch 2/80\n",
            "202/202 [==============================] - 0s 74us/step - loss: 0.6882 - acc: 0.5842\n",
            "Epoch 3/80\n",
            "202/202 [==============================] - 0s 76us/step - loss: 0.6718 - acc: 0.6040\n",
            "Epoch 4/80\n",
            "202/202 [==============================] - 0s 67us/step - loss: 0.6569 - acc: 0.6287\n",
            "Epoch 5/80\n",
            "202/202 [==============================] - 0s 70us/step - loss: 0.6437 - acc: 0.6386\n",
            "Epoch 6/80\n",
            "202/202 [==============================] - 0s 70us/step - loss: 0.6305 - acc: 0.6634\n",
            "Epoch 7/80\n",
            "202/202 [==============================] - 0s 74us/step - loss: 0.6186 - acc: 0.6733\n",
            "Epoch 8/80\n",
            "202/202 [==============================] - 0s 80us/step - loss: 0.6082 - acc: 0.7030\n",
            "Epoch 9/80\n",
            "202/202 [==============================] - 0s 69us/step - loss: 0.5988 - acc: 0.7129\n",
            "Epoch 10/80\n",
            "202/202 [==============================] - 0s 64us/step - loss: 0.5891 - acc: 0.7327\n",
            "Epoch 11/80\n",
            "202/202 [==============================] - 0s 72us/step - loss: 0.5796 - acc: 0.7376\n",
            "Epoch 12/80\n",
            "202/202 [==============================] - 0s 70us/step - loss: 0.5705 - acc: 0.7376\n",
            "Epoch 13/80\n",
            "202/202 [==============================] - 0s 68us/step - loss: 0.5624 - acc: 0.7426\n",
            "Epoch 14/80\n",
            "202/202 [==============================] - 0s 67us/step - loss: 0.5547 - acc: 0.7525\n",
            "Epoch 15/80\n",
            "202/202 [==============================] - 0s 71us/step - loss: 0.5475 - acc: 0.7475\n",
            "Epoch 16/80\n",
            "202/202 [==============================] - 0s 68us/step - loss: 0.5411 - acc: 0.7574\n",
            "Epoch 17/80\n",
            "202/202 [==============================] - 0s 85us/step - loss: 0.5344 - acc: 0.7673\n",
            "Epoch 18/80\n",
            "202/202 [==============================] - 0s 65us/step - loss: 0.5280 - acc: 0.7673\n",
            "Epoch 19/80\n",
            "202/202 [==============================] - 0s 76us/step - loss: 0.5215 - acc: 0.7723\n",
            "Epoch 20/80\n",
            "202/202 [==============================] - 0s 73us/step - loss: 0.5158 - acc: 0.7822\n",
            "Epoch 21/80\n",
            "202/202 [==============================] - 0s 77us/step - loss: 0.5095 - acc: 0.7822\n",
            "Epoch 22/80\n",
            "202/202 [==============================] - 0s 71us/step - loss: 0.5044 - acc: 0.7921\n",
            "Epoch 23/80\n",
            "202/202 [==============================] - 0s 77us/step - loss: 0.4987 - acc: 0.7970\n",
            "Epoch 24/80\n",
            "202/202 [==============================] - 0s 101us/step - loss: 0.4933 - acc: 0.7970\n",
            "Epoch 25/80\n",
            "202/202 [==============================] - 0s 86us/step - loss: 0.4882 - acc: 0.7970\n",
            "Epoch 26/80\n",
            "202/202 [==============================] - 0s 88us/step - loss: 0.4831 - acc: 0.8020\n",
            "Epoch 27/80\n",
            "202/202 [==============================] - 0s 70us/step - loss: 0.4783 - acc: 0.8020\n",
            "Epoch 28/80\n",
            "202/202 [==============================] - 0s 75us/step - loss: 0.4737 - acc: 0.8020\n",
            "Epoch 29/80\n",
            "202/202 [==============================] - 0s 70us/step - loss: 0.4692 - acc: 0.8020\n",
            "Epoch 30/80\n",
            "202/202 [==============================] - 0s 73us/step - loss: 0.4646 - acc: 0.8069\n",
            "Epoch 31/80\n",
            "202/202 [==============================] - 0s 94us/step - loss: 0.4605 - acc: 0.8069\n",
            "Epoch 32/80\n",
            "202/202 [==============================] - 0s 94us/step - loss: 0.4568 - acc: 0.8119\n",
            "Epoch 33/80\n",
            "202/202 [==============================] - 0s 80us/step - loss: 0.4532 - acc: 0.8168\n",
            "Epoch 34/80\n",
            "202/202 [==============================] - 0s 138us/step - loss: 0.4495 - acc: 0.8168\n",
            "Epoch 35/80\n",
            "202/202 [==============================] - 0s 69us/step - loss: 0.4458 - acc: 0.8168\n",
            "Epoch 36/80\n",
            "202/202 [==============================] - 0s 81us/step - loss: 0.4419 - acc: 0.8119\n",
            "Epoch 37/80\n",
            "202/202 [==============================] - 0s 78us/step - loss: 0.4388 - acc: 0.8119\n",
            "Epoch 38/80\n",
            "202/202 [==============================] - 0s 75us/step - loss: 0.4355 - acc: 0.8168\n",
            "Epoch 39/80\n",
            "202/202 [==============================] - 0s 81us/step - loss: 0.4324 - acc: 0.8119\n",
            "Epoch 40/80\n",
            "202/202 [==============================] - 0s 102us/step - loss: 0.4292 - acc: 0.8119\n",
            "Epoch 41/80\n",
            "202/202 [==============================] - 0s 95us/step - loss: 0.4262 - acc: 0.8119\n",
            "Epoch 42/80\n",
            "202/202 [==============================] - 0s 79us/step - loss: 0.4232 - acc: 0.8119\n",
            "Epoch 43/80\n",
            "202/202 [==============================] - 0s 76us/step - loss: 0.4204 - acc: 0.8218\n",
            "Epoch 44/80\n",
            "202/202 [==============================] - 0s 106us/step - loss: 0.4177 - acc: 0.8168\n",
            "Epoch 45/80\n",
            "202/202 [==============================] - 0s 75us/step - loss: 0.4151 - acc: 0.8168\n",
            "Epoch 46/80\n",
            "202/202 [==============================] - 0s 83us/step - loss: 0.4125 - acc: 0.8168\n",
            "Epoch 47/80\n",
            "202/202 [==============================] - 0s 72us/step - loss: 0.4102 - acc: 0.8119\n",
            "Epoch 48/80\n",
            "202/202 [==============================] - 0s 75us/step - loss: 0.4077 - acc: 0.8119\n",
            "Epoch 49/80\n",
            "202/202 [==============================] - 0s 76us/step - loss: 0.4053 - acc: 0.8168\n",
            "Epoch 50/80\n",
            "202/202 [==============================] - 0s 86us/step - loss: 0.4026 - acc: 0.8218\n",
            "Epoch 51/80\n",
            "202/202 [==============================] - 0s 103us/step - loss: 0.4002 - acc: 0.8218\n",
            "Epoch 52/80\n",
            "202/202 [==============================] - 0s 84us/step - loss: 0.3981 - acc: 0.8168\n",
            "Epoch 53/80\n",
            "202/202 [==============================] - 0s 92us/step - loss: 0.3964 - acc: 0.8168\n",
            "Epoch 54/80\n",
            "202/202 [==============================] - 0s 86us/step - loss: 0.3944 - acc: 0.8168\n",
            "Epoch 55/80\n",
            "202/202 [==============================] - 0s 73us/step - loss: 0.3920 - acc: 0.8168\n",
            "Epoch 56/80\n",
            "202/202 [==============================] - 0s 83us/step - loss: 0.3899 - acc: 0.8218\n",
            "Epoch 57/80\n",
            "202/202 [==============================] - 0s 71us/step - loss: 0.3879 - acc: 0.8218\n",
            "Epoch 58/80\n",
            "202/202 [==============================] - 0s 89us/step - loss: 0.3860 - acc: 0.8168\n",
            "Epoch 59/80\n",
            "202/202 [==============================] - 0s 87us/step - loss: 0.3843 - acc: 0.8168\n",
            "Epoch 60/80\n",
            "202/202 [==============================] - 0s 88us/step - loss: 0.3824 - acc: 0.8168\n",
            "Epoch 61/80\n",
            "202/202 [==============================] - 0s 77us/step - loss: 0.3804 - acc: 0.8168\n",
            "Epoch 62/80\n",
            "202/202 [==============================] - 0s 78us/step - loss: 0.3785 - acc: 0.8168\n",
            "Epoch 63/80\n",
            "202/202 [==============================] - 0s 80us/step - loss: 0.3766 - acc: 0.8218\n",
            "Epoch 64/80\n",
            "202/202 [==============================] - 0s 69us/step - loss: 0.3751 - acc: 0.8218\n",
            "Epoch 65/80\n",
            "202/202 [==============================] - 0s 65us/step - loss: 0.3732 - acc: 0.8218\n",
            "Epoch 66/80\n",
            "202/202 [==============================] - 0s 83us/step - loss: 0.3716 - acc: 0.8218\n",
            "Epoch 67/80\n",
            "202/202 [==============================] - 0s 97us/step - loss: 0.3698 - acc: 0.8218\n",
            "Epoch 68/80\n",
            "202/202 [==============================] - 0s 99us/step - loss: 0.3684 - acc: 0.8218\n",
            "Epoch 69/80\n",
            "202/202 [==============================] - 0s 87us/step - loss: 0.3667 - acc: 0.8218\n",
            "Epoch 70/80\n",
            "202/202 [==============================] - 0s 78us/step - loss: 0.3651 - acc: 0.8267\n",
            "Epoch 71/80\n",
            "202/202 [==============================] - 0s 101us/step - loss: 0.3637 - acc: 0.8317\n",
            "Epoch 72/80\n",
            "202/202 [==============================] - 0s 79us/step - loss: 0.3622 - acc: 0.8366\n",
            "Epoch 73/80\n",
            "202/202 [==============================] - 0s 77us/step - loss: 0.3606 - acc: 0.8366\n",
            "Epoch 74/80\n",
            "202/202 [==============================] - 0s 89us/step - loss: 0.3592 - acc: 0.8366\n",
            "Epoch 75/80\n",
            "202/202 [==============================] - 0s 91us/step - loss: 0.3575 - acc: 0.8366\n",
            "Epoch 76/80\n",
            "202/202 [==============================] - 0s 111us/step - loss: 0.3559 - acc: 0.8416\n",
            "Epoch 77/80\n",
            "202/202 [==============================] - 0s 86us/step - loss: 0.3545 - acc: 0.8465\n",
            "Epoch 78/80\n",
            "202/202 [==============================] - 0s 86us/step - loss: 0.3531 - acc: 0.8416\n",
            "Epoch 79/80\n",
            "202/202 [==============================] - 0s 92us/step - loss: 0.3517 - acc: 0.8416\n",
            "Epoch 80/80\n",
            "202/202 [==============================] - 0s 80us/step - loss: 0.3503 - acc: 0.8465\n",
            "101/101 [==============================] - 1s 6ms/step\n",
            "Epoch 1/80\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 1.1458 - acc: 0.4356\n",
            "Epoch 2/80\n",
            "202/202 [==============================] - 0s 67us/step - loss: 1.1071 - acc: 0.4356\n",
            "Epoch 3/80\n",
            "202/202 [==============================] - 0s 71us/step - loss: 1.0735 - acc: 0.4356\n",
            "Epoch 4/80\n",
            "202/202 [==============================] - 0s 73us/step - loss: 1.0432 - acc: 0.4554\n",
            "Epoch 5/80\n",
            "202/202 [==============================] - 0s 68us/step - loss: 1.0112 - acc: 0.4653\n",
            "Epoch 6/80\n",
            "202/202 [==============================] - 0s 63us/step - loss: 0.9818 - acc: 0.4802\n",
            "Epoch 7/80\n",
            "202/202 [==============================] - 0s 74us/step - loss: 0.9553 - acc: 0.4802\n",
            "Epoch 8/80\n",
            "202/202 [==============================] - 0s 68us/step - loss: 0.9277 - acc: 0.4901\n",
            "Epoch 9/80\n",
            "202/202 [==============================] - 0s 66us/step - loss: 0.9019 - acc: 0.5050\n",
            "Epoch 10/80\n",
            "202/202 [==============================] - 0s 64us/step - loss: 0.8772 - acc: 0.5149\n",
            "Epoch 11/80\n",
            "202/202 [==============================] - 0s 64us/step - loss: 0.8519 - acc: 0.5248\n",
            "Epoch 12/80\n",
            "202/202 [==============================] - 0s 66us/step - loss: 0.8298 - acc: 0.5446\n",
            "Epoch 13/80\n",
            "202/202 [==============================] - 0s 79us/step - loss: 0.8075 - acc: 0.5446\n",
            "Epoch 14/80\n",
            "202/202 [==============================] - 0s 84us/step - loss: 0.7879 - acc: 0.5545\n",
            "Epoch 15/80\n",
            "202/202 [==============================] - 0s 68us/step - loss: 0.7671 - acc: 0.5545\n",
            "Epoch 16/80\n",
            "202/202 [==============================] - 0s 83us/step - loss: 0.7464 - acc: 0.5743\n",
            "Epoch 17/80\n",
            "202/202 [==============================] - 0s 67us/step - loss: 0.7269 - acc: 0.5842\n",
            "Epoch 18/80\n",
            "202/202 [==============================] - 0s 80us/step - loss: 0.7087 - acc: 0.5842\n",
            "Epoch 19/80\n",
            "202/202 [==============================] - 0s 71us/step - loss: 0.6923 - acc: 0.5990\n",
            "Epoch 20/80\n",
            "202/202 [==============================] - 0s 80us/step - loss: 0.6770 - acc: 0.6089\n",
            "Epoch 21/80\n",
            "202/202 [==============================] - 0s 55us/step - loss: 0.6609 - acc: 0.6089\n",
            "Epoch 22/80\n",
            "202/202 [==============================] - 0s 63us/step - loss: 0.6464 - acc: 0.6089\n",
            "Epoch 23/80\n",
            "202/202 [==============================] - 0s 75us/step - loss: 0.6323 - acc: 0.6238\n",
            "Epoch 24/80\n",
            "202/202 [==============================] - 0s 175us/step - loss: 0.6193 - acc: 0.6287\n",
            "Epoch 25/80\n",
            "202/202 [==============================] - 0s 76us/step - loss: 0.6048 - acc: 0.6485\n",
            "Epoch 26/80\n",
            "202/202 [==============================] - 0s 81us/step - loss: 0.5918 - acc: 0.6584\n",
            "Epoch 27/80\n",
            "202/202 [==============================] - 0s 105us/step - loss: 0.5792 - acc: 0.6931\n",
            "Epoch 28/80\n",
            "202/202 [==============================] - 0s 76us/step - loss: 0.5685 - acc: 0.7129\n",
            "Epoch 29/80\n",
            "202/202 [==============================] - 0s 78us/step - loss: 0.5571 - acc: 0.7178\n",
            "Epoch 30/80\n",
            "202/202 [==============================] - 0s 97us/step - loss: 0.5465 - acc: 0.7376\n",
            "Epoch 31/80\n",
            "202/202 [==============================] - 0s 77us/step - loss: 0.5361 - acc: 0.7475\n",
            "Epoch 32/80\n",
            "202/202 [==============================] - 0s 73us/step - loss: 0.5257 - acc: 0.7525\n",
            "Epoch 33/80\n",
            "202/202 [==============================] - 0s 71us/step - loss: 0.5156 - acc: 0.7673\n",
            "Epoch 34/80\n",
            "202/202 [==============================] - 0s 67us/step - loss: 0.5064 - acc: 0.7772\n",
            "Epoch 35/80\n",
            "202/202 [==============================] - 0s 71us/step - loss: 0.4974 - acc: 0.7772\n",
            "Epoch 36/80\n",
            "202/202 [==============================] - 0s 96us/step - loss: 0.4888 - acc: 0.7871\n",
            "Epoch 37/80\n",
            "202/202 [==============================] - 0s 88us/step - loss: 0.4804 - acc: 0.7921\n",
            "Epoch 38/80\n",
            "202/202 [==============================] - 0s 68us/step - loss: 0.4722 - acc: 0.8020\n",
            "Epoch 39/80\n",
            "202/202 [==============================] - 0s 69us/step - loss: 0.4637 - acc: 0.8069\n",
            "Epoch 40/80\n",
            "202/202 [==============================] - 0s 76us/step - loss: 0.4561 - acc: 0.8069\n",
            "Epoch 41/80\n",
            "202/202 [==============================] - 0s 69us/step - loss: 0.4482 - acc: 0.8119\n",
            "Epoch 42/80\n",
            "202/202 [==============================] - 0s 77us/step - loss: 0.4414 - acc: 0.8119\n",
            "Epoch 43/80\n",
            "202/202 [==============================] - 0s 76us/step - loss: 0.4351 - acc: 0.8069\n",
            "Epoch 44/80\n",
            "202/202 [==============================] - 0s 69us/step - loss: 0.4286 - acc: 0.8069\n",
            "Epoch 45/80\n",
            "202/202 [==============================] - 0s 88us/step - loss: 0.4221 - acc: 0.8119\n",
            "Epoch 46/80\n",
            "202/202 [==============================] - 0s 87us/step - loss: 0.4164 - acc: 0.8317\n",
            "Epoch 47/80\n",
            "202/202 [==============================] - 0s 72us/step - loss: 0.4105 - acc: 0.8366\n",
            "Epoch 48/80\n",
            "202/202 [==============================] - 0s 78us/step - loss: 0.4051 - acc: 0.8465\n",
            "Epoch 49/80\n",
            "202/202 [==============================] - 0s 92us/step - loss: 0.4003 - acc: 0.8465\n",
            "Epoch 50/80\n",
            "202/202 [==============================] - 0s 78us/step - loss: 0.3957 - acc: 0.8515\n",
            "Epoch 51/80\n",
            "202/202 [==============================] - 0s 71us/step - loss: 0.3913 - acc: 0.8515\n",
            "Epoch 52/80\n",
            "202/202 [==============================] - 0s 66us/step - loss: 0.3871 - acc: 0.8564\n",
            "Epoch 53/80\n",
            "202/202 [==============================] - 0s 70us/step - loss: 0.3835 - acc: 0.8564\n",
            "Epoch 54/80\n",
            "202/202 [==============================] - 0s 66us/step - loss: 0.3797 - acc: 0.8564\n",
            "Epoch 55/80\n",
            "202/202 [==============================] - 0s 73us/step - loss: 0.3763 - acc: 0.8663\n",
            "Epoch 56/80\n",
            "202/202 [==============================] - 0s 84us/step - loss: 0.3725 - acc: 0.8663\n",
            "Epoch 57/80\n",
            "202/202 [==============================] - 0s 72us/step - loss: 0.3692 - acc: 0.8663\n",
            "Epoch 58/80\n",
            "202/202 [==============================] - 0s 89us/step - loss: 0.3658 - acc: 0.8663\n",
            "Epoch 59/80\n",
            "202/202 [==============================] - 0s 70us/step - loss: 0.3622 - acc: 0.8614\n",
            "Epoch 60/80\n",
            "202/202 [==============================] - 0s 99us/step - loss: 0.3591 - acc: 0.8663\n",
            "Epoch 61/80\n",
            "202/202 [==============================] - 0s 73us/step - loss: 0.3564 - acc: 0.8713\n",
            "Epoch 62/80\n",
            "202/202 [==============================] - 0s 70us/step - loss: 0.3537 - acc: 0.8713\n",
            "Epoch 63/80\n",
            "202/202 [==============================] - 0s 89us/step - loss: 0.3511 - acc: 0.8713\n",
            "Epoch 64/80\n",
            "202/202 [==============================] - 0s 68us/step - loss: 0.3488 - acc: 0.8713\n",
            "Epoch 65/80\n",
            "202/202 [==============================] - 0s 83us/step - loss: 0.3462 - acc: 0.8713\n",
            "Epoch 66/80\n",
            "202/202 [==============================] - 0s 110us/step - loss: 0.3440 - acc: 0.8713\n",
            "Epoch 67/80\n",
            "202/202 [==============================] - 0s 77us/step - loss: 0.3418 - acc: 0.8713\n",
            "Epoch 68/80\n",
            "202/202 [==============================] - 0s 72us/step - loss: 0.3397 - acc: 0.8713\n",
            "Epoch 69/80\n",
            "202/202 [==============================] - 0s 106us/step - loss: 0.3374 - acc: 0.8762\n",
            "Epoch 70/80\n",
            "202/202 [==============================] - 0s 65us/step - loss: 0.3353 - acc: 0.8762\n",
            "Epoch 71/80\n",
            "202/202 [==============================] - 0s 69us/step - loss: 0.3332 - acc: 0.8762\n",
            "Epoch 72/80\n",
            "202/202 [==============================] - 0s 81us/step - loss: 0.3315 - acc: 0.8762\n",
            "Epoch 73/80\n",
            "202/202 [==============================] - 0s 78us/step - loss: 0.3294 - acc: 0.8812\n",
            "Epoch 74/80\n",
            "202/202 [==============================] - 0s 80us/step - loss: 0.3274 - acc: 0.8812\n",
            "Epoch 75/80\n",
            "202/202 [==============================] - 0s 82us/step - loss: 0.3255 - acc: 0.8812\n",
            "Epoch 76/80\n",
            "202/202 [==============================] - 0s 71us/step - loss: 0.3236 - acc: 0.8861\n",
            "Epoch 77/80\n",
            "202/202 [==============================] - 0s 80us/step - loss: 0.3222 - acc: 0.8861\n",
            "Epoch 78/80\n",
            "202/202 [==============================] - 0s 66us/step - loss: 0.3204 - acc: 0.8861\n",
            "Epoch 79/80\n",
            "202/202 [==============================] - 0s 67us/step - loss: 0.3188 - acc: 0.8861\n",
            "Epoch 80/80\n",
            "202/202 [==============================] - 0s 76us/step - loss: 0.3174 - acc: 0.8861\n",
            "101/101 [==============================] - 1s 7ms/step\n",
            "Epoch 1/80\n",
            "202/202 [==============================] - 2s 8ms/step - loss: 0.5902 - acc: 0.6683\n",
            "Epoch 2/80\n",
            "202/202 [==============================] - 0s 73us/step - loss: 0.5731 - acc: 0.7030\n",
            "Epoch 3/80\n",
            "202/202 [==============================] - 0s 69us/step - loss: 0.5573 - acc: 0.7178\n",
            "Epoch 4/80\n",
            "202/202 [==============================] - 0s 71us/step - loss: 0.5429 - acc: 0.7228\n",
            "Epoch 5/80\n",
            "202/202 [==============================] - 0s 80us/step - loss: 0.5290 - acc: 0.7426\n",
            "Epoch 6/80\n",
            "202/202 [==============================] - 0s 64us/step - loss: 0.5156 - acc: 0.7574\n",
            "Epoch 7/80\n",
            "202/202 [==============================] - 0s 63us/step - loss: 0.5029 - acc: 0.7723\n",
            "Epoch 8/80\n",
            "202/202 [==============================] - 0s 64us/step - loss: 0.4906 - acc: 0.7871\n",
            "Epoch 9/80\n",
            "202/202 [==============================] - 0s 64us/step - loss: 0.4775 - acc: 0.8069\n",
            "Epoch 10/80\n",
            "202/202 [==============================] - 0s 95us/step - loss: 0.4644 - acc: 0.8069\n",
            "Epoch 11/80\n",
            "202/202 [==============================] - 0s 98us/step - loss: 0.4520 - acc: 0.8218\n",
            "Epoch 12/80\n",
            "202/202 [==============================] - 0s 73us/step - loss: 0.4396 - acc: 0.8317\n",
            "Epoch 13/80\n",
            "202/202 [==============================] - 0s 74us/step - loss: 0.4285 - acc: 0.8416\n",
            "Epoch 14/80\n",
            "202/202 [==============================] - 0s 69us/step - loss: 0.4181 - acc: 0.8416\n",
            "Epoch 15/80\n",
            "202/202 [==============================] - 0s 90us/step - loss: 0.4091 - acc: 0.8465\n",
            "Epoch 16/80\n",
            "202/202 [==============================] - 0s 76us/step - loss: 0.4004 - acc: 0.8515\n",
            "Epoch 17/80\n",
            "202/202 [==============================] - 0s 86us/step - loss: 0.3919 - acc: 0.8515\n",
            "Epoch 18/80\n",
            "202/202 [==============================] - 0s 75us/step - loss: 0.3842 - acc: 0.8564\n",
            "Epoch 19/80\n",
            "202/202 [==============================] - 0s 66us/step - loss: 0.3775 - acc: 0.8663\n",
            "Epoch 20/80\n",
            "202/202 [==============================] - 0s 79us/step - loss: 0.3706 - acc: 0.8663\n",
            "Epoch 21/80\n",
            "202/202 [==============================] - 0s 128us/step - loss: 0.3648 - acc: 0.8713\n",
            "Epoch 22/80\n",
            "202/202 [==============================] - 0s 84us/step - loss: 0.3592 - acc: 0.8713\n",
            "Epoch 23/80\n",
            "202/202 [==============================] - 0s 87us/step - loss: 0.3540 - acc: 0.8713\n",
            "Epoch 24/80\n",
            "202/202 [==============================] - 0s 70us/step - loss: 0.3487 - acc: 0.8762\n",
            "Epoch 25/80\n",
            "202/202 [==============================] - 0s 75us/step - loss: 0.3436 - acc: 0.8812\n",
            "Epoch 26/80\n",
            "202/202 [==============================] - 0s 96us/step - loss: 0.3387 - acc: 0.8812\n",
            "Epoch 27/80\n",
            "202/202 [==============================] - 0s 75us/step - loss: 0.3340 - acc: 0.8812\n",
            "Epoch 28/80\n",
            "202/202 [==============================] - 0s 85us/step - loss: 0.3298 - acc: 0.8812\n",
            "Epoch 29/80\n",
            "202/202 [==============================] - 0s 83us/step - loss: 0.3258 - acc: 0.8812\n",
            "Epoch 30/80\n",
            "202/202 [==============================] - 0s 77us/step - loss: 0.3221 - acc: 0.8812\n",
            "Epoch 31/80\n",
            "202/202 [==============================] - 0s 89us/step - loss: 0.3184 - acc: 0.8812\n",
            "Epoch 32/80\n",
            "202/202 [==============================] - 0s 81us/step - loss: 0.3150 - acc: 0.8762\n",
            "Epoch 33/80\n",
            "202/202 [==============================] - 0s 97us/step - loss: 0.3117 - acc: 0.8812\n",
            "Epoch 34/80\n",
            "202/202 [==============================] - 0s 78us/step - loss: 0.3086 - acc: 0.8812\n",
            "Epoch 35/80\n",
            "202/202 [==============================] - 0s 73us/step - loss: 0.3058 - acc: 0.8812\n",
            "Epoch 36/80\n",
            "202/202 [==============================] - 0s 73us/step - loss: 0.3031 - acc: 0.8812\n",
            "Epoch 37/80\n",
            "202/202 [==============================] - 0s 99us/step - loss: 0.3001 - acc: 0.8861\n",
            "Epoch 38/80\n",
            "202/202 [==============================] - 0s 75us/step - loss: 0.2977 - acc: 0.8861\n",
            "Epoch 39/80\n",
            "202/202 [==============================] - 0s 71us/step - loss: 0.2951 - acc: 0.8861\n",
            "Epoch 40/80\n",
            "202/202 [==============================] - 0s 72us/step - loss: 0.2926 - acc: 0.8861\n",
            "Epoch 41/80\n",
            "202/202 [==============================] - 0s 94us/step - loss: 0.2899 - acc: 0.8861\n",
            "Epoch 42/80\n",
            "202/202 [==============================] - 0s 73us/step - loss: 0.2881 - acc: 0.8812\n",
            "Epoch 43/80\n",
            "202/202 [==============================] - 0s 100us/step - loss: 0.2865 - acc: 0.8812\n",
            "Epoch 44/80\n",
            "202/202 [==============================] - 0s 94us/step - loss: 0.2844 - acc: 0.8812\n",
            "Epoch 45/80\n",
            "202/202 [==============================] - 0s 92us/step - loss: 0.2827 - acc: 0.8812\n",
            "Epoch 46/80\n",
            "202/202 [==============================] - 0s 68us/step - loss: 0.2807 - acc: 0.8812\n",
            "Epoch 47/80\n",
            "202/202 [==============================] - 0s 73us/step - loss: 0.2790 - acc: 0.8812\n",
            "Epoch 48/80\n",
            "202/202 [==============================] - 0s 74us/step - loss: 0.2770 - acc: 0.8812\n",
            "Epoch 49/80\n",
            "202/202 [==============================] - 0s 120us/step - loss: 0.2754 - acc: 0.8812\n",
            "Epoch 50/80\n",
            "202/202 [==============================] - 0s 75us/step - loss: 0.2735 - acc: 0.8812\n",
            "Epoch 51/80\n",
            "202/202 [==============================] - 0s 73us/step - loss: 0.2718 - acc: 0.8812\n",
            "Epoch 52/80\n",
            "202/202 [==============================] - 0s 71us/step - loss: 0.2702 - acc: 0.8861\n",
            "Epoch 53/80\n",
            "202/202 [==============================] - 0s 85us/step - loss: 0.2684 - acc: 0.8861\n",
            "Epoch 54/80\n",
            "202/202 [==============================] - 0s 77us/step - loss: 0.2670 - acc: 0.8861\n",
            "Epoch 55/80\n",
            "202/202 [==============================] - 0s 75us/step - loss: 0.2655 - acc: 0.8861\n",
            "Epoch 56/80\n",
            "202/202 [==============================] - 0s 80us/step - loss: 0.2641 - acc: 0.8861\n",
            "Epoch 57/80\n",
            "202/202 [==============================] - 0s 77us/step - loss: 0.2628 - acc: 0.8911\n",
            "Epoch 58/80\n",
            "202/202 [==============================] - 0s 69us/step - loss: 0.2614 - acc: 0.8911\n",
            "Epoch 59/80\n",
            "202/202 [==============================] - 0s 74us/step - loss: 0.2601 - acc: 0.8911\n",
            "Epoch 60/80\n",
            "202/202 [==============================] - 0s 73us/step - loss: 0.2587 - acc: 0.8960\n",
            "Epoch 61/80\n",
            "202/202 [==============================] - 0s 95us/step - loss: 0.2573 - acc: 0.8960\n",
            "Epoch 62/80\n",
            "202/202 [==============================] - 0s 93us/step - loss: 0.2562 - acc: 0.8960\n",
            "Epoch 63/80\n",
            "202/202 [==============================] - 0s 71us/step - loss: 0.2547 - acc: 0.8960\n",
            "Epoch 64/80\n",
            "202/202 [==============================] - 0s 89us/step - loss: 0.2535 - acc: 0.8960\n",
            "Epoch 65/80\n",
            "202/202 [==============================] - 0s 69us/step - loss: 0.2524 - acc: 0.8960\n",
            "Epoch 66/80\n",
            "202/202 [==============================] - 0s 78us/step - loss: 0.2512 - acc: 0.8960\n",
            "Epoch 67/80\n",
            "202/202 [==============================] - 0s 74us/step - loss: 0.2500 - acc: 0.8960\n",
            "Epoch 68/80\n",
            "202/202 [==============================] - 0s 74us/step - loss: 0.2487 - acc: 0.8960\n",
            "Epoch 69/80\n",
            "202/202 [==============================] - 0s 67us/step - loss: 0.2477 - acc: 0.9010\n",
            "Epoch 70/80\n",
            "202/202 [==============================] - 0s 76us/step - loss: 0.2465 - acc: 0.9010\n",
            "Epoch 71/80\n",
            "202/202 [==============================] - 0s 87us/step - loss: 0.2455 - acc: 0.9010\n",
            "Epoch 72/80\n",
            "202/202 [==============================] - 0s 77us/step - loss: 0.2446 - acc: 0.9010\n",
            "Epoch 73/80\n",
            "202/202 [==============================] - 0s 85us/step - loss: 0.2433 - acc: 0.9010\n",
            "Epoch 74/80\n",
            "202/202 [==============================] - 0s 93us/step - loss: 0.2423 - acc: 0.9010\n",
            "Epoch 75/80\n",
            "202/202 [==============================] - 0s 74us/step - loss: 0.2413 - acc: 0.9010\n",
            "Epoch 76/80\n",
            "202/202 [==============================] - 0s 75us/step - loss: 0.2403 - acc: 0.9010\n",
            "Epoch 77/80\n",
            "202/202 [==============================] - 0s 69us/step - loss: 0.2399 - acc: 0.9010\n",
            "Epoch 78/80\n",
            "202/202 [==============================] - 0s 71us/step - loss: 0.2389 - acc: 0.9010\n",
            "Epoch 79/80\n",
            "202/202 [==============================] - 0s 70us/step - loss: 0.2381 - acc: 0.9010\n",
            "Epoch 80/80\n",
            "202/202 [==============================] - 0s 70us/step - loss: 0.2373 - acc: 0.9010\n",
            "101/101 [==============================] - 1s 7ms/step\n",
            "Epoch 1/100\n",
            "202/202 [==============================] - 2s 9ms/step - loss: 0.7891 - acc: 0.4505\n",
            "Epoch 2/100\n",
            "202/202 [==============================] - 0s 86us/step - loss: 0.7644 - acc: 0.4505\n",
            "Epoch 3/100\n",
            "202/202 [==============================] - 0s 78us/step - loss: 0.7411 - acc: 0.4653\n",
            "Epoch 4/100\n",
            "202/202 [==============================] - 0s 78us/step - loss: 0.7189 - acc: 0.4752\n",
            "Epoch 5/100\n",
            "202/202 [==============================] - 0s 116us/step - loss: 0.7002 - acc: 0.5000\n",
            "Epoch 6/100\n",
            "202/202 [==============================] - 0s 94us/step - loss: 0.6853 - acc: 0.5347\n",
            "Epoch 7/100\n",
            "202/202 [==============================] - 0s 72us/step - loss: 0.6701 - acc: 0.5693\n",
            "Epoch 8/100\n",
            "202/202 [==============================] - 0s 82us/step - loss: 0.6539 - acc: 0.5941\n",
            "Epoch 9/100\n",
            "202/202 [==============================] - 0s 78us/step - loss: 0.6385 - acc: 0.5990\n",
            "Epoch 10/100\n",
            "202/202 [==============================] - 0s 78us/step - loss: 0.6243 - acc: 0.6188\n",
            "Epoch 11/100\n",
            "202/202 [==============================] - 0s 76us/step - loss: 0.6114 - acc: 0.6535\n",
            "Epoch 12/100\n",
            "202/202 [==============================] - 0s 91us/step - loss: 0.5990 - acc: 0.6782\n",
            "Epoch 13/100\n",
            "202/202 [==============================] - 0s 73us/step - loss: 0.5868 - acc: 0.6931\n",
            "Epoch 14/100\n",
            "202/202 [==============================] - 0s 72us/step - loss: 0.5749 - acc: 0.7079\n",
            "Epoch 15/100\n",
            "202/202 [==============================] - 0s 76us/step - loss: 0.5633 - acc: 0.7178\n",
            "Epoch 16/100\n",
            "202/202 [==============================] - 0s 89us/step - loss: 0.5515 - acc: 0.7475\n",
            "Epoch 17/100\n",
            "202/202 [==============================] - 0s 93us/step - loss: 0.5400 - acc: 0.7525\n",
            "Epoch 18/100\n",
            "202/202 [==============================] - 0s 76us/step - loss: 0.5296 - acc: 0.7574\n",
            "Epoch 19/100\n",
            "202/202 [==============================] - 0s 87us/step - loss: 0.5192 - acc: 0.7624\n",
            "Epoch 20/100\n",
            "202/202 [==============================] - 0s 140us/step - loss: 0.5101 - acc: 0.7772\n",
            "Epoch 21/100\n",
            "202/202 [==============================] - 0s 86us/step - loss: 0.5012 - acc: 0.7871\n",
            "Epoch 22/100\n",
            "202/202 [==============================] - 0s 86us/step - loss: 0.4938 - acc: 0.7871\n",
            "Epoch 23/100\n",
            "202/202 [==============================] - 0s 79us/step - loss: 0.4866 - acc: 0.7871\n",
            "Epoch 24/100\n",
            "202/202 [==============================] - 0s 85us/step - loss: 0.4789 - acc: 0.7921\n",
            "Epoch 25/100\n",
            "202/202 [==============================] - 0s 97us/step - loss: 0.4715 - acc: 0.8069\n",
            "Epoch 26/100\n",
            "202/202 [==============================] - 0s 79us/step - loss: 0.4635 - acc: 0.8119\n",
            "Epoch 27/100\n",
            "202/202 [==============================] - 0s 110us/step - loss: 0.4564 - acc: 0.8168\n",
            "Epoch 28/100\n",
            "202/202 [==============================] - 0s 77us/step - loss: 0.4494 - acc: 0.8168\n",
            "Epoch 29/100\n",
            "202/202 [==============================] - 0s 83us/step - loss: 0.4431 - acc: 0.8267\n",
            "Epoch 30/100\n",
            "202/202 [==============================] - 0s 86us/step - loss: 0.4369 - acc: 0.8366\n",
            "Epoch 31/100\n",
            "202/202 [==============================] - 0s 74us/step - loss: 0.4304 - acc: 0.8416\n",
            "Epoch 32/100\n",
            "202/202 [==============================] - 0s 70us/step - loss: 0.4243 - acc: 0.8416\n",
            "Epoch 33/100\n",
            "202/202 [==============================] - 0s 69us/step - loss: 0.4185 - acc: 0.8416\n",
            "Epoch 34/100\n",
            "202/202 [==============================] - 0s 77us/step - loss: 0.4134 - acc: 0.8416\n",
            "Epoch 35/100\n",
            "202/202 [==============================] - 0s 95us/step - loss: 0.4085 - acc: 0.8465\n",
            "Epoch 36/100\n",
            "202/202 [==============================] - 0s 109us/step - loss: 0.4038 - acc: 0.8465\n",
            "Epoch 37/100\n",
            "202/202 [==============================] - 0s 87us/step - loss: 0.3991 - acc: 0.8465\n",
            "Epoch 38/100\n",
            "202/202 [==============================] - 0s 88us/step - loss: 0.3950 - acc: 0.8465\n",
            "Epoch 39/100\n",
            "202/202 [==============================] - 0s 82us/step - loss: 0.3913 - acc: 0.8515\n",
            "Epoch 40/100\n",
            "202/202 [==============================] - 0s 95us/step - loss: 0.3880 - acc: 0.8614\n",
            "Epoch 41/100\n",
            "202/202 [==============================] - 0s 86us/step - loss: 0.3846 - acc: 0.8614\n",
            "Epoch 42/100\n",
            "202/202 [==============================] - 0s 85us/step - loss: 0.3811 - acc: 0.8614\n",
            "Epoch 43/100\n",
            "202/202 [==============================] - 0s 73us/step - loss: 0.3775 - acc: 0.8614\n",
            "Epoch 44/100\n",
            "202/202 [==============================] - 0s 94us/step - loss: 0.3740 - acc: 0.8564\n",
            "Epoch 45/100\n",
            "202/202 [==============================] - 0s 86us/step - loss: 0.3706 - acc: 0.8564\n",
            "Epoch 46/100\n",
            "202/202 [==============================] - 0s 99us/step - loss: 0.3671 - acc: 0.8614\n",
            "Epoch 47/100\n",
            "202/202 [==============================] - 0s 79us/step - loss: 0.3643 - acc: 0.8614\n",
            "Epoch 48/100\n",
            "202/202 [==============================] - 0s 76us/step - loss: 0.3618 - acc: 0.8614\n",
            "Epoch 49/100\n",
            "202/202 [==============================] - 0s 88us/step - loss: 0.3592 - acc: 0.8663\n",
            "Epoch 50/100\n",
            "202/202 [==============================] - 0s 88us/step - loss: 0.3565 - acc: 0.8713\n",
            "Epoch 51/100\n",
            "202/202 [==============================] - 0s 114us/step - loss: 0.3539 - acc: 0.8713\n",
            "Epoch 52/100\n",
            "202/202 [==============================] - 0s 84us/step - loss: 0.3513 - acc: 0.8713\n",
            "Epoch 53/100\n",
            "202/202 [==============================] - 0s 74us/step - loss: 0.3489 - acc: 0.8713\n",
            "Epoch 54/100\n",
            "202/202 [==============================] - 0s 100us/step - loss: 0.3462 - acc: 0.8713\n",
            "Epoch 55/100\n",
            "202/202 [==============================] - 0s 88us/step - loss: 0.3438 - acc: 0.8713\n",
            "Epoch 56/100\n",
            "202/202 [==============================] - 0s 105us/step - loss: 0.3415 - acc: 0.8713\n",
            "Epoch 57/100\n",
            "202/202 [==============================] - 0s 90us/step - loss: 0.3394 - acc: 0.8713\n",
            "Epoch 58/100\n",
            "202/202 [==============================] - 0s 99us/step - loss: 0.3369 - acc: 0.8713\n",
            "Epoch 59/100\n",
            "202/202 [==============================] - 0s 82us/step - loss: 0.3357 - acc: 0.8762\n",
            "Epoch 60/100\n",
            "202/202 [==============================] - 0s 98us/step - loss: 0.3338 - acc: 0.8762\n",
            "Epoch 61/100\n",
            "202/202 [==============================] - 0s 104us/step - loss: 0.3320 - acc: 0.8713\n",
            "Epoch 62/100\n",
            "202/202 [==============================] - 0s 78us/step - loss: 0.3301 - acc: 0.8663\n",
            "Epoch 63/100\n",
            "202/202 [==============================] - 0s 76us/step - loss: 0.3283 - acc: 0.8663\n",
            "Epoch 64/100\n",
            "202/202 [==============================] - 0s 81us/step - loss: 0.3263 - acc: 0.8614\n",
            "Epoch 65/100\n",
            "202/202 [==============================] - 0s 173us/step - loss: 0.3245 - acc: 0.8663\n",
            "Epoch 66/100\n",
            "202/202 [==============================] - 0s 90us/step - loss: 0.3230 - acc: 0.8663\n",
            "Epoch 67/100\n",
            "202/202 [==============================] - 0s 97us/step - loss: 0.3213 - acc: 0.8713\n",
            "Epoch 68/100\n",
            "202/202 [==============================] - 0s 96us/step - loss: 0.3202 - acc: 0.8663\n",
            "Epoch 69/100\n",
            "202/202 [==============================] - 0s 100us/step - loss: 0.3186 - acc: 0.8663\n",
            "Epoch 70/100\n",
            "202/202 [==============================] - 0s 91us/step - loss: 0.3174 - acc: 0.8713\n",
            "Epoch 71/100\n",
            "202/202 [==============================] - 0s 91us/step - loss: 0.3160 - acc: 0.8713\n",
            "Epoch 72/100\n",
            "202/202 [==============================] - 0s 93us/step - loss: 0.3146 - acc: 0.8713\n",
            "Epoch 73/100\n",
            "202/202 [==============================] - 0s 85us/step - loss: 0.3136 - acc: 0.8713\n",
            "Epoch 74/100\n",
            "202/202 [==============================] - 0s 95us/step - loss: 0.3127 - acc: 0.8713\n",
            "Epoch 75/100\n",
            "202/202 [==============================] - 0s 89us/step - loss: 0.3116 - acc: 0.8713\n",
            "Epoch 76/100\n",
            "202/202 [==============================] - 0s 87us/step - loss: 0.3104 - acc: 0.8713\n",
            "Epoch 77/100\n",
            "202/202 [==============================] - 0s 75us/step - loss: 0.3092 - acc: 0.8713\n",
            "Epoch 78/100\n",
            "202/202 [==============================] - 0s 88us/step - loss: 0.3081 - acc: 0.8762\n",
            "Epoch 79/100\n",
            "202/202 [==============================] - 0s 84us/step - loss: 0.3068 - acc: 0.8762\n",
            "Epoch 80/100\n",
            "202/202 [==============================] - 0s 76us/step - loss: 0.3055 - acc: 0.8762\n",
            "Epoch 81/100\n",
            "202/202 [==============================] - 0s 103us/step - loss: 0.3043 - acc: 0.8762\n",
            "Epoch 82/100\n",
            "202/202 [==============================] - 0s 83us/step - loss: 0.3032 - acc: 0.8762\n",
            "Epoch 83/100\n",
            "202/202 [==============================] - 0s 86us/step - loss: 0.3023 - acc: 0.8762\n",
            "Epoch 84/100\n",
            "202/202 [==============================] - 0s 71us/step - loss: 0.3012 - acc: 0.8762\n",
            "Epoch 85/100\n",
            "202/202 [==============================] - 0s 75us/step - loss: 0.3003 - acc: 0.8762\n",
            "Epoch 86/100\n",
            "202/202 [==============================] - 0s 87us/step - loss: 0.2994 - acc: 0.8713\n",
            "Epoch 87/100\n",
            "202/202 [==============================] - 0s 79us/step - loss: 0.2985 - acc: 0.8713\n",
            "Epoch 88/100\n",
            "202/202 [==============================] - 0s 78us/step - loss: 0.2978 - acc: 0.8713\n",
            "Epoch 89/100\n",
            "202/202 [==============================] - 0s 89us/step - loss: 0.2969 - acc: 0.8663\n",
            "Epoch 90/100\n",
            "202/202 [==============================] - 0s 79us/step - loss: 0.2961 - acc: 0.8713\n",
            "Epoch 91/100\n",
            "202/202 [==============================] - 0s 81us/step - loss: 0.2953 - acc: 0.8713\n",
            "Epoch 92/100\n",
            "202/202 [==============================] - 0s 91us/step - loss: 0.2945 - acc: 0.8713\n",
            "Epoch 93/100\n",
            "202/202 [==============================] - 0s 75us/step - loss: 0.2937 - acc: 0.8713\n",
            "Epoch 94/100\n",
            "202/202 [==============================] - 0s 87us/step - loss: 0.2930 - acc: 0.8713\n",
            "Epoch 95/100\n",
            "202/202 [==============================] - 0s 92us/step - loss: 0.2923 - acc: 0.8713\n",
            "Epoch 96/100\n",
            "202/202 [==============================] - 0s 137us/step - loss: 0.2917 - acc: 0.8713\n",
            "Epoch 97/100\n",
            "202/202 [==============================] - 0s 103us/step - loss: 0.2908 - acc: 0.8713\n",
            "Epoch 98/100\n",
            "202/202 [==============================] - 0s 73us/step - loss: 0.2905 - acc: 0.8762\n",
            "Epoch 99/100\n",
            "202/202 [==============================] - 0s 83us/step - loss: 0.2895 - acc: 0.8762\n",
            "Epoch 100/100\n",
            "202/202 [==============================] - 0s 73us/step - loss: 0.2889 - acc: 0.8762\n",
            "101/101 [==============================] - 1s 7ms/step\n",
            "Epoch 1/100\n",
            "202/202 [==============================] - 2s 9ms/step - loss: 0.5556 - acc: 0.7426\n",
            "Epoch 2/100\n",
            "202/202 [==============================] - 0s 87us/step - loss: 0.5423 - acc: 0.7426\n",
            "Epoch 3/100\n",
            "202/202 [==============================] - 0s 68us/step - loss: 0.5311 - acc: 0.7574\n",
            "Epoch 4/100\n",
            "202/202 [==============================] - 0s 71us/step - loss: 0.5203 - acc: 0.7723\n",
            "Epoch 5/100\n",
            "202/202 [==============================] - 0s 70us/step - loss: 0.5117 - acc: 0.7772\n",
            "Epoch 6/100\n",
            "202/202 [==============================] - 0s 66us/step - loss: 0.5032 - acc: 0.7921\n",
            "Epoch 7/100\n",
            "202/202 [==============================] - 0s 67us/step - loss: 0.4960 - acc: 0.7970\n",
            "Epoch 8/100\n",
            "202/202 [==============================] - 0s 71us/step - loss: 0.4887 - acc: 0.8020\n",
            "Epoch 9/100\n",
            "202/202 [==============================] - 0s 81us/step - loss: 0.4819 - acc: 0.8069\n",
            "Epoch 10/100\n",
            "202/202 [==============================] - 0s 72us/step - loss: 0.4761 - acc: 0.8119\n",
            "Epoch 11/100\n",
            "202/202 [==============================] - 0s 79us/step - loss: 0.4708 - acc: 0.8168\n",
            "Epoch 12/100\n",
            "202/202 [==============================] - 0s 74us/step - loss: 0.4653 - acc: 0.8069\n",
            "Epoch 13/100\n",
            "202/202 [==============================] - 0s 75us/step - loss: 0.4602 - acc: 0.8168\n",
            "Epoch 14/100\n",
            "202/202 [==============================] - 0s 80us/step - loss: 0.4557 - acc: 0.8218\n",
            "Epoch 15/100\n",
            "202/202 [==============================] - 0s 75us/step - loss: 0.4508 - acc: 0.8168\n",
            "Epoch 16/100\n",
            "202/202 [==============================] - 0s 72us/step - loss: 0.4462 - acc: 0.8168\n",
            "Epoch 17/100\n",
            "202/202 [==============================] - 0s 92us/step - loss: 0.4421 - acc: 0.8168\n",
            "Epoch 18/100\n",
            "202/202 [==============================] - 0s 86us/step - loss: 0.4378 - acc: 0.8218\n",
            "Epoch 19/100\n",
            "202/202 [==============================] - 0s 74us/step - loss: 0.4337 - acc: 0.8267\n",
            "Epoch 20/100\n",
            "202/202 [==============================] - 0s 71us/step - loss: 0.4302 - acc: 0.8317\n",
            "Epoch 21/100\n",
            "202/202 [==============================] - 0s 73us/step - loss: 0.4264 - acc: 0.8317\n",
            "Epoch 22/100\n",
            "202/202 [==============================] - 0s 86us/step - loss: 0.4226 - acc: 0.8366\n",
            "Epoch 23/100\n",
            "202/202 [==============================] - 0s 98us/step - loss: 0.4189 - acc: 0.8366\n",
            "Epoch 24/100\n",
            "202/202 [==============================] - 0s 87us/step - loss: 0.4156 - acc: 0.8366\n",
            "Epoch 25/100\n",
            "202/202 [==============================] - 0s 91us/step - loss: 0.4125 - acc: 0.8366\n",
            "Epoch 26/100\n",
            "202/202 [==============================] - 0s 73us/step - loss: 0.4091 - acc: 0.8366\n",
            "Epoch 27/100\n",
            "202/202 [==============================] - 0s 78us/step - loss: 0.4058 - acc: 0.8366\n",
            "Epoch 28/100\n",
            "202/202 [==============================] - 0s 77us/step - loss: 0.4024 - acc: 0.8416\n",
            "Epoch 29/100\n",
            "202/202 [==============================] - 0s 78us/step - loss: 0.3992 - acc: 0.8416\n",
            "Epoch 30/100\n",
            "202/202 [==============================] - 0s 76us/step - loss: 0.3960 - acc: 0.8416\n",
            "Epoch 31/100\n",
            "202/202 [==============================] - 0s 74us/step - loss: 0.3929 - acc: 0.8416\n",
            "Epoch 32/100\n",
            "202/202 [==============================] - 0s 79us/step - loss: 0.3901 - acc: 0.8416\n",
            "Epoch 33/100\n",
            "202/202 [==============================] - 0s 98us/step - loss: 0.3873 - acc: 0.8416\n",
            "Epoch 34/100\n",
            "202/202 [==============================] - 0s 84us/step - loss: 0.3844 - acc: 0.8465\n",
            "Epoch 35/100\n",
            "202/202 [==============================] - 0s 97us/step - loss: 0.3820 - acc: 0.8416\n",
            "Epoch 36/100\n",
            "202/202 [==============================] - 0s 74us/step - loss: 0.3797 - acc: 0.8465\n",
            "Epoch 37/100\n",
            "202/202 [==============================] - 0s 77us/step - loss: 0.3778 - acc: 0.8465\n",
            "Epoch 38/100\n",
            "202/202 [==============================] - 0s 71us/step - loss: 0.3753 - acc: 0.8515\n",
            "Epoch 39/100\n",
            "202/202 [==============================] - 0s 82us/step - loss: 0.3728 - acc: 0.8515\n",
            "Epoch 40/100\n",
            "202/202 [==============================] - 0s 112us/step - loss: 0.3703 - acc: 0.8515\n",
            "Epoch 41/100\n",
            "202/202 [==============================] - 0s 78us/step - loss: 0.3687 - acc: 0.8515\n",
            "Epoch 42/100\n",
            "202/202 [==============================] - 0s 79us/step - loss: 0.3671 - acc: 0.8614\n",
            "Epoch 43/100\n",
            "202/202 [==============================] - 0s 82us/step - loss: 0.3654 - acc: 0.8614\n",
            "Epoch 44/100\n",
            "202/202 [==============================] - 0s 76us/step - loss: 0.3632 - acc: 0.8663\n",
            "Epoch 45/100\n",
            "202/202 [==============================] - 0s 81us/step - loss: 0.3612 - acc: 0.8663\n",
            "Epoch 46/100\n",
            "202/202 [==============================] - 0s 70us/step - loss: 0.3592 - acc: 0.8663\n",
            "Epoch 47/100\n",
            "202/202 [==============================] - 0s 100us/step - loss: 0.3570 - acc: 0.8663\n",
            "Epoch 48/100\n",
            "202/202 [==============================] - 0s 72us/step - loss: 0.3545 - acc: 0.8663\n",
            "Epoch 49/100\n",
            "202/202 [==============================] - 0s 91us/step - loss: 0.3522 - acc: 0.8614\n",
            "Epoch 50/100\n",
            "202/202 [==============================] - 0s 103us/step - loss: 0.3502 - acc: 0.8614\n",
            "Epoch 51/100\n",
            "202/202 [==============================] - 0s 69us/step - loss: 0.3484 - acc: 0.8614\n",
            "Epoch 52/100\n",
            "202/202 [==============================] - 0s 71us/step - loss: 0.3474 - acc: 0.8614\n",
            "Epoch 53/100\n",
            "202/202 [==============================] - 0s 72us/step - loss: 0.3461 - acc: 0.8614\n",
            "Epoch 54/100\n",
            "202/202 [==============================] - 0s 66us/step - loss: 0.3443 - acc: 0.8663\n",
            "Epoch 55/100\n",
            "202/202 [==============================] - 0s 82us/step - loss: 0.3423 - acc: 0.8663\n",
            "Epoch 56/100\n",
            "202/202 [==============================] - 0s 75us/step - loss: 0.3409 - acc: 0.8663\n",
            "Epoch 57/100\n",
            "202/202 [==============================] - 0s 83us/step - loss: 0.3392 - acc: 0.8663\n",
            "Epoch 58/100\n",
            "202/202 [==============================] - 0s 73us/step - loss: 0.3376 - acc: 0.8663\n",
            "Epoch 59/100\n",
            "202/202 [==============================] - 0s 101us/step - loss: 0.3362 - acc: 0.8663\n",
            "Epoch 60/100\n",
            "202/202 [==============================] - 0s 96us/step - loss: 0.3348 - acc: 0.8663\n",
            "Epoch 61/100\n",
            "202/202 [==============================] - 0s 108us/step - loss: 0.3333 - acc: 0.8713\n",
            "Epoch 62/100\n",
            "202/202 [==============================] - 0s 81us/step - loss: 0.3318 - acc: 0.8713\n",
            "Epoch 63/100\n",
            "202/202 [==============================] - 0s 84us/step - loss: 0.3301 - acc: 0.8663\n",
            "Epoch 64/100\n",
            "202/202 [==============================] - 0s 87us/step - loss: 0.3286 - acc: 0.8663\n",
            "Epoch 65/100\n",
            "202/202 [==============================] - 0s 90us/step - loss: 0.3272 - acc: 0.8663\n",
            "Epoch 66/100\n",
            "202/202 [==============================] - 0s 131us/step - loss: 0.3259 - acc: 0.8663\n",
            "Epoch 67/100\n",
            "202/202 [==============================] - 0s 76us/step - loss: 0.3248 - acc: 0.8663\n",
            "Epoch 68/100\n",
            "202/202 [==============================] - 0s 75us/step - loss: 0.3235 - acc: 0.8663\n",
            "Epoch 69/100\n",
            "202/202 [==============================] - 0s 79us/step - loss: 0.3225 - acc: 0.8614\n",
            "Epoch 70/100\n",
            "202/202 [==============================] - 0s 111us/step - loss: 0.3212 - acc: 0.8614\n",
            "Epoch 71/100\n",
            "202/202 [==============================] - 0s 91us/step - loss: 0.3201 - acc: 0.8663\n",
            "Epoch 72/100\n",
            "202/202 [==============================] - 0s 89us/step - loss: 0.3191 - acc: 0.8663\n",
            "Epoch 73/100\n",
            "202/202 [==============================] - 0s 99us/step - loss: 0.3180 - acc: 0.8663\n",
            "Epoch 74/100\n",
            "202/202 [==============================] - 0s 84us/step - loss: 0.3169 - acc: 0.8663\n",
            "Epoch 75/100\n",
            "202/202 [==============================] - 0s 93us/step - loss: 0.3158 - acc: 0.8713\n",
            "Epoch 76/100\n",
            "202/202 [==============================] - 0s 75us/step - loss: 0.3149 - acc: 0.8812\n",
            "Epoch 77/100\n",
            "202/202 [==============================] - 0s 90us/step - loss: 0.3138 - acc: 0.8911\n",
            "Epoch 78/100\n",
            "202/202 [==============================] - 0s 83us/step - loss: 0.3129 - acc: 0.8911\n",
            "Epoch 79/100\n",
            "202/202 [==============================] - 0s 92us/step - loss: 0.3118 - acc: 0.8911\n",
            "Epoch 80/100\n",
            "202/202 [==============================] - 0s 80us/step - loss: 0.3109 - acc: 0.8911\n",
            "Epoch 81/100\n",
            "202/202 [==============================] - 0s 75us/step - loss: 0.3100 - acc: 0.8911\n",
            "Epoch 82/100\n",
            "202/202 [==============================] - 0s 102us/step - loss: 0.3092 - acc: 0.8911\n",
            "Epoch 83/100\n",
            "202/202 [==============================] - 0s 82us/step - loss: 0.3087 - acc: 0.8911\n",
            "Epoch 84/100\n",
            "202/202 [==============================] - 0s 72us/step - loss: 0.3084 - acc: 0.8812\n",
            "Epoch 85/100\n",
            "202/202 [==============================] - 0s 75us/step - loss: 0.3080 - acc: 0.8812\n",
            "Epoch 86/100\n",
            "202/202 [==============================] - 0s 73us/step - loss: 0.3073 - acc: 0.8812\n",
            "Epoch 87/100\n",
            "202/202 [==============================] - 0s 73us/step - loss: 0.3066 - acc: 0.8812\n",
            "Epoch 88/100\n",
            "202/202 [==============================] - 0s 95us/step - loss: 0.3057 - acc: 0.8812\n",
            "Epoch 89/100\n",
            "202/202 [==============================] - 0s 77us/step - loss: 0.3048 - acc: 0.8861\n",
            "Epoch 90/100\n",
            "202/202 [==============================] - 0s 99us/step - loss: 0.3040 - acc: 0.8861\n",
            "Epoch 91/100\n",
            "202/202 [==============================] - 0s 87us/step - loss: 0.3031 - acc: 0.8861\n",
            "Epoch 92/100\n",
            "202/202 [==============================] - 0s 68us/step - loss: 0.3024 - acc: 0.8861\n",
            "Epoch 93/100\n",
            "202/202 [==============================] - 0s 75us/step - loss: 0.3016 - acc: 0.8861\n",
            "Epoch 94/100\n",
            "202/202 [==============================] - 0s 101us/step - loss: 0.3009 - acc: 0.8861\n",
            "Epoch 95/100\n",
            "202/202 [==============================] - 0s 78us/step - loss: 0.3002 - acc: 0.8861\n",
            "Epoch 96/100\n",
            "202/202 [==============================] - 0s 90us/step - loss: 0.2996 - acc: 0.8861\n",
            "Epoch 97/100\n",
            "202/202 [==============================] - 0s 80us/step - loss: 0.2990 - acc: 0.8861\n",
            "Epoch 98/100\n",
            "202/202 [==============================] - 0s 87us/step - loss: 0.2983 - acc: 0.8861\n",
            "Epoch 99/100\n",
            "202/202 [==============================] - 0s 83us/step - loss: 0.2977 - acc: 0.8861\n",
            "Epoch 100/100\n",
            "202/202 [==============================] - 0s 84us/step - loss: 0.2968 - acc: 0.8861\n",
            "101/101 [==============================] - 1s 7ms/step\n",
            "Epoch 1/100\n",
            "202/202 [==============================] - 2s 9ms/step - loss: 0.8809 - acc: 0.3515\n",
            "Epoch 2/100\n",
            "202/202 [==============================] - 0s 81us/step - loss: 0.8521 - acc: 0.3663\n",
            "Epoch 3/100\n",
            "202/202 [==============================] - 0s 81us/step - loss: 0.8249 - acc: 0.3960\n",
            "Epoch 4/100\n",
            "202/202 [==============================] - 0s 77us/step - loss: 0.7977 - acc: 0.4257\n",
            "Epoch 5/100\n",
            "202/202 [==============================] - 0s 68us/step - loss: 0.7723 - acc: 0.4505\n",
            "Epoch 6/100\n",
            "202/202 [==============================] - 0s 72us/step - loss: 0.7480 - acc: 0.4901\n",
            "Epoch 7/100\n",
            "202/202 [==============================] - 0s 79us/step - loss: 0.7261 - acc: 0.4950\n",
            "Epoch 8/100\n",
            "202/202 [==============================] - 0s 78us/step - loss: 0.7038 - acc: 0.5149\n",
            "Epoch 9/100\n",
            "202/202 [==============================] - 0s 87us/step - loss: 0.6831 - acc: 0.5396\n",
            "Epoch 10/100\n",
            "202/202 [==============================] - 0s 87us/step - loss: 0.6638 - acc: 0.5594\n",
            "Epoch 11/100\n",
            "202/202 [==============================] - 0s 72us/step - loss: 0.6469 - acc: 0.5792\n",
            "Epoch 12/100\n",
            "202/202 [==============================] - 0s 80us/step - loss: 0.6296 - acc: 0.6139\n",
            "Epoch 13/100\n",
            "202/202 [==============================] - 0s 74us/step - loss: 0.6129 - acc: 0.6634\n",
            "Epoch 14/100\n",
            "202/202 [==============================] - 0s 72us/step - loss: 0.5972 - acc: 0.6980\n",
            "Epoch 15/100\n",
            "202/202 [==============================] - 0s 72us/step - loss: 0.5816 - acc: 0.7277\n",
            "Epoch 16/100\n",
            "202/202 [==============================] - 0s 78us/step - loss: 0.5667 - acc: 0.7475\n",
            "Epoch 17/100\n",
            "202/202 [==============================] - 0s 74us/step - loss: 0.5526 - acc: 0.7772\n",
            "Epoch 18/100\n",
            "202/202 [==============================] - 0s 104us/step - loss: 0.5399 - acc: 0.7871\n",
            "Epoch 19/100\n",
            "202/202 [==============================] - 0s 123us/step - loss: 0.5279 - acc: 0.8119\n",
            "Epoch 20/100\n",
            "202/202 [==============================] - 0s 73us/step - loss: 0.5165 - acc: 0.8168\n",
            "Epoch 21/100\n",
            "202/202 [==============================] - 0s 87us/step - loss: 0.5045 - acc: 0.8317\n",
            "Epoch 22/100\n",
            "202/202 [==============================] - 0s 79us/step - loss: 0.4939 - acc: 0.8416\n",
            "Epoch 23/100\n",
            "202/202 [==============================] - 0s 77us/step - loss: 0.4827 - acc: 0.8416\n",
            "Epoch 24/100\n",
            "202/202 [==============================] - 0s 68us/step - loss: 0.4725 - acc: 0.8416\n",
            "Epoch 25/100\n",
            "202/202 [==============================] - 0s 80us/step - loss: 0.4620 - acc: 0.8465\n",
            "Epoch 26/100\n",
            "202/202 [==============================] - 0s 74us/step - loss: 0.4528 - acc: 0.8465\n",
            "Epoch 27/100\n",
            "202/202 [==============================] - 0s 67us/step - loss: 0.4445 - acc: 0.8515\n",
            "Epoch 28/100\n",
            "202/202 [==============================] - 0s 75us/step - loss: 0.4363 - acc: 0.8564\n",
            "Epoch 29/100\n",
            "202/202 [==============================] - 0s 71us/step - loss: 0.4289 - acc: 0.8564\n",
            "Epoch 30/100\n",
            "202/202 [==============================] - 0s 77us/step - loss: 0.4218 - acc: 0.8614\n",
            "Epoch 31/100\n",
            "202/202 [==============================] - 0s 70us/step - loss: 0.4150 - acc: 0.8663\n",
            "Epoch 32/100\n",
            "202/202 [==============================] - 0s 68us/step - loss: 0.4082 - acc: 0.8713\n",
            "Epoch 33/100\n",
            "202/202 [==============================] - 0s 69us/step - loss: 0.4015 - acc: 0.8762\n",
            "Epoch 34/100\n",
            "202/202 [==============================] - 0s 110us/step - loss: 0.3949 - acc: 0.8812\n",
            "Epoch 35/100\n",
            "202/202 [==============================] - 0s 71us/step - loss: 0.3887 - acc: 0.8812\n",
            "Epoch 36/100\n",
            "202/202 [==============================] - 0s 72us/step - loss: 0.3832 - acc: 0.8861\n",
            "Epoch 37/100\n",
            "202/202 [==============================] - 0s 73us/step - loss: 0.3779 - acc: 0.8911\n",
            "Epoch 38/100\n",
            "202/202 [==============================] - 0s 82us/step - loss: 0.3727 - acc: 0.8911\n",
            "Epoch 39/100\n",
            "202/202 [==============================] - 0s 91us/step - loss: 0.3676 - acc: 0.8911\n",
            "Epoch 40/100\n",
            "202/202 [==============================] - 0s 82us/step - loss: 0.3630 - acc: 0.8911\n",
            "Epoch 41/100\n",
            "202/202 [==============================] - 0s 78us/step - loss: 0.3585 - acc: 0.8911\n",
            "Epoch 42/100\n",
            "202/202 [==============================] - 0s 76us/step - loss: 0.3539 - acc: 0.8911\n",
            "Epoch 43/100\n",
            "202/202 [==============================] - 0s 81us/step - loss: 0.3493 - acc: 0.8911\n",
            "Epoch 44/100\n",
            "202/202 [==============================] - 0s 66us/step - loss: 0.3453 - acc: 0.8911\n",
            "Epoch 45/100\n",
            "202/202 [==============================] - 0s 68us/step - loss: 0.3409 - acc: 0.8911\n",
            "Epoch 46/100\n",
            "202/202 [==============================] - 0s 73us/step - loss: 0.3370 - acc: 0.8911\n",
            "Epoch 47/100\n",
            "202/202 [==============================] - 0s 65us/step - loss: 0.3331 - acc: 0.8911\n",
            "Epoch 48/100\n",
            "202/202 [==============================] - 0s 74us/step - loss: 0.3297 - acc: 0.8861\n",
            "Epoch 49/100\n",
            "202/202 [==============================] - 0s 96us/step - loss: 0.3265 - acc: 0.8861\n",
            "Epoch 50/100\n",
            "202/202 [==============================] - 0s 89us/step - loss: 0.3232 - acc: 0.8861\n",
            "Epoch 51/100\n",
            "202/202 [==============================] - 0s 118us/step - loss: 0.3202 - acc: 0.8861\n",
            "Epoch 52/100\n",
            "202/202 [==============================] - 0s 75us/step - loss: 0.3172 - acc: 0.8861\n",
            "Epoch 53/100\n",
            "202/202 [==============================] - 0s 92us/step - loss: 0.3146 - acc: 0.8861\n",
            "Epoch 54/100\n",
            "202/202 [==============================] - 0s 88us/step - loss: 0.3119 - acc: 0.8812\n",
            "Epoch 55/100\n",
            "202/202 [==============================] - 0s 86us/step - loss: 0.3095 - acc: 0.8812\n",
            "Epoch 56/100\n",
            "202/202 [==============================] - 0s 75us/step - loss: 0.3070 - acc: 0.8812\n",
            "Epoch 57/100\n",
            "202/202 [==============================] - 0s 81us/step - loss: 0.3045 - acc: 0.8812\n",
            "Epoch 58/100\n",
            "202/202 [==============================] - 0s 85us/step - loss: 0.3022 - acc: 0.8812\n",
            "Epoch 59/100\n",
            "202/202 [==============================] - 0s 101us/step - loss: 0.2999 - acc: 0.8812\n",
            "Epoch 60/100\n",
            "202/202 [==============================] - 0s 89us/step - loss: 0.2977 - acc: 0.8812\n",
            "Epoch 61/100\n",
            "202/202 [==============================] - 0s 101us/step - loss: 0.2957 - acc: 0.8812\n",
            "Epoch 62/100\n",
            "202/202 [==============================] - 0s 80us/step - loss: 0.2934 - acc: 0.8812\n",
            "Epoch 63/100\n",
            "202/202 [==============================] - 0s 69us/step - loss: 0.2920 - acc: 0.8812\n",
            "Epoch 64/100\n",
            "202/202 [==============================] - 0s 76us/step - loss: 0.2905 - acc: 0.8812\n",
            "Epoch 65/100\n",
            "202/202 [==============================] - 0s 76us/step - loss: 0.2887 - acc: 0.8812\n",
            "Epoch 66/100\n",
            "202/202 [==============================] - 0s 68us/step - loss: 0.2871 - acc: 0.8812\n",
            "Epoch 67/100\n",
            "202/202 [==============================] - 0s 66us/step - loss: 0.2856 - acc: 0.8812\n",
            "Epoch 68/100\n",
            "202/202 [==============================] - 0s 75us/step - loss: 0.2843 - acc: 0.8812\n",
            "Epoch 69/100\n",
            "202/202 [==============================] - 0s 74us/step - loss: 0.2828 - acc: 0.8812\n",
            "Epoch 70/100\n",
            "202/202 [==============================] - 0s 113us/step - loss: 0.2814 - acc: 0.8812\n",
            "Epoch 71/100\n",
            "202/202 [==============================] - 0s 82us/step - loss: 0.2802 - acc: 0.8812\n",
            "Epoch 72/100\n",
            "202/202 [==============================] - 0s 99us/step - loss: 0.2788 - acc: 0.8861\n",
            "Epoch 73/100\n",
            "202/202 [==============================] - 0s 84us/step - loss: 0.2775 - acc: 0.8861\n",
            "Epoch 74/100\n",
            "202/202 [==============================] - 0s 72us/step - loss: 0.2762 - acc: 0.8861\n",
            "Epoch 75/100\n",
            "202/202 [==============================] - 0s 100us/step - loss: 0.2751 - acc: 0.8861\n",
            "Epoch 76/100\n",
            "202/202 [==============================] - 0s 96us/step - loss: 0.2741 - acc: 0.8861\n",
            "Epoch 77/100\n",
            "202/202 [==============================] - 0s 104us/step - loss: 0.2729 - acc: 0.8861\n",
            "Epoch 78/100\n",
            "202/202 [==============================] - 0s 71us/step - loss: 0.2715 - acc: 0.8861\n",
            "Epoch 79/100\n",
            "202/202 [==============================] - 0s 78us/step - loss: 0.2704 - acc: 0.8911\n",
            "Epoch 80/100\n",
            "202/202 [==============================] - 0s 105us/step - loss: 0.2691 - acc: 0.8911\n",
            "Epoch 81/100\n",
            "202/202 [==============================] - 0s 106us/step - loss: 0.2680 - acc: 0.8911\n",
            "Epoch 82/100\n",
            "202/202 [==============================] - 0s 81us/step - loss: 0.2671 - acc: 0.8911\n",
            "Epoch 83/100\n",
            "202/202 [==============================] - 0s 73us/step - loss: 0.2659 - acc: 0.8911\n",
            "Epoch 84/100\n",
            "202/202 [==============================] - 0s 90us/step - loss: 0.2649 - acc: 0.8911\n",
            "Epoch 85/100\n",
            "202/202 [==============================] - 0s 96us/step - loss: 0.2644 - acc: 0.8911\n",
            "Epoch 86/100\n",
            "202/202 [==============================] - 0s 81us/step - loss: 0.2638 - acc: 0.8911\n",
            "Epoch 87/100\n",
            "202/202 [==============================] - 0s 108us/step - loss: 0.2628 - acc: 0.8911\n",
            "Epoch 88/100\n",
            "202/202 [==============================] - 0s 80us/step - loss: 0.2617 - acc: 0.8911\n",
            "Epoch 89/100\n",
            "202/202 [==============================] - 0s 105us/step - loss: 0.2609 - acc: 0.8911\n",
            "Epoch 90/100\n",
            "202/202 [==============================] - 0s 93us/step - loss: 0.2598 - acc: 0.8960\n",
            "Epoch 91/100\n",
            "202/202 [==============================] - 0s 74us/step - loss: 0.2588 - acc: 0.8960\n",
            "Epoch 92/100\n",
            "202/202 [==============================] - 0s 75us/step - loss: 0.2578 - acc: 0.8960\n",
            "Epoch 93/100\n",
            "202/202 [==============================] - 0s 72us/step - loss: 0.2568 - acc: 0.8960\n",
            "Epoch 94/100\n",
            "202/202 [==============================] - 0s 73us/step - loss: 0.2559 - acc: 0.8960\n",
            "Epoch 95/100\n",
            "202/202 [==============================] - 0s 70us/step - loss: 0.2550 - acc: 0.8960\n",
            "Epoch 96/100\n",
            "202/202 [==============================] - 0s 76us/step - loss: 0.2541 - acc: 0.8960\n",
            "Epoch 97/100\n",
            "202/202 [==============================] - 0s 96us/step - loss: 0.2533 - acc: 0.8960\n",
            "Epoch 98/100\n",
            "202/202 [==============================] - 0s 89us/step - loss: 0.2523 - acc: 0.8960\n",
            "Epoch 99/100\n",
            "202/202 [==============================] - 0s 93us/step - loss: 0.2515 - acc: 0.8960\n",
            "Epoch 100/100\n",
            "202/202 [==============================] - 0s 103us/step - loss: 0.2508 - acc: 0.8960\n",
            "101/101 [==============================] - 1s 8ms/step\n",
            "Epoch 1/150\n",
            "202/202 [==============================] - 2s 10ms/step - loss: 0.6620 - acc: 0.6535\n",
            "Epoch 2/150\n",
            "202/202 [==============================] - 0s 87us/step - loss: 0.6446 - acc: 0.6584\n",
            "Epoch 3/150\n",
            "202/202 [==============================] - 0s 74us/step - loss: 0.6277 - acc: 0.6584\n",
            "Epoch 4/150\n",
            "202/202 [==============================] - 0s 66us/step - loss: 0.6135 - acc: 0.6683\n",
            "Epoch 5/150\n",
            "202/202 [==============================] - 0s 67us/step - loss: 0.5999 - acc: 0.6683\n",
            "Epoch 6/150\n",
            "202/202 [==============================] - 0s 67us/step - loss: 0.5875 - acc: 0.6782\n",
            "Epoch 7/150\n",
            "202/202 [==============================] - 0s 71us/step - loss: 0.5757 - acc: 0.6832\n",
            "Epoch 8/150\n",
            "202/202 [==============================] - 0s 66us/step - loss: 0.5648 - acc: 0.6832\n",
            "Epoch 9/150\n",
            "202/202 [==============================] - 0s 70us/step - loss: 0.5557 - acc: 0.6832\n",
            "Epoch 10/150\n",
            "202/202 [==============================] - 0s 72us/step - loss: 0.5466 - acc: 0.6931\n",
            "Epoch 11/150\n",
            "202/202 [==============================] - 0s 69us/step - loss: 0.5378 - acc: 0.7030\n",
            "Epoch 12/150\n",
            "202/202 [==============================] - 0s 68us/step - loss: 0.5296 - acc: 0.7129\n",
            "Epoch 13/150\n",
            "202/202 [==============================] - 0s 72us/step - loss: 0.5220 - acc: 0.7178\n",
            "Epoch 14/150\n",
            "202/202 [==============================] - 0s 74us/step - loss: 0.5142 - acc: 0.7228\n",
            "Epoch 15/150\n",
            "202/202 [==============================] - 0s 65us/step - loss: 0.5077 - acc: 0.7228\n",
            "Epoch 16/150\n",
            "202/202 [==============================] - 0s 71us/step - loss: 0.5013 - acc: 0.7277\n",
            "Epoch 17/150\n",
            "202/202 [==============================] - 0s 98us/step - loss: 0.4958 - acc: 0.7376\n",
            "Epoch 18/150\n",
            "202/202 [==============================] - 0s 75us/step - loss: 0.4901 - acc: 0.7426\n",
            "Epoch 19/150\n",
            "202/202 [==============================] - 0s 77us/step - loss: 0.4852 - acc: 0.7574\n",
            "Epoch 20/150\n",
            "202/202 [==============================] - 0s 69us/step - loss: 0.4799 - acc: 0.7673\n",
            "Epoch 21/150\n",
            "202/202 [==============================] - 0s 82us/step - loss: 0.4749 - acc: 0.7772\n",
            "Epoch 22/150\n",
            "202/202 [==============================] - 0s 74us/step - loss: 0.4697 - acc: 0.7673\n",
            "Epoch 23/150\n",
            "202/202 [==============================] - 0s 69us/step - loss: 0.4654 - acc: 0.7822\n",
            "Epoch 24/150\n",
            "202/202 [==============================] - 0s 68us/step - loss: 0.4608 - acc: 0.7822\n",
            "Epoch 25/150\n",
            "202/202 [==============================] - 0s 71us/step - loss: 0.4567 - acc: 0.7822\n",
            "Epoch 26/150\n",
            "202/202 [==============================] - 0s 65us/step - loss: 0.4526 - acc: 0.7772\n",
            "Epoch 27/150\n",
            "202/202 [==============================] - 0s 89us/step - loss: 0.4487 - acc: 0.7970\n",
            "Epoch 28/150\n",
            "202/202 [==============================] - 0s 72us/step - loss: 0.4452 - acc: 0.7970\n",
            "Epoch 29/150\n",
            "202/202 [==============================] - 0s 79us/step - loss: 0.4422 - acc: 0.8020\n",
            "Epoch 30/150\n",
            "202/202 [==============================] - 0s 72us/step - loss: 0.4386 - acc: 0.8119\n",
            "Epoch 31/150\n",
            "202/202 [==============================] - 0s 77us/step - loss: 0.4340 - acc: 0.8218\n",
            "Epoch 32/150\n",
            "202/202 [==============================] - 0s 75us/step - loss: 0.4298 - acc: 0.8267\n",
            "Epoch 33/150\n",
            "202/202 [==============================] - 0s 81us/step - loss: 0.4261 - acc: 0.8267\n",
            "Epoch 34/150\n",
            "202/202 [==============================] - 0s 73us/step - loss: 0.4235 - acc: 0.8317\n",
            "Epoch 35/150\n",
            "202/202 [==============================] - 0s 72us/step - loss: 0.4205 - acc: 0.8317\n",
            "Epoch 36/150\n",
            "202/202 [==============================] - 0s 72us/step - loss: 0.4176 - acc: 0.8317\n",
            "Epoch 37/150\n",
            "202/202 [==============================] - 0s 76us/step - loss: 0.4148 - acc: 0.8317\n",
            "Epoch 38/150\n",
            "202/202 [==============================] - 0s 69us/step - loss: 0.4119 - acc: 0.8317\n",
            "Epoch 39/150\n",
            "202/202 [==============================] - 0s 69us/step - loss: 0.4091 - acc: 0.8317\n",
            "Epoch 40/150\n",
            "202/202 [==============================] - 0s 71us/step - loss: 0.4072 - acc: 0.8317\n",
            "Epoch 41/150\n",
            "202/202 [==============================] - 0s 69us/step - loss: 0.4052 - acc: 0.8317\n",
            "Epoch 42/150\n",
            "202/202 [==============================] - 0s 75us/step - loss: 0.4025 - acc: 0.8416\n",
            "Epoch 43/150\n",
            "202/202 [==============================] - 0s 66us/step - loss: 0.3997 - acc: 0.8416\n",
            "Epoch 44/150\n",
            "202/202 [==============================] - 0s 69us/step - loss: 0.3966 - acc: 0.8465\n",
            "Epoch 45/150\n",
            "202/202 [==============================] - 0s 71us/step - loss: 0.3935 - acc: 0.8465\n",
            "Epoch 46/150\n",
            "202/202 [==============================] - 0s 73us/step - loss: 0.3905 - acc: 0.8465\n",
            "Epoch 47/150\n",
            "202/202 [==============================] - 0s 77us/step - loss: 0.3877 - acc: 0.8416\n",
            "Epoch 48/150\n",
            "202/202 [==============================] - 0s 75us/step - loss: 0.3852 - acc: 0.8416\n",
            "Epoch 49/150\n",
            "202/202 [==============================] - 0s 70us/step - loss: 0.3824 - acc: 0.8416\n",
            "Epoch 50/150\n",
            "202/202 [==============================] - 0s 74us/step - loss: 0.3799 - acc: 0.8416\n",
            "Epoch 51/150\n",
            "202/202 [==============================] - 0s 104us/step - loss: 0.3774 - acc: 0.8465\n",
            "Epoch 52/150\n",
            "202/202 [==============================] - 0s 77us/step - loss: 0.3747 - acc: 0.8416\n",
            "Epoch 53/150\n",
            "202/202 [==============================] - 0s 67us/step - loss: 0.3723 - acc: 0.8416\n",
            "Epoch 54/150\n",
            "202/202 [==============================] - 0s 79us/step - loss: 0.3695 - acc: 0.8416\n",
            "Epoch 55/150\n",
            "202/202 [==============================] - 0s 67us/step - loss: 0.3666 - acc: 0.8416\n",
            "Epoch 56/150\n",
            "202/202 [==============================] - 0s 70us/step - loss: 0.3639 - acc: 0.8465\n",
            "Epoch 57/150\n",
            "202/202 [==============================] - 0s 72us/step - loss: 0.3617 - acc: 0.8515\n",
            "Epoch 58/150\n",
            "202/202 [==============================] - 0s 73us/step - loss: 0.3596 - acc: 0.8515\n",
            "Epoch 59/150\n",
            "202/202 [==============================] - 0s 74us/step - loss: 0.3576 - acc: 0.8465\n",
            "Epoch 60/150\n",
            "202/202 [==============================] - 0s 70us/step - loss: 0.3555 - acc: 0.8515\n",
            "Epoch 61/150\n",
            "202/202 [==============================] - 0s 70us/step - loss: 0.3532 - acc: 0.8515\n",
            "Epoch 62/150\n",
            "202/202 [==============================] - 0s 78us/step - loss: 0.3508 - acc: 0.8515\n",
            "Epoch 63/150\n",
            "202/202 [==============================] - 0s 88us/step - loss: 0.3487 - acc: 0.8515\n",
            "Epoch 64/150\n",
            "202/202 [==============================] - 0s 99us/step - loss: 0.3464 - acc: 0.8515\n",
            "Epoch 65/150\n",
            "202/202 [==============================] - 0s 103us/step - loss: 0.3442 - acc: 0.8564\n",
            "Epoch 66/150\n",
            "202/202 [==============================] - 0s 76us/step - loss: 0.3421 - acc: 0.8515\n",
            "Epoch 67/150\n",
            "202/202 [==============================] - 0s 74us/step - loss: 0.3403 - acc: 0.8515\n",
            "Epoch 68/150\n",
            "202/202 [==============================] - 0s 73us/step - loss: 0.3387 - acc: 0.8515\n",
            "Epoch 69/150\n",
            "202/202 [==============================] - 0s 73us/step - loss: 0.3374 - acc: 0.8515\n",
            "Epoch 70/150\n",
            "202/202 [==============================] - 0s 71us/step - loss: 0.3360 - acc: 0.8465\n",
            "Epoch 71/150\n",
            "202/202 [==============================] - 0s 73us/step - loss: 0.3349 - acc: 0.8465\n",
            "Epoch 72/150\n",
            "202/202 [==============================] - 0s 78us/step - loss: 0.3332 - acc: 0.8614\n",
            "Epoch 73/150\n",
            "202/202 [==============================] - 0s 74us/step - loss: 0.3315 - acc: 0.8663\n",
            "Epoch 74/150\n",
            "202/202 [==============================] - 0s 72us/step - loss: 0.3299 - acc: 0.8762\n",
            "Epoch 75/150\n",
            "202/202 [==============================] - 0s 80us/step - loss: 0.3284 - acc: 0.8762\n",
            "Epoch 76/150\n",
            "202/202 [==============================] - 0s 76us/step - loss: 0.3269 - acc: 0.8762\n",
            "Epoch 77/150\n",
            "202/202 [==============================] - 0s 80us/step - loss: 0.3258 - acc: 0.8812\n",
            "Epoch 78/150\n",
            "202/202 [==============================] - 0s 98us/step - loss: 0.3251 - acc: 0.8812\n",
            "Epoch 79/150\n",
            "202/202 [==============================] - 0s 72us/step - loss: 0.3238 - acc: 0.8812\n",
            "Epoch 80/150\n",
            "202/202 [==============================] - 0s 101us/step - loss: 0.3228 - acc: 0.8812\n",
            "Epoch 81/150\n",
            "202/202 [==============================] - 0s 70us/step - loss: 0.3213 - acc: 0.8812\n",
            "Epoch 82/150\n",
            "202/202 [==============================] - 0s 87us/step - loss: 0.3201 - acc: 0.8812\n",
            "Epoch 83/150\n",
            "202/202 [==============================] - 0s 111us/step - loss: 0.3189 - acc: 0.8812\n",
            "Epoch 84/150\n",
            "202/202 [==============================] - 0s 78us/step - loss: 0.3177 - acc: 0.8812\n",
            "Epoch 85/150\n",
            "202/202 [==============================] - 0s 78us/step - loss: 0.3164 - acc: 0.8812\n",
            "Epoch 86/150\n",
            "202/202 [==============================] - 0s 74us/step - loss: 0.3153 - acc: 0.8812\n",
            "Epoch 87/150\n",
            "202/202 [==============================] - 0s 80us/step - loss: 0.3141 - acc: 0.8812\n",
            "Epoch 88/150\n",
            "202/202 [==============================] - 0s 67us/step - loss: 0.3127 - acc: 0.8861\n",
            "Epoch 89/150\n",
            "202/202 [==============================] - 0s 84us/step - loss: 0.3120 - acc: 0.8911\n",
            "Epoch 90/150\n",
            "202/202 [==============================] - 0s 83us/step - loss: 0.3106 - acc: 0.8911\n",
            "Epoch 91/150\n",
            "202/202 [==============================] - 0s 72us/step - loss: 0.3094 - acc: 0.8911\n",
            "Epoch 92/150\n",
            "202/202 [==============================] - 0s 117us/step - loss: 0.3082 - acc: 0.8911\n",
            "Epoch 93/150\n",
            "202/202 [==============================] - 0s 86us/step - loss: 0.3069 - acc: 0.8911\n",
            "Epoch 94/150\n",
            "202/202 [==============================] - 0s 76us/step - loss: 0.3059 - acc: 0.8911\n",
            "Epoch 95/150\n",
            "202/202 [==============================] - 0s 82us/step - loss: 0.3051 - acc: 0.8911\n",
            "Epoch 96/150\n",
            "202/202 [==============================] - 0s 75us/step - loss: 0.3039 - acc: 0.8911\n",
            "Epoch 97/150\n",
            "202/202 [==============================] - 0s 71us/step - loss: 0.3028 - acc: 0.8911\n",
            "Epoch 98/150\n",
            "202/202 [==============================] - 0s 77us/step - loss: 0.3017 - acc: 0.8911\n",
            "Epoch 99/150\n",
            "202/202 [==============================] - 0s 98us/step - loss: 0.3006 - acc: 0.8911\n",
            "Epoch 100/150\n",
            "202/202 [==============================] - 0s 80us/step - loss: 0.2994 - acc: 0.8911\n",
            "Epoch 101/150\n",
            "202/202 [==============================] - 0s 72us/step - loss: 0.2987 - acc: 0.8911\n",
            "Epoch 102/150\n",
            "202/202 [==============================] - 0s 83us/step - loss: 0.2977 - acc: 0.8911\n",
            "Epoch 103/150\n",
            "202/202 [==============================] - 0s 72us/step - loss: 0.2967 - acc: 0.8911\n",
            "Epoch 104/150\n",
            "202/202 [==============================] - 0s 68us/step - loss: 0.2957 - acc: 0.8911\n",
            "Epoch 105/150\n",
            "202/202 [==============================] - 0s 68us/step - loss: 0.2949 - acc: 0.8911\n",
            "Epoch 106/150\n",
            "202/202 [==============================] - 0s 72us/step - loss: 0.2944 - acc: 0.8911\n",
            "Epoch 107/150\n",
            "202/202 [==============================] - 0s 77us/step - loss: 0.2935 - acc: 0.8960\n",
            "Epoch 108/150\n",
            "202/202 [==============================] - 0s 94us/step - loss: 0.2935 - acc: 0.8960\n",
            "Epoch 109/150\n",
            "202/202 [==============================] - 0s 99us/step - loss: 0.2930 - acc: 0.8960\n",
            "Epoch 110/150\n",
            "202/202 [==============================] - 0s 84us/step - loss: 0.2923 - acc: 0.8960\n",
            "Epoch 111/150\n",
            "202/202 [==============================] - 0s 83us/step - loss: 0.2915 - acc: 0.8960\n",
            "Epoch 112/150\n",
            "202/202 [==============================] - 0s 81us/step - loss: 0.2904 - acc: 0.8960\n",
            "Epoch 113/150\n",
            "202/202 [==============================] - 0s 79us/step - loss: 0.2899 - acc: 0.8960\n",
            "Epoch 114/150\n",
            "202/202 [==============================] - 0s 89us/step - loss: 0.2888 - acc: 0.8960\n",
            "Epoch 115/150\n",
            "202/202 [==============================] - 0s 88us/step - loss: 0.2881 - acc: 0.8960\n",
            "Epoch 116/150\n",
            "202/202 [==============================] - 0s 74us/step - loss: 0.2875 - acc: 0.8960\n",
            "Epoch 117/150\n",
            "202/202 [==============================] - 0s 69us/step - loss: 0.2867 - acc: 0.8960\n",
            "Epoch 118/150\n",
            "202/202 [==============================] - 0s 73us/step - loss: 0.2857 - acc: 0.8960\n",
            "Epoch 119/150\n",
            "202/202 [==============================] - 0s 86us/step - loss: 0.2851 - acc: 0.8911\n",
            "Epoch 120/150\n",
            "202/202 [==============================] - 0s 81us/step - loss: 0.2846 - acc: 0.8911\n",
            "Epoch 121/150\n",
            "202/202 [==============================] - 0s 96us/step - loss: 0.2839 - acc: 0.8911\n",
            "Epoch 122/150\n",
            "202/202 [==============================] - 0s 85us/step - loss: 0.2831 - acc: 0.8911\n",
            "Epoch 123/150\n",
            "202/202 [==============================] - 0s 75us/step - loss: 0.2825 - acc: 0.8911\n",
            "Epoch 124/150\n",
            "202/202 [==============================] - 0s 89us/step - loss: 0.2816 - acc: 0.8911\n",
            "Epoch 125/150\n",
            "202/202 [==============================] - 0s 96us/step - loss: 0.2812 - acc: 0.8911\n",
            "Epoch 126/150\n",
            "202/202 [==============================] - 0s 72us/step - loss: 0.2804 - acc: 0.8911\n",
            "Epoch 127/150\n",
            "202/202 [==============================] - 0s 81us/step - loss: 0.2796 - acc: 0.8960\n",
            "Epoch 128/150\n",
            "202/202 [==============================] - 0s 69us/step - loss: 0.2791 - acc: 0.8960\n",
            "Epoch 129/150\n",
            "202/202 [==============================] - 0s 100us/step - loss: 0.2785 - acc: 0.8960\n",
            "Epoch 130/150\n",
            "202/202 [==============================] - 0s 78us/step - loss: 0.2778 - acc: 0.8960\n",
            "Epoch 131/150\n",
            "202/202 [==============================] - 0s 103us/step - loss: 0.2770 - acc: 0.9010\n",
            "Epoch 132/150\n",
            "202/202 [==============================] - 0s 67us/step - loss: 0.2764 - acc: 0.8960\n",
            "Epoch 133/150\n",
            "202/202 [==============================] - 0s 66us/step - loss: 0.2756 - acc: 0.8960\n",
            "Epoch 134/150\n",
            "202/202 [==============================] - 0s 92us/step - loss: 0.2750 - acc: 0.8911\n",
            "Epoch 135/150\n",
            "202/202 [==============================] - 0s 76us/step - loss: 0.2743 - acc: 0.8911\n",
            "Epoch 136/150\n",
            "202/202 [==============================] - 0s 87us/step - loss: 0.2736 - acc: 0.8911\n",
            "Epoch 137/150\n",
            "202/202 [==============================] - 0s 88us/step - loss: 0.2732 - acc: 0.8911\n",
            "Epoch 138/150\n",
            "202/202 [==============================] - 0s 77us/step - loss: 0.2724 - acc: 0.8911\n",
            "Epoch 139/150\n",
            "202/202 [==============================] - 0s 71us/step - loss: 0.2718 - acc: 0.8960\n",
            "Epoch 140/150\n",
            "202/202 [==============================] - 0s 83us/step - loss: 0.2710 - acc: 0.8960\n",
            "Epoch 141/150\n",
            "202/202 [==============================] - 0s 85us/step - loss: 0.2704 - acc: 0.8911\n",
            "Epoch 142/150\n",
            "202/202 [==============================] - 0s 82us/step - loss: 0.2697 - acc: 0.8861\n",
            "Epoch 143/150\n",
            "202/202 [==============================] - 0s 84us/step - loss: 0.2690 - acc: 0.8861\n",
            "Epoch 144/150\n",
            "202/202 [==============================] - 0s 79us/step - loss: 0.2683 - acc: 0.8861\n",
            "Epoch 145/150\n",
            "202/202 [==============================] - 0s 120us/step - loss: 0.2678 - acc: 0.8861\n",
            "Epoch 146/150\n",
            "202/202 [==============================] - 0s 71us/step - loss: 0.2673 - acc: 0.8861\n",
            "Epoch 147/150\n",
            "202/202 [==============================] - 0s 72us/step - loss: 0.2668 - acc: 0.8911\n",
            "Epoch 148/150\n",
            "202/202 [==============================] - 0s 68us/step - loss: 0.2663 - acc: 0.8960\n",
            "Epoch 149/150\n",
            "202/202 [==============================] - 0s 76us/step - loss: 0.2658 - acc: 0.8960\n",
            "Epoch 150/150\n",
            "202/202 [==============================] - 0s 96us/step - loss: 0.2653 - acc: 0.8960\n",
            "101/101 [==============================] - 1s 8ms/step\n",
            "Epoch 1/150\n",
            "202/202 [==============================] - 2s 10ms/step - loss: 0.7199 - acc: 0.5495\n",
            "Epoch 2/150\n",
            "202/202 [==============================] - 0s 72us/step - loss: 0.6986 - acc: 0.5545\n",
            "Epoch 3/150\n",
            "202/202 [==============================] - 0s 70us/step - loss: 0.6813 - acc: 0.5792\n",
            "Epoch 4/150\n",
            "202/202 [==============================] - 0s 75us/step - loss: 0.6631 - acc: 0.5792\n",
            "Epoch 5/150\n",
            "202/202 [==============================] - 0s 73us/step - loss: 0.6470 - acc: 0.5891\n",
            "Epoch 6/150\n",
            "202/202 [==============================] - 0s 86us/step - loss: 0.6320 - acc: 0.5990\n",
            "Epoch 7/150\n",
            "202/202 [==============================] - 0s 78us/step - loss: 0.6171 - acc: 0.6089\n",
            "Epoch 8/150\n",
            "202/202 [==============================] - 0s 69us/step - loss: 0.6041 - acc: 0.6238\n",
            "Epoch 9/150\n",
            "202/202 [==============================] - 0s 74us/step - loss: 0.5922 - acc: 0.6287\n",
            "Epoch 10/150\n",
            "202/202 [==============================] - 0s 71us/step - loss: 0.5809 - acc: 0.6386\n",
            "Epoch 11/150\n",
            "202/202 [==============================] - 0s 64us/step - loss: 0.5706 - acc: 0.6436\n",
            "Epoch 12/150\n",
            "202/202 [==============================] - 0s 73us/step - loss: 0.5604 - acc: 0.6634\n",
            "Epoch 13/150\n",
            "202/202 [==============================] - 0s 67us/step - loss: 0.5501 - acc: 0.6634\n",
            "Epoch 14/150\n",
            "202/202 [==============================] - 0s 69us/step - loss: 0.5404 - acc: 0.7030\n",
            "Epoch 15/150\n",
            "202/202 [==============================] - 0s 81us/step - loss: 0.5306 - acc: 0.7129\n",
            "Epoch 16/150\n",
            "202/202 [==============================] - 0s 71us/step - loss: 0.5218 - acc: 0.7277\n",
            "Epoch 17/150\n",
            "202/202 [==============================] - 0s 67us/step - loss: 0.5127 - acc: 0.7277\n",
            "Epoch 18/150\n",
            "202/202 [==============================] - 0s 73us/step - loss: 0.5043 - acc: 0.7327\n",
            "Epoch 19/150\n",
            "202/202 [==============================] - 0s 87us/step - loss: 0.4962 - acc: 0.7475\n",
            "Epoch 20/150\n",
            "202/202 [==============================] - 0s 72us/step - loss: 0.4891 - acc: 0.7426\n",
            "Epoch 21/150\n",
            "202/202 [==============================] - 0s 72us/step - loss: 0.4825 - acc: 0.7525\n",
            "Epoch 22/150\n",
            "202/202 [==============================] - 0s 75us/step - loss: 0.4767 - acc: 0.7574\n",
            "Epoch 23/150\n",
            "202/202 [==============================] - 0s 70us/step - loss: 0.4710 - acc: 0.7624\n",
            "Epoch 24/150\n",
            "202/202 [==============================] - 0s 102us/step - loss: 0.4644 - acc: 0.7772\n",
            "Epoch 25/150\n",
            "202/202 [==============================] - 0s 113us/step - loss: 0.4584 - acc: 0.7822\n",
            "Epoch 26/150\n",
            "202/202 [==============================] - 0s 91us/step - loss: 0.4516 - acc: 0.7921\n",
            "Epoch 27/150\n",
            "202/202 [==============================] - 0s 77us/step - loss: 0.4453 - acc: 0.7921\n",
            "Epoch 28/150\n",
            "202/202 [==============================] - 0s 74us/step - loss: 0.4399 - acc: 0.7970\n",
            "Epoch 29/150\n",
            "202/202 [==============================] - 0s 81us/step - loss: 0.4344 - acc: 0.7970\n",
            "Epoch 30/150\n",
            "202/202 [==============================] - 0s 67us/step - loss: 0.4297 - acc: 0.8069\n",
            "Epoch 31/150\n",
            "202/202 [==============================] - 0s 70us/step - loss: 0.4253 - acc: 0.8119\n",
            "Epoch 32/150\n",
            "202/202 [==============================] - 0s 72us/step - loss: 0.4209 - acc: 0.8168\n",
            "Epoch 33/150\n",
            "202/202 [==============================] - 0s 88us/step - loss: 0.4169 - acc: 0.8168\n",
            "Epoch 34/150\n",
            "202/202 [==============================] - 0s 83us/step - loss: 0.4125 - acc: 0.8168\n",
            "Epoch 35/150\n",
            "202/202 [==============================] - 0s 88us/step - loss: 0.4089 - acc: 0.8168\n",
            "Epoch 36/150\n",
            "202/202 [==============================] - 0s 97us/step - loss: 0.4055 - acc: 0.8168\n",
            "Epoch 37/150\n",
            "202/202 [==============================] - 0s 96us/step - loss: 0.4020 - acc: 0.8168\n",
            "Epoch 38/150\n",
            "202/202 [==============================] - 0s 86us/step - loss: 0.3992 - acc: 0.8218\n",
            "Epoch 39/150\n",
            "202/202 [==============================] - 0s 99us/step - loss: 0.3967 - acc: 0.8267\n",
            "Epoch 40/150\n",
            "202/202 [==============================] - 0s 77us/step - loss: 0.3938 - acc: 0.8267\n",
            "Epoch 41/150\n",
            "202/202 [==============================] - 0s 70us/step - loss: 0.3908 - acc: 0.8267\n",
            "Epoch 42/150\n",
            "202/202 [==============================] - 0s 72us/step - loss: 0.3879 - acc: 0.8267\n",
            "Epoch 43/150\n",
            "202/202 [==============================] - 0s 81us/step - loss: 0.3848 - acc: 0.8218\n",
            "Epoch 44/150\n",
            "202/202 [==============================] - 0s 84us/step - loss: 0.3822 - acc: 0.8218\n",
            "Epoch 45/150\n",
            "202/202 [==============================] - 0s 126us/step - loss: 0.3791 - acc: 0.8317\n",
            "Epoch 46/150\n",
            "202/202 [==============================] - 0s 75us/step - loss: 0.3768 - acc: 0.8317\n",
            "Epoch 47/150\n",
            "202/202 [==============================] - 0s 71us/step - loss: 0.3745 - acc: 0.8317\n",
            "Epoch 48/150\n",
            "202/202 [==============================] - 0s 87us/step - loss: 0.3722 - acc: 0.8366\n",
            "Epoch 49/150\n",
            "202/202 [==============================] - 0s 72us/step - loss: 0.3697 - acc: 0.8366\n",
            "Epoch 50/150\n",
            "202/202 [==============================] - 0s 83us/step - loss: 0.3674 - acc: 0.8366\n",
            "Epoch 51/150\n",
            "202/202 [==============================] - 0s 95us/step - loss: 0.3652 - acc: 0.8416\n",
            "Epoch 52/150\n",
            "202/202 [==============================] - 0s 65us/step - loss: 0.3628 - acc: 0.8416\n",
            "Epoch 53/150\n",
            "202/202 [==============================] - 0s 67us/step - loss: 0.3607 - acc: 0.8416\n",
            "Epoch 54/150\n",
            "202/202 [==============================] - 0s 79us/step - loss: 0.3586 - acc: 0.8416\n",
            "Epoch 55/150\n",
            "202/202 [==============================] - 0s 83us/step - loss: 0.3563 - acc: 0.8416\n",
            "Epoch 56/150\n",
            "202/202 [==============================] - 0s 77us/step - loss: 0.3542 - acc: 0.8416\n",
            "Epoch 57/150\n",
            "202/202 [==============================] - 0s 72us/step - loss: 0.3520 - acc: 0.8416\n",
            "Epoch 58/150\n",
            "202/202 [==============================] - 0s 72us/step - loss: 0.3501 - acc: 0.8465\n",
            "Epoch 59/150\n",
            "202/202 [==============================] - 0s 72us/step - loss: 0.3483 - acc: 0.8465\n",
            "Epoch 60/150\n",
            "202/202 [==============================] - 0s 74us/step - loss: 0.3465 - acc: 0.8465\n",
            "Epoch 61/150\n",
            "202/202 [==============================] - 0s 86us/step - loss: 0.3444 - acc: 0.8465\n",
            "Epoch 62/150\n",
            "202/202 [==============================] - 0s 99us/step - loss: 0.3426 - acc: 0.8515\n",
            "Epoch 63/150\n",
            "202/202 [==============================] - 0s 79us/step - loss: 0.3408 - acc: 0.8515\n",
            "Epoch 64/150\n",
            "202/202 [==============================] - 0s 72us/step - loss: 0.3394 - acc: 0.8515\n",
            "Epoch 65/150\n",
            "202/202 [==============================] - 0s 84us/step - loss: 0.3384 - acc: 0.8515\n",
            "Epoch 66/150\n",
            "202/202 [==============================] - 0s 88us/step - loss: 0.3374 - acc: 0.8515\n",
            "Epoch 67/150\n",
            "202/202 [==============================] - 0s 102us/step - loss: 0.3363 - acc: 0.8465\n",
            "Epoch 68/150\n",
            "202/202 [==============================] - 0s 79us/step - loss: 0.3353 - acc: 0.8465\n",
            "Epoch 69/150\n",
            "202/202 [==============================] - 0s 78us/step - loss: 0.3339 - acc: 0.8465\n",
            "Epoch 70/150\n",
            "202/202 [==============================] - 0s 71us/step - loss: 0.3324 - acc: 0.8465\n",
            "Epoch 71/150\n",
            "202/202 [==============================] - 0s 83us/step - loss: 0.3308 - acc: 0.8465\n",
            "Epoch 72/150\n",
            "202/202 [==============================] - 0s 73us/step - loss: 0.3291 - acc: 0.8465\n",
            "Epoch 73/150\n",
            "202/202 [==============================] - 0s 77us/step - loss: 0.3276 - acc: 0.8465\n",
            "Epoch 74/150\n",
            "202/202 [==============================] - 0s 101us/step - loss: 0.3262 - acc: 0.8515\n",
            "Epoch 75/150\n",
            "202/202 [==============================] - 0s 78us/step - loss: 0.3246 - acc: 0.8515\n",
            "Epoch 76/150\n",
            "202/202 [==============================] - 0s 75us/step - loss: 0.3230 - acc: 0.8515\n",
            "Epoch 77/150\n",
            "202/202 [==============================] - 0s 80us/step - loss: 0.3211 - acc: 0.8564\n",
            "Epoch 78/150\n",
            "202/202 [==============================] - 0s 103us/step - loss: 0.3197 - acc: 0.8564\n",
            "Epoch 79/150\n",
            "202/202 [==============================] - 0s 87us/step - loss: 0.3181 - acc: 0.8564\n",
            "Epoch 80/150\n",
            "202/202 [==============================] - 0s 70us/step - loss: 0.3170 - acc: 0.8614\n",
            "Epoch 81/150\n",
            "202/202 [==============================] - 0s 79us/step - loss: 0.3159 - acc: 0.8614\n",
            "Epoch 82/150\n",
            "202/202 [==============================] - 0s 74us/step - loss: 0.3146 - acc: 0.8614\n",
            "Epoch 83/150\n",
            "202/202 [==============================] - 0s 71us/step - loss: 0.3134 - acc: 0.8614\n",
            "Epoch 84/150\n",
            "202/202 [==============================] - 0s 76us/step - loss: 0.3121 - acc: 0.8614\n",
            "Epoch 85/150\n",
            "202/202 [==============================] - 0s 91us/step - loss: 0.3109 - acc: 0.8614\n",
            "Epoch 86/150\n",
            "202/202 [==============================] - 0s 79us/step - loss: 0.3098 - acc: 0.8614\n",
            "Epoch 87/150\n",
            "202/202 [==============================] - 0s 82us/step - loss: 0.3088 - acc: 0.8614\n",
            "Epoch 88/150\n",
            "202/202 [==============================] - 0s 89us/step - loss: 0.3076 - acc: 0.8614\n",
            "Epoch 89/150\n",
            "202/202 [==============================] - 0s 100us/step - loss: 0.3065 - acc: 0.8614\n",
            "Epoch 90/150\n",
            "202/202 [==============================] - 0s 105us/step - loss: 0.3054 - acc: 0.8614\n",
            "Epoch 91/150\n",
            "202/202 [==============================] - 0s 67us/step - loss: 0.3043 - acc: 0.8614\n",
            "Epoch 92/150\n",
            "202/202 [==============================] - 0s 93us/step - loss: 0.3031 - acc: 0.8614\n",
            "Epoch 93/150\n",
            "202/202 [==============================] - 0s 80us/step - loss: 0.3021 - acc: 0.8663\n",
            "Epoch 94/150\n",
            "202/202 [==============================] - 0s 84us/step - loss: 0.3010 - acc: 0.8663\n",
            "Epoch 95/150\n",
            "202/202 [==============================] - 0s 81us/step - loss: 0.3001 - acc: 0.8663\n",
            "Epoch 96/150\n",
            "202/202 [==============================] - 0s 95us/step - loss: 0.2993 - acc: 0.8663\n",
            "Epoch 97/150\n",
            "202/202 [==============================] - 0s 81us/step - loss: 0.2983 - acc: 0.8713\n",
            "Epoch 98/150\n",
            "202/202 [==============================] - 0s 89us/step - loss: 0.2974 - acc: 0.8713\n",
            "Epoch 99/150\n",
            "202/202 [==============================] - 0s 103us/step - loss: 0.2965 - acc: 0.8713\n",
            "Epoch 100/150\n",
            "202/202 [==============================] - 0s 91us/step - loss: 0.2955 - acc: 0.8713\n",
            "Epoch 101/150\n",
            "202/202 [==============================] - 0s 72us/step - loss: 0.2945 - acc: 0.8762\n",
            "Epoch 102/150\n",
            "202/202 [==============================] - 0s 82us/step - loss: 0.2936 - acc: 0.8762\n",
            "Epoch 103/150\n",
            "202/202 [==============================] - 0s 78us/step - loss: 0.2925 - acc: 0.8861\n",
            "Epoch 104/150\n",
            "202/202 [==============================] - 0s 77us/step - loss: 0.2913 - acc: 0.8861\n",
            "Epoch 105/150\n",
            "202/202 [==============================] - 0s 119us/step - loss: 0.2902 - acc: 0.8861\n",
            "Epoch 106/150\n",
            "202/202 [==============================] - 0s 94us/step - loss: 0.2891 - acc: 0.8861\n",
            "Epoch 107/150\n",
            "202/202 [==============================] - 0s 102us/step - loss: 0.2880 - acc: 0.8861\n",
            "Epoch 108/150\n",
            "202/202 [==============================] - 0s 102us/step - loss: 0.2871 - acc: 0.8861\n",
            "Epoch 109/150\n",
            "202/202 [==============================] - 0s 79us/step - loss: 0.2864 - acc: 0.8861\n",
            "Epoch 110/150\n",
            "202/202 [==============================] - 0s 75us/step - loss: 0.2854 - acc: 0.8861\n",
            "Epoch 111/150\n",
            "202/202 [==============================] - 0s 76us/step - loss: 0.2849 - acc: 0.8861\n",
            "Epoch 112/150\n",
            "202/202 [==============================] - 0s 89us/step - loss: 0.2840 - acc: 0.8861\n",
            "Epoch 113/150\n",
            "202/202 [==============================] - 0s 95us/step - loss: 0.2832 - acc: 0.8861\n",
            "Epoch 114/150\n",
            "202/202 [==============================] - 0s 81us/step - loss: 0.2825 - acc: 0.8861\n",
            "Epoch 115/150\n",
            "202/202 [==============================] - 0s 93us/step - loss: 0.2818 - acc: 0.8861\n",
            "Epoch 116/150\n",
            "202/202 [==============================] - 0s 95us/step - loss: 0.2812 - acc: 0.8861\n",
            "Epoch 117/150\n",
            "202/202 [==============================] - 0s 95us/step - loss: 0.2804 - acc: 0.8812\n",
            "Epoch 118/150\n",
            "202/202 [==============================] - 0s 105us/step - loss: 0.2797 - acc: 0.8812\n",
            "Epoch 119/150\n",
            "202/202 [==============================] - 0s 76us/step - loss: 0.2788 - acc: 0.8812\n",
            "Epoch 120/150\n",
            "202/202 [==============================] - 0s 74us/step - loss: 0.2779 - acc: 0.8812\n",
            "Epoch 121/150\n",
            "202/202 [==============================] - 0s 182us/step - loss: 0.2772 - acc: 0.8812\n",
            "Epoch 122/150\n",
            "202/202 [==============================] - 0s 116us/step - loss: 0.2763 - acc: 0.8812\n",
            "Epoch 123/150\n",
            "202/202 [==============================] - 0s 90us/step - loss: 0.2758 - acc: 0.8812\n",
            "Epoch 124/150\n",
            "202/202 [==============================] - 0s 78us/step - loss: 0.2751 - acc: 0.8812\n",
            "Epoch 125/150\n",
            "202/202 [==============================] - 0s 87us/step - loss: 0.2744 - acc: 0.8812\n",
            "Epoch 126/150\n",
            "202/202 [==============================] - 0s 104us/step - loss: 0.2738 - acc: 0.8812\n",
            "Epoch 127/150\n",
            "202/202 [==============================] - 0s 89us/step - loss: 0.2732 - acc: 0.8812\n",
            "Epoch 128/150\n",
            "202/202 [==============================] - 0s 89us/step - loss: 0.2725 - acc: 0.8812\n",
            "Epoch 129/150\n",
            "202/202 [==============================] - 0s 94us/step - loss: 0.2719 - acc: 0.8812\n",
            "Epoch 130/150\n",
            "202/202 [==============================] - 0s 91us/step - loss: 0.2710 - acc: 0.8812\n",
            "Epoch 131/150\n",
            "202/202 [==============================] - 0s 73us/step - loss: 0.2699 - acc: 0.8812\n",
            "Epoch 132/150\n",
            "202/202 [==============================] - 0s 77us/step - loss: 0.2692 - acc: 0.8812\n",
            "Epoch 133/150\n",
            "202/202 [==============================] - 0s 78us/step - loss: 0.2684 - acc: 0.8812\n",
            "Epoch 134/150\n",
            "202/202 [==============================] - 0s 78us/step - loss: 0.2678 - acc: 0.8812\n",
            "Epoch 135/150\n",
            "202/202 [==============================] - 0s 85us/step - loss: 0.2671 - acc: 0.8812\n",
            "Epoch 136/150\n",
            "202/202 [==============================] - 0s 87us/step - loss: 0.2664 - acc: 0.8812\n",
            "Epoch 137/150\n",
            "202/202 [==============================] - 0s 69us/step - loss: 0.2659 - acc: 0.8812\n",
            "Epoch 138/150\n",
            "202/202 [==============================] - 0s 72us/step - loss: 0.2654 - acc: 0.8812\n",
            "Epoch 139/150\n",
            "202/202 [==============================] - 0s 69us/step - loss: 0.2647 - acc: 0.8861\n",
            "Epoch 140/150\n",
            "202/202 [==============================] - 0s 75us/step - loss: 0.2638 - acc: 0.8861\n",
            "Epoch 141/150\n",
            "202/202 [==============================] - 0s 87us/step - loss: 0.2633 - acc: 0.8812\n",
            "Epoch 142/150\n",
            "202/202 [==============================] - 0s 87us/step - loss: 0.2628 - acc: 0.8812\n",
            "Epoch 143/150\n",
            "202/202 [==============================] - 0s 84us/step - loss: 0.2622 - acc: 0.8812\n",
            "Epoch 144/150\n",
            "202/202 [==============================] - 0s 72us/step - loss: 0.2615 - acc: 0.8861\n",
            "Epoch 145/150\n",
            "202/202 [==============================] - 0s 105us/step - loss: 0.2612 - acc: 0.8861\n",
            "Epoch 146/150\n",
            "202/202 [==============================] - 0s 74us/step - loss: 0.2605 - acc: 0.8861\n",
            "Epoch 147/150\n",
            "202/202 [==============================] - 0s 87us/step - loss: 0.2599 - acc: 0.8861\n",
            "Epoch 148/150\n",
            "202/202 [==============================] - 0s 82us/step - loss: 0.2593 - acc: 0.8861\n",
            "Epoch 149/150\n",
            "202/202 [==============================] - 0s 124us/step - loss: 0.2589 - acc: 0.8861\n",
            "Epoch 150/150\n",
            "202/202 [==============================] - 0s 103us/step - loss: 0.2584 - acc: 0.8861\n",
            "101/101 [==============================] - 1s 8ms/step\n",
            "Epoch 1/150\n",
            "202/202 [==============================] - 2s 10ms/step - loss: 0.9971 - acc: 0.2228\n",
            "Epoch 2/150\n",
            "202/202 [==============================] - 0s 82us/step - loss: 0.9588 - acc: 0.2277\n",
            "Epoch 3/150\n",
            "202/202 [==============================] - 0s 68us/step - loss: 0.9246 - acc: 0.2327\n",
            "Epoch 4/150\n",
            "202/202 [==============================] - 0s 71us/step - loss: 0.8913 - acc: 0.2426\n",
            "Epoch 5/150\n",
            "202/202 [==============================] - 0s 74us/step - loss: 0.8604 - acc: 0.2525\n",
            "Epoch 6/150\n",
            "202/202 [==============================] - 0s 73us/step - loss: 0.8310 - acc: 0.2673\n",
            "Epoch 7/150\n",
            "202/202 [==============================] - 0s 68us/step - loss: 0.8039 - acc: 0.2921\n",
            "Epoch 8/150\n",
            "202/202 [==============================] - 0s 70us/step - loss: 0.7786 - acc: 0.3515\n",
            "Epoch 9/150\n",
            "202/202 [==============================] - 0s 68us/step - loss: 0.7545 - acc: 0.4109\n",
            "Epoch 10/150\n",
            "202/202 [==============================] - 0s 71us/step - loss: 0.7318 - acc: 0.4802\n",
            "Epoch 11/150\n",
            "202/202 [==============================] - 0s 72us/step - loss: 0.7099 - acc: 0.5396\n",
            "Epoch 12/150\n",
            "202/202 [==============================] - 0s 71us/step - loss: 0.6883 - acc: 0.5891\n",
            "Epoch 13/150\n",
            "202/202 [==============================] - 0s 76us/step - loss: 0.6694 - acc: 0.6386\n",
            "Epoch 14/150\n",
            "202/202 [==============================] - 0s 68us/step - loss: 0.6524 - acc: 0.6980\n",
            "Epoch 15/150\n",
            "202/202 [==============================] - 0s 81us/step - loss: 0.6359 - acc: 0.7277\n",
            "Epoch 16/150\n",
            "202/202 [==============================] - 0s 75us/step - loss: 0.6198 - acc: 0.7327\n",
            "Epoch 17/150\n",
            "202/202 [==============================] - 0s 79us/step - loss: 0.6028 - acc: 0.7525\n",
            "Epoch 18/150\n",
            "202/202 [==============================] - 0s 78us/step - loss: 0.5864 - acc: 0.7871\n",
            "Epoch 19/150\n",
            "202/202 [==============================] - 0s 94us/step - loss: 0.5704 - acc: 0.8119\n",
            "Epoch 20/150\n",
            "202/202 [==============================] - 0s 77us/step - loss: 0.5559 - acc: 0.8119\n",
            "Epoch 21/150\n",
            "202/202 [==============================] - 0s 69us/step - loss: 0.5421 - acc: 0.8069\n",
            "Epoch 22/150\n",
            "202/202 [==============================] - 0s 75us/step - loss: 0.5303 - acc: 0.8317\n",
            "Epoch 23/150\n",
            "202/202 [==============================] - 0s 85us/step - loss: 0.5187 - acc: 0.8317\n",
            "Epoch 24/150\n",
            "202/202 [==============================] - 0s 86us/step - loss: 0.5076 - acc: 0.8317\n",
            "Epoch 25/150\n",
            "202/202 [==============================] - 0s 77us/step - loss: 0.4965 - acc: 0.8515\n",
            "Epoch 26/150\n",
            "202/202 [==============================] - 0s 81us/step - loss: 0.4865 - acc: 0.8515\n",
            "Epoch 27/150\n",
            "202/202 [==============================] - 0s 99us/step - loss: 0.4769 - acc: 0.8663\n",
            "Epoch 28/150\n",
            "202/202 [==============================] - 0s 77us/step - loss: 0.4679 - acc: 0.8762\n",
            "Epoch 29/150\n",
            "202/202 [==============================] - 0s 110us/step - loss: 0.4587 - acc: 0.8713\n",
            "Epoch 30/150\n",
            "202/202 [==============================] - 0s 72us/step - loss: 0.4499 - acc: 0.8713\n",
            "Epoch 31/150\n",
            "202/202 [==============================] - 0s 87us/step - loss: 0.4417 - acc: 0.8762\n",
            "Epoch 32/150\n",
            "202/202 [==============================] - 0s 75us/step - loss: 0.4340 - acc: 0.8812\n",
            "Epoch 33/150\n",
            "202/202 [==============================] - 0s 70us/step - loss: 0.4267 - acc: 0.8812\n",
            "Epoch 34/150\n",
            "202/202 [==============================] - 0s 71us/step - loss: 0.4202 - acc: 0.8812\n",
            "Epoch 35/150\n",
            "202/202 [==============================] - 0s 84us/step - loss: 0.4142 - acc: 0.8812\n",
            "Epoch 36/150\n",
            "202/202 [==============================] - 0s 97us/step - loss: 0.4088 - acc: 0.8812\n",
            "Epoch 37/150\n",
            "202/202 [==============================] - 0s 75us/step - loss: 0.4042 - acc: 0.8861\n",
            "Epoch 38/150\n",
            "202/202 [==============================] - 0s 108us/step - loss: 0.3988 - acc: 0.8861\n",
            "Epoch 39/150\n",
            "202/202 [==============================] - 0s 71us/step - loss: 0.3933 - acc: 0.8861\n",
            "Epoch 40/150\n",
            "202/202 [==============================] - 0s 99us/step - loss: 0.3875 - acc: 0.8861\n",
            "Epoch 41/150\n",
            "202/202 [==============================] - 0s 94us/step - loss: 0.3818 - acc: 0.8861\n",
            "Epoch 42/150\n",
            "202/202 [==============================] - 0s 74us/step - loss: 0.3762 - acc: 0.8911\n",
            "Epoch 43/150\n",
            "202/202 [==============================] - 0s 78us/step - loss: 0.3709 - acc: 0.8911\n",
            "Epoch 44/150\n",
            "202/202 [==============================] - 0s 79us/step - loss: 0.3658 - acc: 0.8911\n",
            "Epoch 45/150\n",
            "202/202 [==============================] - 0s 80us/step - loss: 0.3610 - acc: 0.8911\n",
            "Epoch 46/150\n",
            "202/202 [==============================] - 0s 77us/step - loss: 0.3566 - acc: 0.8911\n",
            "Epoch 47/150\n",
            "202/202 [==============================] - 0s 92us/step - loss: 0.3523 - acc: 0.8911\n",
            "Epoch 48/150\n",
            "202/202 [==============================] - 0s 79us/step - loss: 0.3482 - acc: 0.8911\n",
            "Epoch 49/150\n",
            "202/202 [==============================] - 0s 98us/step - loss: 0.3444 - acc: 0.8911\n",
            "Epoch 50/150\n",
            "202/202 [==============================] - 0s 72us/step - loss: 0.3407 - acc: 0.8861\n",
            "Epoch 51/150\n",
            "202/202 [==============================] - 0s 91us/step - loss: 0.3372 - acc: 0.8861\n",
            "Epoch 52/150\n",
            "202/202 [==============================] - 0s 90us/step - loss: 0.3344 - acc: 0.8861\n",
            "Epoch 53/150\n",
            "202/202 [==============================] - 0s 78us/step - loss: 0.3320 - acc: 0.8861\n",
            "Epoch 54/150\n",
            "202/202 [==============================] - 0s 100us/step - loss: 0.3297 - acc: 0.8911\n",
            "Epoch 55/150\n",
            "202/202 [==============================] - 0s 84us/step - loss: 0.3272 - acc: 0.8861\n",
            "Epoch 56/150\n",
            "202/202 [==============================] - 0s 76us/step - loss: 0.3248 - acc: 0.8861\n",
            "Epoch 57/150\n",
            "202/202 [==============================] - 0s 83us/step - loss: 0.3227 - acc: 0.8861\n",
            "Epoch 58/150\n",
            "202/202 [==============================] - 0s 86us/step - loss: 0.3203 - acc: 0.8861\n",
            "Epoch 59/150\n",
            "202/202 [==============================] - 0s 78us/step - loss: 0.3179 - acc: 0.8861\n",
            "Epoch 60/150\n",
            "202/202 [==============================] - 0s 75us/step - loss: 0.3155 - acc: 0.8861\n",
            "Epoch 61/150\n",
            "202/202 [==============================] - 0s 69us/step - loss: 0.3130 - acc: 0.8861\n",
            "Epoch 62/150\n",
            "202/202 [==============================] - 0s 80us/step - loss: 0.3106 - acc: 0.8861\n",
            "Epoch 63/150\n",
            "202/202 [==============================] - 0s 74us/step - loss: 0.3085 - acc: 0.8861\n",
            "Epoch 64/150\n",
            "202/202 [==============================] - 0s 86us/step - loss: 0.3062 - acc: 0.8861\n",
            "Epoch 65/150\n",
            "202/202 [==============================] - 0s 76us/step - loss: 0.3042 - acc: 0.8861\n",
            "Epoch 66/150\n",
            "202/202 [==============================] - 0s 95us/step - loss: 0.3025 - acc: 0.8861\n",
            "Epoch 67/150\n",
            "202/202 [==============================] - 0s 93us/step - loss: 0.3004 - acc: 0.8861\n",
            "Epoch 68/150\n",
            "202/202 [==============================] - 0s 75us/step - loss: 0.2988 - acc: 0.8861\n",
            "Epoch 69/150\n",
            "202/202 [==============================] - 0s 85us/step - loss: 0.2969 - acc: 0.8861\n",
            "Epoch 70/150\n",
            "202/202 [==============================] - 0s 102us/step - loss: 0.2952 - acc: 0.8861\n",
            "Epoch 71/150\n",
            "202/202 [==============================] - 0s 144us/step - loss: 0.2935 - acc: 0.8861\n",
            "Epoch 72/150\n",
            "202/202 [==============================] - 0s 83us/step - loss: 0.2918 - acc: 0.8861\n",
            "Epoch 73/150\n",
            "202/202 [==============================] - 0s 79us/step - loss: 0.2901 - acc: 0.8861\n",
            "Epoch 74/150\n",
            "202/202 [==============================] - 0s 84us/step - loss: 0.2886 - acc: 0.8861\n",
            "Epoch 75/150\n",
            "202/202 [==============================] - 0s 90us/step - loss: 0.2871 - acc: 0.8861\n",
            "Epoch 76/150\n",
            "202/202 [==============================] - 0s 79us/step - loss: 0.2856 - acc: 0.8861\n",
            "Epoch 77/150\n",
            "202/202 [==============================] - 0s 79us/step - loss: 0.2841 - acc: 0.8861\n",
            "Epoch 78/150\n",
            "202/202 [==============================] - 0s 108us/step - loss: 0.2828 - acc: 0.8911\n",
            "Epoch 79/150\n",
            "202/202 [==============================] - 0s 82us/step - loss: 0.2814 - acc: 0.8911\n",
            "Epoch 80/150\n",
            "202/202 [==============================] - 0s 92us/step - loss: 0.2802 - acc: 0.8911\n",
            "Epoch 81/150\n",
            "202/202 [==============================] - 0s 76us/step - loss: 0.2789 - acc: 0.8911\n",
            "Epoch 82/150\n",
            "202/202 [==============================] - 0s 78us/step - loss: 0.2777 - acc: 0.8911\n",
            "Epoch 83/150\n",
            "202/202 [==============================] - 0s 82us/step - loss: 0.2765 - acc: 0.8911\n",
            "Epoch 84/150\n",
            "202/202 [==============================] - 0s 81us/step - loss: 0.2755 - acc: 0.8911\n",
            "Epoch 85/150\n",
            "202/202 [==============================] - 0s 82us/step - loss: 0.2744 - acc: 0.8911\n",
            "Epoch 86/150\n",
            "202/202 [==============================] - 0s 82us/step - loss: 0.2733 - acc: 0.8911\n",
            "Epoch 87/150\n",
            "202/202 [==============================] - 0s 78us/step - loss: 0.2722 - acc: 0.8911\n",
            "Epoch 88/150\n",
            "202/202 [==============================] - 0s 84us/step - loss: 0.2713 - acc: 0.8911\n",
            "Epoch 89/150\n",
            "202/202 [==============================] - 0s 90us/step - loss: 0.2703 - acc: 0.8911\n",
            "Epoch 90/150\n",
            "202/202 [==============================] - 0s 89us/step - loss: 0.2693 - acc: 0.8911\n",
            "Epoch 91/150\n",
            "202/202 [==============================] - 0s 102us/step - loss: 0.2682 - acc: 0.8911\n",
            "Epoch 92/150\n",
            "202/202 [==============================] - 0s 78us/step - loss: 0.2673 - acc: 0.8911\n",
            "Epoch 93/150\n",
            "202/202 [==============================] - 0s 83us/step - loss: 0.2662 - acc: 0.8911\n",
            "Epoch 94/150\n",
            "202/202 [==============================] - 0s 98us/step - loss: 0.2652 - acc: 0.8911\n",
            "Epoch 95/150\n",
            "202/202 [==============================] - 0s 75us/step - loss: 0.2643 - acc: 0.8911\n",
            "Epoch 96/150\n",
            "202/202 [==============================] - 0s 88us/step - loss: 0.2634 - acc: 0.8911\n",
            "Epoch 97/150\n",
            "202/202 [==============================] - 0s 82us/step - loss: 0.2624 - acc: 0.8911\n",
            "Epoch 98/150\n",
            "202/202 [==============================] - 0s 79us/step - loss: 0.2616 - acc: 0.8911\n",
            "Epoch 99/150\n",
            "202/202 [==============================] - 0s 83us/step - loss: 0.2608 - acc: 0.8911\n",
            "Epoch 100/150\n",
            "202/202 [==============================] - 0s 82us/step - loss: 0.2597 - acc: 0.8911\n",
            "Epoch 101/150\n",
            "202/202 [==============================] - 0s 82us/step - loss: 0.2588 - acc: 0.8911\n",
            "Epoch 102/150\n",
            "202/202 [==============================] - 0s 104us/step - loss: 0.2579 - acc: 0.8911\n",
            "Epoch 103/150\n",
            "202/202 [==============================] - 0s 73us/step - loss: 0.2571 - acc: 0.8911\n",
            "Epoch 104/150\n",
            "202/202 [==============================] - 0s 72us/step - loss: 0.2562 - acc: 0.8911\n",
            "Epoch 105/150\n",
            "202/202 [==============================] - 0s 85us/step - loss: 0.2554 - acc: 0.8911\n",
            "Epoch 106/150\n",
            "202/202 [==============================] - 0s 92us/step - loss: 0.2545 - acc: 0.8911\n",
            "Epoch 107/150\n",
            "202/202 [==============================] - 0s 77us/step - loss: 0.2537 - acc: 0.8911\n",
            "Epoch 108/150\n",
            "202/202 [==============================] - 0s 91us/step - loss: 0.2529 - acc: 0.9010\n",
            "Epoch 109/150\n",
            "202/202 [==============================] - 0s 81us/step - loss: 0.2525 - acc: 0.9010\n",
            "Epoch 110/150\n",
            "202/202 [==============================] - 0s 92us/step - loss: 0.2517 - acc: 0.9010\n",
            "Epoch 111/150\n",
            "202/202 [==============================] - 0s 79us/step - loss: 0.2510 - acc: 0.9010\n",
            "Epoch 112/150\n",
            "202/202 [==============================] - 0s 90us/step - loss: 0.2503 - acc: 0.9010\n",
            "Epoch 113/150\n",
            "202/202 [==============================] - 0s 90us/step - loss: 0.2496 - acc: 0.9010\n",
            "Epoch 114/150\n",
            "202/202 [==============================] - 0s 82us/step - loss: 0.2489 - acc: 0.9010\n",
            "Epoch 115/150\n",
            "202/202 [==============================] - 0s 76us/step - loss: 0.2480 - acc: 0.9010\n",
            "Epoch 116/150\n",
            "202/202 [==============================] - 0s 74us/step - loss: 0.2472 - acc: 0.9010\n",
            "Epoch 117/150\n",
            "202/202 [==============================] - 0s 80us/step - loss: 0.2466 - acc: 0.9010\n",
            "Epoch 118/150\n",
            "202/202 [==============================] - 0s 85us/step - loss: 0.2460 - acc: 0.9010\n",
            "Epoch 119/150\n",
            "202/202 [==============================] - 0s 76us/step - loss: 0.2453 - acc: 0.9059\n",
            "Epoch 120/150\n",
            "202/202 [==============================] - 0s 85us/step - loss: 0.2445 - acc: 0.9059\n",
            "Epoch 121/150\n",
            "202/202 [==============================] - 0s 69us/step - loss: 0.2439 - acc: 0.9059\n",
            "Epoch 122/150\n",
            "202/202 [==============================] - 0s 77us/step - loss: 0.2431 - acc: 0.9059\n",
            "Epoch 123/150\n",
            "202/202 [==============================] - 0s 82us/step - loss: 0.2426 - acc: 0.9059\n",
            "Epoch 124/150\n",
            "202/202 [==============================] - 0s 118us/step - loss: 0.2418 - acc: 0.9059\n",
            "Epoch 125/150\n",
            "202/202 [==============================] - 0s 73us/step - loss: 0.2414 - acc: 0.9059\n",
            "Epoch 126/150\n",
            "202/202 [==============================] - 0s 77us/step - loss: 0.2409 - acc: 0.9059\n",
            "Epoch 127/150\n",
            "202/202 [==============================] - 0s 80us/step - loss: 0.2403 - acc: 0.9059\n",
            "Epoch 128/150\n",
            "202/202 [==============================] - 0s 79us/step - loss: 0.2396 - acc: 0.9059\n",
            "Epoch 129/150\n",
            "202/202 [==============================] - 0s 75us/step - loss: 0.2390 - acc: 0.9059\n",
            "Epoch 130/150\n",
            "202/202 [==============================] - 0s 76us/step - loss: 0.2385 - acc: 0.9059\n",
            "Epoch 131/150\n",
            "202/202 [==============================] - 0s 80us/step - loss: 0.2379 - acc: 0.9059\n",
            "Epoch 132/150\n",
            "202/202 [==============================] - 0s 96us/step - loss: 0.2373 - acc: 0.9059\n",
            "Epoch 133/150\n",
            "202/202 [==============================] - 0s 94us/step - loss: 0.2367 - acc: 0.9059\n",
            "Epoch 134/150\n",
            "202/202 [==============================] - 0s 119us/step - loss: 0.2361 - acc: 0.9059\n",
            "Epoch 135/150\n",
            "202/202 [==============================] - 0s 81us/step - loss: 0.2353 - acc: 0.9109\n",
            "Epoch 136/150\n",
            "202/202 [==============================] - 0s 80us/step - loss: 0.2344 - acc: 0.9109\n",
            "Epoch 137/150\n",
            "202/202 [==============================] - 0s 75us/step - loss: 0.2337 - acc: 0.9109\n",
            "Epoch 138/150\n",
            "202/202 [==============================] - 0s 76us/step - loss: 0.2331 - acc: 0.9109\n",
            "Epoch 139/150\n",
            "202/202 [==============================] - 0s 76us/step - loss: 0.2324 - acc: 0.9109\n",
            "Epoch 140/150\n",
            "202/202 [==============================] - 0s 82us/step - loss: 0.2317 - acc: 0.9109\n",
            "Epoch 141/150\n",
            "202/202 [==============================] - 0s 81us/step - loss: 0.2310 - acc: 0.9109\n",
            "Epoch 142/150\n",
            "202/202 [==============================] - 0s 77us/step - loss: 0.2305 - acc: 0.9109\n",
            "Epoch 143/150\n",
            "202/202 [==============================] - 0s 74us/step - loss: 0.2299 - acc: 0.9109\n",
            "Epoch 144/150\n",
            "202/202 [==============================] - 0s 74us/step - loss: 0.2293 - acc: 0.9158\n",
            "Epoch 145/150\n",
            "202/202 [==============================] - 0s 90us/step - loss: 0.2286 - acc: 0.9158\n",
            "Epoch 146/150\n",
            "202/202 [==============================] - 0s 88us/step - loss: 0.2281 - acc: 0.9158\n",
            "Epoch 147/150\n",
            "202/202 [==============================] - 0s 90us/step - loss: 0.2276 - acc: 0.9158\n",
            "Epoch 148/150\n",
            "202/202 [==============================] - 0s 87us/step - loss: 0.2268 - acc: 0.9158\n",
            "Epoch 149/150\n",
            "202/202 [==============================] - 0s 98us/step - loss: 0.2263 - acc: 0.9158\n",
            "Epoch 150/150\n",
            "202/202 [==============================] - 0s 83us/step - loss: 0.2257 - acc: 0.9158\n",
            "101/101 [==============================] - 1s 8ms/step\n",
            "Epoch 1/20\n",
            "303/303 [==============================] - 2s 7ms/step - loss: 0.9655 - acc: 0.3630\n",
            "Epoch 2/20\n",
            "303/303 [==============================] - 0s 64us/step - loss: 0.9077 - acc: 0.3927\n",
            "Epoch 3/20\n",
            "303/303 [==============================] - 0s 58us/step - loss: 0.8532 - acc: 0.4323\n",
            "Epoch 4/20\n",
            "303/303 [==============================] - 0s 62us/step - loss: 0.8017 - acc: 0.4818\n",
            "Epoch 5/20\n",
            "303/303 [==============================] - 0s 61us/step - loss: 0.7558 - acc: 0.5281\n",
            "Epoch 6/20\n",
            "303/303 [==============================] - 0s 59us/step - loss: 0.7125 - acc: 0.5809\n",
            "Epoch 7/20\n",
            "303/303 [==============================] - 0s 61us/step - loss: 0.6737 - acc: 0.6040\n",
            "Epoch 8/20\n",
            "303/303 [==============================] - 0s 60us/step - loss: 0.6414 - acc: 0.6271\n",
            "Epoch 9/20\n",
            "303/303 [==============================] - 0s 57us/step - loss: 0.6109 - acc: 0.6502\n",
            "Epoch 10/20\n",
            "303/303 [==============================] - 0s 63us/step - loss: 0.5838 - acc: 0.6799\n",
            "Epoch 11/20\n",
            "303/303 [==============================] - 0s 56us/step - loss: 0.5594 - acc: 0.7426\n",
            "Epoch 12/20\n",
            "303/303 [==============================] - 0s 64us/step - loss: 0.5390 - acc: 0.7624\n",
            "Epoch 13/20\n",
            "303/303 [==============================] - 0s 68us/step - loss: 0.5199 - acc: 0.7822\n",
            "Epoch 14/20\n",
            "303/303 [==============================] - 0s 72us/step - loss: 0.5029 - acc: 0.8020\n",
            "Epoch 15/20\n",
            "303/303 [==============================] - 0s 60us/step - loss: 0.4882 - acc: 0.8053\n",
            "Epoch 16/20\n",
            "303/303 [==============================] - 0s 67us/step - loss: 0.4743 - acc: 0.8119\n",
            "Epoch 17/20\n",
            "303/303 [==============================] - 0s 62us/step - loss: 0.4623 - acc: 0.8152\n",
            "Epoch 18/20\n",
            "303/303 [==============================] - 0s 64us/step - loss: 0.4510 - acc: 0.8251\n",
            "Epoch 19/20\n",
            "303/303 [==============================] - 0s 92us/step - loss: 0.4407 - acc: 0.8218\n",
            "Epoch 20/20\n",
            "303/303 [==============================] - 0s 78us/step - loss: 0.4316 - acc: 0.8251\n",
            "Best: 0.719471952014237 using {'batch_size': 40, 'epochs': 20}\n",
            "\n",
            "Means: 0.6666666766991316, Stdev: 0.10236344309861015 with: {'batch_size': 40, 'epochs': 10}\n",
            "Means: 0.719471952014237, Stdev: 0.03267160281553832 with: {'batch_size': 40, 'epochs': 20}\n",
            "Means: 0.6303630305988954, Stdev: 0.11442201899065937 with: {'batch_size': 40, 'epochs': 40}\n",
            "Means: 0.6303630365987029, Stdev: 0.12968239329237696 with: {'batch_size': 40, 'epochs': 60}\n",
            "Means: 0.6897689765042597, Stdev: 0.11779912772301304 with: {'batch_size': 40, 'epochs': 80}\n",
            "Means: 0.6435643499440485, Stdev: 0.10876078275583578 with: {'batch_size': 40, 'epochs': 100}\n",
            "Means: 0.6798679909296949, Stdev: 0.08568155472081472 with: {'batch_size': 40, 'epochs': 150}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5mfKDykXpzK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17632
        },
        "outputId": "42987c4e-c287-48dd-f24c-663503d9e54b"
      },
      "source": [
        "# Gridsearch on activation\n",
        "\n",
        "# define the grid search parameters\n",
        "activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n",
        "param_grid = dict(activation=activation)\n",
        "\n",
        "# Function to create model, required for KerasClassifier\n",
        "def create_model(activation='relu'):\n",
        "\t# create model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(13, input_dim=13, activation=activation))\n",
        "\tmodel.add(Dense(1, activation='sigmoid'))\n",
        "\t# Compile model\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\treturn model\n",
        "\n",
        "# create model\n",
        "model = KerasClassifier(build_fn=create_model, epochs=20, batch_size=40, verbose=1)\n",
        "\n",
        "# Create Grid Search\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1)\n",
        "grid_result = grid.fit(X, y)\n",
        "\n",
        "# Report Results\n",
        "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
            "  warnings.warn(CV_WARNING, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "202/202 [==============================] - 2s 11ms/step - loss: 0.6964 - acc: 0.4653\n",
            "Epoch 2/20\n",
            "202/202 [==============================] - 0s 85us/step - loss: 0.6913 - acc: 0.5198\n",
            "Epoch 3/20\n",
            "202/202 [==============================] - 0s 79us/step - loss: 0.6863 - acc: 0.5644\n",
            "Epoch 4/20\n",
            "202/202 [==============================] - 0s 72us/step - loss: 0.6816 - acc: 0.6089\n",
            "Epoch 5/20\n",
            "202/202 [==============================] - 0s 75us/step - loss: 0.6769 - acc: 0.6535\n",
            "Epoch 6/20\n",
            "202/202 [==============================] - 0s 75us/step - loss: 0.6724 - acc: 0.6931\n",
            "Epoch 7/20\n",
            "202/202 [==============================] - 0s 72us/step - loss: 0.6685 - acc: 0.7178\n",
            "Epoch 8/20\n",
            "202/202 [==============================] - 0s 80us/step - loss: 0.6646 - acc: 0.7228\n",
            "Epoch 9/20\n",
            "202/202 [==============================] - 0s 74us/step - loss: 0.6614 - acc: 0.7228\n",
            "Epoch 10/20\n",
            "202/202 [==============================] - 0s 75us/step - loss: 0.6580 - acc: 0.7426\n",
            "Epoch 11/20\n",
            "202/202 [==============================] - 0s 81us/step - loss: 0.6549 - acc: 0.7525\n",
            "Epoch 12/20\n",
            "202/202 [==============================] - 0s 74us/step - loss: 0.6514 - acc: 0.7574\n",
            "Epoch 13/20\n",
            "202/202 [==============================] - 0s 84us/step - loss: 0.6481 - acc: 0.7574\n",
            "Epoch 14/20\n",
            "202/202 [==============================] - 0s 95us/step - loss: 0.6450 - acc: 0.7574\n",
            "Epoch 15/20\n",
            "202/202 [==============================] - 0s 70us/step - loss: 0.6416 - acc: 0.7574\n",
            "Epoch 16/20\n",
            "202/202 [==============================] - 0s 65us/step - loss: 0.6387 - acc: 0.7475\n",
            "Epoch 17/20\n",
            "202/202 [==============================] - 0s 74us/step - loss: 0.6358 - acc: 0.7327\n",
            "Epoch 18/20\n",
            "202/202 [==============================] - 0s 75us/step - loss: 0.6329 - acc: 0.7277\n",
            "Epoch 19/20\n",
            "202/202 [==============================] - 0s 75us/step - loss: 0.6302 - acc: 0.7327\n",
            "Epoch 20/20\n",
            "202/202 [==============================] - 0s 73us/step - loss: 0.6275 - acc: 0.7327\n",
            "101/101 [==============================] - 1s 9ms/step\n",
            "Epoch 1/20\n",
            "202/202 [==============================] - 2s 11ms/step - loss: 0.7226 - acc: 0.2871\n",
            "Epoch 2/20\n",
            "202/202 [==============================] - 0s 87us/step - loss: 0.7196 - acc: 0.2970\n",
            "Epoch 3/20\n",
            "202/202 [==============================] - 0s 95us/step - loss: 0.7165 - acc: 0.3267\n",
            "Epoch 4/20\n",
            "202/202 [==============================] - 0s 77us/step - loss: 0.7138 - acc: 0.3564\n",
            "Epoch 5/20\n",
            "202/202 [==============================] - 0s 82us/step - loss: 0.7110 - acc: 0.3812\n",
            "Epoch 6/20\n",
            "202/202 [==============================] - 0s 71us/step - loss: 0.7083 - acc: 0.3911\n",
            "Epoch 7/20\n",
            "202/202 [==============================] - 0s 76us/step - loss: 0.7055 - acc: 0.3861\n",
            "Epoch 8/20\n",
            "202/202 [==============================] - 0s 75us/step - loss: 0.7030 - acc: 0.4010\n",
            "Epoch 9/20\n",
            "202/202 [==============================] - 0s 82us/step - loss: 0.7004 - acc: 0.4307\n",
            "Epoch 10/20\n",
            "202/202 [==============================] - 0s 70us/step - loss: 0.6980 - acc: 0.4554\n",
            "Epoch 11/20\n",
            "202/202 [==============================] - 0s 73us/step - loss: 0.6956 - acc: 0.4752\n",
            "Epoch 12/20\n",
            "202/202 [==============================] - 0s 77us/step - loss: 0.6931 - acc: 0.5099\n",
            "Epoch 13/20\n",
            "202/202 [==============================] - 0s 79us/step - loss: 0.6907 - acc: 0.5248\n",
            "Epoch 14/20\n",
            "202/202 [==============================] - 0s 75us/step - loss: 0.6883 - acc: 0.5446\n",
            "Epoch 15/20\n",
            "202/202 [==============================] - 0s 81us/step - loss: 0.6857 - acc: 0.5693\n",
            "Epoch 16/20\n",
            "202/202 [==============================] - 0s 84us/step - loss: 0.6832 - acc: 0.5990\n",
            "Epoch 17/20\n",
            "202/202 [==============================] - 0s 84us/step - loss: 0.6806 - acc: 0.6238\n",
            "Epoch 18/20\n",
            "202/202 [==============================] - 0s 78us/step - loss: 0.6783 - acc: 0.6584\n",
            "Epoch 19/20\n",
            "202/202 [==============================] - 0s 87us/step - loss: 0.6758 - acc: 0.6683\n",
            "Epoch 20/20\n",
            "202/202 [==============================] - 0s 84us/step - loss: 0.6735 - acc: 0.6931\n",
            "101/101 [==============================] - 1s 9ms/step\n",
            "Epoch 1/20\n",
            "202/202 [==============================] - 2s 11ms/step - loss: 0.7356 - acc: 0.2327\n",
            "Epoch 2/20\n",
            "202/202 [==============================] - 0s 83us/step - loss: 0.7286 - acc: 0.2426\n",
            "Epoch 3/20\n",
            "202/202 [==============================] - 0s 90us/step - loss: 0.7215 - acc: 0.2673\n",
            "Epoch 4/20\n",
            "202/202 [==============================] - 0s 85us/step - loss: 0.7146 - acc: 0.3218\n",
            "Epoch 5/20\n",
            "202/202 [==============================] - 0s 81us/step - loss: 0.7079 - acc: 0.3713\n",
            "Epoch 6/20\n",
            "202/202 [==============================] - 0s 71us/step - loss: 0.7011 - acc: 0.4455\n",
            "Epoch 7/20\n",
            "202/202 [==============================] - 0s 81us/step - loss: 0.6947 - acc: 0.5050\n",
            "Epoch 8/20\n",
            "202/202 [==============================] - 0s 78us/step - loss: 0.6884 - acc: 0.5495\n",
            "Epoch 9/20\n",
            "202/202 [==============================] - 0s 74us/step - loss: 0.6824 - acc: 0.6436\n",
            "Epoch 10/20\n",
            "202/202 [==============================] - 0s 76us/step - loss: 0.6769 - acc: 0.6634\n",
            "Epoch 11/20\n",
            "202/202 [==============================] - 0s 72us/step - loss: 0.6721 - acc: 0.7030\n",
            "Epoch 12/20\n",
            "202/202 [==============================] - 0s 74us/step - loss: 0.6666 - acc: 0.7376\n",
            "Epoch 13/20\n",
            "202/202 [==============================] - 0s 76us/step - loss: 0.6613 - acc: 0.7624\n",
            "Epoch 14/20\n",
            "202/202 [==============================] - 0s 73us/step - loss: 0.6558 - acc: 0.7772\n",
            "Epoch 15/20\n",
            "202/202 [==============================] - 0s 78us/step - loss: 0.6503 - acc: 0.8168\n",
            "Epoch 16/20\n",
            "202/202 [==============================] - 0s 72us/step - loss: 0.6449 - acc: 0.8218\n",
            "Epoch 17/20\n",
            "202/202 [==============================] - 0s 88us/step - loss: 0.6396 - acc: 0.8168\n",
            "Epoch 18/20\n",
            "202/202 [==============================] - 0s 87us/step - loss: 0.6345 - acc: 0.8564\n",
            "Epoch 19/20\n",
            "202/202 [==============================] - 0s 104us/step - loss: 0.6292 - acc: 0.8614\n",
            "Epoch 20/20\n",
            "202/202 [==============================] - 0s 100us/step - loss: 0.6242 - acc: 0.8663\n",
            "101/101 [==============================] - 1s 9ms/step\n",
            "Epoch 1/20\n",
            "202/202 [==============================] - 2s 11ms/step - loss: 0.6966 - acc: 0.5842\n",
            "Epoch 2/20\n",
            "202/202 [==============================] - 0s 95us/step - loss: 0.6678 - acc: 0.6287\n",
            "Epoch 3/20\n",
            "202/202 [==============================] - 0s 73us/step - loss: 0.6442 - acc: 0.6782\n",
            "Epoch 4/20\n",
            "202/202 [==============================] - 0s 74us/step - loss: 0.6201 - acc: 0.6733\n",
            "Epoch 5/20\n",
            "202/202 [==============================] - 0s 73us/step - loss: 0.5984 - acc: 0.6931\n",
            "Epoch 6/20\n",
            "202/202 [==============================] - 0s 71us/step - loss: 0.5785 - acc: 0.7079\n",
            "Epoch 7/20\n",
            "202/202 [==============================] - 0s 72us/step - loss: 0.5614 - acc: 0.7277\n",
            "Epoch 8/20\n",
            "202/202 [==============================] - 0s 80us/step - loss: 0.5471 - acc: 0.7327\n",
            "Epoch 9/20\n",
            "202/202 [==============================] - 0s 72us/step - loss: 0.5333 - acc: 0.7574\n",
            "Epoch 10/20\n",
            "202/202 [==============================] - 0s 81us/step - loss: 0.5217 - acc: 0.7624\n",
            "Epoch 11/20\n",
            "202/202 [==============================] - 0s 79us/step - loss: 0.5106 - acc: 0.7673\n",
            "Epoch 12/20\n",
            "202/202 [==============================] - 0s 76us/step - loss: 0.5010 - acc: 0.7822\n",
            "Epoch 13/20\n",
            "202/202 [==============================] - 0s 79us/step - loss: 0.4922 - acc: 0.7822\n",
            "Epoch 14/20\n",
            "202/202 [==============================] - 0s 96us/step - loss: 0.4848 - acc: 0.7871\n",
            "Epoch 15/20\n",
            "202/202 [==============================] - 0s 84us/step - loss: 0.4778 - acc: 0.7871\n",
            "Epoch 16/20\n",
            "202/202 [==============================] - 0s 80us/step - loss: 0.4711 - acc: 0.7871\n",
            "Epoch 17/20\n",
            "202/202 [==============================] - 0s 89us/step - loss: 0.4643 - acc: 0.7871\n",
            "Epoch 18/20\n",
            "202/202 [==============================] - 0s 108us/step - loss: 0.4568 - acc: 0.7970\n",
            "Epoch 19/20\n",
            "202/202 [==============================] - 0s 92us/step - loss: 0.4498 - acc: 0.8069\n",
            "Epoch 20/20\n",
            "202/202 [==============================] - 0s 81us/step - loss: 0.4431 - acc: 0.8218\n",
            "101/101 [==============================] - 1s 10ms/step\n",
            "Epoch 1/20\n",
            "202/202 [==============================] - 2s 12ms/step - loss: 0.7662 - acc: 0.5396\n",
            "Epoch 2/20\n",
            "202/202 [==============================] - 0s 84us/step - loss: 0.7308 - acc: 0.5545\n",
            "Epoch 3/20\n",
            "202/202 [==============================] - 0s 76us/step - loss: 0.7022 - acc: 0.5644\n",
            "Epoch 4/20\n",
            "202/202 [==============================] - 0s 78us/step - loss: 0.6740 - acc: 0.5842\n",
            "Epoch 5/20\n",
            "202/202 [==============================] - 0s 88us/step - loss: 0.6479 - acc: 0.6337\n",
            "Epoch 6/20\n",
            "202/202 [==============================] - 0s 71us/step - loss: 0.6247 - acc: 0.6436\n",
            "Epoch 7/20\n",
            "202/202 [==============================] - 0s 79us/step - loss: 0.6025 - acc: 0.6584\n",
            "Epoch 8/20\n",
            "202/202 [==============================] - 0s 73us/step - loss: 0.5802 - acc: 0.6782\n",
            "Epoch 9/20\n",
            "202/202 [==============================] - 0s 82us/step - loss: 0.5600 - acc: 0.6931\n",
            "Epoch 10/20\n",
            "202/202 [==============================] - 0s 96us/step - loss: 0.5420 - acc: 0.7079\n",
            "Epoch 11/20\n",
            "202/202 [==============================] - 0s 81us/step - loss: 0.5262 - acc: 0.7228\n",
            "Epoch 12/20\n",
            "202/202 [==============================] - 0s 89us/step - loss: 0.5124 - acc: 0.7475\n",
            "Epoch 13/20\n",
            "202/202 [==============================] - 0s 82us/step - loss: 0.4976 - acc: 0.7624\n",
            "Epoch 14/20\n",
            "202/202 [==============================] - 0s 87us/step - loss: 0.4850 - acc: 0.7723\n",
            "Epoch 15/20\n",
            "202/202 [==============================] - 0s 89us/step - loss: 0.4746 - acc: 0.7772\n",
            "Epoch 16/20\n",
            "202/202 [==============================] - 0s 76us/step - loss: 0.4644 - acc: 0.7970\n",
            "Epoch 17/20\n",
            "202/202 [==============================] - 0s 99us/step - loss: 0.4547 - acc: 0.8168\n",
            "Epoch 18/20\n",
            "202/202 [==============================] - 0s 78us/step - loss: 0.4464 - acc: 0.8317\n",
            "Epoch 19/20\n",
            "202/202 [==============================] - 0s 84us/step - loss: 0.4391 - acc: 0.8317\n",
            "Epoch 20/20\n",
            "202/202 [==============================] - 0s 80us/step - loss: 0.4320 - acc: 0.8416\n",
            "101/101 [==============================] - 1s 10ms/step\n",
            "Epoch 1/20\n",
            "202/202 [==============================] - 2s 12ms/step - loss: 0.5943 - acc: 0.7723\n",
            "Epoch 2/20\n",
            "202/202 [==============================] - 0s 91us/step - loss: 0.5674 - acc: 0.7921\n",
            "Epoch 3/20\n",
            "202/202 [==============================] - 0s 64us/step - loss: 0.5427 - acc: 0.7970\n",
            "Epoch 4/20\n",
            "202/202 [==============================] - 0s 67us/step - loss: 0.5217 - acc: 0.8020\n",
            "Epoch 5/20\n",
            "202/202 [==============================] - 0s 77us/step - loss: 0.5025 - acc: 0.8020\n",
            "Epoch 6/20\n",
            "202/202 [==============================] - 0s 72us/step - loss: 0.4849 - acc: 0.8119\n",
            "Epoch 7/20\n",
            "202/202 [==============================] - 0s 73us/step - loss: 0.4696 - acc: 0.8119\n",
            "Epoch 8/20\n",
            "202/202 [==============================] - 0s 70us/step - loss: 0.4557 - acc: 0.8168\n",
            "Epoch 9/20\n",
            "202/202 [==============================] - 0s 77us/step - loss: 0.4442 - acc: 0.8168\n",
            "Epoch 10/20\n",
            "202/202 [==============================] - 0s 67us/step - loss: 0.4334 - acc: 0.8168\n",
            "Epoch 11/20\n",
            "202/202 [==============================] - 0s 75us/step - loss: 0.4236 - acc: 0.8168\n",
            "Epoch 12/20\n",
            "202/202 [==============================] - 0s 75us/step - loss: 0.4143 - acc: 0.8168\n",
            "Epoch 13/20\n",
            "202/202 [==============================] - 0s 78us/step - loss: 0.4060 - acc: 0.8168\n",
            "Epoch 14/20\n",
            "202/202 [==============================] - 0s 83us/step - loss: 0.3983 - acc: 0.8168\n",
            "Epoch 15/20\n",
            "202/202 [==============================] - 0s 70us/step - loss: 0.3906 - acc: 0.8168\n",
            "Epoch 16/20\n",
            "202/202 [==============================] - 0s 89us/step - loss: 0.3846 - acc: 0.8218\n",
            "Epoch 17/20\n",
            "202/202 [==============================] - 0s 85us/step - loss: 0.3784 - acc: 0.8267\n",
            "Epoch 18/20\n",
            "202/202 [==============================] - 0s 82us/step - loss: 0.3734 - acc: 0.8267\n",
            "Epoch 19/20\n",
            "202/202 [==============================] - 0s 73us/step - loss: 0.3683 - acc: 0.8267\n",
            "Epoch 20/20\n",
            "202/202 [==============================] - 0s 74us/step - loss: 0.3633 - acc: 0.8366\n",
            "101/101 [==============================] - 1s 10ms/step\n",
            "Epoch 1/20\n",
            "202/202 [==============================] - 2s 12ms/step - loss: 0.6751 - acc: 0.5891\n",
            "Epoch 2/20\n",
            "202/202 [==============================] - 0s 79us/step - loss: 0.6581 - acc: 0.6238\n",
            "Epoch 3/20\n",
            "202/202 [==============================] - 0s 74us/step - loss: 0.6425 - acc: 0.6584\n",
            "Epoch 4/20\n",
            "202/202 [==============================] - 0s 78us/step - loss: 0.6275 - acc: 0.6782\n",
            "Epoch 5/20\n",
            "202/202 [==============================] - 0s 76us/step - loss: 0.6126 - acc: 0.6980\n",
            "Epoch 6/20\n",
            "202/202 [==============================] - 0s 73us/step - loss: 0.5994 - acc: 0.7277\n",
            "Epoch 7/20\n",
            "202/202 [==============================] - 0s 68us/step - loss: 0.5863 - acc: 0.7327\n",
            "Epoch 8/20\n",
            "202/202 [==============================] - 0s 97us/step - loss: 0.5744 - acc: 0.7525\n",
            "Epoch 9/20\n",
            "202/202 [==============================] - 0s 78us/step - loss: 0.5635 - acc: 0.7673\n",
            "Epoch 10/20\n",
            "202/202 [==============================] - 0s 82us/step - loss: 0.5533 - acc: 0.7822\n",
            "Epoch 11/20\n",
            "202/202 [==============================] - 0s 83us/step - loss: 0.5443 - acc: 0.7921\n",
            "Epoch 12/20\n",
            "202/202 [==============================] - 0s 88us/step - loss: 0.5362 - acc: 0.7871\n",
            "Epoch 13/20\n",
            "202/202 [==============================] - 0s 90us/step - loss: 0.5285 - acc: 0.7921\n",
            "Epoch 14/20\n",
            "202/202 [==============================] - 0s 93us/step - loss: 0.5204 - acc: 0.7871\n",
            "Epoch 15/20\n",
            "202/202 [==============================] - 0s 101us/step - loss: 0.5133 - acc: 0.7921\n",
            "Epoch 16/20\n",
            "202/202 [==============================] - 0s 80us/step - loss: 0.5061 - acc: 0.7970\n",
            "Epoch 17/20\n",
            "202/202 [==============================] - 0s 75us/step - loss: 0.4987 - acc: 0.7970\n",
            "Epoch 18/20\n",
            "202/202 [==============================] - 0s 80us/step - loss: 0.4914 - acc: 0.8020\n",
            "Epoch 19/20\n",
            "202/202 [==============================] - 0s 77us/step - loss: 0.4845 - acc: 0.8069\n",
            "Epoch 20/20\n",
            "202/202 [==============================] - 0s 78us/step - loss: 0.4784 - acc: 0.8119\n",
            "101/101 [==============================] - 1s 10ms/step\n",
            "Epoch 1/20\n",
            "202/202 [==============================] - 3s 13ms/step - loss: 0.8967 - acc: 0.2723\n",
            "Epoch 2/20\n",
            "202/202 [==============================] - 0s 89us/step - loss: 0.8733 - acc: 0.2970\n",
            "Epoch 3/20\n",
            "202/202 [==============================] - 0s 87us/step - loss: 0.8509 - acc: 0.3069\n",
            "Epoch 4/20\n",
            "202/202 [==============================] - 0s 81us/step - loss: 0.8313 - acc: 0.3317\n",
            "Epoch 5/20\n",
            "202/202 [==============================] - 0s 84us/step - loss: 0.8112 - acc: 0.3713\n",
            "Epoch 6/20\n",
            "202/202 [==============================] - 0s 89us/step - loss: 0.7928 - acc: 0.4059\n",
            "Epoch 7/20\n",
            "202/202 [==============================] - 0s 85us/step - loss: 0.7749 - acc: 0.4257\n",
            "Epoch 8/20\n",
            "202/202 [==============================] - 0s 87us/step - loss: 0.7590 - acc: 0.4455\n",
            "Epoch 9/20\n",
            "202/202 [==============================] - 0s 95us/step - loss: 0.7437 - acc: 0.4851\n",
            "Epoch 10/20\n",
            "202/202 [==============================] - 0s 99us/step - loss: 0.7301 - acc: 0.5050\n",
            "Epoch 11/20\n",
            "202/202 [==============================] - 0s 86us/step - loss: 0.7165 - acc: 0.5297\n",
            "Epoch 12/20\n",
            "202/202 [==============================] - 0s 89us/step - loss: 0.7035 - acc: 0.5594\n",
            "Epoch 13/20\n",
            "202/202 [==============================] - 0s 84us/step - loss: 0.6912 - acc: 0.5792\n",
            "Epoch 14/20\n",
            "202/202 [==============================] - 0s 82us/step - loss: 0.6789 - acc: 0.5792\n",
            "Epoch 15/20\n",
            "202/202 [==============================] - 0s 82us/step - loss: 0.6669 - acc: 0.6089\n",
            "Epoch 16/20\n",
            "202/202 [==============================] - 0s 78us/step - loss: 0.6555 - acc: 0.6386\n",
            "Epoch 17/20\n",
            "202/202 [==============================] - 0s 90us/step - loss: 0.6449 - acc: 0.6485\n",
            "Epoch 18/20\n",
            "202/202 [==============================] - 0s 82us/step - loss: 0.6348 - acc: 0.6584\n",
            "Epoch 19/20\n",
            "202/202 [==============================] - 0s 91us/step - loss: 0.6249 - acc: 0.6832\n",
            "Epoch 20/20\n",
            "202/202 [==============================] - 0s 97us/step - loss: 0.6147 - acc: 0.7030\n",
            "101/101 [==============================] - 1s 10ms/step\n",
            "Epoch 1/20\n",
            "202/202 [==============================] - 3s 13ms/step - loss: 0.6140 - acc: 0.7376\n",
            "Epoch 2/20\n",
            "202/202 [==============================] - 0s 106us/step - loss: 0.5952 - acc: 0.7574\n",
            "Epoch 3/20\n",
            "202/202 [==============================] - 0s 75us/step - loss: 0.5783 - acc: 0.7723\n",
            "Epoch 4/20\n",
            "202/202 [==============================] - 0s 85us/step - loss: 0.5621 - acc: 0.7822\n",
            "Epoch 5/20\n",
            "202/202 [==============================] - 0s 96us/step - loss: 0.5460 - acc: 0.7871\n",
            "Epoch 6/20\n",
            "202/202 [==============================] - 0s 154us/step - loss: 0.5317 - acc: 0.8020\n",
            "Epoch 7/20\n",
            "202/202 [==============================] - 0s 80us/step - loss: 0.5188 - acc: 0.8119\n",
            "Epoch 8/20\n",
            "202/202 [==============================] - 0s 81us/step - loss: 0.5060 - acc: 0.8168\n",
            "Epoch 9/20\n",
            "202/202 [==============================] - 0s 76us/step - loss: 0.4933 - acc: 0.8317\n",
            "Epoch 10/20\n",
            "202/202 [==============================] - 0s 82us/step - loss: 0.4818 - acc: 0.8366\n",
            "Epoch 11/20\n",
            "202/202 [==============================] - 0s 93us/step - loss: 0.4711 - acc: 0.8465\n",
            "Epoch 12/20\n",
            "202/202 [==============================] - 0s 94us/step - loss: 0.4605 - acc: 0.8465\n",
            "Epoch 13/20\n",
            "202/202 [==============================] - 0s 92us/step - loss: 0.4510 - acc: 0.8564\n",
            "Epoch 14/20\n",
            "202/202 [==============================] - 0s 84us/step - loss: 0.4434 - acc: 0.8564\n",
            "Epoch 15/20\n",
            "202/202 [==============================] - 0s 112us/step - loss: 0.4364 - acc: 0.8614\n",
            "Epoch 16/20\n",
            "202/202 [==============================] - 0s 79us/step - loss: 0.4291 - acc: 0.8614\n",
            "Epoch 17/20\n",
            "202/202 [==============================] - 0s 125us/step - loss: 0.4217 - acc: 0.8614\n",
            "Epoch 18/20\n",
            "202/202 [==============================] - 0s 110us/step - loss: 0.4147 - acc: 0.8614\n",
            "Epoch 19/20\n",
            "202/202 [==============================] - 0s 92us/step - loss: 0.4082 - acc: 0.8663\n",
            "Epoch 20/20\n",
            "202/202 [==============================] - 0s 82us/step - loss: 0.4016 - acc: 0.8663\n",
            "101/101 [==============================] - 1s 11ms/step\n",
            "Epoch 1/20\n",
            "202/202 [==============================] - 3s 13ms/step - loss: 1.7360 - acc: 0.3168\n",
            "Epoch 2/20\n",
            "202/202 [==============================] - 0s 80us/step - loss: 1.6645 - acc: 0.3168\n",
            "Epoch 3/20\n",
            "202/202 [==============================] - 0s 79us/step - loss: 1.5946 - acc: 0.3168\n",
            "Epoch 4/20\n",
            "202/202 [==============================] - 0s 80us/step - loss: 1.5311 - acc: 0.3168\n",
            "Epoch 5/20\n",
            "202/202 [==============================] - 0s 86us/step - loss: 1.4680 - acc: 0.3168\n",
            "Epoch 6/20\n",
            "202/202 [==============================] - 0s 79us/step - loss: 1.4049 - acc: 0.3168\n",
            "Epoch 7/20\n",
            "202/202 [==============================] - 0s 108us/step - loss: 1.3467 - acc: 0.3168\n",
            "Epoch 8/20\n",
            "202/202 [==============================] - 0s 74us/step - loss: 1.2907 - acc: 0.3168\n",
            "Epoch 9/20\n",
            "202/202 [==============================] - 0s 82us/step - loss: 1.2375 - acc: 0.3168\n",
            "Epoch 10/20\n",
            "202/202 [==============================] - 0s 74us/step - loss: 1.1882 - acc: 0.3168\n",
            "Epoch 11/20\n",
            "202/202 [==============================] - 0s 78us/step - loss: 1.1388 - acc: 0.3168\n",
            "Epoch 12/20\n",
            "202/202 [==============================] - 0s 94us/step - loss: 1.0981 - acc: 0.3168\n",
            "Epoch 13/20\n",
            "202/202 [==============================] - 0s 82us/step - loss: 1.0595 - acc: 0.3168\n",
            "Epoch 14/20\n",
            "202/202 [==============================] - 0s 96us/step - loss: 1.0212 - acc: 0.3168\n",
            "Epoch 15/20\n",
            "202/202 [==============================] - 0s 87us/step - loss: 0.9871 - acc: 0.3168\n",
            "Epoch 16/20\n",
            "202/202 [==============================] - 0s 90us/step - loss: 0.9546 - acc: 0.3267\n",
            "Epoch 17/20\n",
            "202/202 [==============================] - 0s 84us/step - loss: 0.9254 - acc: 0.3317\n",
            "Epoch 18/20\n",
            "202/202 [==============================] - 0s 80us/step - loss: 0.8968 - acc: 0.3267\n",
            "Epoch 19/20\n",
            "202/202 [==============================] - 0s 79us/step - loss: 0.8706 - acc: 0.3564\n",
            "Epoch 20/20\n",
            "202/202 [==============================] - 0s 83us/step - loss: 0.8437 - acc: 0.3762\n",
            "101/101 [==============================] - 1s 11ms/step\n",
            "Epoch 1/20\n",
            "202/202 [==============================] - 3s 13ms/step - loss: 0.8872 - acc: 0.5248\n",
            "Epoch 2/20\n",
            "202/202 [==============================] - 0s 75us/step - loss: 0.8611 - acc: 0.5396\n",
            "Epoch 3/20\n",
            "202/202 [==============================] - 0s 76us/step - loss: 0.8354 - acc: 0.5446\n",
            "Epoch 4/20\n",
            "202/202 [==============================] - 0s 82us/step - loss: 0.8132 - acc: 0.5495\n",
            "Epoch 5/20\n",
            "202/202 [==============================] - 0s 78us/step - loss: 0.7942 - acc: 0.5594\n",
            "Epoch 6/20\n",
            "202/202 [==============================] - 0s 80us/step - loss: 0.7742 - acc: 0.5693\n",
            "Epoch 7/20\n",
            "202/202 [==============================] - 0s 80us/step - loss: 0.7560 - acc: 0.5693\n",
            "Epoch 8/20\n",
            "202/202 [==============================] - 0s 87us/step - loss: 0.7386 - acc: 0.5990\n",
            "Epoch 9/20\n",
            "202/202 [==============================] - 0s 79us/step - loss: 0.7221 - acc: 0.6040\n",
            "Epoch 10/20\n",
            "202/202 [==============================] - 0s 80us/step - loss: 0.7064 - acc: 0.6287\n",
            "Epoch 11/20\n",
            "202/202 [==============================] - 0s 74us/step - loss: 0.6912 - acc: 0.6337\n",
            "Epoch 12/20\n",
            "202/202 [==============================] - 0s 75us/step - loss: 0.6771 - acc: 0.6485\n",
            "Epoch 13/20\n",
            "202/202 [==============================] - 0s 65us/step - loss: 0.6626 - acc: 0.6485\n",
            "Epoch 14/20\n",
            "202/202 [==============================] - 0s 76us/step - loss: 0.6489 - acc: 0.6584\n",
            "Epoch 15/20\n",
            "202/202 [==============================] - 0s 83us/step - loss: 0.6352 - acc: 0.6683\n",
            "Epoch 16/20\n",
            "202/202 [==============================] - 0s 78us/step - loss: 0.6236 - acc: 0.6782\n",
            "Epoch 17/20\n",
            "202/202 [==============================] - 0s 82us/step - loss: 0.6132 - acc: 0.6832\n",
            "Epoch 18/20\n",
            "202/202 [==============================] - 0s 76us/step - loss: 0.6032 - acc: 0.6832\n",
            "Epoch 19/20\n",
            "202/202 [==============================] - 0s 81us/step - loss: 0.5932 - acc: 0.6881\n",
            "Epoch 20/20\n",
            "202/202 [==============================] - 0s 93us/step - loss: 0.5831 - acc: 0.6931\n",
            "101/101 [==============================] - 1s 11ms/step\n",
            "Epoch 1/20\n",
            "202/202 [==============================] - 3s 13ms/step - loss: 0.9548 - acc: 0.1881\n",
            "Epoch 2/20\n",
            "202/202 [==============================] - 0s 81us/step - loss: 0.9169 - acc: 0.1980\n",
            "Epoch 3/20\n",
            "202/202 [==============================] - 0s 85us/step - loss: 0.8819 - acc: 0.2327\n",
            "Epoch 4/20\n",
            "202/202 [==============================] - 0s 81us/step - loss: 0.8486 - acc: 0.2475\n",
            "Epoch 5/20\n",
            "202/202 [==============================] - 0s 73us/step - loss: 0.8173 - acc: 0.2624\n",
            "Epoch 6/20\n",
            "202/202 [==============================] - 0s 84us/step - loss: 0.7882 - acc: 0.2970\n",
            "Epoch 7/20\n",
            "202/202 [==============================] - 0s 81us/step - loss: 0.7605 - acc: 0.3564\n",
            "Epoch 8/20\n",
            "202/202 [==============================] - 0s 79us/step - loss: 0.7335 - acc: 0.3812\n",
            "Epoch 9/20\n",
            "202/202 [==============================] - 0s 79us/step - loss: 0.7083 - acc: 0.4703\n",
            "Epoch 10/20\n",
            "202/202 [==============================] - 0s 78us/step - loss: 0.6847 - acc: 0.5545\n",
            "Epoch 11/20\n",
            "202/202 [==============================] - 0s 85us/step - loss: 0.6630 - acc: 0.6238\n",
            "Epoch 12/20\n",
            "202/202 [==============================] - 0s 82us/step - loss: 0.6417 - acc: 0.6980\n",
            "Epoch 13/20\n",
            "202/202 [==============================] - 0s 96us/step - loss: 0.6217 - acc: 0.7277\n",
            "Epoch 14/20\n",
            "202/202 [==============================] - 0s 104us/step - loss: 0.6031 - acc: 0.7525\n",
            "Epoch 15/20\n",
            "202/202 [==============================] - 0s 97us/step - loss: 0.5866 - acc: 0.7772\n",
            "Epoch 16/20\n",
            "202/202 [==============================] - 0s 92us/step - loss: 0.5706 - acc: 0.8119\n",
            "Epoch 17/20\n",
            "202/202 [==============================] - 0s 82us/step - loss: 0.5568 - acc: 0.8267\n",
            "Epoch 18/20\n",
            "202/202 [==============================] - 0s 78us/step - loss: 0.5430 - acc: 0.8267\n",
            "Epoch 19/20\n",
            "202/202 [==============================] - 0s 96us/step - loss: 0.5294 - acc: 0.8317\n",
            "Epoch 20/20\n",
            "202/202 [==============================] - 0s 105us/step - loss: 0.5159 - acc: 0.8416\n",
            "101/101 [==============================] - 1s 11ms/step\n",
            "Epoch 1/20\n",
            "202/202 [==============================] - 3s 14ms/step - loss: 0.7675 - acc: 0.5099\n",
            "Epoch 2/20\n",
            "202/202 [==============================] - 0s 80us/step - loss: 0.7288 - acc: 0.5446\n",
            "Epoch 3/20\n",
            "202/202 [==============================] - 0s 81us/step - loss: 0.6946 - acc: 0.5842\n",
            "Epoch 4/20\n",
            "202/202 [==============================] - 0s 83us/step - loss: 0.6651 - acc: 0.6040\n",
            "Epoch 5/20\n",
            "202/202 [==============================] - 0s 85us/step - loss: 0.6372 - acc: 0.6535\n",
            "Epoch 6/20\n",
            "202/202 [==============================] - 0s 82us/step - loss: 0.6119 - acc: 0.6733\n",
            "Epoch 7/20\n",
            "202/202 [==============================] - 0s 90us/step - loss: 0.5885 - acc: 0.6980\n",
            "Epoch 8/20\n",
            "202/202 [==============================] - 0s 103us/step - loss: 0.5662 - acc: 0.7376\n",
            "Epoch 9/20\n",
            "202/202 [==============================] - 0s 107us/step - loss: 0.5488 - acc: 0.7475\n",
            "Epoch 10/20\n",
            "202/202 [==============================] - 0s 90us/step - loss: 0.5311 - acc: 0.7673\n",
            "Epoch 11/20\n",
            "202/202 [==============================] - 0s 101us/step - loss: 0.5156 - acc: 0.7772\n",
            "Epoch 12/20\n",
            "202/202 [==============================] - 0s 92us/step - loss: 0.5029 - acc: 0.7871\n",
            "Epoch 13/20\n",
            "202/202 [==============================] - 0s 99us/step - loss: 0.4914 - acc: 0.7921\n",
            "Epoch 14/20\n",
            "202/202 [==============================] - 0s 81us/step - loss: 0.4814 - acc: 0.8069\n",
            "Epoch 15/20\n",
            "202/202 [==============================] - 0s 98us/step - loss: 0.4703 - acc: 0.8218\n",
            "Epoch 16/20\n",
            "202/202 [==============================] - 0s 93us/step - loss: 0.4610 - acc: 0.8218\n",
            "Epoch 17/20\n",
            "202/202 [==============================] - 0s 80us/step - loss: 0.4519 - acc: 0.8218\n",
            "Epoch 18/20\n",
            "202/202 [==============================] - 0s 93us/step - loss: 0.4431 - acc: 0.8218\n",
            "Epoch 19/20\n",
            "202/202 [==============================] - 0s 96us/step - loss: 0.4358 - acc: 0.8218\n",
            "Epoch 20/20\n",
            "202/202 [==============================] - 0s 82us/step - loss: 0.4294 - acc: 0.8218\n",
            "101/101 [==============================] - 1s 12ms/step\n",
            "Epoch 1/20\n",
            "202/202 [==============================] - 3s 14ms/step - loss: 0.7743 - acc: 0.4604\n",
            "Epoch 2/20\n",
            "202/202 [==============================] - 0s 96us/step - loss: 0.7475 - acc: 0.4851\n",
            "Epoch 3/20\n",
            "202/202 [==============================] - 0s 81us/step - loss: 0.7227 - acc: 0.5099\n",
            "Epoch 4/20\n",
            "202/202 [==============================] - 0s 78us/step - loss: 0.7006 - acc: 0.5396\n",
            "Epoch 5/20\n",
            "202/202 [==============================] - 0s 77us/step - loss: 0.6783 - acc: 0.5792\n",
            "Epoch 6/20\n",
            "202/202 [==============================] - 0s 81us/step - loss: 0.6584 - acc: 0.6089\n",
            "Epoch 7/20\n",
            "202/202 [==============================] - 0s 88us/step - loss: 0.6390 - acc: 0.6436\n",
            "Epoch 8/20\n",
            "202/202 [==============================] - 0s 97us/step - loss: 0.6212 - acc: 0.6683\n",
            "Epoch 9/20\n",
            "202/202 [==============================] - 0s 95us/step - loss: 0.6046 - acc: 0.6881\n",
            "Epoch 10/20\n",
            "202/202 [==============================] - 0s 85us/step - loss: 0.5881 - acc: 0.7129\n",
            "Epoch 11/20\n",
            "202/202 [==============================] - 0s 79us/step - loss: 0.5731 - acc: 0.7277\n",
            "Epoch 12/20\n",
            "202/202 [==============================] - 0s 89us/step - loss: 0.5598 - acc: 0.7426\n",
            "Epoch 13/20\n",
            "202/202 [==============================] - 0s 99us/step - loss: 0.5476 - acc: 0.7574\n",
            "Epoch 14/20\n",
            "202/202 [==============================] - 0s 92us/step - loss: 0.5355 - acc: 0.7624\n",
            "Epoch 15/20\n",
            "202/202 [==============================] - 0s 101us/step - loss: 0.5240 - acc: 0.7624\n",
            "Epoch 16/20\n",
            "202/202 [==============================] - 0s 96us/step - loss: 0.5135 - acc: 0.7624\n",
            "Epoch 17/20\n",
            "202/202 [==============================] - 0s 90us/step - loss: 0.5041 - acc: 0.7723\n",
            "Epoch 18/20\n",
            "202/202 [==============================] - 0s 91us/step - loss: 0.4957 - acc: 0.7723\n",
            "Epoch 19/20\n",
            "202/202 [==============================] - 0s 87us/step - loss: 0.4885 - acc: 0.7871\n",
            "Epoch 20/20\n",
            "202/202 [==============================] - 0s 85us/step - loss: 0.4821 - acc: 0.7921\n",
            "101/101 [==============================] - 1s 12ms/step\n",
            "Epoch 1/20\n",
            "202/202 [==============================] - 3s 14ms/step - loss: 1.0094 - acc: 0.3069\n",
            "Epoch 2/20\n",
            "202/202 [==============================] - 0s 93us/step - loss: 0.9675 - acc: 0.3168\n",
            "Epoch 3/20\n",
            "202/202 [==============================] - 0s 76us/step - loss: 0.9271 - acc: 0.3218\n",
            "Epoch 4/20\n",
            "202/202 [==============================] - 0s 83us/step - loss: 0.8873 - acc: 0.3564\n",
            "Epoch 5/20\n",
            "202/202 [==============================] - 0s 77us/step - loss: 0.8473 - acc: 0.3960\n",
            "Epoch 6/20\n",
            "202/202 [==============================] - 0s 93us/step - loss: 0.8104 - acc: 0.4307\n",
            "Epoch 7/20\n",
            "202/202 [==============================] - 0s 93us/step - loss: 0.7753 - acc: 0.4554\n",
            "Epoch 8/20\n",
            "202/202 [==============================] - 0s 91us/step - loss: 0.7431 - acc: 0.4901\n",
            "Epoch 9/20\n",
            "202/202 [==============================] - 0s 82us/step - loss: 0.7132 - acc: 0.5347\n",
            "Epoch 10/20\n",
            "202/202 [==============================] - 0s 93us/step - loss: 0.6853 - acc: 0.5842\n",
            "Epoch 11/20\n",
            "202/202 [==============================] - 0s 90us/step - loss: 0.6598 - acc: 0.6139\n",
            "Epoch 12/20\n",
            "202/202 [==============================] - 0s 100us/step - loss: 0.6351 - acc: 0.6436\n",
            "Epoch 13/20\n",
            "202/202 [==============================] - 0s 80us/step - loss: 0.6113 - acc: 0.6980\n",
            "Epoch 14/20\n",
            "202/202 [==============================] - 0s 100us/step - loss: 0.5895 - acc: 0.7475\n",
            "Epoch 15/20\n",
            "202/202 [==============================] - 0s 87us/step - loss: 0.5704 - acc: 0.7970\n",
            "Epoch 16/20\n",
            "202/202 [==============================] - 0s 85us/step - loss: 0.5512 - acc: 0.8069\n",
            "Epoch 17/20\n",
            "202/202 [==============================] - 0s 71us/step - loss: 0.5341 - acc: 0.8119\n",
            "Epoch 18/20\n",
            "202/202 [==============================] - 0s 92us/step - loss: 0.5176 - acc: 0.8168\n",
            "Epoch 19/20\n",
            "202/202 [==============================] - 0s 88us/step - loss: 0.5029 - acc: 0.8267\n",
            "Epoch 20/20\n",
            "202/202 [==============================] - 0s 92us/step - loss: 0.4884 - acc: 0.8366\n",
            "101/101 [==============================] - 1s 12ms/step\n",
            "Epoch 1/20\n",
            "202/202 [==============================] - 3s 15ms/step - loss: 0.6290 - acc: 0.6832\n",
            "Epoch 2/20\n",
            "202/202 [==============================] - 0s 91us/step - loss: 0.6196 - acc: 0.6832\n",
            "Epoch 3/20\n",
            "202/202 [==============================] - 0s 86us/step - loss: 0.6113 - acc: 0.6832\n",
            "Epoch 4/20\n",
            "202/202 [==============================] - 0s 83us/step - loss: 0.6030 - acc: 0.6832\n",
            "Epoch 5/20\n",
            "202/202 [==============================] - 0s 81us/step - loss: 0.5951 - acc: 0.6832\n",
            "Epoch 6/20\n",
            "202/202 [==============================] - 0s 84us/step - loss: 0.5877 - acc: 0.6832\n",
            "Epoch 7/20\n",
            "202/202 [==============================] - 0s 92us/step - loss: 0.5797 - acc: 0.6832\n",
            "Epoch 8/20\n",
            "202/202 [==============================] - 0s 86us/step - loss: 0.5724 - acc: 0.6832\n",
            "Epoch 9/20\n",
            "202/202 [==============================] - 0s 84us/step - loss: 0.5649 - acc: 0.6832\n",
            "Epoch 10/20\n",
            "202/202 [==============================] - 0s 83us/step - loss: 0.5579 - acc: 0.6832\n",
            "Epoch 11/20\n",
            "202/202 [==============================] - 0s 77us/step - loss: 0.5513 - acc: 0.6832\n",
            "Epoch 12/20\n",
            "202/202 [==============================] - 0s 81us/step - loss: 0.5449 - acc: 0.6832\n",
            "Epoch 13/20\n",
            "202/202 [==============================] - 0s 110us/step - loss: 0.5398 - acc: 0.6832\n",
            "Epoch 14/20\n",
            "202/202 [==============================] - 0s 87us/step - loss: 0.5340 - acc: 0.6832\n",
            "Epoch 15/20\n",
            "202/202 [==============================] - 0s 85us/step - loss: 0.5286 - acc: 0.6832\n",
            "Epoch 16/20\n",
            "202/202 [==============================] - 0s 85us/step - loss: 0.5234 - acc: 0.6832\n",
            "Epoch 17/20\n",
            "202/202 [==============================] - 0s 116us/step - loss: 0.5192 - acc: 0.6832\n",
            "Epoch 18/20\n",
            "202/202 [==============================] - 0s 101us/step - loss: 0.5156 - acc: 0.6881\n",
            "Epoch 19/20\n",
            "202/202 [==============================] - 0s 112us/step - loss: 0.5120 - acc: 0.6931\n",
            "Epoch 20/20\n",
            "202/202 [==============================] - 0s 89us/step - loss: 0.5083 - acc: 0.6980\n",
            "101/101 [==============================] - 1s 12ms/step\n",
            "Epoch 1/20\n",
            "202/202 [==============================] - 3s 15ms/step - loss: 0.7668 - acc: 0.4455\n",
            "Epoch 2/20\n",
            "202/202 [==============================] - 0s 83us/step - loss: 0.7591 - acc: 0.4455\n",
            "Epoch 3/20\n",
            "202/202 [==============================] - 0s 84us/step - loss: 0.7519 - acc: 0.4554\n",
            "Epoch 4/20\n",
            "202/202 [==============================] - 0s 88us/step - loss: 0.7450 - acc: 0.4653\n",
            "Epoch 5/20\n",
            "202/202 [==============================] - 0s 82us/step - loss: 0.7386 - acc: 0.4752\n",
            "Epoch 6/20\n",
            "202/202 [==============================] - 0s 82us/step - loss: 0.7328 - acc: 0.4752\n",
            "Epoch 7/20\n",
            "202/202 [==============================] - 0s 83us/step - loss: 0.7272 - acc: 0.4752\n",
            "Epoch 8/20\n",
            "202/202 [==============================] - 0s 76us/step - loss: 0.7208 - acc: 0.4752\n",
            "Epoch 9/20\n",
            "202/202 [==============================] - 0s 76us/step - loss: 0.7144 - acc: 0.4851\n",
            "Epoch 10/20\n",
            "202/202 [==============================] - 0s 81us/step - loss: 0.7079 - acc: 0.4851\n",
            "Epoch 11/20\n",
            "202/202 [==============================] - 0s 94us/step - loss: 0.7018 - acc: 0.4901\n",
            "Epoch 12/20\n",
            "202/202 [==============================] - 0s 94us/step - loss: 0.6958 - acc: 0.5000\n",
            "Epoch 13/20\n",
            "202/202 [==============================] - 0s 85us/step - loss: 0.6895 - acc: 0.5000\n",
            "Epoch 14/20\n",
            "202/202 [==============================] - 0s 82us/step - loss: 0.6837 - acc: 0.5198\n",
            "Epoch 15/20\n",
            "202/202 [==============================] - 0s 80us/step - loss: 0.6780 - acc: 0.5545\n",
            "Epoch 16/20\n",
            "202/202 [==============================] - 0s 105us/step - loss: 0.6727 - acc: 0.5792\n",
            "Epoch 17/20\n",
            "202/202 [==============================] - 0s 83us/step - loss: 0.6673 - acc: 0.5891\n",
            "Epoch 18/20\n",
            "202/202 [==============================] - 0s 96us/step - loss: 0.6623 - acc: 0.6089\n",
            "Epoch 19/20\n",
            "202/202 [==============================] - 0s 114us/step - loss: 0.6573 - acc: 0.6287\n",
            "Epoch 20/20\n",
            "202/202 [==============================] - 0s 89us/step - loss: 0.6524 - acc: 0.6535\n",
            "101/101 [==============================] - 1s 12ms/step\n",
            "Epoch 1/20\n",
            "202/202 [==============================] - 3s 15ms/step - loss: 0.6622 - acc: 0.6634\n",
            "Epoch 2/20\n",
            "202/202 [==============================] - 0s 80us/step - loss: 0.6433 - acc: 0.7277\n",
            "Epoch 3/20\n",
            "202/202 [==============================] - 0s 95us/step - loss: 0.6258 - acc: 0.7327\n",
            "Epoch 4/20\n",
            "202/202 [==============================] - 0s 91us/step - loss: 0.6096 - acc: 0.7772\n",
            "Epoch 5/20\n",
            "202/202 [==============================] - 0s 85us/step - loss: 0.5944 - acc: 0.7921\n",
            "Epoch 6/20\n",
            "202/202 [==============================] - 0s 83us/step - loss: 0.5795 - acc: 0.8119\n",
            "Epoch 7/20\n",
            "202/202 [==============================] - 0s 88us/step - loss: 0.5655 - acc: 0.8119\n",
            "Epoch 8/20\n",
            "202/202 [==============================] - 0s 85us/step - loss: 0.5529 - acc: 0.8119\n",
            "Epoch 9/20\n",
            "202/202 [==============================] - 0s 89us/step - loss: 0.5405 - acc: 0.8168\n",
            "Epoch 10/20\n",
            "202/202 [==============================] - 0s 86us/step - loss: 0.5298 - acc: 0.8168\n",
            "Epoch 11/20\n",
            "202/202 [==============================] - 0s 86us/step - loss: 0.5199 - acc: 0.8168\n",
            "Epoch 12/20\n",
            "202/202 [==============================] - 0s 84us/step - loss: 0.5104 - acc: 0.8168\n",
            "Epoch 13/20\n",
            "202/202 [==============================] - 0s 100us/step - loss: 0.5014 - acc: 0.8168\n",
            "Epoch 14/20\n",
            "202/202 [==============================] - 0s 93us/step - loss: 0.4936 - acc: 0.8168\n",
            "Epoch 15/20\n",
            "202/202 [==============================] - 0s 95us/step - loss: 0.4873 - acc: 0.8168\n",
            "Epoch 16/20\n",
            "202/202 [==============================] - 0s 90us/step - loss: 0.4811 - acc: 0.8168\n",
            "Epoch 17/20\n",
            "202/202 [==============================] - 0s 108us/step - loss: 0.4745 - acc: 0.8168\n",
            "Epoch 18/20\n",
            "202/202 [==============================] - 0s 94us/step - loss: 0.4686 - acc: 0.8168\n",
            "Epoch 19/20\n",
            "202/202 [==============================] - 0s 86us/step - loss: 0.4633 - acc: 0.8168\n",
            "Epoch 20/20\n",
            "202/202 [==============================] - 0s 85us/step - loss: 0.4571 - acc: 0.8168\n",
            "101/101 [==============================] - 1s 13ms/step\n",
            "Epoch 1/20\n",
            "202/202 [==============================] - 3s 15ms/step - loss: 0.9400 - acc: 0.3020\n",
            "Epoch 2/20\n",
            "202/202 [==============================] - 0s 95us/step - loss: 0.9159 - acc: 0.2921\n",
            "Epoch 3/20\n",
            "202/202 [==============================] - 0s 86us/step - loss: 0.8928 - acc: 0.2921\n",
            "Epoch 4/20\n",
            "202/202 [==============================] - 0s 80us/step - loss: 0.8718 - acc: 0.2921\n",
            "Epoch 5/20\n",
            "202/202 [==============================] - 0s 84us/step - loss: 0.8517 - acc: 0.2871\n",
            "Epoch 6/20\n",
            "202/202 [==============================] - 0s 88us/step - loss: 0.8329 - acc: 0.2921\n",
            "Epoch 7/20\n",
            "202/202 [==============================] - 0s 80us/step - loss: 0.8138 - acc: 0.2970\n",
            "Epoch 8/20\n",
            "202/202 [==============================] - 0s 84us/step - loss: 0.7959 - acc: 0.3020\n",
            "Epoch 9/20\n",
            "202/202 [==============================] - 0s 98us/step - loss: 0.7785 - acc: 0.3119\n",
            "Epoch 10/20\n",
            "202/202 [==============================] - 0s 121us/step - loss: 0.7640 - acc: 0.3366\n",
            "Epoch 11/20\n",
            "202/202 [==============================] - 0s 103us/step - loss: 0.7515 - acc: 0.3416\n",
            "Epoch 12/20\n",
            "202/202 [==============================] - 0s 89us/step - loss: 0.7386 - acc: 0.3614\n",
            "Epoch 13/20\n",
            "202/202 [==============================] - 0s 95us/step - loss: 0.7259 - acc: 0.3812\n",
            "Epoch 14/20\n",
            "202/202 [==============================] - 0s 101us/step - loss: 0.7138 - acc: 0.4059\n",
            "Epoch 15/20\n",
            "202/202 [==============================] - 0s 111us/step - loss: 0.7009 - acc: 0.4455\n",
            "Epoch 16/20\n",
            "202/202 [==============================] - 0s 97us/step - loss: 0.6893 - acc: 0.5099\n",
            "Epoch 17/20\n",
            "202/202 [==============================] - 0s 113us/step - loss: 0.6791 - acc: 0.5446\n",
            "Epoch 18/20\n",
            "202/202 [==============================] - 0s 84us/step - loss: 0.6696 - acc: 0.5990\n",
            "Epoch 19/20\n",
            "202/202 [==============================] - 0s 78us/step - loss: 0.6609 - acc: 0.6733\n",
            "Epoch 20/20\n",
            "202/202 [==============================] - 0s 86us/step - loss: 0.6513 - acc: 0.6931\n",
            "101/101 [==============================] - 1s 13ms/step\n",
            "Epoch 1/20\n",
            "202/202 [==============================] - 3s 16ms/step - loss: 0.6827 - acc: 0.5941\n",
            "Epoch 2/20\n",
            "202/202 [==============================] - 0s 87us/step - loss: 0.6732 - acc: 0.6139\n",
            "Epoch 3/20\n",
            "202/202 [==============================] - 0s 84us/step - loss: 0.6647 - acc: 0.6337\n",
            "Epoch 4/20\n",
            "202/202 [==============================] - 0s 92us/step - loss: 0.6562 - acc: 0.6634\n",
            "Epoch 5/20\n",
            "202/202 [==============================] - 0s 87us/step - loss: 0.6482 - acc: 0.6832\n",
            "Epoch 6/20\n",
            "202/202 [==============================] - 0s 90us/step - loss: 0.6412 - acc: 0.6832\n",
            "Epoch 7/20\n",
            "202/202 [==============================] - 0s 95us/step - loss: 0.6340 - acc: 0.6881\n",
            "Epoch 8/20\n",
            "202/202 [==============================] - 0s 83us/step - loss: 0.6274 - acc: 0.7030\n",
            "Epoch 9/20\n",
            "202/202 [==============================] - 0s 88us/step - loss: 0.6206 - acc: 0.7178\n",
            "Epoch 10/20\n",
            "202/202 [==============================] - 0s 83us/step - loss: 0.6141 - acc: 0.7376\n",
            "Epoch 11/20\n",
            "202/202 [==============================] - 0s 91us/step - loss: 0.6080 - acc: 0.7426\n",
            "Epoch 12/20\n",
            "202/202 [==============================] - 0s 82us/step - loss: 0.6021 - acc: 0.7376\n",
            "Epoch 13/20\n",
            "202/202 [==============================] - 0s 105us/step - loss: 0.5963 - acc: 0.7426\n",
            "Epoch 14/20\n",
            "202/202 [==============================] - 0s 109us/step - loss: 0.5906 - acc: 0.7475\n",
            "Epoch 15/20\n",
            "202/202 [==============================] - 0s 106us/step - loss: 0.5843 - acc: 0.7525\n",
            "Epoch 16/20\n",
            "202/202 [==============================] - 0s 82us/step - loss: 0.5787 - acc: 0.7624\n",
            "Epoch 17/20\n",
            "202/202 [==============================] - 0s 84us/step - loss: 0.5731 - acc: 0.7673\n",
            "Epoch 18/20\n",
            "202/202 [==============================] - 0s 122us/step - loss: 0.5672 - acc: 0.7772\n",
            "Epoch 19/20\n",
            "202/202 [==============================] - 0s 93us/step - loss: 0.5618 - acc: 0.7772\n",
            "Epoch 20/20\n",
            "202/202 [==============================] - 0s 89us/step - loss: 0.5561 - acc: 0.7822\n",
            "101/101 [==============================] - 1s 13ms/step\n",
            "Epoch 1/20\n",
            "202/202 [==============================] - 3s 16ms/step - loss: 1.3085 - acc: 0.1832\n",
            "Epoch 2/20\n",
            "202/202 [==============================] - 0s 84us/step - loss: 1.2697 - acc: 0.1832\n",
            "Epoch 3/20\n",
            "202/202 [==============================] - 0s 81us/step - loss: 1.2321 - acc: 0.1832\n",
            "Epoch 4/20\n",
            "202/202 [==============================] - 0s 75us/step - loss: 1.1954 - acc: 0.1832\n",
            "Epoch 5/20\n",
            "202/202 [==============================] - 0s 84us/step - loss: 1.1590 - acc: 0.1832\n",
            "Epoch 6/20\n",
            "202/202 [==============================] - 0s 78us/step - loss: 1.1242 - acc: 0.1832\n",
            "Epoch 7/20\n",
            "202/202 [==============================] - 0s 80us/step - loss: 1.0916 - acc: 0.1881\n",
            "Epoch 8/20\n",
            "202/202 [==============================] - 0s 80us/step - loss: 1.0583 - acc: 0.1881\n",
            "Epoch 9/20\n",
            "202/202 [==============================] - 0s 79us/step - loss: 1.0286 - acc: 0.1881\n",
            "Epoch 10/20\n",
            "202/202 [==============================] - 0s 83us/step - loss: 0.9993 - acc: 0.1881\n",
            "Epoch 11/20\n",
            "202/202 [==============================] - 0s 90us/step - loss: 0.9718 - acc: 0.1881\n",
            "Epoch 12/20\n",
            "202/202 [==============================] - 0s 96us/step - loss: 0.9431 - acc: 0.1980\n",
            "Epoch 13/20\n",
            "202/202 [==============================] - 0s 81us/step - loss: 0.9153 - acc: 0.2178\n",
            "Epoch 14/20\n",
            "202/202 [==============================] - 0s 92us/step - loss: 0.8890 - acc: 0.2228\n",
            "Epoch 15/20\n",
            "202/202 [==============================] - 0s 82us/step - loss: 0.8649 - acc: 0.2327\n",
            "Epoch 16/20\n",
            "202/202 [==============================] - 0s 84us/step - loss: 0.8418 - acc: 0.2376\n",
            "Epoch 17/20\n",
            "202/202 [==============================] - 0s 85us/step - loss: 0.8192 - acc: 0.2574\n",
            "Epoch 18/20\n",
            "202/202 [==============================] - 0s 89us/step - loss: 0.7982 - acc: 0.2723\n",
            "Epoch 19/20\n",
            "202/202 [==============================] - 0s 81us/step - loss: 0.7772 - acc: 0.3069\n",
            "Epoch 20/20\n",
            "202/202 [==============================] - 0s 78us/step - loss: 0.7573 - acc: 0.3762\n",
            "101/101 [==============================] - 1s 14ms/step\n",
            "Epoch 1/20\n",
            "202/202 [==============================] - 3s 16ms/step - loss: 0.9601 - acc: 0.4109\n",
            "Epoch 2/20\n",
            "202/202 [==============================] - 0s 101us/step - loss: 0.8839 - acc: 0.4505\n",
            "Epoch 3/20\n",
            "202/202 [==============================] - 0s 89us/step - loss: 0.8176 - acc: 0.4901\n",
            "Epoch 4/20\n",
            "202/202 [==============================] - 0s 84us/step - loss: 0.7570 - acc: 0.5099\n",
            "Epoch 5/20\n",
            "202/202 [==============================] - 0s 88us/step - loss: 0.7056 - acc: 0.5644\n",
            "Epoch 6/20\n",
            "202/202 [==============================] - 0s 76us/step - loss: 0.6619 - acc: 0.5941\n",
            "Epoch 7/20\n",
            "202/202 [==============================] - 0s 78us/step - loss: 0.6257 - acc: 0.6287\n",
            "Epoch 8/20\n",
            "202/202 [==============================] - 0s 84us/step - loss: 0.5972 - acc: 0.6535\n",
            "Epoch 9/20\n",
            "202/202 [==============================] - 0s 82us/step - loss: 0.5712 - acc: 0.6980\n",
            "Epoch 10/20\n",
            "202/202 [==============================] - 0s 80us/step - loss: 0.5495 - acc: 0.6881\n",
            "Epoch 11/20\n",
            "202/202 [==============================] - 0s 86us/step - loss: 0.5313 - acc: 0.7178\n",
            "Epoch 12/20\n",
            "202/202 [==============================] - 0s 91us/step - loss: 0.5160 - acc: 0.7178\n",
            "Epoch 13/20\n",
            "202/202 [==============================] - 0s 87us/step - loss: 0.5011 - acc: 0.7178\n",
            "Epoch 14/20\n",
            "202/202 [==============================] - 0s 95us/step - loss: 0.4865 - acc: 0.7327\n",
            "Epoch 15/20\n",
            "202/202 [==============================] - 0s 84us/step - loss: 0.4742 - acc: 0.7475\n",
            "Epoch 16/20\n",
            "202/202 [==============================] - 0s 91us/step - loss: 0.4634 - acc: 0.7475\n",
            "Epoch 17/20\n",
            "202/202 [==============================] - 0s 87us/step - loss: 0.4523 - acc: 0.7574\n",
            "Epoch 18/20\n",
            "202/202 [==============================] - 0s 94us/step - loss: 0.4437 - acc: 0.7673\n",
            "Epoch 19/20\n",
            "202/202 [==============================] - 0s 88us/step - loss: 0.4364 - acc: 0.7822\n",
            "Epoch 20/20\n",
            "202/202 [==============================] - 0s 88us/step - loss: 0.4281 - acc: 0.7822\n",
            "101/101 [==============================] - 1s 14ms/step\n",
            "Epoch 1/20\n",
            "202/202 [==============================] - 3s 16ms/step - loss: 0.9472 - acc: 0.4950\n",
            "Epoch 2/20\n",
            "202/202 [==============================] - 0s 98us/step - loss: 0.9060 - acc: 0.5198\n",
            "Epoch 3/20\n",
            "202/202 [==============================] - 0s 81us/step - loss: 0.8664 - acc: 0.5396\n",
            "Epoch 4/20\n",
            "202/202 [==============================] - 0s 84us/step - loss: 0.8324 - acc: 0.5446\n",
            "Epoch 5/20\n",
            "202/202 [==============================] - 0s 92us/step - loss: 0.8005 - acc: 0.5545\n",
            "Epoch 6/20\n",
            "202/202 [==============================] - 0s 83us/step - loss: 0.7720 - acc: 0.5644\n",
            "Epoch 7/20\n",
            "202/202 [==============================] - 0s 87us/step - loss: 0.7440 - acc: 0.5693\n",
            "Epoch 8/20\n",
            "202/202 [==============================] - 0s 79us/step - loss: 0.7151 - acc: 0.6040\n",
            "Epoch 9/20\n",
            "202/202 [==============================] - 0s 82us/step - loss: 0.6904 - acc: 0.6188\n",
            "Epoch 10/20\n",
            "202/202 [==============================] - 0s 80us/step - loss: 0.6667 - acc: 0.6386\n",
            "Epoch 11/20\n",
            "202/202 [==============================] - 0s 81us/step - loss: 0.6444 - acc: 0.6436\n",
            "Epoch 12/20\n",
            "202/202 [==============================] - 0s 79us/step - loss: 0.6239 - acc: 0.6733\n",
            "Epoch 13/20\n",
            "202/202 [==============================] - 0s 91us/step - loss: 0.6038 - acc: 0.6832\n",
            "Epoch 14/20\n",
            "202/202 [==============================] - 0s 89us/step - loss: 0.5869 - acc: 0.6832\n",
            "Epoch 15/20\n",
            "202/202 [==============================] - 0s 105us/step - loss: 0.5696 - acc: 0.6832\n",
            "Epoch 16/20\n",
            "202/202 [==============================] - 0s 132us/step - loss: 0.5522 - acc: 0.6980\n",
            "Epoch 17/20\n",
            "202/202 [==============================] - 0s 102us/step - loss: 0.5355 - acc: 0.7079\n",
            "Epoch 18/20\n",
            "202/202 [==============================] - 0s 87us/step - loss: 0.5205 - acc: 0.7129\n",
            "Epoch 19/20\n",
            "202/202 [==============================] - 0s 79us/step - loss: 0.5064 - acc: 0.7228\n",
            "Epoch 20/20\n",
            "202/202 [==============================] - 0s 83us/step - loss: 0.4947 - acc: 0.7475\n",
            "101/101 [==============================] - 1s 14ms/step\n",
            "Epoch 1/20\n",
            "202/202 [==============================] - 3s 17ms/step - loss: 0.9076 - acc: 0.3812\n",
            "Epoch 2/20\n",
            "202/202 [==============================] - 0s 83us/step - loss: 0.8409 - acc: 0.4059\n",
            "Epoch 3/20\n",
            "202/202 [==============================] - 0s 84us/step - loss: 0.7787 - acc: 0.4505\n",
            "Epoch 4/20\n",
            "202/202 [==============================] - 0s 87us/step - loss: 0.7243 - acc: 0.5000\n",
            "Epoch 5/20\n",
            "202/202 [==============================] - 0s 85us/step - loss: 0.6733 - acc: 0.5545\n",
            "Epoch 6/20\n",
            "202/202 [==============================] - 0s 87us/step - loss: 0.6291 - acc: 0.6238\n",
            "Epoch 7/20\n",
            "202/202 [==============================] - 0s 81us/step - loss: 0.5894 - acc: 0.6832\n",
            "Epoch 8/20\n",
            "202/202 [==============================] - 0s 76us/step - loss: 0.5559 - acc: 0.7228\n",
            "Epoch 9/20\n",
            "202/202 [==============================] - 0s 85us/step - loss: 0.5256 - acc: 0.7723\n",
            "Epoch 10/20\n",
            "202/202 [==============================] - 0s 74us/step - loss: 0.4980 - acc: 0.7970\n",
            "Epoch 11/20\n",
            "202/202 [==============================] - 0s 86us/step - loss: 0.4741 - acc: 0.8119\n",
            "Epoch 12/20\n",
            "202/202 [==============================] - 0s 90us/step - loss: 0.4534 - acc: 0.8317\n",
            "Epoch 13/20\n",
            "202/202 [==============================] - 0s 84us/step - loss: 0.4349 - acc: 0.8515\n",
            "Epoch 14/20\n",
            "202/202 [==============================] - 0s 100us/step - loss: 0.4197 - acc: 0.8465\n",
            "Epoch 15/20\n",
            "202/202 [==============================] - 0s 111us/step - loss: 0.4076 - acc: 0.8515\n",
            "Epoch 16/20\n",
            "202/202 [==============================] - 0s 89us/step - loss: 0.3958 - acc: 0.8515\n",
            "Epoch 17/20\n",
            "202/202 [==============================] - 0s 89us/step - loss: 0.3854 - acc: 0.8564\n",
            "Epoch 18/20\n",
            "202/202 [==============================] - 0s 86us/step - loss: 0.3761 - acc: 0.8564\n",
            "Epoch 19/20\n",
            "202/202 [==============================] - 0s 84us/step - loss: 0.3669 - acc: 0.8564\n",
            "Epoch 20/20\n",
            "202/202 [==============================] - 0s 101us/step - loss: 0.3584 - acc: 0.8614\n",
            "101/101 [==============================] - 1s 14ms/step\n",
            "Epoch 1/20\n",
            "303/303 [==============================] - 3s 11ms/step - loss: 0.6640 - acc: 0.6106\n",
            "Epoch 2/20\n",
            "303/303 [==============================] - 0s 69us/step - loss: 0.6201 - acc: 0.6535\n",
            "Epoch 3/20\n",
            "303/303 [==============================] - 0s 76us/step - loss: 0.5825 - acc: 0.6832\n",
            "Epoch 4/20\n",
            "303/303 [==============================] - 0s 81us/step - loss: 0.5501 - acc: 0.7030\n",
            "Epoch 5/20\n",
            "303/303 [==============================] - 0s 68us/step - loss: 0.5224 - acc: 0.7228\n",
            "Epoch 6/20\n",
            "303/303 [==============================] - 0s 77us/step - loss: 0.5001 - acc: 0.7459\n",
            "Epoch 7/20\n",
            "303/303 [==============================] - 0s 79us/step - loss: 0.4800 - acc: 0.7558\n",
            "Epoch 8/20\n",
            "303/303 [==============================] - 0s 90us/step - loss: 0.4649 - acc: 0.7723\n",
            "Epoch 9/20\n",
            "303/303 [==============================] - 0s 77us/step - loss: 0.4514 - acc: 0.7789\n",
            "Epoch 10/20\n",
            "303/303 [==============================] - 0s 79us/step - loss: 0.4399 - acc: 0.7987\n",
            "Epoch 11/20\n",
            "303/303 [==============================] - 0s 82us/step - loss: 0.4303 - acc: 0.8152\n",
            "Epoch 12/20\n",
            "303/303 [==============================] - 0s 71us/step - loss: 0.4221 - acc: 0.8185\n",
            "Epoch 13/20\n",
            "303/303 [==============================] - 0s 71us/step - loss: 0.4145 - acc: 0.8218\n",
            "Epoch 14/20\n",
            "303/303 [==============================] - 0s 70us/step - loss: 0.4086 - acc: 0.8218\n",
            "Epoch 15/20\n",
            "303/303 [==============================] - 0s 70us/step - loss: 0.4031 - acc: 0.8218\n",
            "Epoch 16/20\n",
            "303/303 [==============================] - 0s 83us/step - loss: 0.3982 - acc: 0.8218\n",
            "Epoch 17/20\n",
            "303/303 [==============================] - 0s 75us/step - loss: 0.3936 - acc: 0.8218\n",
            "Epoch 18/20\n",
            "303/303 [==============================] - 0s 77us/step - loss: 0.3901 - acc: 0.8317\n",
            "Epoch 19/20\n",
            "303/303 [==============================] - 0s 75us/step - loss: 0.3866 - acc: 0.8317\n",
            "Epoch 20/20\n",
            "303/303 [==============================] - 0s 102us/step - loss: 0.3834 - acc: 0.8317\n",
            "Best: 0.7392739350646242 using {'activation': 'linear'}\n",
            "Means: 0.3993399341409356, Stdev: 0.2346253763514157 with: {'activation': 'softmax'}\n",
            "Means: 0.4191419126422885, Stdev: 0.290391536808424 with: {'activation': 'softplus'}\n",
            "Means: 0.7095709645708795, Stdev: 0.05958900543216723 with: {'activation': 'softsign'}\n",
            "Means: 0.6963696392259189, Stdev: 0.22640360251897923 with: {'activation': 'relu'}\n",
            "Means: 0.6798679841430274, Stdev: 0.10975768747452666 with: {'activation': 'tanh'}\n",
            "Means: 0.22442243817468288, Stdev: 0.28263621900511804 with: {'activation': 'sigmoid'}\n",
            "Means: 0.7359736149657284, Stdev: 0.19407512297970134 with: {'activation': 'hard_sigmoid'}\n",
            "Means: 0.7392739350646242, Stdev: 0.030605995780698666 with: {'activation': 'linear'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsaX4FJCZFDe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 11308
        },
        "outputId": "a9a32ed6-7847-4fb4-cdfd-a25e0a180377"
      },
      "source": [
        "# Testing out SGD to see if it's better than Adam for this data\n",
        "# Gridsearch on learn rate\n",
        "\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "# Function to create model, required for KerasClassifier\n",
        "def create_model(learn_rate=0.01, momentum=0):\n",
        "  # create model\n",
        "  model = Sequential()\n",
        "  model.add(Dense(13, input_dim=13, activation='linear'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  optimizer = SGD(lr=learn_rate, momentum=momentum)\n",
        "  # Compile model\n",
        "  model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "# create model\n",
        "model = KerasClassifier(build_fn=create_model, epochs=20, batch_size=40, verbose=1)\n",
        "\n",
        "# Create param grid\n",
        "learn_rate = [0.001, 0.01, 0.1, 0.2, 0.3]\n",
        "momentum = [0.0]\n",
        "param_grid = dict(learn_rate=learn_rate, momentum=momentum)\n",
        "\n",
        "# Create Grid Search\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1)\n",
        "grid_result = grid.fit(X, y)\n",
        "\n",
        "# Report Results\n",
        "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\")\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
            "  warnings.warn(CV_WARNING, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "202/202 [==============================] - 6s 29ms/step - loss: 1.0816 - acc: 0.4653\n",
            "Epoch 2/20\n",
            "202/202 [==============================] - 0s 104us/step - loss: 1.0722 - acc: 0.4752\n",
            "Epoch 3/20\n",
            "202/202 [==============================] - 0s 103us/step - loss: 1.0643 - acc: 0.4802\n",
            "Epoch 4/20\n",
            "202/202 [==============================] - 0s 103us/step - loss: 1.0576 - acc: 0.4901\n",
            "Epoch 5/20\n",
            "202/202 [==============================] - 0s 109us/step - loss: 1.0507 - acc: 0.4901\n",
            "Epoch 6/20\n",
            "202/202 [==============================] - 0s 95us/step - loss: 1.0413 - acc: 0.4901\n",
            "Epoch 7/20\n",
            "202/202 [==============================] - 0s 112us/step - loss: 1.0338 - acc: 0.4950\n",
            "Epoch 8/20\n",
            "202/202 [==============================] - 0s 94us/step - loss: 1.0243 - acc: 0.5000\n",
            "Epoch 9/20\n",
            "202/202 [==============================] - 0s 102us/step - loss: 1.0169 - acc: 0.5000\n",
            "Epoch 10/20\n",
            "202/202 [==============================] - 0s 115us/step - loss: 1.0104 - acc: 0.5000\n",
            "Epoch 11/20\n",
            "202/202 [==============================] - 0s 104us/step - loss: 1.0030 - acc: 0.5000\n",
            "Epoch 12/20\n",
            "202/202 [==============================] - 0s 149us/step - loss: 0.9952 - acc: 0.5000\n",
            "Epoch 13/20\n",
            "202/202 [==============================] - 0s 104us/step - loss: 0.9888 - acc: 0.5050\n",
            "Epoch 14/20\n",
            "202/202 [==============================] - 0s 93us/step - loss: 0.9829 - acc: 0.5050\n",
            "Epoch 15/20\n",
            "202/202 [==============================] - 0s 112us/step - loss: 0.9780 - acc: 0.5050\n",
            "Epoch 16/20\n",
            "202/202 [==============================] - 0s 97us/step - loss: 0.9713 - acc: 0.5050\n",
            "Epoch 17/20\n",
            "202/202 [==============================] - 0s 112us/step - loss: 0.9657 - acc: 0.5099\n",
            "Epoch 18/20\n",
            "202/202 [==============================] - 0s 128us/step - loss: 0.9594 - acc: 0.5198\n",
            "Epoch 19/20\n",
            "202/202 [==============================] - 0s 104us/step - loss: 0.9539 - acc: 0.5198\n",
            "Epoch 20/20\n",
            "202/202 [==============================] - 0s 115us/step - loss: 0.9483 - acc: 0.5248\n",
            "101/101 [==============================] - 2s 24ms/step\n",
            "Epoch 1/20\n",
            "202/202 [==============================] - 6s 28ms/step - loss: 0.8497 - acc: 0.5248\n",
            "Epoch 2/20\n",
            "202/202 [==============================] - 0s 117us/step - loss: 0.8457 - acc: 0.5297\n",
            "Epoch 3/20\n",
            "202/202 [==============================] - 0s 113us/step - loss: 0.8389 - acc: 0.5297\n",
            "Epoch 4/20\n",
            "202/202 [==============================] - 0s 101us/step - loss: 0.8345 - acc: 0.5347\n",
            "Epoch 5/20\n",
            "202/202 [==============================] - 0s 101us/step - loss: 0.8294 - acc: 0.5347\n",
            "Epoch 6/20\n",
            "202/202 [==============================] - 0s 99us/step - loss: 0.8252 - acc: 0.5347\n",
            "Epoch 7/20\n",
            "202/202 [==============================] - 0s 114us/step - loss: 0.8209 - acc: 0.5396\n",
            "Epoch 8/20\n",
            "202/202 [==============================] - 0s 115us/step - loss: 0.8166 - acc: 0.5396\n",
            "Epoch 9/20\n",
            "202/202 [==============================] - 0s 100us/step - loss: 0.8130 - acc: 0.5396\n",
            "Epoch 10/20\n",
            "202/202 [==============================] - 0s 143us/step - loss: 0.8098 - acc: 0.5446\n",
            "Epoch 11/20\n",
            "202/202 [==============================] - 0s 125us/step - loss: 0.8065 - acc: 0.5446\n",
            "Epoch 12/20\n",
            "202/202 [==============================] - 0s 121us/step - loss: 0.8025 - acc: 0.5446\n",
            "Epoch 13/20\n",
            "202/202 [==============================] - 0s 110us/step - loss: 0.7985 - acc: 0.5446\n",
            "Epoch 14/20\n",
            "202/202 [==============================] - 0s 111us/step - loss: 0.7947 - acc: 0.5495\n",
            "Epoch 15/20\n",
            "202/202 [==============================] - 0s 114us/step - loss: 0.7911 - acc: 0.5495\n",
            "Epoch 16/20\n",
            "202/202 [==============================] - 0s 108us/step - loss: 0.7876 - acc: 0.5495\n",
            "Epoch 17/20\n",
            "202/202 [==============================] - 0s 121us/step - loss: 0.7835 - acc: 0.5594\n",
            "Epoch 18/20\n",
            "202/202 [==============================] - 0s 112us/step - loss: 0.7803 - acc: 0.5594\n",
            "Epoch 19/20\n",
            "202/202 [==============================] - 0s 111us/step - loss: 0.7766 - acc: 0.5594\n",
            "Epoch 20/20\n",
            "202/202 [==============================] - 0s 118us/step - loss: 0.7737 - acc: 0.5693\n",
            "101/101 [==============================] - 2s 24ms/step\n",
            "Epoch 1/20\n",
            "202/202 [==============================] - 6s 28ms/step - loss: 0.5522 - acc: 0.7277\n",
            "Epoch 2/20\n",
            "202/202 [==============================] - 0s 91us/step - loss: 0.5506 - acc: 0.7277\n",
            "Epoch 3/20\n",
            "202/202 [==============================] - 0s 96us/step - loss: 0.5486 - acc: 0.7277\n",
            "Epoch 4/20\n",
            "202/202 [==============================] - 0s 107us/step - loss: 0.5464 - acc: 0.7277\n",
            "Epoch 5/20\n",
            "202/202 [==============================] - 0s 100us/step - loss: 0.5447 - acc: 0.7277\n",
            "Epoch 6/20\n",
            "202/202 [==============================] - 0s 108us/step - loss: 0.5428 - acc: 0.7327\n",
            "Epoch 7/20\n",
            "202/202 [==============================] - 0s 109us/step - loss: 0.5414 - acc: 0.7327\n",
            "Epoch 8/20\n",
            "202/202 [==============================] - 0s 116us/step - loss: 0.5397 - acc: 0.7376\n",
            "Epoch 9/20\n",
            "202/202 [==============================] - 0s 121us/step - loss: 0.5378 - acc: 0.7426\n",
            "Epoch 10/20\n",
            "202/202 [==============================] - 0s 117us/step - loss: 0.5361 - acc: 0.7426\n",
            "Epoch 11/20\n",
            "202/202 [==============================] - 0s 127us/step - loss: 0.5340 - acc: 0.7426\n",
            "Epoch 12/20\n",
            "202/202 [==============================] - 0s 128us/step - loss: 0.5324 - acc: 0.7426\n",
            "Epoch 13/20\n",
            "202/202 [==============================] - 0s 150us/step - loss: 0.5304 - acc: 0.7475\n",
            "Epoch 14/20\n",
            "202/202 [==============================] - 0s 113us/step - loss: 0.5289 - acc: 0.7475\n",
            "Epoch 15/20\n",
            "202/202 [==============================] - 0s 111us/step - loss: 0.5274 - acc: 0.7525\n",
            "Epoch 16/20\n",
            "202/202 [==============================] - 0s 127us/step - loss: 0.5259 - acc: 0.7525\n",
            "Epoch 17/20\n",
            "202/202 [==============================] - 0s 131us/step - loss: 0.5241 - acc: 0.7525\n",
            "Epoch 18/20\n",
            "202/202 [==============================] - 0s 113us/step - loss: 0.5221 - acc: 0.7525\n",
            "Epoch 19/20\n",
            "202/202 [==============================] - 0s 114us/step - loss: 0.5206 - acc: 0.7574\n",
            "Epoch 20/20\n",
            "202/202 [==============================] - 0s 123us/step - loss: 0.5182 - acc: 0.7574\n",
            "101/101 [==============================] - 2s 24ms/step\n",
            "Epoch 1/20\n",
            "202/202 [==============================] - 6s 28ms/step - loss: 0.5910 - acc: 0.6683\n",
            "Epoch 2/20\n",
            "202/202 [==============================] - 0s 100us/step - loss: 0.5701 - acc: 0.6881\n",
            "Epoch 3/20\n",
            "202/202 [==============================] - 0s 96us/step - loss: 0.5533 - acc: 0.7030\n",
            "Epoch 4/20\n",
            "202/202 [==============================] - 0s 93us/step - loss: 0.5414 - acc: 0.7277\n",
            "Epoch 5/20\n",
            "202/202 [==============================] - 0s 113us/step - loss: 0.5317 - acc: 0.7376\n",
            "Epoch 6/20\n",
            "202/202 [==============================] - 0s 105us/step - loss: 0.5190 - acc: 0.7624\n",
            "Epoch 7/20\n",
            "202/202 [==============================] - 0s 91us/step - loss: 0.5066 - acc: 0.7673\n",
            "Epoch 8/20\n",
            "202/202 [==============================] - 0s 96us/step - loss: 0.4963 - acc: 0.7525\n",
            "Epoch 9/20\n",
            "202/202 [==============================] - 0s 93us/step - loss: 0.4843 - acc: 0.7673\n",
            "Epoch 10/20\n",
            "202/202 [==============================] - 0s 104us/step - loss: 0.4748 - acc: 0.7723\n",
            "Epoch 11/20\n",
            "202/202 [==============================] - 0s 116us/step - loss: 0.4658 - acc: 0.7723\n",
            "Epoch 12/20\n",
            "202/202 [==============================] - 0s 115us/step - loss: 0.4583 - acc: 0.7822\n",
            "Epoch 13/20\n",
            "202/202 [==============================] - 0s 100us/step - loss: 0.4524 - acc: 0.7822\n",
            "Epoch 14/20\n",
            "202/202 [==============================] - 0s 111us/step - loss: 0.4457 - acc: 0.7921\n",
            "Epoch 15/20\n",
            "202/202 [==============================] - 0s 108us/step - loss: 0.4399 - acc: 0.8020\n",
            "Epoch 16/20\n",
            "202/202 [==============================] - 0s 118us/step - loss: 0.4338 - acc: 0.8020\n",
            "Epoch 17/20\n",
            "202/202 [==============================] - 0s 106us/step - loss: 0.4291 - acc: 0.8119\n",
            "Epoch 18/20\n",
            "202/202 [==============================] - 0s 117us/step - loss: 0.4242 - acc: 0.8119\n",
            "Epoch 19/20\n",
            "202/202 [==============================] - 0s 99us/step - loss: 0.4173 - acc: 0.8168\n",
            "Epoch 20/20\n",
            "202/202 [==============================] - 0s 106us/step - loss: 0.4138 - acc: 0.8168\n",
            "101/101 [==============================] - 2s 24ms/step\n",
            "Epoch 1/20\n",
            "202/202 [==============================] - 6s 28ms/step - loss: 0.8068 - acc: 0.5297\n",
            "Epoch 2/20\n",
            "202/202 [==============================] - 0s 95us/step - loss: 0.7541 - acc: 0.5693\n",
            "Epoch 3/20\n",
            "202/202 [==============================] - 0s 96us/step - loss: 0.7033 - acc: 0.6238\n",
            "Epoch 4/20\n",
            "202/202 [==============================] - 0s 92us/step - loss: 0.6680 - acc: 0.6386\n",
            "Epoch 5/20\n",
            "202/202 [==============================] - 0s 98us/step - loss: 0.6304 - acc: 0.6535\n",
            "Epoch 6/20\n",
            "202/202 [==============================] - 0s 95us/step - loss: 0.6080 - acc: 0.6931\n",
            "Epoch 7/20\n",
            "202/202 [==============================] - 0s 101us/step - loss: 0.5790 - acc: 0.7129\n",
            "Epoch 8/20\n",
            "202/202 [==============================] - 0s 108us/step - loss: 0.5567 - acc: 0.7426\n",
            "Epoch 9/20\n",
            "202/202 [==============================] - 0s 109us/step - loss: 0.5431 - acc: 0.7525\n",
            "Epoch 10/20\n",
            "202/202 [==============================] - 0s 104us/step - loss: 0.5265 - acc: 0.7624\n",
            "Epoch 11/20\n",
            "202/202 [==============================] - 0s 118us/step - loss: 0.5104 - acc: 0.7624\n",
            "Epoch 12/20\n",
            "202/202 [==============================] - 0s 99us/step - loss: 0.5007 - acc: 0.7723\n",
            "Epoch 13/20\n",
            "202/202 [==============================] - 0s 128us/step - loss: 0.4873 - acc: 0.7673\n",
            "Epoch 14/20\n",
            "202/202 [==============================] - 0s 96us/step - loss: 0.4751 - acc: 0.7772\n",
            "Epoch 15/20\n",
            "202/202 [==============================] - 0s 91us/step - loss: 0.4643 - acc: 0.7772\n",
            "Epoch 16/20\n",
            "202/202 [==============================] - 0s 88us/step - loss: 0.4553 - acc: 0.7772\n",
            "Epoch 17/20\n",
            "202/202 [==============================] - 0s 102us/step - loss: 0.4478 - acc: 0.7772\n",
            "Epoch 18/20\n",
            "202/202 [==============================] - 0s 117us/step - loss: 0.4421 - acc: 0.7772\n",
            "Epoch 19/20\n",
            "202/202 [==============================] - 0s 109us/step - loss: 0.4365 - acc: 0.7723\n",
            "Epoch 20/20\n",
            "202/202 [==============================] - 0s 106us/step - loss: 0.4309 - acc: 0.7822\n",
            "101/101 [==============================] - 2s 25ms/step\n",
            "Epoch 1/20\n",
            "202/202 [==============================] - 6s 29ms/step - loss: 0.5725 - acc: 0.6634\n",
            "Epoch 2/20\n",
            "202/202 [==============================] - 0s 89us/step - loss: 0.5375 - acc: 0.6931\n",
            "Epoch 3/20\n",
            "202/202 [==============================] - 0s 111us/step - loss: 0.5094 - acc: 0.7178\n",
            "Epoch 4/20\n",
            "202/202 [==============================] - 0s 103us/step - loss: 0.4836 - acc: 0.7475\n",
            "Epoch 5/20\n",
            "202/202 [==============================] - 0s 107us/step - loss: 0.4577 - acc: 0.7624\n",
            "Epoch 6/20\n",
            "202/202 [==============================] - 0s 111us/step - loss: 0.4354 - acc: 0.7970\n",
            "Epoch 7/20\n",
            "202/202 [==============================] - 0s 125us/step - loss: 0.4192 - acc: 0.8267\n",
            "Epoch 8/20\n",
            "202/202 [==============================] - 0s 127us/step - loss: 0.4056 - acc: 0.8267\n",
            "Epoch 9/20\n",
            "202/202 [==============================] - 0s 111us/step - loss: 0.3959 - acc: 0.8317\n",
            "Epoch 10/20\n",
            "202/202 [==============================] - 0s 112us/step - loss: 0.3843 - acc: 0.8515\n",
            "Epoch 11/20\n",
            "202/202 [==============================] - 0s 118us/step - loss: 0.3748 - acc: 0.8465\n",
            "Epoch 12/20\n",
            "202/202 [==============================] - 0s 114us/step - loss: 0.3659 - acc: 0.8564\n",
            "Epoch 13/20\n",
            "202/202 [==============================] - 0s 119us/step - loss: 0.3571 - acc: 0.8713\n",
            "Epoch 14/20\n",
            "202/202 [==============================] - 0s 110us/step - loss: 0.3501 - acc: 0.8713\n",
            "Epoch 15/20\n",
            "202/202 [==============================] - 0s 121us/step - loss: 0.3440 - acc: 0.8713\n",
            "Epoch 16/20\n",
            "202/202 [==============================] - 0s 137us/step - loss: 0.3378 - acc: 0.8762\n",
            "Epoch 17/20\n",
            "202/202 [==============================] - 0s 111us/step - loss: 0.3323 - acc: 0.8762\n",
            "Epoch 18/20\n",
            "202/202 [==============================] - 0s 108us/step - loss: 0.3270 - acc: 0.8762\n",
            "Epoch 19/20\n",
            "202/202 [==============================] - 0s 128us/step - loss: 0.3224 - acc: 0.8812\n",
            "Epoch 20/20\n",
            "202/202 [==============================] - 0s 112us/step - loss: 0.3179 - acc: 0.8861\n",
            "101/101 [==============================] - 2s 25ms/step\n",
            "Epoch 1/20\n",
            "202/202 [==============================] - 6s 29ms/step - loss: 0.8844 - acc: 0.4653\n",
            "Epoch 2/20\n",
            "202/202 [==============================] - 0s 106us/step - loss: 0.5384 - acc: 0.7376\n",
            "Epoch 3/20\n",
            "202/202 [==============================] - 0s 107us/step - loss: 0.4343 - acc: 0.8119\n",
            "Epoch 4/20\n",
            "202/202 [==============================] - 0s 100us/step - loss: 0.3917 - acc: 0.8317\n",
            "Epoch 5/20\n",
            "202/202 [==============================] - 0s 109us/step - loss: 0.3714 - acc: 0.8267\n",
            "Epoch 6/20\n",
            "202/202 [==============================] - 0s 105us/step - loss: 0.3580 - acc: 0.8416\n",
            "Epoch 7/20\n",
            "202/202 [==============================] - 0s 102us/step - loss: 0.3477 - acc: 0.8515\n",
            "Epoch 8/20\n",
            "202/202 [==============================] - 0s 116us/step - loss: 0.3408 - acc: 0.8515\n",
            "Epoch 9/20\n",
            "202/202 [==============================] - 0s 115us/step - loss: 0.3356 - acc: 0.8614\n",
            "Epoch 10/20\n",
            "202/202 [==============================] - 0s 108us/step - loss: 0.3321 - acc: 0.8564\n",
            "Epoch 11/20\n",
            "202/202 [==============================] - 0s 98us/step - loss: 0.3280 - acc: 0.8614\n",
            "Epoch 12/20\n",
            "202/202 [==============================] - 0s 107us/step - loss: 0.3242 - acc: 0.8713\n",
            "Epoch 13/20\n",
            "202/202 [==============================] - 0s 112us/step - loss: 0.3214 - acc: 0.8564\n",
            "Epoch 14/20\n",
            "202/202 [==============================] - 0s 110us/step - loss: 0.3262 - acc: 0.8515\n",
            "Epoch 15/20\n",
            "202/202 [==============================] - 0s 108us/step - loss: 0.3223 - acc: 0.8614\n",
            "Epoch 16/20\n",
            "202/202 [==============================] - 0s 125us/step - loss: 0.3236 - acc: 0.8515\n",
            "Epoch 17/20\n",
            "202/202 [==============================] - 0s 99us/step - loss: 0.3199 - acc: 0.8564\n",
            "Epoch 18/20\n",
            "202/202 [==============================] - 0s 101us/step - loss: 0.3298 - acc: 0.8465\n",
            "Epoch 19/20\n",
            "202/202 [==============================] - 0s 105us/step - loss: 0.3272 - acc: 0.8614\n",
            "Epoch 20/20\n",
            "202/202 [==============================] - 0s 116us/step - loss: 0.3292 - acc: 0.8515\n",
            "101/101 [==============================] - 3s 25ms/step\n",
            "Epoch 1/20\n",
            "202/202 [==============================] - 6s 29ms/step - loss: 0.5675 - acc: 0.7228\n",
            "Epoch 2/20\n",
            "202/202 [==============================] - 0s 113us/step - loss: 0.4378 - acc: 0.8119\n",
            "Epoch 3/20\n",
            "202/202 [==============================] - 0s 103us/step - loss: 0.3914 - acc: 0.8515\n",
            "Epoch 4/20\n",
            "202/202 [==============================] - 0s 116us/step - loss: 0.3741 - acc: 0.8465\n",
            "Epoch 5/20\n",
            "202/202 [==============================] - 0s 115us/step - loss: 0.3601 - acc: 0.8515\n",
            "Epoch 6/20\n",
            "202/202 [==============================] - 0s 113us/step - loss: 0.3473 - acc: 0.8564\n",
            "Epoch 7/20\n",
            "202/202 [==============================] - 0s 124us/step - loss: 0.3407 - acc: 0.8663\n",
            "Epoch 8/20\n",
            "202/202 [==============================] - 0s 106us/step - loss: 0.3461 - acc: 0.8465\n",
            "Epoch 9/20\n",
            "202/202 [==============================] - 0s 133us/step - loss: 0.3350 - acc: 0.8614\n",
            "Epoch 10/20\n",
            "202/202 [==============================] - 0s 137us/step - loss: 0.3319 - acc: 0.8713\n",
            "Epoch 11/20\n",
            "202/202 [==============================] - 0s 112us/step - loss: 0.3438 - acc: 0.8515\n",
            "Epoch 12/20\n",
            "202/202 [==============================] - 0s 106us/step - loss: 0.3362 - acc: 0.8515\n",
            "Epoch 13/20\n",
            "202/202 [==============================] - 0s 110us/step - loss: 0.3306 - acc: 0.8614\n",
            "Epoch 14/20\n",
            "202/202 [==============================] - 0s 147us/step - loss: 0.3283 - acc: 0.8614\n",
            "Epoch 15/20\n",
            "202/202 [==============================] - 0s 113us/step - loss: 0.3286 - acc: 0.8614\n",
            "Epoch 16/20\n",
            "202/202 [==============================] - 0s 95us/step - loss: 0.3455 - acc: 0.8564\n",
            "Epoch 17/20\n",
            "202/202 [==============================] - 0s 113us/step - loss: 0.3356 - acc: 0.8614\n",
            "Epoch 18/20\n",
            "202/202 [==============================] - 0s 131us/step - loss: 0.3360 - acc: 0.8564\n",
            "Epoch 19/20\n",
            "202/202 [==============================] - 0s 130us/step - loss: 0.3315 - acc: 0.8614\n",
            "Epoch 20/20\n",
            "202/202 [==============================] - 0s 109us/step - loss: 0.3309 - acc: 0.8663\n",
            "101/101 [==============================] - 3s 25ms/step\n",
            "Epoch 1/20\n",
            "202/202 [==============================] - 6s 29ms/step - loss: 0.4400 - acc: 0.7970\n",
            "Epoch 2/20\n",
            "202/202 [==============================] - 0s 104us/step - loss: 0.3741 - acc: 0.8564\n",
            "Epoch 3/20\n",
            "202/202 [==============================] - 0s 101us/step - loss: 0.3121 - acc: 0.8812\n",
            "Epoch 4/20\n",
            "202/202 [==============================] - 0s 101us/step - loss: 0.2881 - acc: 0.8861\n",
            "Epoch 5/20\n",
            "202/202 [==============================] - 0s 103us/step - loss: 0.2777 - acc: 0.8960\n",
            "Epoch 6/20\n",
            "202/202 [==============================] - 0s 108us/step - loss: 0.2687 - acc: 0.8960\n",
            "Epoch 7/20\n",
            "202/202 [==============================] - 0s 97us/step - loss: 0.2622 - acc: 0.8911\n",
            "Epoch 8/20\n",
            "202/202 [==============================] - 0s 100us/step - loss: 0.2609 - acc: 0.8911\n",
            "Epoch 9/20\n",
            "202/202 [==============================] - 0s 98us/step - loss: 0.2562 - acc: 0.8911\n",
            "Epoch 10/20\n",
            "202/202 [==============================] - 0s 114us/step - loss: 0.2528 - acc: 0.8911\n",
            "Epoch 11/20\n",
            "202/202 [==============================] - 0s 125us/step - loss: 0.2545 - acc: 0.9109\n",
            "Epoch 12/20\n",
            "202/202 [==============================] - 0s 108us/step - loss: 0.2508 - acc: 0.9010\n",
            "Epoch 13/20\n",
            "202/202 [==============================] - 0s 128us/step - loss: 0.2480 - acc: 0.9059\n",
            "Epoch 14/20\n",
            "202/202 [==============================] - 0s 106us/step - loss: 0.2443 - acc: 0.9010\n",
            "Epoch 15/20\n",
            "202/202 [==============================] - 0s 99us/step - loss: 0.2468 - acc: 0.8960\n",
            "Epoch 16/20\n",
            "202/202 [==============================] - 0s 116us/step - loss: 0.2533 - acc: 0.9158\n",
            "Epoch 17/20\n",
            "202/202 [==============================] - 0s 99us/step - loss: 0.2453 - acc: 0.9109\n",
            "Epoch 18/20\n",
            "202/202 [==============================] - 0s 106us/step - loss: 0.2430 - acc: 0.9010\n",
            "Epoch 19/20\n",
            "202/202 [==============================] - 0s 110us/step - loss: 0.2404 - acc: 0.9010\n",
            "Epoch 20/20\n",
            "202/202 [==============================] - 0s 191us/step - loss: 0.2479 - acc: 0.9109\n",
            "101/101 [==============================] - 3s 25ms/step\n",
            "Epoch 1/20\n",
            "202/202 [==============================] - 6s 29ms/step - loss: 0.5456 - acc: 0.7376\n",
            "Epoch 2/20\n",
            "202/202 [==============================] - 0s 102us/step - loss: 0.4633 - acc: 0.7673\n",
            "Epoch 3/20\n",
            "202/202 [==============================] - 0s 92us/step - loss: 0.4521 - acc: 0.7574\n",
            "Epoch 4/20\n",
            "202/202 [==============================] - 0s 95us/step - loss: 0.3470 - acc: 0.8317\n",
            "Epoch 5/20\n",
            "202/202 [==============================] - 0s 99us/step - loss: 0.3371 - acc: 0.8465\n",
            "Epoch 6/20\n",
            "202/202 [==============================] - 0s 110us/step - loss: 0.3493 - acc: 0.8366\n",
            "Epoch 7/20\n",
            "202/202 [==============================] - 0s 103us/step - loss: 0.3289 - acc: 0.8465\n",
            "Epoch 8/20\n",
            "202/202 [==============================] - 0s 96us/step - loss: 0.3496 - acc: 0.8564\n",
            "Epoch 9/20\n",
            "202/202 [==============================] - 0s 107us/step - loss: 0.3331 - acc: 0.8564\n",
            "Epoch 10/20\n",
            "202/202 [==============================] - 0s 131us/step - loss: 0.3241 - acc: 0.8614\n",
            "Epoch 11/20\n",
            "202/202 [==============================] - 0s 145us/step - loss: 0.3195 - acc: 0.8465\n",
            "Epoch 12/20\n",
            "202/202 [==============================] - 0s 107us/step - loss: 0.3163 - acc: 0.8564\n",
            "Epoch 13/20\n",
            "202/202 [==============================] - 0s 112us/step - loss: 0.3157 - acc: 0.8515\n",
            "Epoch 14/20\n",
            "202/202 [==============================] - 0s 119us/step - loss: 0.3160 - acc: 0.8465\n",
            "Epoch 15/20\n",
            "202/202 [==============================] - 0s 132us/step - loss: 0.3240 - acc: 0.8663\n",
            "Epoch 16/20\n",
            "202/202 [==============================] - 0s 106us/step - loss: 0.3183 - acc: 0.8614\n",
            "Epoch 17/20\n",
            "202/202 [==============================] - 0s 138us/step - loss: 0.3213 - acc: 0.8515\n",
            "Epoch 18/20\n",
            "202/202 [==============================] - 0s 115us/step - loss: 0.3152 - acc: 0.8515\n",
            "Epoch 19/20\n",
            "202/202 [==============================] - 0s 124us/step - loss: 0.3243 - acc: 0.8465\n",
            "Epoch 20/20\n",
            "202/202 [==============================] - 0s 127us/step - loss: 0.3378 - acc: 0.8663\n",
            "101/101 [==============================] - 3s 25ms/step\n",
            "Epoch 1/20\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.6979 - acc: 0.6089\n",
            "Epoch 2/20\n",
            "202/202 [==============================] - 0s 105us/step - loss: 0.4502 - acc: 0.7921\n",
            "Epoch 3/20\n",
            "202/202 [==============================] - 0s 98us/step - loss: 0.4032 - acc: 0.8168\n",
            "Epoch 4/20\n",
            "202/202 [==============================] - 0s 103us/step - loss: 0.3917 - acc: 0.8267\n",
            "Epoch 5/20\n",
            "202/202 [==============================] - 0s 106us/step - loss: 0.4238 - acc: 0.8069\n",
            "Epoch 6/20\n",
            "202/202 [==============================] - 0s 108us/step - loss: 0.4155 - acc: 0.8119\n",
            "Epoch 7/20\n",
            "202/202 [==============================] - 0s 105us/step - loss: 0.3755 - acc: 0.8416\n",
            "Epoch 8/20\n",
            "202/202 [==============================] - 0s 104us/step - loss: 0.3528 - acc: 0.8515\n",
            "Epoch 9/20\n",
            "202/202 [==============================] - 0s 107us/step - loss: 0.3487 - acc: 0.8317\n",
            "Epoch 10/20\n",
            "202/202 [==============================] - 0s 103us/step - loss: 0.3420 - acc: 0.8366\n",
            "Epoch 11/20\n",
            "202/202 [==============================] - 0s 119us/step - loss: 0.3475 - acc: 0.8366\n",
            "Epoch 12/20\n",
            "202/202 [==============================] - 0s 115us/step - loss: 0.3928 - acc: 0.7921\n",
            "Epoch 13/20\n",
            "202/202 [==============================] - 0s 96us/step - loss: 0.3667 - acc: 0.8119\n",
            "Epoch 14/20\n",
            "202/202 [==============================] - 0s 101us/step - loss: 0.3576 - acc: 0.8317\n",
            "Epoch 15/20\n",
            "202/202 [==============================] - 0s 110us/step - loss: 0.3536 - acc: 0.8465\n",
            "Epoch 16/20\n",
            "202/202 [==============================] - 0s 118us/step - loss: 0.3439 - acc: 0.8614\n",
            "Epoch 17/20\n",
            "202/202 [==============================] - 0s 142us/step - loss: 0.3348 - acc: 0.8564\n",
            "Epoch 18/20\n",
            "202/202 [==============================] - 0s 141us/step - loss: 0.3327 - acc: 0.8564\n",
            "Epoch 19/20\n",
            "202/202 [==============================] - 0s 136us/step - loss: 0.3322 - acc: 0.8663\n",
            "Epoch 20/20\n",
            "202/202 [==============================] - 0s 103us/step - loss: 0.3311 - acc: 0.8614\n",
            "101/101 [==============================] - 3s 25ms/step\n",
            "Epoch 1/20\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.6699 - acc: 0.6188\n",
            "Epoch 2/20\n",
            "202/202 [==============================] - 0s 107us/step - loss: 0.3611 - acc: 0.8713\n",
            "Epoch 3/20\n",
            "202/202 [==============================] - 0s 111us/step - loss: 0.3007 - acc: 0.8911\n",
            "Epoch 4/20\n",
            "202/202 [==============================] - 0s 111us/step - loss: 0.2764 - acc: 0.9010\n",
            "Epoch 5/20\n",
            "202/202 [==============================] - 0s 106us/step - loss: 0.2658 - acc: 0.8861\n",
            "Epoch 6/20\n",
            "202/202 [==============================] - 0s 117us/step - loss: 0.2610 - acc: 0.8911\n",
            "Epoch 7/20\n",
            "202/202 [==============================] - 0s 111us/step - loss: 0.2516 - acc: 0.8861\n",
            "Epoch 8/20\n",
            "202/202 [==============================] - 0s 106us/step - loss: 0.2510 - acc: 0.8861\n",
            "Epoch 9/20\n",
            "202/202 [==============================] - 0s 107us/step - loss: 0.2487 - acc: 0.8861\n",
            "Epoch 10/20\n",
            "202/202 [==============================] - 0s 98us/step - loss: 0.2442 - acc: 0.8861\n",
            "Epoch 11/20\n",
            "202/202 [==============================] - 0s 101us/step - loss: 0.2425 - acc: 0.8911\n",
            "Epoch 12/20\n",
            "202/202 [==============================] - 0s 101us/step - loss: 0.2402 - acc: 0.9010\n",
            "Epoch 13/20\n",
            "202/202 [==============================] - 0s 136us/step - loss: 0.2408 - acc: 0.9059\n",
            "Epoch 14/20\n",
            "202/202 [==============================] - 0s 114us/step - loss: 0.2967 - acc: 0.9158\n",
            "Epoch 15/20\n",
            "202/202 [==============================] - 0s 106us/step - loss: 0.2709 - acc: 0.9109\n",
            "Epoch 16/20\n",
            "202/202 [==============================] - 0s 105us/step - loss: 0.2560 - acc: 0.9109\n",
            "Epoch 17/20\n",
            "202/202 [==============================] - 0s 110us/step - loss: 0.2456 - acc: 0.9158\n",
            "Epoch 18/20\n",
            "202/202 [==============================] - 0s 96us/step - loss: 0.2614 - acc: 0.8960\n",
            "Epoch 19/20\n",
            "202/202 [==============================] - 0s 116us/step - loss: 0.2591 - acc: 0.9010\n",
            "Epoch 20/20\n",
            "202/202 [==============================] - 0s 105us/step - loss: 0.2598 - acc: 0.9059\n",
            "101/101 [==============================] - 3s 26ms/step\n",
            "Epoch 1/20\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4485 - acc: 0.7574\n",
            "Epoch 2/20\n",
            "202/202 [==============================] - 0s 117us/step - loss: 0.3848 - acc: 0.8317\n",
            "Epoch 3/20\n",
            "202/202 [==============================] - 0s 115us/step - loss: 0.3550 - acc: 0.8515\n",
            "Epoch 4/20\n",
            "202/202 [==============================] - 0s 113us/step - loss: 0.3403 - acc: 0.8465\n",
            "Epoch 5/20\n",
            "202/202 [==============================] - 0s 109us/step - loss: 0.4017 - acc: 0.8069\n",
            "Epoch 6/20\n",
            "202/202 [==============================] - 0s 110us/step - loss: 0.3560 - acc: 0.8465\n",
            "Epoch 7/20\n",
            "202/202 [==============================] - 0s 99us/step - loss: 0.3390 - acc: 0.8317\n",
            "Epoch 8/20\n",
            "202/202 [==============================] - 0s 105us/step - loss: 0.3300 - acc: 0.8317\n",
            "Epoch 9/20\n",
            "202/202 [==============================] - 0s 122us/step - loss: 0.3204 - acc: 0.8564\n",
            "Epoch 10/20\n",
            "202/202 [==============================] - 0s 111us/step - loss: 0.3281 - acc: 0.8416\n",
            "Epoch 11/20\n",
            "202/202 [==============================] - 0s 102us/step - loss: 0.3202 - acc: 0.8614\n",
            "Epoch 12/20\n",
            "202/202 [==============================] - 0s 96us/step - loss: 0.3254 - acc: 0.8465\n",
            "Epoch 13/20\n",
            "202/202 [==============================] - 0s 110us/step - loss: 0.3529 - acc: 0.8564\n",
            "Epoch 14/20\n",
            "202/202 [==============================] - 0s 101us/step - loss: 0.3419 - acc: 0.8465\n",
            "Epoch 15/20\n",
            "202/202 [==============================] - 0s 123us/step - loss: 0.3697 - acc: 0.8218\n",
            "Epoch 16/20\n",
            "202/202 [==============================] - 0s 104us/step - loss: 0.3853 - acc: 0.7970\n",
            "Epoch 17/20\n",
            "202/202 [==============================] - 0s 99us/step - loss: 0.3441 - acc: 0.8564\n",
            "Epoch 18/20\n",
            "202/202 [==============================] - 0s 107us/step - loss: 0.3651 - acc: 0.8515\n",
            "Epoch 19/20\n",
            "202/202 [==============================] - 0s 115us/step - loss: 0.3469 - acc: 0.8416\n",
            "Epoch 20/20\n",
            "202/202 [==============================] - 0s 98us/step - loss: 0.4334 - acc: 0.7871\n",
            "101/101 [==============================] - 3s 26ms/step\n",
            "Epoch 1/20\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.5172 - acc: 0.7475\n",
            "Epoch 2/20\n",
            "202/202 [==============================] - 0s 99us/step - loss: 0.4078 - acc: 0.7822\n",
            "Epoch 3/20\n",
            "202/202 [==============================] - 0s 95us/step - loss: 0.3571 - acc: 0.8564\n",
            "Epoch 4/20\n",
            "202/202 [==============================] - 0s 105us/step - loss: 0.4607 - acc: 0.7970\n",
            "Epoch 5/20\n",
            "202/202 [==============================] - 0s 100us/step - loss: 0.4119 - acc: 0.8416\n",
            "Epoch 6/20\n",
            "202/202 [==============================] - 0s 118us/step - loss: 0.3737 - acc: 0.8564\n",
            "Epoch 7/20\n",
            "202/202 [==============================] - 0s 109us/step - loss: 0.3639 - acc: 0.8663\n",
            "Epoch 8/20\n",
            "202/202 [==============================] - 0s 111us/step - loss: 0.3534 - acc: 0.8713\n",
            "Epoch 9/20\n",
            "202/202 [==============================] - 0s 107us/step - loss: 0.3409 - acc: 0.8614\n",
            "Epoch 10/20\n",
            "202/202 [==============================] - 0s 133us/step - loss: 0.3487 - acc: 0.8515\n",
            "Epoch 11/20\n",
            "202/202 [==============================] - 0s 120us/step - loss: 0.3422 - acc: 0.8564\n",
            "Epoch 12/20\n",
            "202/202 [==============================] - 0s 115us/step - loss: 0.3399 - acc: 0.8762\n",
            "Epoch 13/20\n",
            "202/202 [==============================] - 0s 99us/step - loss: 0.3353 - acc: 0.8762\n",
            "Epoch 14/20\n",
            "202/202 [==============================] - 0s 129us/step - loss: 0.3822 - acc: 0.8168\n",
            "Epoch 15/20\n",
            "202/202 [==============================] - 0s 112us/step - loss: 0.4187 - acc: 0.8267\n",
            "Epoch 16/20\n",
            "202/202 [==============================] - 0s 127us/step - loss: 0.3553 - acc: 0.8218\n",
            "Epoch 17/20\n",
            "202/202 [==============================] - 0s 110us/step - loss: 0.3389 - acc: 0.8267\n",
            "Epoch 18/20\n",
            "202/202 [==============================] - 0s 130us/step - loss: 0.3372 - acc: 0.8465\n",
            "Epoch 19/20\n",
            "202/202 [==============================] - 0s 116us/step - loss: 0.3342 - acc: 0.8465\n",
            "Epoch 20/20\n",
            "202/202 [==============================] - 0s 131us/step - loss: 0.3387 - acc: 0.8564\n",
            "101/101 [==============================] - 3s 26ms/step\n",
            "Epoch 1/20\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.6247 - acc: 0.7030\n",
            "Epoch 2/20\n",
            "202/202 [==============================] - 0s 104us/step - loss: 0.3354 - acc: 0.8911\n",
            "Epoch 3/20\n",
            "202/202 [==============================] - 0s 101us/step - loss: 0.3748 - acc: 0.8366\n",
            "Epoch 4/20\n",
            "202/202 [==============================] - 0s 108us/step - loss: 0.2874 - acc: 0.8713\n",
            "Epoch 5/20\n",
            "202/202 [==============================] - 0s 123us/step - loss: 0.2663 - acc: 0.8762\n",
            "Epoch 6/20\n",
            "202/202 [==============================] - 0s 105us/step - loss: 0.3219 - acc: 0.8564\n",
            "Epoch 7/20\n",
            "202/202 [==============================] - 0s 114us/step - loss: 0.2706 - acc: 0.8960\n",
            "Epoch 8/20\n",
            "202/202 [==============================] - 0s 106us/step - loss: 0.2557 - acc: 0.8960\n",
            "Epoch 9/20\n",
            "202/202 [==============================] - 0s 104us/step - loss: 0.2503 - acc: 0.8960\n",
            "Epoch 10/20\n",
            "202/202 [==============================] - 0s 106us/step - loss: 0.2670 - acc: 0.9109\n",
            "Epoch 11/20\n",
            "202/202 [==============================] - 0s 145us/step - loss: 0.2924 - acc: 0.9010\n",
            "Epoch 12/20\n",
            "202/202 [==============================] - 0s 107us/step - loss: 0.2638 - acc: 0.8960\n",
            "Epoch 13/20\n",
            "202/202 [==============================] - 0s 111us/step - loss: 0.2488 - acc: 0.8960\n",
            "Epoch 14/20\n",
            "202/202 [==============================] - 0s 110us/step - loss: 0.2459 - acc: 0.9109\n",
            "Epoch 15/20\n",
            "202/202 [==============================] - 0s 129us/step - loss: 0.2509 - acc: 0.9059\n",
            "Epoch 16/20\n",
            "202/202 [==============================] - 0s 95us/step - loss: 0.2469 - acc: 0.9059\n",
            "Epoch 17/20\n",
            "202/202 [==============================] - 0s 112us/step - loss: 0.2407 - acc: 0.9158\n",
            "Epoch 18/20\n",
            "202/202 [==============================] - 0s 121us/step - loss: 0.2919 - acc: 0.8762\n",
            "Epoch 19/20\n",
            "202/202 [==============================] - 0s 99us/step - loss: 0.2624 - acc: 0.8960\n",
            "Epoch 20/20\n",
            "202/202 [==============================] - 0s 111us/step - loss: 0.2520 - acc: 0.8861\n",
            "101/101 [==============================] - 3s 26ms/step\n",
            "Epoch 1/20\n",
            "303/303 [==============================] - 6s 20ms/step - loss: 0.6857 - acc: 0.5809\n",
            "Epoch 2/20\n",
            "303/303 [==============================] - 0s 78us/step - loss: 0.6291 - acc: 0.6700\n",
            "Epoch 3/20\n",
            "303/303 [==============================] - 0s 87us/step - loss: 0.5853 - acc: 0.7030\n",
            "Epoch 4/20\n",
            "303/303 [==============================] - 0s 87us/step - loss: 0.5510 - acc: 0.7426\n",
            "Epoch 5/20\n",
            "303/303 [==============================] - 0s 88us/step - loss: 0.5242 - acc: 0.7657\n",
            "Epoch 6/20\n",
            "303/303 [==============================] - 0s 85us/step - loss: 0.5033 - acc: 0.7624\n",
            "Epoch 7/20\n",
            "303/303 [==============================] - 0s 83us/step - loss: 0.4864 - acc: 0.7756\n",
            "Epoch 8/20\n",
            "303/303 [==============================] - 0s 81us/step - loss: 0.4722 - acc: 0.7756\n",
            "Epoch 9/20\n",
            "303/303 [==============================] - 0s 98us/step - loss: 0.4606 - acc: 0.7855\n",
            "Epoch 10/20\n",
            "303/303 [==============================] - 0s 98us/step - loss: 0.4505 - acc: 0.7921\n",
            "Epoch 11/20\n",
            "303/303 [==============================] - 0s 106us/step - loss: 0.4424 - acc: 0.7987\n",
            "Epoch 12/20\n",
            "303/303 [==============================] - 0s 89us/step - loss: 0.4348 - acc: 0.8053\n",
            "Epoch 13/20\n",
            "303/303 [==============================] - 0s 80us/step - loss: 0.4285 - acc: 0.8086\n",
            "Epoch 14/20\n",
            "303/303 [==============================] - 0s 84us/step - loss: 0.4232 - acc: 0.8119\n",
            "Epoch 15/20\n",
            "303/303 [==============================] - 0s 100us/step - loss: 0.4179 - acc: 0.8086\n",
            "Epoch 16/20\n",
            "303/303 [==============================] - 0s 102us/step - loss: 0.4134 - acc: 0.8119\n",
            "Epoch 17/20\n",
            "303/303 [==============================] - 0s 90us/step - loss: 0.4094 - acc: 0.8119\n",
            "Epoch 18/20\n",
            "303/303 [==============================] - 0s 91us/step - loss: 0.4060 - acc: 0.8119\n",
            "Epoch 19/20\n",
            "303/303 [==============================] - 0s 91us/step - loss: 0.4027 - acc: 0.8152\n",
            "Epoch 20/20\n",
            "303/303 [==============================] - 0s 97us/step - loss: 0.3996 - acc: 0.8152\n",
            "Best: 0.719471948079937 using {'learn_rate': 0.01, 'momentum': 0.0}\n",
            "Means: 0.6402640330909503, Stdev: 0.06484119858611656 with: {'learn_rate': 0.001, 'momentum': 0.0}\n",
            "Means: 0.719471948079937, Stdev: 0.057353619804731915 with: {'learn_rate': 0.01, 'momentum': 0.0}\n",
            "Means: 0.6699670005356124, Stdev: 0.08296900643377052 with: {'learn_rate': 0.1, 'momentum': 0.0}\n",
            "Means: 0.660066009944815, Stdev: 0.10236345284362496 with: {'learn_rate': 0.2, 'momentum': 0.0}\n",
            "Means: 0.6732673204377932, Stdev: 0.09933939595955862 with: {'learn_rate': 0.3, 'momentum': 0.0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SK6jVj1HYadS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 13416
        },
        "outputId": "e0eb4f37-f08a-44a0-9fca-9e583e2e5049"
      },
      "source": [
        "# Gridsearch on momentum\n",
        "\n",
        "# Function to create model, required for KerasClassifier\n",
        "def create_model(learn_rate=0.01, momentum=0):\n",
        "  # create model\n",
        "  model = Sequential()\n",
        "  model.add(Dense(13, input_dim=13, activation='linear'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  optimizer = SGD(lr=learn_rate, momentum=momentum)\n",
        "  # Compile model\n",
        "  model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "# create model\n",
        "model = KerasClassifier(build_fn=create_model, epochs=20, batch_size=40, verbose=1)\n",
        "\n",
        "# Create param grid\n",
        "learn_rate = [0.01]\n",
        "momentum = [0.0, 0.2, 0.4, 0.6, 0.8, 0.9]\n",
        "param_grid = dict(learn_rate=learn_rate, momentum=momentum)\n",
        "\n",
        "# Create Grid Search\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1)\n",
        "grid_result = grid.fit(X, y)\n",
        "\n",
        "# Report Results\n",
        "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
            "  warnings.warn(CV_WARNING, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "202/202 [==============================] - 5s 27ms/step - loss: 1.0370 - acc: 0.4604\n",
            "Epoch 2/20\n",
            "202/202 [==============================] - 0s 97us/step - loss: 0.9501 - acc: 0.4802\n",
            "Epoch 3/20\n",
            "202/202 [==============================] - 0s 104us/step - loss: 0.8808 - acc: 0.5099\n",
            "Epoch 4/20\n",
            "202/202 [==============================] - 0s 98us/step - loss: 0.8089 - acc: 0.5792\n",
            "Epoch 5/20\n",
            "202/202 [==============================] - 0s 102us/step - loss: 0.7536 - acc: 0.6139\n",
            "Epoch 6/20\n",
            "202/202 [==============================] - 0s 98us/step - loss: 0.7148 - acc: 0.6436\n",
            "Epoch 7/20\n",
            "202/202 [==============================] - 0s 99us/step - loss: 0.6760 - acc: 0.6832\n",
            "Epoch 8/20\n",
            "202/202 [==============================] - 0s 110us/step - loss: 0.6452 - acc: 0.7178\n",
            "Epoch 9/20\n",
            "202/202 [==============================] - 0s 108us/step - loss: 0.6157 - acc: 0.7327\n",
            "Epoch 10/20\n",
            "202/202 [==============================] - 0s 116us/step - loss: 0.5950 - acc: 0.7475\n",
            "Epoch 11/20\n",
            "202/202 [==============================] - 0s 117us/step - loss: 0.5763 - acc: 0.7475\n",
            "Epoch 12/20\n",
            "202/202 [==============================] - 0s 100us/step - loss: 0.5575 - acc: 0.7525\n",
            "Epoch 13/20\n",
            "202/202 [==============================] - 0s 107us/step - loss: 0.5440 - acc: 0.7525\n",
            "Epoch 14/20\n",
            "202/202 [==============================] - 0s 96us/step - loss: 0.5272 - acc: 0.7525\n",
            "Epoch 15/20\n",
            "202/202 [==============================] - 0s 99us/step - loss: 0.5140 - acc: 0.7624\n",
            "Epoch 16/20\n",
            "202/202 [==============================] - 0s 102us/step - loss: 0.5008 - acc: 0.7673\n",
            "Epoch 17/20\n",
            "202/202 [==============================] - 0s 141us/step - loss: 0.4872 - acc: 0.7822\n",
            "Epoch 18/20\n",
            "202/202 [==============================] - 0s 100us/step - loss: 0.4790 - acc: 0.7822\n",
            "Epoch 19/20\n",
            "202/202 [==============================] - 0s 101us/step - loss: 0.4696 - acc: 0.7921\n",
            "Epoch 20/20\n",
            "202/202 [==============================] - 0s 107us/step - loss: 0.4552 - acc: 0.7921\n",
            "101/101 [==============================] - 2s 21ms/step\n",
            "Epoch 1/20\n",
            "202/202 [==============================] - 5s 24ms/step - loss: 0.6424 - acc: 0.7030\n",
            "Epoch 2/20\n",
            "202/202 [==============================] - 0s 97us/step - loss: 0.6184 - acc: 0.7277\n",
            "Epoch 3/20\n",
            "202/202 [==============================] - 0s 83us/step - loss: 0.5885 - acc: 0.7574\n",
            "Epoch 4/20\n",
            "202/202 [==============================] - 0s 85us/step - loss: 0.5670 - acc: 0.7673\n",
            "Epoch 5/20\n",
            "202/202 [==============================] - 0s 89us/step - loss: 0.5491 - acc: 0.7673\n",
            "Epoch 6/20\n",
            "202/202 [==============================] - 0s 95us/step - loss: 0.5336 - acc: 0.7723\n",
            "Epoch 7/20\n",
            "202/202 [==============================] - 0s 95us/step - loss: 0.5168 - acc: 0.7871\n",
            "Epoch 8/20\n",
            "202/202 [==============================] - 0s 91us/step - loss: 0.5015 - acc: 0.8020\n",
            "Epoch 9/20\n",
            "202/202 [==============================] - 0s 92us/step - loss: 0.4888 - acc: 0.8069\n",
            "Epoch 10/20\n",
            "202/202 [==============================] - 0s 83us/step - loss: 0.4783 - acc: 0.8119\n",
            "Epoch 11/20\n",
            "202/202 [==============================] - 0s 105us/step - loss: 0.4685 - acc: 0.8168\n",
            "Epoch 12/20\n",
            "202/202 [==============================] - 0s 101us/step - loss: 0.4586 - acc: 0.8267\n",
            "Epoch 13/20\n",
            "202/202 [==============================] - 0s 111us/step - loss: 0.4490 - acc: 0.8168\n",
            "Epoch 14/20\n",
            "202/202 [==============================] - 0s 102us/step - loss: 0.4406 - acc: 0.8119\n",
            "Epoch 15/20\n",
            "202/202 [==============================] - 0s 105us/step - loss: 0.4328 - acc: 0.8218\n",
            "Epoch 16/20\n",
            "202/202 [==============================] - 0s 108us/step - loss: 0.4260 - acc: 0.8218\n",
            "Epoch 17/20\n",
            "202/202 [==============================] - 0s 111us/step - loss: 0.4193 - acc: 0.8218\n",
            "Epoch 18/20\n",
            "202/202 [==============================] - 0s 89us/step - loss: 0.4140 - acc: 0.8218\n",
            "Epoch 19/20\n",
            "202/202 [==============================] - 0s 93us/step - loss: 0.4089 - acc: 0.8267\n",
            "Epoch 20/20\n",
            "202/202 [==============================] - 0s 92us/step - loss: 0.4040 - acc: 0.8416\n",
            "101/101 [==============================] - 2s 21ms/step\n",
            "Epoch 1/20\n",
            "202/202 [==============================] - 5s 24ms/step - loss: 0.7627 - acc: 0.5198\n",
            "Epoch 2/20\n",
            "202/202 [==============================] - 0s 87us/step - loss: 0.7092 - acc: 0.5495\n",
            "Epoch 3/20\n",
            "202/202 [==============================] - 0s 101us/step - loss: 0.6528 - acc: 0.5941\n",
            "Epoch 4/20\n",
            "202/202 [==============================] - 0s 89us/step - loss: 0.6075 - acc: 0.6584\n",
            "Epoch 5/20\n",
            "202/202 [==============================] - 0s 130us/step - loss: 0.5746 - acc: 0.7030\n",
            "Epoch 6/20\n",
            "202/202 [==============================] - 0s 86us/step - loss: 0.5406 - acc: 0.7624\n",
            "Epoch 7/20\n",
            "202/202 [==============================] - 0s 89us/step - loss: 0.5198 - acc: 0.7772\n",
            "Epoch 8/20\n",
            "202/202 [==============================] - 0s 85us/step - loss: 0.4988 - acc: 0.8069\n",
            "Epoch 9/20\n",
            "202/202 [==============================] - 0s 98us/step - loss: 0.4774 - acc: 0.8168\n",
            "Epoch 10/20\n",
            "202/202 [==============================] - 0s 93us/step - loss: 0.4603 - acc: 0.8416\n",
            "Epoch 11/20\n",
            "202/202 [==============================] - 0s 92us/step - loss: 0.4429 - acc: 0.8465\n",
            "Epoch 12/20\n",
            "202/202 [==============================] - 0s 96us/step - loss: 0.4290 - acc: 0.8465\n",
            "Epoch 13/20\n",
            "202/202 [==============================] - 0s 102us/step - loss: 0.4170 - acc: 0.8465\n",
            "Epoch 14/20\n",
            "202/202 [==============================] - 0s 102us/step - loss: 0.4052 - acc: 0.8465\n",
            "Epoch 15/20\n",
            "202/202 [==============================] - 0s 97us/step - loss: 0.3951 - acc: 0.8564\n",
            "Epoch 16/20\n",
            "202/202 [==============================] - 0s 94us/step - loss: 0.3847 - acc: 0.8614\n",
            "Epoch 17/20\n",
            "202/202 [==============================] - 0s 89us/step - loss: 0.3755 - acc: 0.8614\n",
            "Epoch 18/20\n",
            "202/202 [==============================] - 0s 95us/step - loss: 0.3677 - acc: 0.8663\n",
            "Epoch 19/20\n",
            "202/202 [==============================] - 0s 89us/step - loss: 0.3600 - acc: 0.8713\n",
            "Epoch 20/20\n",
            "202/202 [==============================] - 0s 101us/step - loss: 0.3553 - acc: 0.8762\n",
            "101/101 [==============================] - 2s 21ms/step\n",
            "Epoch 1/20\n",
            "202/202 [==============================] - 5s 25ms/step - loss: 0.9418 - acc: 0.4554\n",
            "Epoch 2/20\n",
            "202/202 [==============================] - 0s 111us/step - loss: 0.8004 - acc: 0.5446\n",
            "Epoch 3/20\n",
            "202/202 [==============================] - 0s 99us/step - loss: 0.7228 - acc: 0.5891\n",
            "Epoch 4/20\n",
            "202/202 [==============================] - 0s 91us/step - loss: 0.6638 - acc: 0.6040\n",
            "Epoch 5/20\n",
            "202/202 [==============================] - 0s 84us/step - loss: 0.6129 - acc: 0.6337\n",
            "Epoch 6/20\n",
            "202/202 [==============================] - 0s 91us/step - loss: 0.5805 - acc: 0.6782\n",
            "Epoch 7/20\n",
            "202/202 [==============================] - 0s 108us/step - loss: 0.5521 - acc: 0.6931\n",
            "Epoch 8/20\n",
            "202/202 [==============================] - 0s 103us/step - loss: 0.5257 - acc: 0.7178\n",
            "Epoch 9/20\n",
            "202/202 [==============================] - 0s 87us/step - loss: 0.5029 - acc: 0.7426\n",
            "Epoch 10/20\n",
            "202/202 [==============================] - 0s 101us/step - loss: 0.4825 - acc: 0.7475\n",
            "Epoch 11/20\n",
            "202/202 [==============================] - 0s 95us/step - loss: 0.4706 - acc: 0.7624\n",
            "Epoch 12/20\n",
            "202/202 [==============================] - 0s 132us/step - loss: 0.4580 - acc: 0.7970\n",
            "Epoch 13/20\n",
            "202/202 [==============================] - 0s 131us/step - loss: 0.4480 - acc: 0.7871\n",
            "Epoch 14/20\n",
            "202/202 [==============================] - 0s 114us/step - loss: 0.4384 - acc: 0.7970\n",
            "Epoch 15/20\n",
            "202/202 [==============================] - 0s 95us/step - loss: 0.4272 - acc: 0.8069\n",
            "Epoch 16/20\n",
            "202/202 [==============================] - 0s 104us/step - loss: 0.4200 - acc: 0.8119\n",
            "Epoch 17/20\n",
            "202/202 [==============================] - 0s 96us/step - loss: 0.4172 - acc: 0.8119\n",
            "Epoch 18/20\n",
            "202/202 [==============================] - 0s 109us/step - loss: 0.4112 - acc: 0.8069\n",
            "Epoch 19/20\n",
            "202/202 [==============================] - 0s 111us/step - loss: 0.4046 - acc: 0.8119\n",
            "Epoch 20/20\n",
            "202/202 [==============================] - 0s 145us/step - loss: 0.3998 - acc: 0.8119\n",
            "101/101 [==============================] - 2s 21ms/step\n",
            "Epoch 1/20\n",
            "202/202 [==============================] - 5s 25ms/step - loss: 1.1810 - acc: 0.3317\n",
            "Epoch 2/20\n",
            "202/202 [==============================] - 0s 93us/step - loss: 1.0040 - acc: 0.4059\n",
            "Epoch 3/20\n",
            "202/202 [==============================] - 0s 96us/step - loss: 0.8828 - acc: 0.4703\n",
            "Epoch 4/20\n",
            "202/202 [==============================] - 0s 95us/step - loss: 0.7737 - acc: 0.5347\n",
            "Epoch 5/20\n",
            "202/202 [==============================] - 0s 93us/step - loss: 0.6993 - acc: 0.5891\n",
            "Epoch 6/20\n",
            "202/202 [==============================] - 0s 107us/step - loss: 0.6312 - acc: 0.6337\n",
            "Epoch 7/20\n",
            "202/202 [==============================] - 0s 111us/step - loss: 0.5879 - acc: 0.6584\n",
            "Epoch 8/20\n",
            "202/202 [==============================] - 0s 101us/step - loss: 0.5527 - acc: 0.6980\n",
            "Epoch 9/20\n",
            "202/202 [==============================] - 0s 113us/step - loss: 0.5257 - acc: 0.7376\n",
            "Epoch 10/20\n",
            "202/202 [==============================] - 0s 150us/step - loss: 0.4996 - acc: 0.7624\n",
            "Epoch 11/20\n",
            "202/202 [==============================] - 0s 115us/step - loss: 0.4764 - acc: 0.7723\n",
            "Epoch 12/20\n",
            "202/202 [==============================] - 0s 101us/step - loss: 0.4587 - acc: 0.7871\n",
            "Epoch 13/20\n",
            "202/202 [==============================] - 0s 91us/step - loss: 0.4464 - acc: 0.7970\n",
            "Epoch 14/20\n",
            "202/202 [==============================] - 0s 95us/step - loss: 0.4364 - acc: 0.8069\n",
            "Epoch 15/20\n",
            "202/202 [==============================] - 0s 152us/step - loss: 0.4283 - acc: 0.8168\n",
            "Epoch 16/20\n",
            "202/202 [==============================] - 0s 131us/step - loss: 0.4216 - acc: 0.8168\n",
            "Epoch 17/20\n",
            "202/202 [==============================] - 0s 127us/step - loss: 0.4137 - acc: 0.8317\n",
            "Epoch 18/20\n",
            "202/202 [==============================] - 0s 121us/step - loss: 0.4070 - acc: 0.8366\n",
            "Epoch 19/20\n",
            "202/202 [==============================] - 0s 117us/step - loss: 0.4021 - acc: 0.8366\n",
            "Epoch 20/20\n",
            "202/202 [==============================] - 0s 120us/step - loss: 0.3955 - acc: 0.8366\n",
            "101/101 [==============================] - 2s 22ms/step\n",
            "Epoch 1/20\n",
            "202/202 [==============================] - 5s 25ms/step - loss: 0.7570 - acc: 0.5990\n",
            "Epoch 2/20\n",
            "202/202 [==============================] - 0s 99us/step - loss: 0.6975 - acc: 0.6485\n",
            "Epoch 3/20\n",
            "202/202 [==============================] - 0s 94us/step - loss: 0.6352 - acc: 0.7079\n",
            "Epoch 4/20\n",
            "202/202 [==============================] - 0s 100us/step - loss: 0.5889 - acc: 0.7228\n",
            "Epoch 5/20\n",
            "202/202 [==============================] - 0s 88us/step - loss: 0.5563 - acc: 0.7426\n",
            "Epoch 6/20\n",
            "202/202 [==============================] - 0s 93us/step - loss: 0.5273 - acc: 0.7574\n",
            "Epoch 7/20\n",
            "202/202 [==============================] - 0s 93us/step - loss: 0.5067 - acc: 0.7822\n",
            "Epoch 8/20\n",
            "202/202 [==============================] - 0s 96us/step - loss: 0.4855 - acc: 0.7871\n",
            "Epoch 9/20\n",
            "202/202 [==============================] - 0s 100us/step - loss: 0.4621 - acc: 0.8020\n",
            "Epoch 10/20\n",
            "202/202 [==============================] - 0s 99us/step - loss: 0.4439 - acc: 0.8020\n",
            "Epoch 11/20\n",
            "202/202 [==============================] - 0s 89us/step - loss: 0.4277 - acc: 0.8020\n",
            "Epoch 12/20\n",
            "202/202 [==============================] - 0s 116us/step - loss: 0.4145 - acc: 0.8069\n",
            "Epoch 13/20\n",
            "202/202 [==============================] - 0s 112us/step - loss: 0.4041 - acc: 0.8267\n",
            "Epoch 14/20\n",
            "202/202 [==============================] - 0s 115us/step - loss: 0.3950 - acc: 0.8317\n",
            "Epoch 15/20\n",
            "202/202 [==============================] - 0s 125us/step - loss: 0.3853 - acc: 0.8416\n",
            "Epoch 16/20\n",
            "202/202 [==============================] - 0s 91us/step - loss: 0.3726 - acc: 0.8465\n",
            "Epoch 17/20\n",
            "202/202 [==============================] - 0s 106us/step - loss: 0.3647 - acc: 0.8515\n",
            "Epoch 18/20\n",
            "202/202 [==============================] - 0s 114us/step - loss: 0.3569 - acc: 0.8515\n",
            "Epoch 19/20\n",
            "202/202 [==============================] - 0s 117us/step - loss: 0.3505 - acc: 0.8564\n",
            "Epoch 20/20\n",
            "202/202 [==============================] - 0s 108us/step - loss: 0.3443 - acc: 0.8564\n",
            "101/101 [==============================] - 2s 22ms/step\n",
            "Epoch 1/20\n",
            "202/202 [==============================] - 5s 25ms/step - loss: 1.2039 - acc: 0.3911\n",
            "Epoch 2/20\n",
            "202/202 [==============================] - 0s 109us/step - loss: 1.0331 - acc: 0.4455\n",
            "Epoch 3/20\n",
            "202/202 [==============================] - 0s 107us/step - loss: 0.8706 - acc: 0.4950\n",
            "Epoch 4/20\n",
            "202/202 [==============================] - 0s 100us/step - loss: 0.7798 - acc: 0.5594\n",
            "Epoch 5/20\n",
            "202/202 [==============================] - 0s 107us/step - loss: 0.7102 - acc: 0.6188\n",
            "Epoch 6/20\n",
            "202/202 [==============================] - 0s 99us/step - loss: 0.6465 - acc: 0.6634\n",
            "Epoch 7/20\n",
            "202/202 [==============================] - 0s 96us/step - loss: 0.5919 - acc: 0.7129\n",
            "Epoch 8/20\n",
            "202/202 [==============================] - 0s 113us/step - loss: 0.5455 - acc: 0.7277\n",
            "Epoch 9/20\n",
            "202/202 [==============================] - 0s 99us/step - loss: 0.5117 - acc: 0.7574\n",
            "Epoch 10/20\n",
            "202/202 [==============================] - 0s 176us/step - loss: 0.4893 - acc: 0.7871\n",
            "Epoch 11/20\n",
            "202/202 [==============================] - 0s 122us/step - loss: 0.4712 - acc: 0.7970\n",
            "Epoch 12/20\n",
            "202/202 [==============================] - 0s 117us/step - loss: 0.4534 - acc: 0.7970\n",
            "Epoch 13/20\n",
            "202/202 [==============================] - 0s 110us/step - loss: 0.4391 - acc: 0.8119\n",
            "Epoch 14/20\n",
            "202/202 [==============================] - 0s 123us/step - loss: 0.4254 - acc: 0.8069\n",
            "Epoch 15/20\n",
            "202/202 [==============================] - 0s 96us/step - loss: 0.4161 - acc: 0.8168\n",
            "Epoch 16/20\n",
            "202/202 [==============================] - 0s 100us/step - loss: 0.4077 - acc: 0.8168\n",
            "Epoch 17/20\n",
            "202/202 [==============================] - 0s 96us/step - loss: 0.3992 - acc: 0.8168\n",
            "Epoch 18/20\n",
            "202/202 [==============================] - 0s 102us/step - loss: 0.3929 - acc: 0.8168\n",
            "Epoch 19/20\n",
            "202/202 [==============================] - 0s 92us/step - loss: 0.3865 - acc: 0.8267\n",
            "Epoch 20/20\n",
            "202/202 [==============================] - 0s 105us/step - loss: 0.3822 - acc: 0.8267\n",
            "101/101 [==============================] - 2s 22ms/step\n",
            "Epoch 1/20\n",
            "202/202 [==============================] - 5s 26ms/step - loss: 0.6318 - acc: 0.6238\n",
            "Epoch 2/20\n",
            "202/202 [==============================] - 0s 96us/step - loss: 0.5890 - acc: 0.6832\n",
            "Epoch 3/20\n",
            "202/202 [==============================] - 0s 113us/step - loss: 0.5501 - acc: 0.7475\n",
            "Epoch 4/20\n",
            "202/202 [==============================] - 0s 124us/step - loss: 0.5194 - acc: 0.7624\n",
            "Epoch 5/20\n",
            "202/202 [==============================] - 0s 106us/step - loss: 0.4918 - acc: 0.7871\n",
            "Epoch 6/20\n",
            "202/202 [==============================] - 0s 108us/step - loss: 0.4715 - acc: 0.7970\n",
            "Epoch 7/20\n",
            "202/202 [==============================] - 0s 109us/step - loss: 0.4532 - acc: 0.8119\n",
            "Epoch 8/20\n",
            "202/202 [==============================] - 0s 104us/step - loss: 0.4432 - acc: 0.8119\n",
            "Epoch 9/20\n",
            "202/202 [==============================] - 0s 110us/step - loss: 0.4369 - acc: 0.8168\n",
            "Epoch 10/20\n",
            "202/202 [==============================] - 0s 115us/step - loss: 0.4264 - acc: 0.8267\n",
            "Epoch 11/20\n",
            "202/202 [==============================] - 0s 153us/step - loss: 0.4170 - acc: 0.8317\n",
            "Epoch 12/20\n",
            "202/202 [==============================] - 0s 142us/step - loss: 0.4065 - acc: 0.8416\n",
            "Epoch 13/20\n",
            "202/202 [==============================] - 0s 103us/step - loss: 0.3981 - acc: 0.8416\n",
            "Epoch 14/20\n",
            "202/202 [==============================] - 0s 108us/step - loss: 0.3911 - acc: 0.8465\n",
            "Epoch 15/20\n",
            "202/202 [==============================] - 0s 104us/step - loss: 0.3850 - acc: 0.8564\n",
            "Epoch 16/20\n",
            "202/202 [==============================] - 0s 104us/step - loss: 0.3800 - acc: 0.8564\n",
            "Epoch 17/20\n",
            "202/202 [==============================] - 0s 125us/step - loss: 0.3758 - acc: 0.8564\n",
            "Epoch 18/20\n",
            "202/202 [==============================] - 0s 94us/step - loss: 0.3746 - acc: 0.8465\n",
            "Epoch 19/20\n",
            "202/202 [==============================] - 0s 103us/step - loss: 0.3716 - acc: 0.8515\n",
            "Epoch 20/20\n",
            "202/202 [==============================] - 0s 105us/step - loss: 0.3681 - acc: 0.8515\n",
            "101/101 [==============================] - 2s 22ms/step\n",
            "Epoch 1/20\n",
            "202/202 [==============================] - 5s 26ms/step - loss: 0.7368 - acc: 0.5941\n",
            "Epoch 2/20\n",
            "202/202 [==============================] - 0s 113us/step - loss: 0.6256 - acc: 0.6535\n",
            "Epoch 3/20\n",
            "202/202 [==============================] - 0s 112us/step - loss: 0.5403 - acc: 0.7475\n",
            "Epoch 4/20\n",
            "202/202 [==============================] - 0s 103us/step - loss: 0.4898 - acc: 0.8069\n",
            "Epoch 5/20\n",
            "202/202 [==============================] - 0s 95us/step - loss: 0.4507 - acc: 0.8119\n",
            "Epoch 6/20\n",
            "202/202 [==============================] - 0s 98us/step - loss: 0.4128 - acc: 0.8366\n",
            "Epoch 7/20\n",
            "202/202 [==============================] - 0s 103us/step - loss: 0.3856 - acc: 0.8416\n",
            "Epoch 8/20\n",
            "202/202 [==============================] - 0s 103us/step - loss: 0.3676 - acc: 0.8465\n",
            "Epoch 9/20\n",
            "202/202 [==============================] - 0s 99us/step - loss: 0.3533 - acc: 0.8515\n",
            "Epoch 10/20\n",
            "202/202 [==============================] - 0s 112us/step - loss: 0.3408 - acc: 0.8614\n",
            "Epoch 11/20\n",
            "202/202 [==============================] - 0s 98us/step - loss: 0.3290 - acc: 0.8663\n",
            "Epoch 12/20\n",
            "202/202 [==============================] - 0s 121us/step - loss: 0.3195 - acc: 0.8762\n",
            "Epoch 13/20\n",
            "202/202 [==============================] - 0s 104us/step - loss: 0.3090 - acc: 0.9010\n",
            "Epoch 14/20\n",
            "202/202 [==============================] - 0s 105us/step - loss: 0.3041 - acc: 0.8960\n",
            "Epoch 15/20\n",
            "202/202 [==============================] - 0s 90us/step - loss: 0.2990 - acc: 0.8960\n",
            "Epoch 16/20\n",
            "202/202 [==============================] - 0s 103us/step - loss: 0.2940 - acc: 0.8960\n",
            "Epoch 17/20\n",
            "202/202 [==============================] - 0s 95us/step - loss: 0.2898 - acc: 0.8960\n",
            "Epoch 18/20\n",
            "202/202 [==============================] - 0s 94us/step - loss: 0.2860 - acc: 0.8911\n",
            "Epoch 19/20\n",
            "202/202 [==============================] - 0s 112us/step - loss: 0.2841 - acc: 0.8861\n",
            "Epoch 20/20\n",
            "202/202 [==============================] - 0s 114us/step - loss: 0.2824 - acc: 0.8812\n",
            "101/101 [==============================] - 2s 22ms/step\n",
            "Epoch 1/20\n",
            "202/202 [==============================] - 5s 26ms/step - loss: 1.1714 - acc: 0.3069\n",
            "Epoch 2/20\n",
            "202/202 [==============================] - 0s 107us/step - loss: 0.9030 - acc: 0.4208\n",
            "Epoch 3/20\n",
            "202/202 [==============================] - 0s 90us/step - loss: 0.7263 - acc: 0.5396\n",
            "Epoch 4/20\n",
            "202/202 [==============================] - 0s 98us/step - loss: 0.6116 - acc: 0.6733\n",
            "Epoch 5/20\n",
            "202/202 [==============================] - 0s 103us/step - loss: 0.5451 - acc: 0.7277\n",
            "Epoch 6/20\n",
            "202/202 [==============================] - 0s 96us/step - loss: 0.4999 - acc: 0.7673\n",
            "Epoch 7/20\n",
            "202/202 [==============================] - 0s 93us/step - loss: 0.4720 - acc: 0.7871\n",
            "Epoch 8/20\n",
            "202/202 [==============================] - 0s 105us/step - loss: 0.4466 - acc: 0.7970\n",
            "Epoch 9/20\n",
            "202/202 [==============================] - 0s 100us/step - loss: 0.4244 - acc: 0.8119\n",
            "Epoch 10/20\n",
            "202/202 [==============================] - 0s 95us/step - loss: 0.4097 - acc: 0.8267\n",
            "Epoch 11/20\n",
            "202/202 [==============================] - 0s 103us/step - loss: 0.3956 - acc: 0.8416\n",
            "Epoch 12/20\n",
            "202/202 [==============================] - 0s 97us/step - loss: 0.3868 - acc: 0.8416\n",
            "Epoch 13/20\n",
            "202/202 [==============================] - 0s 93us/step - loss: 0.3821 - acc: 0.8366\n",
            "Epoch 14/20\n",
            "202/202 [==============================] - 0s 97us/step - loss: 0.3733 - acc: 0.8416\n",
            "Epoch 15/20\n",
            "202/202 [==============================] - 0s 109us/step - loss: 0.3659 - acc: 0.8515\n",
            "Epoch 16/20\n",
            "202/202 [==============================] - 0s 86us/step - loss: 0.3599 - acc: 0.8465\n",
            "Epoch 17/20\n",
            "202/202 [==============================] - 0s 89us/step - loss: 0.3549 - acc: 0.8465\n",
            "Epoch 18/20\n",
            "202/202 [==============================] - 0s 102us/step - loss: 0.3514 - acc: 0.8465\n",
            "Epoch 19/20\n",
            "202/202 [==============================] - 0s 96us/step - loss: 0.3489 - acc: 0.8515\n",
            "Epoch 20/20\n",
            "202/202 [==============================] - 0s 103us/step - loss: 0.3471 - acc: 0.8663\n",
            "101/101 [==============================] - 2s 22ms/step\n",
            "Epoch 1/20\n",
            "202/202 [==============================] - 5s 26ms/step - loss: 0.9363 - acc: 0.4505\n",
            "Epoch 2/20\n",
            "202/202 [==============================] - 0s 97us/step - loss: 0.7868 - acc: 0.5446\n",
            "Epoch 3/20\n",
            "202/202 [==============================] - 0s 105us/step - loss: 0.6748 - acc: 0.6436\n",
            "Epoch 4/20\n",
            "202/202 [==============================] - 0s 113us/step - loss: 0.5957 - acc: 0.7376\n",
            "Epoch 5/20\n",
            "202/202 [==============================] - 0s 99us/step - loss: 0.5508 - acc: 0.7673\n",
            "Epoch 6/20\n",
            "202/202 [==============================] - 0s 95us/step - loss: 0.5141 - acc: 0.8069\n",
            "Epoch 7/20\n",
            "202/202 [==============================] - 0s 113us/step - loss: 0.4866 - acc: 0.8069\n",
            "Epoch 8/20\n",
            "202/202 [==============================] - 0s 106us/step - loss: 0.4662 - acc: 0.8168\n",
            "Epoch 9/20\n",
            "202/202 [==============================] - 0s 116us/step - loss: 0.4458 - acc: 0.8267\n",
            "Epoch 10/20\n",
            "202/202 [==============================] - 0s 112us/step - loss: 0.4291 - acc: 0.8069\n",
            "Epoch 11/20\n",
            "202/202 [==============================] - 0s 102us/step - loss: 0.4169 - acc: 0.8218\n",
            "Epoch 12/20\n",
            "202/202 [==============================] - 0s 100us/step - loss: 0.4062 - acc: 0.8119\n",
            "Epoch 13/20\n",
            "202/202 [==============================] - 0s 102us/step - loss: 0.3980 - acc: 0.8119\n",
            "Epoch 14/20\n",
            "202/202 [==============================] - 0s 103us/step - loss: 0.3927 - acc: 0.8218\n",
            "Epoch 15/20\n",
            "202/202 [==============================] - 0s 119us/step - loss: 0.3862 - acc: 0.8218\n",
            "Epoch 16/20\n",
            "202/202 [==============================] - 0s 109us/step - loss: 0.3801 - acc: 0.8069\n",
            "Epoch 17/20\n",
            "202/202 [==============================] - 0s 113us/step - loss: 0.3744 - acc: 0.8119\n",
            "Epoch 18/20\n",
            "202/202 [==============================] - 0s 100us/step - loss: 0.3711 - acc: 0.8267\n",
            "Epoch 19/20\n",
            "202/202 [==============================] - 0s 106us/step - loss: 0.3666 - acc: 0.8119\n",
            "Epoch 20/20\n",
            "202/202 [==============================] - 0s 128us/step - loss: 0.3621 - acc: 0.8069\n",
            "101/101 [==============================] - 2s 22ms/step\n",
            "Epoch 1/20\n",
            "202/202 [==============================] - 5s 26ms/step - loss: 1.0281 - acc: 0.3861\n",
            "Epoch 2/20\n",
            "202/202 [==============================] - 0s 107us/step - loss: 0.8354 - acc: 0.5099\n",
            "Epoch 3/20\n",
            "202/202 [==============================] - 0s 94us/step - loss: 0.6940 - acc: 0.6436\n",
            "Epoch 4/20\n",
            "202/202 [==============================] - 0s 101us/step - loss: 0.6021 - acc: 0.7079\n",
            "Epoch 5/20\n",
            "202/202 [==============================] - 0s 100us/step - loss: 0.5455 - acc: 0.7525\n",
            "Epoch 6/20\n",
            "202/202 [==============================] - 0s 93us/step - loss: 0.4950 - acc: 0.7723\n",
            "Epoch 7/20\n",
            "202/202 [==============================] - 0s 103us/step - loss: 0.4519 - acc: 0.7723\n",
            "Epoch 8/20\n",
            "202/202 [==============================] - 0s 102us/step - loss: 0.4220 - acc: 0.7970\n",
            "Epoch 9/20\n",
            "202/202 [==============================] - 0s 106us/step - loss: 0.4001 - acc: 0.8069\n",
            "Epoch 10/20\n",
            "202/202 [==============================] - 0s 112us/step - loss: 0.3818 - acc: 0.8020\n",
            "Epoch 11/20\n",
            "202/202 [==============================] - 0s 123us/step - loss: 0.3677 - acc: 0.8317\n",
            "Epoch 12/20\n",
            "202/202 [==============================] - 0s 118us/step - loss: 0.3567 - acc: 0.8366\n",
            "Epoch 13/20\n",
            "202/202 [==============================] - 0s 96us/step - loss: 0.3452 - acc: 0.8564\n",
            "Epoch 14/20\n",
            "202/202 [==============================] - 0s 127us/step - loss: 0.3342 - acc: 0.8564\n",
            "Epoch 15/20\n",
            "202/202 [==============================] - 0s 114us/step - loss: 0.3266 - acc: 0.8614\n",
            "Epoch 16/20\n",
            "202/202 [==============================] - 0s 106us/step - loss: 0.3198 - acc: 0.8614\n",
            "Epoch 17/20\n",
            "202/202 [==============================] - 0s 109us/step - loss: 0.3122 - acc: 0.8713\n",
            "Epoch 18/20\n",
            "202/202 [==============================] - 0s 108us/step - loss: 0.3056 - acc: 0.8762\n",
            "Epoch 19/20\n",
            "202/202 [==============================] - 0s 122us/step - loss: 0.3007 - acc: 0.8812\n",
            "Epoch 20/20\n",
            "202/202 [==============================] - 0s 142us/step - loss: 0.2955 - acc: 0.8812\n",
            "101/101 [==============================] - 2s 23ms/step\n",
            "Epoch 1/20\n",
            "202/202 [==============================] - 5s 26ms/step - loss: 0.7579 - acc: 0.6287\n",
            "Epoch 2/20\n",
            "202/202 [==============================] - 0s 102us/step - loss: 0.6176 - acc: 0.6980\n",
            "Epoch 3/20\n",
            "202/202 [==============================] - 0s 99us/step - loss: 0.5109 - acc: 0.7475\n",
            "Epoch 4/20\n",
            "202/202 [==============================] - 0s 92us/step - loss: 0.4483 - acc: 0.7822\n",
            "Epoch 5/20\n",
            "202/202 [==============================] - 0s 90us/step - loss: 0.4086 - acc: 0.8069\n",
            "Epoch 6/20\n",
            "202/202 [==============================] - 0s 91us/step - loss: 0.3883 - acc: 0.8267\n",
            "Epoch 7/20\n",
            "202/202 [==============================] - 0s 93us/step - loss: 0.3691 - acc: 0.8465\n",
            "Epoch 8/20\n",
            "202/202 [==============================] - 0s 96us/step - loss: 0.3558 - acc: 0.8663\n",
            "Epoch 9/20\n",
            "202/202 [==============================] - 0s 91us/step - loss: 0.3495 - acc: 0.8614\n",
            "Epoch 10/20\n",
            "202/202 [==============================] - 0s 92us/step - loss: 0.3412 - acc: 0.8614\n",
            "Epoch 11/20\n",
            "202/202 [==============================] - 0s 82us/step - loss: 0.3336 - acc: 0.8465\n",
            "Epoch 12/20\n",
            "202/202 [==============================] - 0s 105us/step - loss: 0.3286 - acc: 0.8416\n",
            "Epoch 13/20\n",
            "202/202 [==============================] - 0s 99us/step - loss: 0.3255 - acc: 0.8465\n",
            "Epoch 14/20\n",
            "202/202 [==============================] - 0s 89us/step - loss: 0.3237 - acc: 0.8564\n",
            "Epoch 15/20\n",
            "202/202 [==============================] - 0s 108us/step - loss: 0.3250 - acc: 0.8465\n",
            "Epoch 16/20\n",
            "202/202 [==============================] - 0s 107us/step - loss: 0.3238 - acc: 0.8366\n",
            "Epoch 17/20\n",
            "202/202 [==============================] - 0s 108us/step - loss: 0.3216 - acc: 0.8366\n",
            "Epoch 18/20\n",
            "202/202 [==============================] - 0s 131us/step - loss: 0.3203 - acc: 0.8416\n",
            "Epoch 19/20\n",
            "202/202 [==============================] - 0s 106us/step - loss: 0.3196 - acc: 0.8416\n",
            "Epoch 20/20\n",
            "202/202 [==============================] - 0s 99us/step - loss: 0.3186 - acc: 0.8465\n",
            "101/101 [==============================] - 2s 23ms/step\n",
            "Epoch 1/20\n",
            "202/202 [==============================] - 5s 27ms/step - loss: 0.9135 - acc: 0.3564\n",
            "Epoch 2/20\n",
            "202/202 [==============================] - 0s 90us/step - loss: 0.6842 - acc: 0.6188\n",
            "Epoch 3/20\n",
            "202/202 [==============================] - 0s 87us/step - loss: 0.5274 - acc: 0.7327\n",
            "Epoch 4/20\n",
            "202/202 [==============================] - 0s 91us/step - loss: 0.4536 - acc: 0.7970\n",
            "Epoch 5/20\n",
            "202/202 [==============================] - 0s 102us/step - loss: 0.4159 - acc: 0.8168\n",
            "Epoch 6/20\n",
            "202/202 [==============================] - 0s 104us/step - loss: 0.3887 - acc: 0.8366\n",
            "Epoch 7/20\n",
            "202/202 [==============================] - 0s 96us/step - loss: 0.3733 - acc: 0.8317\n",
            "Epoch 8/20\n",
            "202/202 [==============================] - 0s 104us/step - loss: 0.3653 - acc: 0.8317\n",
            "Epoch 9/20\n",
            "202/202 [==============================] - 0s 105us/step - loss: 0.3555 - acc: 0.8366\n",
            "Epoch 10/20\n",
            "202/202 [==============================] - 0s 102us/step - loss: 0.3508 - acc: 0.8515\n",
            "Epoch 11/20\n",
            "202/202 [==============================] - 0s 118us/step - loss: 0.3476 - acc: 0.8564\n",
            "Epoch 12/20\n",
            "202/202 [==============================] - 0s 108us/step - loss: 0.3441 - acc: 0.8564\n",
            "Epoch 13/20\n",
            "202/202 [==============================] - 0s 92us/step - loss: 0.3401 - acc: 0.8515\n",
            "Epoch 14/20\n",
            "202/202 [==============================] - 0s 96us/step - loss: 0.3355 - acc: 0.8713\n",
            "Epoch 15/20\n",
            "202/202 [==============================] - 0s 91us/step - loss: 0.3348 - acc: 0.8713\n",
            "Epoch 16/20\n",
            "202/202 [==============================] - 0s 100us/step - loss: 0.3326 - acc: 0.8713\n",
            "Epoch 17/20\n",
            "202/202 [==============================] - 0s 111us/step - loss: 0.3304 - acc: 0.8713\n",
            "Epoch 18/20\n",
            "202/202 [==============================] - 0s 126us/step - loss: 0.3315 - acc: 0.8564\n",
            "Epoch 19/20\n",
            "202/202 [==============================] - 0s 99us/step - loss: 0.3293 - acc: 0.8465\n",
            "Epoch 20/20\n",
            "202/202 [==============================] - 0s 109us/step - loss: 0.3306 - acc: 0.8663\n",
            "101/101 [==============================] - 2s 23ms/step\n",
            "Epoch 1/20\n",
            "202/202 [==============================] - 5s 27ms/step - loss: 0.7085 - acc: 0.5990\n",
            "Epoch 2/20\n",
            "202/202 [==============================] - 0s 106us/step - loss: 0.5969 - acc: 0.7129\n",
            "Epoch 3/20\n",
            "202/202 [==============================] - 0s 108us/step - loss: 0.4907 - acc: 0.7970\n",
            "Epoch 4/20\n",
            "202/202 [==============================] - 0s 109us/step - loss: 0.4233 - acc: 0.8218\n",
            "Epoch 5/20\n",
            "202/202 [==============================] - 0s 118us/step - loss: 0.3816 - acc: 0.8515\n",
            "Epoch 6/20\n",
            "202/202 [==============================] - 0s 115us/step - loss: 0.3493 - acc: 0.8762\n",
            "Epoch 7/20\n",
            "202/202 [==============================] - 0s 111us/step - loss: 0.3254 - acc: 0.8861\n",
            "Epoch 8/20\n",
            "202/202 [==============================] - 0s 110us/step - loss: 0.3088 - acc: 0.8911\n",
            "Epoch 9/20\n",
            "202/202 [==============================] - 0s 104us/step - loss: 0.2970 - acc: 0.8911\n",
            "Epoch 10/20\n",
            "202/202 [==============================] - 0s 109us/step - loss: 0.2879 - acc: 0.8911\n",
            "Epoch 11/20\n",
            "202/202 [==============================] - 0s 100us/step - loss: 0.2815 - acc: 0.8911\n",
            "Epoch 12/20\n",
            "202/202 [==============================] - 0s 98us/step - loss: 0.2782 - acc: 0.8861\n",
            "Epoch 13/20\n",
            "202/202 [==============================] - 0s 97us/step - loss: 0.2736 - acc: 0.8812\n",
            "Epoch 14/20\n",
            "202/202 [==============================] - 0s 103us/step - loss: 0.2714 - acc: 0.8861\n",
            "Epoch 15/20\n",
            "202/202 [==============================] - 0s 109us/step - loss: 0.2690 - acc: 0.9010\n",
            "Epoch 16/20\n",
            "202/202 [==============================] - 0s 111us/step - loss: 0.2623 - acc: 0.9059\n",
            "Epoch 17/20\n",
            "202/202 [==============================] - 0s 108us/step - loss: 0.2589 - acc: 0.9059\n",
            "Epoch 18/20\n",
            "202/202 [==============================] - 0s 100us/step - loss: 0.2583 - acc: 0.9010\n",
            "Epoch 19/20\n",
            "202/202 [==============================] - 0s 113us/step - loss: 0.2559 - acc: 0.9010\n",
            "Epoch 20/20\n",
            "202/202 [==============================] - 0s 108us/step - loss: 0.2555 - acc: 0.9010\n",
            "101/101 [==============================] - 2s 23ms/step\n",
            "Epoch 1/20\n",
            "202/202 [==============================] - 5s 27ms/step - loss: 0.5619 - acc: 0.7079\n",
            "Epoch 2/20\n",
            "202/202 [==============================] - 0s 94us/step - loss: 0.5111 - acc: 0.7426\n",
            "Epoch 3/20\n",
            "202/202 [==============================] - 0s 98us/step - loss: 0.4583 - acc: 0.7772\n",
            "Epoch 4/20\n",
            "202/202 [==============================] - 0s 96us/step - loss: 0.4137 - acc: 0.8218\n",
            "Epoch 5/20\n",
            "202/202 [==============================] - 0s 96us/step - loss: 0.3889 - acc: 0.8465\n",
            "Epoch 6/20\n",
            "202/202 [==============================] - 0s 103us/step - loss: 0.3725 - acc: 0.8515\n",
            "Epoch 7/20\n",
            "202/202 [==============================] - 0s 93us/step - loss: 0.3609 - acc: 0.8564\n",
            "Epoch 8/20\n",
            "202/202 [==============================] - 0s 104us/step - loss: 0.3529 - acc: 0.8465\n",
            "Epoch 9/20\n",
            "202/202 [==============================] - 0s 99us/step - loss: 0.3448 - acc: 0.8366\n",
            "Epoch 10/20\n",
            "202/202 [==============================] - 0s 115us/step - loss: 0.3428 - acc: 0.8267\n",
            "Epoch 11/20\n",
            "202/202 [==============================] - 0s 103us/step - loss: 0.3414 - acc: 0.8218\n",
            "Epoch 12/20\n",
            "202/202 [==============================] - 0s 119us/step - loss: 0.3433 - acc: 0.8267\n",
            "Epoch 13/20\n",
            "202/202 [==============================] - 0s 99us/step - loss: 0.3419 - acc: 0.8317\n",
            "Epoch 14/20\n",
            "202/202 [==============================] - 0s 95us/step - loss: 0.3390 - acc: 0.8168\n",
            "Epoch 15/20\n",
            "202/202 [==============================] - 0s 104us/step - loss: 0.3349 - acc: 0.8267\n",
            "Epoch 16/20\n",
            "202/202 [==============================] - 0s 130us/step - loss: 0.3304 - acc: 0.8267\n",
            "Epoch 17/20\n",
            "202/202 [==============================] - 0s 106us/step - loss: 0.3257 - acc: 0.8267\n",
            "Epoch 18/20\n",
            "202/202 [==============================] - 0s 105us/step - loss: 0.3237 - acc: 0.8218\n",
            "Epoch 19/20\n",
            "202/202 [==============================] - 0s 92us/step - loss: 0.3216 - acc: 0.8366\n",
            "Epoch 20/20\n",
            "202/202 [==============================] - 0s 88us/step - loss: 0.3205 - acc: 0.8366\n",
            "101/101 [==============================] - 2s 23ms/step\n",
            "Epoch 1/20\n",
            "202/202 [==============================] - 5s 27ms/step - loss: 1.1547 - acc: 0.3168\n",
            "Epoch 2/20\n",
            "202/202 [==============================] - 0s 102us/step - loss: 0.7384 - acc: 0.5446\n",
            "Epoch 3/20\n",
            "202/202 [==============================] - 0s 89us/step - loss: 0.4771 - acc: 0.7822\n",
            "Epoch 4/20\n",
            "202/202 [==============================] - 0s 114us/step - loss: 0.4046 - acc: 0.8119\n",
            "Epoch 5/20\n",
            "202/202 [==============================] - 0s 104us/step - loss: 0.3730 - acc: 0.8317\n",
            "Epoch 6/20\n",
            "202/202 [==============================] - 0s 108us/step - loss: 0.3619 - acc: 0.8317\n",
            "Epoch 7/20\n",
            "202/202 [==============================] - 0s 105us/step - loss: 0.3541 - acc: 0.8465\n",
            "Epoch 8/20\n",
            "202/202 [==============================] - 0s 107us/step - loss: 0.3485 - acc: 0.8515\n",
            "Epoch 9/20\n",
            "202/202 [==============================] - 0s 100us/step - loss: 0.3460 - acc: 0.8564\n",
            "Epoch 10/20\n",
            "202/202 [==============================] - 0s 105us/step - loss: 0.3418 - acc: 0.8564\n",
            "Epoch 11/20\n",
            "202/202 [==============================] - 0s 118us/step - loss: 0.3388 - acc: 0.8713\n",
            "Epoch 12/20\n",
            "202/202 [==============================] - 0s 114us/step - loss: 0.3356 - acc: 0.8762\n",
            "Epoch 13/20\n",
            "202/202 [==============================] - 0s 97us/step - loss: 0.3351 - acc: 0.8663\n",
            "Epoch 14/20\n",
            "202/202 [==============================] - 0s 110us/step - loss: 0.3357 - acc: 0.8713\n",
            "Epoch 15/20\n",
            "202/202 [==============================] - 0s 93us/step - loss: 0.3375 - acc: 0.8713\n",
            "Epoch 16/20\n",
            "202/202 [==============================] - 0s 102us/step - loss: 0.3379 - acc: 0.8713\n",
            "Epoch 17/20\n",
            "202/202 [==============================] - 0s 106us/step - loss: 0.3369 - acc: 0.8713\n",
            "Epoch 18/20\n",
            "202/202 [==============================] - 0s 111us/step - loss: 0.3338 - acc: 0.8713\n",
            "Epoch 19/20\n",
            "202/202 [==============================] - 0s 145us/step - loss: 0.3330 - acc: 0.8713\n",
            "Epoch 20/20\n",
            "202/202 [==============================] - 0s 129us/step - loss: 0.3323 - acc: 0.8663\n",
            "101/101 [==============================] - 2s 23ms/step\n",
            "Epoch 1/20\n",
            "202/202 [==============================] - 6s 27ms/step - loss: 0.8784 - acc: 0.5644\n",
            "Epoch 2/20\n",
            "202/202 [==============================] - 0s 100us/step - loss: 0.6456 - acc: 0.6832\n",
            "Epoch 3/20\n",
            "202/202 [==============================] - 0s 105us/step - loss: 0.4543 - acc: 0.7772\n",
            "Epoch 4/20\n",
            "202/202 [==============================] - 0s 115us/step - loss: 0.3631 - acc: 0.8416\n",
            "Epoch 5/20\n",
            "202/202 [==============================] - 0s 109us/step - loss: 0.3224 - acc: 0.8762\n",
            "Epoch 6/20\n",
            "202/202 [==============================] - 0s 106us/step - loss: 0.2931 - acc: 0.8762\n",
            "Epoch 7/20\n",
            "202/202 [==============================] - 0s 106us/step - loss: 0.2793 - acc: 0.8713\n",
            "Epoch 8/20\n",
            "202/202 [==============================] - 0s 111us/step - loss: 0.2716 - acc: 0.8762\n",
            "Epoch 9/20\n",
            "202/202 [==============================] - 0s 116us/step - loss: 0.2647 - acc: 0.8861\n",
            "Epoch 10/20\n",
            "202/202 [==============================] - 0s 110us/step - loss: 0.2589 - acc: 0.8861\n",
            "Epoch 11/20\n",
            "202/202 [==============================] - 0s 104us/step - loss: 0.2542 - acc: 0.8861\n",
            "Epoch 12/20\n",
            "202/202 [==============================] - 0s 108us/step - loss: 0.2506 - acc: 0.8911\n",
            "Epoch 13/20\n",
            "202/202 [==============================] - 0s 95us/step - loss: 0.2515 - acc: 0.8960\n",
            "Epoch 14/20\n",
            "202/202 [==============================] - 0s 117us/step - loss: 0.2510 - acc: 0.8911\n",
            "Epoch 15/20\n",
            "202/202 [==============================] - 0s 113us/step - loss: 0.2503 - acc: 0.8861\n",
            "Epoch 16/20\n",
            "202/202 [==============================] - 0s 113us/step - loss: 0.2493 - acc: 0.8911\n",
            "Epoch 17/20\n",
            "202/202 [==============================] - 0s 110us/step - loss: 0.2470 - acc: 0.8911\n",
            "Epoch 18/20\n",
            "202/202 [==============================] - 0s 127us/step - loss: 0.2442 - acc: 0.8911\n",
            "Epoch 19/20\n",
            "202/202 [==============================] - 0s 101us/step - loss: 0.2434 - acc: 0.8960\n",
            "Epoch 20/20\n",
            "202/202 [==============================] - 0s 123us/step - loss: 0.2432 - acc: 0.8960\n",
            "101/101 [==============================] - 2s 24ms/step\n",
            "Epoch 1/20\n",
            "303/303 [==============================] - 6s 19ms/step - loss: 0.8189 - acc: 0.6337\n",
            "Epoch 2/20\n",
            "303/303 [==============================] - 0s 82us/step - loss: 0.7392 - acc: 0.6733\n",
            "Epoch 3/20\n",
            "303/303 [==============================] - 0s 84us/step - loss: 0.6776 - acc: 0.6931\n",
            "Epoch 4/20\n",
            "303/303 [==============================] - 0s 87us/step - loss: 0.6300 - acc: 0.7063\n",
            "Epoch 5/20\n",
            "303/303 [==============================] - 0s 86us/step - loss: 0.5915 - acc: 0.7030\n",
            "Epoch 6/20\n",
            "303/303 [==============================] - 0s 85us/step - loss: 0.5612 - acc: 0.7261\n",
            "Epoch 7/20\n",
            "303/303 [==============================] - 0s 84us/step - loss: 0.5360 - acc: 0.7459\n",
            "Epoch 8/20\n",
            "303/303 [==============================] - 0s 84us/step - loss: 0.5148 - acc: 0.7591\n",
            "Epoch 9/20\n",
            "303/303 [==============================] - 0s 83us/step - loss: 0.4964 - acc: 0.7558\n",
            "Epoch 10/20\n",
            "303/303 [==============================] - 0s 87us/step - loss: 0.4808 - acc: 0.7789\n",
            "Epoch 11/20\n",
            "303/303 [==============================] - 0s 84us/step - loss: 0.4677 - acc: 0.7822\n",
            "Epoch 12/20\n",
            "303/303 [==============================] - 0s 86us/step - loss: 0.4571 - acc: 0.7888\n",
            "Epoch 13/20\n",
            "303/303 [==============================] - 0s 86us/step - loss: 0.4476 - acc: 0.7789\n",
            "Epoch 14/20\n",
            "303/303 [==============================] - 0s 85us/step - loss: 0.4391 - acc: 0.7888\n",
            "Epoch 15/20\n",
            "303/303 [==============================] - 0s 83us/step - loss: 0.4318 - acc: 0.7921\n",
            "Epoch 16/20\n",
            "303/303 [==============================] - 0s 94us/step - loss: 0.4254 - acc: 0.7987\n",
            "Epoch 17/20\n",
            "303/303 [==============================] - 0s 88us/step - loss: 0.4195 - acc: 0.8053\n",
            "Epoch 18/20\n",
            "303/303 [==============================] - 0s 85us/step - loss: 0.4144 - acc: 0.8086\n",
            "Epoch 19/20\n",
            "303/303 [==============================] - 0s 91us/step - loss: 0.4097 - acc: 0.8152\n",
            "Epoch 20/20\n",
            "303/303 [==============================] - 0s 88us/step - loss: 0.4057 - acc: 0.8185\n",
            "Best: 0.6996699868649146 using {'learn_rate': 0.01, 'momentum': 0.4}\n",
            "Means: 0.6501650215178827, Stdev: 0.03733897882922052 with: {'learn_rate': 0.01, 'momentum': 0.0}\n",
            "Means: 0.6534653453543635, Stdev: 0.07711763173808266 with: {'learn_rate': 0.01, 'momentum': 0.2}\n",
            "Means: 0.6996699868649146, Stdev: 0.061743514662106626 with: {'learn_rate': 0.01, 'momentum': 0.4}\n",
            "Means: 0.6930693162746555, Stdev: 0.09801480517779977 with: {'learn_rate': 0.01, 'momentum': 0.6}\n",
            "Means: 0.6666666666666666, Stdev: 0.0785173407382072 with: {'learn_rate': 0.01, 'momentum': 0.8}\n",
            "Means: 0.6930693074224805, Stdev: 0.06617141315646843 with: {'learn_rate': 0.01, 'momentum': 0.9}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5t-4_UNnY8-4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}