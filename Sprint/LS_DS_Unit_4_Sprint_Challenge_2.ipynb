{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2*\n",
    "\n",
    "# Sprint Challenge - Neural Network Foundations\n",
    "\n",
    "Table of Problems\n",
    "\n",
    "1. [Defining Neural Networks](#Q1)\n",
    "2. [Chocolate Gummy Bears](#Q2)\n",
    "    - Perceptron\n",
    "    - Multilayer Perceptron\n",
    "4. [Keras MMP](#Q3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Q1\"></a>\n",
    "## 1. Define the following terms:\n",
    "\n",
    "- **Neuron:** A neuron takes inputs and fires an output if the weighted sum of the input meets the activation threshold\n",
    "\n",
    "- **Input Layer:** Input layer is the layer of a neural network that directly interfaces with the input to the network.\n",
    "\n",
    "- **Hidden Layer:** Hidden layers are the layers of a neural network that neither the input or output have direct access to.\n",
    "\n",
    "- **Output Layer:** Output layer is the layer of a neural network that directly interfaces with the outputs of the network.\n",
    "\n",
    "- **Activation:** Activation is the function of a perceptron that takes weighted inputs of a perceptron and determines what should be the output. Common activation functions includes sigmoid, tanh, ReLU, leakyReLU, etc.\n",
    "\n",
    "- **Backpropagation:** Back propogation is one of the algorithms that is used to update the weights/parameters of neural networks. First, inputs are processed through a forward step and produce an output. That output is differenced against the expected target output. The differences are then back propogated to find attributions from weights and biases parameters. Update the parameters and go through the steps until it converges to a solution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Chocolate Gummy Bears <a id=\"Q2\"></a>\n",
    "\n",
    "Right now, you're probably thinking, \"yuck, who the hell would eat that?\". Great question. Your candy company wants to know too. And you thought I was kidding about the [Chocolate Gummy Bears](https://nuts.com/chocolatessweets/gummies/gummy-bears/milk-gummy-bears.html?utm_source=google&utm_medium=cpc&adpos=1o1&gclid=Cj0KCQjwrfvsBRD7ARIsAKuDvMOZrysDku3jGuWaDqf9TrV3x5JLXt1eqnVhN0KM6fMcbA1nod3h8AwaAvWwEALw_wcB). \n",
    "\n",
    "Let's assume that a candy company has gone out and collected information on the types of Halloween candy kids ate. Our candy company wants to predict the eating behavior of witches, warlocks, and ghosts -- aka costumed kids. They shared a sample dataset with us. Each row represents a piece of candy that a costumed child was presented with during \"trick\" or \"treat\". We know if the candy was `chocolate` (or not chocolate) or `gummy` (or not gummy). Your goal is to predict if the costumed kid `ate` the piece of candy. \n",
    "\n",
    "If both chocolate and gummy equal one, you've got a chocolate gummy bear on your hands!?!?!\n",
    "![Chocolate Gummy Bear](https://ed910ae2d60f0d25bcb8-80550f96b5feb12604f4f720bfefb46d.ssl.cf1.rackcdn.com/3fb630c04435b7b5-2leZuM7_-zoom.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "candy = pd.read_csv('chocolate_gummy_bears.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chocolate</th>\n",
       "      <th>gummy</th>\n",
       "      <th>ate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   chocolate  gummy  ate\n",
       "0          0      1    1\n",
       "1          1      0    1\n",
       "2          0      1    1\n",
       "3          0      0    0\n",
       "4          1      1    0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(candy.shape)\n",
    "candy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron\n",
    "\n",
    "To make predictions on the `candy` dataframe. Build and train a Perceptron using numpy. Your target column is `ate` and your features: `chocolate` and `gummy`. Do not do any feature engineering. :P\n",
    "\n",
    "Once you've trained your model, report your accuracy. Explain why you could not achieve a higher accuracy with a *simple perceptron*. It's possible to achieve ~95% accuracy on this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "# Start your candy perceptron here\n",
    "\n",
    "X = candy[['chocolate', 'gummy']].values\n",
    "y = candy['ate'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8000, 2), (2000, 2), (8000,), (2000,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42,\n",
    "                                                 )\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    sx = sigmoid(x)\n",
    "    return sx * (1-sx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = 2*np.random.random((2, 1)) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights after training\n",
      "[[-316.45971145]\n",
      " [-158.72278313]]\n",
      "output after training\n",
      "[[0.5]\n",
      " [1. ]\n",
      " [1. ]\n",
      " ...\n",
      " [1. ]\n",
      " [1. ]\n",
      " [0.5]]\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(10000):\n",
    "    \n",
    "    #weighted sum of inputs / weights\n",
    "    weighted_sum = np.dot(X_train, weights)\n",
    "    \n",
    "    #activate\n",
    "    activated_output = sigmoid(weighted_sum)\n",
    "    \n",
    "    #cac error\n",
    "    error = y_train - activated_output\n",
    "    \n",
    "    adjustments = error * sigmoid_derivative(activated_output)\n",
    "    \n",
    "    #update the weights\n",
    "    \n",
    "    weights += np.dot(X_train.T, adjustments)\n",
    "    \n",
    "print(\"weights after training\")\n",
    "print(weights)\n",
    "    \n",
    "print(\"output after training\")\n",
    "print(activated_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "activated_output[activated_output < .5] = 0\n",
    "activated_output[activated_output >= .5] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.5025\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy:\", accuracy_score(activated_output, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple perceptrons do not utilize feed forward and back propagation, which limits them to only learning linearly separable patterns. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer Perceptron <a id=\"Q3\"></a>\n",
    "\n",
    "Using the sample candy dataset, implement a Neural Network Multilayer Perceptron class that uses backpropagation to update the network's weights. Your Multilayer Perceptron should be implemented in Numpy. \n",
    "Your network must have one hidden layer.\n",
    "\n",
    "Once you've trained your model, report your accuracy. Explain why your MLP's performance is considerably better than your simple perceptron's on the candy dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork: \n",
    "    def __init__(self):\n",
    "        # Set up Architecture \n",
    "        self.inputs = 2\n",
    "        self.hiddenNodes = 8\n",
    "        self.outputNodes = 1\n",
    "        \n",
    "        #Initial weights\n",
    "        self.weights1 = np.random.randn(self.inputs, self.hiddenNodes)\n",
    "        self.weights2 = np.random.randn(self.hiddenNodes, self.outputNodes)\n",
    "    \n",
    "    def sigmoid(self, s):\n",
    "        return 1 / (1+np.exp(-s))\n",
    "    \n",
    "    def sigmoidPrime(self, s):\n",
    "        return np.exp(-s)/((1+np.exp(-s))**2)\n",
    "    \n",
    "    def feed_forward(self, X):\n",
    "        \"\"\"\n",
    "        Calculate the NN inference using feed forward.\n",
    "        \"\"\"\n",
    "        \n",
    "        #Weighted sume of inputs and hidden layer\n",
    "        self.h2 = np.dot(X, self.weights1)\n",
    "        \n",
    "        #Acivations of weighted sum\n",
    "        self.a2 = self.sigmoid(self.h2)\n",
    "        \n",
    "        # Weight sum between hidden and output\n",
    "        self.h3 = np.dot(self.a2, self.weights2)\n",
    "        \n",
    "        #Final activation of output\n",
    "        self.a3 = self.sigmoid(self.h3)\n",
    "        \n",
    "        return self.a3\n",
    "    \n",
    "    def backward(self, X, y, o, learning_rate=0.1):\n",
    "        \"\"\"\n",
    "        Backward propagate through the network\n",
    "        \"\"\"\n",
    "        self.o_error = y - o #error in output\n",
    "        self.o_delta = learning_rate*(self.o_error * self.sigmoidPrime(o)) # apply derivative of sigmoid to error\n",
    "        \n",
    "        self.z2_error = self.o_delta.dot(self.weights2.T) # z2 error: how much our hidden layer weights were off\n",
    "        self.z2_delta = self.z2_error*self.sigmoidPrime(self.a2)\n",
    "        \n",
    "        self.weights1 += X.T.dot(self.z2_delta) #Adjust first set (input => hidden) weights\n",
    "        self.weights2 += self.a2.T.dot(self.o_delta) #adjust second set (hidden => output) weights\n",
    "        \n",
    "    def train(self, X, y, learning_rate=0.01):\n",
    "        for _ in range(10000):\n",
    "            o = self.feed_forward(X)\n",
    "            self.backward(X, y, o, learning_rate=learning_rate)\n",
    "        self.loss = np.mean(np.square(y-self.feed_forward(X)))\n",
    "        print(\"Loss: \" + str(self.loss))\n",
    "        \n",
    "    def predict(self, X, y):\n",
    "        preds = self.feed_forward(X)\n",
    "        \n",
    "        preds[preds < .5] = 0\n",
    "        preds[preds >= .5] = 1\n",
    "        \n",
    "        print(\"Accuracy:\", accuracy_score(y, preds))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.reshape(-1,1)\n",
    "y_test = y_test.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.20073220120943674\n",
      "Accuracy: 0.946\n"
     ]
    }
   ],
   "source": [
    "nn = NeuralNetwork()\n",
    "\n",
    "nn.train(X_train, y_train)\n",
    "\n",
    "nn.predict(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With backpropagation, the weights are updated in reverse order to minimize loss. Combining weights into the input contributes to the output, so minimizing the error associated with weights helps with better accuracy. They can also account for non-linear patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P.S. Don't try candy gummy bears. They're disgusting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Keras MMP <a id=\"Q3\"></a>\n",
    "\n",
    "Implement a Multilayer Perceptron architecture of your choosing using the Keras library. Train your model and report its baseline accuracy. Then hyperparameter tune at least two parameters and report your model's accuracy.\n",
    "Use the Heart Disease Dataset (binary classification)\n",
    "Use an appropriate loss function for a binary classification task\n",
    "Use an appropriate activation function on the final layer of your network.\n",
    "Train your model using verbose output for ease of grading.\n",
    "Use GridSearchCV or RandomSearchCV to hyperparameter tune your model. (for at least two hyperparameters)\n",
    "When hyperparameter tuning, show you work by adding code cells for each new experiment.\n",
    "Report the accuracy for each combination of hyperparameters as you test them so that we can easily see which resulted in the highest accuracy.\n",
    "You must hyperparameter tune at least 3 parameters in order to get a 3 on this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(303, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>191</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>216</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>131</td>\n",
       "      <td>1</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>124</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>94</td>\n",
       "      <td>199</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>179</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>262</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "      <td>294</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>153</td>\n",
       "      <td>0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>212</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>157</td>\n",
       "      <td>0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "191   58    1   0       128   216    0        0      131      1      2.2   \n",
       "124   39    0   2        94   199    0        1      179      0      0.0   \n",
       "114   55    1   1       130   262    0        1      155      0      0.0   \n",
       "6     56    0   1       140   294    0        0      153      0      1.3   \n",
       "26    59    1   2       150   212    1        1      157      0      1.6   \n",
       "\n",
       "     slope  ca  thal  target  \n",
       "191      1   3     3       0  \n",
       "124      2   0     2       1  \n",
       "114      2   0     2       1  \n",
       "6        1   0     2       1  \n",
       "26       2   0     2       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/ryanleeallred/datasets/master/heart.csv')\n",
    "df = df.sample(frac=1)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(242, 13) (61, 13) (242,) (61,)\n"
     ]
    }
   ],
   "source": [
    "# Scale values\n",
    "x = df.values \n",
    "min_max_scaler = StandardScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "\n",
    "# Split values into x and y components\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_scaled[:, :-1], x_scaled[:, -1], test_size=0.2)\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 13)]              0         \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 1)                 14        \n",
      "=================================================================\n",
      "Total params: 14\n",
      "Trainable params: 14\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Baseline Model\n",
    "inputs = Input(shape=(X_train.shape[1],))\n",
    "x = Dense(64, activation='relu')(inputs)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "predictions = Dense(1, activation='sigmoid')(inputs)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "model.compile(optimizer='adam',\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, validation_split=0.20, epochs=10, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test, verbose=False)\n",
    "print(f'{model.metrics_names[1]}: {scores[1]*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper right')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.8595041300147033 using {'batch_size': 32, 'epochs': 80}\n",
      "Means: 0.8512396736085908, Stdev: 0.03459863708372117 with: {'batch_size': 16, 'epochs': 20}\n",
      "Means: 0.8388429744677111, Stdev: 0.027400996599243277 with: {'batch_size': 16, 'epochs': 80}\n",
      "Means: 0.8305785104262927, Stdev: 0.030188114360189464 with: {'batch_size': 32, 'epochs': 20}\n",
      "Means: 0.8595041300147033, Stdev: 0.03201150516339827 with: {'batch_size': 32, 'epochs': 80}\n",
      "Means: 0.8512396721307897, Stdev: 0.03587449853312993 with: {'batch_size': 64, 'epochs': 20}\n",
      "Means: 0.8512396750863919, Stdev: 0.009387370432712922 with: {'batch_size': 64, 'epochs': 80}\n"
     ]
    }
   ],
   "source": [
    "inputs = X_train.shape[1]\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, activation='relu', input_shape=(inputs,)))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "\n",
    "batch_size = [16, 32, 64]\n",
    "epochs = [20, 80]\n",
    "\n",
    "# define the grid search parameters\n",
    "param_grid = dict(\n",
    "                  batch_size=batch_size,\n",
    "                  epochs=epochs\n",
    "                )\n",
    "\n",
    "# Create Grid Search\n",
    "grid = GridSearchCV(estimator=model, \n",
    "                    param_grid=param_grid, \n",
    "                    cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# Report Results\n",
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'batch_size': 32, 'epochs': 80}, Best score: 0.8595041300147033\n"
     ]
    }
   ],
   "source": [
    "print(f'Best params: {grid_result.best_params_}, Best score: {grid_result.best_score_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stretch Goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.8636363818625773 using {'init_mode': 'he_normal', 'momentum': 0.2, 'optimizer': 'Adamax'}\n",
      "Means: 0.847107446144435, Stdev: 0.01479978983247294 with: {'init_mode': 'normal', 'momentum': 0.0, 'optimizer': 'SGD'}\n",
      "Means: 0.851239676564193, Stdev: 0.01013852353280649 with: {'init_mode': 'normal', 'momentum': 0.0, 'optimizer': 'RMSprop'}\n",
      "Means: 0.8595041529206205, Stdev: 0.00547172314189714 with: {'init_mode': 'normal', 'momentum': 0.0, 'optimizer': 'Adagrad'}\n",
      "Means: 0.8471074446666339, Stdev: 0.04042360178874821 with: {'init_mode': 'normal', 'momentum': 0.0, 'optimizer': 'Adadelta'}\n",
      "Means: 0.8512396750863919, Stdev: 0.009387370432712922 with: {'init_mode': 'normal', 'momentum': 0.0, 'optimizer': 'Adam'}\n",
      "Means: 0.83884297298991, Stdev: 0.018005557528859278 with: {'init_mode': 'normal', 'momentum': 0.0, 'optimizer': 'Adamax'}\n",
      "Means: 0.8429752004540656, Stdev: 0.015632429986491916 with: {'init_mode': 'normal', 'momentum': 0.0, 'optimizer': 'Nadam'}\n",
      "Means: 0.8305785165837973, Stdev: 0.016230516651746664 with: {'init_mode': 'normal', 'momentum': 0.2, 'optimizer': 'SGD'}\n",
      "Means: 0.8305784951556813, Stdev: 0.006393382851959231 with: {'init_mode': 'normal', 'momentum': 0.2, 'optimizer': 'RMSprop'}\n",
      "Means: 0.8429752048874689, Stdev: 0.036333941560210824 with: {'init_mode': 'normal', 'momentum': 0.2, 'optimizer': 'Adagrad'}\n",
      "Means: 0.834710742570152, Stdev: 0.015277786653167662 with: {'init_mode': 'normal', 'momentum': 0.2, 'optimizer': 'Adadelta'}\n",
      "Means: 0.8264462676915255, Stdev: 0.01102525078263853 with: {'init_mode': 'normal', 'momentum': 0.2, 'optimizer': 'Adam'}\n",
      "Means: 0.8512396736085908, Stdev: 0.019514672310923034 with: {'init_mode': 'normal', 'momentum': 0.2, 'optimizer': 'Adamax'}\n",
      "Means: 0.8305784951556813, Stdev: 0.006393382851959231 with: {'init_mode': 'normal', 'momentum': 0.2, 'optimizer': 'Nadam'}\n",
      "Means: 0.8388429715121088, Stdev: 0.02022406496297069 with: {'init_mode': 'normal', 'momentum': 0.4, 'optimizer': 'SGD'}\n",
      "Means: 0.8553718872799361, Stdev: 0.023787666666076127 with: {'init_mode': 'normal', 'momentum': 0.4, 'optimizer': 'RMSprop'}\n",
      "Means: 0.8471074476222361, Stdev: 0.0054442325098005805 with: {'init_mode': 'normal', 'momentum': 0.4, 'optimizer': 'Adagrad'}\n",
      "Means: 0.8223140372717677, Stdev: 0.005391679127638451 with: {'init_mode': 'normal', 'momentum': 0.4, 'optimizer': 'Adadelta'}\n",
      "Means: 0.8595041329703055, Stdev: 0.03541616775493025 with: {'init_mode': 'normal', 'momentum': 0.4, 'optimizer': 'Adam'}\n",
      "Means: 0.851239676564193, Stdev: 0.02022080617380072 with: {'init_mode': 'normal', 'momentum': 0.4, 'optimizer': 'Adamax'}\n",
      "Means: 0.8305785119040938, Stdev: 0.020392090028223356 with: {'init_mode': 'normal', 'momentum': 0.4, 'optimizer': 'Nadam'}\n",
      "Means: 0.8223140586998837, Stdev: 0.03107792401540163 with: {'init_mode': 'normal', 'momentum': 0.6, 'optimizer': 'SGD'}\n",
      "Means: 0.8181818297579269, Stdev: 0.025566243734596827 with: {'init_mode': 'normal', 'momentum': 0.6, 'optimizer': 'RMSprop'}\n",
      "Means: 0.8512396750863919, Stdev: 0.009387370432712922 with: {'init_mode': 'normal', 'momentum': 0.6, 'optimizer': 'Adagrad'}\n",
      "Means: 0.8388429697880075, Stdev: 0.00932625885713924 with: {'init_mode': 'normal', 'momentum': 0.6, 'optimizer': 'Adadelta'}\n",
      "Means: 0.8471074431888328, Stdev: 0.03484005764288235 with: {'init_mode': 'normal', 'momentum': 0.6, 'optimizer': 'Adam'}\n",
      "Means: 0.8429752004540656, Stdev: 0.006349158040279714 with: {'init_mode': 'normal', 'momentum': 0.6, 'optimizer': 'Adamax'}\n",
      "Means: 0.8429752172024783, Stdev: 0.03792266216147917 with: {'init_mode': 'normal', 'momentum': 0.6, 'optimizer': 'Nadam'}\n",
      "Means: 0.8347107440479531, Stdev: 0.02132344762051113 with: {'init_mode': 'normal', 'momentum': 0.8, 'optimizer': 'SGD'}\n",
      "Means: 0.8595041314925044, Stdev: 0.014852929415775606 with: {'init_mode': 'normal', 'momentum': 0.8, 'optimizer': 'RMSprop'}\n",
      "Means: 0.8429752172024783, Stdev: 0.028739278213404523 with: {'init_mode': 'normal', 'momentum': 0.8, 'optimizer': 'Adagrad'}\n",
      "Means: 0.8388429715121088, Stdev: 0.010145021475251405 with: {'init_mode': 'normal', 'momentum': 0.8, 'optimizer': 'Adadelta'}\n",
      "Means: 0.8595041329703055, Stdev: 0.025340140987357294 with: {'init_mode': 'normal', 'momentum': 0.8, 'optimizer': 'Adam'}\n",
      "Means: 0.8595041314925044, Stdev: 0.02294996416387526 with: {'init_mode': 'normal', 'momentum': 0.8, 'optimizer': 'Adamax'}\n",
      "Means: 0.8347107593185645, Stdev: 0.03192248194705029 with: {'init_mode': 'normal', 'momentum': 0.8, 'optimizer': 'Nadam'}\n",
      "Means: 0.8553719072302511, Stdev: 0.012559112971866536 with: {'init_mode': 'normal', 'momentum': 0.9, 'optimizer': 'SGD'}\n",
      "Means: 0.8305785151059962, Stdev: 0.025555007069023375 with: {'init_mode': 'normal', 'momentum': 0.9, 'optimizer': 'RMSprop'}\n",
      "Means: 0.8429752186802794, Stdev: 0.02079642868653285 with: {'init_mode': 'normal', 'momentum': 0.9, 'optimizer': 'Adagrad'}\n",
      "Means: 0.842975215724677, Stdev: 0.03024210211114016 with: {'init_mode': 'normal', 'momentum': 0.9, 'optimizer': 'Adadelta'}\n",
      "Means: 0.8471074476222361, Stdev: 0.015287273369796612 with: {'init_mode': 'normal', 'momentum': 0.9, 'optimizer': 'Adam'}\n",
      "Means: 0.8388429744677111, Stdev: 0.021088463000858912 with: {'init_mode': 'normal', 'momentum': 0.9, 'optimizer': 'Adamax'}\n",
      "Means: 0.8347107455257542, Stdev: 0.021752754239875414 with: {'init_mode': 'normal', 'momentum': 0.9, 'optimizer': 'Nadam'}\n",
      "Means: 0.8388429882605214, Stdev: 0.026162852369242137 with: {'init_mode': 'he_normal', 'momentum': 0.0, 'optimizer': 'SGD'}\n",
      "Means: 0.8471074446666339, Stdev: 0.031966942118211286 with: {'init_mode': 'he_normal', 'momentum': 0.0, 'optimizer': 'RMSprop'}\n",
      "Means: 0.8595041300147033, Stdev: 0.02483173043712629 with: {'init_mode': 'he_normal', 'momentum': 0.0, 'optimizer': 'Adagrad'}\n",
      "Means: 0.8223140402273699, Stdev: 0.01647397783782909 with: {'init_mode': 'he_normal', 'momentum': 0.0, 'optimizer': 'Adadelta'}\n",
      "Means: 0.8595041529206205, Stdev: 0.00547172314189714 with: {'init_mode': 'he_normal', 'momentum': 0.0, 'optimizer': 'Adam'}\n",
      "Means: 0.8305785136281951, Stdev: 0.020779309918272926 with: {'init_mode': 'he_normal', 'momentum': 0.0, 'optimizer': 'Adamax'}\n",
      "Means: 0.8223140402273699, Stdev: 0.01647397783782909 with: {'init_mode': 'he_normal', 'momentum': 0.0, 'optimizer': 'Nadam'}\n",
      "Means: 0.8429751972521632, Stdev: 0.014620655418194592 with: {'init_mode': 'he_normal', 'momentum': 0.2, 'optimizer': 'SGD'}\n",
      "Means: 0.8636363803847762, Stdev: 0.009448618208374795 with: {'init_mode': 'he_normal', 'momentum': 0.2, 'optimizer': 'RMSprop'}\n",
      "Means: 0.8305785136281951, Stdev: 0.020779309918272926 with: {'init_mode': 'he_normal', 'momentum': 0.2, 'optimizer': 'Adagrad'}\n",
      "Means: 0.8512396782882943, Stdev: 0.010896420198480722 with: {'init_mode': 'he_normal', 'momentum': 0.2, 'optimizer': 'Adadelta'}\n",
      "Means: 0.8305785165837973, Stdev: 0.023864639399659326 with: {'init_mode': 'he_normal', 'momentum': 0.2, 'optimizer': 'Adam'}\n",
      "Means: 0.8636363818625773, Stdev: 0.0007985593955914432 with: {'init_mode': 'he_normal', 'momentum': 0.2, 'optimizer': 'Adamax'}\n",
      "Means: 0.8429752004540656, Stdev: 0.006349158040279714 with: {'init_mode': 'he_normal', 'momentum': 0.2, 'optimizer': 'Nadam'}\n",
      "Means: 0.8553719040283487, Stdev: 0.011274843484554807 with: {'init_mode': 'he_normal', 'momentum': 0.4, 'optimizer': 'SGD'}\n",
      "Means: 0.8305785136281951, Stdev: 0.020779309918272926 with: {'init_mode': 'he_normal', 'momentum': 0.4, 'optimizer': 'RMSprop'}\n",
      "Means: 0.8553719040283487, Stdev: 0.0407133617485315 with: {'init_mode': 'he_normal', 'momentum': 0.4, 'optimizer': 'Adagrad'}\n",
      "Means: 0.8512396736085908, Stdev: 0.019514672310923034 with: {'init_mode': 'he_normal', 'momentum': 0.4, 'optimizer': 'Adadelta'}\n",
      "Means: 0.8347107607963656, Stdev: 0.022881431960035996 with: {'init_mode': 'he_normal', 'momentum': 0.4, 'optimizer': 'Adam'}\n",
      "Means: 0.8553719055061498, Stdev: 0.02553313394253581 with: {'init_mode': 'he_normal', 'momentum': 0.4, 'optimizer': 'Adamax'}\n",
      "Means: 0.8512396782882943, Stdev: 0.010896420198480722 with: {'init_mode': 'he_normal', 'momentum': 0.4, 'optimizer': 'Nadam'}\n",
      "Means: 0.8595041329703055, Stdev: 0.025340140987357294 with: {'init_mode': 'he_normal', 'momentum': 0.6, 'optimizer': 'SGD'}\n",
      "Means: 0.8512396782882943, Stdev: 0.010896420198480722 with: {'init_mode': 'he_normal', 'momentum': 0.6, 'optimizer': 'RMSprop'}\n",
      "Means: 0.8429752004540656, Stdev: 0.025543971766480274 with: {'init_mode': 'he_normal', 'momentum': 0.6, 'optimizer': 'Adagrad'}\n",
      "Means: 0.8264462876418406, Stdev: 0.018044881140658397 with: {'init_mode': 'he_normal', 'momentum': 0.6, 'optimizer': 'Adadelta'}\n",
      "Means: 0.8388429697880075, Stdev: 0.00932625885713924 with: {'init_mode': 'he_normal', 'momentum': 0.6, 'optimizer': 'Adam'}\n",
      "Means: 0.8471074476222361, Stdev: 0.0054442325098005805 with: {'init_mode': 'he_normal', 'momentum': 0.6, 'optimizer': 'Adamax'}\n",
      "Means: 0.8429752172024783, Stdev: 0.020440755512047444 with: {'init_mode': 'he_normal', 'momentum': 0.6, 'optimizer': 'Nadam'}\n",
      "Means: 0.8512396750863919, Stdev: 0.026463284176898107 with: {'init_mode': 'he_normal', 'momentum': 0.8, 'optimizer': 'SGD'}\n",
      "Means: 0.8305785151059962, Stdev: 0.025555007069023375 with: {'init_mode': 'he_normal', 'momentum': 0.8, 'optimizer': 'RMSprop'}\n",
      "Means: 0.8553719025505476, Stdev: 0.02877400642768289 with: {'init_mode': 'he_normal', 'momentum': 0.8, 'optimizer': 'Adagrad'}\n",
      "Means: 0.8553719254564648, Stdev: 0.006305402658703168 with: {'init_mode': 'he_normal', 'momentum': 0.8, 'optimizer': 'Adadelta'}\n",
      "Means: 0.8553719239786637, Stdev: 0.005009109613231354 with: {'init_mode': 'he_normal', 'momentum': 0.8, 'optimizer': 'Adam'}\n",
      "Means: 0.8636363604344612, Stdev: 0.017127110547886158 with: {'init_mode': 'he_normal', 'momentum': 0.8, 'optimizer': 'Adamax'}\n",
      "Means: 0.83884297298991, Stdev: 0.010960795703913924 with: {'init_mode': 'he_normal', 'momentum': 0.8, 'optimizer': 'Nadam'}\n",
      "Means: 0.8553719040283487, Stdev: 0.011274843484554807 with: {'init_mode': 'he_normal', 'momentum': 0.9, 'optimizer': 'SGD'}\n",
      "Means: 0.8512396583379793, Stdev: 0.017966441166171916 with: {'init_mode': 'he_normal', 'momentum': 0.9, 'optimizer': 'RMSprop'}\n",
      "Means: 0.834710742570152, Stdev: 0.015277786653167662 with: {'init_mode': 'he_normal', 'momentum': 0.9, 'optimizer': 'Adagrad'}\n",
      "Means: 0.8388429683102064, Stdev: 0.019452595578469272 with: {'init_mode': 'he_normal', 'momentum': 0.9, 'optimizer': 'Adadelta'}\n",
      "Means: 0.8388429744677111, Stdev: 0.021088463000858912 with: {'init_mode': 'he_normal', 'momentum': 0.9, 'optimizer': 'Adam'}\n",
      "Means: 0.8388429897383225, Stdev: 0.01705990006402624 with: {'init_mode': 'he_normal', 'momentum': 0.9, 'optimizer': 'Adamax'}\n",
      "Means: 0.851239676564193, Stdev: 0.01013852353280649 with: {'init_mode': 'he_normal', 'momentum': 0.9, 'optimizer': 'Nadam'}\n"
     ]
    }
   ],
   "source": [
    "# Incorporating best params into model\n",
    "def create_model(init_mode, momentum, optimizer):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, activation='relu', input_shape=(inputs,)))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, batch_size=32, epochs=80, verbose=0)\n",
    "\n",
    "# Fine-tuning 3 more parameters\n",
    "init_mode = ['normal', 'he_normal']\n",
    "momentum = [0.0, 0.2, 0.4, 0.6, 0.8, 0.9]\n",
    "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "\n",
    "\n",
    "# define the grid search parameters\n",
    "param_grid = dict(\n",
    "                  init_mode=init_mode,\n",
    "                  momentum=momentum,\n",
    "                  optimizer=optimizer\n",
    "                )\n",
    "\n",
    "# Create Grid Search\n",
    "grid = GridSearchCV(estimator=model, \n",
    "                    param_grid=param_grid, \n",
    "                    cv=3)\n",
    "\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# Report Results\n",
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'init_mode': 'he_normal', 'momentum': 0.2, 'optimizer': 'Adamax'}, Best score: 0.8636363818625773\n"
     ]
    }
   ],
   "source": [
    "print(f'Best params: {grid_result.best_params_}, Best score: {grid_result.best_score_}')"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "nteract": {
   "version": "0.15.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
