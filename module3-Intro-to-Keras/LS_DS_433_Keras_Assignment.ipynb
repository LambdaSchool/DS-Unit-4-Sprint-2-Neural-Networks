{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pBQsZEJmubLs"
   },
   "source": [
    "# Use the Keras Library to build a Multi-Layer Perceptron Model on the Boston Housing dataset\n",
    "\n",
    "- The Boston Housing dataset comes with the Keras library so use Keras to import it into your notebook. \n",
    "- Normalize the data (all features should have roughly the same scale)\n",
    "- Import the type of model and layers that you will need from Keras.\n",
    "- Instantiate a model object and use `model.add()` to add layers to your model\n",
    "- Since this is a regression model you will have a single output node in the final layer.\n",
    "- Use activation functions that are appropriate for this task\n",
    "- Compile your model\n",
    "- Fit your model and report its accuracy in terms of Mean Squared Error\n",
    "- Use the history object that is returned from model.fit to make graphs of the model's loss or train/validation accuracies by epoch. \n",
    "- Run this same data through a linear regression model. Which achieves higher accuracy?\n",
    "- Do a little bit of feature engineering and see how that affects your neural network model. (you will need to change your model to accept more inputs)\n",
    "- After feature engineering, which model sees a greater accuracy boost due to the new features?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-09T03:26:59.478020Z",
     "start_time": "2019-05-09T03:26:59.424066Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "8NLTAR87uYJ-"
   },
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/api_docs/python/tf/keras/utils/normalize\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.datasets import boston_housing\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = boston_housing.load_data()\n",
    "\n",
    "x_train = keras.utils.normalize(x_train, axis=-1, order=2)\n",
    "x_test = keras.utils.normalize(x_test, axis=-1, order=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-09T03:27:59.899245Z",
     "start_time": "2019-05-09T03:27:59.884635Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[2.41189924e-03, 0.00000000e+00, 1.59296858e-02, ...,\n",
       "         4.10962409e-02, 7.76718953e-01, 3.66343633e-02],\n",
       "        [4.07923050e-05, 1.54587284e-01, 3.80378407e-03, ...,\n",
       "         2.75446433e-02, 7.40857215e-01, 5.82747215e-03],\n",
       "        [6.34505528e-03, 0.00000000e+00, 2.34463745e-02, ...,\n",
       "         2.61666721e-02, 4.86441025e-01, 4.22293817e-03],\n",
       "        ...,\n",
       "        [7.29281484e-05, 7.36435428e-02, 1.27508534e-02, ...,\n",
       "         3.55593107e-02, 7.62210668e-01, 1.64751126e-02],\n",
       "        [4.37205159e-03, 0.00000000e+00, 3.98313637e-02, ...,\n",
       "         2.99040371e-02, 5.32881804e-01, 3.21214113e-02],\n",
       "        [3.09311543e-05, 1.28969372e-01, 6.29800433e-03, ...,\n",
       "         3.35320367e-02, 8.09712706e-01, 9.41476414e-03]]),\n",
       " array([[2.67567471e-02, 0.00000000e+00, 2.67795319e-02, ...,\n",
       "         2.98865495e-02, 4.03172511e-02, 4.29804090e-02],\n",
       "        [2.07806276e-04, 0.00000000e+00, 1.68719346e-02, ...,\n",
       "         3.00020416e-02, 6.65691367e-01, 2.73220840e-02],\n",
       "        [1.19845746e-04, 0.00000000e+00, 1.13152524e-02, ...,\n",
       "         4.40400960e-02, 8.65322480e-01, 2.12351750e-02],\n",
       "        ...,\n",
       "        [3.21889389e-03, 0.00000000e+00, 3.43696005e-02, ...,\n",
       "         2.58035305e-02, 6.83898879e-01, 3.37025704e-03],\n",
       "        [7.07644197e-04, 0.00000000e+00, 1.22522104e-02, ...,\n",
       "         3.43852356e-02, 7.74063034e-01, 1.91885424e-02],\n",
       "        [6.10350794e-03, 0.00000000e+00, 4.08709594e-02, ...,\n",
       "         3.06845303e-02, 5.01305905e-01, 2.04772274e-02]]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the type of model and layers that you will need from Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-09T03:37:47.486480Z",
     "start_time": "2019-05-09T03:37:47.304251Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 15)                210       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                160       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 431\n",
      "Trainable params: 431\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(15, activation='relu', input_shape=(13,)))\n",
    "model.add(Dense(10, activation='sigmoid'))\n",
    "model.add(Dense(5, activation='linear'))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "model.compile(loss='mean_squared_error', optimizer='sgd', metrics=['mean_squared_error'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-09T03:38:07.436285Z",
     "start_time": "2019-05-09T03:37:58.457036Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 303 samples, validate on 101 samples\n",
      "Epoch 1/100\n",
      "303/303 [==============================] - 1s 5ms/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 2/100\n",
      "303/303 [==============================] - 0s 263us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 3/100\n",
      "303/303 [==============================] - 0s 164us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 4/100\n",
      "303/303 [==============================] - 0s 270us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 5/100\n",
      "303/303 [==============================] - 0s 175us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 6/100\n",
      "303/303 [==============================] - 0s 177us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 7/100\n",
      "303/303 [==============================] - 0s 305us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 8/100\n",
      "303/303 [==============================] - 0s 209us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 9/100\n",
      "303/303 [==============================] - 0s 317us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 10/100\n",
      "303/303 [==============================] - 0s 174us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 11/100\n",
      "303/303 [==============================] - 0s 248us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 12/100\n",
      "303/303 [==============================] - 0s 126us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 13/100\n",
      "303/303 [==============================] - 0s 409us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 14/100\n",
      "303/303 [==============================] - 0s 217us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 15/100\n",
      "303/303 [==============================] - 0s 209us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 16/100\n",
      "303/303 [==============================] - 0s 344us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 17/100\n",
      "303/303 [==============================] - 0s 110us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 18/100\n",
      "303/303 [==============================] - 0s 197us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 19/100\n",
      "303/303 [==============================] - 0s 201us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 20/100\n",
      "303/303 [==============================] - 0s 308us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 21/100\n",
      "303/303 [==============================] - 0s 171us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 22/100\n",
      "303/303 [==============================] - 0s 180us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 23/100\n",
      "303/303 [==============================] - 0s 232us/step - loss: 551.3301 - mean_squared_error: 551.3301 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 24/100\n",
      "303/303 [==============================] - 0s 202us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 25/100\n",
      "303/303 [==============================] - 0s 266us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 26/100\n",
      "303/303 [==============================] - 0s 207us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 27/100\n",
      "303/303 [==============================] - 0s 300us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 28/100\n",
      "303/303 [==============================] - 0s 207us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 29/100\n",
      "303/303 [==============================] - 0s 209us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 30/100\n",
      "303/303 [==============================] - 0s 300us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 31/100\n",
      "303/303 [==============================] - 0s 186us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 32/100\n",
      "303/303 [==============================] - 0s 245us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 33/100\n",
      "303/303 [==============================] - 0s 154us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 34/100\n",
      "303/303 [==============================] - 0s 158us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 35/100\n",
      "303/303 [==============================] - 0s 317us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 36/100\n",
      "303/303 [==============================] - 0s 181us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 37/100\n",
      "303/303 [==============================] - 0s 364us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 38/100\n",
      "303/303 [==============================] - 0s 178us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 39/100\n",
      "303/303 [==============================] - 0s 168us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 40/100\n",
      "303/303 [==============================] - 0s 178us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 41/100\n",
      "303/303 [==============================] - 0s 185us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 42/100\n",
      "303/303 [==============================] - 0s 277us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 43/100\n",
      "303/303 [==============================] - 0s 185us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 44/100\n",
      "303/303 [==============================] - 0s 108us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 45/100\n",
      "303/303 [==============================] - 0s 136us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 46/100\n",
      "303/303 [==============================] - 0s 167us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 47/100\n",
      "303/303 [==============================] - 0s 285us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/100\n",
      "303/303 [==============================] - 0s 303us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 49/100\n",
      "303/303 [==============================] - 0s 197us/step - loss: 551.3301 - mean_squared_error: 551.3301 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 50/100\n",
      "303/303 [==============================] - 0s 278us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 51/100\n",
      "303/303 [==============================] - 0s 259us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 52/100\n",
      "303/303 [==============================] - 0s 220us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 53/100\n",
      "303/303 [==============================] - 0s 302us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 54/100\n",
      "303/303 [==============================] - 0s 192us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 55/100\n",
      "303/303 [==============================] - 0s 188us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 56/100\n",
      "303/303 [==============================] - 0s 317us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 57/100\n",
      "303/303 [==============================] - 0s 206us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 58/100\n",
      "303/303 [==============================] - 0s 251us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 59/100\n",
      "303/303 [==============================] - 0s 210us/step - loss: 551.3301 - mean_squared_error: 551.3301 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 60/100\n",
      "303/303 [==============================] - 0s 180us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 61/100\n",
      "303/303 [==============================] - 0s 248us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 62/100\n",
      "303/303 [==============================] - 0s 216us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 63/100\n",
      "303/303 [==============================] - 0s 289us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 64/100\n",
      "303/303 [==============================] - 0s 265us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 65/100\n",
      "303/303 [==============================] - 0s 121us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 66/100\n",
      "303/303 [==============================] - 0s 255us/step - loss: 551.3301 - mean_squared_error: 551.3301 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 67/100\n",
      "303/303 [==============================] - 0s 270us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 68/100\n",
      "303/303 [==============================] - 0s 122us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 69/100\n",
      "303/303 [==============================] - 0s 189us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 70/100\n",
      "303/303 [==============================] - 0s 192us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 71/100\n",
      "303/303 [==============================] - 0s 194us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 72/100\n",
      "303/303 [==============================] - 0s 311us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 73/100\n",
      "303/303 [==============================] - 0s 214us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 74/100\n",
      "303/303 [==============================] - 0s 202us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 75/100\n",
      "303/303 [==============================] - 0s 251us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 76/100\n",
      "303/303 [==============================] - 0s 171us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 77/100\n",
      "303/303 [==============================] - 0s 274us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 78/100\n",
      "303/303 [==============================] - 0s 174us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 79/100\n",
      "303/303 [==============================] - 0s 173us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 80/100\n",
      "303/303 [==============================] - 0s 189us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 81/100\n",
      "303/303 [==============================] - 0s 199us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 82/100\n",
      "303/303 [==============================] - 0s 204us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 83/100\n",
      "303/303 [==============================] - 0s 218us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 84/100\n",
      "303/303 [==============================] - 0s 272us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 85/100\n",
      "303/303 [==============================] - 0s 181us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 86/100\n",
      "303/303 [==============================] - 0s 157us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 87/100\n",
      "303/303 [==============================] - 0s 232us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 88/100\n",
      "303/303 [==============================] - 0s 327us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 89/100\n",
      "303/303 [==============================] - 0s 235us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 90/100\n",
      "303/303 [==============================] - 0s 378us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 91/100\n",
      "303/303 [==============================] - 0s 265us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 92/100\n",
      "303/303 [==============================] - 0s 169us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 93/100\n",
      "303/303 [==============================] - 0s 263us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 94/100\n",
      "303/303 [==============================] - 0s 127us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 0s 124us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 96/100\n",
      "303/303 [==============================] - 0s 229us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 97/100\n",
      "303/303 [==============================] - 0s 227us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 98/100\n",
      "303/303 [==============================] - 0s 312us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 99/100\n",
      "303/303 [==============================] - 0s 226us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n",
      "Epoch 100/100\n",
      "303/303 [==============================] - 0s 202us/step - loss: 551.3300 - mean_squared_error: 551.3300 - val_loss: 690.6519 - val_mean_squared_error: 690.6519\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8c6beff668>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=100, validation_split=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit your model and report its accuracy in terms of Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-09T03:38:29.473245Z",
     "start_time": "2019-05-09T03:38:29.247804Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "model_dump = pickle.dumps(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-09T03:38:32.441341Z",
     "start_time": "2019-05-09T03:38:32.432532Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\x80\\x03ckeras.engine.sequential\\nSequential\\nq\\x00)\\x81q\\x01}q\\x02(X\\t\\x00\\x00\\x00_is_groupq\\x03\\x88X\\r\\x00\\x00\\x00keras_versionq\\x04C\\x052.2.4q\\x05X\\x07\\x00\\x00\\x00backendq\\x06C\\ntensorflowq\\x07X\\x0c\\x00\\x00\\x00model_configq\\x08B\\xcc\\x07\\x00\\x00{\"class_name\": \"Sequential\", \"config\": {\"name\": \"sequential_2\", \"layers\": [{\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_5\", \"trainable\": true, \"batch_input_shape\": [null, 13], \"dtype\": \"float32\", \"units\": 15, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"VarianceScaling\", \"config\": {\"scale\": 1.0, \"mode\": \"fan_avg\", \"distribution\": \"uniform\", \"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_6\", \"trainable\": true, \"units\": 10, \"activation\": \"sigmoid\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"VarianceScaling\", \"config\": {\"scale\": 1.0, \"mode\": \"fan_avg\", \"distribution\": \"uniform\", \"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_7\", \"trainable\": true, \"units\": 5, \"activation\": \"linear\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"VarianceScaling\", \"config\": {\"scale\": 1.0, \"mode\": \"fan_avg\", \"distribution\": \"uniform\", \"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_8\", \"trainable\": true, \"units\": 1, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"VarianceScaling\", \"config\": {\"scale\": 1.0, \"mode\": \"fan_avg\", \"distribution\": \"uniform\", \"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}]}}q\\tX\\r\\x00\\x00\\x00model_weightsq\\n}q\\x0b(h\\x03\\x88X\\x0b\\x00\\x00\\x00layer_namesq\\x0c]q\\r(C\\x07dense_5q\\x0eC\\x07dense_6q\\x0fC\\x07dense_7q\\x10C\\x07dense_8q\\x11eh\\x06C\\ntensorflowq\\x12h\\x04C\\x052.2.4q\\x13X\\x07\\x00\\x00\\x00dense_5q\\x14}q\\x15(h\\x03\\x88X\\x0c\\x00\\x00\\x00weight_namesq\\x16]q\\x17(C\\x10dense_5/kernel:0q\\x18C\\x0edense_5/bias:0q\\x19eX\\x10\\x00\\x00\\x00dense_5/kernel:0q\\x1aB\\xac\\x03\\x00\\x00\\x80\\x03cnumpy.core.multiarray\\n_reconstruct\\nq\\x00cnumpy\\nndarray\\nq\\x01K\\x00\\x85q\\x02C\\x01bq\\x03\\x87q\\x04Rq\\x05(K\\x01K\\rK\\x0f\\x86q\\x06cnumpy\\ndtype\\nq\\x07X\\x02\\x00\\x00\\x00f4q\\x08K\\x00K\\x01\\x87q\\tRq\\n(K\\x03X\\x01\\x00\\x00\\x00<q\\x0bNNNJ\\xff\\xff\\xff\\xffJ\\xff\\xff\\xff\\xffK\\x00tq\\x0cb\\x89B\\x0c\\x03\\x00\\x00L\\x01R>\\xc4\\xcb\"\\xbe\\xc0u|=xs\\xcf=\\xe2\\x83\\x8e\\xbe\\x88\\x12\\x8b\\xbd\\xe0\\xad}=Xw\\x8f\\xbe2\\xf2\\x99\\xbeD\\x87t>@\\xfb\\xe6=\\xd2w\\x1b\\xbeb\\xb3\\xa0>\\x18zR>p\\xe8\\xf8\\xbd\\xe6\\xdc\\x90>V\\x84\\xbf>\\xa2-\\xc4\\xbe\\x9a\\x9e\\x8b\\xbeD\\xfbs>\\xf2\\x97\\xd8\\xbe`\\xfb(<,h\\xdd>\\xaa \\xd1\\xbe$\\xad\\x0e\\xbe\\x1d\\x83\\x8a\\xbe\\xf2\\x9c\\x9d>o\\xf3\\x88\\xbef\\x81\\xbf\\xbez\\xee\\xa8\\xbe\\xe8\\xf0\\xcc>g!\\xb3\\xbe%\\xcc\\xe9\\xbe\\xfa\\x10\\xa6>\\x10\\xd5\\xcd=h\\x8a\\xaa\\xbe\\xfe\\xc7\\x18\\xbe\\x06\\xc5\\xe8\\xbe#\\xa2u\\xbeS\\xd5\\xd4\\xbe\\x10^\\xa4>\\x00\\xcb\\xd0=BO\\x83\\xbe4f\\x9b\\xbd\\xdf\\xf7\\xe4\\xbe\\xf4R\\xb4>hB\\xd3> \\x17\\xb4\\xbd\\xf4\\xa3u>\\xacJe\\xbeZ\\xe1\\x1c\\xbe.\\x04\\xb2>\\xd8\\xaa\\x01>H\\xd0\\xc0=\\xfb\\x9b\\xc8\\xbe\\x04+\\xbb\\xbd\\xb0\\x9f\\xaf=h?\\xbe>\\xdf7\\xe6\\xbe\\x14n\\x82\\xbe\\xe0\\x91\\xa2\\xbd\\xbc\\x85\\x9e\\xbe\\x0c\\xc6\\xc1>0\\xde\\x03\\xbd\\xf0\\x94\\x97\\xbd,\\x9c\\x0c\\xbe\\xf5\\x07\\xca\\xbe(\\x87\\xe4=\\x08Y\\xd4\\xbe\\xd0\\xe1\\x0f>4P\\xe9>\\xb4\\x02\\x19>`h\\xe4=\\xb0;\\x97\\xbe\\x18\\rf\\xbe`O7=\\xf8&\\xca>\\xe4\\xeb\\x92\\xbe\\xb6K\\x97>\"\\x9c(\\xbe\\x9a\\x8d\\xbc>T\\xc6j>\\x9a\\x0c\\xc2\\xbe\\x942\\x8e>\\xf6\\xe51\\xbe\\x00#\\xa9=\\xf4\\x9a\\x12>\\x12\\x1c\\x95>\\xe8\\x08x>\\xb5\\x00\\xc9\\xbekw\\xde\\xbe`\\x81\\x14\\xbc\\x82\\x87\\x8a>\\xe8\\xdf\\x89>\\x80\\x8e\\xa2=\\xea\\x94\\x9f\\xbe\\x89+\\xa5\\xbe\\x86\\x86\\xd3\\xbe\\xe09S\\xbc\\x0e\\xa4\\xb6>\\xd2\\x07\\xa2\\xbe\\xafY\\xeb\\xbeXR\\xa8>@\"\\xb5\\xbe\\nE\\xb1\\xbe\\x00\\xf2\\xbf;N\\x05\\x93\\xbe\\x07;_\\xbe\\xc8Ty>l\\x8e\\xe1\\xbd\\xc8_\\x95=\\x0c]\\x97>h\\xda\\x17\\xbe\\xc0\\x8f\\xe6\\xbd\\x12\\xac\\xe8>|Jt\\xbet\\xf8T>H\\x9c<\\xbd\\xb0]\\x9d>\\xb4l\\xd7\\xbe\\xc2\\x1a\\x82>\\x80\\'\\xe4=D@\\x0e>\\xc8\\xcd\\x8c>\\xb4;\\\\>0\\xb2\\xd1=\\xd2\\x92v\\xbe\\xfa8\\xcc>@\\x86\\xa2\\xbb\\x05_\\xdf\\xbe\\xe0\\xd5/\\xbc\\x15S\\xcf\\xbep\\xd1\\x9b>\\x04}\\xa0>\\xe6L\\xd8>\\xae\\xe3\\x10\\xbe@q\\x1b=\\xd2+^\\xbe \\xc0(\\xbc@&G\\xbdB\\xf3\\xda>\\xa4\\x06\\xa4\\xbep\\x08\\x05>H\\x16\\x8c>\\x9cU\\x04\\xbe\\x9c\\xa9\\xec\\xbd`\\xd0\\x10=\\xf45M\\xbe\\xccNQ>\\x00\\x19\\x16>n\\xb5P\\xbe\\xf0\\xe6Q=\\xbe\\xfd\\x93>\\x80(n\\xbc\\xc0\\xd5\\x9c\\xbd0\\x9cV>\\x8a\\xfeB\\xbet\\xf8\\xe2>\\x83\\xf2r\\xbe<\\xf7N>\\xb2X[\\xbe8\\xc4\\x8c\\xbd0\\x19.=\\xfa\\x0c\\xbb\\xbe\\xc6T\\xbb\\xbe\\xbe\\x7f\\xb5>\\x14\\xb3\\xb3>\\x92\\x1b\\x9f>\\xden\\xd5>4>\\x97\\xbd2\\x9a\\x95>\\xa2rO\\xbe-\\x02\\xcf\\xbedLA>\\x80\\r#<\\x027\\xd4\\xbe\\xd4\\x01\\xdf\\xbd\\xa0\\xd1\\xb6\\xbe\\xb6\\xda\\xaf>\\x10o\\xf0\\xbd\\x8bQt\\xbe\\xa0\\xc04=\\x80tr=\\xfc\\x84|>`o\\xbd<\\xc0t\\xfa\\xbb\\x08\\x91\\x8a>\\xfc[\\xdb> \\x02+\\xbe`\\xc57>`\\xf6\\xf7\\xbc\\xa0\\x9b\\xd0<yX\\xba\\xbe\\x84\\xd1\\x0f>\\xf6K\\xca\\xbeq\\rtq\\x0eb.q\\x1bX\\x19\\x00\\x00\\x00_dense_5/kernel:0_pickledq\\x1c\\x88X\\x0e\\x00\\x00\\x00dense_5/bias:0q\\x1dC\\xd7\\x80\\x03cnumpy.core.multiarray\\n_reconstruct\\nq\\x00cnumpy\\nndarray\\nq\\x01K\\x00\\x85q\\x02C\\x01bq\\x03\\x87q\\x04Rq\\x05(K\\x01K\\x0f\\x85q\\x06cnumpy\\ndtype\\nq\\x07X\\x02\\x00\\x00\\x00f4q\\x08K\\x00K\\x01\\x87q\\tRq\\n(K\\x03X\\x01\\x00\\x00\\x00<q\\x0bNNNJ\\xff\\xff\\xff\\xffJ\\xff\\xff\\xff\\xffK\\x00tq\\x0cb\\x89C<\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00q\\rtq\\x0eb.q\\x1eX\\x17\\x00\\x00\\x00_dense_5/bias:0_pickledq\\x1f\\x88uX\\x07\\x00\\x00\\x00dense_6q }q!(h\\x03\\x88h\\x16]q\"(C\\x10dense_6/kernel:0q#C\\x0edense_6/bias:0q$eX\\x10\\x00\\x00\\x00dense_6/kernel:0q%B\\xf8\\x02\\x00\\x00\\x80\\x03cnumpy.core.multiarray\\n_reconstruct\\nq\\x00cnumpy\\nndarray\\nq\\x01K\\x00\\x85q\\x02C\\x01bq\\x03\\x87q\\x04Rq\\x05(K\\x01K\\x0fK\\n\\x86q\\x06cnumpy\\ndtype\\nq\\x07X\\x02\\x00\\x00\\x00f4q\\x08K\\x00K\\x01\\x87q\\tRq\\n(K\\x03X\\x01\\x00\\x00\\x00<q\\x0bNNNJ\\xff\\xff\\xff\\xffJ\\xff\\xff\\xff\\xffK\\x00tq\\x0cb\\x89BX\\x02\\x00\\x00\\xbb\\xeb\\xc2>\\xcb\\xe1\\xe9>zJB>PB\\x8c\\xbc\\xfe\\xf5p\\xbe^\\xec\\xcc\\xbeB,f>\\x0c\\xb6\\xc9=@<\\x1e\\xbe\\xf7\\xd7\\xbf>\\x0c\\xd3z\\xbeT\\x87\\x8d=\\xf0d\\x0e\\xbd\\xd9\\'\\x99\\xbeme\\xc2\\xbe\\xc4\\x01\\x10\\xbeR\\x9a\\x14>\\xde\\xfbd>\\x8a\\xad+\\xbe3\\x04\\xb0\\xbehn+=\\x1a\\xb6h\\xbe2\\xceJ>\\x90f*\\xbe\\x05\\x92\\xd7>\\xdd9{\\xbe\\xc8Rw=\\x90\\x15\\xbf\\xbe|\\xc0\\xf7\\xbe\\x98\\xdc\\x19\\xbe\\xcf\\xd4\\xc6\\xbew(\\x87>\\xb4E\\xd1=\\xf1\\xeb\\xb8>\\x1cf\\xf1=+\\xc6\\xb1>\\xcf\\x07\\xf0>luU\\xbe\\xa6\\x07a\\xbe\\xef3\\xdf>?\\xed\\xe8>\\xaaJ\\\\>V}3>\\xfc{\\x98\\xbd|\\xb0\\x9e=n\\x8fg\\xbe&\\x83\\x14>\\xf0\\xb0o\\xbe\\xb8\\x08\\xd5\\xbdx\\x9f\\x86\\xbdP\\xae\\xdd\\xbe\\xf7\\x8e\\x82>\\x1a\\xdd\\x88\\xbeJF4>G\\x9f\\xac>\\xc07\\xee\\xbc\\rY\\xa5>\\xd41\\x94=\\r|\\xd6\\xbe\\xc3T\\xef>D\\xfb\\xa6\\xbd\\xdeu\\xa0\\xbe\\x1b~\\xcf>\\x90\\x94C\\xbdLx\\xc4=\\x07\\x94\\xe5>\\xf3O\\x89>\\x12\\x7f\\x7f\\xbe\\x96\\xbf\\x81\\xbe\\xbe\\xfd[>xS\\x88\\xbd\\xe3\\xb8\\x91\\xbe\\x14w=\\xbe\\x88_C\\xbdHKl\\xbe\\xb0\\xd5\\x98\\xbc \\'\\xb7\\xbcl\\x1f\\xa2=\\xa0\\xbd\\x9c\\xbeX\\xa7\\x11=\\xec\\xfa\\xc8=\\x06\\x8fr\\xbe\\xf3\\xc7\\xd4\\xbe\\n\\x82\\x15>\\x10\\\\8\\xbe i\\x10\\xbc\\xe2\\xdd\\x02>\\xb2\\xac#\\xbe\\xe4\\x85\\x83\\xbe\\x94\\xaf\\xcf=X\\xbc\\x8f\\xbe\\xb4\\xc3\\xab=\\x9c\\xd3f\\xbe\\xa8\\x7f\\x05=*A\\\\>\\xb0\\x7f\\xab<_-\\x8f>`\\xe0k\\xbc\\xfcM\\xa1\\xbd\\x96H\\x01\\xbefv.>\\xddL\\x83>\\xd4\\xe2\\x97\\xbd\\xfb\\x83v\\xbeP\\x15\\xda<\\xb7\\xc8\\x98>\\xe1\\xa9\\xc6>\\xc3\\x1a\\x9a>\\xaf?\\x98\\xbe)\\x8f\\xd7\\xbe\\x04O\\x8f\\xbe(\\xffE=(\\x0c,\\xbdh\\x9d5=m}\\xe2\\xbeB{S>Ve\\xa8\\xbe\\xdd\\xde\\xbd\\xbe\\x9c\\xd4\\x89\\xbe\\xbf\\xb5\\xe0\\xbeIp\\xbd>\\xd0\\xa3\\xe2\\xbc\\xa2\\xb6\\xb7\\xbe\\xa3g\\xfa>\\x84x\\x9e\\xbd\\xa0\\x1b/\\xbd\\x06\\x14\\xce\\xbe\\x9a\\x84\\x97\\xbe\\x86M\\x0f>\\xe4\\xa7\\xd0=\\'\\xa0\\xf3>\\x84y\\xfa=\\xa5&\\x87>p\\x04\\xce\\xbc\\x07$\\xd2>R~Q>\\xf4\\xee\\x8f=X\\xd3Z=\\xc3\\x91\\xbc\\xbe\\x19\\x0f\\x9b>\\x82\\x19\\xaf\\xbe\\xe6\\xa8\\xa2\\xbe\\xff\\x98\\xee\\xbe\\xff\\xf0\\xba\\xbe\\x0b\\xa4\\x9c>&\\n\\x8c\\xbe\\x1b\\xbd\\xaf>\\xd8\\xa8\\x08\\xbd\\x9aQ2>\\x8d\\xd7\\xa5>q\\rtq\\x0eb.q&X\\x19\\x00\\x00\\x00_dense_6/kernel:0_pickledq\\'\\x88X\\x0e\\x00\\x00\\x00dense_6/bias:0q(C\\xc3\\x80\\x03cnumpy.core.multiarray\\n_reconstruct\\nq\\x00cnumpy\\nndarray\\nq\\x01K\\x00\\x85q\\x02C\\x01bq\\x03\\x87q\\x04Rq\\x05(K\\x01K\\n\\x85q\\x06cnumpy\\ndtype\\nq\\x07X\\x02\\x00\\x00\\x00f4q\\x08K\\x00K\\x01\\x87q\\tRq\\n(K\\x03X\\x01\\x00\\x00\\x00<q\\x0bNNNJ\\xff\\xff\\xff\\xffJ\\xff\\xff\\xff\\xffK\\x00tq\\x0cb\\x89C(\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00q\\rtq\\x0eb.q)X\\x17\\x00\\x00\\x00_dense_6/bias:0_pickledq*\\x88uX\\x07\\x00\\x00\\x00dense_7q+}q,(h\\x03\\x88h\\x16]q-(C\\x10dense_7/kernel:0q.C\\x0edense_7/bias:0q/eX\\x10\\x00\\x00\\x00dense_7/kernel:0q0Be\\x01\\x00\\x00\\x80\\x03cnumpy.core.multiarray\\n_reconstruct\\nq\\x00cnumpy\\nndarray\\nq\\x01K\\x00\\x85q\\x02C\\x01bq\\x03\\x87q\\x04Rq\\x05(K\\x01K\\nK\\x05\\x86q\\x06cnumpy\\ndtype\\nq\\x07X\\x02\\x00\\x00\\x00f4q\\x08K\\x00K\\x01\\x87q\\tRq\\n(K\\x03X\\x01\\x00\\x00\\x00<q\\x0bNNNJ\\xff\\xff\\xff\\xffJ\\xff\\xff\\xff\\xffK\\x00tq\\x0cb\\x89C\\xc8@\\xbe\\x82=\\x91\\x08\\x07?\\xaa@\\xd5>\\x92\\xdd\\xdd>\\x88\\xe2W>\\xb0\\x9e\\xa1=\\xd66\\xf9>&\\xd3\\x1a\\xbf\\xa9\\xf9\\x17\\xbf\\xa4+\\xd1\\xbeF\\xd1\\xc5>\\x94\\xdb\\xfb\\xbeX\\x9c\\xb7\\xbd\\x8c@\\x02\\xbf\\x00R\\x84<\\x90\\xbe\\xbc=p\\xdc9=2\\x0e\\xe3>(\\xd7\\xd9=\"h\\xfa>\\xa4\\xa3=>\\xee&\\xba\\xbeR\\xd4\\xcf>6!\\xff>\\xd0w\\x0c\\xbdTi\\xbb>\\xc0\\xf7\\xf8\\xbc\\xb0\\xae:=h\\x16\\x96>\\x87\\x12\\x8c\\xbe\\xd1B\\x10\\xbf\\x98B\\x02\\xbfxI\\x08\\xbfB\\xf4\\xdd>!\\x06\\x9b\\xbe`\\xb5\\xe5<\\x82_\\xec\\xbe \\xcc\\xd7\\xbd\\x90\\x9ej>:K\\xc6>\\xa1\\x14\\x1a?V\\x9f\\x93>\\xa6N\\x0f\\xbeF\\xf7\\xc1>4\\x1b\\x82>G\\xb2\\xd2\\xbe\\xc0Q\\x1e<\\xf0\\xf8\\xde\\xbdo\\xc7\\x03?|\\xc0\\x01\\xbfq\\rtq\\x0eb.q1X\\x19\\x00\\x00\\x00_dense_7/kernel:0_pickledq2\\x88X\\x0e\\x00\\x00\\x00dense_7/bias:0q3C\\xaf\\x80\\x03cnumpy.core.multiarray\\n_reconstruct\\nq\\x00cnumpy\\nndarray\\nq\\x01K\\x00\\x85q\\x02C\\x01bq\\x03\\x87q\\x04Rq\\x05(K\\x01K\\x05\\x85q\\x06cnumpy\\ndtype\\nq\\x07X\\x02\\x00\\x00\\x00f4q\\x08K\\x00K\\x01\\x87q\\tRq\\n(K\\x03X\\x01\\x00\\x00\\x00<q\\x0bNNNJ\\xff\\xff\\xff\\xffJ\\xff\\xff\\xff\\xffK\\x00tq\\x0cb\\x89C\\x14\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00q\\rtq\\x0eb.q4X\\x17\\x00\\x00\\x00_dense_7/bias:0_pickledq5\\x88uX\\x07\\x00\\x00\\x00dense_8q6}q7(h\\x03\\x88h\\x16]q8(C\\x10dense_8/kernel:0q9C\\x0edense_8/bias:0q:eX\\x10\\x00\\x00\\x00dense_8/kernel:0q;C\\xb1\\x80\\x03cnumpy.core.multiarray\\n_reconstruct\\nq\\x00cnumpy\\nndarray\\nq\\x01K\\x00\\x85q\\x02C\\x01bq\\x03\\x87q\\x04Rq\\x05(K\\x01K\\x05K\\x01\\x86q\\x06cnumpy\\ndtype\\nq\\x07X\\x02\\x00\\x00\\x00f4q\\x08K\\x00K\\x01\\x87q\\tRq\\n(K\\x03X\\x01\\x00\\x00\\x00<q\\x0bNNNJ\\xff\\xff\\xff\\xffJ\\xff\\xff\\xff\\xffK\\x00tq\\x0cb\\x89C\\x14\\x80]P\\xbdx\\xfe\\xb0\\xbe\\xc0\\xc3\\xe0>`g\\x18\\xbe\\xbcPq?q\\rtq\\x0eb.q<X\\x19\\x00\\x00\\x00_dense_8/kernel:0_pickledq=\\x88X\\x0e\\x00\\x00\\x00dense_8/bias:0q>C\\x9f\\x80\\x03cnumpy.core.multiarray\\n_reconstruct\\nq\\x00cnumpy\\nndarray\\nq\\x01K\\x00\\x85q\\x02C\\x01bq\\x03\\x87q\\x04Rq\\x05(K\\x01K\\x01\\x85q\\x06cnumpy\\ndtype\\nq\\x07X\\x02\\x00\\x00\\x00f4q\\x08K\\x00K\\x01\\x87q\\tRq\\n(K\\x03X\\x01\\x00\\x00\\x00<q\\x0bNNNJ\\xff\\xff\\xff\\xffJ\\xff\\xff\\xff\\xffK\\x00tq\\x0cb\\x89C\\x04\\x00\\x00\\x00\\x00q\\rtq\\x0eb.q?X\\x17\\x00\\x00\\x00_dense_8/bias:0_pickledq@\\x88uuX\\x0f\\x00\\x00\\x00training_configqAC\\xf8{\"optimizer_config\": {\"class_name\": \"SGD\", \"config\": {\"lr\": 0.009999999776482582, \"momentum\": 0.0, \"decay\": 0.0, \"nesterov\": false}}, \"loss\": \"mean_squared_error\", \"metrics\": [\"mean_squared_error\"], \"sample_weight_mode\": null, \"loss_weights\": null}qBX\\x11\\x00\\x00\\x00optimizer_weightsqC}qD(h\\x03\\x88h\\x16]qE(C\\x12SGD_1/iterations:0qFC\\x19training_1/SGD/Variable:0qGC\\x1btraining_1/SGD/Variable_1:0qHC\\x1btraining_1/SGD/Variable_2:0qIC\\x1btraining_1/SGD/Variable_3:0qJC\\x1btraining_1/SGD/Variable_4:0qKC\\x1btraining_1/SGD/Variable_5:0qLC\\x1btraining_1/SGD/Variable_6:0qMC\\x1btraining_1/SGD/Variable_7:0qNeX\\x12\\x00\\x00\\x00SGD_1/iterations:0qOCu\\x80\\x03cnumpy.core.multiarray\\nscalar\\nq\\x00cnumpy\\ndtype\\nq\\x01X\\x02\\x00\\x00\\x00i8q\\x02K\\x00K\\x01\\x87q\\x03Rq\\x04(K\\x03X\\x01\\x00\\x00\\x00<q\\x05NNNJ\\xff\\xff\\xff\\xffJ\\xff\\xff\\xff\\xffK\\x00tq\\x06bC\\x08\\xe8\\x03\\x00\\x00\\x00\\x00\\x00\\x00q\\x07\\x86q\\x08Rq\\t.qPX\\x1b\\x00\\x00\\x00_SGD_1/iterations:0_pickledqQ\\x88X\\x19\\x00\\x00\\x00training_1/SGD/Variable:0qRB\\xac\\x03\\x00\\x00\\x80\\x03cnumpy.core.multiarray\\n_reconstruct\\nq\\x00cnumpy\\nndarray\\nq\\x01K\\x00\\x85q\\x02C\\x01bq\\x03\\x87q\\x04Rq\\x05(K\\x01K\\rK\\x0f\\x86q\\x06cnumpy\\ndtype\\nq\\x07X\\x02\\x00\\x00\\x00f4q\\x08K\\x00K\\x01\\x87q\\tRq\\n(K\\x03X\\x01\\x00\\x00\\x00<q\\x0bNNNJ\\xff\\xff\\xff\\xffJ\\xff\\xff\\xff\\xffK\\x00tq\\x0cb\\x89B\\x0c\\x03\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00q\\rtq\\x0eb.qSX\"\\x00\\x00\\x00_training_1/SGD/Variable:0_pickledqT\\x88X\\x1b\\x00\\x00\\x00training_1/SGD/Variable_1:0qUC\\xd7\\x80\\x03cnumpy.core.multiarray\\n_reconstruct\\nq\\x00cnumpy\\nndarray\\nq\\x01K\\x00\\x85q\\x02C\\x01bq\\x03\\x87q\\x04Rq\\x05(K\\x01K\\x0f\\x85q\\x06cnumpy\\ndtype\\nq\\x07X\\x02\\x00\\x00\\x00f4q\\x08K\\x00K\\x01\\x87q\\tRq\\n(K\\x03X\\x01\\x00\\x00\\x00<q\\x0bNNNJ\\xff\\xff\\xff\\xffJ\\xff\\xff\\xff\\xffK\\x00tq\\x0cb\\x89C<\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00q\\rtq\\x0eb.qVX$\\x00\\x00\\x00_training_1/SGD/Variable_1:0_pickledqW\\x88X\\x1b\\x00\\x00\\x00training_1/SGD/Variable_2:0qXB\\xf8\\x02\\x00\\x00\\x80\\x03cnumpy.core.multiarray\\n_reconstruct\\nq\\x00cnumpy\\nndarray\\nq\\x01K\\x00\\x85q\\x02C\\x01bq\\x03\\x87q\\x04Rq\\x05(K\\x01K\\x0fK\\n\\x86q\\x06cnumpy\\ndtype\\nq\\x07X\\x02\\x00\\x00\\x00f4q\\x08K\\x00K\\x01\\x87q\\tRq\\n(K\\x03X\\x01\\x00\\x00\\x00<q\\x0bNNNJ\\xff\\xff\\xff\\xffJ\\xff\\xff\\xff\\xffK\\x00tq\\x0cb\\x89BX\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00q\\rtq\\x0eb.qYX$\\x00\\x00\\x00_training_1/SGD/Variable_2:0_pickledqZ\\x88X\\x1b\\x00\\x00\\x00training_1/SGD/Variable_3:0q[C\\xc3\\x80\\x03cnumpy.core.multiarray\\n_reconstruct\\nq\\x00cnumpy\\nndarray\\nq\\x01K\\x00\\x85q\\x02C\\x01bq\\x03\\x87q\\x04Rq\\x05(K\\x01K\\n\\x85q\\x06cnumpy\\ndtype\\nq\\x07X\\x02\\x00\\x00\\x00f4q\\x08K\\x00K\\x01\\x87q\\tRq\\n(K\\x03X\\x01\\x00\\x00\\x00<q\\x0bNNNJ\\xff\\xff\\xff\\xffJ\\xff\\xff\\xff\\xffK\\x00tq\\x0cb\\x89C(\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00q\\rtq\\x0eb.q\\\\X$\\x00\\x00\\x00_training_1/SGD/Variable_3:0_pickledq]\\x88X\\x1b\\x00\\x00\\x00training_1/SGD/Variable_4:0q^Be\\x01\\x00\\x00\\x80\\x03cnumpy.core.multiarray\\n_reconstruct\\nq\\x00cnumpy\\nndarray\\nq\\x01K\\x00\\x85q\\x02C\\x01bq\\x03\\x87q\\x04Rq\\x05(K\\x01K\\nK\\x05\\x86q\\x06cnumpy\\ndtype\\nq\\x07X\\x02\\x00\\x00\\x00f4q\\x08K\\x00K\\x01\\x87q\\tRq\\n(K\\x03X\\x01\\x00\\x00\\x00<q\\x0bNNNJ\\xff\\xff\\xff\\xffJ\\xff\\xff\\xff\\xffK\\x00tq\\x0cb\\x89C\\xc8\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00q\\rtq\\x0eb.q_X$\\x00\\x00\\x00_training_1/SGD/Variable_4:0_pickledq`\\x88X\\x1b\\x00\\x00\\x00training_1/SGD/Variable_5:0qaC\\xaf\\x80\\x03cnumpy.core.multiarray\\n_reconstruct\\nq\\x00cnumpy\\nndarray\\nq\\x01K\\x00\\x85q\\x02C\\x01bq\\x03\\x87q\\x04Rq\\x05(K\\x01K\\x05\\x85q\\x06cnumpy\\ndtype\\nq\\x07X\\x02\\x00\\x00\\x00f4q\\x08K\\x00K\\x01\\x87q\\tRq\\n(K\\x03X\\x01\\x00\\x00\\x00<q\\x0bNNNJ\\xff\\xff\\xff\\xffJ\\xff\\xff\\xff\\xffK\\x00tq\\x0cb\\x89C\\x14\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00q\\rtq\\x0eb.qbX$\\x00\\x00\\x00_training_1/SGD/Variable_5:0_pickledqc\\x88X\\x1b\\x00\\x00\\x00training_1/SGD/Variable_6:0qdC\\xb1\\x80\\x03cnumpy.core.multiarray\\n_reconstruct\\nq\\x00cnumpy\\nndarray\\nq\\x01K\\x00\\x85q\\x02C\\x01bq\\x03\\x87q\\x04Rq\\x05(K\\x01K\\x05K\\x01\\x86q\\x06cnumpy\\ndtype\\nq\\x07X\\x02\\x00\\x00\\x00f4q\\x08K\\x00K\\x01\\x87q\\tRq\\n(K\\x03X\\x01\\x00\\x00\\x00<q\\x0bNNNJ\\xff\\xff\\xff\\xffJ\\xff\\xff\\xff\\xffK\\x00tq\\x0cb\\x89C\\x14\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00q\\rtq\\x0eb.qeX$\\x00\\x00\\x00_training_1/SGD/Variable_6:0_pickledqf\\x88X\\x1b\\x00\\x00\\x00training_1/SGD/Variable_7:0qgC\\x9f\\x80\\x03cnumpy.core.multiarray\\n_reconstruct\\nq\\x00cnumpy\\nndarray\\nq\\x01K\\x00\\x85q\\x02C\\x01bq\\x03\\x87q\\x04Rq\\x05(K\\x01K\\x01\\x85q\\x06cnumpy\\ndtype\\nq\\x07X\\x02\\x00\\x00\\x00f4q\\x08K\\x00K\\x01\\x87q\\tRq\\n(K\\x03X\\x01\\x00\\x00\\x00<q\\x0bNNNJ\\xff\\xff\\xff\\xffJ\\xff\\xff\\xff\\xffK\\x00tq\\x0cb\\x89C\\x04\\x00\\x00\\x00\\x00q\\rtq\\x0eb.qhX$\\x00\\x00\\x00_training_1/SGD/Variable_7:0_pickledqi\\x88uub.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-09T03:38:47.649847Z",
     "start_time": "2019-05-09T03:38:46.442676Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7f8c48eb3a58>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_reborn = pickle.loads(model_dump)\n",
    "model_reborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-09T03:45:19.927282Z",
     "start_time": "2019-05-09T03:45:19.897149Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE : 615.86\n",
      "RMSE : 24.82\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "y_pred = model_reborn.predict(x_test)\n",
    "MSE = mean_squared_error(y_test, y_pred)\n",
    "RMSE = np.sqrt(MSE)\n",
    "\n",
    "print(f'MSE : {MSE:.2f}')\n",
    "print(f'RMSE : {RMSE:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare MSE of Neural Network vs. Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-09T03:50:22.326834Z",
     "start_time": "2019-05-09T03:50:22.042942Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE : 18.17\n",
      "RMSE : 4.26\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "MSE = mean_squared_error(y_test, y_pred)\n",
    "RMSE = np.sqrt(MSE)\n",
    "\n",
    "print(f'MSE : {MSE:.2f}')\n",
    "print(f'RMSE : {RMSE:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SfcFnOONyuNm"
   },
   "source": [
    "# Use the Keras Library to build an image recognition network using the Fashion-MNIST dataset (also comes with keras)\n",
    "\n",
    "- Load and preprocess the image data similar to how we preprocessed the MNIST data in class.\n",
    "- Make sure to one-hot encode your category labels\n",
    "- Make sure to have your final layer have as many nodes as the number of classes that you want to predict.\n",
    "- Try different hyperparameters. What is the highest accuracy that you are able to achieve.\n",
    "- Use the history object that is returned from model.fit to make graphs of the model's loss or train/validation accuracies by epoch. \n",
    "- Remember that neural networks fall prey to randomness so you may need to run your model multiple times (or use Cross Validation) in order to tell if a change to a hyperparameter is truly producing better results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and preprocess the image data \n",
    "similar to how we preprocessed the MNIST data in class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-09T03:54:57.383905Z",
     "start_time": "2019-05-09T03:54:28.142739Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "szi6-IpuzaH1",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 9us/step\n",
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 23s 1us/step\n",
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "8192/5148 [===============================================] - 0s 0us/step\n",
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 4s 1us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (10000, 28, 28), (60000,), (10000,))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-09T04:01:06.460059Z",
     "start_time": "2019-05-09T04:01:04.956144Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   1.,   0.,   0.,\n",
       "        13.,  73.,   0.,   0.,   1.,   4.,   0.,   0.,   0.,   0.,   1.,\n",
       "         1.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   3.,   0.,  36., 136., 127.,  62.,  54.,   0.,\n",
       "         0.,   0.,   1.,   3.,   4.,   0.,   0.,   3.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   6.,   0.,\n",
       "       102., 204., 176., 134., 144., 123.,  23.,   0.,   0.,   0.,   0.,\n",
       "        12.,  10.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0., 155., 236., 207., 178., 107.,\n",
       "       156., 161., 109.,  64.,  23.,  77., 130.,  72.,  15.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   1.,   0.,\n",
       "        69., 207., 223., 218., 216., 216., 163., 127., 121., 122., 146.,\n",
       "       141.,  88., 172.,  66.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   1.,   1.,   1.,   0., 200., 232., 232., 233., 229.,\n",
       "       223., 223., 215., 213., 164., 127., 123., 196., 229.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0., 183., 225., 216., 223., 228., 235., 227., 224., 222., 224.,\n",
       "       221., 223., 245., 173.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0., 193., 228., 218., 213.,\n",
       "       198., 180., 212., 210., 211., 213., 223., 220., 243., 202.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   1.,   3.,\n",
       "         0.,  12., 219., 220., 212., 218., 192., 169., 227., 208., 218.,\n",
       "       224., 212., 226., 197., 209.,  52.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   6.,   0.,  99., 244., 222., 220.,\n",
       "       218., 203., 198., 221., 215., 213., 222., 220., 245., 119., 167.,\n",
       "        56.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   4.,\n",
       "         0.,   0.,  55., 236., 228., 230., 228., 240., 232., 213., 218.,\n",
       "       223., 234., 217., 217., 209.,  92.,   0.,   0.,   0.,   1.,   4.,\n",
       "         6.,   7.,   2.,   0.,   0.,   0.,   0.,   0., 237., 226., 217.,\n",
       "       223., 222., 219., 222., 221., 216., 223., 229., 215., 218., 255.,\n",
       "        77.,   0.,   0.,   3.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "        62., 145., 204., 228., 207., 213., 221., 218., 208., 211., 218.,\n",
       "       224., 223., 219., 215., 224., 244., 159.,   0.,   0.,   0.,   0.,\n",
       "         0.,  18.,  44.,  82., 107., 189., 228., 220., 222., 217., 226.,\n",
       "       200., 205., 211., 230., 224., 234., 176., 188., 250., 248., 233.,\n",
       "       238., 215.,   0.,   0.,  57., 187., 208., 224., 221., 224., 208.,\n",
       "       204., 214., 208., 209., 200., 159., 245., 193., 206., 223., 255.,\n",
       "       255., 221., 234., 221., 211., 220., 232., 246.,   0.,   3., 202.,\n",
       "       228., 224., 221., 211., 211., 214., 205., 205., 205., 220., 240.,\n",
       "        80., 150., 255., 229., 221., 188., 154., 191., 210., 204., 209.,\n",
       "       222., 228., 225.,   0.,  98., 233., 198., 210., 222., 229., 229.,\n",
       "       234., 249., 220., 194., 215., 217., 241.,  65.,  73., 106., 117.,\n",
       "       168., 219., 221., 215., 217., 223., 223., 224., 229.,  29.,  75.,\n",
       "       204., 212., 204., 193., 205., 211., 225., 216., 185., 197., 206.,\n",
       "       198., 213., 240., 195., 227., 245., 239., 223., 218., 212., 209.,\n",
       "       222., 220., 221., 230.,  67.,  48., 203., 183., 194., 213., 197.,\n",
       "       185., 190., 194., 192., 202., 214., 219., 221., 220., 236., 225.,\n",
       "       216., 199., 206., 186., 181., 177., 172., 181., 205., 206., 115.,\n",
       "         0., 122., 219., 193., 179., 171., 183., 196., 204., 210., 213.,\n",
       "       207., 211., 210., 200., 196., 194., 191., 195., 191., 198., 192.,\n",
       "       176., 156., 167., 177., 210.,  92.,   0.,   0.,  74., 189., 212.,\n",
       "       191., 175., 172., 175., 181., 185., 188., 189., 188., 193., 198.,\n",
       "       204., 209., 210., 210., 211., 188., 188., 194., 192., 216., 170.,\n",
       "         0.,   2.,   0.,   0.,   0.,  66., 200., 222., 237., 239., 242.,\n",
       "       246., 243., 244., 221., 220., 193., 191., 179., 182., 182., 181.,\n",
       "       176., 166., 168.,  99.,  58.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,  40.,  61.,  44.,  72.,  41.,  35.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Flatten the image data\n",
    "X_train = x_train.reshape(60000, 784)\n",
    "X_test = x_test.reshape(10000, 784)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-09T04:02:59.429756Z",
     "start_time": "2019-05-09T04:02:59.160418Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.00392157, 0.        , 0.        , 0.05098039,\n",
       "       0.28627452, 0.        , 0.        , 0.00392157, 0.01568628,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
       "       0.00392157, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.01176471,\n",
       "       0.        , 0.14117648, 0.53333336, 0.49803922, 0.24313726,\n",
       "       0.21176471, 0.        , 0.        , 0.        , 0.00392157,\n",
       "       0.01176471, 0.01568628, 0.        , 0.        , 0.01176471,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.02352941, 0.        , 0.4       ,\n",
       "       0.8       , 0.6901961 , 0.5254902 , 0.5647059 , 0.48235294,\n",
       "       0.09019608, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.04705882, 0.03921569, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.60784316, 0.9254902 , 0.8117647 ,\n",
       "       0.69803923, 0.41960785, 0.6117647 , 0.6313726 , 0.42745098,\n",
       "       0.2509804 , 0.09019608, 0.3019608 , 0.50980395, 0.28235295,\n",
       "       0.05882353, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.00392157, 0.        , 0.27058825,\n",
       "       0.8117647 , 0.8745098 , 0.85490197, 0.84705883, 0.84705883,\n",
       "       0.6392157 , 0.49803922, 0.4745098 , 0.47843137, 0.57254905,\n",
       "       0.5529412 , 0.34509805, 0.6745098 , 0.25882354, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.00392157, 0.00392157,\n",
       "       0.00392157, 0.        , 0.78431374, 0.9098039 , 0.9098039 ,\n",
       "       0.9137255 , 0.8980392 , 0.8745098 , 0.8745098 , 0.84313726,\n",
       "       0.8352941 , 0.6431373 , 0.49803922, 0.48235294, 0.76862746,\n",
       "       0.8980392 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.7176471 , 0.88235295, 0.84705883, 0.8745098 , 0.89411765,\n",
       "       0.92156863, 0.8901961 , 0.8784314 , 0.87058824, 0.8784314 ,\n",
       "       0.8666667 , 0.8745098 , 0.9607843 , 0.6784314 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.75686276, 0.89411765,\n",
       "       0.85490197, 0.8352941 , 0.7764706 , 0.7058824 , 0.83137256,\n",
       "       0.8235294 , 0.827451  , 0.8352941 , 0.8745098 , 0.8627451 ,\n",
       "       0.9529412 , 0.7921569 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.00392157, 0.01176471, 0.        ,\n",
       "       0.04705882, 0.85882354, 0.8627451 , 0.83137256, 0.85490197,\n",
       "       0.7529412 , 0.6627451 , 0.8901961 , 0.8156863 , 0.85490197,\n",
       "       0.8784314 , 0.83137256, 0.8862745 , 0.77254903, 0.81960785,\n",
       "       0.20392157, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.02352941, 0.        , 0.3882353 , 0.95686275,\n",
       "       0.87058824, 0.8627451 , 0.85490197, 0.79607844, 0.7764706 ,\n",
       "       0.8666667 , 0.84313726, 0.8352941 , 0.87058824, 0.8627451 ,\n",
       "       0.9607843 , 0.46666667, 0.654902  , 0.21960784, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.01568628, 0.        ,\n",
       "       0.        , 0.21568628, 0.9254902 , 0.89411765, 0.9019608 ,\n",
       "       0.89411765, 0.9411765 , 0.9098039 , 0.8352941 , 0.85490197,\n",
       "       0.8745098 , 0.91764706, 0.8509804 , 0.8509804 , 0.81960785,\n",
       "       0.36078432, 0.        , 0.        , 0.        , 0.00392157,\n",
       "       0.01568628, 0.02352941, 0.02745098, 0.00784314, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.92941177,\n",
       "       0.8862745 , 0.8509804 , 0.8745098 , 0.87058824, 0.85882354,\n",
       "       0.87058824, 0.8666667 , 0.84705883, 0.8745098 , 0.8980392 ,\n",
       "       0.84313726, 0.85490197, 1.        , 0.3019608 , 0.        ,\n",
       "       0.        , 0.01176471, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.24313726,\n",
       "       0.5686275 , 0.8       , 0.89411765, 0.8117647 , 0.8352941 ,\n",
       "       0.8666667 , 0.85490197, 0.8156863 , 0.827451  , 0.85490197,\n",
       "       0.8784314 , 0.8745098 , 0.85882354, 0.84313726, 0.8784314 ,\n",
       "       0.95686275, 0.62352943, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.07058824, 0.17254902, 0.32156864,\n",
       "       0.41960785, 0.7411765 , 0.89411765, 0.8627451 , 0.87058824,\n",
       "       0.8509804 , 0.8862745 , 0.78431374, 0.8039216 , 0.827451  ,\n",
       "       0.9019608 , 0.8784314 , 0.91764706, 0.6901961 , 0.7372549 ,\n",
       "       0.98039216, 0.972549  , 0.9137255 , 0.93333334, 0.84313726,\n",
       "       0.        , 0.        , 0.22352941, 0.73333335, 0.8156863 ,\n",
       "       0.8784314 , 0.8666667 , 0.8784314 , 0.8156863 , 0.8       ,\n",
       "       0.8392157 , 0.8156863 , 0.81960785, 0.78431374, 0.62352943,\n",
       "       0.9607843 , 0.75686276, 0.80784315, 0.8745098 , 1.        ,\n",
       "       1.        , 0.8666667 , 0.91764706, 0.8666667 , 0.827451  ,\n",
       "       0.8627451 , 0.9098039 , 0.9647059 , 0.        , 0.01176471,\n",
       "       0.7921569 , 0.89411765, 0.8784314 , 0.8666667 , 0.827451  ,\n",
       "       0.827451  , 0.8392157 , 0.8039216 , 0.8039216 , 0.8039216 ,\n",
       "       0.8627451 , 0.9411765 , 0.3137255 , 0.5882353 , 1.        ,\n",
       "       0.8980392 , 0.8666667 , 0.7372549 , 0.6039216 , 0.7490196 ,\n",
       "       0.8235294 , 0.8       , 0.81960785, 0.87058824, 0.89411765,\n",
       "       0.88235295, 0.        , 0.38431373, 0.9137255 , 0.7764706 ,\n",
       "       0.8235294 , 0.87058824, 0.8980392 , 0.8980392 , 0.91764706,\n",
       "       0.9764706 , 0.8627451 , 0.7607843 , 0.84313726, 0.8509804 ,\n",
       "       0.94509804, 0.25490198, 0.28627452, 0.41568628, 0.45882353,\n",
       "       0.65882355, 0.85882354, 0.8666667 , 0.84313726, 0.8509804 ,\n",
       "       0.8745098 , 0.8745098 , 0.8784314 , 0.8980392 , 0.11372549,\n",
       "       0.29411766, 0.8       , 0.83137256, 0.8       , 0.75686276,\n",
       "       0.8039216 , 0.827451  , 0.88235295, 0.84705883, 0.7254902 ,\n",
       "       0.77254903, 0.80784315, 0.7764706 , 0.8352941 , 0.9411765 ,\n",
       "       0.7647059 , 0.8901961 , 0.9607843 , 0.9372549 , 0.8745098 ,\n",
       "       0.85490197, 0.83137256, 0.81960785, 0.87058824, 0.8627451 ,\n",
       "       0.8666667 , 0.9019608 , 0.2627451 , 0.1882353 , 0.79607844,\n",
       "       0.7176471 , 0.7607843 , 0.8352941 , 0.77254903, 0.7254902 ,\n",
       "       0.74509805, 0.7607843 , 0.7529412 , 0.7921569 , 0.8392157 ,\n",
       "       0.85882354, 0.8666667 , 0.8627451 , 0.9254902 , 0.88235295,\n",
       "       0.84705883, 0.78039217, 0.80784315, 0.7294118 , 0.70980394,\n",
       "       0.69411767, 0.6745098 , 0.70980394, 0.8039216 , 0.80784315,\n",
       "       0.4509804 , 0.        , 0.47843137, 0.85882354, 0.75686276,\n",
       "       0.7019608 , 0.67058825, 0.7176471 , 0.76862746, 0.8       ,\n",
       "       0.8235294 , 0.8352941 , 0.8117647 , 0.827451  , 0.8235294 ,\n",
       "       0.78431374, 0.76862746, 0.7607843 , 0.7490196 , 0.7647059 ,\n",
       "       0.7490196 , 0.7764706 , 0.7529412 , 0.6901961 , 0.6117647 ,\n",
       "       0.654902  , 0.69411767, 0.8235294 , 0.36078432, 0.        ,\n",
       "       0.        , 0.2901961 , 0.7411765 , 0.83137256, 0.7490196 ,\n",
       "       0.6862745 , 0.6745098 , 0.6862745 , 0.70980394, 0.7254902 ,\n",
       "       0.7372549 , 0.7411765 , 0.7372549 , 0.75686276, 0.7764706 ,\n",
       "       0.8       , 0.81960785, 0.8235294 , 0.8235294 , 0.827451  ,\n",
       "       0.7372549 , 0.7372549 , 0.7607843 , 0.7529412 , 0.84705883,\n",
       "       0.6666667 , 0.        , 0.00784314, 0.        , 0.        ,\n",
       "       0.        , 0.25882354, 0.78431374, 0.87058824, 0.92941177,\n",
       "       0.9372549 , 0.9490196 , 0.9647059 , 0.9529412 , 0.95686275,\n",
       "       0.8666667 , 0.8627451 , 0.75686276, 0.7490196 , 0.7019608 ,\n",
       "       0.7137255 , 0.7137255 , 0.70980394, 0.6901961 , 0.6509804 ,\n",
       "       0.65882355, 0.3882353 , 0.22745098, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.15686275, 0.23921569, 0.17254902,\n",
       "       0.28235295, 0.16078432, 0.13725491, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scale the X data to also be 0-1\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-09T04:01:55.109461Z",
     "start_time": "2019-05-09T04:01:55.101677Z"
    }
   },
   "source": [
    "## Make sure to one-hot encode your category labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-09T04:02:14.811160Z",
     "start_time": "2019-05-09T04:02:14.779039Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = 10 # b/c there are 9 types of clothing articles and 1 'bag'\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "y_train[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensure final layer has correct # of nodes\n",
    "Make sure to have your final layer have as many nodes as the number of classes that you want to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-09T04:07:20.312859Z",
     "start_time": "2019-05-09T04:07:20.119355Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 28)                21980     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 28)                812       \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                290       \n",
      "=================================================================\n",
      "Total params: 23,082\n",
      "Trainable params: 23,082\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(28, activation='relu', input_dim=784))  # inner layer = 28 (X columns), 784 is the reshape columns\n",
    "model.add(Dense(28, activation='relu')) # inner layer = 28 (X columns)\n",
    "model.add(Dense(10, activation='softmax')) \n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-09T04:13:36.839876Z",
     "start_time": "2019-05-09T04:09:13.719188Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/20\n",
      "54000/54000 [==============================] - 17s 310us/step - loss: 0.5684 - acc: 0.8029 - val_loss: 0.4447 - val_acc: 0.8353\n",
      "Epoch 2/20\n",
      "54000/54000 [==============================] - 11s 196us/step - loss: 0.4163 - acc: 0.8518 - val_loss: 0.3994 - val_acc: 0.8540\n",
      "Epoch 3/20\n",
      "54000/54000 [==============================] - 12s 226us/step - loss: 0.3811 - acc: 0.8626 - val_loss: 0.3918 - val_acc: 0.8587\n",
      "Epoch 4/20\n",
      "54000/54000 [==============================] - 12s 228us/step - loss: 0.3593 - acc: 0.8695 - val_loss: 0.3727 - val_acc: 0.8617\n",
      "Epoch 5/20\n",
      "54000/54000 [==============================] - 12s 216us/step - loss: 0.3426 - acc: 0.8758 - val_loss: 0.3818 - val_acc: 0.8645\n",
      "Epoch 6/20\n",
      "54000/54000 [==============================] - 12s 229us/step - loss: 0.3307 - acc: 0.8789 - val_loss: 0.3833 - val_acc: 0.8632\n",
      "Epoch 7/20\n",
      "54000/54000 [==============================] - 15s 279us/step - loss: 0.3190 - acc: 0.8835 - val_loss: 0.3758 - val_acc: 0.8668\n",
      "Epoch 8/20\n",
      "54000/54000 [==============================] - 15s 286us/step - loss: 0.3113 - acc: 0.8848 - val_loss: 0.3718 - val_acc: 0.8630\n",
      "Epoch 9/20\n",
      "54000/54000 [==============================] - 14s 262us/step - loss: 0.3029 - acc: 0.8893 - val_loss: 0.3568 - val_acc: 0.8710\n",
      "Epoch 10/20\n",
      "54000/54000 [==============================] - 13s 242us/step - loss: 0.2960 - acc: 0.8906 - val_loss: 0.3770 - val_acc: 0.8638\n",
      "Epoch 11/20\n",
      "54000/54000 [==============================] - 12s 218us/step - loss: 0.2904 - acc: 0.8925 - val_loss: 0.3836 - val_acc: 0.8610\n",
      "Epoch 12/20\n",
      "54000/54000 [==============================] - 8s 149us/step - loss: 0.2868 - acc: 0.8939 - val_loss: 0.3947 - val_acc: 0.8655\n",
      "Epoch 13/20\n",
      "54000/54000 [==============================] - 11s 195us/step - loss: 0.2812 - acc: 0.8957 - val_loss: 0.3634 - val_acc: 0.8708\n",
      "Epoch 14/20\n",
      "54000/54000 [==============================] - 15s 270us/step - loss: 0.2737 - acc: 0.8974 - val_loss: 0.3520 - val_acc: 0.8738\n",
      "Epoch 15/20\n",
      "54000/54000 [==============================] - 10s 191us/step - loss: 0.2684 - acc: 0.9009 - val_loss: 0.3527 - val_acc: 0.8755\n",
      "Epoch 16/20\n",
      "54000/54000 [==============================] - 13s 235us/step - loss: 0.2677 - acc: 0.9009 - val_loss: 0.3670 - val_acc: 0.8732\n",
      "Epoch 17/20\n",
      "54000/54000 [==============================] - 14s 267us/step - loss: 0.2635 - acc: 0.9010 - val_loss: 0.3810 - val_acc: 0.8712\n",
      "Epoch 18/20\n",
      "54000/54000 [==============================] - 15s 284us/step - loss: 0.2601 - acc: 0.9028 - val_loss: 0.3715 - val_acc: 0.8705\n",
      "Epoch 19/20\n",
      "54000/54000 [==============================] - 15s 271us/step - loss: 0.2567 - acc: 0.9045 - val_loss: 0.3549 - val_acc: 0.8733\n",
      "Epoch 20/20\n",
      "54000/54000 [==============================] - 16s 287us/step - loss: 0.2515 - acc: 0.9062 - val_loss: 0.3675 - val_acc: 0.8697\n",
      "10000/10000 [==============================] - 1s 111us/step\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters Modification\n",
    "batch_size = 64\n",
    "epochs = 20\n",
    "history = model.fit(x_train, y_train, validation_data=(x_test, y_test), \n",
    "                    epochs=epochs, batch_size=batch_size, verbose=2)\n",
    "scores = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph of Model Performance\n",
    "Use the history object that is returned from model.fit to make graphs of the model's loss or train/validation accuracies by epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-09T04:25:05.801026Z",
     "start_time": "2019-05-09T04:25:05.504034Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(history.history['acc'], label = 'Train')\n",
    "ax.plot(history.history['val_acc'], label = 'Test')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Accuracy')\n",
    "plt.title(\"Train and Test Accuracies by Epoch\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-09T04:21:04.596867Z",
     "start_time": "2019-05-09T04:21:04.587969Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Accuracy: 86.7%', 'Final test error: 13.30%')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'Accuracy: {scores[1]*100}%', f'Final test error: {100-scores[1]*100:.2f}%'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zv_3xNMjzdLI"
   },
   "source": [
    "# Stretch Goals:\n",
    "\n",
    "- Use Hyperparameter Tuning to make the accuracy of your models as high as possible. (error as low as possible)\n",
    "- Use Cross Validation techniques to get more consistent results with your model.\n",
    "- Use GridSearchCV to try different combinations of hyperparameters. \n",
    "- Start looking into other types of Keras layers for CNNs and RNNs maybe try and build a CNN model for fashion-MNIST to see how the results compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "LS_DS_433_Keras_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "400.747px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
