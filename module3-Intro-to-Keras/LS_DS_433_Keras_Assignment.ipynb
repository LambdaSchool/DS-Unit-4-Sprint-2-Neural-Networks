{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LS_DS_433_Keras_Assignment.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ruwai/DS-Unit-4-Sprint-3-Neural-Networks/blob/master/module3-Intro-to-Keras/LS_DS_433_Keras_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBQsZEJmubLs",
        "colab_type": "text"
      },
      "source": [
        "## Use the Keras Library to build a Multi-Layer Perceptron Model on the Boston Housing dataset\n",
        "\n",
        "- The Boston Housing dataset comes with the Keras library so use Keras to import it into your notebook. \n",
        "- Normalize the data (all features should have roughly the same scale)\n",
        "- Import the type of model and layers that you will need from Keras.\n",
        "- Instantiate a model object and use `model.add()` to add layers to your model\n",
        "- Since this is a regression model you will have a single output node in the final layer.\n",
        "- Use activation functions that are appropriate for this task\n",
        "- Compile your model\n",
        "- Fit your model and report its accuracy in terms of Mean Squared Error\n",
        "- Use the history object that is returned from model.fit to make graphs of the model's loss or train/validation accuracies by epoch. \n",
        "- Run this same data through a linear regression model. Which achieves higher accuracy?\n",
        "- Do a little bit of feature engineering and see how that affects your neural network model. (you will need to change your model to accept more inputs)\n",
        "- After feature engineering, which model sees a greater accuracy boost due to the new features?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NLTAR87uYJ-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d3cbc582-ff2c-4a76-a620-ce597bb9aab3"
      },
      "source": [
        "##### Your Code Here #####\n",
        "\n",
        "import tensorflow\n",
        "tensorflow.__version__"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.13.1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Co3IX2YCU2Un",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.datasets import boston_housing\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout  # Stretch - use dropout!\n",
        "import numpy as np\n",
        "# fix random seed for reproducibility\n",
        "np.random.seed(42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHCaBY6kWtyS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = boston_housing.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gd3cKu4jX53t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 1000\n",
        "\n",
        "(X_train,y_train),(X_test,y_test) = boston_housing.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRtEUaQEs7Z_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0352cc68-9447-4d6b-b9dd-a25c980c57ca"
      },
      "source": [
        "X_train[0].shape"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BaI9AnEG0nyI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "3fe98a11-cceb-4328-93b2-2db49e415d09"
      },
      "source": [
        "X_train[0]"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  1.23247,   0.     ,   8.14   ,   0.     ,   0.538  ,   6.142  ,\n",
              "        91.7    ,   3.9769 ,   4.     , 307.     ,  21.     , 396.9    ,\n",
              "        18.72   ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDEhWZ1Zs8IW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ef83dc88-d3e8-4710-b723-2f95e90f5e37"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(404,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUcMnHcJtCa-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "outputId": "4b495308-39cb-42a3-8dce-a5777c3fc37e"
      },
      "source": [
        "y_train"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([15.2, 42.3, 50. , 21.1, 17.7, 18.5, 11.3, 15.6, 15.6, 14.4, 12.1,\n",
              "       17.9, 23.1, 19.9, 15.7,  8.8, 50. , 22.5, 24.1, 27.5, 10.9, 30.8,\n",
              "       32.9, 24. , 18.5, 13.3, 22.9, 34.7, 16.6, 17.5, 22.3, 16.1, 14.9,\n",
              "       23.1, 34.9, 25. , 13.9, 13.1, 20.4, 20. , 15.2, 24.7, 22.2, 16.7,\n",
              "       12.7, 15.6, 18.4, 21. , 30.1, 15.1, 18.7,  9.6, 31.5, 24.8, 19.1,\n",
              "       22. , 14.5, 11. , 32. , 29.4, 20.3, 24.4, 14.6, 19.5, 14.1, 14.3,\n",
              "       15.6, 10.5,  6.3, 19.3, 19.3, 13.4, 36.4, 17.8, 13.5, 16.5,  8.3,\n",
              "       14.3, 16. , 13.4, 28.6, 43.5, 20.2, 22. , 23. , 20.7, 12.5, 48.5,\n",
              "       14.6, 13.4, 23.7, 50. , 21.7, 39.8, 38.7, 22.2, 34.9, 22.5, 31.1,\n",
              "       28.7, 46. , 41.7, 21. , 26.6, 15. , 24.4, 13.3, 21.2, 11.7, 21.7,\n",
              "       19.4, 50. , 22.8, 19.7, 24.7, 36.2, 14.2, 18.9, 18.3, 20.6, 24.6,\n",
              "       18.2,  8.7, 44. , 10.4, 13.2, 21.2, 37. , 30.7, 22.9, 20. , 19.3,\n",
              "       31.7, 32. , 23.1, 18.8, 10.9, 50. , 19.6,  5. , 14.4, 19.8, 13.8,\n",
              "       19.6, 23.9, 24.5, 25. , 19.9, 17.2, 24.6, 13.5, 26.6, 21.4, 11.9,\n",
              "       22.6, 19.6,  8.5, 23.7, 23.1, 22.4, 20.5, 23.6, 18.4, 35.2, 23.1,\n",
              "       27.9, 20.6, 23.7, 28. , 13.6, 27.1, 23.6, 20.6, 18.2, 21.7, 17.1,\n",
              "        8.4, 25.3, 13.8, 22.2, 18.4, 20.7, 31.6, 30.5, 20.3,  8.8, 19.2,\n",
              "       19.4, 23.1, 23. , 14.8, 48.8, 22.6, 33.4, 21.1, 13.6, 32.2, 13.1,\n",
              "       23.4, 18.9, 23.9, 11.8, 23.3, 22.8, 19.6, 16.7, 13.4, 22.2, 20.4,\n",
              "       21.8, 26.4, 14.9, 24.1, 23.8, 12.3, 29.1, 21. , 19.5, 23.3, 23.8,\n",
              "       17.8, 11.5, 21.7, 19.9, 25. , 33.4, 28.5, 21.4, 24.3, 27.5, 33.1,\n",
              "       16.2, 23.3, 48.3, 22.9, 22.8, 13.1, 12.7, 22.6, 15. , 15.3, 10.5,\n",
              "       24. , 18.5, 21.7, 19.5, 33.2, 23.2,  5. , 19.1, 12.7, 22.3, 10.2,\n",
              "       13.9, 16.3, 17. , 20.1, 29.9, 17.2, 37.3, 45.4, 17.8, 23.2, 29. ,\n",
              "       22. , 18. , 17.4, 34.6, 20.1, 25. , 15.6, 24.8, 28.2, 21.2, 21.4,\n",
              "       23.8, 31. , 26.2, 17.4, 37.9, 17.5, 20. ,  8.3, 23.9,  8.4, 13.8,\n",
              "        7.2, 11.7, 17.1, 21.6, 50. , 16.1, 20.4, 20.6, 21.4, 20.6, 36.5,\n",
              "        8.5, 24.8, 10.8, 21.9, 17.3, 18.9, 36.2, 14.9, 18.2, 33.3, 21.8,\n",
              "       19.7, 31.6, 24.8, 19.4, 22.8,  7.5, 44.8, 16.8, 18.7, 50. , 50. ,\n",
              "       19.5, 20.1, 50. , 17.2, 20.8, 19.3, 41.3, 20.4, 20.5, 13.8, 16.5,\n",
              "       23.9, 20.6, 31.5, 23.3, 16.8, 14. , 33.8, 36.1, 12.8, 18.3, 18.7,\n",
              "       19.1, 29. , 30.1, 50. , 50. , 22. , 11.9, 37.6, 50. , 22.7, 20.8,\n",
              "       23.5, 27.9, 50. , 19.3, 23.9, 22.6, 15.2, 21.7, 19.2, 43.8, 20.3,\n",
              "       33.2, 19.9, 22.5, 32.7, 22. , 17.1, 19. , 15. , 16.1, 25.1, 23.7,\n",
              "       28.7, 37.2, 22.6, 16.4, 25. , 29.8, 22.1, 17.4, 18.1, 30.3, 17.5,\n",
              "       24.7, 12.6, 26.5, 28.7, 13.3, 10.4, 24.4, 23. , 20. , 17.8,  7. ,\n",
              "       11.8, 24.4, 13.8, 19.4, 25.2, 19.4, 19.4, 29.1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiAKh3mMW0c3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "609ed567-318d-46bc-ac69-922153035358"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(404, 13)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4IRYGZwtNKl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = keras.utils.normalize(X_train, axis=-1, order=2)\n",
        "X_test = keras.utils.normalize(X_test, axis=-1, order=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "014kHPlp05y_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "cf95838d-b4c0-4566-a85c-a24102e34f27"
      },
      "source": [
        "X_test[0]"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.02675675, 0.        , 0.02677953, 0.        , 0.0010046 ,\n",
              "       0.00951931, 0.14795322, 0.0027145 , 0.03550877, 0.98536841,\n",
              "       0.02988655, 0.04031725, 0.04298041])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kz0T2-mut8hp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9da7ca8b-d509-45ef-b075-c4163dd03597"
      },
      "source": [
        "y_train[0:20]"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([15.2, 42.3, 50. , 21.1, 17.7, 18.5, 11.3, 15.6, 15.6, 14.4, 12.1,\n",
              "       17.9, 23.1, 19.9, 15.7,  8.8, 50. , 22.5, 24.1, 27.5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xX0P2StNW4_O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "eff11825-6d56-449e-8e51-8c33c5fc49bb"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(13, input_dim=13, activation='relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(13, activation='relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(1,activation='linear'))\n",
        "\n",
        "model.compile(loss='mean_squared_error',\n",
        "              optimizer='adam',\n",
        "              metrics=['mean_squared_error'])\n",
        "model.compile(optimizer='rmsprop', \n",
        "              loss='mean_squared_error', \n",
        "              metrics=['mean_squared_error'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_8 (Dense)              (None, 13)                182       \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 13)                0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 13)                182       \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 13)                0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 1)                 14        \n",
            "=================================================================\n",
            "Total params: 378\n",
            "Trainable params: 378\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wS-D6rol1x9V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34088
        },
        "outputId": "dd442707-5dd2-46db-e832-e7e15860dd8e"
      },
      "source": [
        "model.fit(X_train, y_train, epochs=epochs, validation_split=.1)\n",
        "test_scores = model.evaluate(X_test, y_test)\n",
        "\n",
        "print(f'After {epochs} epochs: ', f'{model.metrics_names[0]}: {test_scores[1]}')"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 363 samples, validate on 41 samples\n",
            "Epoch 1/1000\n",
            "363/363 [==============================] - 0s 642us/step - loss: 584.6028 - mean_squared_error: 584.6028 - val_loss: 492.5116 - val_mean_squared_error: 492.5116\n",
            "Epoch 2/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 578.5777 - mean_squared_error: 578.5777 - val_loss: 487.3837 - val_mean_squared_error: 487.3837\n",
            "Epoch 3/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 573.2931 - mean_squared_error: 573.2931 - val_loss: 481.9057 - val_mean_squared_error: 481.9057\n",
            "Epoch 4/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 567.6832 - mean_squared_error: 567.6832 - val_loss: 475.9875 - val_mean_squared_error: 475.9875\n",
            "Epoch 5/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 561.1107 - mean_squared_error: 561.1107 - val_loss: 469.5503 - val_mean_squared_error: 469.5503\n",
            "Epoch 6/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 553.3391 - mean_squared_error: 553.3391 - val_loss: 462.4355 - val_mean_squared_error: 462.4355\n",
            "Epoch 7/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 546.1288 - mean_squared_error: 546.1288 - val_loss: 454.7117 - val_mean_squared_error: 454.7117\n",
            "Epoch 8/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 537.4343 - mean_squared_error: 537.4343 - val_loss: 446.5289 - val_mean_squared_error: 446.5289\n",
            "Epoch 9/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 530.3821 - mean_squared_error: 530.3821 - val_loss: 437.9377 - val_mean_squared_error: 437.9377\n",
            "Epoch 10/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 517.8151 - mean_squared_error: 517.8151 - val_loss: 428.1439 - val_mean_squared_error: 428.1439\n",
            "Epoch 11/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 507.5467 - mean_squared_error: 507.5467 - val_loss: 417.7954 - val_mean_squared_error: 417.7954\n",
            "Epoch 12/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 496.7477 - mean_squared_error: 496.7477 - val_loss: 406.7940 - val_mean_squared_error: 406.7940\n",
            "Epoch 13/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 486.6463 - mean_squared_error: 486.6463 - val_loss: 395.2499 - val_mean_squared_error: 395.2499\n",
            "Epoch 14/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 472.4564 - mean_squared_error: 472.4564 - val_loss: 382.4758 - val_mean_squared_error: 382.4758\n",
            "Epoch 15/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 458.3703 - mean_squared_error: 458.3703 - val_loss: 369.1601 - val_mean_squared_error: 369.1601\n",
            "Epoch 16/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 448.4127 - mean_squared_error: 448.4127 - val_loss: 355.3875 - val_mean_squared_error: 355.3875\n",
            "Epoch 17/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 429.4255 - mean_squared_error: 429.4255 - val_loss: 340.2424 - val_mean_squared_error: 340.2424\n",
            "Epoch 18/1000\n",
            "363/363 [==============================] - 0s 42us/step - loss: 414.1960 - mean_squared_error: 414.1960 - val_loss: 324.8485 - val_mean_squared_error: 324.8485\n",
            "Epoch 19/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 396.0030 - mean_squared_error: 396.0030 - val_loss: 308.4688 - val_mean_squared_error: 308.4688\n",
            "Epoch 20/1000\n",
            "363/363 [==============================] - 0s 39us/step - loss: 384.5677 - mean_squared_error: 384.5677 - val_loss: 292.2807 - val_mean_squared_error: 292.2807\n",
            "Epoch 21/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 362.5718 - mean_squared_error: 362.5718 - val_loss: 275.8167 - val_mean_squared_error: 275.8167\n",
            "Epoch 22/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 343.9639 - mean_squared_error: 343.9639 - val_loss: 258.2849 - val_mean_squared_error: 258.2849\n",
            "Epoch 23/1000\n",
            "363/363 [==============================] - 0s 41us/step - loss: 327.7158 - mean_squared_error: 327.7158 - val_loss: 240.8536 - val_mean_squared_error: 240.8536\n",
            "Epoch 24/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 304.1754 - mean_squared_error: 304.1754 - val_loss: 223.0408 - val_mean_squared_error: 223.0408\n",
            "Epoch 25/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 289.0372 - mean_squared_error: 289.0372 - val_loss: 205.4125 - val_mean_squared_error: 205.4125\n",
            "Epoch 26/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 267.7575 - mean_squared_error: 267.7575 - val_loss: 187.6442 - val_mean_squared_error: 187.6442\n",
            "Epoch 27/1000\n",
            "363/363 [==============================] - 0s 37us/step - loss: 256.7689 - mean_squared_error: 256.7689 - val_loss: 170.3456 - val_mean_squared_error: 170.3456\n",
            "Epoch 28/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 231.5839 - mean_squared_error: 231.5839 - val_loss: 153.3293 - val_mean_squared_error: 153.3293\n",
            "Epoch 29/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 217.6778 - mean_squared_error: 217.6778 - val_loss: 136.8936 - val_mean_squared_error: 136.8936\n",
            "Epoch 30/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 197.2774 - mean_squared_error: 197.2774 - val_loss: 120.8478 - val_mean_squared_error: 120.8478\n",
            "Epoch 31/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 184.1085 - mean_squared_error: 184.1085 - val_loss: 106.1239 - val_mean_squared_error: 106.1239\n",
            "Epoch 32/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 170.0829 - mean_squared_error: 170.0829 - val_loss: 92.3950 - val_mean_squared_error: 92.3950\n",
            "Epoch 33/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 153.0788 - mean_squared_error: 153.0788 - val_loss: 80.1802 - val_mean_squared_error: 80.1802\n",
            "Epoch 34/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 141.0662 - mean_squared_error: 141.0662 - val_loss: 69.4785 - val_mean_squared_error: 69.4785\n",
            "Epoch 35/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 129.5481 - mean_squared_error: 129.5481 - val_loss: 59.8113 - val_mean_squared_error: 59.8113\n",
            "Epoch 36/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 117.2502 - mean_squared_error: 117.2502 - val_loss: 52.4934 - val_mean_squared_error: 52.4934\n",
            "Epoch 37/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 116.1149 - mean_squared_error: 116.1149 - val_loss: 46.8782 - val_mean_squared_error: 46.8782\n",
            "Epoch 38/1000\n",
            "363/363 [==============================] - 0s 41us/step - loss: 114.1556 - mean_squared_error: 114.1556 - val_loss: 43.4975 - val_mean_squared_error: 43.4975\n",
            "Epoch 39/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 108.7125 - mean_squared_error: 108.7125 - val_loss: 41.0367 - val_mean_squared_error: 41.0367\n",
            "Epoch 40/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 105.6555 - mean_squared_error: 105.6555 - val_loss: 39.6708 - val_mean_squared_error: 39.6708\n",
            "Epoch 41/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 98.9858 - mean_squared_error: 98.9858 - val_loss: 39.0366 - val_mean_squared_error: 39.0366\n",
            "Epoch 42/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 103.1488 - mean_squared_error: 103.1488 - val_loss: 38.6613 - val_mean_squared_error: 38.6613\n",
            "Epoch 43/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 102.9052 - mean_squared_error: 102.9052 - val_loss: 38.2826 - val_mean_squared_error: 38.2826\n",
            "Epoch 44/1000\n",
            "363/363 [==============================] - 0s 41us/step - loss: 98.3318 - mean_squared_error: 98.3318 - val_loss: 37.9374 - val_mean_squared_error: 37.9374\n",
            "Epoch 45/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 104.6911 - mean_squared_error: 104.6911 - val_loss: 37.6121 - val_mean_squared_error: 37.6121\n",
            "Epoch 46/1000\n",
            "363/363 [==============================] - 0s 37us/step - loss: 107.0010 - mean_squared_error: 107.0010 - val_loss: 37.2586 - val_mean_squared_error: 37.2586\n",
            "Epoch 47/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 102.7701 - mean_squared_error: 102.7701 - val_loss: 36.9617 - val_mean_squared_error: 36.9617\n",
            "Epoch 48/1000\n",
            "363/363 [==============================] - 0s 40us/step - loss: 97.0622 - mean_squared_error: 97.0622 - val_loss: 36.7027 - val_mean_squared_error: 36.7027\n",
            "Epoch 49/1000\n",
            "363/363 [==============================] - 0s 42us/step - loss: 102.7662 - mean_squared_error: 102.7662 - val_loss: 36.4037 - val_mean_squared_error: 36.4037\n",
            "Epoch 50/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 98.1502 - mean_squared_error: 98.1502 - val_loss: 36.1477 - val_mean_squared_error: 36.1477\n",
            "Epoch 51/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 95.0979 - mean_squared_error: 95.0979 - val_loss: 35.8073 - val_mean_squared_error: 35.8073\n",
            "Epoch 52/1000\n",
            "363/363 [==============================] - 0s 40us/step - loss: 104.1964 - mean_squared_error: 104.1964 - val_loss: 35.5170 - val_mean_squared_error: 35.5170\n",
            "Epoch 53/1000\n",
            "363/363 [==============================] - 0s 42us/step - loss: 102.0313 - mean_squared_error: 102.0313 - val_loss: 35.1838 - val_mean_squared_error: 35.1838\n",
            "Epoch 54/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 98.4202 - mean_squared_error: 98.4202 - val_loss: 34.8794 - val_mean_squared_error: 34.8794\n",
            "Epoch 55/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 98.2414 - mean_squared_error: 98.2414 - val_loss: 34.6197 - val_mean_squared_error: 34.6197\n",
            "Epoch 56/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 100.2624 - mean_squared_error: 100.2624 - val_loss: 34.2772 - val_mean_squared_error: 34.2772\n",
            "Epoch 57/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 93.3164 - mean_squared_error: 93.3164 - val_loss: 34.0811 - val_mean_squared_error: 34.0811\n",
            "Epoch 58/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 99.8227 - mean_squared_error: 99.8227 - val_loss: 33.8187 - val_mean_squared_error: 33.8187\n",
            "Epoch 59/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 96.1428 - mean_squared_error: 96.1428 - val_loss: 33.6152 - val_mean_squared_error: 33.6152\n",
            "Epoch 60/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 98.8976 - mean_squared_error: 98.8976 - val_loss: 33.2945 - val_mean_squared_error: 33.2945\n",
            "Epoch 61/1000\n",
            "363/363 [==============================] - 0s 58us/step - loss: 94.5981 - mean_squared_error: 94.5981 - val_loss: 33.0936 - val_mean_squared_error: 33.0936\n",
            "Epoch 62/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 98.4578 - mean_squared_error: 98.4578 - val_loss: 32.8392 - val_mean_squared_error: 32.8392\n",
            "Epoch 63/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 91.4897 - mean_squared_error: 91.4897 - val_loss: 32.6176 - val_mean_squared_error: 32.6176\n",
            "Epoch 64/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 106.9500 - mean_squared_error: 106.9500 - val_loss: 32.3691 - val_mean_squared_error: 32.3691\n",
            "Epoch 65/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 104.5965 - mean_squared_error: 104.5965 - val_loss: 32.1789 - val_mean_squared_error: 32.1789\n",
            "Epoch 66/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 99.8466 - mean_squared_error: 99.8466 - val_loss: 31.9796 - val_mean_squared_error: 31.9796\n",
            "Epoch 67/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 87.6702 - mean_squared_error: 87.6702 - val_loss: 31.7239 - val_mean_squared_error: 31.7239\n",
            "Epoch 68/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 93.7692 - mean_squared_error: 93.7692 - val_loss: 31.4819 - val_mean_squared_error: 31.4819\n",
            "Epoch 69/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 103.5019 - mean_squared_error: 103.5019 - val_loss: 31.1929 - val_mean_squared_error: 31.1929\n",
            "Epoch 70/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 97.2929 - mean_squared_error: 97.2929 - val_loss: 30.9983 - val_mean_squared_error: 30.9983\n",
            "Epoch 71/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 107.9772 - mean_squared_error: 107.9772 - val_loss: 30.8818 - val_mean_squared_error: 30.8818\n",
            "Epoch 72/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 89.9577 - mean_squared_error: 89.9577 - val_loss: 30.5718 - val_mean_squared_error: 30.5718\n",
            "Epoch 73/1000\n",
            "363/363 [==============================] - 0s 42us/step - loss: 92.8483 - mean_squared_error: 92.8483 - val_loss: 30.3590 - val_mean_squared_error: 30.3590\n",
            "Epoch 74/1000\n",
            "363/363 [==============================] - 0s 40us/step - loss: 92.2204 - mean_squared_error: 92.2204 - val_loss: 30.2830 - val_mean_squared_error: 30.2830\n",
            "Epoch 75/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 90.4321 - mean_squared_error: 90.4321 - val_loss: 30.0914 - val_mean_squared_error: 30.0914\n",
            "Epoch 76/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 94.9081 - mean_squared_error: 94.9081 - val_loss: 29.8732 - val_mean_squared_error: 29.8732\n",
            "Epoch 77/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 95.8678 - mean_squared_error: 95.8678 - val_loss: 29.5772 - val_mean_squared_error: 29.5772\n",
            "Epoch 78/1000\n",
            "363/363 [==============================] - 0s 40us/step - loss: 84.0101 - mean_squared_error: 84.0101 - val_loss: 29.4150 - val_mean_squared_error: 29.4150\n",
            "Epoch 79/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 87.7454 - mean_squared_error: 87.7454 - val_loss: 29.2506 - val_mean_squared_error: 29.2506\n",
            "Epoch 80/1000\n",
            "363/363 [==============================] - 0s 42us/step - loss: 97.1808 - mean_squared_error: 97.1808 - val_loss: 29.0209 - val_mean_squared_error: 29.0209\n",
            "Epoch 81/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 87.7713 - mean_squared_error: 87.7713 - val_loss: 28.8869 - val_mean_squared_error: 28.8869\n",
            "Epoch 82/1000\n",
            "363/363 [==============================] - 0s 41us/step - loss: 94.1331 - mean_squared_error: 94.1331 - val_loss: 28.7317 - val_mean_squared_error: 28.7317\n",
            "Epoch 83/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 92.2498 - mean_squared_error: 92.2498 - val_loss: 28.5802 - val_mean_squared_error: 28.5802\n",
            "Epoch 84/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 100.6781 - mean_squared_error: 100.6781 - val_loss: 28.3259 - val_mean_squared_error: 28.3259\n",
            "Epoch 85/1000\n",
            "363/363 [==============================] - 0s 41us/step - loss: 87.2871 - mean_squared_error: 87.2871 - val_loss: 28.1834 - val_mean_squared_error: 28.1834\n",
            "Epoch 86/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 87.6122 - mean_squared_error: 87.6122 - val_loss: 28.0395 - val_mean_squared_error: 28.0395\n",
            "Epoch 87/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 84.7071 - mean_squared_error: 84.7071 - val_loss: 27.8690 - val_mean_squared_error: 27.8690\n",
            "Epoch 88/1000\n",
            "363/363 [==============================] - 0s 41us/step - loss: 98.2001 - mean_squared_error: 98.2001 - val_loss: 27.7430 - val_mean_squared_error: 27.7430\n",
            "Epoch 89/1000\n",
            "363/363 [==============================] - 0s 41us/step - loss: 86.7180 - mean_squared_error: 86.7180 - val_loss: 27.5829 - val_mean_squared_error: 27.5829\n",
            "Epoch 90/1000\n",
            "363/363 [==============================] - 0s 37us/step - loss: 88.8102 - mean_squared_error: 88.8102 - val_loss: 27.3763 - val_mean_squared_error: 27.3763\n",
            "Epoch 91/1000\n",
            "363/363 [==============================] - 0s 42us/step - loss: 85.4694 - mean_squared_error: 85.4694 - val_loss: 27.2834 - val_mean_squared_error: 27.2834\n",
            "Epoch 92/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 88.4028 - mean_squared_error: 88.4028 - val_loss: 27.1082 - val_mean_squared_error: 27.1082\n",
            "Epoch 93/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 92.6588 - mean_squared_error: 92.6588 - val_loss: 26.9385 - val_mean_squared_error: 26.9385\n",
            "Epoch 94/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 85.1605 - mean_squared_error: 85.1605 - val_loss: 26.9272 - val_mean_squared_error: 26.9272\n",
            "Epoch 95/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 88.8329 - mean_squared_error: 88.8329 - val_loss: 26.8654 - val_mean_squared_error: 26.8654\n",
            "Epoch 96/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 86.1093 - mean_squared_error: 86.1093 - val_loss: 26.6758 - val_mean_squared_error: 26.6758\n",
            "Epoch 97/1000\n",
            "363/363 [==============================] - 0s 41us/step - loss: 90.9473 - mean_squared_error: 90.9473 - val_loss: 26.5065 - val_mean_squared_error: 26.5065\n",
            "Epoch 98/1000\n",
            "363/363 [==============================] - 0s 41us/step - loss: 83.1008 - mean_squared_error: 83.1008 - val_loss: 26.2549 - val_mean_squared_error: 26.2549\n",
            "Epoch 99/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 79.7186 - mean_squared_error: 79.7186 - val_loss: 26.1163 - val_mean_squared_error: 26.1163\n",
            "Epoch 100/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 87.8707 - mean_squared_error: 87.8707 - val_loss: 25.9799 - val_mean_squared_error: 25.9799\n",
            "Epoch 101/1000\n",
            "363/363 [==============================] - 0s 42us/step - loss: 99.3553 - mean_squared_error: 99.3553 - val_loss: 25.8752 - val_mean_squared_error: 25.8752\n",
            "Epoch 102/1000\n",
            "363/363 [==============================] - 0s 42us/step - loss: 83.5691 - mean_squared_error: 83.5691 - val_loss: 25.7040 - val_mean_squared_error: 25.7040\n",
            "Epoch 103/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 90.9866 - mean_squared_error: 90.9866 - val_loss: 25.7647 - val_mean_squared_error: 25.7647\n",
            "Epoch 104/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 86.7656 - mean_squared_error: 86.7656 - val_loss: 25.6677 - val_mean_squared_error: 25.6677\n",
            "Epoch 105/1000\n",
            "363/363 [==============================] - 0s 38us/step - loss: 73.9852 - mean_squared_error: 73.9852 - val_loss: 25.4170 - val_mean_squared_error: 25.4170\n",
            "Epoch 106/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 93.7728 - mean_squared_error: 93.7728 - val_loss: 25.2263 - val_mean_squared_error: 25.2263\n",
            "Epoch 107/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 88.9909 - mean_squared_error: 88.9909 - val_loss: 25.2743 - val_mean_squared_error: 25.2743\n",
            "Epoch 108/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 87.2920 - mean_squared_error: 87.2920 - val_loss: 25.2258 - val_mean_squared_error: 25.2258\n",
            "Epoch 109/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 91.7340 - mean_squared_error: 91.7340 - val_loss: 25.1166 - val_mean_squared_error: 25.1166\n",
            "Epoch 110/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 82.4743 - mean_squared_error: 82.4743 - val_loss: 25.0860 - val_mean_squared_error: 25.0860\n",
            "Epoch 111/1000\n",
            "363/363 [==============================] - 0s 40us/step - loss: 90.4184 - mean_squared_error: 90.4184 - val_loss: 24.8519 - val_mean_squared_error: 24.8519\n",
            "Epoch 112/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 87.4514 - mean_squared_error: 87.4514 - val_loss: 24.6626 - val_mean_squared_error: 24.6626\n",
            "Epoch 113/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 91.1754 - mean_squared_error: 91.1754 - val_loss: 24.5370 - val_mean_squared_error: 24.5370\n",
            "Epoch 114/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 86.6041 - mean_squared_error: 86.6041 - val_loss: 24.4184 - val_mean_squared_error: 24.4184\n",
            "Epoch 115/1000\n",
            "363/363 [==============================] - 0s 59us/step - loss: 78.1091 - mean_squared_error: 78.1091 - val_loss: 24.4407 - val_mean_squared_error: 24.4407\n",
            "Epoch 116/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 84.6041 - mean_squared_error: 84.6041 - val_loss: 24.2344 - val_mean_squared_error: 24.2344\n",
            "Epoch 117/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 83.0342 - mean_squared_error: 83.0342 - val_loss: 24.1344 - val_mean_squared_error: 24.1344\n",
            "Epoch 118/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 83.9460 - mean_squared_error: 83.9460 - val_loss: 24.0579 - val_mean_squared_error: 24.0579\n",
            "Epoch 119/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 84.6520 - mean_squared_error: 84.6520 - val_loss: 23.9746 - val_mean_squared_error: 23.9746\n",
            "Epoch 120/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 90.0704 - mean_squared_error: 90.0704 - val_loss: 23.8988 - val_mean_squared_error: 23.8988\n",
            "Epoch 121/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 80.3256 - mean_squared_error: 80.3256 - val_loss: 23.7971 - val_mean_squared_error: 23.7971\n",
            "Epoch 122/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 81.1923 - mean_squared_error: 81.1923 - val_loss: 23.7335 - val_mean_squared_error: 23.7335\n",
            "Epoch 123/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 83.6563 - mean_squared_error: 83.6563 - val_loss: 23.6995 - val_mean_squared_error: 23.6995\n",
            "Epoch 124/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 86.9577 - mean_squared_error: 86.9577 - val_loss: 23.5661 - val_mean_squared_error: 23.5661\n",
            "Epoch 125/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 87.1827 - mean_squared_error: 87.1827 - val_loss: 23.4678 - val_mean_squared_error: 23.4678\n",
            "Epoch 126/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 83.6336 - mean_squared_error: 83.6336 - val_loss: 23.3493 - val_mean_squared_error: 23.3493\n",
            "Epoch 127/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 84.9155 - mean_squared_error: 84.9155 - val_loss: 23.2800 - val_mean_squared_error: 23.2800\n",
            "Epoch 128/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 77.7492 - mean_squared_error: 77.7492 - val_loss: 23.2605 - val_mean_squared_error: 23.2605\n",
            "Epoch 129/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 86.1537 - mean_squared_error: 86.1537 - val_loss: 23.1687 - val_mean_squared_error: 23.1687\n",
            "Epoch 130/1000\n",
            "363/363 [==============================] - 0s 42us/step - loss: 84.9651 - mean_squared_error: 84.9651 - val_loss: 23.0861 - val_mean_squared_error: 23.0861\n",
            "Epoch 131/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 84.3336 - mean_squared_error: 84.3336 - val_loss: 23.1150 - val_mean_squared_error: 23.1150\n",
            "Epoch 132/1000\n",
            "363/363 [==============================] - 0s 55us/step - loss: 88.3550 - mean_squared_error: 88.3550 - val_loss: 22.9522 - val_mean_squared_error: 22.9522\n",
            "Epoch 133/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 79.0000 - mean_squared_error: 79.0000 - val_loss: 22.8778 - val_mean_squared_error: 22.8778\n",
            "Epoch 134/1000\n",
            "363/363 [==============================] - 0s 42us/step - loss: 82.1826 - mean_squared_error: 82.1826 - val_loss: 22.8722 - val_mean_squared_error: 22.8722\n",
            "Epoch 135/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 77.5831 - mean_squared_error: 77.5831 - val_loss: 22.8406 - val_mean_squared_error: 22.8406\n",
            "Epoch 136/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 84.2538 - mean_squared_error: 84.2538 - val_loss: 22.6997 - val_mean_squared_error: 22.6997\n",
            "Epoch 137/1000\n",
            "363/363 [==============================] - 0s 40us/step - loss: 84.0258 - mean_squared_error: 84.0258 - val_loss: 22.7136 - val_mean_squared_error: 22.7136\n",
            "Epoch 138/1000\n",
            "363/363 [==============================] - 0s 41us/step - loss: 84.9131 - mean_squared_error: 84.9131 - val_loss: 22.7299 - val_mean_squared_error: 22.7299\n",
            "Epoch 139/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 80.7753 - mean_squared_error: 80.7753 - val_loss: 22.5621 - val_mean_squared_error: 22.5621\n",
            "Epoch 140/1000\n",
            "363/363 [==============================] - 0s 42us/step - loss: 79.5103 - mean_squared_error: 79.5103 - val_loss: 22.4646 - val_mean_squared_error: 22.4646\n",
            "Epoch 141/1000\n",
            "363/363 [==============================] - 0s 42us/step - loss: 81.6935 - mean_squared_error: 81.6935 - val_loss: 22.4627 - val_mean_squared_error: 22.4627\n",
            "Epoch 142/1000\n",
            "363/363 [==============================] - 0s 38us/step - loss: 82.8240 - mean_squared_error: 82.8240 - val_loss: 22.4274 - val_mean_squared_error: 22.4274\n",
            "Epoch 143/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 83.8865 - mean_squared_error: 83.8865 - val_loss: 22.4329 - val_mean_squared_error: 22.4329\n",
            "Epoch 144/1000\n",
            "363/363 [==============================] - 0s 42us/step - loss: 82.9570 - mean_squared_error: 82.9570 - val_loss: 22.3276 - val_mean_squared_error: 22.3276\n",
            "Epoch 145/1000\n",
            "363/363 [==============================] - 0s 36us/step - loss: 73.6931 - mean_squared_error: 73.6931 - val_loss: 22.2444 - val_mean_squared_error: 22.2444\n",
            "Epoch 146/1000\n",
            "363/363 [==============================] - 0s 40us/step - loss: 82.1911 - mean_squared_error: 82.1911 - val_loss: 22.1610 - val_mean_squared_error: 22.1610\n",
            "Epoch 147/1000\n",
            "363/363 [==============================] - 0s 41us/step - loss: 89.6095 - mean_squared_error: 89.6095 - val_loss: 22.0890 - val_mean_squared_error: 22.0890\n",
            "Epoch 148/1000\n",
            "363/363 [==============================] - 0s 40us/step - loss: 85.8358 - mean_squared_error: 85.8358 - val_loss: 22.0434 - val_mean_squared_error: 22.0434\n",
            "Epoch 149/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 81.2502 - mean_squared_error: 81.2502 - val_loss: 22.0771 - val_mean_squared_error: 22.0771\n",
            "Epoch 150/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 78.2600 - mean_squared_error: 78.2600 - val_loss: 22.1274 - val_mean_squared_error: 22.1274\n",
            "Epoch 151/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 78.9656 - mean_squared_error: 78.9656 - val_loss: 21.9079 - val_mean_squared_error: 21.9079\n",
            "Epoch 152/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 83.9001 - mean_squared_error: 83.9001 - val_loss: 21.8708 - val_mean_squared_error: 21.8708\n",
            "Epoch 153/1000\n",
            "363/363 [==============================] - 0s 39us/step - loss: 89.0313 - mean_squared_error: 89.0313 - val_loss: 21.8162 - val_mean_squared_error: 21.8162\n",
            "Epoch 154/1000\n",
            "363/363 [==============================] - 0s 42us/step - loss: 78.2005 - mean_squared_error: 78.2005 - val_loss: 21.8708 - val_mean_squared_error: 21.8708\n",
            "Epoch 155/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 80.4372 - mean_squared_error: 80.4372 - val_loss: 21.8431 - val_mean_squared_error: 21.8431\n",
            "Epoch 156/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 76.2739 - mean_squared_error: 76.2739 - val_loss: 22.0103 - val_mean_squared_error: 22.0103\n",
            "Epoch 157/1000\n",
            "363/363 [==============================] - 0s 41us/step - loss: 83.6671 - mean_squared_error: 83.6671 - val_loss: 21.7203 - val_mean_squared_error: 21.7203\n",
            "Epoch 158/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 75.4416 - mean_squared_error: 75.4416 - val_loss: 21.6458 - val_mean_squared_error: 21.6458\n",
            "Epoch 159/1000\n",
            "363/363 [==============================] - 0s 42us/step - loss: 83.7793 - mean_squared_error: 83.7793 - val_loss: 21.6058 - val_mean_squared_error: 21.6058\n",
            "Epoch 160/1000\n",
            "363/363 [==============================] - 0s 40us/step - loss: 74.2224 - mean_squared_error: 74.2224 - val_loss: 21.5347 - val_mean_squared_error: 21.5347\n",
            "Epoch 161/1000\n",
            "363/363 [==============================] - 0s 39us/step - loss: 87.2029 - mean_squared_error: 87.2029 - val_loss: 21.5116 - val_mean_squared_error: 21.5116\n",
            "Epoch 162/1000\n",
            "363/363 [==============================] - 0s 42us/step - loss: 78.4091 - mean_squared_error: 78.4091 - val_loss: 21.4714 - val_mean_squared_error: 21.4714\n",
            "Epoch 163/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 77.7298 - mean_squared_error: 77.7298 - val_loss: 21.4790 - val_mean_squared_error: 21.4790\n",
            "Epoch 164/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 78.7393 - mean_squared_error: 78.7393 - val_loss: 21.3948 - val_mean_squared_error: 21.3948\n",
            "Epoch 165/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 73.8960 - mean_squared_error: 73.8960 - val_loss: 21.3657 - val_mean_squared_error: 21.3657\n",
            "Epoch 166/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 77.9713 - mean_squared_error: 77.9713 - val_loss: 21.3732 - val_mean_squared_error: 21.3732\n",
            "Epoch 167/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 79.3687 - mean_squared_error: 79.3687 - val_loss: 21.2700 - val_mean_squared_error: 21.2700\n",
            "Epoch 168/1000\n",
            "363/363 [==============================] - 0s 41us/step - loss: 80.5863 - mean_squared_error: 80.5863 - val_loss: 21.2546 - val_mean_squared_error: 21.2546\n",
            "Epoch 169/1000\n",
            "363/363 [==============================] - 0s 41us/step - loss: 79.0280 - mean_squared_error: 79.0280 - val_loss: 21.2331 - val_mean_squared_error: 21.2331\n",
            "Epoch 170/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 80.1791 - mean_squared_error: 80.1791 - val_loss: 21.1908 - val_mean_squared_error: 21.1908\n",
            "Epoch 171/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 76.0765 - mean_squared_error: 76.0765 - val_loss: 21.1536 - val_mean_squared_error: 21.1536\n",
            "Epoch 172/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 74.5708 - mean_squared_error: 74.5708 - val_loss: 21.1084 - val_mean_squared_error: 21.1084\n",
            "Epoch 173/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 79.0751 - mean_squared_error: 79.0751 - val_loss: 21.0651 - val_mean_squared_error: 21.0651\n",
            "Epoch 174/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 76.5452 - mean_squared_error: 76.5452 - val_loss: 21.0243 - val_mean_squared_error: 21.0243\n",
            "Epoch 175/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 80.0258 - mean_squared_error: 80.0258 - val_loss: 21.0390 - val_mean_squared_error: 21.0390\n",
            "Epoch 176/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 81.0722 - mean_squared_error: 81.0722 - val_loss: 20.9695 - val_mean_squared_error: 20.9695\n",
            "Epoch 177/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 80.3868 - mean_squared_error: 80.3868 - val_loss: 20.9471 - val_mean_squared_error: 20.9471\n",
            "Epoch 178/1000\n",
            "363/363 [==============================] - 0s 42us/step - loss: 75.4047 - mean_squared_error: 75.4047 - val_loss: 21.1217 - val_mean_squared_error: 21.1217\n",
            "Epoch 179/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 73.4433 - mean_squared_error: 73.4433 - val_loss: 21.0689 - val_mean_squared_error: 21.0689\n",
            "Epoch 180/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 72.4659 - mean_squared_error: 72.4659 - val_loss: 20.9125 - val_mean_squared_error: 20.9125\n",
            "Epoch 181/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 75.9168 - mean_squared_error: 75.9168 - val_loss: 21.1028 - val_mean_squared_error: 21.1028\n",
            "Epoch 182/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 75.0653 - mean_squared_error: 75.0653 - val_loss: 20.9228 - val_mean_squared_error: 20.9228\n",
            "Epoch 183/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 77.9937 - mean_squared_error: 77.9937 - val_loss: 20.8672 - val_mean_squared_error: 20.8672\n",
            "Epoch 184/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 78.8562 - mean_squared_error: 78.8562 - val_loss: 20.7978 - val_mean_squared_error: 20.7978\n",
            "Epoch 185/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 81.6720 - mean_squared_error: 81.6720 - val_loss: 20.7251 - val_mean_squared_error: 20.7251\n",
            "Epoch 186/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 81.4350 - mean_squared_error: 81.4350 - val_loss: 20.7798 - val_mean_squared_error: 20.7798\n",
            "Epoch 187/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 79.3124 - mean_squared_error: 79.3124 - val_loss: 20.9195 - val_mean_squared_error: 20.9195\n",
            "Epoch 188/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 77.7313 - mean_squared_error: 77.7313 - val_loss: 20.9127 - val_mean_squared_error: 20.9127\n",
            "Epoch 189/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 75.3664 - mean_squared_error: 75.3664 - val_loss: 20.6351 - val_mean_squared_error: 20.6351\n",
            "Epoch 190/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 72.1727 - mean_squared_error: 72.1727 - val_loss: 20.5958 - val_mean_squared_error: 20.5958\n",
            "Epoch 191/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 73.5570 - mean_squared_error: 73.5570 - val_loss: 20.5634 - val_mean_squared_error: 20.5634\n",
            "Epoch 192/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 80.9443 - mean_squared_error: 80.9443 - val_loss: 20.5956 - val_mean_squared_error: 20.5956\n",
            "Epoch 193/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 75.9365 - mean_squared_error: 75.9365 - val_loss: 20.7554 - val_mean_squared_error: 20.7554\n",
            "Epoch 194/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 73.3747 - mean_squared_error: 73.3747 - val_loss: 20.5682 - val_mean_squared_error: 20.5682\n",
            "Epoch 195/1000\n",
            "363/363 [==============================] - 0s 57us/step - loss: 80.0406 - mean_squared_error: 80.0406 - val_loss: 20.4958 - val_mean_squared_error: 20.4958\n",
            "Epoch 196/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 78.3070 - mean_squared_error: 78.3070 - val_loss: 20.4525 - val_mean_squared_error: 20.4525\n",
            "Epoch 197/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 83.2859 - mean_squared_error: 83.2859 - val_loss: 20.4117 - val_mean_squared_error: 20.4117\n",
            "Epoch 198/1000\n",
            "363/363 [==============================] - 0s 42us/step - loss: 78.9514 - mean_squared_error: 78.9514 - val_loss: 20.4970 - val_mean_squared_error: 20.4970\n",
            "Epoch 199/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 77.6781 - mean_squared_error: 77.6781 - val_loss: 20.5992 - val_mean_squared_error: 20.5992\n",
            "Epoch 200/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 77.6735 - mean_squared_error: 77.6735 - val_loss: 20.3996 - val_mean_squared_error: 20.3996\n",
            "Epoch 201/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 75.9229 - mean_squared_error: 75.9229 - val_loss: 20.3071 - val_mean_squared_error: 20.3071\n",
            "Epoch 202/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 73.4481 - mean_squared_error: 73.4481 - val_loss: 20.2875 - val_mean_squared_error: 20.2875\n",
            "Epoch 203/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 72.7511 - mean_squared_error: 72.7511 - val_loss: 20.2635 - val_mean_squared_error: 20.2635\n",
            "Epoch 204/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 71.9997 - mean_squared_error: 71.9997 - val_loss: 20.2975 - val_mean_squared_error: 20.2975\n",
            "Epoch 205/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 69.2719 - mean_squared_error: 69.2719 - val_loss: 20.3738 - val_mean_squared_error: 20.3738\n",
            "Epoch 206/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 81.0582 - mean_squared_error: 81.0582 - val_loss: 20.2003 - val_mean_squared_error: 20.2003\n",
            "Epoch 207/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 70.5668 - mean_squared_error: 70.5668 - val_loss: 20.1801 - val_mean_squared_error: 20.1801\n",
            "Epoch 208/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 80.2200 - mean_squared_error: 80.2200 - val_loss: 20.1567 - val_mean_squared_error: 20.1567\n",
            "Epoch 209/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 80.5146 - mean_squared_error: 80.5146 - val_loss: 20.1453 - val_mean_squared_error: 20.1453\n",
            "Epoch 210/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 79.0411 - mean_squared_error: 79.0411 - val_loss: 20.1251 - val_mean_squared_error: 20.1251\n",
            "Epoch 211/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 73.2013 - mean_squared_error: 73.2013 - val_loss: 20.1796 - val_mean_squared_error: 20.1796\n",
            "Epoch 212/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 72.3240 - mean_squared_error: 72.3240 - val_loss: 20.0934 - val_mean_squared_error: 20.0934\n",
            "Epoch 213/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 77.8092 - mean_squared_error: 77.8092 - val_loss: 20.0994 - val_mean_squared_error: 20.0994\n",
            "Epoch 214/1000\n",
            "363/363 [==============================] - 0s 40us/step - loss: 73.1828 - mean_squared_error: 73.1828 - val_loss: 20.0498 - val_mean_squared_error: 20.0498\n",
            "Epoch 215/1000\n",
            "363/363 [==============================] - 0s 58us/step - loss: 76.5671 - mean_squared_error: 76.5671 - val_loss: 20.1731 - val_mean_squared_error: 20.1731\n",
            "Epoch 216/1000\n",
            "363/363 [==============================] - 0s 84us/step - loss: 82.2604 - mean_squared_error: 82.2604 - val_loss: 20.0376 - val_mean_squared_error: 20.0376\n",
            "Epoch 217/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 77.8106 - mean_squared_error: 77.8106 - val_loss: 20.0170 - val_mean_squared_error: 20.0170\n",
            "Epoch 218/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 74.8475 - mean_squared_error: 74.8475 - val_loss: 19.9934 - val_mean_squared_error: 19.9934\n",
            "Epoch 219/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 80.0696 - mean_squared_error: 80.0696 - val_loss: 19.9711 - val_mean_squared_error: 19.9711\n",
            "Epoch 220/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 76.7469 - mean_squared_error: 76.7469 - val_loss: 19.9543 - val_mean_squared_error: 19.9543\n",
            "Epoch 221/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 76.2360 - mean_squared_error: 76.2360 - val_loss: 20.0374 - val_mean_squared_error: 20.0374\n",
            "Epoch 222/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 79.4146 - mean_squared_error: 79.4146 - val_loss: 19.9489 - val_mean_squared_error: 19.9489\n",
            "Epoch 223/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 77.1045 - mean_squared_error: 77.1045 - val_loss: 19.8907 - val_mean_squared_error: 19.8907\n",
            "Epoch 224/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 78.2196 - mean_squared_error: 78.2196 - val_loss: 19.9091 - val_mean_squared_error: 19.9091\n",
            "Epoch 225/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 76.8042 - mean_squared_error: 76.8042 - val_loss: 19.8447 - val_mean_squared_error: 19.8447\n",
            "Epoch 226/1000\n",
            "363/363 [==============================] - 0s 60us/step - loss: 73.6131 - mean_squared_error: 73.6131 - val_loss: 19.8900 - val_mean_squared_error: 19.8900\n",
            "Epoch 227/1000\n",
            "363/363 [==============================] - 0s 55us/step - loss: 75.3156 - mean_squared_error: 75.3156 - val_loss: 19.9415 - val_mean_squared_error: 19.9415\n",
            "Epoch 228/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 76.7515 - mean_squared_error: 76.7515 - val_loss: 19.8311 - val_mean_squared_error: 19.8311\n",
            "Epoch 229/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 75.0232 - mean_squared_error: 75.0232 - val_loss: 19.9088 - val_mean_squared_error: 19.9088\n",
            "Epoch 230/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 70.8327 - mean_squared_error: 70.8327 - val_loss: 19.8120 - val_mean_squared_error: 19.8120\n",
            "Epoch 231/1000\n",
            "363/363 [==============================] - 0s 42us/step - loss: 73.3022 - mean_squared_error: 73.3022 - val_loss: 19.7595 - val_mean_squared_error: 19.7595\n",
            "Epoch 232/1000\n",
            "363/363 [==============================] - 0s 40us/step - loss: 75.5032 - mean_squared_error: 75.5032 - val_loss: 19.7933 - val_mean_squared_error: 19.7933\n",
            "Epoch 233/1000\n",
            "363/363 [==============================] - 0s 42us/step - loss: 81.1820 - mean_squared_error: 81.1820 - val_loss: 19.7875 - val_mean_squared_error: 19.7875\n",
            "Epoch 234/1000\n",
            "363/363 [==============================] - 0s 41us/step - loss: 80.9920 - mean_squared_error: 80.9920 - val_loss: 19.8533 - val_mean_squared_error: 19.8533\n",
            "Epoch 235/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 72.5437 - mean_squared_error: 72.5437 - val_loss: 19.7228 - val_mean_squared_error: 19.7228\n",
            "Epoch 236/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 74.7271 - mean_squared_error: 74.7271 - val_loss: 19.7072 - val_mean_squared_error: 19.7072\n",
            "Epoch 237/1000\n",
            "363/363 [==============================] - 0s 42us/step - loss: 75.2012 - mean_squared_error: 75.2012 - val_loss: 19.6589 - val_mean_squared_error: 19.6589\n",
            "Epoch 238/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 72.2997 - mean_squared_error: 72.2997 - val_loss: 19.7753 - val_mean_squared_error: 19.7753\n",
            "Epoch 239/1000\n",
            "363/363 [==============================] - 0s 40us/step - loss: 81.3491 - mean_squared_error: 81.3491 - val_loss: 19.7272 - val_mean_squared_error: 19.7272\n",
            "Epoch 240/1000\n",
            "363/363 [==============================] - 0s 40us/step - loss: 86.1317 - mean_squared_error: 86.1317 - val_loss: 19.6472 - val_mean_squared_error: 19.6472\n",
            "Epoch 241/1000\n",
            "363/363 [==============================] - 0s 41us/step - loss: 72.1354 - mean_squared_error: 72.1354 - val_loss: 19.6411 - val_mean_squared_error: 19.6411\n",
            "Epoch 242/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 72.2415 - mean_squared_error: 72.2415 - val_loss: 19.6376 - val_mean_squared_error: 19.6376\n",
            "Epoch 243/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 72.2833 - mean_squared_error: 72.2833 - val_loss: 19.5575 - val_mean_squared_error: 19.5575\n",
            "Epoch 244/1000\n",
            "363/363 [==============================] - 0s 40us/step - loss: 70.8499 - mean_squared_error: 70.8499 - val_loss: 19.6246 - val_mean_squared_error: 19.6246\n",
            "Epoch 245/1000\n",
            "363/363 [==============================] - 0s 41us/step - loss: 75.9082 - mean_squared_error: 75.9082 - val_loss: 19.5537 - val_mean_squared_error: 19.5537\n",
            "Epoch 246/1000\n",
            "363/363 [==============================] - 0s 39us/step - loss: 70.3317 - mean_squared_error: 70.3317 - val_loss: 19.5474 - val_mean_squared_error: 19.5474\n",
            "Epoch 247/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 74.6624 - mean_squared_error: 74.6624 - val_loss: 19.5137 - val_mean_squared_error: 19.5137\n",
            "Epoch 248/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 79.8257 - mean_squared_error: 79.8257 - val_loss: 19.5033 - val_mean_squared_error: 19.5033\n",
            "Epoch 249/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 72.1267 - mean_squared_error: 72.1267 - val_loss: 19.5138 - val_mean_squared_error: 19.5138\n",
            "Epoch 250/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 70.6351 - mean_squared_error: 70.6351 - val_loss: 19.4316 - val_mean_squared_error: 19.4316\n",
            "Epoch 251/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 71.4452 - mean_squared_error: 71.4452 - val_loss: 19.4088 - val_mean_squared_error: 19.4088\n",
            "Epoch 252/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 72.9322 - mean_squared_error: 72.9322 - val_loss: 19.3971 - val_mean_squared_error: 19.3971\n",
            "Epoch 253/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 71.6351 - mean_squared_error: 71.6351 - val_loss: 19.3885 - val_mean_squared_error: 19.3885\n",
            "Epoch 254/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 76.2507 - mean_squared_error: 76.2507 - val_loss: 19.3613 - val_mean_squared_error: 19.3613\n",
            "Epoch 255/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 76.0651 - mean_squared_error: 76.0651 - val_loss: 19.3538 - val_mean_squared_error: 19.3538\n",
            "Epoch 256/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 76.6376 - mean_squared_error: 76.6376 - val_loss: 19.3509 - val_mean_squared_error: 19.3509\n",
            "Epoch 257/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 71.9246 - mean_squared_error: 71.9246 - val_loss: 19.3141 - val_mean_squared_error: 19.3141\n",
            "Epoch 258/1000\n",
            "363/363 [==============================] - 0s 55us/step - loss: 70.6092 - mean_squared_error: 70.6092 - val_loss: 19.4236 - val_mean_squared_error: 19.4236\n",
            "Epoch 259/1000\n",
            "363/363 [==============================] - 0s 56us/step - loss: 73.7517 - mean_squared_error: 73.7517 - val_loss: 19.5082 - val_mean_squared_error: 19.5082\n",
            "Epoch 260/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 79.4120 - mean_squared_error: 79.4120 - val_loss: 19.3413 - val_mean_squared_error: 19.3413\n",
            "Epoch 261/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 72.2421 - mean_squared_error: 72.2421 - val_loss: 19.2759 - val_mean_squared_error: 19.2759\n",
            "Epoch 262/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 67.4348 - mean_squared_error: 67.4348 - val_loss: 19.2565 - val_mean_squared_error: 19.2565\n",
            "Epoch 263/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 73.7068 - mean_squared_error: 73.7068 - val_loss: 19.2333 - val_mean_squared_error: 19.2333\n",
            "Epoch 264/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 71.2259 - mean_squared_error: 71.2259 - val_loss: 19.2141 - val_mean_squared_error: 19.2141\n",
            "Epoch 265/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 70.3124 - mean_squared_error: 70.3124 - val_loss: 19.2023 - val_mean_squared_error: 19.2023\n",
            "Epoch 266/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 68.8901 - mean_squared_error: 68.8901 - val_loss: 19.1810 - val_mean_squared_error: 19.1810\n",
            "Epoch 267/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 76.7498 - mean_squared_error: 76.7498 - val_loss: 19.1778 - val_mean_squared_error: 19.1778\n",
            "Epoch 268/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 74.2624 - mean_squared_error: 74.2624 - val_loss: 19.2186 - val_mean_squared_error: 19.2186\n",
            "Epoch 269/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 71.0194 - mean_squared_error: 71.0194 - val_loss: 19.1530 - val_mean_squared_error: 19.1530\n",
            "Epoch 270/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 76.1569 - mean_squared_error: 76.1569 - val_loss: 19.1629 - val_mean_squared_error: 19.1629\n",
            "Epoch 271/1000\n",
            "363/363 [==============================] - 0s 57us/step - loss: 80.9947 - mean_squared_error: 80.9947 - val_loss: 19.1114 - val_mean_squared_error: 19.1114\n",
            "Epoch 272/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 70.8469 - mean_squared_error: 70.8469 - val_loss: 19.1021 - val_mean_squared_error: 19.1021\n",
            "Epoch 273/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 75.6872 - mean_squared_error: 75.6872 - val_loss: 19.0772 - val_mean_squared_error: 19.0772\n",
            "Epoch 274/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 72.3253 - mean_squared_error: 72.3253 - val_loss: 19.1410 - val_mean_squared_error: 19.1410\n",
            "Epoch 275/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 71.6009 - mean_squared_error: 71.6009 - val_loss: 19.1452 - val_mean_squared_error: 19.1452\n",
            "Epoch 276/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 75.2429 - mean_squared_error: 75.2429 - val_loss: 19.1423 - val_mean_squared_error: 19.1423\n",
            "Epoch 277/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 72.1280 - mean_squared_error: 72.1280 - val_loss: 19.1064 - val_mean_squared_error: 19.1064\n",
            "Epoch 278/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 76.0567 - mean_squared_error: 76.0567 - val_loss: 19.1773 - val_mean_squared_error: 19.1773\n",
            "Epoch 279/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 74.2356 - mean_squared_error: 74.2356 - val_loss: 19.0455 - val_mean_squared_error: 19.0455\n",
            "Epoch 280/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 75.6140 - mean_squared_error: 75.6140 - val_loss: 18.9835 - val_mean_squared_error: 18.9835\n",
            "Epoch 281/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 72.2993 - mean_squared_error: 72.2993 - val_loss: 18.9608 - val_mean_squared_error: 18.9608\n",
            "Epoch 282/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 70.6198 - mean_squared_error: 70.6198 - val_loss: 18.9497 - val_mean_squared_error: 18.9497\n",
            "Epoch 283/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 74.6887 - mean_squared_error: 74.6887 - val_loss: 18.9361 - val_mean_squared_error: 18.9361\n",
            "Epoch 284/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 74.7122 - mean_squared_error: 74.7122 - val_loss: 18.9297 - val_mean_squared_error: 18.9297\n",
            "Epoch 285/1000\n",
            "363/363 [==============================] - 0s 55us/step - loss: 73.8203 - mean_squared_error: 73.8203 - val_loss: 18.9435 - val_mean_squared_error: 18.9435\n",
            "Epoch 286/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 73.3124 - mean_squared_error: 73.3124 - val_loss: 18.9241 - val_mean_squared_error: 18.9241\n",
            "Epoch 287/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 73.2087 - mean_squared_error: 73.2087 - val_loss: 18.9578 - val_mean_squared_error: 18.9578\n",
            "Epoch 288/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 75.1925 - mean_squared_error: 75.1925 - val_loss: 18.8650 - val_mean_squared_error: 18.8650\n",
            "Epoch 289/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 70.9220 - mean_squared_error: 70.9220 - val_loss: 18.8626 - val_mean_squared_error: 18.8626\n",
            "Epoch 290/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 71.2579 - mean_squared_error: 71.2579 - val_loss: 18.9073 - val_mean_squared_error: 18.9073\n",
            "Epoch 291/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 73.3569 - mean_squared_error: 73.3569 - val_loss: 18.9962 - val_mean_squared_error: 18.9962\n",
            "Epoch 292/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 73.8576 - mean_squared_error: 73.8576 - val_loss: 18.8564 - val_mean_squared_error: 18.8564\n",
            "Epoch 293/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 74.0718 - mean_squared_error: 74.0718 - val_loss: 18.8404 - val_mean_squared_error: 18.8404\n",
            "Epoch 294/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 65.1083 - mean_squared_error: 65.1083 - val_loss: 18.7773 - val_mean_squared_error: 18.7773\n",
            "Epoch 295/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 74.1510 - mean_squared_error: 74.1510 - val_loss: 18.7972 - val_mean_squared_error: 18.7972\n",
            "Epoch 296/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 68.9829 - mean_squared_error: 68.9829 - val_loss: 18.8115 - val_mean_squared_error: 18.8115\n",
            "Epoch 297/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 74.6215 - mean_squared_error: 74.6215 - val_loss: 18.7656 - val_mean_squared_error: 18.7656\n",
            "Epoch 298/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 80.3220 - mean_squared_error: 80.3220 - val_loss: 18.7400 - val_mean_squared_error: 18.7400\n",
            "Epoch 299/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 76.1405 - mean_squared_error: 76.1405 - val_loss: 18.7255 - val_mean_squared_error: 18.7255\n",
            "Epoch 300/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 74.1146 - mean_squared_error: 74.1146 - val_loss: 18.7515 - val_mean_squared_error: 18.7515\n",
            "Epoch 301/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 68.2878 - mean_squared_error: 68.2878 - val_loss: 18.7579 - val_mean_squared_error: 18.7579\n",
            "Epoch 302/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 69.1935 - mean_squared_error: 69.1935 - val_loss: 18.7212 - val_mean_squared_error: 18.7212\n",
            "Epoch 303/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 71.7725 - mean_squared_error: 71.7725 - val_loss: 18.6702 - val_mean_squared_error: 18.6702\n",
            "Epoch 304/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 75.7536 - mean_squared_error: 75.7536 - val_loss: 18.7381 - val_mean_squared_error: 18.7381\n",
            "Epoch 305/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 70.2944 - mean_squared_error: 70.2944 - val_loss: 18.6651 - val_mean_squared_error: 18.6651\n",
            "Epoch 306/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 74.1994 - mean_squared_error: 74.1994 - val_loss: 18.6714 - val_mean_squared_error: 18.6714\n",
            "Epoch 307/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 69.0342 - mean_squared_error: 69.0342 - val_loss: 18.7373 - val_mean_squared_error: 18.7373\n",
            "Epoch 308/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 76.7198 - mean_squared_error: 76.7198 - val_loss: 18.6245 - val_mean_squared_error: 18.6245\n",
            "Epoch 309/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 71.6665 - mean_squared_error: 71.6665 - val_loss: 18.5782 - val_mean_squared_error: 18.5782\n",
            "Epoch 310/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 69.9822 - mean_squared_error: 69.9822 - val_loss: 18.5966 - val_mean_squared_error: 18.5966\n",
            "Epoch 311/1000\n",
            "363/363 [==============================] - 0s 41us/step - loss: 71.2449 - mean_squared_error: 71.2449 - val_loss: 18.5796 - val_mean_squared_error: 18.5796\n",
            "Epoch 312/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 66.2923 - mean_squared_error: 66.2923 - val_loss: 18.5397 - val_mean_squared_error: 18.5397\n",
            "Epoch 313/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 62.4590 - mean_squared_error: 62.4590 - val_loss: 18.6871 - val_mean_squared_error: 18.6871\n",
            "Epoch 314/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 68.1113 - mean_squared_error: 68.1113 - val_loss: 18.5184 - val_mean_squared_error: 18.5184\n",
            "Epoch 315/1000\n",
            "363/363 [==============================] - 0s 60us/step - loss: 68.8293 - mean_squared_error: 68.8293 - val_loss: 18.4916 - val_mean_squared_error: 18.4916\n",
            "Epoch 316/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 69.3692 - mean_squared_error: 69.3692 - val_loss: 18.4795 - val_mean_squared_error: 18.4795\n",
            "Epoch 317/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 79.4283 - mean_squared_error: 79.4283 - val_loss: 18.4799 - val_mean_squared_error: 18.4799\n",
            "Epoch 318/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 76.5849 - mean_squared_error: 76.5849 - val_loss: 18.4509 - val_mean_squared_error: 18.4509\n",
            "Epoch 319/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 73.8235 - mean_squared_error: 73.8235 - val_loss: 18.4400 - val_mean_squared_error: 18.4400\n",
            "Epoch 320/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 69.0292 - mean_squared_error: 69.0292 - val_loss: 18.5688 - val_mean_squared_error: 18.5688\n",
            "Epoch 321/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 71.5512 - mean_squared_error: 71.5512 - val_loss: 18.4352 - val_mean_squared_error: 18.4352\n",
            "Epoch 322/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 72.3184 - mean_squared_error: 72.3184 - val_loss: 18.4269 - val_mean_squared_error: 18.4269\n",
            "Epoch 323/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 75.9115 - mean_squared_error: 75.9115 - val_loss: 18.4027 - val_mean_squared_error: 18.4027\n",
            "Epoch 324/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 65.9010 - mean_squared_error: 65.9010 - val_loss: 18.4259 - val_mean_squared_error: 18.4259\n",
            "Epoch 325/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 72.0784 - mean_squared_error: 72.0784 - val_loss: 18.6647 - val_mean_squared_error: 18.6647\n",
            "Epoch 326/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 61.4010 - mean_squared_error: 61.4010 - val_loss: 18.5079 - val_mean_squared_error: 18.5079\n",
            "Epoch 327/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 74.9434 - mean_squared_error: 74.9434 - val_loss: 18.3829 - val_mean_squared_error: 18.3829\n",
            "Epoch 328/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 75.2977 - mean_squared_error: 75.2977 - val_loss: 18.3197 - val_mean_squared_error: 18.3197\n",
            "Epoch 329/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 66.0776 - mean_squared_error: 66.0776 - val_loss: 18.3828 - val_mean_squared_error: 18.3828\n",
            "Epoch 330/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 67.4338 - mean_squared_error: 67.4338 - val_loss: 18.4310 - val_mean_squared_error: 18.4310\n",
            "Epoch 331/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 76.3087 - mean_squared_error: 76.3087 - val_loss: 18.3542 - val_mean_squared_error: 18.3542\n",
            "Epoch 332/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 66.0031 - mean_squared_error: 66.0031 - val_loss: 18.3276 - val_mean_squared_error: 18.3276\n",
            "Epoch 333/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 73.6878 - mean_squared_error: 73.6878 - val_loss: 18.4046 - val_mean_squared_error: 18.4046\n",
            "Epoch 334/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 71.8162 - mean_squared_error: 71.8162 - val_loss: 18.2906 - val_mean_squared_error: 18.2906\n",
            "Epoch 335/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 75.3122 - mean_squared_error: 75.3122 - val_loss: 18.2309 - val_mean_squared_error: 18.2309\n",
            "Epoch 336/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 75.3001 - mean_squared_error: 75.3001 - val_loss: 18.2134 - val_mean_squared_error: 18.2134\n",
            "Epoch 337/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 68.5145 - mean_squared_error: 68.5145 - val_loss: 18.2925 - val_mean_squared_error: 18.2925\n",
            "Epoch 338/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 67.7380 - mean_squared_error: 67.7380 - val_loss: 18.4245 - val_mean_squared_error: 18.4245\n",
            "Epoch 339/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 73.9439 - mean_squared_error: 73.9439 - val_loss: 18.2880 - val_mean_squared_error: 18.2880\n",
            "Epoch 340/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 68.0739 - mean_squared_error: 68.0739 - val_loss: 18.1648 - val_mean_squared_error: 18.1648\n",
            "Epoch 341/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 69.0416 - mean_squared_error: 69.0416 - val_loss: 18.1558 - val_mean_squared_error: 18.1558\n",
            "Epoch 342/1000\n",
            "363/363 [==============================] - 0s 39us/step - loss: 70.1206 - mean_squared_error: 70.1206 - val_loss: 18.1462 - val_mean_squared_error: 18.1462\n",
            "Epoch 343/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 65.2313 - mean_squared_error: 65.2313 - val_loss: 18.1898 - val_mean_squared_error: 18.1898\n",
            "Epoch 344/1000\n",
            "363/363 [==============================] - 0s 42us/step - loss: 70.6450 - mean_squared_error: 70.6450 - val_loss: 18.1397 - val_mean_squared_error: 18.1397\n",
            "Epoch 345/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 73.2731 - mean_squared_error: 73.2731 - val_loss: 18.1814 - val_mean_squared_error: 18.1814\n",
            "Epoch 346/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 70.7363 - mean_squared_error: 70.7363 - val_loss: 18.2072 - val_mean_squared_error: 18.2072\n",
            "Epoch 347/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 68.6211 - mean_squared_error: 68.6211 - val_loss: 18.2608 - val_mean_squared_error: 18.2608\n",
            "Epoch 348/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 69.5537 - mean_squared_error: 69.5537 - val_loss: 18.0736 - val_mean_squared_error: 18.0736\n",
            "Epoch 349/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 64.8870 - mean_squared_error: 64.8870 - val_loss: 18.2724 - val_mean_squared_error: 18.2724\n",
            "Epoch 350/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 72.9048 - mean_squared_error: 72.9048 - val_loss: 18.2632 - val_mean_squared_error: 18.2632\n",
            "Epoch 351/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 69.0951 - mean_squared_error: 69.0951 - val_loss: 18.0724 - val_mean_squared_error: 18.0724\n",
            "Epoch 352/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 71.2296 - mean_squared_error: 71.2296 - val_loss: 18.2066 - val_mean_squared_error: 18.2066\n",
            "Epoch 353/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 65.6289 - mean_squared_error: 65.6289 - val_loss: 18.0432 - val_mean_squared_error: 18.0432\n",
            "Epoch 354/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 66.7968 - mean_squared_error: 66.7968 - val_loss: 18.0563 - val_mean_squared_error: 18.0563\n",
            "Epoch 355/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 70.6172 - mean_squared_error: 70.6172 - val_loss: 17.9780 - val_mean_squared_error: 17.9780\n",
            "Epoch 356/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 70.0842 - mean_squared_error: 70.0842 - val_loss: 17.9782 - val_mean_squared_error: 17.9782\n",
            "Epoch 357/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 70.9062 - mean_squared_error: 70.9062 - val_loss: 17.9633 - val_mean_squared_error: 17.9633\n",
            "Epoch 358/1000\n",
            "363/363 [==============================] - 0s 56us/step - loss: 63.2502 - mean_squared_error: 63.2502 - val_loss: 18.0917 - val_mean_squared_error: 18.0917\n",
            "Epoch 359/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 67.0951 - mean_squared_error: 67.0951 - val_loss: 17.9732 - val_mean_squared_error: 17.9732\n",
            "Epoch 360/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 64.6205 - mean_squared_error: 64.6205 - val_loss: 17.9424 - val_mean_squared_error: 17.9424\n",
            "Epoch 361/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 71.5042 - mean_squared_error: 71.5042 - val_loss: 17.9411 - val_mean_squared_error: 17.9411\n",
            "Epoch 362/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 71.6470 - mean_squared_error: 71.6470 - val_loss: 18.0033 - val_mean_squared_error: 18.0033\n",
            "Epoch 363/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 68.5349 - mean_squared_error: 68.5349 - val_loss: 18.1283 - val_mean_squared_error: 18.1283\n",
            "Epoch 364/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 65.4836 - mean_squared_error: 65.4836 - val_loss: 18.1439 - val_mean_squared_error: 18.1439\n",
            "Epoch 365/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 68.3242 - mean_squared_error: 68.3242 - val_loss: 18.1650 - val_mean_squared_error: 18.1650\n",
            "Epoch 366/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 71.3034 - mean_squared_error: 71.3034 - val_loss: 18.0709 - val_mean_squared_error: 18.0709\n",
            "Epoch 367/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 65.7246 - mean_squared_error: 65.7246 - val_loss: 18.1166 - val_mean_squared_error: 18.1166\n",
            "Epoch 368/1000\n",
            "363/363 [==============================] - 0s 42us/step - loss: 67.4195 - mean_squared_error: 67.4195 - val_loss: 18.0850 - val_mean_squared_error: 18.0850\n",
            "Epoch 369/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 64.0118 - mean_squared_error: 64.0118 - val_loss: 17.8732 - val_mean_squared_error: 17.8732\n",
            "Epoch 370/1000\n",
            "363/363 [==============================] - 0s 59us/step - loss: 68.4455 - mean_squared_error: 68.4455 - val_loss: 18.0357 - val_mean_squared_error: 18.0357\n",
            "Epoch 371/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 71.9860 - mean_squared_error: 71.9860 - val_loss: 17.9815 - val_mean_squared_error: 17.9815\n",
            "Epoch 372/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 63.3206 - mean_squared_error: 63.3206 - val_loss: 17.8059 - val_mean_squared_error: 17.8059\n",
            "Epoch 373/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 71.8761 - mean_squared_error: 71.8761 - val_loss: 17.7721 - val_mean_squared_error: 17.7721\n",
            "Epoch 374/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 65.0175 - mean_squared_error: 65.0175 - val_loss: 17.8170 - val_mean_squared_error: 17.8170\n",
            "Epoch 375/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 65.4760 - mean_squared_error: 65.4760 - val_loss: 18.0198 - val_mean_squared_error: 18.0198\n",
            "Epoch 376/1000\n",
            "363/363 [==============================] - 0s 59us/step - loss: 64.9746 - mean_squared_error: 64.9746 - val_loss: 17.7454 - val_mean_squared_error: 17.7454\n",
            "Epoch 377/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 69.6278 - mean_squared_error: 69.6278 - val_loss: 17.7275 - val_mean_squared_error: 17.7275\n",
            "Epoch 378/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 64.2292 - mean_squared_error: 64.2292 - val_loss: 17.7010 - val_mean_squared_error: 17.7010\n",
            "Epoch 379/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 67.2671 - mean_squared_error: 67.2671 - val_loss: 17.7054 - val_mean_squared_error: 17.7054\n",
            "Epoch 380/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 66.7307 - mean_squared_error: 66.7307 - val_loss: 17.6815 - val_mean_squared_error: 17.6815\n",
            "Epoch 381/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 65.5219 - mean_squared_error: 65.5219 - val_loss: 17.8769 - val_mean_squared_error: 17.8769\n",
            "Epoch 382/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 66.2188 - mean_squared_error: 66.2188 - val_loss: 17.6736 - val_mean_squared_error: 17.6736\n",
            "Epoch 383/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 70.4736 - mean_squared_error: 70.4736 - val_loss: 17.7151 - val_mean_squared_error: 17.7151\n",
            "Epoch 384/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 69.6997 - mean_squared_error: 69.6997 - val_loss: 17.6792 - val_mean_squared_error: 17.6792\n",
            "Epoch 385/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 70.3150 - mean_squared_error: 70.3150 - val_loss: 17.6647 - val_mean_squared_error: 17.6647\n",
            "Epoch 386/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 70.2491 - mean_squared_error: 70.2491 - val_loss: 17.6235 - val_mean_squared_error: 17.6235\n",
            "Epoch 387/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 67.6541 - mean_squared_error: 67.6541 - val_loss: 17.6084 - val_mean_squared_error: 17.6084\n",
            "Epoch 388/1000\n",
            "363/363 [==============================] - 0s 55us/step - loss: 65.4516 - mean_squared_error: 65.4516 - val_loss: 17.5979 - val_mean_squared_error: 17.5979\n",
            "Epoch 389/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 67.1214 - mean_squared_error: 67.1214 - val_loss: 17.7590 - val_mean_squared_error: 17.7590\n",
            "Epoch 390/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 67.4828 - mean_squared_error: 67.4828 - val_loss: 17.7102 - val_mean_squared_error: 17.7102\n",
            "Epoch 391/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 63.3358 - mean_squared_error: 63.3358 - val_loss: 17.7684 - val_mean_squared_error: 17.7684\n",
            "Epoch 392/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 65.6756 - mean_squared_error: 65.6756 - val_loss: 17.5657 - val_mean_squared_error: 17.5657\n",
            "Epoch 393/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 68.8156 - mean_squared_error: 68.8156 - val_loss: 17.5275 - val_mean_squared_error: 17.5275\n",
            "Epoch 394/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 72.7307 - mean_squared_error: 72.7307 - val_loss: 17.6282 - val_mean_squared_error: 17.6282\n",
            "Epoch 395/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 67.6480 - mean_squared_error: 67.6480 - val_loss: 17.5200 - val_mean_squared_error: 17.5200\n",
            "Epoch 396/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 60.5737 - mean_squared_error: 60.5737 - val_loss: 17.6895 - val_mean_squared_error: 17.6895\n",
            "Epoch 397/1000\n",
            "363/363 [==============================] - 0s 57us/step - loss: 64.6677 - mean_squared_error: 64.6677 - val_loss: 17.8268 - val_mean_squared_error: 17.8268\n",
            "Epoch 398/1000\n",
            "363/363 [==============================] - 0s 59us/step - loss: 64.4616 - mean_squared_error: 64.4616 - val_loss: 17.5062 - val_mean_squared_error: 17.5062\n",
            "Epoch 399/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 58.2816 - mean_squared_error: 58.2816 - val_loss: 17.4587 - val_mean_squared_error: 17.4587\n",
            "Epoch 400/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 70.8009 - mean_squared_error: 70.8009 - val_loss: 17.4492 - val_mean_squared_error: 17.4492\n",
            "Epoch 401/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 66.2412 - mean_squared_error: 66.2412 - val_loss: 17.4443 - val_mean_squared_error: 17.4443\n",
            "Epoch 402/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 67.9617 - mean_squared_error: 67.9617 - val_loss: 17.4184 - val_mean_squared_error: 17.4184\n",
            "Epoch 403/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 65.8904 - mean_squared_error: 65.8904 - val_loss: 17.4102 - val_mean_squared_error: 17.4102\n",
            "Epoch 404/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 72.1649 - mean_squared_error: 72.1649 - val_loss: 17.3930 - val_mean_squared_error: 17.3930\n",
            "Epoch 405/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 62.8992 - mean_squared_error: 62.8992 - val_loss: 17.4455 - val_mean_squared_error: 17.4455\n",
            "Epoch 406/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 71.1909 - mean_squared_error: 71.1909 - val_loss: 17.3652 - val_mean_squared_error: 17.3652\n",
            "Epoch 407/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 70.2964 - mean_squared_error: 70.2964 - val_loss: 17.4877 - val_mean_squared_error: 17.4877\n",
            "Epoch 408/1000\n",
            "363/363 [==============================] - 0s 55us/step - loss: 64.7559 - mean_squared_error: 64.7559 - val_loss: 17.4672 - val_mean_squared_error: 17.4672\n",
            "Epoch 409/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 67.0751 - mean_squared_error: 67.0751 - val_loss: 17.3712 - val_mean_squared_error: 17.3712\n",
            "Epoch 410/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 64.1062 - mean_squared_error: 64.1062 - val_loss: 17.4080 - val_mean_squared_error: 17.4080\n",
            "Epoch 411/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 65.9671 - mean_squared_error: 65.9671 - val_loss: 17.4636 - val_mean_squared_error: 17.4636\n",
            "Epoch 412/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 61.2523 - mean_squared_error: 61.2523 - val_loss: 17.3653 - val_mean_squared_error: 17.3653\n",
            "Epoch 413/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 63.6543 - mean_squared_error: 63.6543 - val_loss: 17.2990 - val_mean_squared_error: 17.2990\n",
            "Epoch 414/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 61.5177 - mean_squared_error: 61.5177 - val_loss: 17.3492 - val_mean_squared_error: 17.3492\n",
            "Epoch 415/1000\n",
            "363/363 [==============================] - 0s 62us/step - loss: 68.4771 - mean_squared_error: 68.4771 - val_loss: 17.3047 - val_mean_squared_error: 17.3047\n",
            "Epoch 416/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 65.1495 - mean_squared_error: 65.1495 - val_loss: 17.2508 - val_mean_squared_error: 17.2508\n",
            "Epoch 417/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 63.3193 - mean_squared_error: 63.3193 - val_loss: 17.3341 - val_mean_squared_error: 17.3341\n",
            "Epoch 418/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 60.4624 - mean_squared_error: 60.4624 - val_loss: 17.3691 - val_mean_squared_error: 17.3691\n",
            "Epoch 419/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 68.0104 - mean_squared_error: 68.0104 - val_loss: 17.2736 - val_mean_squared_error: 17.2736\n",
            "Epoch 420/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 67.4321 - mean_squared_error: 67.4321 - val_loss: 17.2108 - val_mean_squared_error: 17.2108\n",
            "Epoch 421/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 63.7527 - mean_squared_error: 63.7527 - val_loss: 17.1900 - val_mean_squared_error: 17.1900\n",
            "Epoch 422/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 65.2115 - mean_squared_error: 65.2115 - val_loss: 17.1834 - val_mean_squared_error: 17.1834\n",
            "Epoch 423/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 65.2303 - mean_squared_error: 65.2303 - val_loss: 17.1792 - val_mean_squared_error: 17.1792\n",
            "Epoch 424/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 69.7657 - mean_squared_error: 69.7657 - val_loss: 17.1641 - val_mean_squared_error: 17.1641\n",
            "Epoch 425/1000\n",
            "363/363 [==============================] - 0s 56us/step - loss: 66.1010 - mean_squared_error: 66.1010 - val_loss: 17.1635 - val_mean_squared_error: 17.1635\n",
            "Epoch 426/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 65.8519 - mean_squared_error: 65.8519 - val_loss: 17.1364 - val_mean_squared_error: 17.1364\n",
            "Epoch 427/1000\n",
            "363/363 [==============================] - 0s 64us/step - loss: 67.0162 - mean_squared_error: 67.0162 - val_loss: 17.1580 - val_mean_squared_error: 17.1580\n",
            "Epoch 428/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 63.9717 - mean_squared_error: 63.9717 - val_loss: 17.1509 - val_mean_squared_error: 17.1509\n",
            "Epoch 429/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 63.0441 - mean_squared_error: 63.0441 - val_loss: 17.0990 - val_mean_squared_error: 17.0990\n",
            "Epoch 430/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 68.9918 - mean_squared_error: 68.9918 - val_loss: 17.1495 - val_mean_squared_error: 17.1495\n",
            "Epoch 431/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 65.4177 - mean_squared_error: 65.4177 - val_loss: 17.2945 - val_mean_squared_error: 17.2945\n",
            "Epoch 432/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 65.5258 - mean_squared_error: 65.5258 - val_loss: 17.0788 - val_mean_squared_error: 17.0788\n",
            "Epoch 433/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 67.9577 - mean_squared_error: 67.9577 - val_loss: 17.1814 - val_mean_squared_error: 17.1814\n",
            "Epoch 434/1000\n",
            "363/363 [==============================] - 0s 69us/step - loss: 65.8371 - mean_squared_error: 65.8371 - val_loss: 17.0388 - val_mean_squared_error: 17.0388\n",
            "Epoch 435/1000\n",
            "363/363 [==============================] - 0s 39us/step - loss: 62.3556 - mean_squared_error: 62.3556 - val_loss: 17.0594 - val_mean_squared_error: 17.0594\n",
            "Epoch 436/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 65.3983 - mean_squared_error: 65.3983 - val_loss: 17.0183 - val_mean_squared_error: 17.0183\n",
            "Epoch 437/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 63.9057 - mean_squared_error: 63.9057 - val_loss: 17.0204 - val_mean_squared_error: 17.0204\n",
            "Epoch 438/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 67.8327 - mean_squared_error: 67.8327 - val_loss: 17.0193 - val_mean_squared_error: 17.0193\n",
            "Epoch 439/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 67.5582 - mean_squared_error: 67.5582 - val_loss: 16.9902 - val_mean_squared_error: 16.9902\n",
            "Epoch 440/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 66.5401 - mean_squared_error: 66.5401 - val_loss: 17.0153 - val_mean_squared_error: 17.0153\n",
            "Epoch 441/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 66.4356 - mean_squared_error: 66.4356 - val_loss: 16.9620 - val_mean_squared_error: 16.9620\n",
            "Epoch 442/1000\n",
            "363/363 [==============================] - 0s 42us/step - loss: 59.2788 - mean_squared_error: 59.2788 - val_loss: 17.0037 - val_mean_squared_error: 17.0037\n",
            "Epoch 443/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 61.5795 - mean_squared_error: 61.5795 - val_loss: 16.9913 - val_mean_squared_error: 16.9913\n",
            "Epoch 444/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 64.3148 - mean_squared_error: 64.3148 - val_loss: 16.9251 - val_mean_squared_error: 16.9251\n",
            "Epoch 445/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 66.3523 - mean_squared_error: 66.3523 - val_loss: 16.9181 - val_mean_squared_error: 16.9181\n",
            "Epoch 446/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 70.5593 - mean_squared_error: 70.5593 - val_loss: 16.9835 - val_mean_squared_error: 16.9835\n",
            "Epoch 447/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 62.3719 - mean_squared_error: 62.3719 - val_loss: 16.8929 - val_mean_squared_error: 16.8929\n",
            "Epoch 448/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 65.1153 - mean_squared_error: 65.1153 - val_loss: 16.9109 - val_mean_squared_error: 16.9109\n",
            "Epoch 449/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 63.8465 - mean_squared_error: 63.8465 - val_loss: 17.0082 - val_mean_squared_error: 17.0082\n",
            "Epoch 450/1000\n",
            "363/363 [==============================] - 0s 42us/step - loss: 64.5338 - mean_squared_error: 64.5338 - val_loss: 16.8450 - val_mean_squared_error: 16.8450\n",
            "Epoch 451/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 62.7371 - mean_squared_error: 62.7371 - val_loss: 16.8369 - val_mean_squared_error: 16.8369\n",
            "Epoch 452/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 69.6628 - mean_squared_error: 69.6628 - val_loss: 16.8215 - val_mean_squared_error: 16.8215\n",
            "Epoch 453/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 64.1008 - mean_squared_error: 64.1008 - val_loss: 16.8121 - val_mean_squared_error: 16.8121\n",
            "Epoch 454/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 62.6847 - mean_squared_error: 62.6847 - val_loss: 16.8180 - val_mean_squared_error: 16.8180\n",
            "Epoch 455/1000\n",
            "363/363 [==============================] - 0s 56us/step - loss: 64.2925 - mean_squared_error: 64.2925 - val_loss: 16.8541 - val_mean_squared_error: 16.8541\n",
            "Epoch 456/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 61.2935 - mean_squared_error: 61.2935 - val_loss: 16.8545 - val_mean_squared_error: 16.8545\n",
            "Epoch 457/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 60.6097 - mean_squared_error: 60.6097 - val_loss: 16.7930 - val_mean_squared_error: 16.7930\n",
            "Epoch 458/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 67.8161 - mean_squared_error: 67.8161 - val_loss: 16.7886 - val_mean_squared_error: 16.7886\n",
            "Epoch 459/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 59.7555 - mean_squared_error: 59.7555 - val_loss: 16.8921 - val_mean_squared_error: 16.8921\n",
            "Epoch 460/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 71.9675 - mean_squared_error: 71.9675 - val_loss: 16.7902 - val_mean_squared_error: 16.7902\n",
            "Epoch 461/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 59.5094 - mean_squared_error: 59.5094 - val_loss: 16.7809 - val_mean_squared_error: 16.7809\n",
            "Epoch 462/1000\n",
            "363/363 [==============================] - 0s 41us/step - loss: 58.7361 - mean_squared_error: 58.7361 - val_loss: 16.7729 - val_mean_squared_error: 16.7729\n",
            "Epoch 463/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 61.3652 - mean_squared_error: 61.3652 - val_loss: 16.7069 - val_mean_squared_error: 16.7069\n",
            "Epoch 464/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 64.7050 - mean_squared_error: 64.7050 - val_loss: 16.7020 - val_mean_squared_error: 16.7020\n",
            "Epoch 465/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 65.4962 - mean_squared_error: 65.4962 - val_loss: 16.6956 - val_mean_squared_error: 16.6956\n",
            "Epoch 466/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 60.9077 - mean_squared_error: 60.9077 - val_loss: 16.7210 - val_mean_squared_error: 16.7210\n",
            "Epoch 467/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 64.5950 - mean_squared_error: 64.5950 - val_loss: 16.7146 - val_mean_squared_error: 16.7146\n",
            "Epoch 468/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 65.6403 - mean_squared_error: 65.6403 - val_loss: 16.6700 - val_mean_squared_error: 16.6700\n",
            "Epoch 469/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 67.2700 - mean_squared_error: 67.2700 - val_loss: 16.6650 - val_mean_squared_error: 16.6650\n",
            "Epoch 470/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 57.9425 - mean_squared_error: 57.9425 - val_loss: 16.7027 - val_mean_squared_error: 16.7027\n",
            "Epoch 471/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 67.1343 - mean_squared_error: 67.1343 - val_loss: 16.6897 - val_mean_squared_error: 16.6897\n",
            "Epoch 472/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 62.5846 - mean_squared_error: 62.5846 - val_loss: 16.6268 - val_mean_squared_error: 16.6268\n",
            "Epoch 473/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 63.7823 - mean_squared_error: 63.7823 - val_loss: 16.6063 - val_mean_squared_error: 16.6063\n",
            "Epoch 474/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 65.5460 - mean_squared_error: 65.5460 - val_loss: 16.5949 - val_mean_squared_error: 16.5949\n",
            "Epoch 475/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 61.4540 - mean_squared_error: 61.4540 - val_loss: 16.5864 - val_mean_squared_error: 16.5864\n",
            "Epoch 476/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 61.4643 - mean_squared_error: 61.4643 - val_loss: 16.5866 - val_mean_squared_error: 16.5866\n",
            "Epoch 477/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 65.7676 - mean_squared_error: 65.7676 - val_loss: 16.6191 - val_mean_squared_error: 16.6191\n",
            "Epoch 478/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 62.8298 - mean_squared_error: 62.8298 - val_loss: 16.5648 - val_mean_squared_error: 16.5648\n",
            "Epoch 479/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 68.8434 - mean_squared_error: 68.8434 - val_loss: 16.5554 - val_mean_squared_error: 16.5554\n",
            "Epoch 480/1000\n",
            "363/363 [==============================] - 0s 56us/step - loss: 57.1761 - mean_squared_error: 57.1761 - val_loss: 16.6622 - val_mean_squared_error: 16.6622\n",
            "Epoch 481/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 64.6651 - mean_squared_error: 64.6651 - val_loss: 16.5507 - val_mean_squared_error: 16.5507\n",
            "Epoch 482/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 61.9307 - mean_squared_error: 61.9307 - val_loss: 16.5522 - val_mean_squared_error: 16.5522\n",
            "Epoch 483/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 59.9818 - mean_squared_error: 59.9818 - val_loss: 16.5352 - val_mean_squared_error: 16.5352\n",
            "Epoch 484/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 63.2995 - mean_squared_error: 63.2995 - val_loss: 16.5171 - val_mean_squared_error: 16.5171\n",
            "Epoch 485/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 60.7847 - mean_squared_error: 60.7847 - val_loss: 16.5440 - val_mean_squared_error: 16.5440\n",
            "Epoch 486/1000\n",
            "363/363 [==============================] - 0s 56us/step - loss: 60.5067 - mean_squared_error: 60.5067 - val_loss: 16.5044 - val_mean_squared_error: 16.5044\n",
            "Epoch 487/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 57.1405 - mean_squared_error: 57.1405 - val_loss: 16.4983 - val_mean_squared_error: 16.4983\n",
            "Epoch 488/1000\n",
            "363/363 [==============================] - 0s 42us/step - loss: 65.7667 - mean_squared_error: 65.7667 - val_loss: 16.6248 - val_mean_squared_error: 16.6248\n",
            "Epoch 489/1000\n",
            "363/363 [==============================] - 0s 40us/step - loss: 63.2937 - mean_squared_error: 63.2937 - val_loss: 16.5318 - val_mean_squared_error: 16.5318\n",
            "Epoch 490/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 59.0921 - mean_squared_error: 59.0921 - val_loss: 16.4447 - val_mean_squared_error: 16.4447\n",
            "Epoch 491/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 58.4641 - mean_squared_error: 58.4641 - val_loss: 16.4361 - val_mean_squared_error: 16.4361\n",
            "Epoch 492/1000\n",
            "363/363 [==============================] - 0s 42us/step - loss: 58.1229 - mean_squared_error: 58.1229 - val_loss: 16.4322 - val_mean_squared_error: 16.4322\n",
            "Epoch 493/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 61.7309 - mean_squared_error: 61.7309 - val_loss: 16.4428 - val_mean_squared_error: 16.4428\n",
            "Epoch 494/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 70.4091 - mean_squared_error: 70.4091 - val_loss: 16.3953 - val_mean_squared_error: 16.3953\n",
            "Epoch 495/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 60.9751 - mean_squared_error: 60.9751 - val_loss: 16.4177 - val_mean_squared_error: 16.4177\n",
            "Epoch 496/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 62.9877 - mean_squared_error: 62.9877 - val_loss: 16.3855 - val_mean_squared_error: 16.3855\n",
            "Epoch 497/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 65.3770 - mean_squared_error: 65.3770 - val_loss: 16.3799 - val_mean_squared_error: 16.3799\n",
            "Epoch 498/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 61.4260 - mean_squared_error: 61.4260 - val_loss: 16.4500 - val_mean_squared_error: 16.4500\n",
            "Epoch 499/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 60.0315 - mean_squared_error: 60.0315 - val_loss: 16.4538 - val_mean_squared_error: 16.4538\n",
            "Epoch 500/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 54.8171 - mean_squared_error: 54.8171 - val_loss: 16.3660 - val_mean_squared_error: 16.3660\n",
            "Epoch 501/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 58.2305 - mean_squared_error: 58.2305 - val_loss: 16.3669 - val_mean_squared_error: 16.3669\n",
            "Epoch 502/1000\n",
            "363/363 [==============================] - 0s 42us/step - loss: 59.0190 - mean_squared_error: 59.0190 - val_loss: 16.4260 - val_mean_squared_error: 16.4260\n",
            "Epoch 503/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 59.0686 - mean_squared_error: 59.0686 - val_loss: 16.3351 - val_mean_squared_error: 16.3351\n",
            "Epoch 504/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 56.4981 - mean_squared_error: 56.4981 - val_loss: 16.3169 - val_mean_squared_error: 16.3169\n",
            "Epoch 505/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 62.4932 - mean_squared_error: 62.4932 - val_loss: 16.3058 - val_mean_squared_error: 16.3058\n",
            "Epoch 506/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 63.2131 - mean_squared_error: 63.2131 - val_loss: 16.3233 - val_mean_squared_error: 16.3233\n",
            "Epoch 507/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 62.1372 - mean_squared_error: 62.1372 - val_loss: 16.3863 - val_mean_squared_error: 16.3863\n",
            "Epoch 508/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 60.4396 - mean_squared_error: 60.4396 - val_loss: 16.2607 - val_mean_squared_error: 16.2607\n",
            "Epoch 509/1000\n",
            "363/363 [==============================] - 0s 57us/step - loss: 61.3771 - mean_squared_error: 61.3771 - val_loss: 16.3543 - val_mean_squared_error: 16.3543\n",
            "Epoch 510/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 62.2516 - mean_squared_error: 62.2516 - val_loss: 16.2543 - val_mean_squared_error: 16.2543\n",
            "Epoch 511/1000\n",
            "363/363 [==============================] - 0s 42us/step - loss: 66.1950 - mean_squared_error: 66.1950 - val_loss: 16.2553 - val_mean_squared_error: 16.2553\n",
            "Epoch 512/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 57.5471 - mean_squared_error: 57.5471 - val_loss: 16.2370 - val_mean_squared_error: 16.2370\n",
            "Epoch 513/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 56.6029 - mean_squared_error: 56.6029 - val_loss: 16.3478 - val_mean_squared_error: 16.3478\n",
            "Epoch 514/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 57.4072 - mean_squared_error: 57.4072 - val_loss: 16.3269 - val_mean_squared_error: 16.3269\n",
            "Epoch 515/1000\n",
            "363/363 [==============================] - 0s 41us/step - loss: 65.6727 - mean_squared_error: 65.6727 - val_loss: 16.1978 - val_mean_squared_error: 16.1978\n",
            "Epoch 516/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 57.7565 - mean_squared_error: 57.7565 - val_loss: 16.2211 - val_mean_squared_error: 16.2211\n",
            "Epoch 517/1000\n",
            "363/363 [==============================] - 0s 41us/step - loss: 60.2388 - mean_squared_error: 60.2388 - val_loss: 16.2177 - val_mean_squared_error: 16.2177\n",
            "Epoch 518/1000\n",
            "363/363 [==============================] - 0s 40us/step - loss: 58.2696 - mean_squared_error: 58.2696 - val_loss: 16.2112 - val_mean_squared_error: 16.2112\n",
            "Epoch 519/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 63.4689 - mean_squared_error: 63.4689 - val_loss: 16.1643 - val_mean_squared_error: 16.1643\n",
            "Epoch 520/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 55.5000 - mean_squared_error: 55.5000 - val_loss: 16.1980 - val_mean_squared_error: 16.1980\n",
            "Epoch 521/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 60.0217 - mean_squared_error: 60.0217 - val_loss: 16.1440 - val_mean_squared_error: 16.1440\n",
            "Epoch 522/1000\n",
            "363/363 [==============================] - 0s 42us/step - loss: 57.7231 - mean_squared_error: 57.7231 - val_loss: 16.1519 - val_mean_squared_error: 16.1519\n",
            "Epoch 523/1000\n",
            "363/363 [==============================] - 0s 41us/step - loss: 55.3571 - mean_squared_error: 55.3571 - val_loss: 16.1405 - val_mean_squared_error: 16.1405\n",
            "Epoch 524/1000\n",
            "363/363 [==============================] - 0s 41us/step - loss: 68.9873 - mean_squared_error: 68.9873 - val_loss: 16.1134 - val_mean_squared_error: 16.1134\n",
            "Epoch 525/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 61.2604 - mean_squared_error: 61.2604 - val_loss: 16.2069 - val_mean_squared_error: 16.2069\n",
            "Epoch 526/1000\n",
            "363/363 [==============================] - 0s 42us/step - loss: 59.3412 - mean_squared_error: 59.3412 - val_loss: 16.1154 - val_mean_squared_error: 16.1154\n",
            "Epoch 527/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 56.0944 - mean_squared_error: 56.0944 - val_loss: 16.1594 - val_mean_squared_error: 16.1594\n",
            "Epoch 528/1000\n",
            "363/363 [==============================] - 0s 41us/step - loss: 57.2074 - mean_squared_error: 57.2074 - val_loss: 16.1063 - val_mean_squared_error: 16.1063\n",
            "Epoch 529/1000\n",
            "363/363 [==============================] - 0s 41us/step - loss: 58.2371 - mean_squared_error: 58.2371 - val_loss: 16.1521 - val_mean_squared_error: 16.1521\n",
            "Epoch 530/1000\n",
            "363/363 [==============================] - 0s 41us/step - loss: 59.2573 - mean_squared_error: 59.2573 - val_loss: 16.0939 - val_mean_squared_error: 16.0939\n",
            "Epoch 531/1000\n",
            "363/363 [==============================] - 0s 42us/step - loss: 56.3182 - mean_squared_error: 56.3182 - val_loss: 16.0966 - val_mean_squared_error: 16.0966\n",
            "Epoch 532/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 57.7818 - mean_squared_error: 57.7818 - val_loss: 16.2834 - val_mean_squared_error: 16.2834\n",
            "Epoch 533/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 59.8931 - mean_squared_error: 59.8931 - val_loss: 16.1898 - val_mean_squared_error: 16.1898\n",
            "Epoch 534/1000\n",
            "363/363 [==============================] - 0s 42us/step - loss: 57.2449 - mean_squared_error: 57.2449 - val_loss: 16.0932 - val_mean_squared_error: 16.0932\n",
            "Epoch 535/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 57.1152 - mean_squared_error: 57.1152 - val_loss: 16.0732 - val_mean_squared_error: 16.0732\n",
            "Epoch 536/1000\n",
            "363/363 [==============================] - 0s 39us/step - loss: 57.1197 - mean_squared_error: 57.1197 - val_loss: 16.1196 - val_mean_squared_error: 16.1196\n",
            "Epoch 537/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 57.1110 - mean_squared_error: 57.1110 - val_loss: 16.2210 - val_mean_squared_error: 16.2210\n",
            "Epoch 538/1000\n",
            "363/363 [==============================] - 0s 41us/step - loss: 61.9233 - mean_squared_error: 61.9233 - val_loss: 16.0728 - val_mean_squared_error: 16.0728\n",
            "Epoch 539/1000\n",
            "363/363 [==============================] - 0s 40us/step - loss: 58.7314 - mean_squared_error: 58.7314 - val_loss: 16.1667 - val_mean_squared_error: 16.1667\n",
            "Epoch 540/1000\n",
            "363/363 [==============================] - 0s 39us/step - loss: 62.6968 - mean_squared_error: 62.6968 - val_loss: 16.0787 - val_mean_squared_error: 16.0787\n",
            "Epoch 541/1000\n",
            "363/363 [==============================] - 0s 41us/step - loss: 58.2850 - mean_squared_error: 58.2850 - val_loss: 16.0997 - val_mean_squared_error: 16.0997\n",
            "Epoch 542/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 58.4111 - mean_squared_error: 58.4111 - val_loss: 16.0723 - val_mean_squared_error: 16.0723\n",
            "Epoch 543/1000\n",
            "363/363 [==============================] - 0s 42us/step - loss: 58.2323 - mean_squared_error: 58.2323 - val_loss: 16.0662 - val_mean_squared_error: 16.0662\n",
            "Epoch 544/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 58.1317 - mean_squared_error: 58.1317 - val_loss: 16.0658 - val_mean_squared_error: 16.0658\n",
            "Epoch 545/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 56.9431 - mean_squared_error: 56.9431 - val_loss: 16.0922 - val_mean_squared_error: 16.0922\n",
            "Epoch 546/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 56.1240 - mean_squared_error: 56.1240 - val_loss: 16.1098 - val_mean_squared_error: 16.1098\n",
            "Epoch 547/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 58.7338 - mean_squared_error: 58.7338 - val_loss: 16.0761 - val_mean_squared_error: 16.0761\n",
            "Epoch 548/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 57.2446 - mean_squared_error: 57.2446 - val_loss: 16.0939 - val_mean_squared_error: 16.0939\n",
            "Epoch 549/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 58.0117 - mean_squared_error: 58.0117 - val_loss: 16.0390 - val_mean_squared_error: 16.0390\n",
            "Epoch 550/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 60.5690 - mean_squared_error: 60.5690 - val_loss: 16.0088 - val_mean_squared_error: 16.0088\n",
            "Epoch 551/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 58.2062 - mean_squared_error: 58.2062 - val_loss: 16.1670 - val_mean_squared_error: 16.1670\n",
            "Epoch 552/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 59.4522 - mean_squared_error: 59.4522 - val_loss: 16.1655 - val_mean_squared_error: 16.1655\n",
            "Epoch 553/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 55.7481 - mean_squared_error: 55.7481 - val_loss: 16.0640 - val_mean_squared_error: 16.0640\n",
            "Epoch 554/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 58.3708 - mean_squared_error: 58.3708 - val_loss: 16.0816 - val_mean_squared_error: 16.0816\n",
            "Epoch 555/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 57.3997 - mean_squared_error: 57.3997 - val_loss: 16.0290 - val_mean_squared_error: 16.0290\n",
            "Epoch 556/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 61.4637 - mean_squared_error: 61.4637 - val_loss: 15.9548 - val_mean_squared_error: 15.9548\n",
            "Epoch 557/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 55.6433 - mean_squared_error: 55.6433 - val_loss: 15.9544 - val_mean_squared_error: 15.9544\n",
            "Epoch 558/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 57.4969 - mean_squared_error: 57.4969 - val_loss: 15.9477 - val_mean_squared_error: 15.9477\n",
            "Epoch 559/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 54.6430 - mean_squared_error: 54.6430 - val_loss: 15.9619 - val_mean_squared_error: 15.9619\n",
            "Epoch 560/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 54.3406 - mean_squared_error: 54.3406 - val_loss: 15.9645 - val_mean_squared_error: 15.9645\n",
            "Epoch 561/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 60.2979 - mean_squared_error: 60.2979 - val_loss: 15.9531 - val_mean_squared_error: 15.9531\n",
            "Epoch 562/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 59.2146 - mean_squared_error: 59.2146 - val_loss: 15.9342 - val_mean_squared_error: 15.9342\n",
            "Epoch 563/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 52.4984 - mean_squared_error: 52.4984 - val_loss: 15.9078 - val_mean_squared_error: 15.9078\n",
            "Epoch 564/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 51.4748 - mean_squared_error: 51.4748 - val_loss: 15.9950 - val_mean_squared_error: 15.9950\n",
            "Epoch 565/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 61.7104 - mean_squared_error: 61.7104 - val_loss: 15.9142 - val_mean_squared_error: 15.9142\n",
            "Epoch 566/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 58.9639 - mean_squared_error: 58.9639 - val_loss: 15.9288 - val_mean_squared_error: 15.9288\n",
            "Epoch 567/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 57.4078 - mean_squared_error: 57.4078 - val_loss: 15.9043 - val_mean_squared_error: 15.9043\n",
            "Epoch 568/1000\n",
            "363/363 [==============================] - 0s 59us/step - loss: 52.4722 - mean_squared_error: 52.4722 - val_loss: 16.0346 - val_mean_squared_error: 16.0346\n",
            "Epoch 569/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 57.4565 - mean_squared_error: 57.4565 - val_loss: 15.8877 - val_mean_squared_error: 15.8877\n",
            "Epoch 570/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 58.4271 - mean_squared_error: 58.4271 - val_loss: 15.8906 - val_mean_squared_error: 15.8906\n",
            "Epoch 571/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 56.2663 - mean_squared_error: 56.2663 - val_loss: 15.9307 - val_mean_squared_error: 15.9307\n",
            "Epoch 572/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 54.4006 - mean_squared_error: 54.4006 - val_loss: 15.8790 - val_mean_squared_error: 15.8790\n",
            "Epoch 573/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 54.3511 - mean_squared_error: 54.3511 - val_loss: 15.8649 - val_mean_squared_error: 15.8649\n",
            "Epoch 574/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 54.4376 - mean_squared_error: 54.4376 - val_loss: 15.8895 - val_mean_squared_error: 15.8895\n",
            "Epoch 575/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 63.1358 - mean_squared_error: 63.1358 - val_loss: 15.8558 - val_mean_squared_error: 15.8558\n",
            "Epoch 576/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 56.8001 - mean_squared_error: 56.8001 - val_loss: 15.9169 - val_mean_squared_error: 15.9169\n",
            "Epoch 577/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 55.3001 - mean_squared_error: 55.3001 - val_loss: 15.8488 - val_mean_squared_error: 15.8488\n",
            "Epoch 578/1000\n",
            "363/363 [==============================] - 0s 41us/step - loss: 52.4847 - mean_squared_error: 52.4847 - val_loss: 15.9072 - val_mean_squared_error: 15.9072\n",
            "Epoch 579/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 60.2505 - mean_squared_error: 60.2505 - val_loss: 15.9233 - val_mean_squared_error: 15.9233\n",
            "Epoch 580/1000\n",
            "363/363 [==============================] - 0s 39us/step - loss: 52.6470 - mean_squared_error: 52.6470 - val_loss: 15.8737 - val_mean_squared_error: 15.8737\n",
            "Epoch 581/1000\n",
            "363/363 [==============================] - 0s 41us/step - loss: 54.7892 - mean_squared_error: 54.7892 - val_loss: 15.8343 - val_mean_squared_error: 15.8343\n",
            "Epoch 582/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 59.0672 - mean_squared_error: 59.0672 - val_loss: 15.8238 - val_mean_squared_error: 15.8238\n",
            "Epoch 583/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 55.9398 - mean_squared_error: 55.9398 - val_loss: 15.8259 - val_mean_squared_error: 15.8259\n",
            "Epoch 584/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 61.5543 - mean_squared_error: 61.5543 - val_loss: 15.7935 - val_mean_squared_error: 15.7935\n",
            "Epoch 585/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 58.7836 - mean_squared_error: 58.7836 - val_loss: 15.7939 - val_mean_squared_error: 15.7939\n",
            "Epoch 586/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 60.3434 - mean_squared_error: 60.3434 - val_loss: 15.7591 - val_mean_squared_error: 15.7591\n",
            "Epoch 587/1000\n",
            "363/363 [==============================] - 0s 42us/step - loss: 50.9875 - mean_squared_error: 50.9875 - val_loss: 15.7803 - val_mean_squared_error: 15.7803\n",
            "Epoch 588/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 57.7001 - mean_squared_error: 57.7001 - val_loss: 15.7229 - val_mean_squared_error: 15.7229\n",
            "Epoch 589/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 52.5607 - mean_squared_error: 52.5607 - val_loss: 15.7500 - val_mean_squared_error: 15.7500\n",
            "Epoch 590/1000\n",
            "363/363 [==============================] - 0s 41us/step - loss: 55.6923 - mean_squared_error: 55.6923 - val_loss: 15.7416 - val_mean_squared_error: 15.7416\n",
            "Epoch 591/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 57.1504 - mean_squared_error: 57.1504 - val_loss: 15.8035 - val_mean_squared_error: 15.8035\n",
            "Epoch 592/1000\n",
            "363/363 [==============================] - 0s 42us/step - loss: 54.8903 - mean_squared_error: 54.8903 - val_loss: 15.7666 - val_mean_squared_error: 15.7666\n",
            "Epoch 593/1000\n",
            "363/363 [==============================] - 0s 42us/step - loss: 51.3341 - mean_squared_error: 51.3341 - val_loss: 15.6994 - val_mean_squared_error: 15.6994\n",
            "Epoch 594/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 52.4525 - mean_squared_error: 52.4525 - val_loss: 15.6813 - val_mean_squared_error: 15.6813\n",
            "Epoch 595/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 53.7697 - mean_squared_error: 53.7697 - val_loss: 15.6743 - val_mean_squared_error: 15.6743\n",
            "Epoch 596/1000\n",
            "363/363 [==============================] - 0s 40us/step - loss: 50.0904 - mean_squared_error: 50.0904 - val_loss: 15.6369 - val_mean_squared_error: 15.6369\n",
            "Epoch 597/1000\n",
            "363/363 [==============================] - 0s 40us/step - loss: 59.0532 - mean_squared_error: 59.0532 - val_loss: 15.6733 - val_mean_squared_error: 15.6733\n",
            "Epoch 598/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 58.8632 - mean_squared_error: 58.8632 - val_loss: 15.6802 - val_mean_squared_error: 15.6802\n",
            "Epoch 599/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 56.4791 - mean_squared_error: 56.4791 - val_loss: 15.5813 - val_mean_squared_error: 15.5813\n",
            "Epoch 600/1000\n",
            "363/363 [==============================] - 0s 41us/step - loss: 58.7187 - mean_squared_error: 58.7187 - val_loss: 15.5703 - val_mean_squared_error: 15.5703\n",
            "Epoch 601/1000\n",
            "363/363 [==============================] - 0s 41us/step - loss: 56.1125 - mean_squared_error: 56.1125 - val_loss: 15.5764 - val_mean_squared_error: 15.5764\n",
            "Epoch 602/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 54.2018 - mean_squared_error: 54.2018 - val_loss: 15.6211 - val_mean_squared_error: 15.6211\n",
            "Epoch 603/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 54.9567 - mean_squared_error: 54.9567 - val_loss: 15.6321 - val_mean_squared_error: 15.6321\n",
            "Epoch 604/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 57.3399 - mean_squared_error: 57.3399 - val_loss: 15.5032 - val_mean_squared_error: 15.5032\n",
            "Epoch 605/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 56.0028 - mean_squared_error: 56.0028 - val_loss: 15.5344 - val_mean_squared_error: 15.5344\n",
            "Epoch 606/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 52.4571 - mean_squared_error: 52.4571 - val_loss: 15.4960 - val_mean_squared_error: 15.4960\n",
            "Epoch 607/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 54.7021 - mean_squared_error: 54.7021 - val_loss: 15.5629 - val_mean_squared_error: 15.5629\n",
            "Epoch 608/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 53.8731 - mean_squared_error: 53.8731 - val_loss: 15.4812 - val_mean_squared_error: 15.4812\n",
            "Epoch 609/1000\n",
            "363/363 [==============================] - 0s 55us/step - loss: 53.6239 - mean_squared_error: 53.6239 - val_loss: 15.4584 - val_mean_squared_error: 15.4584\n",
            "Epoch 610/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 49.4062 - mean_squared_error: 49.4062 - val_loss: 15.5584 - val_mean_squared_error: 15.5584\n",
            "Epoch 611/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 50.9459 - mean_squared_error: 50.9459 - val_loss: 15.4700 - val_mean_squared_error: 15.4700\n",
            "Epoch 612/1000\n",
            "363/363 [==============================] - 0s 40us/step - loss: 50.9308 - mean_squared_error: 50.9308 - val_loss: 15.4697 - val_mean_squared_error: 15.4697\n",
            "Epoch 613/1000\n",
            "363/363 [==============================] - 0s 40us/step - loss: 49.0463 - mean_squared_error: 49.0463 - val_loss: 15.3975 - val_mean_squared_error: 15.3975\n",
            "Epoch 614/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 50.5894 - mean_squared_error: 50.5894 - val_loss: 15.4146 - val_mean_squared_error: 15.4146\n",
            "Epoch 615/1000\n",
            "363/363 [==============================] - 0s 41us/step - loss: 53.5258 - mean_squared_error: 53.5258 - val_loss: 15.4264 - val_mean_squared_error: 15.4264\n",
            "Epoch 616/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 49.1003 - mean_squared_error: 49.1003 - val_loss: 15.5264 - val_mean_squared_error: 15.5264\n",
            "Epoch 617/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 53.8865 - mean_squared_error: 53.8865 - val_loss: 15.3949 - val_mean_squared_error: 15.3949\n",
            "Epoch 618/1000\n",
            "363/363 [==============================] - 0s 39us/step - loss: 47.5319 - mean_squared_error: 47.5319 - val_loss: 15.3270 - val_mean_squared_error: 15.3270\n",
            "Epoch 619/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 57.3444 - mean_squared_error: 57.3444 - val_loss: 15.3422 - val_mean_squared_error: 15.3422\n",
            "Epoch 620/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 53.5525 - mean_squared_error: 53.5525 - val_loss: 15.3619 - val_mean_squared_error: 15.3619\n",
            "Epoch 621/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 55.0062 - mean_squared_error: 55.0062 - val_loss: 15.3062 - val_mean_squared_error: 15.3062\n",
            "Epoch 622/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 51.4588 - mean_squared_error: 51.4588 - val_loss: 15.3041 - val_mean_squared_error: 15.3041\n",
            "Epoch 623/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 49.6039 - mean_squared_error: 49.6039 - val_loss: 15.4034 - val_mean_squared_error: 15.4034\n",
            "Epoch 624/1000\n",
            "363/363 [==============================] - 0s 42us/step - loss: 50.2976 - mean_squared_error: 50.2976 - val_loss: 15.2398 - val_mean_squared_error: 15.2398\n",
            "Epoch 625/1000\n",
            "363/363 [==============================] - 0s 42us/step - loss: 51.9273 - mean_squared_error: 51.9273 - val_loss: 15.2377 - val_mean_squared_error: 15.2377\n",
            "Epoch 626/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 50.7335 - mean_squared_error: 50.7335 - val_loss: 15.2194 - val_mean_squared_error: 15.2194\n",
            "Epoch 627/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 50.2412 - mean_squared_error: 50.2412 - val_loss: 15.4691 - val_mean_squared_error: 15.4691\n",
            "Epoch 628/1000\n",
            "363/363 [==============================] - 0s 42us/step - loss: 48.9794 - mean_squared_error: 48.9794 - val_loss: 15.2156 - val_mean_squared_error: 15.2156\n",
            "Epoch 629/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 50.3140 - mean_squared_error: 50.3140 - val_loss: 15.3746 - val_mean_squared_error: 15.3746\n",
            "Epoch 630/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 52.1211 - mean_squared_error: 52.1211 - val_loss: 15.1754 - val_mean_squared_error: 15.1754\n",
            "Epoch 631/1000\n",
            "363/363 [==============================] - 0s 42us/step - loss: 53.8820 - mean_squared_error: 53.8820 - val_loss: 15.1726 - val_mean_squared_error: 15.1726\n",
            "Epoch 632/1000\n",
            "363/363 [==============================] - 0s 56us/step - loss: 50.1374 - mean_squared_error: 50.1374 - val_loss: 15.1333 - val_mean_squared_error: 15.1333\n",
            "Epoch 633/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 50.3792 - mean_squared_error: 50.3792 - val_loss: 15.2438 - val_mean_squared_error: 15.2438\n",
            "Epoch 634/1000\n",
            "363/363 [==============================] - 0s 63us/step - loss: 57.1337 - mean_squared_error: 57.1337 - val_loss: 15.1122 - val_mean_squared_error: 15.1122\n",
            "Epoch 635/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 53.9739 - mean_squared_error: 53.9739 - val_loss: 15.1499 - val_mean_squared_error: 15.1499\n",
            "Epoch 636/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 50.0313 - mean_squared_error: 50.0313 - val_loss: 15.1824 - val_mean_squared_error: 15.1824\n",
            "Epoch 637/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 50.9184 - mean_squared_error: 50.9184 - val_loss: 15.1302 - val_mean_squared_error: 15.1302\n",
            "Epoch 638/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 47.6638 - mean_squared_error: 47.6638 - val_loss: 15.3463 - val_mean_squared_error: 15.3463\n",
            "Epoch 639/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 50.6781 - mean_squared_error: 50.6781 - val_loss: 15.3672 - val_mean_squared_error: 15.3672\n",
            "Epoch 640/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 52.2939 - mean_squared_error: 52.2939 - val_loss: 15.2584 - val_mean_squared_error: 15.2584\n",
            "Epoch 641/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 50.6995 - mean_squared_error: 50.6995 - val_loss: 15.1063 - val_mean_squared_error: 15.1063\n",
            "Epoch 642/1000\n",
            "363/363 [==============================] - 0s 42us/step - loss: 50.2328 - mean_squared_error: 50.2328 - val_loss: 15.0599 - val_mean_squared_error: 15.0599\n",
            "Epoch 643/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 47.1730 - mean_squared_error: 47.1730 - val_loss: 15.0541 - val_mean_squared_error: 15.0541\n",
            "Epoch 644/1000\n",
            "363/363 [==============================] - 0s 39us/step - loss: 50.0995 - mean_squared_error: 50.0995 - val_loss: 15.1035 - val_mean_squared_error: 15.1035\n",
            "Epoch 645/1000\n",
            "363/363 [==============================] - 0s 42us/step - loss: 54.1505 - mean_squared_error: 54.1505 - val_loss: 15.0778 - val_mean_squared_error: 15.0778\n",
            "Epoch 646/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 51.1226 - mean_squared_error: 51.1226 - val_loss: 15.3333 - val_mean_squared_error: 15.3333\n",
            "Epoch 647/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 49.5017 - mean_squared_error: 49.5017 - val_loss: 15.0854 - val_mean_squared_error: 15.0854\n",
            "Epoch 648/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 46.9359 - mean_squared_error: 46.9359 - val_loss: 15.0347 - val_mean_squared_error: 15.0347\n",
            "Epoch 649/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 47.6257 - mean_squared_error: 47.6257 - val_loss: 15.0352 - val_mean_squared_error: 15.0352\n",
            "Epoch 650/1000\n",
            "363/363 [==============================] - 0s 41us/step - loss: 53.8819 - mean_squared_error: 53.8819 - val_loss: 15.0825 - val_mean_squared_error: 15.0825\n",
            "Epoch 651/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 48.6450 - mean_squared_error: 48.6450 - val_loss: 15.0037 - val_mean_squared_error: 15.0037\n",
            "Epoch 652/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 52.1437 - mean_squared_error: 52.1437 - val_loss: 15.0026 - val_mean_squared_error: 15.0026\n",
            "Epoch 653/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 52.9140 - mean_squared_error: 52.9140 - val_loss: 14.9819 - val_mean_squared_error: 14.9819\n",
            "Epoch 654/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 49.7384 - mean_squared_error: 49.7384 - val_loss: 15.2563 - val_mean_squared_error: 15.2563\n",
            "Epoch 655/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 54.6439 - mean_squared_error: 54.6439 - val_loss: 14.9536 - val_mean_squared_error: 14.9536\n",
            "Epoch 656/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 45.5488 - mean_squared_error: 45.5488 - val_loss: 14.9295 - val_mean_squared_error: 14.9295\n",
            "Epoch 657/1000\n",
            "363/363 [==============================] - 0s 40us/step - loss: 49.2165 - mean_squared_error: 49.2165 - val_loss: 14.9961 - val_mean_squared_error: 14.9961\n",
            "Epoch 658/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 48.9450 - mean_squared_error: 48.9450 - val_loss: 15.0337 - val_mean_squared_error: 15.0337\n",
            "Epoch 659/1000\n",
            "363/363 [==============================] - 0s 42us/step - loss: 51.0412 - mean_squared_error: 51.0412 - val_loss: 14.8994 - val_mean_squared_error: 14.8994\n",
            "Epoch 660/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 50.0285 - mean_squared_error: 50.0285 - val_loss: 14.8562 - val_mean_squared_error: 14.8562\n",
            "Epoch 661/1000\n",
            "363/363 [==============================] - 0s 40us/step - loss: 48.1267 - mean_squared_error: 48.1267 - val_loss: 14.8777 - val_mean_squared_error: 14.8777\n",
            "Epoch 662/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 52.1267 - mean_squared_error: 52.1267 - val_loss: 14.7898 - val_mean_squared_error: 14.7898\n",
            "Epoch 663/1000\n",
            "363/363 [==============================] - 0s 42us/step - loss: 51.0200 - mean_squared_error: 51.0200 - val_loss: 15.0749 - val_mean_squared_error: 15.0749\n",
            "Epoch 664/1000\n",
            "363/363 [==============================] - 0s 42us/step - loss: 48.5112 - mean_squared_error: 48.5112 - val_loss: 14.7667 - val_mean_squared_error: 14.7667\n",
            "Epoch 665/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 47.5721 - mean_squared_error: 47.5721 - val_loss: 14.8966 - val_mean_squared_error: 14.8966\n",
            "Epoch 666/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 44.3215 - mean_squared_error: 44.3215 - val_loss: 14.7631 - val_mean_squared_error: 14.7631\n",
            "Epoch 667/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 43.8340 - mean_squared_error: 43.8340 - val_loss: 14.7108 - val_mean_squared_error: 14.7108\n",
            "Epoch 668/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 45.9489 - mean_squared_error: 45.9489 - val_loss: 14.7120 - val_mean_squared_error: 14.7120\n",
            "Epoch 669/1000\n",
            "363/363 [==============================] - 0s 61us/step - loss: 51.0903 - mean_squared_error: 51.0903 - val_loss: 14.6579 - val_mean_squared_error: 14.6579\n",
            "Epoch 670/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 49.6042 - mean_squared_error: 49.6042 - val_loss: 14.7293 - val_mean_squared_error: 14.7293\n",
            "Epoch 671/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 46.0338 - mean_squared_error: 46.0338 - val_loss: 14.6284 - val_mean_squared_error: 14.6284\n",
            "Epoch 672/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 48.2028 - mean_squared_error: 48.2028 - val_loss: 14.6328 - val_mean_squared_error: 14.6328\n",
            "Epoch 673/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 45.1752 - mean_squared_error: 45.1752 - val_loss: 14.5906 - val_mean_squared_error: 14.5906\n",
            "Epoch 674/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 42.0939 - mean_squared_error: 42.0939 - val_loss: 14.5854 - val_mean_squared_error: 14.5854\n",
            "Epoch 675/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 48.8801 - mean_squared_error: 48.8801 - val_loss: 14.6286 - val_mean_squared_error: 14.6286\n",
            "Epoch 676/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 48.8159 - mean_squared_error: 48.8159 - val_loss: 14.5350 - val_mean_squared_error: 14.5350\n",
            "Epoch 677/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 46.8836 - mean_squared_error: 46.8836 - val_loss: 14.5232 - val_mean_squared_error: 14.5232\n",
            "Epoch 678/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 47.1104 - mean_squared_error: 47.1104 - val_loss: 14.5920 - val_mean_squared_error: 14.5920\n",
            "Epoch 679/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 41.9416 - mean_squared_error: 41.9416 - val_loss: 14.5411 - val_mean_squared_error: 14.5411\n",
            "Epoch 680/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 42.8873 - mean_squared_error: 42.8873 - val_loss: 14.4809 - val_mean_squared_error: 14.4809\n",
            "Epoch 681/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 45.8814 - mean_squared_error: 45.8814 - val_loss: 14.4585 - val_mean_squared_error: 14.4585\n",
            "Epoch 682/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 49.7550 - mean_squared_error: 49.7550 - val_loss: 14.5095 - val_mean_squared_error: 14.5095\n",
            "Epoch 683/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 48.5988 - mean_squared_error: 48.5988 - val_loss: 14.4091 - val_mean_squared_error: 14.4091\n",
            "Epoch 684/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 50.7352 - mean_squared_error: 50.7352 - val_loss: 14.3810 - val_mean_squared_error: 14.3810\n",
            "Epoch 685/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 49.2340 - mean_squared_error: 49.2340 - val_loss: 14.3958 - val_mean_squared_error: 14.3958\n",
            "Epoch 686/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 45.4827 - mean_squared_error: 45.4827 - val_loss: 14.3300 - val_mean_squared_error: 14.3300\n",
            "Epoch 687/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 51.8248 - mean_squared_error: 51.8248 - val_loss: 14.4080 - val_mean_squared_error: 14.4080\n",
            "Epoch 688/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 45.1871 - mean_squared_error: 45.1871 - val_loss: 14.2038 - val_mean_squared_error: 14.2038\n",
            "Epoch 689/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 47.4865 - mean_squared_error: 47.4865 - val_loss: 14.2050 - val_mean_squared_error: 14.2050\n",
            "Epoch 690/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 46.0648 - mean_squared_error: 46.0648 - val_loss: 14.3221 - val_mean_squared_error: 14.3221\n",
            "Epoch 691/1000\n",
            "363/363 [==============================] - 0s 41us/step - loss: 47.5895 - mean_squared_error: 47.5895 - val_loss: 14.2178 - val_mean_squared_error: 14.2178\n",
            "Epoch 692/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 45.4380 - mean_squared_error: 45.4380 - val_loss: 14.2473 - val_mean_squared_error: 14.2473\n",
            "Epoch 693/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 43.5635 - mean_squared_error: 43.5635 - val_loss: 14.1244 - val_mean_squared_error: 14.1244\n",
            "Epoch 694/1000\n",
            "363/363 [==============================] - 0s 41us/step - loss: 47.0024 - mean_squared_error: 47.0024 - val_loss: 14.1076 - val_mean_squared_error: 14.1076\n",
            "Epoch 695/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 40.8202 - mean_squared_error: 40.8202 - val_loss: 14.0587 - val_mean_squared_error: 14.0587\n",
            "Epoch 696/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 43.0059 - mean_squared_error: 43.0059 - val_loss: 14.1321 - val_mean_squared_error: 14.1321\n",
            "Epoch 697/1000\n",
            "363/363 [==============================] - 0s 41us/step - loss: 44.2063 - mean_squared_error: 44.2063 - val_loss: 14.0619 - val_mean_squared_error: 14.0619\n",
            "Epoch 698/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 45.0173 - mean_squared_error: 45.0173 - val_loss: 14.1274 - val_mean_squared_error: 14.1274\n",
            "Epoch 699/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 47.0535 - mean_squared_error: 47.0535 - val_loss: 14.0045 - val_mean_squared_error: 14.0045\n",
            "Epoch 700/1000\n",
            "363/363 [==============================] - 0s 41us/step - loss: 46.9423 - mean_squared_error: 46.9423 - val_loss: 14.1099 - val_mean_squared_error: 14.1099\n",
            "Epoch 701/1000\n",
            "363/363 [==============================] - 0s 41us/step - loss: 43.8311 - mean_squared_error: 43.8311 - val_loss: 13.9608 - val_mean_squared_error: 13.9608\n",
            "Epoch 702/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 46.1534 - mean_squared_error: 46.1534 - val_loss: 13.8989 - val_mean_squared_error: 13.8989\n",
            "Epoch 703/1000\n",
            "363/363 [==============================] - 0s 42us/step - loss: 41.2301 - mean_squared_error: 41.2301 - val_loss: 13.8703 - val_mean_squared_error: 13.8703\n",
            "Epoch 704/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 44.3703 - mean_squared_error: 44.3703 - val_loss: 13.8243 - val_mean_squared_error: 13.8243\n",
            "Epoch 705/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 45.7076 - mean_squared_error: 45.7076 - val_loss: 13.7496 - val_mean_squared_error: 13.7496\n",
            "Epoch 706/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 40.3648 - mean_squared_error: 40.3648 - val_loss: 13.7879 - val_mean_squared_error: 13.7879\n",
            "Epoch 707/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 41.7232 - mean_squared_error: 41.7232 - val_loss: 13.6876 - val_mean_squared_error: 13.6876\n",
            "Epoch 708/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 40.4526 - mean_squared_error: 40.4526 - val_loss: 13.7083 - val_mean_squared_error: 13.7083\n",
            "Epoch 709/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 45.2650 - mean_squared_error: 45.2650 - val_loss: 13.6840 - val_mean_squared_error: 13.6840\n",
            "Epoch 710/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 43.8422 - mean_squared_error: 43.8422 - val_loss: 13.7321 - val_mean_squared_error: 13.7321\n",
            "Epoch 711/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 42.3184 - mean_squared_error: 42.3184 - val_loss: 13.6342 - val_mean_squared_error: 13.6342\n",
            "Epoch 712/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 45.2500 - mean_squared_error: 45.2500 - val_loss: 13.5842 - val_mean_squared_error: 13.5842\n",
            "Epoch 713/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 44.4180 - mean_squared_error: 44.4180 - val_loss: 13.5938 - val_mean_squared_error: 13.5938\n",
            "Epoch 714/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 43.7610 - mean_squared_error: 43.7610 - val_loss: 13.5262 - val_mean_squared_error: 13.5262\n",
            "Epoch 715/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 45.8339 - mean_squared_error: 45.8339 - val_loss: 13.5360 - val_mean_squared_error: 13.5360\n",
            "Epoch 716/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 43.9941 - mean_squared_error: 43.9941 - val_loss: 13.4968 - val_mean_squared_error: 13.4968\n",
            "Epoch 717/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 42.7629 - mean_squared_error: 42.7629 - val_loss: 13.4486 - val_mean_squared_error: 13.4486\n",
            "Epoch 718/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 44.2696 - mean_squared_error: 44.2696 - val_loss: 13.4444 - val_mean_squared_error: 13.4444\n",
            "Epoch 719/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 40.5350 - mean_squared_error: 40.5350 - val_loss: 13.6109 - val_mean_squared_error: 13.6109\n",
            "Epoch 720/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 44.5356 - mean_squared_error: 44.5356 - val_loss: 13.3919 - val_mean_squared_error: 13.3919\n",
            "Epoch 721/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 40.9500 - mean_squared_error: 40.9500 - val_loss: 13.3815 - val_mean_squared_error: 13.3815\n",
            "Epoch 722/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 44.1390 - mean_squared_error: 44.1390 - val_loss: 13.3567 - val_mean_squared_error: 13.3567\n",
            "Epoch 723/1000\n",
            "363/363 [==============================] - 0s 41us/step - loss: 45.9912 - mean_squared_error: 45.9912 - val_loss: 13.4202 - val_mean_squared_error: 13.4202\n",
            "Epoch 724/1000\n",
            "363/363 [==============================] - 0s 41us/step - loss: 41.3177 - mean_squared_error: 41.3177 - val_loss: 13.3569 - val_mean_squared_error: 13.3569\n",
            "Epoch 725/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 42.4627 - mean_squared_error: 42.4627 - val_loss: 13.2971 - val_mean_squared_error: 13.2971\n",
            "Epoch 726/1000\n",
            "363/363 [==============================] - 0s 55us/step - loss: 39.4026 - mean_squared_error: 39.4026 - val_loss: 13.4145 - val_mean_squared_error: 13.4145\n",
            "Epoch 727/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 39.4107 - mean_squared_error: 39.4107 - val_loss: 13.4065 - val_mean_squared_error: 13.4065\n",
            "Epoch 728/1000\n",
            "363/363 [==============================] - 0s 42us/step - loss: 39.2400 - mean_squared_error: 39.2400 - val_loss: 13.2095 - val_mean_squared_error: 13.2095\n",
            "Epoch 729/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 42.7233 - mean_squared_error: 42.7233 - val_loss: 13.1948 - val_mean_squared_error: 13.1948\n",
            "Epoch 730/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 43.5422 - mean_squared_error: 43.5422 - val_loss: 13.2015 - val_mean_squared_error: 13.2015\n",
            "Epoch 731/1000\n",
            "363/363 [==============================] - 0s 58us/step - loss: 42.2083 - mean_squared_error: 42.2083 - val_loss: 13.3690 - val_mean_squared_error: 13.3690\n",
            "Epoch 732/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 43.5555 - mean_squared_error: 43.5555 - val_loss: 13.0976 - val_mean_squared_error: 13.0976\n",
            "Epoch 733/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 39.9209 - mean_squared_error: 39.9209 - val_loss: 13.1175 - val_mean_squared_error: 13.1175\n",
            "Epoch 734/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 41.6657 - mean_squared_error: 41.6657 - val_loss: 13.0775 - val_mean_squared_error: 13.0775\n",
            "Epoch 735/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 43.0645 - mean_squared_error: 43.0645 - val_loss: 13.0636 - val_mean_squared_error: 13.0636\n",
            "Epoch 736/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 43.6618 - mean_squared_error: 43.6618 - val_loss: 13.0794 - val_mean_squared_error: 13.0794\n",
            "Epoch 737/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 43.3869 - mean_squared_error: 43.3869 - val_loss: 13.5917 - val_mean_squared_error: 13.5917\n",
            "Epoch 738/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 39.1756 - mean_squared_error: 39.1756 - val_loss: 12.9817 - val_mean_squared_error: 12.9817\n",
            "Epoch 739/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 40.3597 - mean_squared_error: 40.3597 - val_loss: 13.1802 - val_mean_squared_error: 13.1802\n",
            "Epoch 740/1000\n",
            "363/363 [==============================] - 0s 42us/step - loss: 42.6429 - mean_squared_error: 42.6429 - val_loss: 12.9692 - val_mean_squared_error: 12.9692\n",
            "Epoch 741/1000\n",
            "363/363 [==============================] - 0s 42us/step - loss: 39.8399 - mean_squared_error: 39.8399 - val_loss: 13.0883 - val_mean_squared_error: 13.0883\n",
            "Epoch 742/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 41.9393 - mean_squared_error: 41.9393 - val_loss: 12.9464 - val_mean_squared_error: 12.9464\n",
            "Epoch 743/1000\n",
            "363/363 [==============================] - 0s 42us/step - loss: 38.5829 - mean_squared_error: 38.5829 - val_loss: 13.1770 - val_mean_squared_error: 13.1770\n",
            "Epoch 744/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 41.3839 - mean_squared_error: 41.3839 - val_loss: 12.9017 - val_mean_squared_error: 12.9017\n",
            "Epoch 745/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 38.8929 - mean_squared_error: 38.8929 - val_loss: 12.9204 - val_mean_squared_error: 12.9204\n",
            "Epoch 746/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 41.2351 - mean_squared_error: 41.2351 - val_loss: 12.8656 - val_mean_squared_error: 12.8656\n",
            "Epoch 747/1000\n",
            "363/363 [==============================] - 0s 39us/step - loss: 35.4630 - mean_squared_error: 35.4630 - val_loss: 12.8848 - val_mean_squared_error: 12.8848\n",
            "Epoch 748/1000\n",
            "363/363 [==============================] - 0s 42us/step - loss: 36.4599 - mean_squared_error: 36.4599 - val_loss: 12.8358 - val_mean_squared_error: 12.8358\n",
            "Epoch 749/1000\n",
            "363/363 [==============================] - 0s 41us/step - loss: 42.2506 - mean_squared_error: 42.2506 - val_loss: 12.8680 - val_mean_squared_error: 12.8680\n",
            "Epoch 750/1000\n",
            "363/363 [==============================] - 0s 40us/step - loss: 39.1170 - mean_squared_error: 39.1170 - val_loss: 12.8745 - val_mean_squared_error: 12.8745\n",
            "Epoch 751/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 44.0062 - mean_squared_error: 44.0062 - val_loss: 12.8024 - val_mean_squared_error: 12.8024\n",
            "Epoch 752/1000\n",
            "363/363 [==============================] - 0s 40us/step - loss: 39.0242 - mean_squared_error: 39.0242 - val_loss: 12.8379 - val_mean_squared_error: 12.8379\n",
            "Epoch 753/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 42.3541 - mean_squared_error: 42.3541 - val_loss: 12.8939 - val_mean_squared_error: 12.8939\n",
            "Epoch 754/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 35.3637 - mean_squared_error: 35.3637 - val_loss: 12.7527 - val_mean_squared_error: 12.7527\n",
            "Epoch 755/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 43.0086 - mean_squared_error: 43.0086 - val_loss: 12.9303 - val_mean_squared_error: 12.9303\n",
            "Epoch 756/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 37.9248 - mean_squared_error: 37.9248 - val_loss: 12.7683 - val_mean_squared_error: 12.7683\n",
            "Epoch 757/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 36.5749 - mean_squared_error: 36.5749 - val_loss: 12.7278 - val_mean_squared_error: 12.7278\n",
            "Epoch 758/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 40.8542 - mean_squared_error: 40.8542 - val_loss: 12.7683 - val_mean_squared_error: 12.7683\n",
            "Epoch 759/1000\n",
            "363/363 [==============================] - 0s 63us/step - loss: 40.7939 - mean_squared_error: 40.7939 - val_loss: 12.7822 - val_mean_squared_error: 12.7822\n",
            "Epoch 760/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 38.2823 - mean_squared_error: 38.2823 - val_loss: 12.6474 - val_mean_squared_error: 12.6474\n",
            "Epoch 761/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 35.4387 - mean_squared_error: 35.4387 - val_loss: 12.7756 - val_mean_squared_error: 12.7756\n",
            "Epoch 762/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 39.2466 - mean_squared_error: 39.2466 - val_loss: 12.6492 - val_mean_squared_error: 12.6492\n",
            "Epoch 763/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 36.3704 - mean_squared_error: 36.3704 - val_loss: 13.0314 - val_mean_squared_error: 13.0314\n",
            "Epoch 764/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 33.4643 - mean_squared_error: 33.4643 - val_loss: 12.7919 - val_mean_squared_error: 12.7919\n",
            "Epoch 765/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 37.7134 - mean_squared_error: 37.7134 - val_loss: 12.6376 - val_mean_squared_error: 12.6376\n",
            "Epoch 766/1000\n",
            "363/363 [==============================] - 0s 62us/step - loss: 41.6306 - mean_squared_error: 41.6306 - val_loss: 12.6734 - val_mean_squared_error: 12.6734\n",
            "Epoch 767/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 35.9273 - mean_squared_error: 35.9273 - val_loss: 12.6023 - val_mean_squared_error: 12.6023\n",
            "Epoch 768/1000\n",
            "363/363 [==============================] - 0s 85us/step - loss: 37.3124 - mean_squared_error: 37.3124 - val_loss: 12.6002 - val_mean_squared_error: 12.6002\n",
            "Epoch 769/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 37.6880 - mean_squared_error: 37.6880 - val_loss: 12.6013 - val_mean_squared_error: 12.6013\n",
            "Epoch 770/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 36.8958 - mean_squared_error: 36.8958 - val_loss: 12.5904 - val_mean_squared_error: 12.5904\n",
            "Epoch 771/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 41.1778 - mean_squared_error: 41.1778 - val_loss: 12.5844 - val_mean_squared_error: 12.5844\n",
            "Epoch 772/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 38.4947 - mean_squared_error: 38.4947 - val_loss: 12.5561 - val_mean_squared_error: 12.5561\n",
            "Epoch 773/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 36.1607 - mean_squared_error: 36.1607 - val_loss: 12.5306 - val_mean_squared_error: 12.5306\n",
            "Epoch 774/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 36.7045 - mean_squared_error: 36.7045 - val_loss: 12.5928 - val_mean_squared_error: 12.5928\n",
            "Epoch 775/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 38.3696 - mean_squared_error: 38.3696 - val_loss: 12.5775 - val_mean_squared_error: 12.5775\n",
            "Epoch 776/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 35.0695 - mean_squared_error: 35.0695 - val_loss: 12.5372 - val_mean_squared_error: 12.5372\n",
            "Epoch 777/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 39.7180 - mean_squared_error: 39.7180 - val_loss: 12.7347 - val_mean_squared_error: 12.7347\n",
            "Epoch 778/1000\n",
            "363/363 [==============================] - 0s 41us/step - loss: 35.4303 - mean_squared_error: 35.4303 - val_loss: 12.5206 - val_mean_squared_error: 12.5206\n",
            "Epoch 779/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 37.8120 - mean_squared_error: 37.8120 - val_loss: 12.8370 - val_mean_squared_error: 12.8370\n",
            "Epoch 780/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 41.5719 - mean_squared_error: 41.5719 - val_loss: 12.6483 - val_mean_squared_error: 12.6483\n",
            "Epoch 781/1000\n",
            "363/363 [==============================] - 0s 58us/step - loss: 37.7833 - mean_squared_error: 37.7833 - val_loss: 12.5157 - val_mean_squared_error: 12.5157\n",
            "Epoch 782/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 38.0386 - mean_squared_error: 38.0386 - val_loss: 12.6555 - val_mean_squared_error: 12.6555\n",
            "Epoch 783/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 34.6731 - mean_squared_error: 34.6731 - val_loss: 12.7739 - val_mean_squared_error: 12.7739\n",
            "Epoch 784/1000\n",
            "363/363 [==============================] - 0s 40us/step - loss: 40.2890 - mean_squared_error: 40.2890 - val_loss: 12.4796 - val_mean_squared_error: 12.4796\n",
            "Epoch 785/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 32.8019 - mean_squared_error: 32.8019 - val_loss: 12.4461 - val_mean_squared_error: 12.4461\n",
            "Epoch 786/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 34.7160 - mean_squared_error: 34.7160 - val_loss: 12.4980 - val_mean_squared_error: 12.4980\n",
            "Epoch 787/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 38.2150 - mean_squared_error: 38.2150 - val_loss: 12.4054 - val_mean_squared_error: 12.4054\n",
            "Epoch 788/1000\n",
            "363/363 [==============================] - 0s 58us/step - loss: 39.5755 - mean_squared_error: 39.5755 - val_loss: 12.4318 - val_mean_squared_error: 12.4318\n",
            "Epoch 789/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 36.8071 - mean_squared_error: 36.8071 - val_loss: 12.5389 - val_mean_squared_error: 12.5389\n",
            "Epoch 790/1000\n",
            "363/363 [==============================] - 0s 55us/step - loss: 39.5367 - mean_squared_error: 39.5367 - val_loss: 12.7038 - val_mean_squared_error: 12.7038\n",
            "Epoch 791/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 36.1886 - mean_squared_error: 36.1886 - val_loss: 12.5411 - val_mean_squared_error: 12.5411\n",
            "Epoch 792/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 39.7743 - mean_squared_error: 39.7743 - val_loss: 12.4756 - val_mean_squared_error: 12.4756\n",
            "Epoch 793/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 33.9364 - mean_squared_error: 33.9364 - val_loss: 12.5896 - val_mean_squared_error: 12.5896\n",
            "Epoch 794/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 34.8449 - mean_squared_error: 34.8449 - val_loss: 12.5097 - val_mean_squared_error: 12.5097\n",
            "Epoch 795/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 38.2209 - mean_squared_error: 38.2209 - val_loss: 12.4963 - val_mean_squared_error: 12.4963\n",
            "Epoch 796/1000\n",
            "363/363 [==============================] - 0s 42us/step - loss: 32.9227 - mean_squared_error: 32.9227 - val_loss: 12.4053 - val_mean_squared_error: 12.4053\n",
            "Epoch 797/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 39.6991 - mean_squared_error: 39.6991 - val_loss: 12.4057 - val_mean_squared_error: 12.4057\n",
            "Epoch 798/1000\n",
            "363/363 [==============================] - 0s 42us/step - loss: 38.1247 - mean_squared_error: 38.1247 - val_loss: 12.3812 - val_mean_squared_error: 12.3812\n",
            "Epoch 799/1000\n",
            "363/363 [==============================] - 0s 41us/step - loss: 34.4987 - mean_squared_error: 34.4987 - val_loss: 12.6380 - val_mean_squared_error: 12.6380\n",
            "Epoch 800/1000\n",
            "363/363 [==============================] - 0s 55us/step - loss: 37.2005 - mean_squared_error: 37.2005 - val_loss: 12.3987 - val_mean_squared_error: 12.3987\n",
            "Epoch 801/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 40.4940 - mean_squared_error: 40.4940 - val_loss: 12.3991 - val_mean_squared_error: 12.3991\n",
            "Epoch 802/1000\n",
            "363/363 [==============================] - 0s 41us/step - loss: 31.3765 - mean_squared_error: 31.3765 - val_loss: 12.4965 - val_mean_squared_error: 12.4965\n",
            "Epoch 803/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 33.8691 - mean_squared_error: 33.8691 - val_loss: 12.4054 - val_mean_squared_error: 12.4054\n",
            "Epoch 804/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 34.6706 - mean_squared_error: 34.6706 - val_loss: 12.4428 - val_mean_squared_error: 12.4428\n",
            "Epoch 805/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 33.5779 - mean_squared_error: 33.5779 - val_loss: 12.3814 - val_mean_squared_error: 12.3814\n",
            "Epoch 806/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 35.9809 - mean_squared_error: 35.9809 - val_loss: 12.4438 - val_mean_squared_error: 12.4438\n",
            "Epoch 807/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 37.6961 - mean_squared_error: 37.6961 - val_loss: 12.5437 - val_mean_squared_error: 12.5437\n",
            "Epoch 808/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 34.5753 - mean_squared_error: 34.5753 - val_loss: 12.4950 - val_mean_squared_error: 12.4950\n",
            "Epoch 809/1000\n",
            "363/363 [==============================] - 0s 40us/step - loss: 35.6398 - mean_squared_error: 35.6398 - val_loss: 12.4652 - val_mean_squared_error: 12.4652\n",
            "Epoch 810/1000\n",
            "363/363 [==============================] - 0s 39us/step - loss: 33.2855 - mean_squared_error: 33.2855 - val_loss: 12.5426 - val_mean_squared_error: 12.5426\n",
            "Epoch 811/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 35.7509 - mean_squared_error: 35.7509 - val_loss: 12.4699 - val_mean_squared_error: 12.4699\n",
            "Epoch 812/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 35.2892 - mean_squared_error: 35.2892 - val_loss: 12.6078 - val_mean_squared_error: 12.6078\n",
            "Epoch 813/1000\n",
            "363/363 [==============================] - 0s 42us/step - loss: 38.1775 - mean_squared_error: 38.1775 - val_loss: 12.3935 - val_mean_squared_error: 12.3935\n",
            "Epoch 814/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 33.1913 - mean_squared_error: 33.1913 - val_loss: 12.4504 - val_mean_squared_error: 12.4504\n",
            "Epoch 815/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 38.8983 - mean_squared_error: 38.8983 - val_loss: 12.3503 - val_mean_squared_error: 12.3503\n",
            "Epoch 816/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 35.2284 - mean_squared_error: 35.2284 - val_loss: 12.3466 - val_mean_squared_error: 12.3466\n",
            "Epoch 817/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 33.7016 - mean_squared_error: 33.7016 - val_loss: 12.2945 - val_mean_squared_error: 12.2945\n",
            "Epoch 818/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 34.6320 - mean_squared_error: 34.6320 - val_loss: 12.2968 - val_mean_squared_error: 12.2968\n",
            "Epoch 819/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 32.5287 - mean_squared_error: 32.5287 - val_loss: 12.2251 - val_mean_squared_error: 12.2251\n",
            "Epoch 820/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 31.8363 - mean_squared_error: 31.8363 - val_loss: 12.2299 - val_mean_squared_error: 12.2299\n",
            "Epoch 821/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 34.3861 - mean_squared_error: 34.3861 - val_loss: 12.2473 - val_mean_squared_error: 12.2473\n",
            "Epoch 822/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 34.0339 - mean_squared_error: 34.0339 - val_loss: 12.4173 - val_mean_squared_error: 12.4173\n",
            "Epoch 823/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 32.8026 - mean_squared_error: 32.8026 - val_loss: 12.6139 - val_mean_squared_error: 12.6139\n",
            "Epoch 824/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 33.1656 - mean_squared_error: 33.1656 - val_loss: 12.2714 - val_mean_squared_error: 12.2714\n",
            "Epoch 825/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 33.0715 - mean_squared_error: 33.0715 - val_loss: 12.4543 - val_mean_squared_error: 12.4543\n",
            "Epoch 826/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 33.9201 - mean_squared_error: 33.9201 - val_loss: 12.3302 - val_mean_squared_error: 12.3302\n",
            "Epoch 827/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 34.7526 - mean_squared_error: 34.7526 - val_loss: 12.5610 - val_mean_squared_error: 12.5610\n",
            "Epoch 828/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 33.5864 - mean_squared_error: 33.5864 - val_loss: 12.3932 - val_mean_squared_error: 12.3932\n",
            "Epoch 829/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 31.0114 - mean_squared_error: 31.0114 - val_loss: 12.4077 - val_mean_squared_error: 12.4077\n",
            "Epoch 830/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 31.6840 - mean_squared_error: 31.6840 - val_loss: 12.4311 - val_mean_squared_error: 12.4311\n",
            "Epoch 831/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 35.2171 - mean_squared_error: 35.2171 - val_loss: 12.2910 - val_mean_squared_error: 12.2910\n",
            "Epoch 832/1000\n",
            "363/363 [==============================] - 0s 40us/step - loss: 35.1617 - mean_squared_error: 35.1617 - val_loss: 12.2116 - val_mean_squared_error: 12.2116\n",
            "Epoch 833/1000\n",
            "363/363 [==============================] - 0s 40us/step - loss: 30.2581 - mean_squared_error: 30.2581 - val_loss: 12.3263 - val_mean_squared_error: 12.3263\n",
            "Epoch 834/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 31.6629 - mean_squared_error: 31.6629 - val_loss: 12.4218 - val_mean_squared_error: 12.4218\n",
            "Epoch 835/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 35.5691 - mean_squared_error: 35.5691 - val_loss: 12.3481 - val_mean_squared_error: 12.3481\n",
            "Epoch 836/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 34.6217 - mean_squared_error: 34.6217 - val_loss: 12.3211 - val_mean_squared_error: 12.3211\n",
            "Epoch 837/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 33.4786 - mean_squared_error: 33.4786 - val_loss: 12.2713 - val_mean_squared_error: 12.2713\n",
            "Epoch 838/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 32.2004 - mean_squared_error: 32.2004 - val_loss: 12.3634 - val_mean_squared_error: 12.3634\n",
            "Epoch 839/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 31.1991 - mean_squared_error: 31.1991 - val_loss: 12.3124 - val_mean_squared_error: 12.3124\n",
            "Epoch 840/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 33.7941 - mean_squared_error: 33.7941 - val_loss: 12.4842 - val_mean_squared_error: 12.4842\n",
            "Epoch 841/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 34.4123 - mean_squared_error: 34.4123 - val_loss: 12.6543 - val_mean_squared_error: 12.6543\n",
            "Epoch 842/1000\n",
            "363/363 [==============================] - 0s 42us/step - loss: 29.8383 - mean_squared_error: 29.8383 - val_loss: 12.3457 - val_mean_squared_error: 12.3457\n",
            "Epoch 843/1000\n",
            "363/363 [==============================] - 0s 41us/step - loss: 34.7729 - mean_squared_error: 34.7729 - val_loss: 12.4435 - val_mean_squared_error: 12.4435\n",
            "Epoch 844/1000\n",
            "363/363 [==============================] - 0s 41us/step - loss: 31.2029 - mean_squared_error: 31.2029 - val_loss: 12.7000 - val_mean_squared_error: 12.7000\n",
            "Epoch 845/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 36.5694 - mean_squared_error: 36.5694 - val_loss: 12.2654 - val_mean_squared_error: 12.2654\n",
            "Epoch 846/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 32.9596 - mean_squared_error: 32.9596 - val_loss: 12.2651 - val_mean_squared_error: 12.2651\n",
            "Epoch 847/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 27.2085 - mean_squared_error: 27.2085 - val_loss: 12.2781 - val_mean_squared_error: 12.2781\n",
            "Epoch 848/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 35.9541 - mean_squared_error: 35.9541 - val_loss: 12.3245 - val_mean_squared_error: 12.3245\n",
            "Epoch 849/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 31.2228 - mean_squared_error: 31.2228 - val_loss: 12.3117 - val_mean_squared_error: 12.3117\n",
            "Epoch 850/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 32.7651 - mean_squared_error: 32.7651 - val_loss: 12.2919 - val_mean_squared_error: 12.2919\n",
            "Epoch 851/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 34.3253 - mean_squared_error: 34.3253 - val_loss: 12.6361 - val_mean_squared_error: 12.6361\n",
            "Epoch 852/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 32.0611 - mean_squared_error: 32.0611 - val_loss: 12.3561 - val_mean_squared_error: 12.3561\n",
            "Epoch 853/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 36.8449 - mean_squared_error: 36.8449 - val_loss: 12.4210 - val_mean_squared_error: 12.4210\n",
            "Epoch 854/1000\n",
            "363/363 [==============================] - 0s 42us/step - loss: 34.3767 - mean_squared_error: 34.3767 - val_loss: 12.6336 - val_mean_squared_error: 12.6336\n",
            "Epoch 855/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 33.8988 - mean_squared_error: 33.8988 - val_loss: 12.2997 - val_mean_squared_error: 12.2997\n",
            "Epoch 856/1000\n",
            "363/363 [==============================] - 0s 42us/step - loss: 30.8011 - mean_squared_error: 30.8011 - val_loss: 12.5963 - val_mean_squared_error: 12.5963\n",
            "Epoch 857/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 35.6345 - mean_squared_error: 35.6345 - val_loss: 12.3996 - val_mean_squared_error: 12.3996\n",
            "Epoch 858/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 26.9454 - mean_squared_error: 26.9454 - val_loss: 12.3969 - val_mean_squared_error: 12.3969\n",
            "Epoch 859/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 33.3986 - mean_squared_error: 33.3986 - val_loss: 12.2771 - val_mean_squared_error: 12.2771\n",
            "Epoch 860/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 31.5362 - mean_squared_error: 31.5362 - val_loss: 12.2323 - val_mean_squared_error: 12.2323\n",
            "Epoch 861/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 29.1633 - mean_squared_error: 29.1633 - val_loss: 12.5762 - val_mean_squared_error: 12.5762\n",
            "Epoch 862/1000\n",
            "363/363 [==============================] - 0s 42us/step - loss: 28.2728 - mean_squared_error: 28.2728 - val_loss: 12.4639 - val_mean_squared_error: 12.4639\n",
            "Epoch 863/1000\n",
            "363/363 [==============================] - 0s 40us/step - loss: 30.1530 - mean_squared_error: 30.1530 - val_loss: 12.3384 - val_mean_squared_error: 12.3384\n",
            "Epoch 864/1000\n",
            "363/363 [==============================] - 0s 42us/step - loss: 33.2808 - mean_squared_error: 33.2808 - val_loss: 12.4826 - val_mean_squared_error: 12.4826\n",
            "Epoch 865/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 34.1488 - mean_squared_error: 34.1488 - val_loss: 12.2238 - val_mean_squared_error: 12.2238\n",
            "Epoch 866/1000\n",
            "363/363 [==============================] - 0s 42us/step - loss: 33.6872 - mean_squared_error: 33.6872 - val_loss: 12.2427 - val_mean_squared_error: 12.2427\n",
            "Epoch 867/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 30.3563 - mean_squared_error: 30.3563 - val_loss: 12.3299 - val_mean_squared_error: 12.3299\n",
            "Epoch 868/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 32.9117 - mean_squared_error: 32.9117 - val_loss: 12.6863 - val_mean_squared_error: 12.6863\n",
            "Epoch 869/1000\n",
            "363/363 [==============================] - 0s 41us/step - loss: 31.0404 - mean_squared_error: 31.0404 - val_loss: 12.2837 - val_mean_squared_error: 12.2837\n",
            "Epoch 870/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 31.3593 - mean_squared_error: 31.3593 - val_loss: 12.5479 - val_mean_squared_error: 12.5479\n",
            "Epoch 871/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 32.8328 - mean_squared_error: 32.8328 - val_loss: 12.4023 - val_mean_squared_error: 12.4023\n",
            "Epoch 872/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 32.0888 - mean_squared_error: 32.0888 - val_loss: 12.3059 - val_mean_squared_error: 12.3059\n",
            "Epoch 873/1000\n",
            "363/363 [==============================] - 0s 40us/step - loss: 28.2176 - mean_squared_error: 28.2176 - val_loss: 12.5972 - val_mean_squared_error: 12.5972\n",
            "Epoch 874/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 30.8683 - mean_squared_error: 30.8683 - val_loss: 12.2527 - val_mean_squared_error: 12.2527\n",
            "Epoch 875/1000\n",
            "363/363 [==============================] - 0s 41us/step - loss: 28.8029 - mean_squared_error: 28.8029 - val_loss: 12.2714 - val_mean_squared_error: 12.2714\n",
            "Epoch 876/1000\n",
            "363/363 [==============================] - 0s 41us/step - loss: 33.1504 - mean_squared_error: 33.1504 - val_loss: 12.5596 - val_mean_squared_error: 12.5596\n",
            "Epoch 877/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 29.2246 - mean_squared_error: 29.2246 - val_loss: 12.5140 - val_mean_squared_error: 12.5140\n",
            "Epoch 878/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 33.6842 - mean_squared_error: 33.6842 - val_loss: 12.4888 - val_mean_squared_error: 12.4888\n",
            "Epoch 879/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 30.1535 - mean_squared_error: 30.1535 - val_loss: 12.4335 - val_mean_squared_error: 12.4335\n",
            "Epoch 880/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 30.9785 - mean_squared_error: 30.9785 - val_loss: 12.5224 - val_mean_squared_error: 12.5224\n",
            "Epoch 881/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 29.2446 - mean_squared_error: 29.2446 - val_loss: 12.3829 - val_mean_squared_error: 12.3829\n",
            "Epoch 882/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 32.6731 - mean_squared_error: 32.6731 - val_loss: 13.0951 - val_mean_squared_error: 13.0951\n",
            "Epoch 883/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 34.9134 - mean_squared_error: 34.9134 - val_loss: 12.7270 - val_mean_squared_error: 12.7270\n",
            "Epoch 884/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 32.6313 - mean_squared_error: 32.6313 - val_loss: 12.4453 - val_mean_squared_error: 12.4453\n",
            "Epoch 885/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 33.1238 - mean_squared_error: 33.1238 - val_loss: 12.4005 - val_mean_squared_error: 12.4005\n",
            "Epoch 886/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 33.8031 - mean_squared_error: 33.8031 - val_loss: 12.3980 - val_mean_squared_error: 12.3980\n",
            "Epoch 887/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 29.4146 - mean_squared_error: 29.4146 - val_loss: 12.4714 - val_mean_squared_error: 12.4714\n",
            "Epoch 888/1000\n",
            "363/363 [==============================] - 0s 56us/step - loss: 28.5809 - mean_squared_error: 28.5809 - val_loss: 12.4501 - val_mean_squared_error: 12.4501\n",
            "Epoch 889/1000\n",
            "363/363 [==============================] - 0s 39us/step - loss: 32.9092 - mean_squared_error: 32.9092 - val_loss: 12.4698 - val_mean_squared_error: 12.4698\n",
            "Epoch 890/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 31.0276 - mean_squared_error: 31.0276 - val_loss: 12.6533 - val_mean_squared_error: 12.6533\n",
            "Epoch 891/1000\n",
            "363/363 [==============================] - 0s 41us/step - loss: 27.6522 - mean_squared_error: 27.6522 - val_loss: 12.9817 - val_mean_squared_error: 12.9817\n",
            "Epoch 892/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 30.9628 - mean_squared_error: 30.9628 - val_loss: 12.4505 - val_mean_squared_error: 12.4505\n",
            "Epoch 893/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 30.1546 - mean_squared_error: 30.1546 - val_loss: 12.4028 - val_mean_squared_error: 12.4028\n",
            "Epoch 894/1000\n",
            "363/363 [==============================] - 0s 57us/step - loss: 28.1311 - mean_squared_error: 28.1311 - val_loss: 12.5860 - val_mean_squared_error: 12.5860\n",
            "Epoch 895/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 30.4854 - mean_squared_error: 30.4854 - val_loss: 12.5899 - val_mean_squared_error: 12.5899\n",
            "Epoch 896/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 27.9087 - mean_squared_error: 27.9087 - val_loss: 12.7472 - val_mean_squared_error: 12.7472\n",
            "Epoch 897/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 29.3300 - mean_squared_error: 29.3300 - val_loss: 12.6239 - val_mean_squared_error: 12.6239\n",
            "Epoch 898/1000\n",
            "363/363 [==============================] - 0s 42us/step - loss: 31.1804 - mean_squared_error: 31.1804 - val_loss: 12.7127 - val_mean_squared_error: 12.7127\n",
            "Epoch 899/1000\n",
            "363/363 [==============================] - 0s 41us/step - loss: 31.8451 - mean_squared_error: 31.8451 - val_loss: 12.5655 - val_mean_squared_error: 12.5655\n",
            "Epoch 900/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 30.5353 - mean_squared_error: 30.5353 - val_loss: 12.6968 - val_mean_squared_error: 12.6968\n",
            "Epoch 901/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 25.3452 - mean_squared_error: 25.3452 - val_loss: 12.7247 - val_mean_squared_error: 12.7247\n",
            "Epoch 902/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 30.6105 - mean_squared_error: 30.6105 - val_loss: 12.6501 - val_mean_squared_error: 12.6501\n",
            "Epoch 903/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 26.7848 - mean_squared_error: 26.7848 - val_loss: 13.1254 - val_mean_squared_error: 13.1254\n",
            "Epoch 904/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 25.7934 - mean_squared_error: 25.7934 - val_loss: 12.6031 - val_mean_squared_error: 12.6031\n",
            "Epoch 905/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 31.8999 - mean_squared_error: 31.8999 - val_loss: 12.5077 - val_mean_squared_error: 12.5077\n",
            "Epoch 906/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 30.6066 - mean_squared_error: 30.6066 - val_loss: 12.5142 - val_mean_squared_error: 12.5142\n",
            "Epoch 907/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 31.5962 - mean_squared_error: 31.5962 - val_loss: 12.6927 - val_mean_squared_error: 12.6927\n",
            "Epoch 908/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 28.9976 - mean_squared_error: 28.9976 - val_loss: 12.6331 - val_mean_squared_error: 12.6331\n",
            "Epoch 909/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 31.4032 - mean_squared_error: 31.4032 - val_loss: 12.6637 - val_mean_squared_error: 12.6637\n",
            "Epoch 910/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 28.3472 - mean_squared_error: 28.3472 - val_loss: 12.7492 - val_mean_squared_error: 12.7492\n",
            "Epoch 911/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 28.5714 - mean_squared_error: 28.5714 - val_loss: 12.8237 - val_mean_squared_error: 12.8237\n",
            "Epoch 912/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 29.1006 - mean_squared_error: 29.1006 - val_loss: 12.6824 - val_mean_squared_error: 12.6824\n",
            "Epoch 913/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 27.2496 - mean_squared_error: 27.2496 - val_loss: 12.6811 - val_mean_squared_error: 12.6811\n",
            "Epoch 914/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 30.9295 - mean_squared_error: 30.9295 - val_loss: 12.5673 - val_mean_squared_error: 12.5673\n",
            "Epoch 915/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 33.9871 - mean_squared_error: 33.9871 - val_loss: 12.6036 - val_mean_squared_error: 12.6036\n",
            "Epoch 916/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 29.3437 - mean_squared_error: 29.3437 - val_loss: 12.8764 - val_mean_squared_error: 12.8764\n",
            "Epoch 917/1000\n",
            "363/363 [==============================] - 0s 42us/step - loss: 28.7860 - mean_squared_error: 28.7860 - val_loss: 12.7051 - val_mean_squared_error: 12.7051\n",
            "Epoch 918/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 26.2683 - mean_squared_error: 26.2683 - val_loss: 12.5601 - val_mean_squared_error: 12.5601\n",
            "Epoch 919/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 27.9553 - mean_squared_error: 27.9553 - val_loss: 12.5911 - val_mean_squared_error: 12.5911\n",
            "Epoch 920/1000\n",
            "363/363 [==============================] - 0s 60us/step - loss: 30.5713 - mean_squared_error: 30.5713 - val_loss: 12.8999 - val_mean_squared_error: 12.8999\n",
            "Epoch 921/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 28.0590 - mean_squared_error: 28.0590 - val_loss: 12.4968 - val_mean_squared_error: 12.4968\n",
            "Epoch 922/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 27.6685 - mean_squared_error: 27.6685 - val_loss: 13.2033 - val_mean_squared_error: 13.2033\n",
            "Epoch 923/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 26.3231 - mean_squared_error: 26.3231 - val_loss: 12.5510 - val_mean_squared_error: 12.5510\n",
            "Epoch 924/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 27.5804 - mean_squared_error: 27.5804 - val_loss: 12.5351 - val_mean_squared_error: 12.5351\n",
            "Epoch 925/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 29.0021 - mean_squared_error: 29.0021 - val_loss: 12.9920 - val_mean_squared_error: 12.9920\n",
            "Epoch 926/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 27.4017 - mean_squared_error: 27.4017 - val_loss: 12.7546 - val_mean_squared_error: 12.7546\n",
            "Epoch 927/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 28.9389 - mean_squared_error: 28.9389 - val_loss: 13.2549 - val_mean_squared_error: 13.2549\n",
            "Epoch 928/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 29.8577 - mean_squared_error: 29.8577 - val_loss: 12.7228 - val_mean_squared_error: 12.7228\n",
            "Epoch 929/1000\n",
            "363/363 [==============================] - 0s 42us/step - loss: 27.3468 - mean_squared_error: 27.3468 - val_loss: 12.5010 - val_mean_squared_error: 12.5010\n",
            "Epoch 930/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 30.8109 - mean_squared_error: 30.8109 - val_loss: 12.7733 - val_mean_squared_error: 12.7733\n",
            "Epoch 931/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 30.6568 - mean_squared_error: 30.6568 - val_loss: 12.5050 - val_mean_squared_error: 12.5050\n",
            "Epoch 932/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 29.2432 - mean_squared_error: 29.2432 - val_loss: 12.5505 - val_mean_squared_error: 12.5505\n",
            "Epoch 933/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 26.5087 - mean_squared_error: 26.5087 - val_loss: 12.6511 - val_mean_squared_error: 12.6511\n",
            "Epoch 934/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 27.3103 - mean_squared_error: 27.3103 - val_loss: 12.8416 - val_mean_squared_error: 12.8416\n",
            "Epoch 935/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 26.2037 - mean_squared_error: 26.2037 - val_loss: 13.0676 - val_mean_squared_error: 13.0676\n",
            "Epoch 936/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 28.5276 - mean_squared_error: 28.5276 - val_loss: 12.8617 - val_mean_squared_error: 12.8617\n",
            "Epoch 937/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 28.7624 - mean_squared_error: 28.7624 - val_loss: 12.7388 - val_mean_squared_error: 12.7388\n",
            "Epoch 938/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 30.3314 - mean_squared_error: 30.3314 - val_loss: 12.8394 - val_mean_squared_error: 12.8394\n",
            "Epoch 939/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 29.4251 - mean_squared_error: 29.4251 - val_loss: 12.9451 - val_mean_squared_error: 12.9451\n",
            "Epoch 940/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 25.0210 - mean_squared_error: 25.0210 - val_loss: 12.6675 - val_mean_squared_error: 12.6675\n",
            "Epoch 941/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 29.3971 - mean_squared_error: 29.3971 - val_loss: 12.7808 - val_mean_squared_error: 12.7808\n",
            "Epoch 942/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 27.8445 - mean_squared_error: 27.8445 - val_loss: 12.6320 - val_mean_squared_error: 12.6320\n",
            "Epoch 943/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 29.2960 - mean_squared_error: 29.2960 - val_loss: 12.8195 - val_mean_squared_error: 12.8195\n",
            "Epoch 944/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 26.5317 - mean_squared_error: 26.5317 - val_loss: 12.6984 - val_mean_squared_error: 12.6984\n",
            "Epoch 945/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 27.3786 - mean_squared_error: 27.3786 - val_loss: 12.6838 - val_mean_squared_error: 12.6838\n",
            "Epoch 946/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 29.8356 - mean_squared_error: 29.8356 - val_loss: 12.6334 - val_mean_squared_error: 12.6334\n",
            "Epoch 947/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 28.6049 - mean_squared_error: 28.6049 - val_loss: 12.6370 - val_mean_squared_error: 12.6370\n",
            "Epoch 948/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 30.0935 - mean_squared_error: 30.0935 - val_loss: 12.7052 - val_mean_squared_error: 12.7052\n",
            "Epoch 949/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 28.0964 - mean_squared_error: 28.0964 - val_loss: 13.1136 - val_mean_squared_error: 13.1136\n",
            "Epoch 950/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 27.4117 - mean_squared_error: 27.4117 - val_loss: 12.6860 - val_mean_squared_error: 12.6860\n",
            "Epoch 951/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 30.2098 - mean_squared_error: 30.2098 - val_loss: 12.6790 - val_mean_squared_error: 12.6790\n",
            "Epoch 952/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 25.4012 - mean_squared_error: 25.4012 - val_loss: 13.0756 - val_mean_squared_error: 13.0756\n",
            "Epoch 953/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 27.6089 - mean_squared_error: 27.6089 - val_loss: 13.1353 - val_mean_squared_error: 13.1353\n",
            "Epoch 954/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 24.6819 - mean_squared_error: 24.6819 - val_loss: 12.5893 - val_mean_squared_error: 12.5893\n",
            "Epoch 955/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 28.2534 - mean_squared_error: 28.2534 - val_loss: 12.8086 - val_mean_squared_error: 12.8086\n",
            "Epoch 956/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 26.8146 - mean_squared_error: 26.8146 - val_loss: 12.6882 - val_mean_squared_error: 12.6882\n",
            "Epoch 957/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 26.8595 - mean_squared_error: 26.8595 - val_loss: 12.6529 - val_mean_squared_error: 12.6529\n",
            "Epoch 958/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 31.0571 - mean_squared_error: 31.0571 - val_loss: 12.6285 - val_mean_squared_error: 12.6285\n",
            "Epoch 959/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 29.1313 - mean_squared_error: 29.1313 - val_loss: 12.8682 - val_mean_squared_error: 12.8682\n",
            "Epoch 960/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 24.2407 - mean_squared_error: 24.2407 - val_loss: 12.6910 - val_mean_squared_error: 12.6910\n",
            "Epoch 961/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 27.3352 - mean_squared_error: 27.3352 - val_loss: 12.6073 - val_mean_squared_error: 12.6073\n",
            "Epoch 962/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 28.0680 - mean_squared_error: 28.0680 - val_loss: 12.7150 - val_mean_squared_error: 12.7150\n",
            "Epoch 963/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 27.2118 - mean_squared_error: 27.2118 - val_loss: 12.8801 - val_mean_squared_error: 12.8801\n",
            "Epoch 964/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 27.3897 - mean_squared_error: 27.3897 - val_loss: 12.7863 - val_mean_squared_error: 12.7863\n",
            "Epoch 965/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 29.2466 - mean_squared_error: 29.2466 - val_loss: 12.7448 - val_mean_squared_error: 12.7448\n",
            "Epoch 966/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 26.6961 - mean_squared_error: 26.6961 - val_loss: 12.8027 - val_mean_squared_error: 12.8027\n",
            "Epoch 967/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 30.2170 - mean_squared_error: 30.2170 - val_loss: 13.1846 - val_mean_squared_error: 13.1846\n",
            "Epoch 968/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 27.8074 - mean_squared_error: 27.8074 - val_loss: 13.6193 - val_mean_squared_error: 13.6193\n",
            "Epoch 969/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 29.2634 - mean_squared_error: 29.2634 - val_loss: 13.1512 - val_mean_squared_error: 13.1512\n",
            "Epoch 970/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 26.8714 - mean_squared_error: 26.8714 - val_loss: 12.9326 - val_mean_squared_error: 12.9326\n",
            "Epoch 971/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 25.9189 - mean_squared_error: 25.9189 - val_loss: 12.6156 - val_mean_squared_error: 12.6156\n",
            "Epoch 972/1000\n",
            "363/363 [==============================] - 0s 41us/step - loss: 34.3678 - mean_squared_error: 34.3678 - val_loss: 12.6474 - val_mean_squared_error: 12.6474\n",
            "Epoch 973/1000\n",
            "363/363 [==============================] - 0s 59us/step - loss: 25.9153 - mean_squared_error: 25.9153 - val_loss: 13.0547 - val_mean_squared_error: 13.0547\n",
            "Epoch 974/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 26.2689 - mean_squared_error: 26.2689 - val_loss: 12.8098 - val_mean_squared_error: 12.8098\n",
            "Epoch 975/1000\n",
            "363/363 [==============================] - 0s 42us/step - loss: 27.3073 - mean_squared_error: 27.3073 - val_loss: 12.9198 - val_mean_squared_error: 12.9198\n",
            "Epoch 976/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 28.1664 - mean_squared_error: 28.1664 - val_loss: 12.9089 - val_mean_squared_error: 12.9089\n",
            "Epoch 977/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 29.0460 - mean_squared_error: 29.0460 - val_loss: 12.8280 - val_mean_squared_error: 12.8280\n",
            "Epoch 978/1000\n",
            "363/363 [==============================] - 0s 56us/step - loss: 27.4047 - mean_squared_error: 27.4047 - val_loss: 12.7377 - val_mean_squared_error: 12.7377\n",
            "Epoch 979/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 25.7026 - mean_squared_error: 25.7026 - val_loss: 13.0202 - val_mean_squared_error: 13.0202\n",
            "Epoch 980/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 26.4544 - mean_squared_error: 26.4544 - val_loss: 12.7802 - val_mean_squared_error: 12.7802\n",
            "Epoch 981/1000\n",
            "363/363 [==============================] - 0s 41us/step - loss: 26.6923 - mean_squared_error: 26.6923 - val_loss: 12.9118 - val_mean_squared_error: 12.9118\n",
            "Epoch 982/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 27.8304 - mean_squared_error: 27.8304 - val_loss: 12.7353 - val_mean_squared_error: 12.7353\n",
            "Epoch 983/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 28.8275 - mean_squared_error: 28.8275 - val_loss: 13.0882 - val_mean_squared_error: 13.0882\n",
            "Epoch 984/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 22.9380 - mean_squared_error: 22.9380 - val_loss: 12.6986 - val_mean_squared_error: 12.6986\n",
            "Epoch 985/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 25.9163 - mean_squared_error: 25.9163 - val_loss: 12.8691 - val_mean_squared_error: 12.8691\n",
            "Epoch 986/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 28.6503 - mean_squared_error: 28.6503 - val_loss: 13.2931 - val_mean_squared_error: 13.2931\n",
            "Epoch 987/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 24.6909 - mean_squared_error: 24.6909 - val_loss: 12.9345 - val_mean_squared_error: 12.9345\n",
            "Epoch 988/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 26.3854 - mean_squared_error: 26.3854 - val_loss: 12.5848 - val_mean_squared_error: 12.5848\n",
            "Epoch 989/1000\n",
            "363/363 [==============================] - 0s 41us/step - loss: 26.3966 - mean_squared_error: 26.3966 - val_loss: 12.7281 - val_mean_squared_error: 12.7281\n",
            "Epoch 990/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 29.0991 - mean_squared_error: 29.0991 - val_loss: 12.9403 - val_mean_squared_error: 12.9403\n",
            "Epoch 991/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 25.9246 - mean_squared_error: 25.9246 - val_loss: 12.9512 - val_mean_squared_error: 12.9512\n",
            "Epoch 992/1000\n",
            "363/363 [==============================] - 0s 40us/step - loss: 28.7682 - mean_squared_error: 28.7682 - val_loss: 12.7462 - val_mean_squared_error: 12.7462\n",
            "Epoch 993/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 22.1192 - mean_squared_error: 22.1192 - val_loss: 12.7231 - val_mean_squared_error: 12.7231\n",
            "Epoch 994/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 27.2991 - mean_squared_error: 27.2991 - val_loss: 12.7697 - val_mean_squared_error: 12.7697\n",
            "Epoch 995/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 25.8529 - mean_squared_error: 25.8529 - val_loss: 12.6470 - val_mean_squared_error: 12.6470\n",
            "Epoch 996/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 28.0930 - mean_squared_error: 28.0930 - val_loss: 12.6335 - val_mean_squared_error: 12.6335\n",
            "Epoch 997/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 27.3814 - mean_squared_error: 27.3814 - val_loss: 13.1487 - val_mean_squared_error: 13.1487\n",
            "Epoch 998/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 25.6401 - mean_squared_error: 25.6401 - val_loss: 12.9982 - val_mean_squared_error: 12.9982\n",
            "Epoch 999/1000\n",
            "363/363 [==============================] - 0s 43us/step - loss: 25.6285 - mean_squared_error: 25.6285 - val_loss: 13.0648 - val_mean_squared_error: 13.0648\n",
            "Epoch 1000/1000\n",
            "363/363 [==============================] - 0s 44us/step - loss: 24.9971 - mean_squared_error: 24.9971 - val_loss: 12.7335 - val_mean_squared_error: 12.7335\n",
            "102/102 [==============================] - 0s 62us/step\n",
            "After 1000 epochs:  loss: 29.37628974166571\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyyzdirX2hht",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfcFnOONyuNm",
        "colab_type": "text"
      },
      "source": [
        "## Use the Keras Library to build an image recognition network using the Fashion-MNIST dataset (also comes with keras)\n",
        "\n",
        "- Load and preprocess the image data similar to how we preprocessed the MNIST data in class.\n",
        "- Make sure to one-hot encode your category labels\n",
        "- Make sure to have your final layer have as many nodes as the number of classes that you want to predict.\n",
        "- Try different hyperparameters. What is the highest accuracy that you are able to achieve.\n",
        "- Use the history object that is returned from model.fit to make graphs of the model's loss or train/validation accuracies by epoch. \n",
        "- Remember that neural networks fall prey to randomness so you may need to run your model multiple times (or use Cross Validation) in order to tell if a change to a hyperparameter is truly producing better results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szi6-IpuzaH1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##### Your Code Here #####\n",
        "from keras.datasets import fashion_mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLNlRHa55Okt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 64\n",
        "num_classes = 10\n",
        "epochs = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCTiQSG3_Mz4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "f6190210-2277-455c-804d-81b71a203c90"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "X_train = X_train.reshape(60000,784)\n",
        "X_test = X_test.reshape(10000,784)\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "\n",
        "print(X_train.shape[0], 'Train Samples')\n",
        "print(X_test.shape[0], 'Test Samples')"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 5us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 2s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 1s 0us/step\n",
            "60000 Train Samples\n",
            "10000 Test Samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbwwM1EOBrGK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "9d50c7e9-a954-4fe0-c7d9-2df5dc8bc85f"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(32,activation='relu', input_shape=(784,)))\n",
        "model.add(Dense(32,activation='relu'))\n",
        "model.add(Dense(num_classes,activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='mean_squared_error',\n",
        "              metrics=['mean_squared_error'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_11 (Dense)             (None, 32)                25120     \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 26,506\n",
            "Trainable params: 26,506\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3ydRUXHCFDt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "outputId": "a2273216-a6a3-47b3-fc9c-a628f2d8b7a8"
      },
      "source": [
        "#https://github.com/keras-team/keras/blob/master/examples/mnist_dataset_api.py\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import tempfile\n",
        "\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras import layers\n",
        "from keras.datasets import fashion_mnist\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "def cnn_layers(inputs):\n",
        "    X = layers.Conv2D(32, (3, 3),\n",
        "                      activation='relu', padding='valid')(inputs)\n",
        "    X = layers.MaxPooling2D(pool_size=(2, 2))(X)\n",
        "    X = layers.Conv2D(64, (3, 3), activation='relu')(X)\n",
        "    X = layers.MaxPooling2D(pool_size=(2, 2))(X)\n",
        "    X = layers.Flatten()(X)\n",
        "    X = layers.Dense(512, activation='relu')(X)\n",
        "    X = layers.Dropout(0.5)(X)\n",
        "    predictions = layers.Dense(num_classes,\n",
        "                               activation='softmax',\n",
        "                               name='X_train_out')(X)\n",
        "    return predictions\n",
        "\n",
        "\n",
        "batch_size = 128\n",
        "buffer_size = 10000\n",
        "steps_per_epoch = int(np.ceil(60000 / float(batch_size)))  # = 469\n",
        "epochs = 5\n",
        "num_classes = 10\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "X_train = X_train.astype(np.float32) / 255\n",
        "X_train = np.expand_dims(X_train, -1)\n",
        "y_train = tf.one_hot(y_train, num_classes)\n",
        "\n",
        "# Create the dataset and its associated one-shot iterator.\n",
        "dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "dataset = dataset.repeat()\n",
        "dataset = dataset.shuffle(buffer_size)\n",
        "dataset = dataset.batch(batch_size)\n",
        "iterator = dataset.make_one_shot_iterator()\n",
        "\n",
        "# Model creation using tensors from the get_next() graph node.\n",
        "inputs, targets = iterator.get_next()\n",
        "model_input = layers.Input(tensor=inputs)\n",
        "model_output = cnn_layers(model_input)\n",
        "train_model = keras.models.Model(inputs=model_input, outputs=model_output)\n",
        "\n",
        "train_model.compile(optimizer=keras.optimizers.RMSprop(lr=2e-3, decay=1e-5),\n",
        "                    loss='categorical_crossentropy',\n",
        "                    metrics=['accuracy'],\n",
        "                    target_tensors=[targets])\n",
        "train_model.summary()\n",
        "\n",
        "train_model.fit(epochs=epochs,\n",
        "                steps_per_epoch=steps_per_epoch)\n",
        "\n",
        "# Save the model weights.\n",
        "weight = os.path.join(tempfile.gettempdir(), 'saved_weight.h5')\n",
        "train_model.save_weights(weight)\n",
        "\n",
        "# Clean up the TF session.\n",
        "K.clear_session()\n",
        "\n",
        "# Second session to test loading trained model without tensors.\n",
        "X_test = X_test.astype(np.float32)\n",
        "X_test = np.eXpand_dims(X_test, -1)\n",
        "\n",
        "X_test_inp = layers.Input(shape=X_test.shape[1:])\n",
        "test_out = cnn_layers(X_test_inp)\n",
        "test_model = keras.models.Model(inputs=X_test_inp, outputs=test_out)\n",
        "\n",
        "test_model.load_weights(weight_path)\n",
        "test_model.compile(optimizer='rmsprop',\n",
        "                   loss='sparse_categorical_crossentropy',\n",
        "                   metrics=['accuracy'])\n",
        "test_model.summary()\n",
        "\n",
        "loss, acc = test_model.evaluate(X_test, y_test, num_classes)\n",
        "print('\\nTest accuracy: {0}'.format(acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 11, 11, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 512)               819712    \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "X_train_out (Dense)          (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 843,658\n",
            "Trainable params: 843,658\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "469/469 [==============================] - 66s 141ms/step - loss: 0.1577 - acc: 0.9511\n",
            "Epoch 2/5\n",
            "118/469 [======>.......................] - ETA: 44s - loss: 0.0547 - acc: 0.9831"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zv_3xNMjzdLI",
        "colab_type": "text"
      },
      "source": [
        "## Stretch Goals:\n",
        "\n",
        "- Use Hyperparameter Tuning to make the accuracy of your models as high as possible. (error as low as possible)\n",
        "- Use Cross Validation techniques to get more consistent results with your model.\n",
        "- Use GridSearchCV to try different combinations of hyperparameters. \n",
        "- Start looking into other types of Keras layers for CNNs and RNNs maybe try and build a CNN model for fashion-MNIST to see how the results compare."
      ]
    }
  ]
}