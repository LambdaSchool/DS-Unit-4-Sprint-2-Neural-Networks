{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LS_DS_433_Keras_Assignment.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DimaKav/DS-Unit-4-Sprint-3-Neural-Networks/blob/master/module3-Intro-to-Keras/LS_DS_433_Keras_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBQsZEJmubLs",
        "colab_type": "text"
      },
      "source": [
        "## Use the Keras Library to build a Multi-Layer Perceptron Model on the Boston Housing dataset\n",
        "\n",
        "- The Boston Housing dataset comes with the Keras library so use Keras to import it into your notebook. \n",
        "- Normalize the data (all features should have roughly the same scale)\n",
        "- Import the type of model and layers that you will need from Keras.\n",
        "- Instantiate a model object and use `model.add()` to add layers to your model\n",
        "- Since this is a regression model you will have a single output node in the final layer.\n",
        "- Use activation functions that are appropriate for this task\n",
        "- Compile your model\n",
        "- Fit your model and report its accuracy in terms of Mean Squared Error\n",
        "- Use the history object that is returned from model.fit to make graphs of the model's loss or train/validation accuracies by epoch. \n",
        "- Run this same data through a linear regression model. Which achieves higher accuracy?\n",
        "- Do a little bit of feature engineering and see how that affects your neural network model. (you will need to change your model to accept more inputs)\n",
        "- After feature engineering, which model sees a greater accuracy boost due to the new features?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ri35azDdmR_j",
        "colab_type": "text"
      },
      "source": [
        "# Scope out the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NLTAR87uYJ-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bb0e8395-f85d-4a70-8247-482ba2878c7f"
      },
      "source": [
        "import keras\n",
        "from keras.datasets import boston_housing"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gL2pf6STkxMS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(X_train, y_train),(X_test,y_test)=boston_housing.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZh0F6KfkzMK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f1ab536d-6a69-4171-8235-fe36f9060a85"
      },
      "source": [
        "X_train[1], y_train[1]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([2.1770e-02, 8.2500e+01, 2.0300e+00, 0.0000e+00, 4.1500e-01,\n",
              "        7.6100e+00, 1.5700e+01, 6.2700e+00, 2.0000e+00, 3.4800e+02,\n",
              "        1.4700e+01, 3.9538e+02, 3.1100e+00]), 42.3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EK7nw9Aofcrq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ae4fa7e6-5b54-4f24-eb95-fc5b47feb7c1"
      },
      "source": [
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((404, 13), (404,), (102, 13), (102,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmkwDpr7iUzV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "30a0b064-f58d-4544-a822-f017a9c45344"
      },
      "source": [
        "X_train.dtype"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('float64')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSxqancnk-kt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "column_names=['CRIM','ZN','INDUS','CHAS','NOX','RM','AGE','DIS','RAD','TAX',\n",
        "              'PTRATIO','B','LSTAT']\n",
        "              \n",
        "key= ['Per capita crime rate.',\n",
        "    'The proportion of residential land zoned for lots over 25,000\\\n",
        "     square feet.',\n",
        "    'The proportion of non-retail business acres per town.',\n",
        "    'Charles River dummy variable (=1 if tract bounds river; 0\\\n",
        "     otherwise).',\n",
        "    'Nitric oxides concentration (parts per 10 million).',\n",
        "    'The average number of rooms per dwelling.',\n",
        "    'The porportion of owner-occupied units built before 1940.',\n",
        "    'Weighted distances to five Boston employment centers.',\n",
        "    'Index of accessibility to radial highways.',\n",
        "    'Full-value property tax rate per $10,000.',\n",
        "    'Pupil-Teacher ratio by town.',\n",
        "    '1000*(Bk-0.63)**2 where Bk is the proportion of Black people by\\\n",
        "     town.',\n",
        "    'Percentage lower status of the population.']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qm1XQqhRk-iJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "959e4b6e-0f62-4c5d-807b-4522459daea7"
      },
      "source": [
        "import pandas as pd\n",
        "df= pd.DataFrame(X_train, columns=column_names)\n",
        "df.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CRIM</th>\n",
              "      <th>ZN</th>\n",
              "      <th>INDUS</th>\n",
              "      <th>CHAS</th>\n",
              "      <th>NOX</th>\n",
              "      <th>RM</th>\n",
              "      <th>AGE</th>\n",
              "      <th>DIS</th>\n",
              "      <th>RAD</th>\n",
              "      <th>TAX</th>\n",
              "      <th>PTRATIO</th>\n",
              "      <th>B</th>\n",
              "      <th>LSTAT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.23247</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.14</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.538</td>\n",
              "      <td>6.142</td>\n",
              "      <td>91.7</td>\n",
              "      <td>3.9769</td>\n",
              "      <td>4.0</td>\n",
              "      <td>307.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>396.90</td>\n",
              "      <td>18.72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.02177</td>\n",
              "      <td>82.5</td>\n",
              "      <td>2.03</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.415</td>\n",
              "      <td>7.610</td>\n",
              "      <td>15.7</td>\n",
              "      <td>6.2700</td>\n",
              "      <td>2.0</td>\n",
              "      <td>348.0</td>\n",
              "      <td>14.7</td>\n",
              "      <td>395.38</td>\n",
              "      <td>3.11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.89822</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18.10</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.631</td>\n",
              "      <td>4.970</td>\n",
              "      <td>100.0</td>\n",
              "      <td>1.3325</td>\n",
              "      <td>24.0</td>\n",
              "      <td>666.0</td>\n",
              "      <td>20.2</td>\n",
              "      <td>375.52</td>\n",
              "      <td>3.26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.03961</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.19</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.515</td>\n",
              "      <td>6.037</td>\n",
              "      <td>34.5</td>\n",
              "      <td>5.9853</td>\n",
              "      <td>5.0</td>\n",
              "      <td>224.0</td>\n",
              "      <td>20.2</td>\n",
              "      <td>396.90</td>\n",
              "      <td>8.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3.69311</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18.10</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.713</td>\n",
              "      <td>6.376</td>\n",
              "      <td>88.4</td>\n",
              "      <td>2.5671</td>\n",
              "      <td>24.0</td>\n",
              "      <td>666.0</td>\n",
              "      <td>20.2</td>\n",
              "      <td>391.43</td>\n",
              "      <td>14.65</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      CRIM    ZN  INDUS  CHAS    NOX     RM    AGE     DIS   RAD    TAX  \\\n",
              "0  1.23247   0.0   8.14   0.0  0.538  6.142   91.7  3.9769   4.0  307.0   \n",
              "1  0.02177  82.5   2.03   0.0  0.415  7.610   15.7  6.2700   2.0  348.0   \n",
              "2  4.89822   0.0  18.10   0.0  0.631  4.970  100.0  1.3325  24.0  666.0   \n",
              "3  0.03961   0.0   5.19   0.0  0.515  6.037   34.5  5.9853   5.0  224.0   \n",
              "4  3.69311   0.0  18.10   0.0  0.713  6.376   88.4  2.5671  24.0  666.0   \n",
              "\n",
              "   PTRATIO       B  LSTAT  \n",
              "0     21.0  396.90  18.72  \n",
              "1     14.7  395.38   3.11  \n",
              "2     20.2  375.52   3.26  \n",
              "3     20.2  396.90   8.01  \n",
              "4     20.2  391.43  14.65  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7-sckPbD9NV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUCDxHBUk-dJ",
        "colab_type": "text"
      },
      "source": [
        "# Build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88GZwe9p6uQn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "2e281dac-7f22-4929-fbc1-c7028c117b98"
      },
      "source": [
        "mean = X_train.mean(axis=0)\n",
        "std = X_train.std(axis=0)\n",
        "x_train = (X_train - mean)/std\n",
        "x_test = (X_test - mean)/std\n",
        "print(x_train[0])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-0.27224633 -0.48361547 -0.43576161 -0.25683275 -0.1652266  -0.1764426\n",
            "  0.81306188  0.1166983  -0.62624905 -0.59517003  1.14850044  0.44807713\n",
            "  0.8252202 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCVfmolfEBXe",
        "colab_type": "text"
      },
      "source": [
        "#### Linear regression first..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EuU_ZJsEEhc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "520bf3f4-f5e1-4939-951b-0a949de29090"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "lr = LinearRegression()\n",
        "lr.fit(X_train, y_train)\n",
        "y_pred = lr.predict(X_test)\n",
        "mean_squared_error(y_test, y_pred)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23.195599256422906"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iY2MmDJnE9v3",
        "colab_type": "text"
      },
      "source": [
        "Should not be hard to beast this score..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V36h0_9L6uNp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "f9977b29-65a2-43d4-881b-e8e97af939cb"
      },
      "source": [
        "from keras.layers import Dense, Dropout\n",
        "from keras.models import Sequential\n",
        "model= Sequential()\n",
        "model.add(Dense(26, activation='relu',input_shape=(13,)))\n",
        "model.add(Dense(26, activation='relu'))\n",
        "model.add(Dense(12, activation='relu'))\n",
        "model.add(Dense(1))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLvvSZXe6uDW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "a3b14554-e2b2-4a6b-e247-610137fc458b"
      },
      "source": [
        "from keras import optimizers\n",
        "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
        "              loss='mse', metrics=['mae'])\n",
        "model.summary()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 26)                364       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 26)                702       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 12)                324       \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 13        \n",
            "=================================================================\n",
            "Total params: 1,403\n",
            "Trainable params: 1,403\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgupgzN67u_S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34071
        },
        "outputId": "f00b4781-af71-4a85-c1cb-24654d31b2b8"
      },
      "source": [
        "history = model.fit(X_train, y_train, epochs=1000, validation_split=.1)\n",
        "scores = model.evaluate(X_test, y_test)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 363 samples, validate on 41 samples\n",
            "Epoch 1/1000\n",
            "363/363 [==============================] - 0s 64us/step - loss: 15.3343 - mean_absolute_error: 2.8282 - val_loss: 21.0408 - val_mean_absolute_error: 3.4755\n",
            "Epoch 2/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 25.7477 - mean_absolute_error: 3.4219 - val_loss: 19.4203 - val_mean_absolute_error: 3.4331\n",
            "Epoch 3/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 14.7253 - mean_absolute_error: 2.7510 - val_loss: 19.4639 - val_mean_absolute_error: 3.4256\n",
            "Epoch 4/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 23.1647 - mean_absolute_error: 3.4440 - val_loss: 20.0413 - val_mean_absolute_error: 3.5325\n",
            "Epoch 5/1000\n",
            "363/363 [==============================] - 0s 56us/step - loss: 14.5472 - mean_absolute_error: 2.7527 - val_loss: 25.2948 - val_mean_absolute_error: 3.6862\n",
            "Epoch 6/1000\n",
            "363/363 [==============================] - 0s 58us/step - loss: 16.9044 - mean_absolute_error: 2.9618 - val_loss: 20.7709 - val_mean_absolute_error: 3.5555\n",
            "Epoch 7/1000\n",
            "363/363 [==============================] - 0s 66us/step - loss: 16.6558 - mean_absolute_error: 2.9461 - val_loss: 32.8541 - val_mean_absolute_error: 4.4557\n",
            "Epoch 8/1000\n",
            "363/363 [==============================] - 0s 58us/step - loss: 20.7469 - mean_absolute_error: 3.1963 - val_loss: 29.1931 - val_mean_absolute_error: 4.1224\n",
            "Epoch 9/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 15.6721 - mean_absolute_error: 2.8409 - val_loss: 32.9142 - val_mean_absolute_error: 4.4632\n",
            "Epoch 10/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 17.5904 - mean_absolute_error: 3.0143 - val_loss: 19.9133 - val_mean_absolute_error: 3.4522\n",
            "Epoch 11/1000\n",
            "363/363 [==============================] - 0s 60us/step - loss: 19.8518 - mean_absolute_error: 3.2398 - val_loss: 22.5502 - val_mean_absolute_error: 3.3694\n",
            "Epoch 12/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 14.9166 - mean_absolute_error: 2.8400 - val_loss: 20.0452 - val_mean_absolute_error: 3.3182\n",
            "Epoch 13/1000\n",
            "363/363 [==============================] - 0s 56us/step - loss: 22.4113 - mean_absolute_error: 3.2797 - val_loss: 20.4862 - val_mean_absolute_error: 3.6019\n",
            "Epoch 14/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 14.1235 - mean_absolute_error: 2.7057 - val_loss: 24.3211 - val_mean_absolute_error: 3.9390\n",
            "Epoch 15/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 16.3734 - mean_absolute_error: 2.9683 - val_loss: 19.1789 - val_mean_absolute_error: 3.3176\n",
            "Epoch 16/1000\n",
            "363/363 [==============================] - 0s 60us/step - loss: 24.2783 - mean_absolute_error: 3.3236 - val_loss: 28.8194 - val_mean_absolute_error: 4.0700\n",
            "Epoch 17/1000\n",
            "363/363 [==============================] - 0s 57us/step - loss: 17.2957 - mean_absolute_error: 2.9028 - val_loss: 27.1860 - val_mean_absolute_error: 3.8392\n",
            "Epoch 18/1000\n",
            "363/363 [==============================] - 0s 58us/step - loss: 12.2170 - mean_absolute_error: 2.5965 - val_loss: 25.1186 - val_mean_absolute_error: 3.7916\n",
            "Epoch 19/1000\n",
            "363/363 [==============================] - 0s 56us/step - loss: 17.6782 - mean_absolute_error: 3.0171 - val_loss: 21.1978 - val_mean_absolute_error: 3.6585\n",
            "Epoch 20/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 16.5639 - mean_absolute_error: 2.9103 - val_loss: 24.3130 - val_mean_absolute_error: 3.9544\n",
            "Epoch 21/1000\n",
            "363/363 [==============================] - 0s 59us/step - loss: 17.7898 - mean_absolute_error: 3.0919 - val_loss: 18.2893 - val_mean_absolute_error: 3.2092\n",
            "Epoch 22/1000\n",
            "363/363 [==============================] - 0s 58us/step - loss: 20.4097 - mean_absolute_error: 3.1347 - val_loss: 28.9919 - val_mean_absolute_error: 4.0727\n",
            "Epoch 23/1000\n",
            "363/363 [==============================] - 0s 65us/step - loss: 14.9966 - mean_absolute_error: 2.8296 - val_loss: 21.0317 - val_mean_absolute_error: 3.4872\n",
            "Epoch 24/1000\n",
            "363/363 [==============================] - 0s 64us/step - loss: 20.7616 - mean_absolute_error: 3.2745 - val_loss: 20.4690 - val_mean_absolute_error: 3.2588\n",
            "Epoch 25/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 15.7477 - mean_absolute_error: 2.7796 - val_loss: 19.5676 - val_mean_absolute_error: 3.2689\n",
            "Epoch 26/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 18.0328 - mean_absolute_error: 2.9082 - val_loss: 18.7847 - val_mean_absolute_error: 3.3242\n",
            "Epoch 27/1000\n",
            "363/363 [==============================] - 0s 60us/step - loss: 19.8518 - mean_absolute_error: 3.1539 - val_loss: 32.2425 - val_mean_absolute_error: 4.3573\n",
            "Epoch 28/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 22.1469 - mean_absolute_error: 3.1368 - val_loss: 25.9443 - val_mean_absolute_error: 3.7735\n",
            "Epoch 29/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 12.3581 - mean_absolute_error: 2.5484 - val_loss: 23.7854 - val_mean_absolute_error: 3.6139\n",
            "Epoch 30/1000\n",
            "363/363 [==============================] - 0s 59us/step - loss: 18.7408 - mean_absolute_error: 3.0517 - val_loss: 27.4963 - val_mean_absolute_error: 3.9470\n",
            "Epoch 31/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 18.1381 - mean_absolute_error: 3.0333 - val_loss: 18.5915 - val_mean_absolute_error: 3.3542\n",
            "Epoch 32/1000\n",
            "363/363 [==============================] - 0s 56us/step - loss: 17.6008 - mean_absolute_error: 2.9547 - val_loss: 22.9547 - val_mean_absolute_error: 3.8148\n",
            "Epoch 33/1000\n",
            "363/363 [==============================] - 0s 66us/step - loss: 18.0628 - mean_absolute_error: 2.9620 - val_loss: 21.9935 - val_mean_absolute_error: 3.7026\n",
            "Epoch 34/1000\n",
            "363/363 [==============================] - 0s 60us/step - loss: 14.6395 - mean_absolute_error: 2.8300 - val_loss: 20.3874 - val_mean_absolute_error: 3.3853\n",
            "Epoch 35/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 15.7055 - mean_absolute_error: 2.8642 - val_loss: 19.0901 - val_mean_absolute_error: 3.1947\n",
            "Epoch 36/1000\n",
            "363/363 [==============================] - 0s 59us/step - loss: 17.5276 - mean_absolute_error: 2.9500 - val_loss: 19.5037 - val_mean_absolute_error: 3.4841\n",
            "Epoch 37/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 15.6004 - mean_absolute_error: 2.9029 - val_loss: 33.2422 - val_mean_absolute_error: 4.4292\n",
            "Epoch 38/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 14.5903 - mean_absolute_error: 2.7702 - val_loss: 76.7092 - val_mean_absolute_error: 7.3327\n",
            "Epoch 39/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 23.9271 - mean_absolute_error: 3.2896 - val_loss: 24.6371 - val_mean_absolute_error: 3.6693\n",
            "Epoch 40/1000\n",
            "363/363 [==============================] - 0s 56us/step - loss: 15.4604 - mean_absolute_error: 2.7601 - val_loss: 21.2420 - val_mean_absolute_error: 3.5740\n",
            "Epoch 41/1000\n",
            "363/363 [==============================] - 0s 72us/step - loss: 18.0829 - mean_absolute_error: 3.0648 - val_loss: 23.2797 - val_mean_absolute_error: 3.8260\n",
            "Epoch 42/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 13.6396 - mean_absolute_error: 2.6680 - val_loss: 22.4292 - val_mean_absolute_error: 3.7241\n",
            "Epoch 43/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 16.5644 - mean_absolute_error: 2.9159 - val_loss: 33.8509 - val_mean_absolute_error: 4.4545\n",
            "Epoch 44/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 18.6752 - mean_absolute_error: 3.1777 - val_loss: 22.0816 - val_mean_absolute_error: 3.4555\n",
            "Epoch 45/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 12.6650 - mean_absolute_error: 2.5991 - val_loss: 29.5862 - val_mean_absolute_error: 4.2083\n",
            "Epoch 46/1000\n",
            "363/363 [==============================] - 0s 57us/step - loss: 22.8685 - mean_absolute_error: 3.4665 - val_loss: 19.0639 - val_mean_absolute_error: 3.1792\n",
            "Epoch 47/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 14.4289 - mean_absolute_error: 2.6939 - val_loss: 29.3883 - val_mean_absolute_error: 4.0531\n",
            "Epoch 48/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 15.3542 - mean_absolute_error: 2.8822 - val_loss: 29.4534 - val_mean_absolute_error: 4.3746\n",
            "Epoch 49/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 18.6411 - mean_absolute_error: 3.0986 - val_loss: 24.1161 - val_mean_absolute_error: 3.9029\n",
            "Epoch 50/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 15.6264 - mean_absolute_error: 2.9251 - val_loss: 21.3575 - val_mean_absolute_error: 3.2873\n",
            "Epoch 51/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 16.1680 - mean_absolute_error: 2.9712 - val_loss: 23.7115 - val_mean_absolute_error: 3.4870\n",
            "Epoch 52/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 19.4596 - mean_absolute_error: 3.0814 - val_loss: 19.9310 - val_mean_absolute_error: 3.5158\n",
            "Epoch 53/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 14.5593 - mean_absolute_error: 2.8051 - val_loss: 19.8891 - val_mean_absolute_error: 3.5368\n",
            "Epoch 54/1000\n",
            "363/363 [==============================] - 0s 57us/step - loss: 23.0718 - mean_absolute_error: 3.2948 - val_loss: 19.7660 - val_mean_absolute_error: 3.5014\n",
            "Epoch 55/1000\n",
            "363/363 [==============================] - 0s 56us/step - loss: 12.1070 - mean_absolute_error: 2.5616 - val_loss: 21.1157 - val_mean_absolute_error: 3.5381\n",
            "Epoch 56/1000\n",
            "363/363 [==============================] - 0s 61us/step - loss: 15.8997 - mean_absolute_error: 2.9188 - val_loss: 31.6753 - val_mean_absolute_error: 4.6394\n",
            "Epoch 57/1000\n",
            "363/363 [==============================] - 0s 57us/step - loss: 15.0052 - mean_absolute_error: 2.8405 - val_loss: 28.3540 - val_mean_absolute_error: 4.3429\n",
            "Epoch 58/1000\n",
            "363/363 [==============================] - 0s 55us/step - loss: 21.5814 - mean_absolute_error: 3.2437 - val_loss: 23.7335 - val_mean_absolute_error: 3.5877\n",
            "Epoch 59/1000\n",
            "363/363 [==============================] - 0s 63us/step - loss: 15.9952 - mean_absolute_error: 2.9160 - val_loss: 21.8215 - val_mean_absolute_error: 3.5388\n",
            "Epoch 60/1000\n",
            "363/363 [==============================] - 0s 67us/step - loss: 16.7732 - mean_absolute_error: 2.9579 - val_loss: 19.8965 - val_mean_absolute_error: 3.2489\n",
            "Epoch 61/1000\n",
            "363/363 [==============================] - 0s 68us/step - loss: 13.7939 - mean_absolute_error: 2.7315 - val_loss: 31.8669 - val_mean_absolute_error: 4.6224\n",
            "Epoch 62/1000\n",
            "363/363 [==============================] - 0s 55us/step - loss: 19.7446 - mean_absolute_error: 3.0999 - val_loss: 19.4459 - val_mean_absolute_error: 3.4525\n",
            "Epoch 63/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 24.4144 - mean_absolute_error: 3.3712 - val_loss: 21.8684 - val_mean_absolute_error: 3.4812\n",
            "Epoch 64/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 13.3741 - mean_absolute_error: 2.5984 - val_loss: 19.0527 - val_mean_absolute_error: 3.3377\n",
            "Epoch 65/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 14.9927 - mean_absolute_error: 2.7652 - val_loss: 19.3910 - val_mean_absolute_error: 3.4454\n",
            "Epoch 66/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 19.2624 - mean_absolute_error: 3.1058 - val_loss: 20.6149 - val_mean_absolute_error: 3.6235\n",
            "Epoch 67/1000\n",
            "363/363 [==============================] - 0s 58us/step - loss: 14.4697 - mean_absolute_error: 2.7700 - val_loss: 32.8048 - val_mean_absolute_error: 4.4504\n",
            "Epoch 68/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 18.5004 - mean_absolute_error: 3.0796 - val_loss: 19.6985 - val_mean_absolute_error: 3.5080\n",
            "Epoch 69/1000\n",
            "363/363 [==============================] - 0s 63us/step - loss: 17.3650 - mean_absolute_error: 2.9873 - val_loss: 21.6085 - val_mean_absolute_error: 3.5331\n",
            "Epoch 70/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 12.7761 - mean_absolute_error: 2.5976 - val_loss: 30.7846 - val_mean_absolute_error: 4.1167\n",
            "Epoch 71/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 15.1802 - mean_absolute_error: 2.8775 - val_loss: 19.1965 - val_mean_absolute_error: 3.3519\n",
            "Epoch 72/1000\n",
            "363/363 [==============================] - 0s 56us/step - loss: 15.4344 - mean_absolute_error: 2.8211 - val_loss: 18.9636 - val_mean_absolute_error: 3.4682\n",
            "Epoch 73/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 16.8569 - mean_absolute_error: 2.9826 - val_loss: 33.5817 - val_mean_absolute_error: 4.7725\n",
            "Epoch 74/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 19.5647 - mean_absolute_error: 3.1708 - val_loss: 23.1875 - val_mean_absolute_error: 3.5759\n",
            "Epoch 75/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 18.3663 - mean_absolute_error: 3.0549 - val_loss: 26.2292 - val_mean_absolute_error: 3.6640\n",
            "Epoch 76/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 17.4830 - mean_absolute_error: 2.9964 - val_loss: 68.2985 - val_mean_absolute_error: 6.9049\n",
            "Epoch 77/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 26.6656 - mean_absolute_error: 3.2744 - val_loss: 22.6618 - val_mean_absolute_error: 3.5599\n",
            "Epoch 78/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 14.5028 - mean_absolute_error: 2.7119 - val_loss: 18.4074 - val_mean_absolute_error: 3.3074\n",
            "Epoch 79/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 13.2923 - mean_absolute_error: 2.6861 - val_loss: 18.9942 - val_mean_absolute_error: 3.4449\n",
            "Epoch 80/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 17.1412 - mean_absolute_error: 3.0105 - val_loss: 23.1272 - val_mean_absolute_error: 3.5019\n",
            "Epoch 81/1000\n",
            "363/363 [==============================] - 0s 65us/step - loss: 16.8694 - mean_absolute_error: 2.8278 - val_loss: 19.7397 - val_mean_absolute_error: 3.4682\n",
            "Epoch 82/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 15.0949 - mean_absolute_error: 2.7876 - val_loss: 17.9916 - val_mean_absolute_error: 3.1093\n",
            "Epoch 83/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 17.4954 - mean_absolute_error: 2.9662 - val_loss: 24.9200 - val_mean_absolute_error: 3.6772\n",
            "Epoch 84/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 17.1645 - mean_absolute_error: 2.9656 - val_loss: 18.3501 - val_mean_absolute_error: 3.1617\n",
            "Epoch 85/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 13.3200 - mean_absolute_error: 2.6077 - val_loss: 25.3304 - val_mean_absolute_error: 3.6469\n",
            "Epoch 86/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 17.2959 - mean_absolute_error: 3.0304 - val_loss: 22.7311 - val_mean_absolute_error: 3.4586\n",
            "Epoch 87/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 16.7492 - mean_absolute_error: 2.8657 - val_loss: 24.5913 - val_mean_absolute_error: 3.5518\n",
            "Epoch 88/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 14.0503 - mean_absolute_error: 2.6436 - val_loss: 19.7514 - val_mean_absolute_error: 3.4612\n",
            "Epoch 89/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 17.9872 - mean_absolute_error: 3.0528 - val_loss: 21.1766 - val_mean_absolute_error: 3.6612\n",
            "Epoch 90/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 15.1984 - mean_absolute_error: 2.7709 - val_loss: 19.9341 - val_mean_absolute_error: 3.5333\n",
            "Epoch 91/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 16.6373 - mean_absolute_error: 2.9870 - val_loss: 20.2973 - val_mean_absolute_error: 3.4703\n",
            "Epoch 92/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 13.8782 - mean_absolute_error: 2.6657 - val_loss: 33.7326 - val_mean_absolute_error: 4.8360\n",
            "Epoch 93/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 15.8157 - mean_absolute_error: 2.9817 - val_loss: 30.7529 - val_mean_absolute_error: 4.5828\n",
            "Epoch 94/1000\n",
            "363/363 [==============================] - 0s 57us/step - loss: 18.0042 - mean_absolute_error: 3.1392 - val_loss: 20.1278 - val_mean_absolute_error: 3.3981\n",
            "Epoch 95/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 15.0060 - mean_absolute_error: 2.8129 - val_loss: 20.8713 - val_mean_absolute_error: 3.6068\n",
            "Epoch 96/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 17.2648 - mean_absolute_error: 2.9917 - val_loss: 20.2176 - val_mean_absolute_error: 3.4259\n",
            "Epoch 97/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 14.3762 - mean_absolute_error: 2.7028 - val_loss: 41.6673 - val_mean_absolute_error: 5.3868\n",
            "Epoch 98/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 18.6558 - mean_absolute_error: 2.9267 - val_loss: 32.6106 - val_mean_absolute_error: 4.6496\n",
            "Epoch 99/1000\n",
            "363/363 [==============================] - 0s 58us/step - loss: 17.8400 - mean_absolute_error: 3.0242 - val_loss: 22.3911 - val_mean_absolute_error: 3.4082\n",
            "Epoch 100/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 13.8809 - mean_absolute_error: 2.6934 - val_loss: 18.9101 - val_mean_absolute_error: 3.3962\n",
            "Epoch 101/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 22.5659 - mean_absolute_error: 3.2057 - val_loss: 21.6382 - val_mean_absolute_error: 3.5401\n",
            "Epoch 102/1000\n",
            "363/363 [==============================] - 0s 63us/step - loss: 15.1592 - mean_absolute_error: 2.7401 - val_loss: 23.5257 - val_mean_absolute_error: 3.5983\n",
            "Epoch 103/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 13.1582 - mean_absolute_error: 2.6225 - val_loss: 22.6288 - val_mean_absolute_error: 3.5287\n",
            "Epoch 104/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 19.7340 - mean_absolute_error: 3.0906 - val_loss: 18.8114 - val_mean_absolute_error: 3.3599\n",
            "Epoch 105/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 12.3579 - mean_absolute_error: 2.5523 - val_loss: 23.5086 - val_mean_absolute_error: 3.3991\n",
            "Epoch 106/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 18.6485 - mean_absolute_error: 2.9660 - val_loss: 21.0086 - val_mean_absolute_error: 3.3724\n",
            "Epoch 107/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 12.7659 - mean_absolute_error: 2.6221 - val_loss: 20.3502 - val_mean_absolute_error: 3.4092\n",
            "Epoch 108/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 20.3785 - mean_absolute_error: 3.0624 - val_loss: 20.3146 - val_mean_absolute_error: 3.6250\n",
            "Epoch 109/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 13.1585 - mean_absolute_error: 2.6261 - val_loss: 19.7121 - val_mean_absolute_error: 3.5152\n",
            "Epoch 110/1000\n",
            "363/363 [==============================] - 0s 57us/step - loss: 15.6032 - mean_absolute_error: 2.9460 - val_loss: 19.6915 - val_mean_absolute_error: 3.5417\n",
            "Epoch 111/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 13.9141 - mean_absolute_error: 2.7875 - val_loss: 21.9103 - val_mean_absolute_error: 3.6107\n",
            "Epoch 112/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 18.8931 - mean_absolute_error: 3.0508 - val_loss: 17.8380 - val_mean_absolute_error: 3.1886\n",
            "Epoch 113/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 12.8168 - mean_absolute_error: 2.6394 - val_loss: 19.5258 - val_mean_absolute_error: 3.4432\n",
            "Epoch 114/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 18.4900 - mean_absolute_error: 2.9506 - val_loss: 18.4589 - val_mean_absolute_error: 3.3241\n",
            "Epoch 115/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 17.8793 - mean_absolute_error: 2.9139 - val_loss: 48.9006 - val_mean_absolute_error: 5.8512\n",
            "Epoch 116/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 16.3385 - mean_absolute_error: 2.9567 - val_loss: 19.3252 - val_mean_absolute_error: 3.5171\n",
            "Epoch 117/1000\n",
            "363/363 [==============================] - 0s 57us/step - loss: 16.5416 - mean_absolute_error: 2.8620 - val_loss: 22.5758 - val_mean_absolute_error: 3.4681\n",
            "Epoch 118/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 15.8929 - mean_absolute_error: 2.8015 - val_loss: 30.2554 - val_mean_absolute_error: 4.5298\n",
            "Epoch 119/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 14.7622 - mean_absolute_error: 2.7675 - val_loss: 25.6991 - val_mean_absolute_error: 3.7653\n",
            "Epoch 120/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 17.8761 - mean_absolute_error: 2.9506 - val_loss: 31.5192 - val_mean_absolute_error: 4.2738\n",
            "Epoch 121/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 13.6553 - mean_absolute_error: 2.6625 - val_loss: 21.8237 - val_mean_absolute_error: 3.4263\n",
            "Epoch 122/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 15.9933 - mean_absolute_error: 2.8403 - val_loss: 18.0838 - val_mean_absolute_error: 3.3044\n",
            "Epoch 123/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 13.5689 - mean_absolute_error: 2.6698 - val_loss: 20.1589 - val_mean_absolute_error: 3.3924\n",
            "Epoch 124/1000\n",
            "363/363 [==============================] - 0s 60us/step - loss: 17.4205 - mean_absolute_error: 2.8875 - val_loss: 33.4174 - val_mean_absolute_error: 4.6223\n",
            "Epoch 125/1000\n",
            "363/363 [==============================] - 0s 59us/step - loss: 15.5803 - mean_absolute_error: 2.8516 - val_loss: 19.9255 - val_mean_absolute_error: 3.5053\n",
            "Epoch 126/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 17.5836 - mean_absolute_error: 3.0490 - val_loss: 17.9178 - val_mean_absolute_error: 3.3030\n",
            "Epoch 127/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 14.4269 - mean_absolute_error: 2.7880 - val_loss: 18.8890 - val_mean_absolute_error: 3.4934\n",
            "Epoch 128/1000\n",
            "363/363 [==============================] - 0s 55us/step - loss: 16.0951 - mean_absolute_error: 2.7346 - val_loss: 41.7020 - val_mean_absolute_error: 5.2643\n",
            "Epoch 129/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 16.0910 - mean_absolute_error: 2.7611 - val_loss: 19.1916 - val_mean_absolute_error: 3.2858\n",
            "Epoch 130/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 20.4969 - mean_absolute_error: 3.0227 - val_loss: 18.9687 - val_mean_absolute_error: 3.4575\n",
            "Epoch 131/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 13.3873 - mean_absolute_error: 2.6449 - val_loss: 26.2897 - val_mean_absolute_error: 4.1768\n",
            "Epoch 132/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 12.9928 - mean_absolute_error: 2.6268 - val_loss: 21.1278 - val_mean_absolute_error: 3.6136\n",
            "Epoch 133/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 17.6169 - mean_absolute_error: 3.0696 - val_loss: 58.4944 - val_mean_absolute_error: 6.2729\n",
            "Epoch 134/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 16.1378 - mean_absolute_error: 2.8510 - val_loss: 22.6328 - val_mean_absolute_error: 3.5261\n",
            "Epoch 135/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 17.5367 - mean_absolute_error: 2.9236 - val_loss: 25.0514 - val_mean_absolute_error: 3.6803\n",
            "Epoch 136/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 13.8613 - mean_absolute_error: 2.7336 - val_loss: 21.1215 - val_mean_absolute_error: 3.6331\n",
            "Epoch 137/1000\n",
            "363/363 [==============================] - 0s 55us/step - loss: 14.6909 - mean_absolute_error: 2.7706 - val_loss: 23.7771 - val_mean_absolute_error: 3.6684\n",
            "Epoch 138/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 17.3894 - mean_absolute_error: 2.9357 - val_loss: 17.7548 - val_mean_absolute_error: 3.2644\n",
            "Epoch 139/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 15.2872 - mean_absolute_error: 2.7656 - val_loss: 22.0222 - val_mean_absolute_error: 3.5111\n",
            "Epoch 140/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 11.7369 - mean_absolute_error: 2.4779 - val_loss: 20.2241 - val_mean_absolute_error: 3.4387\n",
            "Epoch 141/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 20.3496 - mean_absolute_error: 2.9976 - val_loss: 20.0466 - val_mean_absolute_error: 3.4310\n",
            "Epoch 142/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 13.3920 - mean_absolute_error: 2.6231 - val_loss: 22.5777 - val_mean_absolute_error: 3.7310\n",
            "Epoch 143/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 15.2925 - mean_absolute_error: 2.7060 - val_loss: 20.2947 - val_mean_absolute_error: 3.5378\n",
            "Epoch 144/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 18.9995 - mean_absolute_error: 3.0706 - val_loss: 17.9794 - val_mean_absolute_error: 3.3036\n",
            "Epoch 145/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 15.8245 - mean_absolute_error: 2.7755 - val_loss: 18.9550 - val_mean_absolute_error: 3.3158\n",
            "Epoch 146/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 13.0171 - mean_absolute_error: 2.6558 - val_loss: 24.6759 - val_mean_absolute_error: 3.6284\n",
            "Epoch 147/1000\n",
            "363/363 [==============================] - 0s 55us/step - loss: 15.1789 - mean_absolute_error: 2.8304 - val_loss: 19.8617 - val_mean_absolute_error: 3.5728\n",
            "Epoch 148/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 15.1139 - mean_absolute_error: 2.7581 - val_loss: 23.6816 - val_mean_absolute_error: 3.8942\n",
            "Epoch 149/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 12.6373 - mean_absolute_error: 2.5445 - val_loss: 36.1111 - val_mean_absolute_error: 4.7259\n",
            "Epoch 150/1000\n",
            "363/363 [==============================] - 0s 55us/step - loss: 18.6172 - mean_absolute_error: 3.0552 - val_loss: 20.5211 - val_mean_absolute_error: 3.5504\n",
            "Epoch 151/1000\n",
            "363/363 [==============================] - 0s 59us/step - loss: 16.8386 - mean_absolute_error: 2.7782 - val_loss: 48.5997 - val_mean_absolute_error: 5.7428\n",
            "Epoch 152/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 21.3802 - mean_absolute_error: 3.2284 - val_loss: 26.2381 - val_mean_absolute_error: 4.0982\n",
            "Epoch 153/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 11.5449 - mean_absolute_error: 2.5364 - val_loss: 19.1333 - val_mean_absolute_error: 3.4426\n",
            "Epoch 154/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 14.6341 - mean_absolute_error: 2.7857 - val_loss: 20.2640 - val_mean_absolute_error: 3.6185\n",
            "Epoch 155/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 11.9756 - mean_absolute_error: 2.5595 - val_loss: 27.6313 - val_mean_absolute_error: 4.0464\n",
            "Epoch 156/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 17.4402 - mean_absolute_error: 2.9199 - val_loss: 30.9270 - val_mean_absolute_error: 4.4558\n",
            "Epoch 157/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 18.1437 - mean_absolute_error: 2.9298 - val_loss: 23.4227 - val_mean_absolute_error: 3.4990\n",
            "Epoch 158/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 11.1052 - mean_absolute_error: 2.4555 - val_loss: 24.7515 - val_mean_absolute_error: 3.9555\n",
            "Epoch 159/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 15.4805 - mean_absolute_error: 2.8511 - val_loss: 18.5768 - val_mean_absolute_error: 3.4404\n",
            "Epoch 160/1000\n",
            "363/363 [==============================] - 0s 55us/step - loss: 17.1224 - mean_absolute_error: 2.7692 - val_loss: 26.3236 - val_mean_absolute_error: 4.1067\n",
            "Epoch 161/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 15.9077 - mean_absolute_error: 2.8710 - val_loss: 22.1522 - val_mean_absolute_error: 3.4321\n",
            "Epoch 162/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 14.4070 - mean_absolute_error: 2.7744 - val_loss: 31.0644 - val_mean_absolute_error: 4.3524\n",
            "Epoch 163/1000\n",
            "363/363 [==============================] - 0s 55us/step - loss: 16.9563 - mean_absolute_error: 2.9359 - val_loss: 20.1735 - val_mean_absolute_error: 3.3936\n",
            "Epoch 164/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 17.7904 - mean_absolute_error: 2.9321 - val_loss: 34.3294 - val_mean_absolute_error: 4.5850\n",
            "Epoch 165/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 14.1867 - mean_absolute_error: 2.7464 - val_loss: 20.4251 - val_mean_absolute_error: 3.5557\n",
            "Epoch 166/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 15.1079 - mean_absolute_error: 2.6929 - val_loss: 19.0431 - val_mean_absolute_error: 3.4246\n",
            "Epoch 167/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 18.5455 - mean_absolute_error: 2.9178 - val_loss: 20.5084 - val_mean_absolute_error: 3.4054\n",
            "Epoch 168/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 12.4137 - mean_absolute_error: 2.5117 - val_loss: 20.3978 - val_mean_absolute_error: 3.4056\n",
            "Epoch 169/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 12.8859 - mean_absolute_error: 2.5782 - val_loss: 20.8508 - val_mean_absolute_error: 3.2276\n",
            "Epoch 170/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 14.4105 - mean_absolute_error: 2.7591 - val_loss: 26.5614 - val_mean_absolute_error: 4.2118\n",
            "Epoch 171/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 18.7598 - mean_absolute_error: 2.9826 - val_loss: 39.8867 - val_mean_absolute_error: 5.2614\n",
            "Epoch 172/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 15.6119 - mean_absolute_error: 2.6995 - val_loss: 25.4050 - val_mean_absolute_error: 3.8787\n",
            "Epoch 173/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 14.4241 - mean_absolute_error: 2.7914 - val_loss: 21.4366 - val_mean_absolute_error: 3.4549\n",
            "Epoch 174/1000\n",
            "363/363 [==============================] - 0s 57us/step - loss: 19.3634 - mean_absolute_error: 2.9590 - val_loss: 22.1900 - val_mean_absolute_error: 3.6730\n",
            "Epoch 175/1000\n",
            "363/363 [==============================] - 0s 56us/step - loss: 14.2127 - mean_absolute_error: 2.6651 - val_loss: 30.3426 - val_mean_absolute_error: 4.1741\n",
            "Epoch 176/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 20.9504 - mean_absolute_error: 3.1289 - val_loss: 19.0499 - val_mean_absolute_error: 3.4730\n",
            "Epoch 177/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 12.2460 - mean_absolute_error: 2.5743 - val_loss: 18.7718 - val_mean_absolute_error: 3.3682\n",
            "Epoch 178/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 12.5646 - mean_absolute_error: 2.6077 - val_loss: 20.7144 - val_mean_absolute_error: 3.3896\n",
            "Epoch 179/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 15.6278 - mean_absolute_error: 2.7885 - val_loss: 67.4643 - val_mean_absolute_error: 6.8297\n",
            "Epoch 180/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 16.8082 - mean_absolute_error: 2.8723 - val_loss: 19.9771 - val_mean_absolute_error: 3.6303\n",
            "Epoch 181/1000\n",
            "363/363 [==============================] - 0s 61us/step - loss: 16.7972 - mean_absolute_error: 2.8925 - val_loss: 18.2663 - val_mean_absolute_error: 3.2009\n",
            "Epoch 182/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 10.7635 - mean_absolute_error: 2.4198 - val_loss: 21.2503 - val_mean_absolute_error: 3.5348\n",
            "Epoch 183/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 15.3680 - mean_absolute_error: 2.7964 - val_loss: 30.9312 - val_mean_absolute_error: 4.2135\n",
            "Epoch 184/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 15.4375 - mean_absolute_error: 2.7407 - val_loss: 20.1009 - val_mean_absolute_error: 3.3223\n",
            "Epoch 185/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 12.1660 - mean_absolute_error: 2.5332 - val_loss: 20.2858 - val_mean_absolute_error: 3.6296\n",
            "Epoch 186/1000\n",
            "363/363 [==============================] - 0s 58us/step - loss: 21.6060 - mean_absolute_error: 3.1238 - val_loss: 21.7554 - val_mean_absolute_error: 3.5825\n",
            "Epoch 187/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 12.1068 - mean_absolute_error: 2.5567 - val_loss: 20.8487 - val_mean_absolute_error: 3.3384\n",
            "Epoch 188/1000\n",
            "363/363 [==============================] - 0s 60us/step - loss: 17.4479 - mean_absolute_error: 3.0148 - val_loss: 18.0950 - val_mean_absolute_error: 3.1766\n",
            "Epoch 189/1000\n",
            "363/363 [==============================] - 0s 68us/step - loss: 12.9390 - mean_absolute_error: 2.5488 - val_loss: 25.5324 - val_mean_absolute_error: 3.8013\n",
            "Epoch 190/1000\n",
            "363/363 [==============================] - 0s 73us/step - loss: 14.5220 - mean_absolute_error: 2.7720 - val_loss: 22.4356 - val_mean_absolute_error: 3.7924\n",
            "Epoch 191/1000\n",
            "363/363 [==============================] - 0s 57us/step - loss: 15.3541 - mean_absolute_error: 2.7404 - val_loss: 24.3569 - val_mean_absolute_error: 3.7856\n",
            "Epoch 192/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 14.8444 - mean_absolute_error: 2.8590 - val_loss: 17.3369 - val_mean_absolute_error: 3.2954\n",
            "Epoch 193/1000\n",
            "363/363 [==============================] - 0s 55us/step - loss: 13.9581 - mean_absolute_error: 2.7208 - val_loss: 22.2430 - val_mean_absolute_error: 3.7557\n",
            "Epoch 194/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 16.1668 - mean_absolute_error: 2.8465 - val_loss: 23.6040 - val_mean_absolute_error: 3.6661\n",
            "Epoch 195/1000\n",
            "363/363 [==============================] - 0s 55us/step - loss: 16.6084 - mean_absolute_error: 2.8445 - val_loss: 20.6229 - val_mean_absolute_error: 3.4975\n",
            "Epoch 196/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 16.6091 - mean_absolute_error: 2.8179 - val_loss: 43.5951 - val_mean_absolute_error: 5.4437\n",
            "Epoch 197/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 19.2060 - mean_absolute_error: 3.0594 - val_loss: 17.9481 - val_mean_absolute_error: 3.3777\n",
            "Epoch 198/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 12.0874 - mean_absolute_error: 2.4672 - val_loss: 38.4457 - val_mean_absolute_error: 5.0439\n",
            "Epoch 199/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 14.8351 - mean_absolute_error: 2.6651 - val_loss: 21.6990 - val_mean_absolute_error: 3.8218\n",
            "Epoch 200/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 14.2970 - mean_absolute_error: 2.6330 - val_loss: 20.7435 - val_mean_absolute_error: 3.5174\n",
            "Epoch 201/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 14.2939 - mean_absolute_error: 2.6581 - val_loss: 23.0412 - val_mean_absolute_error: 3.8600\n",
            "Epoch 202/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 15.3661 - mean_absolute_error: 2.8823 - val_loss: 22.1365 - val_mean_absolute_error: 3.7673\n",
            "Epoch 203/1000\n",
            "363/363 [==============================] - 0s 55us/step - loss: 14.3753 - mean_absolute_error: 2.7377 - val_loss: 26.9005 - val_mean_absolute_error: 3.9366\n",
            "Epoch 204/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 13.0490 - mean_absolute_error: 2.5660 - val_loss: 25.7603 - val_mean_absolute_error: 3.9561\n",
            "Epoch 205/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 15.1560 - mean_absolute_error: 2.7319 - val_loss: 19.0154 - val_mean_absolute_error: 3.4580\n",
            "Epoch 206/1000\n",
            "363/363 [==============================] - 0s 60us/step - loss: 15.4889 - mean_absolute_error: 2.8313 - val_loss: 27.6341 - val_mean_absolute_error: 4.3351\n",
            "Epoch 207/1000\n",
            "363/363 [==============================] - 0s 55us/step - loss: 17.6414 - mean_absolute_error: 2.8706 - val_loss: 27.1499 - val_mean_absolute_error: 3.9739\n",
            "Epoch 208/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 17.7998 - mean_absolute_error: 2.8731 - val_loss: 19.1230 - val_mean_absolute_error: 3.2927\n",
            "Epoch 209/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 11.6568 - mean_absolute_error: 2.5109 - val_loss: 19.3333 - val_mean_absolute_error: 3.4697\n",
            "Epoch 210/1000\n",
            "363/363 [==============================] - 0s 58us/step - loss: 18.8610 - mean_absolute_error: 3.0950 - val_loss: 20.6150 - val_mean_absolute_error: 3.4194\n",
            "Epoch 211/1000\n",
            "363/363 [==============================] - 0s 58us/step - loss: 14.6072 - mean_absolute_error: 2.6244 - val_loss: 19.4379 - val_mean_absolute_error: 3.5032\n",
            "Epoch 212/1000\n",
            "363/363 [==============================] - 0s 58us/step - loss: 15.5921 - mean_absolute_error: 2.7204 - val_loss: 24.9567 - val_mean_absolute_error: 3.7127\n",
            "Epoch 213/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 12.2214 - mean_absolute_error: 2.5787 - val_loss: 17.6032 - val_mean_absolute_error: 3.1665\n",
            "Epoch 214/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 15.3298 - mean_absolute_error: 2.7496 - val_loss: 22.7405 - val_mean_absolute_error: 3.6187\n",
            "Epoch 215/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 11.6893 - mean_absolute_error: 2.4546 - val_loss: 19.8073 - val_mean_absolute_error: 3.5648\n",
            "Epoch 216/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 14.1035 - mean_absolute_error: 2.6674 - val_loss: 20.2575 - val_mean_absolute_error: 3.5092\n",
            "Epoch 217/1000\n",
            "363/363 [==============================] - 0s 55us/step - loss: 15.5987 - mean_absolute_error: 2.8693 - val_loss: 27.2179 - val_mean_absolute_error: 4.1862\n",
            "Epoch 218/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 13.2360 - mean_absolute_error: 2.5734 - val_loss: 25.5351 - val_mean_absolute_error: 3.6175\n",
            "Epoch 219/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 15.5456 - mean_absolute_error: 2.8453 - val_loss: 18.8677 - val_mean_absolute_error: 3.4425\n",
            "Epoch 220/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 12.5317 - mean_absolute_error: 2.5824 - val_loss: 20.8399 - val_mean_absolute_error: 3.4717\n",
            "Epoch 221/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 17.3492 - mean_absolute_error: 2.9091 - val_loss: 21.5467 - val_mean_absolute_error: 3.7926\n",
            "Epoch 222/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 13.2687 - mean_absolute_error: 2.6502 - val_loss: 42.0119 - val_mean_absolute_error: 5.3743\n",
            "Epoch 223/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 18.8807 - mean_absolute_error: 2.7602 - val_loss: 18.9411 - val_mean_absolute_error: 3.3398\n",
            "Epoch 224/1000\n",
            "363/363 [==============================] - 0s 60us/step - loss: 11.7687 - mean_absolute_error: 2.4643 - val_loss: 19.2780 - val_mean_absolute_error: 3.4762\n",
            "Epoch 225/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 18.5978 - mean_absolute_error: 2.8893 - val_loss: 26.4616 - val_mean_absolute_error: 3.8672\n",
            "Epoch 226/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 13.6728 - mean_absolute_error: 2.6160 - val_loss: 20.7791 - val_mean_absolute_error: 3.6082\n",
            "Epoch 227/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 14.5262 - mean_absolute_error: 2.6311 - val_loss: 51.4086 - val_mean_absolute_error: 5.9127\n",
            "Epoch 228/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 15.1035 - mean_absolute_error: 2.8238 - val_loss: 23.2109 - val_mean_absolute_error: 3.7325\n",
            "Epoch 229/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 11.3905 - mean_absolute_error: 2.4465 - val_loss: 20.2535 - val_mean_absolute_error: 3.4952\n",
            "Epoch 230/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 17.2079 - mean_absolute_error: 2.7631 - val_loss: 25.3856 - val_mean_absolute_error: 3.6124\n",
            "Epoch 231/1000\n",
            "363/363 [==============================] - 0s 57us/step - loss: 12.4686 - mean_absolute_error: 2.5258 - val_loss: 19.6920 - val_mean_absolute_error: 3.5437\n",
            "Epoch 232/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 11.7290 - mean_absolute_error: 2.4598 - val_loss: 20.1956 - val_mean_absolute_error: 3.5127\n",
            "Epoch 233/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 16.8707 - mean_absolute_error: 2.9330 - val_loss: 22.1304 - val_mean_absolute_error: 3.6775\n",
            "Epoch 234/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 16.5754 - mean_absolute_error: 2.9392 - val_loss: 27.1222 - val_mean_absolute_error: 4.0529\n",
            "Epoch 235/1000\n",
            "363/363 [==============================] - 0s 55us/step - loss: 17.8296 - mean_absolute_error: 2.7950 - val_loss: 19.1285 - val_mean_absolute_error: 3.4082\n",
            "Epoch 236/1000\n",
            "363/363 [==============================] - 0s 57us/step - loss: 14.5626 - mean_absolute_error: 2.6978 - val_loss: 22.2046 - val_mean_absolute_error: 3.4779\n",
            "Epoch 237/1000\n",
            "363/363 [==============================] - 0s 60us/step - loss: 12.4856 - mean_absolute_error: 2.5006 - val_loss: 32.6182 - val_mean_absolute_error: 4.3978\n",
            "Epoch 238/1000\n",
            "363/363 [==============================] - 0s 60us/step - loss: 13.6319 - mean_absolute_error: 2.6455 - val_loss: 21.9502 - val_mean_absolute_error: 3.6591\n",
            "Epoch 239/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 14.9820 - mean_absolute_error: 2.6934 - val_loss: 24.6521 - val_mean_absolute_error: 4.0250\n",
            "Epoch 240/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 12.0240 - mean_absolute_error: 2.5243 - val_loss: 18.7635 - val_mean_absolute_error: 3.4067\n",
            "Epoch 241/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 13.9369 - mean_absolute_error: 2.6845 - val_loss: 39.7863 - val_mean_absolute_error: 5.1661\n",
            "Epoch 242/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 16.6345 - mean_absolute_error: 2.7921 - val_loss: 21.3654 - val_mean_absolute_error: 3.7088\n",
            "Epoch 243/1000\n",
            "363/363 [==============================] - 0s 55us/step - loss: 14.4604 - mean_absolute_error: 2.5821 - val_loss: 32.6012 - val_mean_absolute_error: 4.7132\n",
            "Epoch 244/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 15.4994 - mean_absolute_error: 2.8223 - val_loss: 23.8885 - val_mean_absolute_error: 3.6545\n",
            "Epoch 245/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 12.9888 - mean_absolute_error: 2.6058 - val_loss: 28.3632 - val_mean_absolute_error: 4.1237\n",
            "Epoch 246/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 12.3761 - mean_absolute_error: 2.4833 - val_loss: 33.2014 - val_mean_absolute_error: 4.4816\n",
            "Epoch 247/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 12.4757 - mean_absolute_error: 2.6341 - val_loss: 23.2451 - val_mean_absolute_error: 3.5308\n",
            "Epoch 248/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 14.0845 - mean_absolute_error: 2.6407 - val_loss: 20.1167 - val_mean_absolute_error: 3.4831\n",
            "Epoch 249/1000\n",
            "363/363 [==============================] - 0s 60us/step - loss: 14.3816 - mean_absolute_error: 2.7406 - val_loss: 20.2474 - val_mean_absolute_error: 3.4737\n",
            "Epoch 250/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 16.6656 - mean_absolute_error: 2.8279 - val_loss: 23.6770 - val_mean_absolute_error: 3.8877\n",
            "Epoch 251/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 16.7912 - mean_absolute_error: 2.8790 - val_loss: 18.5843 - val_mean_absolute_error: 3.2870\n",
            "Epoch 252/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 12.8579 - mean_absolute_error: 2.6106 - val_loss: 20.0469 - val_mean_absolute_error: 3.5596\n",
            "Epoch 253/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 11.7476 - mean_absolute_error: 2.4881 - val_loss: 33.6009 - val_mean_absolute_error: 4.4952\n",
            "Epoch 254/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 15.2089 - mean_absolute_error: 2.8174 - val_loss: 29.3355 - val_mean_absolute_error: 4.1777\n",
            "Epoch 255/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 14.2986 - mean_absolute_error: 2.6275 - val_loss: 19.6361 - val_mean_absolute_error: 3.4614\n",
            "Epoch 256/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 12.4787 - mean_absolute_error: 2.5765 - val_loss: 27.3932 - val_mean_absolute_error: 4.0863\n",
            "Epoch 257/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 17.8728 - mean_absolute_error: 3.0762 - val_loss: 19.3695 - val_mean_absolute_error: 3.4513\n",
            "Epoch 258/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 11.2908 - mean_absolute_error: 2.4641 - val_loss: 17.9887 - val_mean_absolute_error: 3.1920\n",
            "Epoch 259/1000\n",
            "363/363 [==============================] - 0s 55us/step - loss: 13.4985 - mean_absolute_error: 2.6408 - val_loss: 22.5801 - val_mean_absolute_error: 3.6290\n",
            "Epoch 260/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 13.7835 - mean_absolute_error: 2.6843 - val_loss: 23.1573 - val_mean_absolute_error: 3.5820\n",
            "Epoch 261/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 14.9229 - mean_absolute_error: 2.6918 - val_loss: 18.7888 - val_mean_absolute_error: 3.3417\n",
            "Epoch 262/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 16.6349 - mean_absolute_error: 2.8119 - val_loss: 18.5477 - val_mean_absolute_error: 3.3629\n",
            "Epoch 263/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 12.6983 - mean_absolute_error: 2.5841 - val_loss: 18.8001 - val_mean_absolute_error: 3.4483\n",
            "Epoch 264/1000\n",
            "363/363 [==============================] - 0s 61us/step - loss: 14.8641 - mean_absolute_error: 2.6509 - val_loss: 19.3915 - val_mean_absolute_error: 3.3143\n",
            "Epoch 265/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 11.4787 - mean_absolute_error: 2.4484 - val_loss: 31.7431 - val_mean_absolute_error: 4.3070\n",
            "Epoch 266/1000\n",
            "363/363 [==============================] - 0s 55us/step - loss: 15.1083 - mean_absolute_error: 2.7026 - val_loss: 61.0890 - val_mean_absolute_error: 6.5303\n",
            "Epoch 267/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 17.0462 - mean_absolute_error: 2.7869 - val_loss: 21.9318 - val_mean_absolute_error: 3.6913\n",
            "Epoch 268/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 13.9554 - mean_absolute_error: 2.6457 - val_loss: 18.3603 - val_mean_absolute_error: 3.3767\n",
            "Epoch 269/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 13.2496 - mean_absolute_error: 2.5856 - val_loss: 19.9098 - val_mean_absolute_error: 3.3490\n",
            "Epoch 270/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 11.6027 - mean_absolute_error: 2.4035 - val_loss: 21.6732 - val_mean_absolute_error: 3.7308\n",
            "Epoch 271/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 17.0196 - mean_absolute_error: 2.8448 - val_loss: 19.1728 - val_mean_absolute_error: 3.3517\n",
            "Epoch 272/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 14.8852 - mean_absolute_error: 2.7108 - val_loss: 17.6887 - val_mean_absolute_error: 3.2803\n",
            "Epoch 273/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 11.8673 - mean_absolute_error: 2.3998 - val_loss: 24.6702 - val_mean_absolute_error: 3.7595\n",
            "Epoch 274/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 14.1521 - mean_absolute_error: 2.7365 - val_loss: 25.4644 - val_mean_absolute_error: 3.9315\n",
            "Epoch 275/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 15.8563 - mean_absolute_error: 2.7379 - val_loss: 18.1486 - val_mean_absolute_error: 3.3720\n",
            "Epoch 276/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 10.8256 - mean_absolute_error: 2.3652 - val_loss: 33.0292 - val_mean_absolute_error: 4.4586\n",
            "Epoch 277/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 15.1147 - mean_absolute_error: 2.7120 - val_loss: 21.9472 - val_mean_absolute_error: 3.6267\n",
            "Epoch 278/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 15.4018 - mean_absolute_error: 2.7409 - val_loss: 19.6437 - val_mean_absolute_error: 3.4748\n",
            "Epoch 279/1000\n",
            "363/363 [==============================] - 0s 55us/step - loss: 13.0406 - mean_absolute_error: 2.5547 - val_loss: 29.4412 - val_mean_absolute_error: 4.2016\n",
            "Epoch 280/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 15.0903 - mean_absolute_error: 2.7932 - val_loss: 23.1004 - val_mean_absolute_error: 3.5697\n",
            "Epoch 281/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 11.9326 - mean_absolute_error: 2.5162 - val_loss: 23.7101 - val_mean_absolute_error: 3.8193\n",
            "Epoch 282/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 15.4893 - mean_absolute_error: 2.7581 - val_loss: 18.3717 - val_mean_absolute_error: 3.3848\n",
            "Epoch 283/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 14.9276 - mean_absolute_error: 2.6308 - val_loss: 19.8598 - val_mean_absolute_error: 3.5733\n",
            "Epoch 284/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 13.9447 - mean_absolute_error: 2.5862 - val_loss: 22.3896 - val_mean_absolute_error: 3.5418\n",
            "Epoch 285/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 12.6002 - mean_absolute_error: 2.5098 - val_loss: 25.4577 - val_mean_absolute_error: 3.6992\n",
            "Epoch 286/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 13.2766 - mean_absolute_error: 2.7369 - val_loss: 21.1567 - val_mean_absolute_error: 3.5985\n",
            "Epoch 287/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 16.3307 - mean_absolute_error: 2.8848 - val_loss: 18.6709 - val_mean_absolute_error: 3.3783\n",
            "Epoch 288/1000\n",
            "363/363 [==============================] - 0s 60us/step - loss: 11.3086 - mean_absolute_error: 2.5000 - val_loss: 22.4224 - val_mean_absolute_error: 3.8363\n",
            "Epoch 289/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 12.2718 - mean_absolute_error: 2.4873 - val_loss: 18.9112 - val_mean_absolute_error: 3.2563\n",
            "Epoch 290/1000\n",
            "363/363 [==============================] - 0s 55us/step - loss: 12.4954 - mean_absolute_error: 2.5112 - val_loss: 34.2597 - val_mean_absolute_error: 4.5554\n",
            "Epoch 291/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 17.6980 - mean_absolute_error: 2.8461 - val_loss: 19.4724 - val_mean_absolute_error: 3.3444\n",
            "Epoch 292/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 14.6137 - mean_absolute_error: 2.6032 - val_loss: 19.0018 - val_mean_absolute_error: 3.4085\n",
            "Epoch 293/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 13.5441 - mean_absolute_error: 2.6523 - val_loss: 18.5839 - val_mean_absolute_error: 3.3545\n",
            "Epoch 294/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 14.1436 - mean_absolute_error: 2.6749 - val_loss: 17.6291 - val_mean_absolute_error: 3.2830\n",
            "Epoch 295/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 13.7858 - mean_absolute_error: 2.6908 - val_loss: 18.4348 - val_mean_absolute_error: 3.3651\n",
            "Epoch 296/1000\n",
            "363/363 [==============================] - 0s 56us/step - loss: 12.0120 - mean_absolute_error: 2.4120 - val_loss: 43.3019 - val_mean_absolute_error: 5.3777\n",
            "Epoch 297/1000\n",
            "363/363 [==============================] - 0s 58us/step - loss: 15.1081 - mean_absolute_error: 2.7443 - val_loss: 21.4098 - val_mean_absolute_error: 3.4340\n",
            "Epoch 298/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 14.0662 - mean_absolute_error: 2.5539 - val_loss: 29.4931 - val_mean_absolute_error: 4.2377\n",
            "Epoch 299/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 11.3995 - mean_absolute_error: 2.4375 - val_loss: 19.7509 - val_mean_absolute_error: 3.4978\n",
            "Epoch 300/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 12.9242 - mean_absolute_error: 2.5694 - val_loss: 67.2199 - val_mean_absolute_error: 6.7518\n",
            "Epoch 301/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 19.2300 - mean_absolute_error: 2.9993 - val_loss: 20.9483 - val_mean_absolute_error: 3.4496\n",
            "Epoch 302/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 12.7934 - mean_absolute_error: 2.4938 - val_loss: 18.9759 - val_mean_absolute_error: 3.3428\n",
            "Epoch 303/1000\n",
            "363/363 [==============================] - 0s 56us/step - loss: 10.1994 - mean_absolute_error: 2.2928 - val_loss: 21.1924 - val_mean_absolute_error: 3.5441\n",
            "Epoch 304/1000\n",
            "363/363 [==============================] - 0s 67us/step - loss: 15.3521 - mean_absolute_error: 2.8196 - val_loss: 22.3724 - val_mean_absolute_error: 3.5341\n",
            "Epoch 305/1000\n",
            "363/363 [==============================] - 0s 72us/step - loss: 12.4750 - mean_absolute_error: 2.5348 - val_loss: 25.8026 - val_mean_absolute_error: 4.0638\n",
            "Epoch 306/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 19.2299 - mean_absolute_error: 3.0621 - val_loss: 22.4000 - val_mean_absolute_error: 3.7556\n",
            "Epoch 307/1000\n",
            "363/363 [==============================] - 0s 60us/step - loss: 10.9896 - mean_absolute_error: 2.3627 - val_loss: 18.2824 - val_mean_absolute_error: 3.3114\n",
            "Epoch 308/1000\n",
            "363/363 [==============================] - 0s 55us/step - loss: 11.4149 - mean_absolute_error: 2.4235 - val_loss: 24.8093 - val_mean_absolute_error: 3.8123\n",
            "Epoch 309/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 13.0829 - mean_absolute_error: 2.5549 - val_loss: 25.3971 - val_mean_absolute_error: 3.8032\n",
            "Epoch 310/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 16.6825 - mean_absolute_error: 2.8157 - val_loss: 22.8367 - val_mean_absolute_error: 3.5883\n",
            "Epoch 311/1000\n",
            "363/363 [==============================] - 0s 56us/step - loss: 13.5737 - mean_absolute_error: 2.6092 - val_loss: 21.0942 - val_mean_absolute_error: 3.5182\n",
            "Epoch 312/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 15.3751 - mean_absolute_error: 2.8670 - val_loss: 27.3801 - val_mean_absolute_error: 3.9754\n",
            "Epoch 313/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 15.0765 - mean_absolute_error: 2.7299 - val_loss: 22.1660 - val_mean_absolute_error: 3.5267\n",
            "Epoch 314/1000\n",
            "363/363 [==============================] - 0s 57us/step - loss: 13.1065 - mean_absolute_error: 2.5381 - val_loss: 23.3842 - val_mean_absolute_error: 3.5903\n",
            "Epoch 315/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 14.5536 - mean_absolute_error: 2.5364 - val_loss: 18.1605 - val_mean_absolute_error: 3.3691\n",
            "Epoch 316/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 14.8438 - mean_absolute_error: 2.7321 - val_loss: 20.0635 - val_mean_absolute_error: 3.4754\n",
            "Epoch 317/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 13.0499 - mean_absolute_error: 2.6700 - val_loss: 22.3841 - val_mean_absolute_error: 3.7220\n",
            "Epoch 318/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 14.3323 - mean_absolute_error: 2.7192 - val_loss: 19.8463 - val_mean_absolute_error: 3.5364\n",
            "Epoch 319/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 13.4401 - mean_absolute_error: 2.5494 - val_loss: 21.2445 - val_mean_absolute_error: 3.3836\n",
            "Epoch 320/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 13.2068 - mean_absolute_error: 2.5998 - val_loss: 19.6538 - val_mean_absolute_error: 3.3690\n",
            "Epoch 321/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 12.3946 - mean_absolute_error: 2.4744 - val_loss: 36.5950 - val_mean_absolute_error: 4.8427\n",
            "Epoch 322/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 12.8937 - mean_absolute_error: 2.5249 - val_loss: 19.5552 - val_mean_absolute_error: 3.5010\n",
            "Epoch 323/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 11.0670 - mean_absolute_error: 2.3693 - val_loss: 20.8010 - val_mean_absolute_error: 3.5329\n",
            "Epoch 324/1000\n",
            "363/363 [==============================] - 0s 71us/step - loss: 14.6880 - mean_absolute_error: 2.6972 - val_loss: 20.9571 - val_mean_absolute_error: 3.6668\n",
            "Epoch 325/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 12.2203 - mean_absolute_error: 2.4443 - val_loss: 21.0943 - val_mean_absolute_error: 3.7287\n",
            "Epoch 326/1000\n",
            "363/363 [==============================] - 0s 56us/step - loss: 16.9166 - mean_absolute_error: 2.9195 - val_loss: 19.9404 - val_mean_absolute_error: 3.3724\n",
            "Epoch 327/1000\n",
            "363/363 [==============================] - 0s 57us/step - loss: 9.9865 - mean_absolute_error: 2.3213 - val_loss: 18.9305 - val_mean_absolute_error: 3.4343\n",
            "Epoch 328/1000\n",
            "363/363 [==============================] - 0s 57us/step - loss: 12.4042 - mean_absolute_error: 2.6527 - val_loss: 21.9002 - val_mean_absolute_error: 3.6311\n",
            "Epoch 329/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 16.3993 - mean_absolute_error: 2.7885 - val_loss: 21.1328 - val_mean_absolute_error: 3.5831\n",
            "Epoch 330/1000\n",
            "363/363 [==============================] - 0s 57us/step - loss: 15.3381 - mean_absolute_error: 2.6621 - val_loss: 31.0696 - val_mean_absolute_error: 4.6306\n",
            "Epoch 331/1000\n",
            "363/363 [==============================] - 0s 73us/step - loss: 14.7888 - mean_absolute_error: 2.7638 - val_loss: 20.1266 - val_mean_absolute_error: 3.4467\n",
            "Epoch 332/1000\n",
            "363/363 [==============================] - 0s 56us/step - loss: 11.5815 - mean_absolute_error: 2.4705 - val_loss: 18.2499 - val_mean_absolute_error: 3.3680\n",
            "Epoch 333/1000\n",
            "363/363 [==============================] - 0s 55us/step - loss: 16.9591 - mean_absolute_error: 2.8634 - val_loss: 21.2388 - val_mean_absolute_error: 3.5035\n",
            "Epoch 334/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 14.1307 - mean_absolute_error: 2.5665 - val_loss: 18.5751 - val_mean_absolute_error: 3.2814\n",
            "Epoch 335/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 11.3265 - mean_absolute_error: 2.4040 - val_loss: 18.8048 - val_mean_absolute_error: 3.4479\n",
            "Epoch 336/1000\n",
            "363/363 [==============================] - 0s 70us/step - loss: 15.8344 - mean_absolute_error: 2.7693 - val_loss: 36.4231 - val_mean_absolute_error: 4.9481\n",
            "Epoch 337/1000\n",
            "363/363 [==============================] - 0s 57us/step - loss: 13.9270 - mean_absolute_error: 2.6743 - val_loss: 19.9046 - val_mean_absolute_error: 3.5417\n",
            "Epoch 338/1000\n",
            "363/363 [==============================] - 0s 57us/step - loss: 15.7218 - mean_absolute_error: 2.7208 - val_loss: 20.5165 - val_mean_absolute_error: 3.7007\n",
            "Epoch 339/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 13.0636 - mean_absolute_error: 2.5986 - val_loss: 18.1170 - val_mean_absolute_error: 3.2430\n",
            "Epoch 340/1000\n",
            "363/363 [==============================] - 0s 55us/step - loss: 10.3431 - mean_absolute_error: 2.3372 - val_loss: 16.9929 - val_mean_absolute_error: 3.2401\n",
            "Epoch 341/1000\n",
            "363/363 [==============================] - 0s 59us/step - loss: 16.2200 - mean_absolute_error: 2.8211 - val_loss: 27.9439 - val_mean_absolute_error: 4.1071\n",
            "Epoch 342/1000\n",
            "363/363 [==============================] - 0s 64us/step - loss: 12.6944 - mean_absolute_error: 2.5708 - val_loss: 27.7364 - val_mean_absolute_error: 4.4178\n",
            "Epoch 343/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 13.8014 - mean_absolute_error: 2.6056 - val_loss: 21.8086 - val_mean_absolute_error: 3.4251\n",
            "Epoch 344/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 13.6419 - mean_absolute_error: 2.6342 - val_loss: 18.4517 - val_mean_absolute_error: 3.2234\n",
            "Epoch 345/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 12.6517 - mean_absolute_error: 2.5290 - val_loss: 18.2305 - val_mean_absolute_error: 3.2804\n",
            "Epoch 346/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 14.7955 - mean_absolute_error: 2.7122 - val_loss: 20.5926 - val_mean_absolute_error: 3.5503\n",
            "Epoch 347/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 11.3430 - mean_absolute_error: 2.4761 - val_loss: 22.6756 - val_mean_absolute_error: 3.8116\n",
            "Epoch 348/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 13.5310 - mean_absolute_error: 2.5894 - val_loss: 37.6035 - val_mean_absolute_error: 4.9254\n",
            "Epoch 349/1000\n",
            "363/363 [==============================] - 0s 57us/step - loss: 13.5950 - mean_absolute_error: 2.6837 - val_loss: 20.1058 - val_mean_absolute_error: 3.5925\n",
            "Epoch 350/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 10.4044 - mean_absolute_error: 2.3411 - val_loss: 22.4738 - val_mean_absolute_error: 3.8178\n",
            "Epoch 351/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 10.8408 - mean_absolute_error: 2.4295 - val_loss: 33.4199 - val_mean_absolute_error: 4.5373\n",
            "Epoch 352/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 15.5419 - mean_absolute_error: 2.8345 - val_loss: 22.8456 - val_mean_absolute_error: 3.7623\n",
            "Epoch 353/1000\n",
            "363/363 [==============================] - 0s 60us/step - loss: 14.5317 - mean_absolute_error: 2.6168 - val_loss: 25.9671 - val_mean_absolute_error: 3.8070\n",
            "Epoch 354/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 10.3410 - mean_absolute_error: 2.3186 - val_loss: 22.4914 - val_mean_absolute_error: 3.6898\n",
            "Epoch 355/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 10.4470 - mean_absolute_error: 2.3827 - val_loss: 17.6486 - val_mean_absolute_error: 3.3509\n",
            "Epoch 356/1000\n",
            "363/363 [==============================] - 0s 59us/step - loss: 19.2956 - mean_absolute_error: 3.0507 - val_loss: 18.4314 - val_mean_absolute_error: 3.2965\n",
            "Epoch 357/1000\n",
            "363/363 [==============================] - 0s 56us/step - loss: 10.0408 - mean_absolute_error: 2.3085 - val_loss: 19.4621 - val_mean_absolute_error: 3.5374\n",
            "Epoch 358/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 12.5610 - mean_absolute_error: 2.5593 - val_loss: 27.8032 - val_mean_absolute_error: 3.9924\n",
            "Epoch 359/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 13.1075 - mean_absolute_error: 2.5539 - val_loss: 19.7866 - val_mean_absolute_error: 3.5629\n",
            "Epoch 360/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 16.9830 - mean_absolute_error: 2.8284 - val_loss: 19.6791 - val_mean_absolute_error: 3.5677\n",
            "Epoch 361/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 10.6220 - mean_absolute_error: 2.3412 - val_loss: 21.1472 - val_mean_absolute_error: 3.6229\n",
            "Epoch 362/1000\n",
            "363/363 [==============================] - 0s 58us/step - loss: 14.6171 - mean_absolute_error: 2.6786 - val_loss: 17.9298 - val_mean_absolute_error: 3.3324\n",
            "Epoch 363/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 10.7139 - mean_absolute_error: 2.3905 - val_loss: 21.2931 - val_mean_absolute_error: 3.6596\n",
            "Epoch 364/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 10.5030 - mean_absolute_error: 2.3689 - val_loss: 20.2212 - val_mean_absolute_error: 3.5298\n",
            "Epoch 365/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 13.8236 - mean_absolute_error: 2.5986 - val_loss: 17.8762 - val_mean_absolute_error: 3.2418\n",
            "Epoch 366/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 11.3453 - mean_absolute_error: 2.4798 - val_loss: 20.2705 - val_mean_absolute_error: 3.5846\n",
            "Epoch 367/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 14.3471 - mean_absolute_error: 2.6620 - val_loss: 19.4306 - val_mean_absolute_error: 3.5756\n",
            "Epoch 368/1000\n",
            "363/363 [==============================] - 0s 60us/step - loss: 15.4258 - mean_absolute_error: 2.7489 - val_loss: 20.4763 - val_mean_absolute_error: 3.5166\n",
            "Epoch 369/1000\n",
            "363/363 [==============================] - 0s 59us/step - loss: 10.4277 - mean_absolute_error: 2.3314 - val_loss: 70.1859 - val_mean_absolute_error: 7.0748\n",
            "Epoch 370/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 17.8216 - mean_absolute_error: 2.8471 - val_loss: 21.5226 - val_mean_absolute_error: 3.6489\n",
            "Epoch 371/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 11.0336 - mean_absolute_error: 2.4163 - val_loss: 19.4613 - val_mean_absolute_error: 3.5987\n",
            "Epoch 372/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 14.4308 - mean_absolute_error: 2.6940 - val_loss: 18.9359 - val_mean_absolute_error: 3.3839\n",
            "Epoch 373/1000\n",
            "363/363 [==============================] - 0s 57us/step - loss: 13.3568 - mean_absolute_error: 2.5709 - val_loss: 20.2512 - val_mean_absolute_error: 3.5336\n",
            "Epoch 374/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 12.5092 - mean_absolute_error: 2.5469 - val_loss: 30.9852 - val_mean_absolute_error: 4.3538\n",
            "Epoch 375/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 12.8076 - mean_absolute_error: 2.6002 - val_loss: 22.4729 - val_mean_absolute_error: 3.4938\n",
            "Epoch 376/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 11.3120 - mean_absolute_error: 2.4347 - val_loss: 19.4276 - val_mean_absolute_error: 3.5184\n",
            "Epoch 377/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 14.7613 - mean_absolute_error: 2.6783 - val_loss: 29.0258 - val_mean_absolute_error: 4.2069\n",
            "Epoch 378/1000\n",
            "363/363 [==============================] - 0s 58us/step - loss: 15.7520 - mean_absolute_error: 2.8226 - val_loss: 17.7679 - val_mean_absolute_error: 3.2588\n",
            "Epoch 379/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 11.2902 - mean_absolute_error: 2.3873 - val_loss: 20.6966 - val_mean_absolute_error: 3.4510\n",
            "Epoch 380/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 13.2512 - mean_absolute_error: 2.5928 - val_loss: 19.3731 - val_mean_absolute_error: 3.4890\n",
            "Epoch 381/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 9.4296 - mean_absolute_error: 2.2594 - val_loss: 31.2507 - val_mean_absolute_error: 4.4614\n",
            "Epoch 382/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 13.4800 - mean_absolute_error: 2.5414 - val_loss: 30.0414 - val_mean_absolute_error: 4.2903\n",
            "Epoch 383/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 14.7470 - mean_absolute_error: 2.7237 - val_loss: 21.9282 - val_mean_absolute_error: 3.7347\n",
            "Epoch 384/1000\n",
            "363/363 [==============================] - 0s 57us/step - loss: 11.5076 - mean_absolute_error: 2.4509 - val_loss: 20.3051 - val_mean_absolute_error: 3.5369\n",
            "Epoch 385/1000\n",
            "363/363 [==============================] - 0s 56us/step - loss: 17.1173 - mean_absolute_error: 2.9452 - val_loss: 18.4279 - val_mean_absolute_error: 3.4658\n",
            "Epoch 386/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 10.2100 - mean_absolute_error: 2.2728 - val_loss: 18.9761 - val_mean_absolute_error: 3.4876\n",
            "Epoch 387/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 9.3808 - mean_absolute_error: 2.2634 - val_loss: 34.7004 - val_mean_absolute_error: 4.8761\n",
            "Epoch 388/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 14.0361 - mean_absolute_error: 2.7987 - val_loss: 18.6553 - val_mean_absolute_error: 3.4975\n",
            "Epoch 389/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 11.6657 - mean_absolute_error: 2.4516 - val_loss: 26.7367 - val_mean_absolute_error: 4.0865\n",
            "Epoch 390/1000\n",
            "363/363 [==============================] - 0s 55us/step - loss: 15.3000 - mean_absolute_error: 2.7026 - val_loss: 21.3960 - val_mean_absolute_error: 3.6804\n",
            "Epoch 391/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 12.6272 - mean_absolute_error: 2.5508 - val_loss: 25.9869 - val_mean_absolute_error: 4.1108\n",
            "Epoch 392/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 14.0106 - mean_absolute_error: 2.6527 - val_loss: 18.1846 - val_mean_absolute_error: 3.3022\n",
            "Epoch 393/1000\n",
            "363/363 [==============================] - 0s 57us/step - loss: 9.6868 - mean_absolute_error: 2.2801 - val_loss: 21.3795 - val_mean_absolute_error: 3.5665\n",
            "Epoch 394/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 12.8594 - mean_absolute_error: 2.5255 - val_loss: 27.2867 - val_mean_absolute_error: 3.8653\n",
            "Epoch 395/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 13.8438 - mean_absolute_error: 2.6283 - val_loss: 17.7158 - val_mean_absolute_error: 3.3827\n",
            "Epoch 396/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 11.2660 - mean_absolute_error: 2.4202 - val_loss: 20.8154 - val_mean_absolute_error: 3.5069\n",
            "Epoch 397/1000\n",
            "363/363 [==============================] - 0s 55us/step - loss: 12.4894 - mean_absolute_error: 2.5616 - val_loss: 25.8018 - val_mean_absolute_error: 3.8686\n",
            "Epoch 398/1000\n",
            "363/363 [==============================] - 0s 57us/step - loss: 12.1808 - mean_absolute_error: 2.4165 - val_loss: 17.9612 - val_mean_absolute_error: 3.3225\n",
            "Epoch 399/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 12.5113 - mean_absolute_error: 2.4655 - val_loss: 26.0176 - val_mean_absolute_error: 3.9745\n",
            "Epoch 400/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 14.2653 - mean_absolute_error: 2.6530 - val_loss: 20.2580 - val_mean_absolute_error: 3.5820\n",
            "Epoch 401/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 11.1793 - mean_absolute_error: 2.4417 - val_loss: 17.3392 - val_mean_absolute_error: 3.2695\n",
            "Epoch 402/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 9.3925 - mean_absolute_error: 2.2450 - val_loss: 30.7550 - val_mean_absolute_error: 4.3374\n",
            "Epoch 403/1000\n",
            "363/363 [==============================] - 0s 55us/step - loss: 10.7946 - mean_absolute_error: 2.4011 - val_loss: 21.7489 - val_mean_absolute_error: 3.4881\n",
            "Epoch 404/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 12.1059 - mean_absolute_error: 2.5698 - val_loss: 18.6890 - val_mean_absolute_error: 3.4028\n",
            "Epoch 405/1000\n",
            "363/363 [==============================] - 0s 55us/step - loss: 13.7587 - mean_absolute_error: 2.6781 - val_loss: 31.8397 - val_mean_absolute_error: 4.4776\n",
            "Epoch 406/1000\n",
            "363/363 [==============================] - 0s 56us/step - loss: 14.2909 - mean_absolute_error: 2.6569 - val_loss: 21.9527 - val_mean_absolute_error: 3.5482\n",
            "Epoch 407/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 10.6060 - mean_absolute_error: 2.3682 - val_loss: 31.8605 - val_mean_absolute_error: 4.4161\n",
            "Epoch 408/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 14.7978 - mean_absolute_error: 2.6705 - val_loss: 22.5302 - val_mean_absolute_error: 3.7006\n",
            "Epoch 409/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 12.8946 - mean_absolute_error: 2.5532 - val_loss: 19.4301 - val_mean_absolute_error: 3.5166\n",
            "Epoch 410/1000\n",
            "363/363 [==============================] - 0s 60us/step - loss: 11.7439 - mean_absolute_error: 2.5318 - val_loss: 19.8686 - val_mean_absolute_error: 3.4863\n",
            "Epoch 411/1000\n",
            "363/363 [==============================] - 0s 55us/step - loss: 11.6457 - mean_absolute_error: 2.5308 - val_loss: 20.7650 - val_mean_absolute_error: 3.5198\n",
            "Epoch 412/1000\n",
            "363/363 [==============================] - 0s 55us/step - loss: 13.3674 - mean_absolute_error: 2.5609 - val_loss: 21.8963 - val_mean_absolute_error: 3.7902\n",
            "Epoch 413/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 15.4639 - mean_absolute_error: 2.6410 - val_loss: 31.0186 - val_mean_absolute_error: 4.4326\n",
            "Epoch 414/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 11.1008 - mean_absolute_error: 2.4046 - val_loss: 17.9798 - val_mean_absolute_error: 3.3152\n",
            "Epoch 415/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 10.0982 - mean_absolute_error: 2.3450 - val_loss: 17.5816 - val_mean_absolute_error: 3.2745\n",
            "Epoch 416/1000\n",
            "363/363 [==============================] - 0s 57us/step - loss: 13.0680 - mean_absolute_error: 2.4848 - val_loss: 25.3126 - val_mean_absolute_error: 3.8577\n",
            "Epoch 417/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 11.0016 - mean_absolute_error: 2.4918 - val_loss: 18.2982 - val_mean_absolute_error: 3.3938\n",
            "Epoch 418/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 8.7957 - mean_absolute_error: 2.1946 - val_loss: 21.2156 - val_mean_absolute_error: 3.5622\n",
            "Epoch 419/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 16.2948 - mean_absolute_error: 2.8857 - val_loss: 17.9283 - val_mean_absolute_error: 3.1969\n",
            "Epoch 420/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 13.7771 - mean_absolute_error: 2.5867 - val_loss: 18.9752 - val_mean_absolute_error: 3.4276\n",
            "Epoch 421/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 10.9735 - mean_absolute_error: 2.3772 - val_loss: 18.3617 - val_mean_absolute_error: 3.4253\n",
            "Epoch 422/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 13.9871 - mean_absolute_error: 2.6906 - val_loss: 20.4757 - val_mean_absolute_error: 3.5821\n",
            "Epoch 423/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 12.0766 - mean_absolute_error: 2.4763 - val_loss: 20.7734 - val_mean_absolute_error: 3.6415\n",
            "Epoch 424/1000\n",
            "363/363 [==============================] - 0s 62us/step - loss: 12.1651 - mean_absolute_error: 2.4588 - val_loss: 21.5855 - val_mean_absolute_error: 3.7235\n",
            "Epoch 425/1000\n",
            "363/363 [==============================] - 0s 56us/step - loss: 14.8774 - mean_absolute_error: 2.7356 - val_loss: 18.9244 - val_mean_absolute_error: 3.3987\n",
            "Epoch 426/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 16.4662 - mean_absolute_error: 2.8184 - val_loss: 17.3835 - val_mean_absolute_error: 3.2820\n",
            "Epoch 427/1000\n",
            "363/363 [==============================] - 0s 57us/step - loss: 9.6935 - mean_absolute_error: 2.2457 - val_loss: 18.3022 - val_mean_absolute_error: 3.4520\n",
            "Epoch 428/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 12.7641 - mean_absolute_error: 2.6208 - val_loss: 22.1393 - val_mean_absolute_error: 3.6650\n",
            "Epoch 429/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 11.8335 - mean_absolute_error: 2.4548 - val_loss: 24.4620 - val_mean_absolute_error: 3.6700\n",
            "Epoch 430/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 11.3808 - mean_absolute_error: 2.4883 - val_loss: 18.7904 - val_mean_absolute_error: 3.4587\n",
            "Epoch 431/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 11.5339 - mean_absolute_error: 2.4685 - val_loss: 16.9051 - val_mean_absolute_error: 3.2961\n",
            "Epoch 432/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 13.6457 - mean_absolute_error: 2.5673 - val_loss: 18.1220 - val_mean_absolute_error: 3.3857\n",
            "Epoch 433/1000\n",
            "363/363 [==============================] - 0s 55us/step - loss: 11.9099 - mean_absolute_error: 2.4679 - val_loss: 18.1782 - val_mean_absolute_error: 3.2597\n",
            "Epoch 434/1000\n",
            "363/363 [==============================] - 0s 56us/step - loss: 13.4157 - mean_absolute_error: 2.5544 - val_loss: 22.6901 - val_mean_absolute_error: 3.8150\n",
            "Epoch 435/1000\n",
            "363/363 [==============================] - 0s 56us/step - loss: 12.9616 - mean_absolute_error: 2.5153 - val_loss: 24.4764 - val_mean_absolute_error: 3.6785\n",
            "Epoch 436/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 9.9504 - mean_absolute_error: 2.2865 - val_loss: 18.8032 - val_mean_absolute_error: 3.4544\n",
            "Epoch 437/1000\n",
            "363/363 [==============================] - 0s 57us/step - loss: 13.4348 - mean_absolute_error: 2.5888 - val_loss: 31.0681 - val_mean_absolute_error: 4.3647\n",
            "Epoch 438/1000\n",
            "363/363 [==============================] - 0s 59us/step - loss: 11.7423 - mean_absolute_error: 2.4024 - val_loss: 22.7045 - val_mean_absolute_error: 3.6636\n",
            "Epoch 439/1000\n",
            "363/363 [==============================] - 0s 60us/step - loss: 13.9077 - mean_absolute_error: 2.6498 - val_loss: 19.4497 - val_mean_absolute_error: 3.3762\n",
            "Epoch 440/1000\n",
            "363/363 [==============================] - 0s 56us/step - loss: 11.1954 - mean_absolute_error: 2.3466 - val_loss: 18.1530 - val_mean_absolute_error: 3.4089\n",
            "Epoch 441/1000\n",
            "363/363 [==============================] - 0s 65us/step - loss: 9.9457 - mean_absolute_error: 2.2784 - val_loss: 22.6403 - val_mean_absolute_error: 3.7980\n",
            "Epoch 442/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 12.0040 - mean_absolute_error: 2.5033 - val_loss: 18.8004 - val_mean_absolute_error: 3.5343\n",
            "Epoch 443/1000\n",
            "363/363 [==============================] - 0s 55us/step - loss: 15.3851 - mean_absolute_error: 2.7528 - val_loss: 24.3878 - val_mean_absolute_error: 3.9473\n",
            "Epoch 444/1000\n",
            "363/363 [==============================] - 0s 59us/step - loss: 11.8467 - mean_absolute_error: 2.4151 - val_loss: 39.4197 - val_mean_absolute_error: 5.1974\n",
            "Epoch 445/1000\n",
            "363/363 [==============================] - 0s 62us/step - loss: 14.2173 - mean_absolute_error: 2.6716 - val_loss: 19.7855 - val_mean_absolute_error: 3.5998\n",
            "Epoch 446/1000\n",
            "363/363 [==============================] - 0s 56us/step - loss: 10.7779 - mean_absolute_error: 2.3615 - val_loss: 17.4944 - val_mean_absolute_error: 3.2410\n",
            "Epoch 447/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 11.5843 - mean_absolute_error: 2.3632 - val_loss: 19.8722 - val_mean_absolute_error: 3.4132\n",
            "Epoch 448/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 9.2925 - mean_absolute_error: 2.2281 - val_loss: 30.9487 - val_mean_absolute_error: 4.3297\n",
            "Epoch 449/1000\n",
            "363/363 [==============================] - 0s 60us/step - loss: 17.7302 - mean_absolute_error: 2.8787 - val_loss: 18.6421 - val_mean_absolute_error: 3.4014\n",
            "Epoch 450/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 12.6393 - mean_absolute_error: 2.4734 - val_loss: 18.5868 - val_mean_absolute_error: 3.3192\n",
            "Epoch 451/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 11.6931 - mean_absolute_error: 2.4442 - val_loss: 25.6872 - val_mean_absolute_error: 4.0683\n",
            "Epoch 452/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 13.3101 - mean_absolute_error: 2.5112 - val_loss: 20.0649 - val_mean_absolute_error: 3.6162\n",
            "Epoch 453/1000\n",
            "363/363 [==============================] - 0s 59us/step - loss: 11.7908 - mean_absolute_error: 2.5164 - val_loss: 33.7108 - val_mean_absolute_error: 4.8000\n",
            "Epoch 454/1000\n",
            "363/363 [==============================] - 0s 64us/step - loss: 15.5844 - mean_absolute_error: 2.6375 - val_loss: 18.9490 - val_mean_absolute_error: 3.4944\n",
            "Epoch 455/1000\n",
            "363/363 [==============================] - 0s 60us/step - loss: 13.1612 - mean_absolute_error: 2.5632 - val_loss: 19.4417 - val_mean_absolute_error: 3.4876\n",
            "Epoch 456/1000\n",
            "363/363 [==============================] - 0s 57us/step - loss: 14.7605 - mean_absolute_error: 2.6881 - val_loss: 19.4104 - val_mean_absolute_error: 3.4985\n",
            "Epoch 457/1000\n",
            "363/363 [==============================] - 0s 60us/step - loss: 9.5272 - mean_absolute_error: 2.2510 - val_loss: 21.6531 - val_mean_absolute_error: 3.4813\n",
            "Epoch 458/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 11.5135 - mean_absolute_error: 2.4641 - val_loss: 20.6944 - val_mean_absolute_error: 3.4300\n",
            "Epoch 459/1000\n",
            "363/363 [==============================] - 0s 56us/step - loss: 12.3148 - mean_absolute_error: 2.4991 - val_loss: 21.9831 - val_mean_absolute_error: 3.5470\n",
            "Epoch 460/1000\n",
            "363/363 [==============================] - 0s 56us/step - loss: 12.9734 - mean_absolute_error: 2.5476 - val_loss: 21.3109 - val_mean_absolute_error: 3.5557\n",
            "Epoch 461/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 10.5421 - mean_absolute_error: 2.3954 - val_loss: 25.4441 - val_mean_absolute_error: 3.7338\n",
            "Epoch 462/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 14.1369 - mean_absolute_error: 2.5741 - val_loss: 19.9590 - val_mean_absolute_error: 3.4016\n",
            "Epoch 463/1000\n",
            "363/363 [==============================] - 0s 59us/step - loss: 12.4236 - mean_absolute_error: 2.4736 - val_loss: 18.3368 - val_mean_absolute_error: 3.2665\n",
            "Epoch 464/1000\n",
            "363/363 [==============================] - 0s 69us/step - loss: 11.6892 - mean_absolute_error: 2.3363 - val_loss: 21.4178 - val_mean_absolute_error: 3.6642\n",
            "Epoch 465/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 10.8507 - mean_absolute_error: 2.3963 - val_loss: 20.5625 - val_mean_absolute_error: 3.6088\n",
            "Epoch 466/1000\n",
            "363/363 [==============================] - 0s 56us/step - loss: 11.5547 - mean_absolute_error: 2.3526 - val_loss: 17.2995 - val_mean_absolute_error: 3.3374\n",
            "Epoch 467/1000\n",
            "363/363 [==============================] - 0s 59us/step - loss: 9.4495 - mean_absolute_error: 2.2825 - val_loss: 32.8114 - val_mean_absolute_error: 4.5108\n",
            "Epoch 468/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 12.8833 - mean_absolute_error: 2.4607 - val_loss: 17.9917 - val_mean_absolute_error: 3.2226\n",
            "Epoch 469/1000\n",
            "363/363 [==============================] - 0s 58us/step - loss: 13.6970 - mean_absolute_error: 2.5967 - val_loss: 26.0797 - val_mean_absolute_error: 3.9277\n",
            "Epoch 470/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 9.9500 - mean_absolute_error: 2.2782 - val_loss: 20.3588 - val_mean_absolute_error: 3.4976\n",
            "Epoch 471/1000\n",
            "363/363 [==============================] - 0s 59us/step - loss: 13.1827 - mean_absolute_error: 2.5215 - val_loss: 27.9401 - val_mean_absolute_error: 3.9878\n",
            "Epoch 472/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 10.1082 - mean_absolute_error: 2.3785 - val_loss: 27.5846 - val_mean_absolute_error: 4.0314\n",
            "Epoch 473/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 14.1780 - mean_absolute_error: 2.6853 - val_loss: 19.8472 - val_mean_absolute_error: 3.4369\n",
            "Epoch 474/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 11.0266 - mean_absolute_error: 2.3371 - val_loss: 20.3291 - val_mean_absolute_error: 3.5895\n",
            "Epoch 475/1000\n",
            "363/363 [==============================] - 0s 57us/step - loss: 13.3059 - mean_absolute_error: 2.6165 - val_loss: 18.5449 - val_mean_absolute_error: 3.3528\n",
            "Epoch 476/1000\n",
            "363/363 [==============================] - 0s 58us/step - loss: 11.5343 - mean_absolute_error: 2.4014 - val_loss: 21.4203 - val_mean_absolute_error: 3.7098\n",
            "Epoch 477/1000\n",
            "363/363 [==============================] - 0s 59us/step - loss: 12.8220 - mean_absolute_error: 2.5397 - val_loss: 19.3948 - val_mean_absolute_error: 3.5029\n",
            "Epoch 478/1000\n",
            "363/363 [==============================] - 0s 58us/step - loss: 12.0190 - mean_absolute_error: 2.4638 - val_loss: 24.1880 - val_mean_absolute_error: 3.7654\n",
            "Epoch 479/1000\n",
            "363/363 [==============================] - 0s 67us/step - loss: 10.6570 - mean_absolute_error: 2.3728 - val_loss: 20.0960 - val_mean_absolute_error: 3.6336\n",
            "Epoch 480/1000\n",
            "363/363 [==============================] - 0s 61us/step - loss: 14.3363 - mean_absolute_error: 2.6526 - val_loss: 20.0144 - val_mean_absolute_error: 3.4780\n",
            "Epoch 481/1000\n",
            "363/363 [==============================] - 0s 60us/step - loss: 9.5675 - mean_absolute_error: 2.2720 - val_loss: 18.3157 - val_mean_absolute_error: 3.3647\n",
            "Epoch 482/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 11.4751 - mean_absolute_error: 2.5352 - val_loss: 22.9143 - val_mean_absolute_error: 3.5519\n",
            "Epoch 483/1000\n",
            "363/363 [==============================] - 0s 56us/step - loss: 12.3591 - mean_absolute_error: 2.5397 - val_loss: 17.1498 - val_mean_absolute_error: 3.2355\n",
            "Epoch 484/1000\n",
            "363/363 [==============================] - 0s 59us/step - loss: 14.0426 - mean_absolute_error: 2.6422 - val_loss: 17.3533 - val_mean_absolute_error: 3.2520\n",
            "Epoch 485/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 11.2398 - mean_absolute_error: 2.3276 - val_loss: 18.6831 - val_mean_absolute_error: 3.4745\n",
            "Epoch 486/1000\n",
            "363/363 [==============================] - 0s 56us/step - loss: 10.8176 - mean_absolute_error: 2.3269 - val_loss: 20.0927 - val_mean_absolute_error: 3.5488\n",
            "Epoch 487/1000\n",
            "363/363 [==============================] - 0s 56us/step - loss: 14.5465 - mean_absolute_error: 2.7255 - val_loss: 19.2245 - val_mean_absolute_error: 3.3729\n",
            "Epoch 488/1000\n",
            "363/363 [==============================] - 0s 56us/step - loss: 10.0680 - mean_absolute_error: 2.2435 - val_loss: 19.0350 - val_mean_absolute_error: 3.5289\n",
            "Epoch 489/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 12.2411 - mean_absolute_error: 2.5243 - val_loss: 22.4238 - val_mean_absolute_error: 3.5832\n",
            "Epoch 490/1000\n",
            "363/363 [==============================] - 0s 57us/step - loss: 11.4713 - mean_absolute_error: 2.5066 - val_loss: 32.3031 - val_mean_absolute_error: 4.6790\n",
            "Epoch 491/1000\n",
            "363/363 [==============================] - 0s 65us/step - loss: 10.4817 - mean_absolute_error: 2.3236 - val_loss: 27.7800 - val_mean_absolute_error: 4.0285\n",
            "Epoch 492/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 13.6542 - mean_absolute_error: 2.6611 - val_loss: 18.5957 - val_mean_absolute_error: 3.3239\n",
            "Epoch 493/1000\n",
            "363/363 [==============================] - 0s 55us/step - loss: 10.1978 - mean_absolute_error: 2.2515 - val_loss: 20.3836 - val_mean_absolute_error: 3.6213\n",
            "Epoch 494/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 11.9598 - mean_absolute_error: 2.4645 - val_loss: 23.6089 - val_mean_absolute_error: 3.8284\n",
            "Epoch 495/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 13.5761 - mean_absolute_error: 2.6710 - val_loss: 17.3435 - val_mean_absolute_error: 3.1711\n",
            "Epoch 496/1000\n",
            "363/363 [==============================] - 0s 68us/step - loss: 10.2818 - mean_absolute_error: 2.3308 - val_loss: 34.5088 - val_mean_absolute_error: 4.7360\n",
            "Epoch 497/1000\n",
            "363/363 [==============================] - 0s 56us/step - loss: 10.9412 - mean_absolute_error: 2.3984 - val_loss: 22.3705 - val_mean_absolute_error: 3.6855\n",
            "Epoch 498/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 9.7419 - mean_absolute_error: 2.2341 - val_loss: 23.0070 - val_mean_absolute_error: 3.5722\n",
            "Epoch 499/1000\n",
            "363/363 [==============================] - 0s 57us/step - loss: 12.1654 - mean_absolute_error: 2.5298 - val_loss: 22.9562 - val_mean_absolute_error: 3.8307\n",
            "Epoch 500/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 10.6023 - mean_absolute_error: 2.3731 - val_loss: 21.9443 - val_mean_absolute_error: 3.7287\n",
            "Epoch 501/1000\n",
            "363/363 [==============================] - 0s 59us/step - loss: 12.2295 - mean_absolute_error: 2.5155 - val_loss: 19.0391 - val_mean_absolute_error: 3.4659\n",
            "Epoch 502/1000\n",
            "363/363 [==============================] - 0s 66us/step - loss: 10.3566 - mean_absolute_error: 2.3725 - val_loss: 22.1122 - val_mean_absolute_error: 3.5576\n",
            "Epoch 503/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 11.5428 - mean_absolute_error: 2.4194 - val_loss: 19.3065 - val_mean_absolute_error: 3.5108\n",
            "Epoch 504/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 11.0921 - mean_absolute_error: 2.3912 - val_loss: 21.5613 - val_mean_absolute_error: 3.7358\n",
            "Epoch 505/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 14.2664 - mean_absolute_error: 2.6811 - val_loss: 19.1169 - val_mean_absolute_error: 3.5312\n",
            "Epoch 506/1000\n",
            "363/363 [==============================] - 0s 62us/step - loss: 9.7873 - mean_absolute_error: 2.2455 - val_loss: 22.1561 - val_mean_absolute_error: 3.5236\n",
            "Epoch 507/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 12.8530 - mean_absolute_error: 2.5606 - val_loss: 19.9417 - val_mean_absolute_error: 3.4322\n",
            "Epoch 508/1000\n",
            "363/363 [==============================] - 0s 61us/step - loss: 9.8989 - mean_absolute_error: 2.3509 - val_loss: 22.6332 - val_mean_absolute_error: 3.7137\n",
            "Epoch 509/1000\n",
            "363/363 [==============================] - 0s 57us/step - loss: 13.8047 - mean_absolute_error: 2.5769 - val_loss: 17.4876 - val_mean_absolute_error: 3.3051\n",
            "Epoch 510/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 12.5273 - mean_absolute_error: 2.5804 - val_loss: 23.4654 - val_mean_absolute_error: 3.7038\n",
            "Epoch 511/1000\n",
            "363/363 [==============================] - 0s 56us/step - loss: 10.4198 - mean_absolute_error: 2.2446 - val_loss: 27.3895 - val_mean_absolute_error: 4.0356\n",
            "Epoch 512/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 11.8352 - mean_absolute_error: 2.4534 - val_loss: 20.0410 - val_mean_absolute_error: 3.3692\n",
            "Epoch 513/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 10.0785 - mean_absolute_error: 2.3505 - val_loss: 20.1257 - val_mean_absolute_error: 3.5999\n",
            "Epoch 514/1000\n",
            "363/363 [==============================] - 0s 72us/step - loss: 13.0044 - mean_absolute_error: 2.5289 - val_loss: 52.4006 - val_mean_absolute_error: 6.0095\n",
            "Epoch 515/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 13.0527 - mean_absolute_error: 2.5346 - val_loss: 27.2520 - val_mean_absolute_error: 4.0727\n",
            "Epoch 516/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 10.7313 - mean_absolute_error: 2.3584 - val_loss: 18.4697 - val_mean_absolute_error: 3.4322\n",
            "Epoch 517/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 14.7397 - mean_absolute_error: 2.6518 - val_loss: 18.9068 - val_mean_absolute_error: 3.3192\n",
            "Epoch 518/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 9.4569 - mean_absolute_error: 2.2772 - val_loss: 27.6401 - val_mean_absolute_error: 4.3289\n",
            "Epoch 519/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 13.2666 - mean_absolute_error: 2.5792 - val_loss: 17.7420 - val_mean_absolute_error: 3.3665\n",
            "Epoch 520/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 9.9895 - mean_absolute_error: 2.2934 - val_loss: 28.0305 - val_mean_absolute_error: 4.3768\n",
            "Epoch 521/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 15.3585 - mean_absolute_error: 2.5541 - val_loss: 21.1730 - val_mean_absolute_error: 3.6717\n",
            "Epoch 522/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 9.6789 - mean_absolute_error: 2.2967 - val_loss: 73.2304 - val_mean_absolute_error: 7.1526\n",
            "Epoch 523/1000\n",
            "363/363 [==============================] - 0s 56us/step - loss: 16.8102 - mean_absolute_error: 2.6701 - val_loss: 25.5984 - val_mean_absolute_error: 3.7928\n",
            "Epoch 524/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 14.7067 - mean_absolute_error: 2.5371 - val_loss: 18.1259 - val_mean_absolute_error: 3.3012\n",
            "Epoch 525/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 11.3266 - mean_absolute_error: 2.2448 - val_loss: 28.9794 - val_mean_absolute_error: 4.1130\n",
            "Epoch 526/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 9.8069 - mean_absolute_error: 2.2831 - val_loss: 22.9677 - val_mean_absolute_error: 3.7791\n",
            "Epoch 527/1000\n",
            "363/363 [==============================] - 0s 62us/step - loss: 9.9832 - mean_absolute_error: 2.2901 - val_loss: 17.9792 - val_mean_absolute_error: 3.2787\n",
            "Epoch 528/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 10.1860 - mean_absolute_error: 2.3282 - val_loss: 20.6022 - val_mean_absolute_error: 3.6373\n",
            "Epoch 529/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 13.5462 - mean_absolute_error: 2.4764 - val_loss: 18.4491 - val_mean_absolute_error: 3.3542\n",
            "Epoch 530/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 15.6664 - mean_absolute_error: 2.6704 - val_loss: 18.4091 - val_mean_absolute_error: 3.3556\n",
            "Epoch 531/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 8.4810 - mean_absolute_error: 2.0725 - val_loss: 20.3739 - val_mean_absolute_error: 3.6419\n",
            "Epoch 532/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 11.1725 - mean_absolute_error: 2.3821 - val_loss: 25.2358 - val_mean_absolute_error: 3.7864\n",
            "Epoch 533/1000\n",
            "363/363 [==============================] - 0s 57us/step - loss: 15.4201 - mean_absolute_error: 2.6947 - val_loss: 19.2215 - val_mean_absolute_error: 3.4766\n",
            "Epoch 534/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 11.4599 - mean_absolute_error: 2.3603 - val_loss: 23.2468 - val_mean_absolute_error: 3.6804\n",
            "Epoch 535/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 11.8283 - mean_absolute_error: 2.4118 - val_loss: 24.0925 - val_mean_absolute_error: 3.6484\n",
            "Epoch 536/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 14.2188 - mean_absolute_error: 2.6501 - val_loss: 19.4056 - val_mean_absolute_error: 3.3531\n",
            "Epoch 537/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 10.3367 - mean_absolute_error: 2.3392 - val_loss: 19.9784 - val_mean_absolute_error: 3.6226\n",
            "Epoch 538/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 13.1882 - mean_absolute_error: 2.5619 - val_loss: 32.3331 - val_mean_absolute_error: 4.5607\n",
            "Epoch 539/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 11.1100 - mean_absolute_error: 2.3760 - val_loss: 22.7436 - val_mean_absolute_error: 3.8114\n",
            "Epoch 540/1000\n",
            "363/363 [==============================] - 0s 61us/step - loss: 9.3198 - mean_absolute_error: 2.2132 - val_loss: 22.8819 - val_mean_absolute_error: 3.8728\n",
            "Epoch 541/1000\n",
            "363/363 [==============================] - 0s 56us/step - loss: 12.2876 - mean_absolute_error: 2.4364 - val_loss: 17.3323 - val_mean_absolute_error: 3.3368\n",
            "Epoch 542/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 11.9428 - mean_absolute_error: 2.3745 - val_loss: 40.4940 - val_mean_absolute_error: 5.2843\n",
            "Epoch 543/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 12.0414 - mean_absolute_error: 2.4427 - val_loss: 19.6332 - val_mean_absolute_error: 3.4054\n",
            "Epoch 544/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 10.1510 - mean_absolute_error: 2.2835 - val_loss: 20.0847 - val_mean_absolute_error: 3.4941\n",
            "Epoch 545/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 12.3842 - mean_absolute_error: 2.4527 - val_loss: 22.6606 - val_mean_absolute_error: 3.6255\n",
            "Epoch 546/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 12.1545 - mean_absolute_error: 2.4140 - val_loss: 18.0859 - val_mean_absolute_error: 3.4013\n",
            "Epoch 547/1000\n",
            "363/363 [==============================] - 0s 61us/step - loss: 11.9890 - mean_absolute_error: 2.3875 - val_loss: 21.7777 - val_mean_absolute_error: 3.5996\n",
            "Epoch 548/1000\n",
            "363/363 [==============================] - 0s 55us/step - loss: 10.6181 - mean_absolute_error: 2.3561 - val_loss: 19.2206 - val_mean_absolute_error: 3.5497\n",
            "Epoch 549/1000\n",
            "363/363 [==============================] - 0s 56us/step - loss: 8.9121 - mean_absolute_error: 2.1839 - val_loss: 41.0530 - val_mean_absolute_error: 5.3023\n",
            "Epoch 550/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 15.4891 - mean_absolute_error: 2.6829 - val_loss: 21.7029 - val_mean_absolute_error: 3.6051\n",
            "Epoch 551/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 10.8777 - mean_absolute_error: 2.3068 - val_loss: 20.7302 - val_mean_absolute_error: 3.6136\n",
            "Epoch 552/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 12.2056 - mean_absolute_error: 2.5103 - val_loss: 23.4974 - val_mean_absolute_error: 3.8567\n",
            "Epoch 553/1000\n",
            "363/363 [==============================] - 0s 58us/step - loss: 11.3434 - mean_absolute_error: 2.3261 - val_loss: 35.7863 - val_mean_absolute_error: 4.9705\n",
            "Epoch 554/1000\n",
            "363/363 [==============================] - 0s 56us/step - loss: 13.0125 - mean_absolute_error: 2.4942 - val_loss: 20.5557 - val_mean_absolute_error: 3.5693\n",
            "Epoch 555/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 10.3300 - mean_absolute_error: 2.3072 - val_loss: 24.0373 - val_mean_absolute_error: 3.7980\n",
            "Epoch 556/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 12.2888 - mean_absolute_error: 2.4743 - val_loss: 25.5389 - val_mean_absolute_error: 3.9250\n",
            "Epoch 557/1000\n",
            "363/363 [==============================] - 0s 56us/step - loss: 13.4696 - mean_absolute_error: 2.5840 - val_loss: 24.5210 - val_mean_absolute_error: 3.9013\n",
            "Epoch 558/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 9.4808 - mean_absolute_error: 2.2562 - val_loss: 19.1562 - val_mean_absolute_error: 3.4542\n",
            "Epoch 559/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 13.0880 - mean_absolute_error: 2.5246 - val_loss: 17.2655 - val_mean_absolute_error: 3.2599\n",
            "Epoch 560/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 9.9715 - mean_absolute_error: 2.3021 - val_loss: 28.0262 - val_mean_absolute_error: 4.1264\n",
            "Epoch 561/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 10.7257 - mean_absolute_error: 2.4151 - val_loss: 25.5411 - val_mean_absolute_error: 3.8161\n",
            "Epoch 562/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 13.0791 - mean_absolute_error: 2.6090 - val_loss: 20.6869 - val_mean_absolute_error: 3.7422\n",
            "Epoch 563/1000\n",
            "363/363 [==============================] - 0s 60us/step - loss: 11.1917 - mean_absolute_error: 2.4083 - val_loss: 24.4727 - val_mean_absolute_error: 3.9362\n",
            "Epoch 564/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 13.0227 - mean_absolute_error: 2.5416 - val_loss: 18.0526 - val_mean_absolute_error: 3.3560\n",
            "Epoch 565/1000\n",
            "363/363 [==============================] - 0s 57us/step - loss: 10.6755 - mean_absolute_error: 2.3764 - val_loss: 17.9096 - val_mean_absolute_error: 3.3310\n",
            "Epoch 566/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 10.1767 - mean_absolute_error: 2.3468 - val_loss: 24.3778 - val_mean_absolute_error: 3.7850\n",
            "Epoch 567/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 11.5753 - mean_absolute_error: 2.3764 - val_loss: 18.7348 - val_mean_absolute_error: 3.3182\n",
            "Epoch 568/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 12.1508 - mean_absolute_error: 2.5418 - val_loss: 20.9695 - val_mean_absolute_error: 3.4442\n",
            "Epoch 569/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 10.0777 - mean_absolute_error: 2.3166 - val_loss: 25.5819 - val_mean_absolute_error: 3.9355\n",
            "Epoch 570/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 13.3109 - mean_absolute_error: 2.6521 - val_loss: 16.5686 - val_mean_absolute_error: 3.1555\n",
            "Epoch 571/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 10.2711 - mean_absolute_error: 2.2193 - val_loss: 34.1591 - val_mean_absolute_error: 4.5907\n",
            "Epoch 572/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 10.6061 - mean_absolute_error: 2.3515 - val_loss: 20.6085 - val_mean_absolute_error: 3.5564\n",
            "Epoch 573/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 13.4956 - mean_absolute_error: 2.5502 - val_loss: 18.6740 - val_mean_absolute_error: 3.3778\n",
            "Epoch 574/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 10.6633 - mean_absolute_error: 2.2870 - val_loss: 21.5687 - val_mean_absolute_error: 3.4872\n",
            "Epoch 575/1000\n",
            "363/363 [==============================] - 0s 55us/step - loss: 9.1358 - mean_absolute_error: 2.2062 - val_loss: 20.4774 - val_mean_absolute_error: 3.5592\n",
            "Epoch 576/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 12.3308 - mean_absolute_error: 2.4163 - val_loss: 21.3305 - val_mean_absolute_error: 3.5405\n",
            "Epoch 577/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 10.1557 - mean_absolute_error: 2.3339 - val_loss: 18.6449 - val_mean_absolute_error: 3.3196\n",
            "Epoch 578/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 10.8491 - mean_absolute_error: 2.3941 - val_loss: 19.5536 - val_mean_absolute_error: 3.5840\n",
            "Epoch 579/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 9.7576 - mean_absolute_error: 2.2611 - val_loss: 24.6191 - val_mean_absolute_error: 4.1015\n",
            "Epoch 580/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 15.6510 - mean_absolute_error: 2.7634 - val_loss: 18.4993 - val_mean_absolute_error: 3.4108\n",
            "Epoch 581/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 10.2187 - mean_absolute_error: 2.2952 - val_loss: 23.8948 - val_mean_absolute_error: 3.8894\n",
            "Epoch 582/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 13.8792 - mean_absolute_error: 2.6741 - val_loss: 20.1335 - val_mean_absolute_error: 3.4513\n",
            "Epoch 583/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 11.0235 - mean_absolute_error: 2.3392 - val_loss: 18.6382 - val_mean_absolute_error: 3.4921\n",
            "Epoch 584/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 8.2257 - mean_absolute_error: 2.0679 - val_loss: 19.3432 - val_mean_absolute_error: 3.3277\n",
            "Epoch 585/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 13.8961 - mean_absolute_error: 2.5083 - val_loss: 18.9288 - val_mean_absolute_error: 3.2804\n",
            "Epoch 586/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 10.3686 - mean_absolute_error: 2.2911 - val_loss: 29.9862 - val_mean_absolute_error: 4.2092\n",
            "Epoch 587/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 12.5420 - mean_absolute_error: 2.4881 - val_loss: 17.9585 - val_mean_absolute_error: 3.2593\n",
            "Epoch 588/1000\n",
            "363/363 [==============================] - 0s 55us/step - loss: 12.2146 - mean_absolute_error: 2.5431 - val_loss: 19.2439 - val_mean_absolute_error: 3.4854\n",
            "Epoch 589/1000\n",
            "363/363 [==============================] - 0s 59us/step - loss: 8.5244 - mean_absolute_error: 2.1413 - val_loss: 23.0903 - val_mean_absolute_error: 3.6376\n",
            "Epoch 590/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 13.8822 - mean_absolute_error: 2.5533 - val_loss: 17.4162 - val_mean_absolute_error: 3.3170\n",
            "Epoch 591/1000\n",
            "363/363 [==============================] - 0s 55us/step - loss: 11.9972 - mean_absolute_error: 2.4171 - val_loss: 18.8708 - val_mean_absolute_error: 3.4665\n",
            "Epoch 592/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 10.7812 - mean_absolute_error: 2.4086 - val_loss: 31.9796 - val_mean_absolute_error: 4.5717\n",
            "Epoch 593/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 11.6945 - mean_absolute_error: 2.4338 - val_loss: 18.5925 - val_mean_absolute_error: 3.3900\n",
            "Epoch 594/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 9.2713 - mean_absolute_error: 2.2437 - val_loss: 22.9015 - val_mean_absolute_error: 3.7809\n",
            "Epoch 595/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 12.8253 - mean_absolute_error: 2.6214 - val_loss: 20.7269 - val_mean_absolute_error: 3.5296\n",
            "Epoch 596/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 8.9993 - mean_absolute_error: 2.1839 - val_loss: 17.7689 - val_mean_absolute_error: 3.4183\n",
            "Epoch 597/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 11.0298 - mean_absolute_error: 2.3833 - val_loss: 24.5751 - val_mean_absolute_error: 3.8299\n",
            "Epoch 598/1000\n",
            "363/363 [==============================] - 0s 55us/step - loss: 11.5793 - mean_absolute_error: 2.4429 - val_loss: 18.3824 - val_mean_absolute_error: 3.4391\n",
            "Epoch 599/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 10.9721 - mean_absolute_error: 2.4349 - val_loss: 20.8738 - val_mean_absolute_error: 3.5758\n",
            "Epoch 600/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 10.9159 - mean_absolute_error: 2.3473 - val_loss: 19.4531 - val_mean_absolute_error: 3.4183\n",
            "Epoch 601/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 10.4724 - mean_absolute_error: 2.3279 - val_loss: 18.1519 - val_mean_absolute_error: 3.2274\n",
            "Epoch 602/1000\n",
            "363/363 [==============================] - 0s 55us/step - loss: 11.9906 - mean_absolute_error: 2.4275 - val_loss: 22.0745 - val_mean_absolute_error: 3.6489\n",
            "Epoch 603/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 11.0706 - mean_absolute_error: 2.3706 - val_loss: 18.5007 - val_mean_absolute_error: 3.4399\n",
            "Epoch 604/1000\n",
            "363/363 [==============================] - 0s 56us/step - loss: 11.2339 - mean_absolute_error: 2.4365 - val_loss: 18.9755 - val_mean_absolute_error: 3.4527\n",
            "Epoch 605/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 14.1925 - mean_absolute_error: 2.5579 - val_loss: 19.0811 - val_mean_absolute_error: 3.3352\n",
            "Epoch 606/1000\n",
            "363/363 [==============================] - 0s 55us/step - loss: 11.0021 - mean_absolute_error: 2.3223 - val_loss: 19.8438 - val_mean_absolute_error: 3.6437\n",
            "Epoch 607/1000\n",
            "363/363 [==============================] - 0s 56us/step - loss: 10.9895 - mean_absolute_error: 2.4002 - val_loss: 17.7863 - val_mean_absolute_error: 3.2596\n",
            "Epoch 608/1000\n",
            "363/363 [==============================] - 0s 55us/step - loss: 14.5149 - mean_absolute_error: 2.5681 - val_loss: 26.4132 - val_mean_absolute_error: 3.8903\n",
            "Epoch 609/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 10.3940 - mean_absolute_error: 2.2993 - val_loss: 18.0763 - val_mean_absolute_error: 3.4019\n",
            "Epoch 610/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 9.2487 - mean_absolute_error: 2.2698 - val_loss: 22.9405 - val_mean_absolute_error: 3.7335\n",
            "Epoch 611/1000\n",
            "363/363 [==============================] - 0s 58us/step - loss: 11.1906 - mean_absolute_error: 2.4213 - val_loss: 19.6411 - val_mean_absolute_error: 3.3459\n",
            "Epoch 612/1000\n",
            "363/363 [==============================] - 0s 55us/step - loss: 11.8983 - mean_absolute_error: 2.4797 - val_loss: 25.5956 - val_mean_absolute_error: 3.8489\n",
            "Epoch 613/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 12.0105 - mean_absolute_error: 2.4667 - val_loss: 16.2299 - val_mean_absolute_error: 3.1960\n",
            "Epoch 614/1000\n",
            "363/363 [==============================] - 0s 55us/step - loss: 9.9758 - mean_absolute_error: 2.3545 - val_loss: 20.0481 - val_mean_absolute_error: 3.6544\n",
            "Epoch 615/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 15.0630 - mean_absolute_error: 2.7858 - val_loss: 20.5450 - val_mean_absolute_error: 3.5687\n",
            "Epoch 616/1000\n",
            "363/363 [==============================] - 0s 57us/step - loss: 9.2123 - mean_absolute_error: 2.2252 - val_loss: 19.4948 - val_mean_absolute_error: 3.5566\n",
            "Epoch 617/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 9.4247 - mean_absolute_error: 2.2031 - val_loss: 26.8949 - val_mean_absolute_error: 3.9919\n",
            "Epoch 618/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 14.1427 - mean_absolute_error: 2.6506 - val_loss: 20.9866 - val_mean_absolute_error: 3.4572\n",
            "Epoch 619/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 9.0373 - mean_absolute_error: 2.1942 - val_loss: 19.8526 - val_mean_absolute_error: 3.5555\n",
            "Epoch 620/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 14.0981 - mean_absolute_error: 2.7694 - val_loss: 20.6488 - val_mean_absolute_error: 3.5765\n",
            "Epoch 621/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 9.0843 - mean_absolute_error: 2.1477 - val_loss: 23.4501 - val_mean_absolute_error: 3.6228\n",
            "Epoch 622/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 11.1486 - mean_absolute_error: 2.3709 - val_loss: 19.5364 - val_mean_absolute_error: 3.4124\n",
            "Epoch 623/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 11.7322 - mean_absolute_error: 2.3924 - val_loss: 19.9549 - val_mean_absolute_error: 3.4223\n",
            "Epoch 624/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 11.0480 - mean_absolute_error: 2.3086 - val_loss: 20.4277 - val_mean_absolute_error: 3.5116\n",
            "Epoch 625/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 11.6101 - mean_absolute_error: 2.3383 - val_loss: 18.2727 - val_mean_absolute_error: 3.3841\n",
            "Epoch 626/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 9.9833 - mean_absolute_error: 2.2665 - val_loss: 19.3561 - val_mean_absolute_error: 3.4126\n",
            "Epoch 627/1000\n",
            "363/363 [==============================] - 0s 55us/step - loss: 11.3129 - mean_absolute_error: 2.3544 - val_loss: 17.3622 - val_mean_absolute_error: 3.2179\n",
            "Epoch 628/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 10.7010 - mean_absolute_error: 2.3279 - val_loss: 17.6653 - val_mean_absolute_error: 3.3019\n",
            "Epoch 629/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 8.3027 - mean_absolute_error: 2.1464 - val_loss: 22.7959 - val_mean_absolute_error: 3.5560\n",
            "Epoch 630/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 13.2554 - mean_absolute_error: 2.5763 - val_loss: 24.2495 - val_mean_absolute_error: 3.7633\n",
            "Epoch 631/1000\n",
            "363/363 [==============================] - 0s 59us/step - loss: 11.8865 - mean_absolute_error: 2.4540 - val_loss: 16.6783 - val_mean_absolute_error: 3.1545\n",
            "Epoch 632/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 10.6660 - mean_absolute_error: 2.2881 - val_loss: 28.7445 - val_mean_absolute_error: 4.1902\n",
            "Epoch 633/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 12.4162 - mean_absolute_error: 2.5529 - val_loss: 18.3958 - val_mean_absolute_error: 3.3166\n",
            "Epoch 634/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 11.4026 - mean_absolute_error: 2.3873 - val_loss: 22.5610 - val_mean_absolute_error: 3.6200\n",
            "Epoch 635/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 10.6091 - mean_absolute_error: 2.3099 - val_loss: 20.7016 - val_mean_absolute_error: 3.5123\n",
            "Epoch 636/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 12.0322 - mean_absolute_error: 2.4983 - val_loss: 18.1168 - val_mean_absolute_error: 3.4428\n",
            "Epoch 637/1000\n",
            "363/363 [==============================] - 0s 57us/step - loss: 8.9252 - mean_absolute_error: 2.2645 - val_loss: 22.1098 - val_mean_absolute_error: 3.8937\n",
            "Epoch 638/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 11.6458 - mean_absolute_error: 2.4896 - val_loss: 17.7429 - val_mean_absolute_error: 3.2926\n",
            "Epoch 639/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 11.1002 - mean_absolute_error: 2.4094 - val_loss: 27.1168 - val_mean_absolute_error: 4.2103\n",
            "Epoch 640/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 10.6600 - mean_absolute_error: 2.3852 - val_loss: 18.6490 - val_mean_absolute_error: 3.3627\n",
            "Epoch 641/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 12.4590 - mean_absolute_error: 2.4612 - val_loss: 17.1863 - val_mean_absolute_error: 3.3054\n",
            "Epoch 642/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 8.7690 - mean_absolute_error: 2.1985 - val_loss: 21.4443 - val_mean_absolute_error: 3.5944\n",
            "Epoch 643/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 10.5163 - mean_absolute_error: 2.2783 - val_loss: 17.1314 - val_mean_absolute_error: 3.1535\n",
            "Epoch 644/1000\n",
            "363/363 [==============================] - 0s 55us/step - loss: 9.4009 - mean_absolute_error: 2.2619 - val_loss: 22.4625 - val_mean_absolute_error: 3.9250\n",
            "Epoch 645/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 12.9292 - mean_absolute_error: 2.4597 - val_loss: 17.7124 - val_mean_absolute_error: 3.3828\n",
            "Epoch 646/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 10.7863 - mean_absolute_error: 2.3095 - val_loss: 22.7283 - val_mean_absolute_error: 3.8539\n",
            "Epoch 647/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 10.5945 - mean_absolute_error: 2.3189 - val_loss: 24.0138 - val_mean_absolute_error: 3.7749\n",
            "Epoch 648/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 11.3885 - mean_absolute_error: 2.4250 - val_loss: 17.7416 - val_mean_absolute_error: 3.2798\n",
            "Epoch 649/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 10.2849 - mean_absolute_error: 2.2924 - val_loss: 20.5788 - val_mean_absolute_error: 3.6421\n",
            "Epoch 650/1000\n",
            "363/363 [==============================] - 0s 56us/step - loss: 10.5503 - mean_absolute_error: 2.3620 - val_loss: 16.9186 - val_mean_absolute_error: 3.1927\n",
            "Epoch 651/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 9.7288 - mean_absolute_error: 2.3545 - val_loss: 19.3142 - val_mean_absolute_error: 3.3930\n",
            "Epoch 652/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 11.8853 - mean_absolute_error: 2.4142 - val_loss: 24.0057 - val_mean_absolute_error: 3.9917\n",
            "Epoch 653/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 10.5862 - mean_absolute_error: 2.2912 - val_loss: 20.9083 - val_mean_absolute_error: 3.6292\n",
            "Epoch 654/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 11.1856 - mean_absolute_error: 2.3691 - val_loss: 20.8655 - val_mean_absolute_error: 3.4812\n",
            "Epoch 655/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 10.4640 - mean_absolute_error: 2.3228 - val_loss: 18.0809 - val_mean_absolute_error: 3.2313\n",
            "Epoch 656/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 9.6841 - mean_absolute_error: 2.2466 - val_loss: 18.7032 - val_mean_absolute_error: 3.3560\n",
            "Epoch 657/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 10.9073 - mean_absolute_error: 2.3331 - val_loss: 18.7762 - val_mean_absolute_error: 3.5543\n",
            "Epoch 658/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 10.8874 - mean_absolute_error: 2.3563 - val_loss: 19.6850 - val_mean_absolute_error: 3.4187\n",
            "Epoch 659/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 9.5166 - mean_absolute_error: 2.2702 - val_loss: 19.3548 - val_mean_absolute_error: 3.4062\n",
            "Epoch 660/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 13.2005 - mean_absolute_error: 2.5110 - val_loss: 24.2134 - val_mean_absolute_error: 3.8229\n",
            "Epoch 661/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 9.4370 - mean_absolute_error: 2.2000 - val_loss: 21.2720 - val_mean_absolute_error: 3.5699\n",
            "Epoch 662/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 13.9446 - mean_absolute_error: 2.5932 - val_loss: 19.3019 - val_mean_absolute_error: 3.3776\n",
            "Epoch 663/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 10.1042 - mean_absolute_error: 2.2449 - val_loss: 22.5995 - val_mean_absolute_error: 3.7348\n",
            "Epoch 664/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 10.1002 - mean_absolute_error: 2.3323 - val_loss: 17.7364 - val_mean_absolute_error: 3.3489\n",
            "Epoch 665/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 10.8153 - mean_absolute_error: 2.3233 - val_loss: 19.2543 - val_mean_absolute_error: 3.4774\n",
            "Epoch 666/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 9.7983 - mean_absolute_error: 2.2665 - val_loss: 18.3793 - val_mean_absolute_error: 3.3363\n",
            "Epoch 667/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 11.0203 - mean_absolute_error: 2.3597 - val_loss: 18.0535 - val_mean_absolute_error: 3.3924\n",
            "Epoch 668/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 10.4754 - mean_absolute_error: 2.3397 - val_loss: 29.9839 - val_mean_absolute_error: 4.1691\n",
            "Epoch 669/1000\n",
            "363/363 [==============================] - 0s 56us/step - loss: 12.0091 - mean_absolute_error: 2.4932 - val_loss: 19.4022 - val_mean_absolute_error: 3.5304\n",
            "Epoch 670/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 10.5708 - mean_absolute_error: 2.2892 - val_loss: 24.1759 - val_mean_absolute_error: 3.8984\n",
            "Epoch 671/1000\n",
            "363/363 [==============================] - 0s 68us/step - loss: 11.7537 - mean_absolute_error: 2.5027 - val_loss: 16.5770 - val_mean_absolute_error: 3.1745\n",
            "Epoch 672/1000\n",
            "363/363 [==============================] - 0s 67us/step - loss: 9.8130 - mean_absolute_error: 2.3368 - val_loss: 24.5108 - val_mean_absolute_error: 3.7307\n",
            "Epoch 673/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 11.2504 - mean_absolute_error: 2.3789 - val_loss: 18.3827 - val_mean_absolute_error: 3.4162\n",
            "Epoch 674/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 9.8960 - mean_absolute_error: 2.2575 - val_loss: 19.3982 - val_mean_absolute_error: 3.3411\n",
            "Epoch 675/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 12.9764 - mean_absolute_error: 2.5926 - val_loss: 16.6917 - val_mean_absolute_error: 3.1516\n",
            "Epoch 676/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 9.8744 - mean_absolute_error: 2.1909 - val_loss: 18.2203 - val_mean_absolute_error: 3.3566\n",
            "Epoch 677/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 10.7038 - mean_absolute_error: 2.3979 - val_loss: 18.0225 - val_mean_absolute_error: 3.2775\n",
            "Epoch 678/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 8.8451 - mean_absolute_error: 2.2129 - val_loss: 19.4244 - val_mean_absolute_error: 3.5256\n",
            "Epoch 679/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 10.5510 - mean_absolute_error: 2.2929 - val_loss: 35.4062 - val_mean_absolute_error: 4.9347\n",
            "Epoch 680/1000\n",
            "363/363 [==============================] - 0s 68us/step - loss: 14.4839 - mean_absolute_error: 2.4903 - val_loss: 29.0605 - val_mean_absolute_error: 4.1747\n",
            "Epoch 681/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 10.0097 - mean_absolute_error: 2.2579 - val_loss: 23.8544 - val_mean_absolute_error: 3.8445\n",
            "Epoch 682/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 9.3589 - mean_absolute_error: 2.2027 - val_loss: 18.9481 - val_mean_absolute_error: 3.5078\n",
            "Epoch 683/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 8.8366 - mean_absolute_error: 2.2093 - val_loss: 18.7391 - val_mean_absolute_error: 3.3392\n",
            "Epoch 684/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 10.6540 - mean_absolute_error: 2.3310 - val_loss: 18.5967 - val_mean_absolute_error: 3.3945\n",
            "Epoch 685/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 9.8132 - mean_absolute_error: 2.2402 - val_loss: 31.3273 - val_mean_absolute_error: 4.5122\n",
            "Epoch 686/1000\n",
            "363/363 [==============================] - 0s 55us/step - loss: 15.1160 - mean_absolute_error: 2.5018 - val_loss: 17.1976 - val_mean_absolute_error: 3.1832\n",
            "Epoch 687/1000\n",
            "363/363 [==============================] - 0s 55us/step - loss: 8.8037 - mean_absolute_error: 2.2088 - val_loss: 20.0837 - val_mean_absolute_error: 3.5116\n",
            "Epoch 688/1000\n",
            "363/363 [==============================] - 0s 55us/step - loss: 11.3685 - mean_absolute_error: 2.3960 - val_loss: 50.5394 - val_mean_absolute_error: 5.9641\n",
            "Epoch 689/1000\n",
            "363/363 [==============================] - 0s 60us/step - loss: 11.6921 - mean_absolute_error: 2.4145 - val_loss: 20.6968 - val_mean_absolute_error: 3.4789\n",
            "Epoch 690/1000\n",
            "363/363 [==============================] - 0s 55us/step - loss: 9.6326 - mean_absolute_error: 2.2615 - val_loss: 18.1420 - val_mean_absolute_error: 3.3898\n",
            "Epoch 691/1000\n",
            "363/363 [==============================] - 0s 59us/step - loss: 9.4247 - mean_absolute_error: 2.2171 - val_loss: 19.3539 - val_mean_absolute_error: 3.5111\n",
            "Epoch 692/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 9.9045 - mean_absolute_error: 2.2882 - val_loss: 21.4458 - val_mean_absolute_error: 3.6679\n",
            "Epoch 693/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 12.7221 - mean_absolute_error: 2.3867 - val_loss: 18.0339 - val_mean_absolute_error: 3.4558\n",
            "Epoch 694/1000\n",
            "363/363 [==============================] - 0s 60us/step - loss: 8.8475 - mean_absolute_error: 2.1863 - val_loss: 18.1991 - val_mean_absolute_error: 3.2953\n",
            "Epoch 695/1000\n",
            "363/363 [==============================] - 0s 63us/step - loss: 9.2544 - mean_absolute_error: 2.2176 - val_loss: 20.1853 - val_mean_absolute_error: 3.5128\n",
            "Epoch 696/1000\n",
            "363/363 [==============================] - 0s 68us/step - loss: 12.2614 - mean_absolute_error: 2.5010 - val_loss: 16.0361 - val_mean_absolute_error: 3.0877\n",
            "Epoch 697/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 10.0289 - mean_absolute_error: 2.2563 - val_loss: 20.3416 - val_mean_absolute_error: 3.6446\n",
            "Epoch 698/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 9.4899 - mean_absolute_error: 2.2124 - val_loss: 25.9577 - val_mean_absolute_error: 3.8790\n",
            "Epoch 699/1000\n",
            "363/363 [==============================] - 0s 67us/step - loss: 10.1677 - mean_absolute_error: 2.3138 - val_loss: 20.1884 - val_mean_absolute_error: 3.6415\n",
            "Epoch 700/1000\n",
            "363/363 [==============================] - 0s 55us/step - loss: 10.7246 - mean_absolute_error: 2.3742 - val_loss: 18.8961 - val_mean_absolute_error: 3.4672\n",
            "Epoch 701/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 11.5065 - mean_absolute_error: 2.4447 - val_loss: 18.0684 - val_mean_absolute_error: 3.2965\n",
            "Epoch 702/1000\n",
            "363/363 [==============================] - 0s 45us/step - loss: 9.9457 - mean_absolute_error: 2.1868 - val_loss: 18.5828 - val_mean_absolute_error: 3.3706\n",
            "Epoch 703/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 14.8450 - mean_absolute_error: 2.6959 - val_loss: 23.5841 - val_mean_absolute_error: 3.7760\n",
            "Epoch 704/1000\n",
            "363/363 [==============================] - 0s 60us/step - loss: 10.4887 - mean_absolute_error: 2.3276 - val_loss: 16.9778 - val_mean_absolute_error: 3.2073\n",
            "Epoch 705/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 8.7149 - mean_absolute_error: 2.1646 - val_loss: 17.8365 - val_mean_absolute_error: 3.2462\n",
            "Epoch 706/1000\n",
            "363/363 [==============================] - 0s 55us/step - loss: 10.4103 - mean_absolute_error: 2.3698 - val_loss: 17.8370 - val_mean_absolute_error: 3.2480\n",
            "Epoch 707/1000\n",
            "363/363 [==============================] - 0s 59us/step - loss: 10.1454 - mean_absolute_error: 2.3405 - val_loss: 21.5001 - val_mean_absolute_error: 3.5861\n",
            "Epoch 708/1000\n",
            "363/363 [==============================] - 0s 55us/step - loss: 13.2605 - mean_absolute_error: 2.5568 - val_loss: 19.8368 - val_mean_absolute_error: 3.5813\n",
            "Epoch 709/1000\n",
            "363/363 [==============================] - 0s 68us/step - loss: 8.8765 - mean_absolute_error: 2.1718 - val_loss: 25.2331 - val_mean_absolute_error: 3.9000\n",
            "Epoch 710/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 10.0711 - mean_absolute_error: 2.2833 - val_loss: 25.5504 - val_mean_absolute_error: 3.9552\n",
            "Epoch 711/1000\n",
            "363/363 [==============================] - 0s 58us/step - loss: 11.0554 - mean_absolute_error: 2.3095 - val_loss: 29.3995 - val_mean_absolute_error: 4.2331\n",
            "Epoch 712/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 11.0385 - mean_absolute_error: 2.3660 - val_loss: 18.4513 - val_mean_absolute_error: 3.3075\n",
            "Epoch 713/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 8.7019 - mean_absolute_error: 2.1710 - val_loss: 25.8536 - val_mean_absolute_error: 3.8464\n",
            "Epoch 714/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 9.0400 - mean_absolute_error: 2.2631 - val_loss: 19.4910 - val_mean_absolute_error: 3.4674\n",
            "Epoch 715/1000\n",
            "363/363 [==============================] - 0s 59us/step - loss: 10.5805 - mean_absolute_error: 2.3733 - val_loss: 17.3270 - val_mean_absolute_error: 3.2412\n",
            "Epoch 716/1000\n",
            "363/363 [==============================] - 0s 56us/step - loss: 9.3220 - mean_absolute_error: 2.1972 - val_loss: 18.6418 - val_mean_absolute_error: 3.4317\n",
            "Epoch 717/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 14.6467 - mean_absolute_error: 2.7016 - val_loss: 18.5213 - val_mean_absolute_error: 3.3453\n",
            "Epoch 718/1000\n",
            "363/363 [==============================] - 0s 55us/step - loss: 7.9396 - mean_absolute_error: 2.0509 - val_loss: 16.3492 - val_mean_absolute_error: 3.1294\n",
            "Epoch 719/1000\n",
            "363/363 [==============================] - 0s 63us/step - loss: 8.2618 - mean_absolute_error: 2.1288 - val_loss: 25.0527 - val_mean_absolute_error: 3.8310\n",
            "Epoch 720/1000\n",
            "363/363 [==============================] - 0s 59us/step - loss: 14.3529 - mean_absolute_error: 2.6159 - val_loss: 21.4070 - val_mean_absolute_error: 3.7196\n",
            "Epoch 721/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 12.1018 - mean_absolute_error: 2.5160 - val_loss: 18.8339 - val_mean_absolute_error: 3.4856\n",
            "Epoch 722/1000\n",
            "363/363 [==============================] - 0s 63us/step - loss: 9.5498 - mean_absolute_error: 2.1689 - val_loss: 19.0390 - val_mean_absolute_error: 3.3682\n",
            "Epoch 723/1000\n",
            "363/363 [==============================] - 0s 55us/step - loss: 9.6128 - mean_absolute_error: 2.2872 - val_loss: 16.7168 - val_mean_absolute_error: 3.1797\n",
            "Epoch 724/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 11.2942 - mean_absolute_error: 2.3387 - val_loss: 21.1991 - val_mean_absolute_error: 3.4884\n",
            "Epoch 725/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 11.8540 - mean_absolute_error: 2.3628 - val_loss: 18.6052 - val_mean_absolute_error: 3.4983\n",
            "Epoch 726/1000\n",
            "363/363 [==============================] - 0s 57us/step - loss: 7.7590 - mean_absolute_error: 2.0568 - val_loss: 19.4256 - val_mean_absolute_error: 3.4630\n",
            "Epoch 727/1000\n",
            "363/363 [==============================] - 0s 61us/step - loss: 14.2117 - mean_absolute_error: 2.6923 - val_loss: 23.5643 - val_mean_absolute_error: 3.6618\n",
            "Epoch 728/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 8.5748 - mean_absolute_error: 2.1449 - val_loss: 18.4287 - val_mean_absolute_error: 3.4040\n",
            "Epoch 729/1000\n",
            "363/363 [==============================] - 0s 71us/step - loss: 9.9452 - mean_absolute_error: 2.2758 - val_loss: 19.4476 - val_mean_absolute_error: 3.4660\n",
            "Epoch 730/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 10.3272 - mean_absolute_error: 2.3040 - val_loss: 18.2303 - val_mean_absolute_error: 3.3536\n",
            "Epoch 731/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 9.5354 - mean_absolute_error: 2.3530 - val_loss: 16.9997 - val_mean_absolute_error: 3.2782\n",
            "Epoch 732/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 10.5659 - mean_absolute_error: 2.3002 - val_loss: 25.1038 - val_mean_absolute_error: 4.0711\n",
            "Epoch 733/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 11.9374 - mean_absolute_error: 2.3425 - val_loss: 17.2110 - val_mean_absolute_error: 3.2696\n",
            "Epoch 734/1000\n",
            "363/363 [==============================] - 0s 56us/step - loss: 10.7982 - mean_absolute_error: 2.2835 - val_loss: 19.2655 - val_mean_absolute_error: 3.4831\n",
            "Epoch 735/1000\n",
            "363/363 [==============================] - 0s 59us/step - loss: 10.3379 - mean_absolute_error: 2.2431 - val_loss: 18.9589 - val_mean_absolute_error: 3.6134\n",
            "Epoch 736/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 9.4521 - mean_absolute_error: 2.2591 - val_loss: 17.4273 - val_mean_absolute_error: 3.3491\n",
            "Epoch 737/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 11.9396 - mean_absolute_error: 2.3946 - val_loss: 18.4049 - val_mean_absolute_error: 3.4191\n",
            "Epoch 738/1000\n",
            "363/363 [==============================] - 0s 61us/step - loss: 8.1173 - mean_absolute_error: 2.0970 - val_loss: 16.9658 - val_mean_absolute_error: 3.2058\n",
            "Epoch 739/1000\n",
            "363/363 [==============================] - 0s 66us/step - loss: 9.9436 - mean_absolute_error: 2.3237 - val_loss: 15.7764 - val_mean_absolute_error: 3.1227\n",
            "Epoch 740/1000\n",
            "363/363 [==============================] - 0s 59us/step - loss: 11.9350 - mean_absolute_error: 2.4286 - val_loss: 17.2151 - val_mean_absolute_error: 3.2656\n",
            "Epoch 741/1000\n",
            "363/363 [==============================] - 0s 55us/step - loss: 8.2170 - mean_absolute_error: 2.1572 - val_loss: 28.5549 - val_mean_absolute_error: 4.1455\n",
            "Epoch 742/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 12.1194 - mean_absolute_error: 2.3918 - val_loss: 18.1419 - val_mean_absolute_error: 3.3679\n",
            "Epoch 743/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 9.6092 - mean_absolute_error: 2.2784 - val_loss: 27.7606 - val_mean_absolute_error: 4.0873\n",
            "Epoch 744/1000\n",
            "363/363 [==============================] - 0s 57us/step - loss: 8.3019 - mean_absolute_error: 2.1110 - val_loss: 20.2151 - val_mean_absolute_error: 3.4819\n",
            "Epoch 745/1000\n",
            "363/363 [==============================] - 0s 59us/step - loss: 10.7229 - mean_absolute_error: 2.3595 - val_loss: 17.0950 - val_mean_absolute_error: 3.2295\n",
            "Epoch 746/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 11.3566 - mean_absolute_error: 2.3553 - val_loss: 20.1254 - val_mean_absolute_error: 3.4871\n",
            "Epoch 747/1000\n",
            "363/363 [==============================] - 0s 55us/step - loss: 10.9733 - mean_absolute_error: 2.3182 - val_loss: 31.6785 - val_mean_absolute_error: 4.4027\n",
            "Epoch 748/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 10.8351 - mean_absolute_error: 2.1841 - val_loss: 16.8185 - val_mean_absolute_error: 3.1864\n",
            "Epoch 749/1000\n",
            "363/363 [==============================] - 0s 61us/step - loss: 8.6075 - mean_absolute_error: 2.1558 - val_loss: 24.5458 - val_mean_absolute_error: 4.0314\n",
            "Epoch 750/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 12.3974 - mean_absolute_error: 2.5214 - val_loss: 23.2698 - val_mean_absolute_error: 3.7266\n",
            "Epoch 751/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 8.3406 - mean_absolute_error: 2.0645 - val_loss: 31.1856 - val_mean_absolute_error: 4.5864\n",
            "Epoch 752/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 10.1744 - mean_absolute_error: 2.2841 - val_loss: 21.4126 - val_mean_absolute_error: 3.7508\n",
            "Epoch 753/1000\n",
            "363/363 [==============================] - 0s 64us/step - loss: 10.3788 - mean_absolute_error: 2.3124 - val_loss: 22.4745 - val_mean_absolute_error: 3.7876\n",
            "Epoch 754/1000\n",
            "363/363 [==============================] - 0s 63us/step - loss: 12.1063 - mean_absolute_error: 2.4024 - val_loss: 20.1164 - val_mean_absolute_error: 3.6431\n",
            "Epoch 755/1000\n",
            "363/363 [==============================] - 0s 62us/step - loss: 9.2135 - mean_absolute_error: 2.2131 - val_loss: 17.4224 - val_mean_absolute_error: 3.1296\n",
            "Epoch 756/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 9.3202 - mean_absolute_error: 2.1675 - val_loss: 32.8434 - val_mean_absolute_error: 4.4369\n",
            "Epoch 757/1000\n",
            "363/363 [==============================] - 0s 56us/step - loss: 9.6661 - mean_absolute_error: 2.1817 - val_loss: 20.1861 - val_mean_absolute_error: 3.5359\n",
            "Epoch 758/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 10.9090 - mean_absolute_error: 2.3325 - val_loss: 28.7110 - val_mean_absolute_error: 4.1281\n",
            "Epoch 759/1000\n",
            "363/363 [==============================] - 0s 59us/step - loss: 8.6476 - mean_absolute_error: 2.1643 - val_loss: 16.8087 - val_mean_absolute_error: 3.1879\n",
            "Epoch 760/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 9.9611 - mean_absolute_error: 2.3314 - val_loss: 26.3295 - val_mean_absolute_error: 3.8780\n",
            "Epoch 761/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 8.4861 - mean_absolute_error: 2.1822 - val_loss: 18.3413 - val_mean_absolute_error: 3.4872\n",
            "Epoch 762/1000\n",
            "363/363 [==============================] - 0s 59us/step - loss: 10.6051 - mean_absolute_error: 2.3391 - val_loss: 21.8408 - val_mean_absolute_error: 3.6511\n",
            "Epoch 763/1000\n",
            "363/363 [==============================] - 0s 56us/step - loss: 10.0193 - mean_absolute_error: 2.2811 - val_loss: 17.7099 - val_mean_absolute_error: 3.3010\n",
            "Epoch 764/1000\n",
            "363/363 [==============================] - 0s 60us/step - loss: 9.0058 - mean_absolute_error: 2.1862 - val_loss: 18.7451 - val_mean_absolute_error: 3.5031\n",
            "Epoch 765/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 8.6809 - mean_absolute_error: 2.0376 - val_loss: 29.0521 - val_mean_absolute_error: 4.2338\n",
            "Epoch 766/1000\n",
            "363/363 [==============================] - 0s 62us/step - loss: 12.2918 - mean_absolute_error: 2.5284 - val_loss: 16.8588 - val_mean_absolute_error: 3.2661\n",
            "Epoch 767/1000\n",
            "363/363 [==============================] - 0s 63us/step - loss: 10.6831 - mean_absolute_error: 2.3339 - val_loss: 17.0343 - val_mean_absolute_error: 3.2231\n",
            "Epoch 768/1000\n",
            "363/363 [==============================] - 0s 57us/step - loss: 10.8794 - mean_absolute_error: 2.2869 - val_loss: 18.5319 - val_mean_absolute_error: 3.5125\n",
            "Epoch 769/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 8.9571 - mean_absolute_error: 2.1709 - val_loss: 16.9473 - val_mean_absolute_error: 3.1830\n",
            "Epoch 770/1000\n",
            "363/363 [==============================] - 0s 60us/step - loss: 10.2580 - mean_absolute_error: 2.3205 - val_loss: 30.6537 - val_mean_absolute_error: 4.4437\n",
            "Epoch 771/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 11.3616 - mean_absolute_error: 2.3690 - val_loss: 21.0898 - val_mean_absolute_error: 3.6719\n",
            "Epoch 772/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 10.5359 - mean_absolute_error: 2.3836 - val_loss: 20.0152 - val_mean_absolute_error: 3.5188\n",
            "Epoch 773/1000\n",
            "363/363 [==============================] - 0s 55us/step - loss: 11.3567 - mean_absolute_error: 2.3247 - val_loss: 18.6752 - val_mean_absolute_error: 3.4813\n",
            "Epoch 774/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 8.7683 - mean_absolute_error: 2.1558 - val_loss: 19.2209 - val_mean_absolute_error: 3.6307\n",
            "Epoch 775/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 9.8846 - mean_absolute_error: 2.2580 - val_loss: 23.5331 - val_mean_absolute_error: 3.6543\n",
            "Epoch 776/1000\n",
            "363/363 [==============================] - 0s 61us/step - loss: 8.1245 - mean_absolute_error: 2.1171 - val_loss: 16.4235 - val_mean_absolute_error: 3.1869\n",
            "Epoch 777/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 10.9775 - mean_absolute_error: 2.4636 - val_loss: 19.9621 - val_mean_absolute_error: 3.6161\n",
            "Epoch 778/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 12.3072 - mean_absolute_error: 2.3302 - val_loss: 16.8475 - val_mean_absolute_error: 3.1728\n",
            "Epoch 779/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 7.9083 - mean_absolute_error: 2.0150 - val_loss: 29.1077 - val_mean_absolute_error: 4.5111\n",
            "Epoch 780/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 10.8230 - mean_absolute_error: 2.3774 - val_loss: 18.7065 - val_mean_absolute_error: 3.4996\n",
            "Epoch 781/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 12.2941 - mean_absolute_error: 2.3307 - val_loss: 18.6598 - val_mean_absolute_error: 3.4110\n",
            "Epoch 782/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 7.6438 - mean_absolute_error: 2.0197 - val_loss: 17.1608 - val_mean_absolute_error: 3.2795\n",
            "Epoch 783/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 11.1823 - mean_absolute_error: 2.4329 - val_loss: 18.3809 - val_mean_absolute_error: 3.2744\n",
            "Epoch 784/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 9.2872 - mean_absolute_error: 2.2302 - val_loss: 18.2313 - val_mean_absolute_error: 3.3132\n",
            "Epoch 785/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 9.8739 - mean_absolute_error: 2.2315 - val_loss: 37.2775 - val_mean_absolute_error: 5.1416\n",
            "Epoch 786/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 10.0188 - mean_absolute_error: 2.2125 - val_loss: 18.6362 - val_mean_absolute_error: 3.3211\n",
            "Epoch 787/1000\n",
            "363/363 [==============================] - 0s 55us/step - loss: 10.9782 - mean_absolute_error: 2.3791 - val_loss: 21.2371 - val_mean_absolute_error: 3.6934\n",
            "Epoch 788/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 9.3013 - mean_absolute_error: 2.1945 - val_loss: 21.2872 - val_mean_absolute_error: 3.6491\n",
            "Epoch 789/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 8.8368 - mean_absolute_error: 2.1845 - val_loss: 31.9340 - val_mean_absolute_error: 4.4090\n",
            "Epoch 790/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 13.4557 - mean_absolute_error: 2.4988 - val_loss: 17.2816 - val_mean_absolute_error: 3.2782\n",
            "Epoch 791/1000\n",
            "363/363 [==============================] - 0s 55us/step - loss: 7.4013 - mean_absolute_error: 2.0296 - val_loss: 16.4474 - val_mean_absolute_error: 3.1804\n",
            "Epoch 792/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 8.3728 - mean_absolute_error: 2.1139 - val_loss: 24.1664 - val_mean_absolute_error: 3.9340\n",
            "Epoch 793/1000\n",
            "363/363 [==============================] - 0s 59us/step - loss: 10.7514 - mean_absolute_error: 2.3203 - val_loss: 22.8158 - val_mean_absolute_error: 3.7051\n",
            "Epoch 794/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 10.9298 - mean_absolute_error: 2.3961 - val_loss: 18.5600 - val_mean_absolute_error: 3.3661\n",
            "Epoch 795/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 8.2225 - mean_absolute_error: 2.0839 - val_loss: 16.4843 - val_mean_absolute_error: 3.1756\n",
            "Epoch 796/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 11.4604 - mean_absolute_error: 2.4153 - val_loss: 16.2493 - val_mean_absolute_error: 3.1334\n",
            "Epoch 797/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 7.7144 - mean_absolute_error: 2.0611 - val_loss: 18.2634 - val_mean_absolute_error: 3.3665\n",
            "Epoch 798/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 9.9082 - mean_absolute_error: 2.1097 - val_loss: 29.2865 - val_mean_absolute_error: 4.2760\n",
            "Epoch 799/1000\n",
            "363/363 [==============================] - 0s 58us/step - loss: 11.8447 - mean_absolute_error: 2.4215 - val_loss: 19.0006 - val_mean_absolute_error: 3.4007\n",
            "Epoch 800/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 9.7528 - mean_absolute_error: 2.2556 - val_loss: 19.0758 - val_mean_absolute_error: 3.4083\n",
            "Epoch 801/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 12.0064 - mean_absolute_error: 2.3693 - val_loss: 18.8706 - val_mean_absolute_error: 3.4826\n",
            "Epoch 802/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 7.9928 - mean_absolute_error: 2.0443 - val_loss: 42.5417 - val_mean_absolute_error: 5.4710\n",
            "Epoch 803/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 13.5767 - mean_absolute_error: 2.4715 - val_loss: 18.2950 - val_mean_absolute_error: 3.4539\n",
            "Epoch 804/1000\n",
            "363/363 [==============================] - 0s 57us/step - loss: 8.4177 - mean_absolute_error: 2.1489 - val_loss: 25.0077 - val_mean_absolute_error: 3.9043\n",
            "Epoch 805/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 10.1543 - mean_absolute_error: 2.2184 - val_loss: 15.7241 - val_mean_absolute_error: 3.1526\n",
            "Epoch 806/1000\n",
            "363/363 [==============================] - 0s 55us/step - loss: 8.2558 - mean_absolute_error: 2.1205 - val_loss: 26.3555 - val_mean_absolute_error: 4.0472\n",
            "Epoch 807/1000\n",
            "363/363 [==============================] - 0s 46us/step - loss: 12.2955 - mean_absolute_error: 2.4595 - val_loss: 24.7873 - val_mean_absolute_error: 3.9952\n",
            "Epoch 808/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 9.2594 - mean_absolute_error: 2.1965 - val_loss: 20.1901 - val_mean_absolute_error: 3.4337\n",
            "Epoch 809/1000\n",
            "363/363 [==============================] - 0s 55us/step - loss: 11.4623 - mean_absolute_error: 2.3073 - val_loss: 17.0705 - val_mean_absolute_error: 3.2638\n",
            "Epoch 810/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 12.1013 - mean_absolute_error: 2.4420 - val_loss: 19.8902 - val_mean_absolute_error: 3.6467\n",
            "Epoch 811/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 10.4137 - mean_absolute_error: 2.2661 - val_loss: 16.7784 - val_mean_absolute_error: 3.2636\n",
            "Epoch 812/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 7.4943 - mean_absolute_error: 2.0261 - val_loss: 24.9203 - val_mean_absolute_error: 3.9270\n",
            "Epoch 813/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 13.5165 - mean_absolute_error: 2.4898 - val_loss: 19.6776 - val_mean_absolute_error: 3.5008\n",
            "Epoch 814/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 8.3752 - mean_absolute_error: 2.1578 - val_loss: 17.5591 - val_mean_absolute_error: 3.3839\n",
            "Epoch 815/1000\n",
            "363/363 [==============================] - 0s 55us/step - loss: 9.3105 - mean_absolute_error: 2.2130 - val_loss: 19.9810 - val_mean_absolute_error: 3.5746\n",
            "Epoch 816/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 11.1015 - mean_absolute_error: 2.4081 - val_loss: 20.1849 - val_mean_absolute_error: 3.5976\n",
            "Epoch 817/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 9.4660 - mean_absolute_error: 2.2039 - val_loss: 17.9197 - val_mean_absolute_error: 3.2673\n",
            "Epoch 818/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 9.0431 - mean_absolute_error: 2.1830 - val_loss: 20.8380 - val_mean_absolute_error: 3.6059\n",
            "Epoch 819/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 8.6059 - mean_absolute_error: 2.1758 - val_loss: 26.8020 - val_mean_absolute_error: 4.2402\n",
            "Epoch 820/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 12.3483 - mean_absolute_error: 2.4153 - val_loss: 17.7232 - val_mean_absolute_error: 3.4330\n",
            "Epoch 821/1000\n",
            "363/363 [==============================] - 0s 56us/step - loss: 9.1576 - mean_absolute_error: 2.1567 - val_loss: 20.6331 - val_mean_absolute_error: 3.5986\n",
            "Epoch 822/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 9.4401 - mean_absolute_error: 2.2089 - val_loss: 18.4318 - val_mean_absolute_error: 3.4224\n",
            "Epoch 823/1000\n",
            "363/363 [==============================] - 0s 55us/step - loss: 11.1155 - mean_absolute_error: 2.3713 - val_loss: 20.5200 - val_mean_absolute_error: 3.5886\n",
            "Epoch 824/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 8.6912 - mean_absolute_error: 2.0959 - val_loss: 19.0592 - val_mean_absolute_error: 3.4832\n",
            "Epoch 825/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 9.4765 - mean_absolute_error: 2.1697 - val_loss: 19.5944 - val_mean_absolute_error: 3.4834\n",
            "Epoch 826/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 9.7826 - mean_absolute_error: 2.2524 - val_loss: 16.1186 - val_mean_absolute_error: 3.1947\n",
            "Epoch 827/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 9.1848 - mean_absolute_error: 2.2469 - val_loss: 29.8958 - val_mean_absolute_error: 4.3623\n",
            "Epoch 828/1000\n",
            "363/363 [==============================] - 0s 55us/step - loss: 11.2929 - mean_absolute_error: 2.2565 - val_loss: 27.0129 - val_mean_absolute_error: 3.9742\n",
            "Epoch 829/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 11.1680 - mean_absolute_error: 2.3544 - val_loss: 17.2515 - val_mean_absolute_error: 3.2761\n",
            "Epoch 830/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 9.0117 - mean_absolute_error: 2.1393 - val_loss: 18.4741 - val_mean_absolute_error: 3.4488\n",
            "Epoch 831/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 7.9646 - mean_absolute_error: 2.1186 - val_loss: 15.9837 - val_mean_absolute_error: 3.1510\n",
            "Epoch 832/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 11.3583 - mean_absolute_error: 2.4314 - val_loss: 20.4280 - val_mean_absolute_error: 3.6849\n",
            "Epoch 833/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 10.3251 - mean_absolute_error: 2.2489 - val_loss: 20.1046 - val_mean_absolute_error: 3.6568\n",
            "Epoch 834/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 8.8696 - mean_absolute_error: 2.1731 - val_loss: 18.3814 - val_mean_absolute_error: 3.3722\n",
            "Epoch 835/1000\n",
            "363/363 [==============================] - 0s 56us/step - loss: 11.6502 - mean_absolute_error: 2.3798 - val_loss: 16.6366 - val_mean_absolute_error: 3.1602\n",
            "Epoch 836/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 8.4596 - mean_absolute_error: 2.1063 - val_loss: 17.9872 - val_mean_absolute_error: 3.2706\n",
            "Epoch 837/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 8.1112 - mean_absolute_error: 2.0988 - val_loss: 19.8796 - val_mean_absolute_error: 3.3453\n",
            "Epoch 838/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 10.0250 - mean_absolute_error: 2.3871 - val_loss: 20.1602 - val_mean_absolute_error: 3.5137\n",
            "Epoch 839/1000\n",
            "363/363 [==============================] - 0s 61us/step - loss: 10.8522 - mean_absolute_error: 2.3121 - val_loss: 18.5697 - val_mean_absolute_error: 3.2756\n",
            "Epoch 840/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 9.5734 - mean_absolute_error: 2.1911 - val_loss: 18.9441 - val_mean_absolute_error: 3.2995\n",
            "Epoch 841/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 12.8935 - mean_absolute_error: 2.5333 - val_loss: 16.6411 - val_mean_absolute_error: 3.1170\n",
            "Epoch 842/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 8.5215 - mean_absolute_error: 2.1229 - val_loss: 20.0718 - val_mean_absolute_error: 3.5316\n",
            "Epoch 843/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 6.8618 - mean_absolute_error: 1.9632 - val_loss: 16.9994 - val_mean_absolute_error: 3.1480\n",
            "Epoch 844/1000\n",
            "363/363 [==============================] - 0s 57us/step - loss: 12.9649 - mean_absolute_error: 2.4899 - val_loss: 16.8312 - val_mean_absolute_error: 3.2805\n",
            "Epoch 845/1000\n",
            "363/363 [==============================] - 0s 57us/step - loss: 11.0136 - mean_absolute_error: 2.3524 - val_loss: 21.5155 - val_mean_absolute_error: 3.6211\n",
            "Epoch 846/1000\n",
            "363/363 [==============================] - 0s 59us/step - loss: 8.2622 - mean_absolute_error: 2.1112 - val_loss: 28.3388 - val_mean_absolute_error: 4.1614\n",
            "Epoch 847/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 11.5793 - mean_absolute_error: 2.3572 - val_loss: 16.4317 - val_mean_absolute_error: 3.1165\n",
            "Epoch 848/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 7.8781 - mean_absolute_error: 2.0307 - val_loss: 23.7042 - val_mean_absolute_error: 3.8236\n",
            "Epoch 849/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 11.4651 - mean_absolute_error: 2.4126 - val_loss: 18.3365 - val_mean_absolute_error: 3.2881\n",
            "Epoch 850/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 7.1363 - mean_absolute_error: 1.9941 - val_loss: 20.9944 - val_mean_absolute_error: 3.6845\n",
            "Epoch 851/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 12.0108 - mean_absolute_error: 2.3804 - val_loss: 20.4929 - val_mean_absolute_error: 3.5544\n",
            "Epoch 852/1000\n",
            "363/363 [==============================] - 0s 61us/step - loss: 8.2450 - mean_absolute_error: 2.0961 - val_loss: 17.1157 - val_mean_absolute_error: 3.2602\n",
            "Epoch 853/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 9.2343 - mean_absolute_error: 2.1887 - val_loss: 22.7480 - val_mean_absolute_error: 3.8491\n",
            "Epoch 854/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 9.1969 - mean_absolute_error: 2.2707 - val_loss: 21.5886 - val_mean_absolute_error: 3.6058\n",
            "Epoch 855/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 11.7925 - mean_absolute_error: 2.4482 - val_loss: 16.0366 - val_mean_absolute_error: 3.1804\n",
            "Epoch 856/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 7.4632 - mean_absolute_error: 2.0881 - val_loss: 20.4235 - val_mean_absolute_error: 3.6135\n",
            "Epoch 857/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 12.3738 - mean_absolute_error: 2.4447 - val_loss: 16.8929 - val_mean_absolute_error: 3.2104\n",
            "Epoch 858/1000\n",
            "363/363 [==============================] - 0s 57us/step - loss: 8.6515 - mean_absolute_error: 2.1673 - val_loss: 16.6537 - val_mean_absolute_error: 3.1994\n",
            "Epoch 859/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 9.7450 - mean_absolute_error: 2.2603 - val_loss: 18.1874 - val_mean_absolute_error: 3.3536\n",
            "Epoch 860/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 7.9964 - mean_absolute_error: 2.1531 - val_loss: 16.4927 - val_mean_absolute_error: 3.2625\n",
            "Epoch 861/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 10.1075 - mean_absolute_error: 2.2977 - val_loss: 18.1833 - val_mean_absolute_error: 3.3574\n",
            "Epoch 862/1000\n",
            "363/363 [==============================] - 0s 64us/step - loss: 9.6073 - mean_absolute_error: 2.2529 - val_loss: 18.3752 - val_mean_absolute_error: 3.3659\n",
            "Epoch 863/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 9.7009 - mean_absolute_error: 2.1806 - val_loss: 21.1104 - val_mean_absolute_error: 3.4616\n",
            "Epoch 864/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 10.4902 - mean_absolute_error: 2.2793 - val_loss: 15.2826 - val_mean_absolute_error: 3.1345\n",
            "Epoch 865/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 11.1642 - mean_absolute_error: 2.3425 - val_loss: 17.9310 - val_mean_absolute_error: 3.3963\n",
            "Epoch 866/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 11.1276 - mean_absolute_error: 2.2368 - val_loss: 18.6267 - val_mean_absolute_error: 3.3447\n",
            "Epoch 867/1000\n",
            "363/363 [==============================] - 0s 59us/step - loss: 7.9535 - mean_absolute_error: 2.0103 - val_loss: 18.3882 - val_mean_absolute_error: 3.4825\n",
            "Epoch 868/1000\n",
            "363/363 [==============================] - 0s 61us/step - loss: 10.0709 - mean_absolute_error: 2.2694 - val_loss: 20.9667 - val_mean_absolute_error: 3.4949\n",
            "Epoch 869/1000\n",
            "363/363 [==============================] - 0s 69us/step - loss: 8.3480 - mean_absolute_error: 2.0984 - val_loss: 19.2181 - val_mean_absolute_error: 3.4081\n",
            "Epoch 870/1000\n",
            "363/363 [==============================] - 0s 66us/step - loss: 10.3412 - mean_absolute_error: 2.3898 - val_loss: 19.4405 - val_mean_absolute_error: 3.5112\n",
            "Epoch 871/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 7.5962 - mean_absolute_error: 2.0263 - val_loss: 20.2738 - val_mean_absolute_error: 3.7190\n",
            "Epoch 872/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 10.4244 - mean_absolute_error: 2.3136 - val_loss: 20.6577 - val_mean_absolute_error: 3.4892\n",
            "Epoch 873/1000\n",
            "363/363 [==============================] - 0s 47us/step - loss: 9.0794 - mean_absolute_error: 2.1755 - val_loss: 19.5172 - val_mean_absolute_error: 3.5161\n",
            "Epoch 874/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 8.5310 - mean_absolute_error: 2.0472 - val_loss: 17.8737 - val_mean_absolute_error: 3.3052\n",
            "Epoch 875/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 7.9900 - mean_absolute_error: 2.1228 - val_loss: 27.1003 - val_mean_absolute_error: 4.0865\n",
            "Epoch 876/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 11.7503 - mean_absolute_error: 2.2986 - val_loss: 18.2212 - val_mean_absolute_error: 3.3307\n",
            "Epoch 877/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 10.3751 - mean_absolute_error: 2.2801 - val_loss: 17.4164 - val_mean_absolute_error: 3.2506\n",
            "Epoch 878/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 11.7382 - mean_absolute_error: 2.3440 - val_loss: 16.8396 - val_mean_absolute_error: 3.1890\n",
            "Epoch 879/1000\n",
            "363/363 [==============================] - 0s 60us/step - loss: 7.6326 - mean_absolute_error: 2.0321 - val_loss: 16.9490 - val_mean_absolute_error: 3.2110\n",
            "Epoch 880/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 9.8811 - mean_absolute_error: 2.3169 - val_loss: 30.4631 - val_mean_absolute_error: 4.4986\n",
            "Epoch 881/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 10.3510 - mean_absolute_error: 2.2314 - val_loss: 21.2427 - val_mean_absolute_error: 3.4611\n",
            "Epoch 882/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 9.5840 - mean_absolute_error: 2.2164 - val_loss: 17.7704 - val_mean_absolute_error: 3.2836\n",
            "Epoch 883/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 6.7279 - mean_absolute_error: 1.9324 - val_loss: 20.3200 - val_mean_absolute_error: 3.5719\n",
            "Epoch 884/1000\n",
            "363/363 [==============================] - 0s 56us/step - loss: 10.6541 - mean_absolute_error: 2.3130 - val_loss: 22.2969 - val_mean_absolute_error: 3.5272\n",
            "Epoch 885/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 11.0036 - mean_absolute_error: 2.3792 - val_loss: 16.4250 - val_mean_absolute_error: 3.1944\n",
            "Epoch 886/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 8.3593 - mean_absolute_error: 2.1025 - val_loss: 16.4177 - val_mean_absolute_error: 3.1822\n",
            "Epoch 887/1000\n",
            "363/363 [==============================] - 0s 60us/step - loss: 10.4027 - mean_absolute_error: 2.3779 - val_loss: 16.7949 - val_mean_absolute_error: 3.2483\n",
            "Epoch 888/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 10.0488 - mean_absolute_error: 2.2370 - val_loss: 19.8758 - val_mean_absolute_error: 3.6625\n",
            "Epoch 889/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 9.3643 - mean_absolute_error: 2.1563 - val_loss: 21.0771 - val_mean_absolute_error: 3.7537\n",
            "Epoch 890/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 8.6249 - mean_absolute_error: 2.0826 - val_loss: 19.3389 - val_mean_absolute_error: 3.5178\n",
            "Epoch 891/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 11.1858 - mean_absolute_error: 2.3309 - val_loss: 16.7171 - val_mean_absolute_error: 3.2019\n",
            "Epoch 892/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 8.1523 - mean_absolute_error: 2.0774 - val_loss: 19.2548 - val_mean_absolute_error: 3.4091\n",
            "Epoch 893/1000\n",
            "363/363 [==============================] - 0s 71us/step - loss: 10.3674 - mean_absolute_error: 2.3012 - val_loss: 27.4859 - val_mean_absolute_error: 4.0909\n",
            "Epoch 894/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 8.4307 - mean_absolute_error: 2.1518 - val_loss: 16.8563 - val_mean_absolute_error: 3.1330\n",
            "Epoch 895/1000\n",
            "363/363 [==============================] - 0s 59us/step - loss: 9.6119 - mean_absolute_error: 2.2819 - val_loss: 18.9218 - val_mean_absolute_error: 3.3705\n",
            "Epoch 896/1000\n",
            "363/363 [==============================] - 0s 58us/step - loss: 9.3231 - mean_absolute_error: 2.2597 - val_loss: 25.3587 - val_mean_absolute_error: 3.9667\n",
            "Epoch 897/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 9.4313 - mean_absolute_error: 2.2275 - val_loss: 26.4625 - val_mean_absolute_error: 3.9197\n",
            "Epoch 898/1000\n",
            "363/363 [==============================] - 0s 69us/step - loss: 8.8262 - mean_absolute_error: 2.1197 - val_loss: 17.8797 - val_mean_absolute_error: 3.2333\n",
            "Epoch 899/1000\n",
            "363/363 [==============================] - 0s 62us/step - loss: 11.1221 - mean_absolute_error: 2.3621 - val_loss: 18.3024 - val_mean_absolute_error: 3.3308\n",
            "Epoch 900/1000\n",
            "363/363 [==============================] - 0s 56us/step - loss: 7.5197 - mean_absolute_error: 2.0146 - val_loss: 15.6650 - val_mean_absolute_error: 3.1321\n",
            "Epoch 901/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 9.8188 - mean_absolute_error: 2.2367 - val_loss: 17.1820 - val_mean_absolute_error: 3.2203\n",
            "Epoch 902/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 7.2436 - mean_absolute_error: 1.9542 - val_loss: 33.5305 - val_mean_absolute_error: 4.9005\n",
            "Epoch 903/1000\n",
            "363/363 [==============================] - 0s 61us/step - loss: 11.4729 - mean_absolute_error: 2.3472 - val_loss: 16.8666 - val_mean_absolute_error: 3.2889\n",
            "Epoch 904/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 9.3028 - mean_absolute_error: 2.1562 - val_loss: 18.6065 - val_mean_absolute_error: 3.4178\n",
            "Epoch 905/1000\n",
            "363/363 [==============================] - 0s 62us/step - loss: 7.7923 - mean_absolute_error: 2.0521 - val_loss: 16.6644 - val_mean_absolute_error: 3.3024\n",
            "Epoch 906/1000\n",
            "363/363 [==============================] - 0s 55us/step - loss: 7.0456 - mean_absolute_error: 1.9830 - val_loss: 17.5353 - val_mean_absolute_error: 3.3462\n",
            "Epoch 907/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 8.1730 - mean_absolute_error: 2.0904 - val_loss: 22.0774 - val_mean_absolute_error: 3.6286\n",
            "Epoch 908/1000\n",
            "363/363 [==============================] - 0s 60us/step - loss: 9.7840 - mean_absolute_error: 2.2727 - val_loss: 17.1594 - val_mean_absolute_error: 3.2025\n",
            "Epoch 909/1000\n",
            "363/363 [==============================] - 0s 70us/step - loss: 10.3490 - mean_absolute_error: 2.2338 - val_loss: 21.6563 - val_mean_absolute_error: 3.7933\n",
            "Epoch 910/1000\n",
            "363/363 [==============================] - 0s 57us/step - loss: 7.9876 - mean_absolute_error: 2.0585 - val_loss: 22.4027 - val_mean_absolute_error: 3.6593\n",
            "Epoch 911/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 11.1489 - mean_absolute_error: 2.3521 - val_loss: 16.6317 - val_mean_absolute_error: 3.1595\n",
            "Epoch 912/1000\n",
            "363/363 [==============================] - 0s 56us/step - loss: 8.8422 - mean_absolute_error: 2.1611 - val_loss: 16.1391 - val_mean_absolute_error: 3.1467\n",
            "Epoch 913/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 11.5838 - mean_absolute_error: 2.4361 - val_loss: 19.1600 - val_mean_absolute_error: 3.4746\n",
            "Epoch 914/1000\n",
            "363/363 [==============================] - 0s 57us/step - loss: 7.3580 - mean_absolute_error: 1.9829 - val_loss: 16.4789 - val_mean_absolute_error: 3.1708\n",
            "Epoch 915/1000\n",
            "363/363 [==============================] - 0s 55us/step - loss: 9.9665 - mean_absolute_error: 2.2047 - val_loss: 19.3639 - val_mean_absolute_error: 3.4643\n",
            "Epoch 916/1000\n",
            "363/363 [==============================] - 0s 62us/step - loss: 10.2454 - mean_absolute_error: 2.2760 - val_loss: 18.5041 - val_mean_absolute_error: 3.4489\n",
            "Epoch 917/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 7.7041 - mean_absolute_error: 2.0568 - val_loss: 22.9984 - val_mean_absolute_error: 3.7818\n",
            "Epoch 918/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 10.1719 - mean_absolute_error: 2.3145 - val_loss: 19.7904 - val_mean_absolute_error: 3.5967\n",
            "Epoch 919/1000\n",
            "363/363 [==============================] - 0s 56us/step - loss: 7.7612 - mean_absolute_error: 2.0937 - val_loss: 30.6235 - val_mean_absolute_error: 4.3102\n",
            "Epoch 920/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 9.4906 - mean_absolute_error: 2.2222 - val_loss: 16.1637 - val_mean_absolute_error: 3.1342\n",
            "Epoch 921/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 11.8741 - mean_absolute_error: 2.2996 - val_loss: 16.6882 - val_mean_absolute_error: 3.2083\n",
            "Epoch 922/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 10.0850 - mean_absolute_error: 2.2881 - val_loss: 19.8670 - val_mean_absolute_error: 3.6422\n",
            "Epoch 923/1000\n",
            "363/363 [==============================] - 0s 57us/step - loss: 10.9217 - mean_absolute_error: 2.3637 - val_loss: 21.0040 - val_mean_absolute_error: 3.6279\n",
            "Epoch 924/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 9.8089 - mean_absolute_error: 2.2765 - val_loss: 16.0408 - val_mean_absolute_error: 3.1650\n",
            "Epoch 925/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 8.3044 - mean_absolute_error: 2.1535 - val_loss: 17.8645 - val_mean_absolute_error: 3.2985\n",
            "Epoch 926/1000\n",
            "363/363 [==============================] - 0s 55us/step - loss: 11.5622 - mean_absolute_error: 2.3462 - val_loss: 25.5647 - val_mean_absolute_error: 3.9650\n",
            "Epoch 927/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 9.0190 - mean_absolute_error: 2.1125 - val_loss: 16.2425 - val_mean_absolute_error: 3.1863\n",
            "Epoch 928/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 7.6805 - mean_absolute_error: 2.0128 - val_loss: 16.9555 - val_mean_absolute_error: 3.2536\n",
            "Epoch 929/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 11.4761 - mean_absolute_error: 2.3800 - val_loss: 19.8943 - val_mean_absolute_error: 3.5547\n",
            "Epoch 930/1000\n",
            "363/363 [==============================] - 0s 56us/step - loss: 6.6722 - mean_absolute_error: 1.8985 - val_loss: 17.6610 - val_mean_absolute_error: 3.3673\n",
            "Epoch 931/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 9.1450 - mean_absolute_error: 2.1286 - val_loss: 15.8856 - val_mean_absolute_error: 3.1499\n",
            "Epoch 932/1000\n",
            "363/363 [==============================] - 0s 56us/step - loss: 7.9291 - mean_absolute_error: 2.1437 - val_loss: 25.6980 - val_mean_absolute_error: 3.8978\n",
            "Epoch 933/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 9.6770 - mean_absolute_error: 2.1664 - val_loss: 24.0574 - val_mean_absolute_error: 3.7059\n",
            "Epoch 934/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 9.7980 - mean_absolute_error: 2.2163 - val_loss: 18.3823 - val_mean_absolute_error: 3.5327\n",
            "Epoch 935/1000\n",
            "363/363 [==============================] - 0s 55us/step - loss: 7.2469 - mean_absolute_error: 1.9142 - val_loss: 16.8074 - val_mean_absolute_error: 3.3431\n",
            "Epoch 936/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 12.7511 - mean_absolute_error: 2.4650 - val_loss: 15.9257 - val_mean_absolute_error: 3.1064\n",
            "Epoch 937/1000\n",
            "363/363 [==============================] - 0s 56us/step - loss: 8.2143 - mean_absolute_error: 2.0577 - val_loss: 28.2574 - val_mean_absolute_error: 4.1120\n",
            "Epoch 938/1000\n",
            "363/363 [==============================] - 0s 57us/step - loss: 8.6722 - mean_absolute_error: 2.1121 - val_loss: 42.4675 - val_mean_absolute_error: 5.5504\n",
            "Epoch 939/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 12.3882 - mean_absolute_error: 2.3064 - val_loss: 16.5026 - val_mean_absolute_error: 3.2703\n",
            "Epoch 940/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 6.4741 - mean_absolute_error: 1.8976 - val_loss: 22.4769 - val_mean_absolute_error: 3.8207\n",
            "Epoch 941/1000\n",
            "363/363 [==============================] - 0s 55us/step - loss: 8.7531 - mean_absolute_error: 2.1481 - val_loss: 18.5106 - val_mean_absolute_error: 3.3103\n",
            "Epoch 942/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 7.8745 - mean_absolute_error: 2.1158 - val_loss: 17.0657 - val_mean_absolute_error: 3.2815\n",
            "Epoch 943/1000\n",
            "363/363 [==============================] - 0s 56us/step - loss: 9.7280 - mean_absolute_error: 2.2347 - val_loss: 22.8815 - val_mean_absolute_error: 3.5681\n",
            "Epoch 944/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 11.2170 - mean_absolute_error: 2.3705 - val_loss: 20.0201 - val_mean_absolute_error: 3.5778\n",
            "Epoch 945/1000\n",
            "363/363 [==============================] - 0s 57us/step - loss: 9.8776 - mean_absolute_error: 2.2610 - val_loss: 18.8638 - val_mean_absolute_error: 3.3508\n",
            "Epoch 946/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 7.1078 - mean_absolute_error: 1.9764 - val_loss: 23.2306 - val_mean_absolute_error: 3.6513\n",
            "Epoch 947/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 10.1931 - mean_absolute_error: 2.3155 - val_loss: 19.6788 - val_mean_absolute_error: 3.4965\n",
            "Epoch 948/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 7.0597 - mean_absolute_error: 1.9716 - val_loss: 17.1251 - val_mean_absolute_error: 3.1904\n",
            "Epoch 949/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 7.6061 - mean_absolute_error: 2.0473 - val_loss: 29.1214 - val_mean_absolute_error: 4.2661\n",
            "Epoch 950/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 8.8459 - mean_absolute_error: 2.1739 - val_loss: 27.1266 - val_mean_absolute_error: 4.0702\n",
            "Epoch 951/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 9.8255 - mean_absolute_error: 2.1899 - val_loss: 23.6884 - val_mean_absolute_error: 3.7702\n",
            "Epoch 952/1000\n",
            "363/363 [==============================] - 0s 58us/step - loss: 8.4476 - mean_absolute_error: 2.1305 - val_loss: 17.5366 - val_mean_absolute_error: 3.3207\n",
            "Epoch 953/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 8.4692 - mean_absolute_error: 2.0700 - val_loss: 30.6174 - val_mean_absolute_error: 4.5339\n",
            "Epoch 954/1000\n",
            "363/363 [==============================] - 0s 55us/step - loss: 11.2532 - mean_absolute_error: 2.2704 - val_loss: 18.9276 - val_mean_absolute_error: 3.4887\n",
            "Epoch 955/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 7.2839 - mean_absolute_error: 2.0221 - val_loss: 24.9626 - val_mean_absolute_error: 3.9177\n",
            "Epoch 956/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 9.1847 - mean_absolute_error: 2.1760 - val_loss: 17.9558 - val_mean_absolute_error: 3.4061\n",
            "Epoch 957/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 7.8010 - mean_absolute_error: 1.9999 - val_loss: 16.0646 - val_mean_absolute_error: 3.1205\n",
            "Epoch 958/1000\n",
            "363/363 [==============================] - 0s 56us/step - loss: 9.3402 - mean_absolute_error: 2.1713 - val_loss: 18.2451 - val_mean_absolute_error: 3.3873\n",
            "Epoch 959/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 8.0563 - mean_absolute_error: 2.0914 - val_loss: 16.4977 - val_mean_absolute_error: 3.2489\n",
            "Epoch 960/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 8.3626 - mean_absolute_error: 2.0649 - val_loss: 17.3204 - val_mean_absolute_error: 3.3906\n",
            "Epoch 961/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 11.9067 - mean_absolute_error: 2.3916 - val_loss: 19.8443 - val_mean_absolute_error: 3.3349\n",
            "Epoch 962/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 8.2649 - mean_absolute_error: 2.0936 - val_loss: 20.0944 - val_mean_absolute_error: 3.6574\n",
            "Epoch 963/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 10.7873 - mean_absolute_error: 2.3251 - val_loss: 17.3471 - val_mean_absolute_error: 3.3713\n",
            "Epoch 964/1000\n",
            "363/363 [==============================] - 0s 56us/step - loss: 6.9157 - mean_absolute_error: 1.9740 - val_loss: 18.3923 - val_mean_absolute_error: 3.4228\n",
            "Epoch 965/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 8.6682 - mean_absolute_error: 2.0956 - val_loss: 18.0453 - val_mean_absolute_error: 3.4904\n",
            "Epoch 966/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 9.3174 - mean_absolute_error: 2.1507 - val_loss: 31.5302 - val_mean_absolute_error: 4.3918\n",
            "Epoch 967/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 10.4556 - mean_absolute_error: 2.3038 - val_loss: 16.8065 - val_mean_absolute_error: 3.2252\n",
            "Epoch 968/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 10.2347 - mean_absolute_error: 2.2116 - val_loss: 26.3184 - val_mean_absolute_error: 4.0185\n",
            "Epoch 969/1000\n",
            "363/363 [==============================] - 0s 59us/step - loss: 7.2548 - mean_absolute_error: 1.9799 - val_loss: 17.6275 - val_mean_absolute_error: 3.2848\n",
            "Epoch 970/1000\n",
            "363/363 [==============================] - 0s 62us/step - loss: 11.0620 - mean_absolute_error: 2.3679 - val_loss: 21.7507 - val_mean_absolute_error: 3.8081\n",
            "Epoch 971/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 9.4590 - mean_absolute_error: 2.1698 - val_loss: 21.2233 - val_mean_absolute_error: 3.4703\n",
            "Epoch 972/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 6.8808 - mean_absolute_error: 1.9417 - val_loss: 27.9480 - val_mean_absolute_error: 4.5198\n",
            "Epoch 973/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 11.9591 - mean_absolute_error: 2.3449 - val_loss: 16.2770 - val_mean_absolute_error: 3.2252\n",
            "Epoch 974/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 8.5710 - mean_absolute_error: 2.1437 - val_loss: 23.2585 - val_mean_absolute_error: 3.6039\n",
            "Epoch 975/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 8.3731 - mean_absolute_error: 2.1010 - val_loss: 16.3626 - val_mean_absolute_error: 3.1957\n",
            "Epoch 976/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 9.0569 - mean_absolute_error: 2.2198 - val_loss: 17.2929 - val_mean_absolute_error: 3.2129\n",
            "Epoch 977/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 8.6105 - mean_absolute_error: 2.1101 - val_loss: 17.0641 - val_mean_absolute_error: 3.3650\n",
            "Epoch 978/1000\n",
            "363/363 [==============================] - 0s 52us/step - loss: 7.1729 - mean_absolute_error: 1.9960 - val_loss: 16.0921 - val_mean_absolute_error: 3.1741\n",
            "Epoch 979/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 9.1514 - mean_absolute_error: 2.1492 - val_loss: 19.2932 - val_mean_absolute_error: 3.4338\n",
            "Epoch 980/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 11.1188 - mean_absolute_error: 2.3855 - val_loss: 18.6986 - val_mean_absolute_error: 3.3424\n",
            "Epoch 981/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 7.7891 - mean_absolute_error: 2.0630 - val_loss: 16.1416 - val_mean_absolute_error: 3.1671\n",
            "Epoch 982/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 10.4440 - mean_absolute_error: 2.2602 - val_loss: 17.1125 - val_mean_absolute_error: 3.2247\n",
            "Epoch 983/1000\n",
            "363/363 [==============================] - 0s 57us/step - loss: 7.9621 - mean_absolute_error: 2.0812 - val_loss: 16.5420 - val_mean_absolute_error: 3.1817\n",
            "Epoch 984/1000\n",
            "363/363 [==============================] - 0s 54us/step - loss: 9.2935 - mean_absolute_error: 2.2534 - val_loss: 22.2430 - val_mean_absolute_error: 3.5462\n",
            "Epoch 985/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 8.7349 - mean_absolute_error: 2.1338 - val_loss: 25.1935 - val_mean_absolute_error: 3.8682\n",
            "Epoch 986/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 8.2960 - mean_absolute_error: 2.0451 - val_loss: 18.1000 - val_mean_absolute_error: 3.3287\n",
            "Epoch 987/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 11.3536 - mean_absolute_error: 2.3838 - val_loss: 17.8203 - val_mean_absolute_error: 3.3396\n",
            "Epoch 988/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 7.1871 - mean_absolute_error: 1.9958 - val_loss: 17.7106 - val_mean_absolute_error: 3.3055\n",
            "Epoch 989/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 10.9020 - mean_absolute_error: 2.2286 - val_loss: 22.1078 - val_mean_absolute_error: 3.5918\n",
            "Epoch 990/1000\n",
            "363/363 [==============================] - 0s 58us/step - loss: 7.8886 - mean_absolute_error: 2.0434 - val_loss: 18.6783 - val_mean_absolute_error: 3.5055\n",
            "Epoch 991/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 9.1208 - mean_absolute_error: 2.1728 - val_loss: 17.8080 - val_mean_absolute_error: 3.3802\n",
            "Epoch 992/1000\n",
            "363/363 [==============================] - 0s 48us/step - loss: 8.1443 - mean_absolute_error: 2.0930 - val_loss: 24.6236 - val_mean_absolute_error: 3.8528\n",
            "Epoch 993/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 9.6074 - mean_absolute_error: 2.2723 - val_loss: 18.1606 - val_mean_absolute_error: 3.4071\n",
            "Epoch 994/1000\n",
            "363/363 [==============================] - 0s 61us/step - loss: 10.3558 - mean_absolute_error: 2.1530 - val_loss: 17.6354 - val_mean_absolute_error: 3.3881\n",
            "Epoch 995/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 8.0284 - mean_absolute_error: 2.0229 - val_loss: 18.7741 - val_mean_absolute_error: 3.4560\n",
            "Epoch 996/1000\n",
            "363/363 [==============================] - 0s 61us/step - loss: 9.4094 - mean_absolute_error: 2.1444 - val_loss: 18.0478 - val_mean_absolute_error: 3.3116\n",
            "Epoch 997/1000\n",
            "363/363 [==============================] - 0s 51us/step - loss: 7.1434 - mean_absolute_error: 1.9933 - val_loss: 19.4062 - val_mean_absolute_error: 3.5577\n",
            "Epoch 998/1000\n",
            "363/363 [==============================] - 0s 49us/step - loss: 9.7479 - mean_absolute_error: 2.1958 - val_loss: 27.1088 - val_mean_absolute_error: 4.2192\n",
            "Epoch 999/1000\n",
            "363/363 [==============================] - 0s 50us/step - loss: 8.9326 - mean_absolute_error: 2.1280 - val_loss: 24.2001 - val_mean_absolute_error: 3.7124\n",
            "Epoch 1000/1000\n",
            "363/363 [==============================] - 0s 53us/step - loss: 7.9529 - mean_absolute_error: 2.0848 - val_loss: 17.2361 - val_mean_absolute_error: 3.2350\n",
            "102/102 [==============================] - 0s 63us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tO8z4HXy7xPm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "3def0c59-0253-412b-f8b3-f6fd603b132d"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "plt.plot(history.epoch, np.array(history.history['loss']))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f3cc5d1b780>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iglJBIn67xT_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "665dd356-bafe-4b13-beb2-6aa8d9048646"
      },
      "source": [
        "# Predict some housing prices using data from the test set\n",
        "\n",
        "test_predictions = model.predict(X_test).flatten()\n",
        "\n",
        "plt.scatter(y_test, test_predictions)\n",
        "plt.xlabel('True values')\n",
        "plt.ylabel('Predictions')\n",
        "plt.axis('equal')\n",
        "plt.xlim(plt.xlim())\n",
        "plt.ylim(plt.ylim())\n",
        "_ = plt.plot([-100,100],[-100,100])"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncAoCEZGCUxCIiBTc/weIabg+aEXIJwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STPqN9767xX3",
        "colab_type": "text"
      },
      "source": [
        "The model seems to capture the general trend in the data. Let's plot a histogram that shows the distribution of our prediction errors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vZqbGuNBGCF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "6a017849-5027-4813-dc0d-e0af51e27952"
      },
      "source": [
        "error = test_predictions - y_test\n",
        "plt.hist(error, bins=50)\n",
        "plt.xlabel(\"Prediction Error\")\n",
        "_ = plt.ylabel('Count')"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n93/GIysv4BRF7QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6PrzNiUBmkx",
        "colab_type": "text"
      },
      "source": [
        "It seems the model is overfitting the most around -5 and +5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GH-Ajds4TK8",
        "colab_type": "text"
      },
      "source": [
        "# Cross validate the model\n",
        "There isn't very much data so repeated sub-sampling via cross validation over all observations (train+test) needs to happen. Here, we train the model on four random split and test it on the fifth."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zo0fUU1muNrS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "41fb6d55-63fe-49d9-f471-fc493b62074e"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from keras.datasets import boston_housing\n",
        "\n",
        "(X_train,y_train),(X_test,y_test) = boston_housing.load_data()\n",
        "\n",
        "X_train.shape, X_test.shape"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((404, 13), (102, 13))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4JPLUpSw6SY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dde8802b-8b8c-4263-cb89-1ef08044a9e8"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "X_train = np.concatenate((X_train,X_test), axis=0)\n",
        "y_train = np.concatenate((y_train,y_test), axis=0)\n",
        "\n",
        "X_train.shape, y_train.shape"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((506, 13), (506,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AR--T5iHw6Pk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def baseline_model():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(13, input_dim=13, kernel_initializer='normal', \n",
        "              activation='relu'))\n",
        "    model.add(Dense(1, kernel_initializer='normal'))\n",
        "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2Tdqq5ow6M7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "1d945561-c4af-4ec3-b676-7551b9f62ba8"
      },
      "source": [
        "# Initialize random number generator with a constant random seed\n",
        "# to ensure consistency in initializing model weights and the model\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "# Add scaler and Keras regressor with the model\n",
        "\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasRegressor(build_fn=baseline_model,   \n",
        "                    epochs=100, batch_size=5, verbose=0)))\n",
        "    \n",
        "# Add estimator list to a Sklearn pipeline\n",
        "\n",
        "pipeline = Pipeline(estimators)\n",
        " \n",
        "# Initialize instance of k-fold validation from sklearn api\n",
        "\n",
        "kfold = KFold(n_splits=5, random_state=42)\n",
        "\n",
        "# Pass pipeline instance, training data and labels, and k-fold crossvalidator instance to evaluate score\n",
        "\n",
        "results = cross_val_score(pipeline, X_train, y_train, cv=kfold)\n",
        "print(\"Average MSE of all 5 runs: %.2f, with standard dev: (%.2f)\" %   \n",
        "      (-1*(results.mean()), results.std()))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Average MSE of all 5 runs: 14.96, with standard dev: (2.56)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfcFnOONyuNm",
        "colab_type": "text"
      },
      "source": [
        "## Use the Keras Library to build an image recognition network using the Fashion-MNIST dataset (also comes with keras)\n",
        "\n",
        "- Load and preprocess the image data similar to how we preprocessed the MNIST data in class.\n",
        "- Make sure to one-hot encode your category labels\n",
        "- Make sure to have your final layer have as many nodes as the number of classes that you want to predict.\n",
        "- Try different hyperparameters. What is the highest accuracy that you are able to achieve.\n",
        "- Use the history object that is returned from model.fit to make graphs of the model's loss or train/validation accuracies by epoch. \n",
        "- Remember that neural networks fall prey to randomness so you may need to run your model multiple times (or use Cross Validation) in order to tell if a change to a hyperparameter is truly producing better results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSAuKYAjuMtZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout \n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szi6-IpuzaH1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zv_3xNMjzdLI",
        "colab_type": "text"
      },
      "source": [
        "## Stretch Goals:\n",
        "\n",
        "- Use Hyperparameter Tuning to make the accuracy of your models as high as possible. (error as low as possible)\n",
        "- Use Cross Validation techniques to get more consistent results with your model.\n",
        "- Use GridSearchCV to try different combinations of hyperparameters. \n",
        "- Start looking into other types of Keras layers for CNNs and RNNs maybe try and build a CNN model for fashion-MNIST to see how the results compare."
      ]
    }
  ]
}