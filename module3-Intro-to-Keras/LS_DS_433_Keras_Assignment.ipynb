{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LS_DS_433_Keras_Assignment.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/donw385/DS-Unit-4-Sprint-3-Neural-Networks/blob/master/module3-Intro-to-Keras/LS_DS_433_Keras_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBQsZEJmubLs",
        "colab_type": "text"
      },
      "source": [
        "## Use the Keras Library to build a Multi-Layer Perceptron Model on the Boston Housing dataset\n",
        "\n",
        "- The Boston Housing dataset comes with the Keras library so use Keras to import it into your notebook. \n",
        "- Normalize the data (all features should have roughly the same scale)\n",
        "- Import the type of model and layers that you will need from Keras.\n",
        "- Instantiate a model object and use `model.add()` to add layers to your model\n",
        "- Since this is a regression model you will have a single output node in the final layer.\n",
        "- Use activation functions that are appropriate for this task\n",
        "- Compile your model\n",
        "- Fit your model and report its accuracy in terms of Mean Squared Error\n",
        "- Use the history object that is returned from model.fit to make graphs of the model's loss or train/validation accuracies by epoch. \n",
        "- Run this same data through a linear regression model. Which achieves higher accuracy?\n",
        "- Do a little bit of feature engineering and see how that affects your neural network model. (you will need to change your model to accept more inputs)\n",
        "- After feature engineering, which model sees a greater accuracy boost due to the new features?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NLTAR87uYJ-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bb5bde0d-96fe-47dd-e8aa-66cfe9dcb87b"
      },
      "source": [
        "from keras.datasets import boston_housing, fashion_mnist\n",
        "\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import numpy\n",
        "# fix random seed for reproducibility\n",
        "numpy.random.seed(42)\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = boston_housing.load_data()\n",
        "\n",
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(404, 13) (404,) (102, 13) (102,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpTqm_9DtvE2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h19h-G_vs6qk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = keras.utils.normalize(X_train, axis=-1, order=2)\n",
        "X_test = keras.utils.normalize(X_test, axis=-1, order=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMnQQa_Prm90",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5512
        },
        "outputId": "d356dcf6-ae34-4a32-e8c2-31c322e00e30"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(5, input_dim=13, activation=\"relu\"))\n",
        "model.add(Dense(30, activation='relu'))\n",
        "model.add(Dense(29, activation='relu'))\n",
        "model.add(Dense(5, activation='relu'))\n",
        "model.add(Dense(1, activation='relu'))\n",
        "\n",
        "model.compile(loss='mean_squared_error', \n",
        "              optimizer='adam', \n",
        "              metrics=['mean_squared_error'])\n",
        "model.fit(X_train, y_train, epochs=150)\n",
        "model.summary()\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "404/404 [==============================] - 1s 2ms/step - loss: 580.6081 - mean_squared_error: 580.6081\n",
            "Epoch 2/150\n",
            "404/404 [==============================] - 0s 52us/step - loss: 573.8648 - mean_squared_error: 573.8648\n",
            "Epoch 3/150\n",
            "404/404 [==============================] - 0s 49us/step - loss: 564.3207 - mean_squared_error: 564.3207\n",
            "Epoch 4/150\n",
            "404/404 [==============================] - 0s 50us/step - loss: 549.8397 - mean_squared_error: 549.8397\n",
            "Epoch 5/150\n",
            "404/404 [==============================] - 0s 48us/step - loss: 527.9162 - mean_squared_error: 527.9162\n",
            "Epoch 6/150\n",
            "404/404 [==============================] - 0s 51us/step - loss: 495.6097 - mean_squared_error: 495.6097\n",
            "Epoch 7/150\n",
            "404/404 [==============================] - 0s 49us/step - loss: 451.2192 - mean_squared_error: 451.2192\n",
            "Epoch 8/150\n",
            "404/404 [==============================] - 0s 54us/step - loss: 391.3475 - mean_squared_error: 391.3475\n",
            "Epoch 9/150\n",
            "404/404 [==============================] - 0s 51us/step - loss: 318.3882 - mean_squared_error: 318.3882\n",
            "Epoch 10/150\n",
            "404/404 [==============================] - 0s 55us/step - loss: 240.3890 - mean_squared_error: 240.3890\n",
            "Epoch 11/150\n",
            "404/404 [==============================] - 0s 55us/step - loss: 169.4083 - mean_squared_error: 169.4083\n",
            "Epoch 12/150\n",
            "404/404 [==============================] - 0s 51us/step - loss: 122.0711 - mean_squared_error: 122.0711\n",
            "Epoch 13/150\n",
            "404/404 [==============================] - 0s 51us/step - loss: 106.2085 - mean_squared_error: 106.2085\n",
            "Epoch 14/150\n",
            "404/404 [==============================] - 0s 49us/step - loss: 104.0481 - mean_squared_error: 104.0481\n",
            "Epoch 15/150\n",
            "404/404 [==============================] - 0s 52us/step - loss: 103.4466 - mean_squared_error: 103.4466\n",
            "Epoch 16/150\n",
            "404/404 [==============================] - 0s 52us/step - loss: 102.1825 - mean_squared_error: 102.1825\n",
            "Epoch 17/150\n",
            "404/404 [==============================] - 0s 50us/step - loss: 101.2408 - mean_squared_error: 101.2408\n",
            "Epoch 18/150\n",
            "404/404 [==============================] - 0s 49us/step - loss: 100.4102 - mean_squared_error: 100.4102\n",
            "Epoch 19/150\n",
            "404/404 [==============================] - 0s 47us/step - loss: 99.5584 - mean_squared_error: 99.5584\n",
            "Epoch 20/150\n",
            "404/404 [==============================] - 0s 53us/step - loss: 98.6554 - mean_squared_error: 98.6554\n",
            "Epoch 21/150\n",
            "404/404 [==============================] - 0s 50us/step - loss: 97.8714 - mean_squared_error: 97.8714\n",
            "Epoch 22/150\n",
            "404/404 [==============================] - 0s 48us/step - loss: 97.1355 - mean_squared_error: 97.1355\n",
            "Epoch 23/150\n",
            "404/404 [==============================] - 0s 59us/step - loss: 96.3637 - mean_squared_error: 96.3637\n",
            "Epoch 24/150\n",
            "404/404 [==============================] - 0s 56us/step - loss: 95.4717 - mean_squared_error: 95.4717\n",
            "Epoch 25/150\n",
            "404/404 [==============================] - 0s 48us/step - loss: 94.9562 - mean_squared_error: 94.9562\n",
            "Epoch 26/150\n",
            "404/404 [==============================] - 0s 50us/step - loss: 94.1014 - mean_squared_error: 94.1014\n",
            "Epoch 27/150\n",
            "404/404 [==============================] - 0s 51us/step - loss: 93.3394 - mean_squared_error: 93.3394\n",
            "Epoch 28/150\n",
            "404/404 [==============================] - 0s 54us/step - loss: 92.7365 - mean_squared_error: 92.7365\n",
            "Epoch 29/150\n",
            "404/404 [==============================] - 0s 48us/step - loss: 92.0714 - mean_squared_error: 92.0714\n",
            "Epoch 30/150\n",
            "404/404 [==============================] - 0s 46us/step - loss: 91.4361 - mean_squared_error: 91.4361\n",
            "Epoch 31/150\n",
            "404/404 [==============================] - 0s 64us/step - loss: 90.7821 - mean_squared_error: 90.7821\n",
            "Epoch 32/150\n",
            "404/404 [==============================] - 0s 49us/step - loss: 90.1407 - mean_squared_error: 90.1407\n",
            "Epoch 33/150\n",
            "404/404 [==============================] - 0s 47us/step - loss: 89.5960 - mean_squared_error: 89.5960\n",
            "Epoch 34/150\n",
            "404/404 [==============================] - 0s 58us/step - loss: 88.8760 - mean_squared_error: 88.8760\n",
            "Epoch 35/150\n",
            "404/404 [==============================] - 0s 47us/step - loss: 88.6456 - mean_squared_error: 88.6456\n",
            "Epoch 36/150\n",
            "404/404 [==============================] - 0s 52us/step - loss: 87.6273 - mean_squared_error: 87.6273\n",
            "Epoch 37/150\n",
            "404/404 [==============================] - 0s 48us/step - loss: 87.4333 - mean_squared_error: 87.4333\n",
            "Epoch 38/150\n",
            "404/404 [==============================] - 0s 63us/step - loss: 86.5827 - mean_squared_error: 86.5827\n",
            "Epoch 39/150\n",
            "404/404 [==============================] - 0s 57us/step - loss: 85.9979 - mean_squared_error: 85.9979\n",
            "Epoch 40/150\n",
            "404/404 [==============================] - 0s 53us/step - loss: 85.4637 - mean_squared_error: 85.4637\n",
            "Epoch 41/150\n",
            "404/404 [==============================] - 0s 57us/step - loss: 84.9985 - mean_squared_error: 84.9985\n",
            "Epoch 42/150\n",
            "404/404 [==============================] - 0s 47us/step - loss: 84.4622 - mean_squared_error: 84.4622\n",
            "Epoch 43/150\n",
            "404/404 [==============================] - 0s 47us/step - loss: 83.8012 - mean_squared_error: 83.8012\n",
            "Epoch 44/150\n",
            "404/404 [==============================] - 0s 52us/step - loss: 83.3797 - mean_squared_error: 83.3797\n",
            "Epoch 45/150\n",
            "404/404 [==============================] - 0s 53us/step - loss: 83.0042 - mean_squared_error: 83.0042\n",
            "Epoch 46/150\n",
            "404/404 [==============================] - 0s 57us/step - loss: 82.2958 - mean_squared_error: 82.2958\n",
            "Epoch 47/150\n",
            "404/404 [==============================] - 0s 50us/step - loss: 81.7685 - mean_squared_error: 81.7685\n",
            "Epoch 48/150\n",
            "404/404 [==============================] - 0s 51us/step - loss: 81.2990 - mean_squared_error: 81.2990\n",
            "Epoch 49/150\n",
            "404/404 [==============================] - 0s 52us/step - loss: 80.8179 - mean_squared_error: 80.8179\n",
            "Epoch 50/150\n",
            "404/404 [==============================] - 0s 52us/step - loss: 80.3692 - mean_squared_error: 80.3692\n",
            "Epoch 51/150\n",
            "404/404 [==============================] - 0s 66us/step - loss: 79.8353 - mean_squared_error: 79.8353\n",
            "Epoch 52/150\n",
            "404/404 [==============================] - 0s 50us/step - loss: 79.4496 - mean_squared_error: 79.4496\n",
            "Epoch 53/150\n",
            "404/404 [==============================] - 0s 53us/step - loss: 78.8768 - mean_squared_error: 78.8768\n",
            "Epoch 54/150\n",
            "404/404 [==============================] - 0s 52us/step - loss: 78.4318 - mean_squared_error: 78.4318\n",
            "Epoch 55/150\n",
            "404/404 [==============================] - 0s 50us/step - loss: 77.9254 - mean_squared_error: 77.9254\n",
            "Epoch 56/150\n",
            "404/404 [==============================] - 0s 50us/step - loss: 77.5755 - mean_squared_error: 77.5755\n",
            "Epoch 57/150\n",
            "404/404 [==============================] - 0s 49us/step - loss: 77.0047 - mean_squared_error: 77.0047\n",
            "Epoch 58/150\n",
            "404/404 [==============================] - 0s 48us/step - loss: 76.6171 - mean_squared_error: 76.6171\n",
            "Epoch 59/150\n",
            "404/404 [==============================] - 0s 49us/step - loss: 76.3275 - mean_squared_error: 76.3275\n",
            "Epoch 60/150\n",
            "404/404 [==============================] - 0s 47us/step - loss: 75.8537 - mean_squared_error: 75.8537\n",
            "Epoch 61/150\n",
            "404/404 [==============================] - 0s 47us/step - loss: 75.3155 - mean_squared_error: 75.3155\n",
            "Epoch 62/150\n",
            "404/404 [==============================] - 0s 46us/step - loss: 75.0163 - mean_squared_error: 75.0163\n",
            "Epoch 63/150\n",
            "404/404 [==============================] - 0s 47us/step - loss: 74.6285 - mean_squared_error: 74.6285\n",
            "Epoch 64/150\n",
            "404/404 [==============================] - 0s 44us/step - loss: 73.9534 - mean_squared_error: 73.9534\n",
            "Epoch 65/150\n",
            "404/404 [==============================] - 0s 50us/step - loss: 73.6362 - mean_squared_error: 73.6362\n",
            "Epoch 66/150\n",
            "404/404 [==============================] - 0s 49us/step - loss: 73.0850 - mean_squared_error: 73.0850\n",
            "Epoch 67/150\n",
            "404/404 [==============================] - 0s 50us/step - loss: 72.9845 - mean_squared_error: 72.9845\n",
            "Epoch 68/150\n",
            "404/404 [==============================] - 0s 56us/step - loss: 72.2743 - mean_squared_error: 72.2743\n",
            "Epoch 69/150\n",
            "404/404 [==============================] - 0s 55us/step - loss: 71.8076 - mean_squared_error: 71.8076\n",
            "Epoch 70/150\n",
            "404/404 [==============================] - 0s 55us/step - loss: 71.4710 - mean_squared_error: 71.4710\n",
            "Epoch 71/150\n",
            "404/404 [==============================] - 0s 55us/step - loss: 70.9908 - mean_squared_error: 70.9908\n",
            "Epoch 72/150\n",
            "404/404 [==============================] - 0s 51us/step - loss: 70.6560 - mean_squared_error: 70.6560\n",
            "Epoch 73/150\n",
            "404/404 [==============================] - 0s 49us/step - loss: 70.2679 - mean_squared_error: 70.2679\n",
            "Epoch 74/150\n",
            "404/404 [==============================] - 0s 51us/step - loss: 69.9432 - mean_squared_error: 69.9432\n",
            "Epoch 75/150\n",
            "404/404 [==============================] - 0s 47us/step - loss: 69.5234 - mean_squared_error: 69.5234\n",
            "Epoch 76/150\n",
            "404/404 [==============================] - 0s 54us/step - loss: 68.9822 - mean_squared_error: 68.9822\n",
            "Epoch 77/150\n",
            "404/404 [==============================] - 0s 52us/step - loss: 68.6921 - mean_squared_error: 68.6921\n",
            "Epoch 78/150\n",
            "404/404 [==============================] - 0s 49us/step - loss: 68.2687 - mean_squared_error: 68.2687\n",
            "Epoch 79/150\n",
            "404/404 [==============================] - 0s 50us/step - loss: 67.8941 - mean_squared_error: 67.8941\n",
            "Epoch 80/150\n",
            "404/404 [==============================] - 0s 59us/step - loss: 67.4571 - mean_squared_error: 67.4571\n",
            "Epoch 81/150\n",
            "404/404 [==============================] - 0s 52us/step - loss: 67.1081 - mean_squared_error: 67.1081\n",
            "Epoch 82/150\n",
            "404/404 [==============================] - 0s 56us/step - loss: 66.7861 - mean_squared_error: 66.7861\n",
            "Epoch 83/150\n",
            "404/404 [==============================] - 0s 54us/step - loss: 66.3665 - mean_squared_error: 66.3665\n",
            "Epoch 84/150\n",
            "404/404 [==============================] - 0s 48us/step - loss: 66.0559 - mean_squared_error: 66.0559\n",
            "Epoch 85/150\n",
            "404/404 [==============================] - 0s 54us/step - loss: 65.6896 - mean_squared_error: 65.6896\n",
            "Epoch 86/150\n",
            "404/404 [==============================] - 0s 51us/step - loss: 65.3252 - mean_squared_error: 65.3252\n",
            "Epoch 87/150\n",
            "404/404 [==============================] - 0s 49us/step - loss: 64.9840 - mean_squared_error: 64.9840\n",
            "Epoch 88/150\n",
            "404/404 [==============================] - 0s 61us/step - loss: 64.5077 - mean_squared_error: 64.5077\n",
            "Epoch 89/150\n",
            "404/404 [==============================] - 0s 56us/step - loss: 64.4704 - mean_squared_error: 64.4704\n",
            "Epoch 90/150\n",
            "404/404 [==============================] - 0s 54us/step - loss: 63.6480 - mean_squared_error: 63.6480\n",
            "Epoch 91/150\n",
            "404/404 [==============================] - 0s 55us/step - loss: 63.3019 - mean_squared_error: 63.3019\n",
            "Epoch 92/150\n",
            "404/404 [==============================] - 0s 50us/step - loss: 62.9549 - mean_squared_error: 62.9549\n",
            "Epoch 93/150\n",
            "404/404 [==============================] - 0s 54us/step - loss: 62.5470 - mean_squared_error: 62.5470\n",
            "Epoch 94/150\n",
            "404/404 [==============================] - 0s 50us/step - loss: 62.2624 - mean_squared_error: 62.2624\n",
            "Epoch 95/150\n",
            "404/404 [==============================] - 0s 48us/step - loss: 61.8199 - mean_squared_error: 61.8199\n",
            "Epoch 96/150\n",
            "404/404 [==============================] - 0s 52us/step - loss: 61.5983 - mean_squared_error: 61.5983\n",
            "Epoch 97/150\n",
            "404/404 [==============================] - 0s 60us/step - loss: 61.1979 - mean_squared_error: 61.1979\n",
            "Epoch 98/150\n",
            "404/404 [==============================] - 0s 52us/step - loss: 60.9827 - mean_squared_error: 60.9827\n",
            "Epoch 99/150\n",
            "404/404 [==============================] - 0s 50us/step - loss: 60.6766 - mean_squared_error: 60.6766\n",
            "Epoch 100/150\n",
            "404/404 [==============================] - 0s 51us/step - loss: 60.4167 - mean_squared_error: 60.4167\n",
            "Epoch 101/150\n",
            "404/404 [==============================] - 0s 55us/step - loss: 60.0594 - mean_squared_error: 60.0594\n",
            "Epoch 102/150\n",
            "404/404 [==============================] - 0s 50us/step - loss: 59.7950 - mean_squared_error: 59.7950\n",
            "Epoch 103/150\n",
            "404/404 [==============================] - 0s 51us/step - loss: 59.6379 - mean_squared_error: 59.6379\n",
            "Epoch 104/150\n",
            "404/404 [==============================] - 0s 61us/step - loss: 59.3836 - mean_squared_error: 59.3836\n",
            "Epoch 105/150\n",
            "404/404 [==============================] - 0s 50us/step - loss: 59.0537 - mean_squared_error: 59.0537\n",
            "Epoch 106/150\n",
            "404/404 [==============================] - 0s 52us/step - loss: 58.8931 - mean_squared_error: 58.8931\n",
            "Epoch 107/150\n",
            "404/404 [==============================] - 0s 48us/step - loss: 58.7079 - mean_squared_error: 58.7079\n",
            "Epoch 108/150\n",
            "404/404 [==============================] - 0s 56us/step - loss: 58.4776 - mean_squared_error: 58.4776\n",
            "Epoch 109/150\n",
            "404/404 [==============================] - 0s 52us/step - loss: 58.3135 - mean_squared_error: 58.3135\n",
            "Epoch 110/150\n",
            "404/404 [==============================] - 0s 55us/step - loss: 58.1373 - mean_squared_error: 58.1373\n",
            "Epoch 111/150\n",
            "404/404 [==============================] - 0s 59us/step - loss: 58.1249 - mean_squared_error: 58.1249\n",
            "Epoch 112/150\n",
            "404/404 [==============================] - 0s 53us/step - loss: 57.8471 - mean_squared_error: 57.8471\n",
            "Epoch 113/150\n",
            "404/404 [==============================] - 0s 57us/step - loss: 57.6757 - mean_squared_error: 57.6757\n",
            "Epoch 114/150\n",
            "404/404 [==============================] - 0s 55us/step - loss: 57.5391 - mean_squared_error: 57.5391\n",
            "Epoch 115/150\n",
            "404/404 [==============================] - 0s 50us/step - loss: 57.3887 - mean_squared_error: 57.3887\n",
            "Epoch 116/150\n",
            "404/404 [==============================] - 0s 52us/step - loss: 57.3117 - mean_squared_error: 57.3117\n",
            "Epoch 117/150\n",
            "404/404 [==============================] - 0s 58us/step - loss: 57.1668 - mean_squared_error: 57.1668\n",
            "Epoch 118/150\n",
            "404/404 [==============================] - 0s 77us/step - loss: 57.1455 - mean_squared_error: 57.1455\n",
            "Epoch 119/150\n",
            "404/404 [==============================] - 0s 70us/step - loss: 57.1837 - mean_squared_error: 57.1837\n",
            "Epoch 120/150\n",
            "404/404 [==============================] - 0s 58us/step - loss: 56.9301 - mean_squared_error: 56.9301\n",
            "Epoch 121/150\n",
            "404/404 [==============================] - 0s 51us/step - loss: 56.8681 - mean_squared_error: 56.8681\n",
            "Epoch 122/150\n",
            "404/404 [==============================] - 0s 54us/step - loss: 56.6363 - mean_squared_error: 56.6363\n",
            "Epoch 123/150\n",
            "404/404 [==============================] - 0s 55us/step - loss: 56.5975 - mean_squared_error: 56.5975\n",
            "Epoch 124/150\n",
            "404/404 [==============================] - 0s 55us/step - loss: 56.4382 - mean_squared_error: 56.4382\n",
            "Epoch 125/150\n",
            "404/404 [==============================] - 0s 49us/step - loss: 56.8693 - mean_squared_error: 56.8693\n",
            "Epoch 126/150\n",
            "404/404 [==============================] - 0s 61us/step - loss: 56.2627 - mean_squared_error: 56.2627\n",
            "Epoch 127/150\n",
            "404/404 [==============================] - 0s 47us/step - loss: 56.2584 - mean_squared_error: 56.2584\n",
            "Epoch 128/150\n",
            "404/404 [==============================] - 0s 66us/step - loss: 56.2865 - mean_squared_error: 56.2865\n",
            "Epoch 129/150\n",
            "404/404 [==============================] - 0s 77us/step - loss: 56.1302 - mean_squared_error: 56.1302\n",
            "Epoch 130/150\n",
            "404/404 [==============================] - 0s 45us/step - loss: 56.0859 - mean_squared_error: 56.0859\n",
            "Epoch 131/150\n",
            "404/404 [==============================] - 0s 49us/step - loss: 55.9465 - mean_squared_error: 55.9465\n",
            "Epoch 132/150\n",
            "404/404 [==============================] - 0s 57us/step - loss: 55.8228 - mean_squared_error: 55.8228\n",
            "Epoch 133/150\n",
            "404/404 [==============================] - 0s 57us/step - loss: 55.7533 - mean_squared_error: 55.7533\n",
            "Epoch 134/150\n",
            "404/404 [==============================] - 0s 54us/step - loss: 55.7651 - mean_squared_error: 55.7651\n",
            "Epoch 135/150\n",
            "404/404 [==============================] - 0s 58us/step - loss: 55.8226 - mean_squared_error: 55.8226\n",
            "Epoch 136/150\n",
            "404/404 [==============================] - 0s 52us/step - loss: 55.4980 - mean_squared_error: 55.4980\n",
            "Epoch 137/150\n",
            "404/404 [==============================] - 0s 64us/step - loss: 55.4729 - mean_squared_error: 55.4729\n",
            "Epoch 138/150\n",
            "404/404 [==============================] - 0s 52us/step - loss: 55.3117 - mean_squared_error: 55.3117\n",
            "Epoch 139/150\n",
            "404/404 [==============================] - 0s 58us/step - loss: 55.3187 - mean_squared_error: 55.3187\n",
            "Epoch 140/150\n",
            "404/404 [==============================] - 0s 55us/step - loss: 55.2359 - mean_squared_error: 55.2359\n",
            "Epoch 141/150\n",
            "404/404 [==============================] - 0s 55us/step - loss: 55.1336 - mean_squared_error: 55.1336\n",
            "Epoch 142/150\n",
            "404/404 [==============================] - 0s 54us/step - loss: 55.0268 - mean_squared_error: 55.0268\n",
            "Epoch 143/150\n",
            "404/404 [==============================] - 0s 50us/step - loss: 54.9158 - mean_squared_error: 54.9158\n",
            "Epoch 144/150\n",
            "404/404 [==============================] - 0s 51us/step - loss: 54.9257 - mean_squared_error: 54.9257\n",
            "Epoch 145/150\n",
            "404/404 [==============================] - 0s 55us/step - loss: 54.8743 - mean_squared_error: 54.8743\n",
            "Epoch 146/150\n",
            "404/404 [==============================] - 0s 51us/step - loss: 54.7983 - mean_squared_error: 54.7983\n",
            "Epoch 147/150\n",
            "404/404 [==============================] - 0s 53us/step - loss: 54.6214 - mean_squared_error: 54.6214\n",
            "Epoch 148/150\n",
            "404/404 [==============================] - 0s 54us/step - loss: 54.5639 - mean_squared_error: 54.5639\n",
            "Epoch 149/150\n",
            "404/404 [==============================] - 0s 54us/step - loss: 54.6927 - mean_squared_error: 54.6927\n",
            "Epoch 150/150\n",
            "404/404 [==============================] - 0s 56us/step - loss: 54.5571 - mean_squared_error: 54.5571\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_26 (Dense)             (None, 5)                 70        \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 30)                180       \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 29)                899       \n",
            "_________________________________________________________________\n",
            "dense_29 (Dense)             (None, 5)                 150       \n",
            "_________________________________________________________________\n",
            "dense_30 (Dense)             (None, 1)                 6         \n",
            "=================================================================\n",
            "Total params: 1,305\n",
            "Trainable params: 1,305\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfcFnOONyuNm",
        "colab_type": "text"
      },
      "source": [
        "## Use the Keras Library to build an image recognition network using the Fashion-MNIST dataset (also comes with keras)\n",
        "\n",
        "- Load and preprocess the image data similar to how we preprocessed the MNIST data in class.\n",
        "- Make sure to one-hot encode your category labels\n",
        "- Make sure to have your final layer have as many nodes as the number of classes that you want to predict.\n",
        "- Try different hyperparameters. What is the highest accuracy that you are able to achieve.\n",
        "- Use the history object that is returned from model.fit to make graphs of the model's loss or train/validation accuracies by epoch. \n",
        "- Remember that neural networks fall prey to randomness so you may need to run your model multiple times (or use Cross Validation) in order to tell if a change to a hyperparameter is truly producing better results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szi6-IpuzaH1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "41c55ce5-55f2-4733-d394-c8c18a4596f9"
      },
      "source": [
        "from keras.datasets import fashion_mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "# Reshape each image into a single line of floats between 0 and 1\n",
        "x_train = x_train.reshape(60000, 784).astype('float32') /255\n",
        "x_test = x_test.reshape(10000, 784).astype('float32') /255\n",
        "\n",
        "num_classes = 10\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 4us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 2s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLfNFslvw2bc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SmVTiMvwx9B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocGHtq_6w0Qb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(42)\n",
        "\n",
        "# Two inner layers of 28 each, \n",
        "def NN1():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(28, activation='relu', input_dim=784))\n",
        "    model.add(Dense(28, activation='relu'))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBNplJegw7cZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1768
        },
        "outputId": "6f7ebaf4-35cf-4333-da53-6fea635f3b15"
      },
      "source": [
        "model = NN1()\n",
        "history = model.fit(x_train, y_train, \n",
        "          validation_data=(x_test, y_test), \n",
        "          epochs=50, batch_size=200, verbose=2)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            " - 2s - loss: 0.7983 - acc: 0.7376 - val_loss: 0.5196 - val_acc: 0.8202\n",
            "Epoch 2/50\n",
            " - 1s - loss: 0.4593 - acc: 0.8407 - val_loss: 0.5042 - val_acc: 0.8219\n",
            "Epoch 3/50\n",
            " - 1s - loss: 0.4203 - acc: 0.8524 - val_loss: 0.4349 - val_acc: 0.8517\n",
            "Epoch 4/50\n",
            " - 1s - loss: 0.3941 - acc: 0.8611 - val_loss: 0.4223 - val_acc: 0.8538\n",
            "Epoch 5/50\n",
            " - 1s - loss: 0.3775 - acc: 0.8673 - val_loss: 0.4127 - val_acc: 0.8554\n",
            "Epoch 6/50\n",
            " - 1s - loss: 0.3708 - acc: 0.8672 - val_loss: 0.4008 - val_acc: 0.8600\n",
            "Epoch 7/50\n",
            " - 1s - loss: 0.3570 - acc: 0.8722 - val_loss: 0.3989 - val_acc: 0.8593\n",
            "Epoch 8/50\n",
            " - 1s - loss: 0.3458 - acc: 0.8770 - val_loss: 0.4110 - val_acc: 0.8544\n",
            "Epoch 9/50\n",
            " - 1s - loss: 0.3400 - acc: 0.8788 - val_loss: 0.4039 - val_acc: 0.8565\n",
            "Epoch 10/50\n",
            " - 1s - loss: 0.3335 - acc: 0.8809 - val_loss: 0.3844 - val_acc: 0.8660\n",
            "Epoch 11/50\n",
            " - 1s - loss: 0.3264 - acc: 0.8826 - val_loss: 0.3850 - val_acc: 0.8649\n",
            "Epoch 12/50\n",
            " - 1s - loss: 0.3220 - acc: 0.8840 - val_loss: 0.3934 - val_acc: 0.8592\n",
            "Epoch 13/50\n",
            " - 1s - loss: 0.3165 - acc: 0.8847 - val_loss: 0.3939 - val_acc: 0.8631\n",
            "Epoch 14/50\n",
            " - 1s - loss: 0.3089 - acc: 0.8879 - val_loss: 0.3839 - val_acc: 0.8646\n",
            "Epoch 15/50\n",
            " - 1s - loss: 0.3074 - acc: 0.8890 - val_loss: 0.3811 - val_acc: 0.8679\n",
            "Epoch 16/50\n",
            " - 1s - loss: 0.3006 - acc: 0.8905 - val_loss: 0.3858 - val_acc: 0.8662\n",
            "Epoch 17/50\n",
            " - 1s - loss: 0.2988 - acc: 0.8918 - val_loss: 0.3794 - val_acc: 0.8667\n",
            "Epoch 18/50\n",
            " - 1s - loss: 0.2946 - acc: 0.8939 - val_loss: 0.3757 - val_acc: 0.8672\n",
            "Epoch 19/50\n",
            " - 1s - loss: 0.2915 - acc: 0.8942 - val_loss: 0.3674 - val_acc: 0.8709\n",
            "Epoch 20/50\n",
            " - 1s - loss: 0.2885 - acc: 0.8954 - val_loss: 0.3724 - val_acc: 0.8720\n",
            "Epoch 21/50\n",
            " - 1s - loss: 0.2837 - acc: 0.8974 - val_loss: 0.3720 - val_acc: 0.8732\n",
            "Epoch 22/50\n",
            " - 1s - loss: 0.2824 - acc: 0.8973 - val_loss: 0.3759 - val_acc: 0.8682\n",
            "Epoch 23/50\n",
            " - 1s - loss: 0.2795 - acc: 0.8985 - val_loss: 0.3662 - val_acc: 0.8720\n",
            "Epoch 24/50\n",
            " - 1s - loss: 0.2752 - acc: 0.9001 - val_loss: 0.3689 - val_acc: 0.8734\n",
            "Epoch 25/50\n",
            " - 1s - loss: 0.2746 - acc: 0.9003 - val_loss: 0.3808 - val_acc: 0.8669\n",
            "Epoch 26/50\n",
            " - 1s - loss: 0.2705 - acc: 0.9015 - val_loss: 0.3778 - val_acc: 0.8698\n",
            "Epoch 27/50\n",
            " - 1s - loss: 0.2694 - acc: 0.9027 - val_loss: 0.3691 - val_acc: 0.8730\n",
            "Epoch 28/50\n",
            " - 1s - loss: 0.2649 - acc: 0.9040 - val_loss: 0.3647 - val_acc: 0.8716\n",
            "Epoch 29/50\n",
            " - 1s - loss: 0.2646 - acc: 0.9044 - val_loss: 0.3749 - val_acc: 0.8692\n",
            "Epoch 30/50\n",
            " - 1s - loss: 0.2605 - acc: 0.9060 - val_loss: 0.3697 - val_acc: 0.8727\n",
            "Epoch 31/50\n",
            " - 1s - loss: 0.2614 - acc: 0.9044 - val_loss: 0.3804 - val_acc: 0.8698\n",
            "Epoch 32/50\n",
            " - 1s - loss: 0.2553 - acc: 0.9075 - val_loss: 0.3706 - val_acc: 0.8716\n",
            "Epoch 33/50\n",
            " - 1s - loss: 0.2553 - acc: 0.9069 - val_loss: 0.3659 - val_acc: 0.8705\n",
            "Epoch 34/50\n",
            " - 1s - loss: 0.2548 - acc: 0.9074 - val_loss: 0.3715 - val_acc: 0.8734\n",
            "Epoch 35/50\n",
            " - 1s - loss: 0.2510 - acc: 0.9086 - val_loss: 0.3615 - val_acc: 0.8767\n",
            "Epoch 36/50\n",
            " - 1s - loss: 0.2486 - acc: 0.9098 - val_loss: 0.3665 - val_acc: 0.8724\n",
            "Epoch 37/50\n",
            " - 1s - loss: 0.2499 - acc: 0.9086 - val_loss: 0.3633 - val_acc: 0.8756\n",
            "Epoch 38/50\n",
            " - 1s - loss: 0.2465 - acc: 0.9102 - val_loss: 0.3683 - val_acc: 0.8720\n",
            "Epoch 39/50\n",
            " - 1s - loss: 0.2440 - acc: 0.9110 - val_loss: 0.3717 - val_acc: 0.8719\n",
            "Epoch 40/50\n",
            " - 1s - loss: 0.2455 - acc: 0.9111 - val_loss: 0.3693 - val_acc: 0.8743\n",
            "Epoch 41/50\n",
            " - 1s - loss: 0.2384 - acc: 0.9127 - val_loss: 0.3669 - val_acc: 0.8742\n",
            "Epoch 42/50\n",
            " - 1s - loss: 0.2397 - acc: 0.9121 - val_loss: 0.3686 - val_acc: 0.8732\n",
            "Epoch 43/50\n",
            " - 1s - loss: 0.2373 - acc: 0.9144 - val_loss: 0.3782 - val_acc: 0.8726\n",
            "Epoch 44/50\n",
            " - 1s - loss: 0.2348 - acc: 0.9142 - val_loss: 0.3674 - val_acc: 0.8744\n",
            "Epoch 45/50\n",
            " - 1s - loss: 0.2349 - acc: 0.9147 - val_loss: 0.3700 - val_acc: 0.8717\n",
            "Epoch 46/50\n",
            " - 1s - loss: 0.2343 - acc: 0.9144 - val_loss: 0.3764 - val_acc: 0.8742\n",
            "Epoch 47/50\n",
            " - 1s - loss: 0.2331 - acc: 0.9152 - val_loss: 0.3711 - val_acc: 0.8746\n",
            "Epoch 48/50\n",
            " - 1s - loss: 0.2319 - acc: 0.9154 - val_loss: 0.3665 - val_acc: 0.8778\n",
            "Epoch 49/50\n",
            " - 1s - loss: 0.2284 - acc: 0.9172 - val_loss: 0.3742 - val_acc: 0.8729\n",
            "Epoch 50/50\n",
            " - 1s - loss: 0.2281 - acc: 0.9158 - val_loss: 0.3949 - val_acc: 0.8697\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hb8RLADixaW4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKSGsG6Pw_P9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "6ff49d61-2fe9-41cc-e79f-da289660ba58"
      },
      "source": [
        "\n",
        "scores = model.evaluate(x_test, y_test, verbose=0)\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(history.history['acc'], label = 'Train')\n",
        "ax.plot(history.history['val_acc'], label = 'Test')\n",
        "ax.set_xlabel('Epoch')\n",
        "ax.set_ylabel('Accuracy')\n",
        "plt.title(f'Final test error: {100-scores[1]*100:.2f}%', fontsize=18)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEaCAYAAAA7YdFPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zv_3xNMjzdLI",
        "colab_type": "text"
      },
      "source": [
        "## Stretch Goals:\n",
        "\n",
        "- Use Hyperparameter Tuning to make the accuracy of your models as high as possible. (error as low as possible)\n",
        "- Use Cross Validation techniques to get more consistent results with your model.\n",
        "- Use GridSearchCV to try different combinations of hyperparameters. \n",
        "- Start looking into other types of Keras layers for CNNs and RNNs maybe try and build a CNN model for fashion-MNIST to see how the results compare."
      ]
    }
  ]
}