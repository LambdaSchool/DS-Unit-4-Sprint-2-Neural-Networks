{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pBQsZEJmubLs"
   },
   "source": [
    "## Use the Keras Library to build a Multi-Layer Perceptron Model on the Boston Housing dataset\n",
    "\n",
    "- The Boston Housing dataset comes with the Keras library so use Keras to import it into your notebook. \n",
    "- Normalize the data (all features should have roughly the same scale)\n",
    "- Import the type of model and layers that you will need from Keras.\n",
    "- Instantiate a model object and use `model.add()` to add layers to your model\n",
    "- Since this is a regression model you will have a single output node in the final layer.\n",
    "- Use activation functions that are appropriate for this task\n",
    "- Compile your model\n",
    "- Fit your model and report its accuracy in terms of Mean Squared Error\n",
    "- Use the history object that is returned from model.fit to make graphs of the model's loss or train/validation accuracies by epoch. \n",
    "- Run this same data through a linear regression model. Which achieves higher accuracy?\n",
    "- Do a little bit of feature engineering and see how that affects your neural network model. (you will need to change your model to accept more inputs)\n",
    "- After feature engineering, which model sees a greater accuracy boost due to the new features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8NLTAR87uYJ-"
   },
   "outputs": [],
   "source": [
    "##### Your Code Here #####\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "from keras.datasets import boston_housing\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(420)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((404, 13), (404,), (102, 13), (102,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.27224633, -0.48361547, -0.43576161, ...,  1.14850044,\n",
       "         0.44807713,  0.8252202 ],\n",
       "       [-0.40342651,  2.99178419, -1.33391162, ..., -1.71818909,\n",
       "         0.43190599, -1.32920239],\n",
       "       [ 0.1249402 , -0.48361547,  1.0283258 , ...,  0.78447637,\n",
       "         0.22061726, -1.30850006],\n",
       "       ...,\n",
       "       [-0.40202987,  0.99079651, -0.7415148 , ..., -0.71712291,\n",
       "         0.07943894, -0.67776904],\n",
       "       [-0.17292018, -0.48361547,  1.24588095, ..., -1.71818909,\n",
       "        -0.98764362,  0.42083466],\n",
       "       [-0.40422614,  2.04394792, -1.20161456, ..., -1.30866202,\n",
       "         0.23317118, -1.15392266]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = preprocessing.StandardScaler().fit(x_train)\n",
    "scaler.transform(x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/joshsolis/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 15)                210       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 15)                240       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 15)                240       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 706\n",
      "Trainable params: 706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(15, input_dim=13, activation=\"relu\"))\n",
    "model.add(Dense(15, activation=\"relu\"))\n",
    "model.add(Dense(15, activation=\"relu\"))\n",
    "model.add(Dense(1, activation='softmax'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['mse'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/joshsolis/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/150\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=150)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404/404 [==============================] - 0s 338us/step\n",
      "mean_squared_error: 542.3704078598778\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "scores = model.evaluate(x_train, y_train)\n",
    "print(f\"{model.metrics_names[1]}: {scores[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "404/404 [==============================] - 0s 98us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 2/150\n",
      "404/404 [==============================] - 0s 100us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 3/150\n",
      "404/404 [==============================] - 0s 87us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 4/150\n",
      "404/404 [==============================] - 0s 90us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 5/150\n",
      "404/404 [==============================] - 0s 89us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 6/150\n",
      "404/404 [==============================] - 0s 86us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 7/150\n",
      "404/404 [==============================] - 0s 87us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 8/150\n",
      "404/404 [==============================] - 0s 84us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 9/150\n",
      "404/404 [==============================] - 0s 90us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 10/150\n",
      "404/404 [==============================] - 0s 91us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 11/150\n",
      "404/404 [==============================] - 0s 93us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 12/150\n",
      "404/404 [==============================] - 0s 89us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 13/150\n",
      "404/404 [==============================] - 0s 92us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 14/150\n",
      "404/404 [==============================] - 0s 95us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 15/150\n",
      "404/404 [==============================] - 0s 84us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 16/150\n",
      "404/404 [==============================] - 0s 92us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 17/150\n",
      "404/404 [==============================] - 0s 91us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 18/150\n",
      "404/404 [==============================] - 0s 93us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 19/150\n",
      "404/404 [==============================] - 0s 100us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 20/150\n",
      "404/404 [==============================] - 0s 92us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 21/150\n",
      "404/404 [==============================] - 0s 91us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 22/150\n",
      "404/404 [==============================] - 0s 82us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 23/150\n",
      "404/404 [==============================] - 0s 84us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 24/150\n",
      "404/404 [==============================] - 0s 96us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 25/150\n",
      "404/404 [==============================] - 0s 99us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 26/150\n",
      "404/404 [==============================] - 0s 105us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 27/150\n",
      "404/404 [==============================] - 0s 98us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 28/150\n",
      "404/404 [==============================] - 0s 84us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 29/150\n",
      "404/404 [==============================] - 0s 94us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 30/150\n",
      "404/404 [==============================] - 0s 107us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 31/150\n",
      "404/404 [==============================] - 0s 88us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 32/150\n",
      "404/404 [==============================] - 0s 88us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 33/150\n",
      "404/404 [==============================] - 0s 99us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 34/150\n",
      "404/404 [==============================] - 0s 89us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 35/150\n",
      "404/404 [==============================] - 0s 90us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 36/150\n",
      "404/404 [==============================] - 0s 84us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 37/150\n",
      "404/404 [==============================] - 0s 91us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 38/150\n",
      "404/404 [==============================] - 0s 89us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 39/150\n",
      "404/404 [==============================] - 0s 88us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 40/150\n",
      "404/404 [==============================] - 0s 83us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 41/150\n",
      "404/404 [==============================] - 0s 83us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 42/150\n",
      "404/404 [==============================] - 0s 88us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 43/150\n",
      "404/404 [==============================] - 0s 92us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 44/150\n",
      "404/404 [==============================] - 0s 82us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 45/150\n",
      "404/404 [==============================] - 0s 92us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 46/150\n",
      "404/404 [==============================] - 0s 93us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 47/150\n",
      "404/404 [==============================] - 0s 90us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 48/150\n",
      "404/404 [==============================] - 0s 89us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 49/150\n",
      "404/404 [==============================] - 0s 89us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 50/150\n",
      "404/404 [==============================] - 0s 82us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 51/150\n",
      "404/404 [==============================] - 0s 88us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 52/150\n",
      "404/404 [==============================] - 0s 82us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 53/150\n",
      "404/404 [==============================] - 0s 91us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 54/150\n",
      "404/404 [==============================] - 0s 81us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 55/150\n",
      "404/404 [==============================] - 0s 90us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 56/150\n",
      "404/404 [==============================] - 0s 87us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 57/150\n",
      "404/404 [==============================] - 0s 89us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 58/150\n",
      "404/404 [==============================] - 0s 82us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 59/150\n",
      "404/404 [==============================] - 0s 82us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 60/150\n",
      "404/404 [==============================] - 0s 97us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 61/150\n",
      "404/404 [==============================] - 0s 101us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 62/150\n",
      "404/404 [==============================] - 0s 90us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 63/150\n",
      "404/404 [==============================] - 0s 87us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 64/150\n",
      "404/404 [==============================] - 0s 89us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 65/150\n",
      "404/404 [==============================] - 0s 97us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 66/150\n",
      "404/404 [==============================] - 0s 86us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 67/150\n",
      "404/404 [==============================] - 0s 84us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 68/150\n",
      "404/404 [==============================] - 0s 87us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 69/150\n",
      "404/404 [==============================] - 0s 98us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 70/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404/404 [==============================] - 0s 87us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 71/150\n",
      "404/404 [==============================] - 0s 89us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 72/150\n",
      "404/404 [==============================] - 0s 85us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 73/150\n",
      "404/404 [==============================] - 0s 76us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 74/150\n",
      "404/404 [==============================] - 0s 81us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 75/150\n",
      "404/404 [==============================] - 0s 80us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 76/150\n",
      "404/404 [==============================] - 0s 81us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 77/150\n",
      "404/404 [==============================] - 0s 84us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 78/150\n",
      "404/404 [==============================] - 0s 72us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 79/150\n",
      "404/404 [==============================] - 0s 89us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 80/150\n",
      "404/404 [==============================] - 0s 98us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 81/150\n",
      "404/404 [==============================] - 0s 104us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 82/150\n",
      "404/404 [==============================] - 0s 87us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 83/150\n",
      "404/404 [==============================] - 0s 88us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 84/150\n",
      "404/404 [==============================] - 0s 81us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 85/150\n",
      "404/404 [==============================] - 0s 83us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 86/150\n",
      "404/404 [==============================] - 0s 78us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 87/150\n",
      "404/404 [==============================] - 0s 81us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 88/150\n",
      "404/404 [==============================] - 0s 85us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 89/150\n",
      "404/404 [==============================] - 0s 83us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 90/150\n",
      "404/404 [==============================] - 0s 85us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 91/150\n",
      "404/404 [==============================] - 0s 84us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 92/150\n",
      "404/404 [==============================] - 0s 88us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 93/150\n",
      "404/404 [==============================] - 0s 87us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 94/150\n",
      "404/404 [==============================] - 0s 77us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 95/150\n",
      "404/404 [==============================] - 0s 91us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 96/150\n",
      "404/404 [==============================] - 0s 83us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 97/150\n",
      "404/404 [==============================] - 0s 82us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 98/150\n",
      "404/404 [==============================] - 0s 84us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 99/150\n",
      "404/404 [==============================] - 0s 79us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 100/150\n",
      "404/404 [==============================] - 0s 83us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 101/150\n",
      "404/404 [==============================] - 0s 88us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 102/150\n",
      "404/404 [==============================] - 0s 86us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 103/150\n",
      "404/404 [==============================] - 0s 91us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 104/150\n",
      "404/404 [==============================] - 0s 83us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 105/150\n",
      "404/404 [==============================] - 0s 78us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 106/150\n",
      "404/404 [==============================] - 0s 85us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 107/150\n",
      "404/404 [==============================] - 0s 77us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 108/150\n",
      "404/404 [==============================] - 0s 86us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 109/150\n",
      "404/404 [==============================] - 0s 80us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 110/150\n",
      "404/404 [==============================] - 0s 87us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 111/150\n",
      "404/404 [==============================] - 0s 79us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 112/150\n",
      "404/404 [==============================] - 0s 88us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 113/150\n",
      "404/404 [==============================] - 0s 107us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 114/150\n",
      "404/404 [==============================] - 0s 94us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 115/150\n",
      "404/404 [==============================] - 0s 79us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 116/150\n",
      "404/404 [==============================] - 0s 87us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 117/150\n",
      "404/404 [==============================] - 0s 79us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 118/150\n",
      "404/404 [==============================] - 0s 80us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 119/150\n",
      "404/404 [==============================] - 0s 77us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 120/150\n",
      "404/404 [==============================] - 0s 84us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 121/150\n",
      "404/404 [==============================] - 0s 76us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 122/150\n",
      "404/404 [==============================] - 0s 79us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 123/150\n",
      "404/404 [==============================] - 0s 76us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 124/150\n",
      "404/404 [==============================] - 0s 88us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 125/150\n",
      "404/404 [==============================] - 0s 83us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 126/150\n",
      "404/404 [==============================] - 0s 84us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 127/150\n",
      "404/404 [==============================] - 0s 89us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 128/150\n",
      "404/404 [==============================] - 0s 83us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 129/150\n",
      "404/404 [==============================] - 0s 93us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 130/150\n",
      "404/404 [==============================] - 0s 83us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 131/150\n",
      "404/404 [==============================] - 0s 92us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 132/150\n",
      "404/404 [==============================] - 0s 80us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 133/150\n",
      "404/404 [==============================] - 0s 88us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 134/150\n",
      "404/404 [==============================] - 0s 88us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 135/150\n",
      "404/404 [==============================] - 0s 89us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 136/150\n",
      "404/404 [==============================] - 0s 92us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 137/150\n",
      "404/404 [==============================] - 0s 88us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 138/150\n",
      "404/404 [==============================] - 0s 94us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 139/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404/404 [==============================] - 0s 99us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 140/150\n",
      "404/404 [==============================] - 0s 93us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 141/150\n",
      "404/404 [==============================] - 0s 90us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 142/150\n",
      "404/404 [==============================] - 0s 82us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 143/150\n",
      "404/404 [==============================] - 0s 82us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 144/150\n",
      "404/404 [==============================] - 0s 79us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 145/150\n",
      "404/404 [==============================] - 0s 81us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 146/150\n",
      "404/404 [==============================] - 0s 76us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 147/150\n",
      "404/404 [==============================] - 0s 79us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 148/150\n",
      "404/404 [==============================] - 0s 90us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 149/150\n",
      "404/404 [==============================] - 0s 80us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 150/150\n",
      "404/404 [==============================] - 0s 87us/step - loss: -341.0881 - mean_squared_error: 542.3704\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=150)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "training_loss = history.history['loss']\n",
    "epoch_count = range(1, len(training_loss) + 1)\n",
    "\n",
    "plt.plot(epoch_count, training_loss, 'r--')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.004800838348142"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "LR = LinearRegression().fit(x_train, y_train)\n",
    "\n",
    "y_pred = LR.predict(x_train)\n",
    "\n",
    "mse(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SfcFnOONyuNm"
   },
   "source": [
    "## Use the Keras Library to build an image recognition network using the Fashion-MNIST dataset (also comes with keras)\n",
    "\n",
    "- Load and preprocess the image data similar to how we preprocessed the MNIST data in class.\n",
    "- Make sure to one-hot encode your category labels\n",
    "- Make sure to have your final layer have as many nodes as the number of classes that you want to predict.\n",
    "- Try different hyperparameters. What is the highest accuracy that you are able to achieve.\n",
    "- Use the history object that is returned from model.fit to make graphs of the model's loss or train/validation accuracies by epoch. \n",
    "- Remember that neural networks fall prey to randomness so you may need to run your model multiple times (or use Cross Validation) in order to tell if a change to a hyperparameter is truly producing better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "szi6-IpuzaH1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joshsolis/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "##### Your Code Here #####\n",
    "from keras.datasets import fashion_mnist\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "import numpy as np\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (10000, 784))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#global hyperparameters\n",
    "import keras\n",
    "\n",
    "batch_size = 64\n",
    "num_classes = 10\n",
    "epochs = 50\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 16)                12560     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                170       \n",
      "=================================================================\n",
      "Total params: 13,274\n",
      "Trainable params: 13,274\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(16, activation = 'relu', input_shape=(784,)))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer = 'adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/50\n",
      "54000/54000 [==============================] - 27s 506us/step - loss: 0.1549 - acc: 0.9389 - val_loss: 0.0953 - val_acc: 0.9617\n",
      "Epoch 2/50\n",
      "54000/54000 [==============================] - 9s 167us/step - loss: 0.1131 - acc: 0.9548 - val_loss: 0.0859 - val_acc: 0.9654\n",
      "Epoch 3/50\n",
      "54000/54000 [==============================] - 8s 146us/step - loss: 0.1059 - acc: 0.9580 - val_loss: 0.0872 - val_acc: 0.9659\n",
      "Epoch 4/50\n",
      "54000/54000 [==============================] - 8s 149us/step - loss: 0.1010 - acc: 0.9595 - val_loss: 0.0812 - val_acc: 0.9680\n",
      "Epoch 5/50\n",
      "54000/54000 [==============================] - 8s 153us/step - loss: 0.0988 - acc: 0.9607 - val_loss: 0.0801 - val_acc: 0.9700\n",
      "Epoch 6/50\n",
      "54000/54000 [==============================] - 11s 203us/step - loss: 0.0970 - acc: 0.9615 - val_loss: 0.0806 - val_acc: 0.9683\n",
      "Epoch 7/50\n",
      "54000/54000 [==============================] - 14s 265us/step - loss: 0.0954 - acc: 0.9622 - val_loss: 0.0796 - val_acc: 0.9695\n",
      "Epoch 8/50\n",
      "54000/54000 [==============================] - 17s 309us/step - loss: 0.0941 - acc: 0.9627 - val_loss: 0.0789 - val_acc: 0.9701\n",
      "Epoch 9/50\n",
      "54000/54000 [==============================] - 16s 303us/step - loss: 0.0931 - acc: 0.9630 - val_loss: 0.0765 - val_acc: 0.9708\n",
      "Epoch 10/50\n",
      "54000/54000 [==============================] - 29s 531us/step - loss: 0.0924 - acc: 0.9632 - val_loss: 0.0783 - val_acc: 0.9702\n",
      "Epoch 11/50\n",
      "54000/54000 [==============================] - 21s 383us/step - loss: 0.0920 - acc: 0.9636 - val_loss: 0.0763 - val_acc: 0.9707\n",
      "Epoch 12/50\n",
      "54000/54000 [==============================] - 15s 271us/step - loss: 0.0907 - acc: 0.9638 - val_loss: 0.0764 - val_acc: 0.9702\n",
      "Epoch 13/50\n",
      "54000/54000 [==============================] - 23s 429us/step - loss: 0.0901 - acc: 0.9642 - val_loss: 0.0758 - val_acc: 0.9713\n",
      "Epoch 14/50\n",
      "54000/54000 [==============================] - 16s 293us/step - loss: 0.0894 - acc: 0.9647 - val_loss: 0.0765 - val_acc: 0.9714\n",
      "Epoch 15/50\n",
      "54000/54000 [==============================] - 10s 190us/step - loss: 0.0895 - acc: 0.9642 - val_loss: 0.0759 - val_acc: 0.9702\n",
      "Epoch 16/50\n",
      "54000/54000 [==============================] - 10s 180us/step - loss: 0.0885 - acc: 0.9648 - val_loss: 0.0752 - val_acc: 0.9713\n",
      "Epoch 17/50\n",
      "54000/54000 [==============================] - 11s 199us/step - loss: 0.0883 - acc: 0.9651 - val_loss: 0.0748 - val_acc: 0.9712\n",
      "Epoch 18/50\n",
      "54000/54000 [==============================] - 13s 243us/step - loss: 0.0875 - acc: 0.9652 - val_loss: 0.0769 - val_acc: 0.9714\n",
      "Epoch 19/50\n",
      "54000/54000 [==============================] - 11s 198us/step - loss: 0.0873 - acc: 0.9652 - val_loss: 0.0741 - val_acc: 0.9717\n",
      "Epoch 20/50\n",
      "54000/54000 [==============================] - 9s 160us/step - loss: 0.0869 - acc: 0.9653 - val_loss: 0.0779 - val_acc: 0.9699\n",
      "Epoch 21/50\n",
      "54000/54000 [==============================] - 10s 190us/step - loss: 0.0866 - acc: 0.9656 - val_loss: 0.0758 - val_acc: 0.9709\n",
      "Epoch 22/50\n",
      "54000/54000 [==============================] - 11s 201us/step - loss: 0.0867 - acc: 0.9653 - val_loss: 0.0732 - val_acc: 0.9723\n",
      "Epoch 23/50\n",
      "54000/54000 [==============================] - 9s 170us/step - loss: 0.0855 - acc: 0.9659 - val_loss: 0.0737 - val_acc: 0.9720\n",
      "Epoch 24/50\n",
      "54000/54000 [==============================] - 8s 151us/step - loss: 0.0858 - acc: 0.9659 - val_loss: 0.0781 - val_acc: 0.9711\n",
      "Epoch 25/50\n",
      "54000/54000 [==============================] - 9s 163us/step - loss: 0.0854 - acc: 0.9661 - val_loss: 0.0740 - val_acc: 0.9721\n",
      "Epoch 26/50\n",
      "54000/54000 [==============================] - 8s 147us/step - loss: 0.0848 - acc: 0.9664 - val_loss: 0.0770 - val_acc: 0.9700\n",
      "Epoch 27/50\n",
      "54000/54000 [==============================] - 8s 157us/step - loss: 0.0855 - acc: 0.9660 - val_loss: 0.0738 - val_acc: 0.9716\n",
      "Epoch 28/50\n",
      "54000/54000 [==============================] - 8s 153us/step - loss: 0.0848 - acc: 0.9664 - val_loss: 0.0770 - val_acc: 0.9705\n",
      "Epoch 29/50\n",
      "54000/54000 [==============================] - 12s 227us/step - loss: 0.0840 - acc: 0.9667 - val_loss: 0.0759 - val_acc: 0.9720\n",
      "Epoch 30/50\n",
      "54000/54000 [==============================] - 9s 167us/step - loss: 0.0842 - acc: 0.9665 - val_loss: 0.0727 - val_acc: 0.9720\n",
      "Epoch 31/50\n",
      "54000/54000 [==============================] - 8s 151us/step - loss: 0.0842 - acc: 0.9667 - val_loss: 0.0750 - val_acc: 0.9707\n",
      "Epoch 32/50\n",
      "54000/54000 [==============================] - 8s 151us/step - loss: 0.0835 - acc: 0.9668 - val_loss: 0.0737 - val_acc: 0.9719\n",
      "Epoch 33/50\n",
      "54000/54000 [==============================] - 8s 149us/step - loss: 0.0845 - acc: 0.9663 - val_loss: 0.0732 - val_acc: 0.9717\n",
      "Epoch 34/50\n",
      "54000/54000 [==============================] - 9s 166us/step - loss: 0.0833 - acc: 0.9671 - val_loss: 0.0730 - val_acc: 0.9719\n",
      "Epoch 35/50\n",
      "54000/54000 [==============================] - 18s 343us/step - loss: 0.0830 - acc: 0.9670 - val_loss: 0.0743 - val_acc: 0.9720\n",
      "Epoch 36/50\n",
      "54000/54000 [==============================] - 10s 177us/step - loss: 0.0833 - acc: 0.9668 - val_loss: 0.0731 - val_acc: 0.9720\n",
      "Epoch 37/50\n",
      "54000/54000 [==============================] - 8s 157us/step - loss: 0.0823 - acc: 0.9673 - val_loss: 0.0718 - val_acc: 0.9722\n",
      "Epoch 38/50\n",
      "54000/54000 [==============================] - 9s 163us/step - loss: 0.0824 - acc: 0.9674 - val_loss: 0.0765 - val_acc: 0.9709\n",
      "Epoch 39/50\n",
      "54000/54000 [==============================] - 12s 222us/step - loss: 0.0827 - acc: 0.9674 - val_loss: 0.0731 - val_acc: 0.9716\n",
      "Epoch 40/50\n",
      "54000/54000 [==============================] - 27s 494us/step - loss: 0.0823 - acc: 0.9678 - val_loss: 0.0718 - val_acc: 0.9727\n",
      "Epoch 41/50\n",
      "54000/54000 [==============================] - 12s 215us/step - loss: 0.0817 - acc: 0.9679 - val_loss: 0.0742 - val_acc: 0.9719\n",
      "Epoch 42/50\n",
      "54000/54000 [==============================] - 18s 339us/step - loss: 0.0820 - acc: 0.9676 - val_loss: 0.0735 - val_acc: 0.9718\n",
      "Epoch 43/50\n",
      "54000/54000 [==============================] - 15s 272us/step - loss: 0.0820 - acc: 0.9676 - val_loss: 0.0724 - val_acc: 0.9719\n",
      "Epoch 44/50\n",
      "54000/54000 [==============================] - 10s 178us/step - loss: 0.0819 - acc: 0.9676 - val_loss: 0.0778 - val_acc: 0.9699\n",
      "Epoch 45/50\n",
      "54000/54000 [==============================] - 8s 146us/step - loss: 0.0820 - acc: 0.9678 - val_loss: 0.0715 - val_acc: 0.9721\n",
      "Epoch 46/50\n",
      "54000/54000 [==============================] - 8s 151us/step - loss: 0.0821 - acc: 0.9675 - val_loss: 0.0742 - val_acc: 0.9716\n",
      "Epoch 47/50\n",
      "54000/54000 [==============================] - 10s 179us/step - loss: 0.0820 - acc: 0.9678 - val_loss: 0.0727 - val_acc: 0.9719\n",
      "Epoch 48/50\n",
      "54000/54000 [==============================] - 9s 170us/step - loss: 0.0810 - acc: 0.9680 - val_loss: 0.0734 - val_acc: 0.9720\n",
      "Epoch 49/50\n",
      "54000/54000 [==============================] - 9s 158us/step - loss: 0.0813 - acc: 0.9679 - val_loss: 0.0729 - val_acc: 0.9717\n",
      "Epoch 50/50\n",
      "54000/54000 [==============================] - 10s 187us/step - loss: 0.0805 - acc: 0.9682 - val_loss: 0.0720 - val_acc: 0.9723\n",
      "10000/10000 [==============================] - 1s 103us/step\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=epochs, validation_split=.1)\n",
    "scores = model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "training_loss = history.history['loss']\n",
    "epoch_count = range(1, len(training_loss) + 1)\n",
    "\n",
    "plt.plot(epoch_count, training_loss, 'r--')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zv_3xNMjzdLI"
   },
   "source": [
    "## Stretch Goals:\n",
    "\n",
    "- Use Hyperparameter Tuning to make the accuracy of your models as high as possible. (error as low as possible)\n",
    "- Use Cross Validation techniques to get more consistent results with your model.\n",
    "- Use GridSearchCV to try different combinations of hyperparameters. \n",
    "- Start looking into other types of Keras layers for CNNs and RNNs maybe try and build a CNN model for fashion-MNIST to see how the results compare."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "LS_DS_433_Keras_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
