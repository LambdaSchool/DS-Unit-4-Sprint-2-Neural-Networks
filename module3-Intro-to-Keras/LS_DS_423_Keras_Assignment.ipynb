{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LS_DS_423_Keras_Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pBQsZEJmubLs"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "\n",
        "# Neural Network Framework (Keras)\n",
        "\n",
        "## *Data Science Unit 4 Sprint 2 Assignmnet 3*\n",
        "\n",
        "## Use the Keras Library to build a Multi-Layer Perceptron Model on the Boston Housing dataset\n",
        "\n",
        "- The Boston Housing dataset comes with the Keras library so use Keras to import it into your notebook. \n",
        "- Normalize the data (all features should have roughly the same scale)\n",
        "- Import the type of model and layers that you will need from Keras.\n",
        "- Instantiate a model object and use `model.add()` to add layers to your model\n",
        "- Since this is a regression model you will have a single output node in the final layer.\n",
        "- Use activation functions that are appropriate for this task\n",
        "- Compile your model\n",
        "- Fit your model and report its accuracy in terms of Mean Squared Error\n",
        "- Use the history object that is returned from model.fit to make graphs of the model's loss or train/validation accuracies by epoch. \n",
        "- Run this same data through a linear regression model. Which achieves higher accuracy?\n",
        "- Do a little bit of feature engineering and see how that affects your neural network model. (you will need to change your model to accept more inputs)\n",
        "- After feature engineering, which model sees a greater accuracy boost due to the new features?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8NLTAR87uYJ-",
        "colab": {}
      },
      "source": [
        "##### Your Code Here #####\n",
        "\n",
        "#Import type of model & layers from keras\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.datasets import boston_housing\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "%matplotlib inline\n",
        "np.random.seed(42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3oiWSFEBHiG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Instantiate train/test data\n",
        "(x_train, y_train), (x_test, y_test) = boston_housing.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5FGKO7jGWRS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "93e26971-907f-44d4-d595-01c8110376f5"
      },
      "source": [
        "x_train.shape  # Get columns for input_dim"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(404, 13)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmVqKwhzBHlL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ee91943f-b25e-40d8-bf5b-aacd8292c26a"
      },
      "source": [
        "# Instantiate the model\n",
        "model = Sequential()\n",
        "\n",
        "# Add layers to the model (1 hidden layer as base model)\n",
        "\n",
        "# Normalization\n",
        "model.add(BatchNormalization())\n",
        "# Input -> Hidden\n",
        "model.add(Dense(13, input_dim=13, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "# Hidden\n",
        "model.add(Dense(13, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "# Hidden\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "# Hidden\n",
        "model.add(Dense(6, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "# Hidden -> Output\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "# Compile model\n",
        "model.compile(\n",
        "    loss='mean_squared_error',\n",
        "    optimizer='adam',\n",
        "    metrics=['mse']\n",
        ")\n",
        "\n",
        "# Fit model\n",
        "model_1 = model.fit(x_train, y_train, epochs=1000, batch_size=10)\n",
        "\n",
        "# Inspect architecture\n",
        "model.summary()"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 404 samples\n",
            "Epoch 1/1000\n",
            "404/404 [==============================] - 1s 1ms/sample - loss: 554.6363 - mean_squared_error: 554.6362\n",
            "Epoch 2/1000\n",
            "404/404 [==============================] - 0s 252us/sample - loss: 478.3484 - mean_squared_error: 478.3484\n",
            "Epoch 3/1000\n",
            "404/404 [==============================] - 0s 249us/sample - loss: 285.4563 - mean_squared_error: 285.4563\n",
            "Epoch 4/1000\n",
            "404/404 [==============================] - 0s 249us/sample - loss: 183.3029 - mean_squared_error: 183.3029\n",
            "Epoch 5/1000\n",
            "404/404 [==============================] - 0s 260us/sample - loss: 152.1742 - mean_squared_error: 152.1742\n",
            "Epoch 6/1000\n",
            "404/404 [==============================] - 0s 253us/sample - loss: 168.5128 - mean_squared_error: 168.5128\n",
            "Epoch 7/1000\n",
            "404/404 [==============================] - 0s 250us/sample - loss: 132.2616 - mean_squared_error: 132.2617\n",
            "Epoch 8/1000\n",
            "404/404 [==============================] - 0s 242us/sample - loss: 134.9558 - mean_squared_error: 134.9558\n",
            "Epoch 9/1000\n",
            "404/404 [==============================] - 0s 253us/sample - loss: 128.0846 - mean_squared_error: 128.0846\n",
            "Epoch 10/1000\n",
            "404/404 [==============================] - 0s 256us/sample - loss: 120.0248 - mean_squared_error: 120.0247\n",
            "Epoch 11/1000\n",
            "404/404 [==============================] - 0s 278us/sample - loss: 118.0622 - mean_squared_error: 118.0622\n",
            "Epoch 12/1000\n",
            "404/404 [==============================] - 0s 285us/sample - loss: 116.8624 - mean_squared_error: 116.8624\n",
            "Epoch 13/1000\n",
            "404/404 [==============================] - 0s 245us/sample - loss: 118.1432 - mean_squared_error: 118.1432\n",
            "Epoch 14/1000\n",
            "404/404 [==============================] - 0s 228us/sample - loss: 119.8905 - mean_squared_error: 119.8905\n",
            "Epoch 15/1000\n",
            "404/404 [==============================] - 0s 247us/sample - loss: 120.8406 - mean_squared_error: 120.8406\n",
            "Epoch 16/1000\n",
            "404/404 [==============================] - 0s 250us/sample - loss: 123.4717 - mean_squared_error: 123.4717\n",
            "Epoch 17/1000\n",
            "404/404 [==============================] - 0s 243us/sample - loss: 121.6945 - mean_squared_error: 121.6945\n",
            "Epoch 18/1000\n",
            "404/404 [==============================] - 0s 244us/sample - loss: 108.3963 - mean_squared_error: 108.3963\n",
            "Epoch 19/1000\n",
            "404/404 [==============================] - 0s 244us/sample - loss: 96.9670 - mean_squared_error: 96.9670\n",
            "Epoch 20/1000\n",
            "404/404 [==============================] - 0s 253us/sample - loss: 112.9811 - mean_squared_error: 112.9811\n",
            "Epoch 21/1000\n",
            "404/404 [==============================] - 0s 237us/sample - loss: 110.5577 - mean_squared_error: 110.5577\n",
            "Epoch 22/1000\n",
            "404/404 [==============================] - 0s 258us/sample - loss: 110.1656 - mean_squared_error: 110.1656\n",
            "Epoch 23/1000\n",
            "404/404 [==============================] - 0s 246us/sample - loss: 114.6583 - mean_squared_error: 114.6583\n",
            "Epoch 24/1000\n",
            "404/404 [==============================] - 0s 276us/sample - loss: 94.4785 - mean_squared_error: 94.4785\n",
            "Epoch 25/1000\n",
            "404/404 [==============================] - 0s 234us/sample - loss: 105.2203 - mean_squared_error: 105.2203\n",
            "Epoch 26/1000\n",
            "404/404 [==============================] - 0s 219us/sample - loss: 93.1910 - mean_squared_error: 93.1910\n",
            "Epoch 27/1000\n",
            "404/404 [==============================] - 0s 228us/sample - loss: 97.2248 - mean_squared_error: 97.2248\n",
            "Epoch 28/1000\n",
            "404/404 [==============================] - 0s 217us/sample - loss: 105.7500 - mean_squared_error: 105.7500\n",
            "Epoch 29/1000\n",
            "404/404 [==============================] - 0s 223us/sample - loss: 105.2029 - mean_squared_error: 105.2029\n",
            "Epoch 30/1000\n",
            "404/404 [==============================] - 0s 231us/sample - loss: 85.0400 - mean_squared_error: 85.0400\n",
            "Epoch 31/1000\n",
            "404/404 [==============================] - 0s 241us/sample - loss: 84.2396 - mean_squared_error: 84.2396\n",
            "Epoch 32/1000\n",
            "404/404 [==============================] - 0s 241us/sample - loss: 94.5169 - mean_squared_error: 94.5169\n",
            "Epoch 33/1000\n",
            "404/404 [==============================] - 0s 218us/sample - loss: 92.1220 - mean_squared_error: 92.1220\n",
            "Epoch 34/1000\n",
            "404/404 [==============================] - 0s 220us/sample - loss: 92.2565 - mean_squared_error: 92.2565\n",
            "Epoch 35/1000\n",
            "404/404 [==============================] - 0s 233us/sample - loss: 90.7802 - mean_squared_error: 90.7802\n",
            "Epoch 36/1000\n",
            "404/404 [==============================] - 0s 229us/sample - loss: 80.0340 - mean_squared_error: 80.0340\n",
            "Epoch 37/1000\n",
            "404/404 [==============================] - 0s 220us/sample - loss: 89.0962 - mean_squared_error: 89.0962\n",
            "Epoch 38/1000\n",
            "404/404 [==============================] - 0s 236us/sample - loss: 88.1486 - mean_squared_error: 88.1486\n",
            "Epoch 39/1000\n",
            "404/404 [==============================] - 0s 231us/sample - loss: 96.4076 - mean_squared_error: 96.4076\n",
            "Epoch 40/1000\n",
            "404/404 [==============================] - 0s 228us/sample - loss: 75.9982 - mean_squared_error: 75.9982\n",
            "Epoch 41/1000\n",
            "404/404 [==============================] - 0s 219us/sample - loss: 80.6524 - mean_squared_error: 80.6524\n",
            "Epoch 42/1000\n",
            "404/404 [==============================] - 0s 229us/sample - loss: 85.6854 - mean_squared_error: 85.6854\n",
            "Epoch 43/1000\n",
            "404/404 [==============================] - 0s 225us/sample - loss: 84.8670 - mean_squared_error: 84.8670\n",
            "Epoch 44/1000\n",
            "404/404 [==============================] - 0s 225us/sample - loss: 75.7151 - mean_squared_error: 75.7151\n",
            "Epoch 45/1000\n",
            "404/404 [==============================] - 0s 252us/sample - loss: 88.0799 - mean_squared_error: 88.0798\n",
            "Epoch 46/1000\n",
            "404/404 [==============================] - 0s 227us/sample - loss: 66.2615 - mean_squared_error: 66.2615\n",
            "Epoch 47/1000\n",
            "404/404 [==============================] - 0s 229us/sample - loss: 72.3322 - mean_squared_error: 72.3322\n",
            "Epoch 48/1000\n",
            "404/404 [==============================] - 0s 229us/sample - loss: 83.5456 - mean_squared_error: 83.5456\n",
            "Epoch 49/1000\n",
            "404/404 [==============================] - 0s 245us/sample - loss: 77.1854 - mean_squared_error: 77.1854\n",
            "Epoch 50/1000\n",
            "404/404 [==============================] - 0s 233us/sample - loss: 91.9242 - mean_squared_error: 91.9242\n",
            "Epoch 51/1000\n",
            "404/404 [==============================] - 0s 230us/sample - loss: 84.7075 - mean_squared_error: 84.7075\n",
            "Epoch 52/1000\n",
            "404/404 [==============================] - 0s 235us/sample - loss: 77.8521 - mean_squared_error: 77.8521\n",
            "Epoch 53/1000\n",
            "404/404 [==============================] - 0s 246us/sample - loss: 77.2371 - mean_squared_error: 77.2371\n",
            "Epoch 54/1000\n",
            "404/404 [==============================] - 0s 254us/sample - loss: 68.7470 - mean_squared_error: 68.7470\n",
            "Epoch 55/1000\n",
            "404/404 [==============================] - 0s 240us/sample - loss: 81.5446 - mean_squared_error: 81.5446\n",
            "Epoch 56/1000\n",
            "404/404 [==============================] - 0s 237us/sample - loss: 72.9920 - mean_squared_error: 72.9920\n",
            "Epoch 57/1000\n",
            "404/404 [==============================] - 0s 236us/sample - loss: 78.6132 - mean_squared_error: 78.6132\n",
            "Epoch 58/1000\n",
            "404/404 [==============================] - 0s 229us/sample - loss: 68.6876 - mean_squared_error: 68.6876\n",
            "Epoch 59/1000\n",
            "404/404 [==============================] - 0s 233us/sample - loss: 79.1918 - mean_squared_error: 79.1918\n",
            "Epoch 60/1000\n",
            "404/404 [==============================] - 0s 237us/sample - loss: 71.9582 - mean_squared_error: 71.9582\n",
            "Epoch 61/1000\n",
            "404/404 [==============================] - 0s 226us/sample - loss: 85.6019 - mean_squared_error: 85.6019\n",
            "Epoch 62/1000\n",
            "404/404 [==============================] - 0s 244us/sample - loss: 71.5487 - mean_squared_error: 71.5487\n",
            "Epoch 63/1000\n",
            "404/404 [==============================] - 0s 236us/sample - loss: 74.0665 - mean_squared_error: 74.0665\n",
            "Epoch 64/1000\n",
            "404/404 [==============================] - 0s 226us/sample - loss: 75.0593 - mean_squared_error: 75.0593\n",
            "Epoch 65/1000\n",
            "404/404 [==============================] - 0s 250us/sample - loss: 65.0216 - mean_squared_error: 65.0216\n",
            "Epoch 66/1000\n",
            "404/404 [==============================] - 0s 239us/sample - loss: 71.2660 - mean_squared_error: 71.2660\n",
            "Epoch 67/1000\n",
            "404/404 [==============================] - 0s 221us/sample - loss: 78.0833 - mean_squared_error: 78.0833\n",
            "Epoch 68/1000\n",
            "404/404 [==============================] - 0s 237us/sample - loss: 74.4639 - mean_squared_error: 74.4639\n",
            "Epoch 69/1000\n",
            "404/404 [==============================] - 0s 258us/sample - loss: 71.2992 - mean_squared_error: 71.2992\n",
            "Epoch 70/1000\n",
            "404/404 [==============================] - 0s 243us/sample - loss: 83.1036 - mean_squared_error: 83.1036\n",
            "Epoch 71/1000\n",
            "404/404 [==============================] - 0s 232us/sample - loss: 82.7268 - mean_squared_error: 82.7268\n",
            "Epoch 72/1000\n",
            "404/404 [==============================] - 0s 244us/sample - loss: 68.9665 - mean_squared_error: 68.9665\n",
            "Epoch 73/1000\n",
            "404/404 [==============================] - 0s 241us/sample - loss: 73.9230 - mean_squared_error: 73.9230\n",
            "Epoch 74/1000\n",
            "404/404 [==============================] - 0s 226us/sample - loss: 71.2972 - mean_squared_error: 71.2972\n",
            "Epoch 75/1000\n",
            "404/404 [==============================] - 0s 233us/sample - loss: 60.5990 - mean_squared_error: 60.5991\n",
            "Epoch 76/1000\n",
            "404/404 [==============================] - 0s 243us/sample - loss: 76.0696 - mean_squared_error: 76.0696\n",
            "Epoch 77/1000\n",
            "404/404 [==============================] - 0s 237us/sample - loss: 76.0640 - mean_squared_error: 76.0640\n",
            "Epoch 78/1000\n",
            "404/404 [==============================] - 0s 239us/sample - loss: 80.0174 - mean_squared_error: 80.0174\n",
            "Epoch 79/1000\n",
            "404/404 [==============================] - 0s 233us/sample - loss: 72.4966 - mean_squared_error: 72.4966\n",
            "Epoch 80/1000\n",
            "404/404 [==============================] - 0s 238us/sample - loss: 70.7608 - mean_squared_error: 70.7608\n",
            "Epoch 81/1000\n",
            "404/404 [==============================] - 0s 249us/sample - loss: 65.9673 - mean_squared_error: 65.9673\n",
            "Epoch 82/1000\n",
            "404/404 [==============================] - 0s 241us/sample - loss: 71.7529 - mean_squared_error: 71.7529\n",
            "Epoch 83/1000\n",
            "404/404 [==============================] - 0s 219us/sample - loss: 73.7512 - mean_squared_error: 73.7512\n",
            "Epoch 84/1000\n",
            "404/404 [==============================] - 0s 224us/sample - loss: 80.3758 - mean_squared_error: 80.3758\n",
            "Epoch 85/1000\n",
            "404/404 [==============================] - 0s 226us/sample - loss: 76.1661 - mean_squared_error: 76.1661\n",
            "Epoch 86/1000\n",
            "404/404 [==============================] - 0s 256us/sample - loss: 67.4403 - mean_squared_error: 67.4403\n",
            "Epoch 87/1000\n",
            "404/404 [==============================] - 0s 237us/sample - loss: 74.2375 - mean_squared_error: 74.2375\n",
            "Epoch 88/1000\n",
            "404/404 [==============================] - 0s 252us/sample - loss: 71.5808 - mean_squared_error: 71.5808\n",
            "Epoch 89/1000\n",
            "404/404 [==============================] - 0s 228us/sample - loss: 66.1819 - mean_squared_error: 66.1819\n",
            "Epoch 90/1000\n",
            "404/404 [==============================] - 0s 242us/sample - loss: 71.0461 - mean_squared_error: 71.0461\n",
            "Epoch 91/1000\n",
            "404/404 [==============================] - 0s 229us/sample - loss: 60.7661 - mean_squared_error: 60.7661\n",
            "Epoch 92/1000\n",
            "404/404 [==============================] - 0s 220us/sample - loss: 71.3643 - mean_squared_error: 71.3643\n",
            "Epoch 93/1000\n",
            "404/404 [==============================] - 0s 224us/sample - loss: 69.7171 - mean_squared_error: 69.7171\n",
            "Epoch 94/1000\n",
            "404/404 [==============================] - 0s 223us/sample - loss: 62.9803 - mean_squared_error: 62.9803\n",
            "Epoch 95/1000\n",
            "404/404 [==============================] - 0s 225us/sample - loss: 76.3456 - mean_squared_error: 76.3456\n",
            "Epoch 96/1000\n",
            "404/404 [==============================] - 0s 229us/sample - loss: 68.5296 - mean_squared_error: 68.5296\n",
            "Epoch 97/1000\n",
            "404/404 [==============================] - 0s 228us/sample - loss: 69.9591 - mean_squared_error: 69.9591\n",
            "Epoch 98/1000\n",
            "404/404 [==============================] - 0s 257us/sample - loss: 82.7360 - mean_squared_error: 82.7360\n",
            "Epoch 99/1000\n",
            "404/404 [==============================] - 0s 243us/sample - loss: 61.6196 - mean_squared_error: 61.6195\n",
            "Epoch 100/1000\n",
            "404/404 [==============================] - 0s 239us/sample - loss: 70.4846 - mean_squared_error: 70.4846\n",
            "Epoch 101/1000\n",
            "404/404 [==============================] - 0s 234us/sample - loss: 67.6507 - mean_squared_error: 67.6507\n",
            "Epoch 102/1000\n",
            "404/404 [==============================] - 0s 247us/sample - loss: 57.0960 - mean_squared_error: 57.0960\n",
            "Epoch 103/1000\n",
            "404/404 [==============================] - 0s 225us/sample - loss: 64.0613 - mean_squared_error: 64.0613\n",
            "Epoch 104/1000\n",
            "404/404 [==============================] - 0s 229us/sample - loss: 73.6009 - mean_squared_error: 73.6009\n",
            "Epoch 105/1000\n",
            "404/404 [==============================] - 0s 228us/sample - loss: 62.1952 - mean_squared_error: 62.1952\n",
            "Epoch 106/1000\n",
            "404/404 [==============================] - 0s 237us/sample - loss: 58.1101 - mean_squared_error: 58.1101\n",
            "Epoch 107/1000\n",
            "404/404 [==============================] - 0s 243us/sample - loss: 58.3004 - mean_squared_error: 58.3004\n",
            "Epoch 108/1000\n",
            "404/404 [==============================] - 0s 235us/sample - loss: 53.4926 - mean_squared_error: 53.4926\n",
            "Epoch 109/1000\n",
            "404/404 [==============================] - 0s 295us/sample - loss: 59.8372 - mean_squared_error: 59.8372\n",
            "Epoch 110/1000\n",
            "404/404 [==============================] - 0s 250us/sample - loss: 63.1907 - mean_squared_error: 63.1908\n",
            "Epoch 111/1000\n",
            "404/404 [==============================] - 0s 284us/sample - loss: 59.0529 - mean_squared_error: 59.0529\n",
            "Epoch 112/1000\n",
            "404/404 [==============================] - 0s 281us/sample - loss: 64.1297 - mean_squared_error: 64.1297\n",
            "Epoch 113/1000\n",
            "404/404 [==============================] - 0s 237us/sample - loss: 62.2782 - mean_squared_error: 62.2782\n",
            "Epoch 114/1000\n",
            "404/404 [==============================] - 0s 255us/sample - loss: 58.8000 - mean_squared_error: 58.8001\n",
            "Epoch 115/1000\n",
            "404/404 [==============================] - 0s 253us/sample - loss: 60.3118 - mean_squared_error: 60.3118\n",
            "Epoch 116/1000\n",
            "404/404 [==============================] - 0s 246us/sample - loss: 59.3506 - mean_squared_error: 59.3506\n",
            "Epoch 117/1000\n",
            "404/404 [==============================] - 0s 266us/sample - loss: 56.7279 - mean_squared_error: 56.7279\n",
            "Epoch 118/1000\n",
            "404/404 [==============================] - 0s 226us/sample - loss: 66.8485 - mean_squared_error: 66.8485\n",
            "Epoch 119/1000\n",
            "404/404 [==============================] - 0s 249us/sample - loss: 58.8302 - mean_squared_error: 58.8302\n",
            "Epoch 120/1000\n",
            "404/404 [==============================] - 0s 276us/sample - loss: 58.4883 - mean_squared_error: 58.4883\n",
            "Epoch 121/1000\n",
            "404/404 [==============================] - 0s 234us/sample - loss: 57.2257 - mean_squared_error: 57.2257\n",
            "Epoch 122/1000\n",
            "404/404 [==============================] - 0s 240us/sample - loss: 52.9802 - mean_squared_error: 52.9802\n",
            "Epoch 123/1000\n",
            "404/404 [==============================] - 0s 233us/sample - loss: 60.5418 - mean_squared_error: 60.5418\n",
            "Epoch 124/1000\n",
            "404/404 [==============================] - 0s 243us/sample - loss: 52.0019 - mean_squared_error: 52.0019\n",
            "Epoch 125/1000\n",
            "404/404 [==============================] - 0s 231us/sample - loss: 60.8734 - mean_squared_error: 60.8734\n",
            "Epoch 126/1000\n",
            "404/404 [==============================] - 0s 240us/sample - loss: 68.8146 - mean_squared_error: 68.8146\n",
            "Epoch 127/1000\n",
            "404/404 [==============================] - 0s 227us/sample - loss: 55.2057 - mean_squared_error: 55.2057\n",
            "Epoch 128/1000\n",
            "404/404 [==============================] - 0s 248us/sample - loss: 65.5209 - mean_squared_error: 65.5209\n",
            "Epoch 129/1000\n",
            "404/404 [==============================] - 0s 241us/sample - loss: 54.8330 - mean_squared_error: 54.8330\n",
            "Epoch 130/1000\n",
            "404/404 [==============================] - 0s 234us/sample - loss: 54.5260 - mean_squared_error: 54.5260\n",
            "Epoch 131/1000\n",
            "404/404 [==============================] - 0s 232us/sample - loss: 62.2557 - mean_squared_error: 62.2557\n",
            "Epoch 132/1000\n",
            "404/404 [==============================] - 0s 228us/sample - loss: 62.6875 - mean_squared_error: 62.6875\n",
            "Epoch 133/1000\n",
            "404/404 [==============================] - 0s 254us/sample - loss: 60.1740 - mean_squared_error: 60.1740\n",
            "Epoch 134/1000\n",
            "404/404 [==============================] - 0s 248us/sample - loss: 58.8843 - mean_squared_error: 58.8843\n",
            "Epoch 135/1000\n",
            "404/404 [==============================] - 0s 241us/sample - loss: 56.6490 - mean_squared_error: 56.6490\n",
            "Epoch 136/1000\n",
            "404/404 [==============================] - 0s 240us/sample - loss: 50.3147 - mean_squared_error: 50.3147\n",
            "Epoch 137/1000\n",
            "404/404 [==============================] - 0s 238us/sample - loss: 52.6159 - mean_squared_error: 52.6159\n",
            "Epoch 138/1000\n",
            "404/404 [==============================] - 0s 252us/sample - loss: 66.4728 - mean_squared_error: 66.4728\n",
            "Epoch 139/1000\n",
            "404/404 [==============================] - 0s 244us/sample - loss: 62.3494 - mean_squared_error: 62.3494\n",
            "Epoch 140/1000\n",
            "404/404 [==============================] - 0s 261us/sample - loss: 63.1420 - mean_squared_error: 63.1420\n",
            "Epoch 141/1000\n",
            "404/404 [==============================] - 0s 237us/sample - loss: 56.7989 - mean_squared_error: 56.7989\n",
            "Epoch 142/1000\n",
            "404/404 [==============================] - 0s 245us/sample - loss: 55.8437 - mean_squared_error: 55.8437\n",
            "Epoch 143/1000\n",
            "404/404 [==============================] - 0s 240us/sample - loss: 64.7258 - mean_squared_error: 64.7258\n",
            "Epoch 144/1000\n",
            "404/404 [==============================] - 0s 235us/sample - loss: 50.4198 - mean_squared_error: 50.4198\n",
            "Epoch 145/1000\n",
            "404/404 [==============================] - 0s 236us/sample - loss: 55.4264 - mean_squared_error: 55.4264\n",
            "Epoch 146/1000\n",
            "404/404 [==============================] - 0s 246us/sample - loss: 55.6305 - mean_squared_error: 55.6305\n",
            "Epoch 147/1000\n",
            "404/404 [==============================] - 0s 260us/sample - loss: 53.4226 - mean_squared_error: 53.4226\n",
            "Epoch 148/1000\n",
            "404/404 [==============================] - 0s 258us/sample - loss: 63.9797 - mean_squared_error: 63.9797\n",
            "Epoch 149/1000\n",
            "404/404 [==============================] - 0s 234us/sample - loss: 57.6781 - mean_squared_error: 57.6781\n",
            "Epoch 150/1000\n",
            "404/404 [==============================] - 0s 245us/sample - loss: 56.8723 - mean_squared_error: 56.8723\n",
            "Epoch 151/1000\n",
            "404/404 [==============================] - 0s 224us/sample - loss: 56.7344 - mean_squared_error: 56.7344\n",
            "Epoch 152/1000\n",
            "404/404 [==============================] - 0s 236us/sample - loss: 58.7542 - mean_squared_error: 58.7542\n",
            "Epoch 153/1000\n",
            "404/404 [==============================] - 0s 246us/sample - loss: 58.2032 - mean_squared_error: 58.2032\n",
            "Epoch 154/1000\n",
            "404/404 [==============================] - 0s 238us/sample - loss: 68.6661 - mean_squared_error: 68.6660\n",
            "Epoch 155/1000\n",
            "404/404 [==============================] - 0s 239us/sample - loss: 45.0860 - mean_squared_error: 45.0860\n",
            "Epoch 156/1000\n",
            "404/404 [==============================] - 0s 234us/sample - loss: 45.6883 - mean_squared_error: 45.6883\n",
            "Epoch 157/1000\n",
            "404/404 [==============================] - 0s 246us/sample - loss: 53.0039 - mean_squared_error: 53.0039\n",
            "Epoch 158/1000\n",
            "404/404 [==============================] - 0s 241us/sample - loss: 53.6768 - mean_squared_error: 53.6768\n",
            "Epoch 159/1000\n",
            "404/404 [==============================] - 0s 227us/sample - loss: 50.1285 - mean_squared_error: 50.1285\n",
            "Epoch 160/1000\n",
            "404/404 [==============================] - 0s 238us/sample - loss: 54.0146 - mean_squared_error: 54.0146\n",
            "Epoch 161/1000\n",
            "404/404 [==============================] - 0s 232us/sample - loss: 56.2972 - mean_squared_error: 56.2972\n",
            "Epoch 162/1000\n",
            "404/404 [==============================] - 0s 241us/sample - loss: 52.5043 - mean_squared_error: 52.5043\n",
            "Epoch 163/1000\n",
            "404/404 [==============================] - 0s 241us/sample - loss: 57.3790 - mean_squared_error: 57.3790\n",
            "Epoch 164/1000\n",
            "404/404 [==============================] - 0s 239us/sample - loss: 48.9283 - mean_squared_error: 48.9283\n",
            "Epoch 165/1000\n",
            "404/404 [==============================] - 0s 257us/sample - loss: 50.6831 - mean_squared_error: 50.6831\n",
            "Epoch 166/1000\n",
            "404/404 [==============================] - 0s 237us/sample - loss: 47.1777 - mean_squared_error: 47.1777\n",
            "Epoch 167/1000\n",
            "404/404 [==============================] - 0s 252us/sample - loss: 59.3006 - mean_squared_error: 59.3006\n",
            "Epoch 168/1000\n",
            "404/404 [==============================] - 0s 240us/sample - loss: 48.0218 - mean_squared_error: 48.0218\n",
            "Epoch 169/1000\n",
            "404/404 [==============================] - 0s 235us/sample - loss: 64.2106 - mean_squared_error: 64.2106\n",
            "Epoch 170/1000\n",
            "404/404 [==============================] - 0s 236us/sample - loss: 60.5229 - mean_squared_error: 60.5229\n",
            "Epoch 171/1000\n",
            "404/404 [==============================] - 0s 221us/sample - loss: 57.6111 - mean_squared_error: 57.6111\n",
            "Epoch 172/1000\n",
            "404/404 [==============================] - 0s 248us/sample - loss: 54.0533 - mean_squared_error: 54.0533\n",
            "Epoch 173/1000\n",
            "404/404 [==============================] - 0s 229us/sample - loss: 54.4931 - mean_squared_error: 54.4931\n",
            "Epoch 174/1000\n",
            "404/404 [==============================] - 0s 242us/sample - loss: 56.2413 - mean_squared_error: 56.2413\n",
            "Epoch 175/1000\n",
            "404/404 [==============================] - 0s 243us/sample - loss: 50.0051 - mean_squared_error: 50.0051\n",
            "Epoch 176/1000\n",
            "404/404 [==============================] - 0s 237us/sample - loss: 56.3062 - mean_squared_error: 56.3062\n",
            "Epoch 177/1000\n",
            "404/404 [==============================] - 0s 237us/sample - loss: 52.3859 - mean_squared_error: 52.3859\n",
            "Epoch 178/1000\n",
            "404/404 [==============================] - 0s 250us/sample - loss: 42.9962 - mean_squared_error: 42.9962\n",
            "Epoch 179/1000\n",
            "404/404 [==============================] - 0s 241us/sample - loss: 62.7646 - mean_squared_error: 62.7646\n",
            "Epoch 180/1000\n",
            "404/404 [==============================] - 0s 235us/sample - loss: 46.5786 - mean_squared_error: 46.5786\n",
            "Epoch 181/1000\n",
            "404/404 [==============================] - 0s 230us/sample - loss: 50.8527 - mean_squared_error: 50.8527\n",
            "Epoch 182/1000\n",
            "404/404 [==============================] - 0s 242us/sample - loss: 48.5123 - mean_squared_error: 48.5123\n",
            "Epoch 183/1000\n",
            "404/404 [==============================] - 0s 246us/sample - loss: 55.9909 - mean_squared_error: 55.9909\n",
            "Epoch 184/1000\n",
            "404/404 [==============================] - 0s 237us/sample - loss: 50.0464 - mean_squared_error: 50.0464\n",
            "Epoch 185/1000\n",
            "404/404 [==============================] - 0s 250us/sample - loss: 52.0343 - mean_squared_error: 52.0343\n",
            "Epoch 186/1000\n",
            "404/404 [==============================] - 0s 238us/sample - loss: 49.2094 - mean_squared_error: 49.2094\n",
            "Epoch 187/1000\n",
            "404/404 [==============================] - 0s 237us/sample - loss: 50.9821 - mean_squared_error: 50.9821\n",
            "Epoch 188/1000\n",
            "404/404 [==============================] - 0s 237us/sample - loss: 56.6392 - mean_squared_error: 56.6392\n",
            "Epoch 189/1000\n",
            "404/404 [==============================] - 0s 236us/sample - loss: 49.3607 - mean_squared_error: 49.3607\n",
            "Epoch 190/1000\n",
            "404/404 [==============================] - 0s 228us/sample - loss: 53.7641 - mean_squared_error: 53.7641\n",
            "Epoch 191/1000\n",
            "404/404 [==============================] - 0s 221us/sample - loss: 52.0131 - mean_squared_error: 52.0131\n",
            "Epoch 192/1000\n",
            "404/404 [==============================] - 0s 229us/sample - loss: 53.5498 - mean_squared_error: 53.5498\n",
            "Epoch 193/1000\n",
            "404/404 [==============================] - 0s 229us/sample - loss: 52.1332 - mean_squared_error: 52.1332\n",
            "Epoch 194/1000\n",
            "404/404 [==============================] - 0s 228us/sample - loss: 52.5974 - mean_squared_error: 52.5974\n",
            "Epoch 195/1000\n",
            "404/404 [==============================] - 0s 224us/sample - loss: 50.9622 - mean_squared_error: 50.9622\n",
            "Epoch 196/1000\n",
            "404/404 [==============================] - 0s 224us/sample - loss: 49.1803 - mean_squared_error: 49.1803\n",
            "Epoch 197/1000\n",
            "404/404 [==============================] - 0s 234us/sample - loss: 47.6769 - mean_squared_error: 47.6769\n",
            "Epoch 198/1000\n",
            "404/404 [==============================] - 0s 259us/sample - loss: 47.5159 - mean_squared_error: 47.5159\n",
            "Epoch 199/1000\n",
            "404/404 [==============================] - 0s 237us/sample - loss: 51.2492 - mean_squared_error: 51.2492\n",
            "Epoch 200/1000\n",
            "404/404 [==============================] - 0s 239us/sample - loss: 52.5523 - mean_squared_error: 52.5523\n",
            "Epoch 201/1000\n",
            "404/404 [==============================] - 0s 227us/sample - loss: 57.4796 - mean_squared_error: 57.4797\n",
            "Epoch 202/1000\n",
            "404/404 [==============================] - 0s 219us/sample - loss: 52.7613 - mean_squared_error: 52.7613\n",
            "Epoch 203/1000\n",
            "404/404 [==============================] - 0s 226us/sample - loss: 49.1332 - mean_squared_error: 49.1332\n",
            "Epoch 204/1000\n",
            "404/404 [==============================] - 0s 239us/sample - loss: 52.0531 - mean_squared_error: 52.0531\n",
            "Epoch 205/1000\n",
            "404/404 [==============================] - 0s 232us/sample - loss: 46.7378 - mean_squared_error: 46.7378\n",
            "Epoch 206/1000\n",
            "404/404 [==============================] - 0s 240us/sample - loss: 44.7448 - mean_squared_error: 44.7448\n",
            "Epoch 207/1000\n",
            "404/404 [==============================] - 0s 248us/sample - loss: 49.2919 - mean_squared_error: 49.2919\n",
            "Epoch 208/1000\n",
            "404/404 [==============================] - 0s 249us/sample - loss: 50.8570 - mean_squared_error: 50.8570\n",
            "Epoch 209/1000\n",
            "404/404 [==============================] - 0s 227us/sample - loss: 45.8106 - mean_squared_error: 45.8106\n",
            "Epoch 210/1000\n",
            "404/404 [==============================] - 0s 235us/sample - loss: 48.6435 - mean_squared_error: 48.6435\n",
            "Epoch 211/1000\n",
            "404/404 [==============================] - 0s 228us/sample - loss: 48.6824 - mean_squared_error: 48.6824\n",
            "Epoch 212/1000\n",
            "404/404 [==============================] - 0s 234us/sample - loss: 58.9659 - mean_squared_error: 58.9659\n",
            "Epoch 213/1000\n",
            "404/404 [==============================] - 0s 248us/sample - loss: 44.3425 - mean_squared_error: 44.3425\n",
            "Epoch 214/1000\n",
            "404/404 [==============================] - 0s 234us/sample - loss: 56.7426 - mean_squared_error: 56.7426\n",
            "Epoch 215/1000\n",
            "404/404 [==============================] - 0s 234us/sample - loss: 43.6975 - mean_squared_error: 43.6975\n",
            "Epoch 216/1000\n",
            "404/404 [==============================] - 0s 228us/sample - loss: 48.9771 - mean_squared_error: 48.9771\n",
            "Epoch 217/1000\n",
            "404/404 [==============================] - 0s 231us/sample - loss: 52.9570 - mean_squared_error: 52.9570\n",
            "Epoch 218/1000\n",
            "404/404 [==============================] - 0s 237us/sample - loss: 54.5752 - mean_squared_error: 54.5752\n",
            "Epoch 219/1000\n",
            "404/404 [==============================] - 0s 233us/sample - loss: 48.3353 - mean_squared_error: 48.3353\n",
            "Epoch 220/1000\n",
            "404/404 [==============================] - 0s 249us/sample - loss: 54.1579 - mean_squared_error: 54.1579\n",
            "Epoch 221/1000\n",
            "404/404 [==============================] - 0s 234us/sample - loss: 48.7204 - mean_squared_error: 48.7204\n",
            "Epoch 222/1000\n",
            "404/404 [==============================] - 0s 235us/sample - loss: 50.2503 - mean_squared_error: 50.2503\n",
            "Epoch 223/1000\n",
            "404/404 [==============================] - 0s 231us/sample - loss: 47.0779 - mean_squared_error: 47.0779\n",
            "Epoch 224/1000\n",
            "404/404 [==============================] - 0s 245us/sample - loss: 47.4854 - mean_squared_error: 47.4854\n",
            "Epoch 225/1000\n",
            "404/404 [==============================] - 0s 252us/sample - loss: 51.4758 - mean_squared_error: 51.4758\n",
            "Epoch 226/1000\n",
            "404/404 [==============================] - 0s 230us/sample - loss: 54.8329 - mean_squared_error: 54.8329\n",
            "Epoch 227/1000\n",
            "404/404 [==============================] - 0s 238us/sample - loss: 48.7175 - mean_squared_error: 48.7175\n",
            "Epoch 228/1000\n",
            "404/404 [==============================] - 0s 239us/sample - loss: 44.4537 - mean_squared_error: 44.4537\n",
            "Epoch 229/1000\n",
            "404/404 [==============================] - 0s 234us/sample - loss: 46.1664 - mean_squared_error: 46.1664\n",
            "Epoch 230/1000\n",
            "404/404 [==============================] - 0s 220us/sample - loss: 52.8909 - mean_squared_error: 52.8909\n",
            "Epoch 231/1000\n",
            "404/404 [==============================] - 0s 238us/sample - loss: 48.0002 - mean_squared_error: 48.0002\n",
            "Epoch 232/1000\n",
            "404/404 [==============================] - 0s 241us/sample - loss: 47.6090 - mean_squared_error: 47.6090\n",
            "Epoch 233/1000\n",
            "404/404 [==============================] - 0s 224us/sample - loss: 53.0607 - mean_squared_error: 53.0607\n",
            "Epoch 234/1000\n",
            "404/404 [==============================] - 0s 223us/sample - loss: 52.0548 - mean_squared_error: 52.0548\n",
            "Epoch 235/1000\n",
            "404/404 [==============================] - 0s 229us/sample - loss: 49.5292 - mean_squared_error: 49.5292\n",
            "Epoch 236/1000\n",
            "404/404 [==============================] - 0s 254us/sample - loss: 54.2433 - mean_squared_error: 54.2433\n",
            "Epoch 237/1000\n",
            "404/404 [==============================] - 0s 240us/sample - loss: 48.8466 - mean_squared_error: 48.8466\n",
            "Epoch 238/1000\n",
            "404/404 [==============================] - 0s 240us/sample - loss: 48.3434 - mean_squared_error: 48.3434\n",
            "Epoch 239/1000\n",
            "404/404 [==============================] - 0s 239us/sample - loss: 49.4224 - mean_squared_error: 49.4223\n",
            "Epoch 240/1000\n",
            "404/404 [==============================] - 0s 249us/sample - loss: 43.3674 - mean_squared_error: 43.3674\n",
            "Epoch 241/1000\n",
            "404/404 [==============================] - 0s 227us/sample - loss: 49.9214 - mean_squared_error: 49.9214\n",
            "Epoch 242/1000\n",
            "404/404 [==============================] - 0s 233us/sample - loss: 45.9907 - mean_squared_error: 45.9907\n",
            "Epoch 243/1000\n",
            "404/404 [==============================] - 0s 233us/sample - loss: 45.9246 - mean_squared_error: 45.9246\n",
            "Epoch 244/1000\n",
            "404/404 [==============================] - 0s 235us/sample - loss: 57.4498 - mean_squared_error: 57.4498\n",
            "Epoch 245/1000\n",
            "404/404 [==============================] - 0s 264us/sample - loss: 55.2013 - mean_squared_error: 55.2013\n",
            "Epoch 246/1000\n",
            "404/404 [==============================] - 0s 250us/sample - loss: 45.2538 - mean_squared_error: 45.2538\n",
            "Epoch 247/1000\n",
            "404/404 [==============================] - 0s 235us/sample - loss: 50.1183 - mean_squared_error: 50.1183\n",
            "Epoch 248/1000\n",
            "404/404 [==============================] - 0s 243us/sample - loss: 47.4030 - mean_squared_error: 47.4030\n",
            "Epoch 249/1000\n",
            "404/404 [==============================] - 0s 232us/sample - loss: 46.3417 - mean_squared_error: 46.3417\n",
            "Epoch 250/1000\n",
            "404/404 [==============================] - 0s 237us/sample - loss: 44.2280 - mean_squared_error: 44.2280\n",
            "Epoch 251/1000\n",
            "404/404 [==============================] - 0s 243us/sample - loss: 45.0768 - mean_squared_error: 45.0768\n",
            "Epoch 252/1000\n",
            "404/404 [==============================] - 0s 242us/sample - loss: 52.0713 - mean_squared_error: 52.0713\n",
            "Epoch 253/1000\n",
            "404/404 [==============================] - 0s 255us/sample - loss: 52.2880 - mean_squared_error: 52.2880\n",
            "Epoch 254/1000\n",
            "404/404 [==============================] - 0s 240us/sample - loss: 48.0046 - mean_squared_error: 48.0046\n",
            "Epoch 255/1000\n",
            "404/404 [==============================] - 0s 225us/sample - loss: 51.9922 - mean_squared_error: 51.9922\n",
            "Epoch 256/1000\n",
            "404/404 [==============================] - 0s 233us/sample - loss: 44.9077 - mean_squared_error: 44.9077\n",
            "Epoch 257/1000\n",
            "404/404 [==============================] - 0s 254us/sample - loss: 48.1544 - mean_squared_error: 48.1545\n",
            "Epoch 258/1000\n",
            "404/404 [==============================] - 0s 248us/sample - loss: 53.0840 - mean_squared_error: 53.0840\n",
            "Epoch 259/1000\n",
            "404/404 [==============================] - 0s 227us/sample - loss: 40.7651 - mean_squared_error: 40.7651\n",
            "Epoch 260/1000\n",
            "404/404 [==============================] - 0s 228us/sample - loss: 51.9517 - mean_squared_error: 51.9517\n",
            "Epoch 261/1000\n",
            "404/404 [==============================] - 0s 218us/sample - loss: 50.6136 - mean_squared_error: 50.6136\n",
            "Epoch 262/1000\n",
            "404/404 [==============================] - 0s 229us/sample - loss: 47.9402 - mean_squared_error: 47.9402\n",
            "Epoch 263/1000\n",
            "404/404 [==============================] - 0s 241us/sample - loss: 52.2618 - mean_squared_error: 52.2618\n",
            "Epoch 264/1000\n",
            "404/404 [==============================] - 0s 229us/sample - loss: 48.0501 - mean_squared_error: 48.0501\n",
            "Epoch 265/1000\n",
            "404/404 [==============================] - 0s 224us/sample - loss: 44.0231 - mean_squared_error: 44.0231\n",
            "Epoch 266/1000\n",
            "404/404 [==============================] - 0s 243us/sample - loss: 53.4705 - mean_squared_error: 53.4705\n",
            "Epoch 267/1000\n",
            "404/404 [==============================] - 0s 244us/sample - loss: 56.2969 - mean_squared_error: 56.2969\n",
            "Epoch 268/1000\n",
            "404/404 [==============================] - 0s 227us/sample - loss: 54.8416 - mean_squared_error: 54.8416\n",
            "Epoch 269/1000\n",
            "404/404 [==============================] - 0s 224us/sample - loss: 48.1445 - mean_squared_error: 48.1445\n",
            "Epoch 270/1000\n",
            "404/404 [==============================] - 0s 236us/sample - loss: 47.0955 - mean_squared_error: 47.0955\n",
            "Epoch 271/1000\n",
            "404/404 [==============================] - 0s 236us/sample - loss: 50.3383 - mean_squared_error: 50.3383\n",
            "Epoch 272/1000\n",
            "404/404 [==============================] - 0s 242us/sample - loss: 51.9470 - mean_squared_error: 51.9470\n",
            "Epoch 273/1000\n",
            "404/404 [==============================] - 0s 232us/sample - loss: 45.0317 - mean_squared_error: 45.0317\n",
            "Epoch 274/1000\n",
            "404/404 [==============================] - 0s 241us/sample - loss: 51.7179 - mean_squared_error: 51.7179\n",
            "Epoch 275/1000\n",
            "404/404 [==============================] - 0s 247us/sample - loss: 48.6484 - mean_squared_error: 48.6484\n",
            "Epoch 276/1000\n",
            "404/404 [==============================] - 0s 229us/sample - loss: 43.2079 - mean_squared_error: 43.2079\n",
            "Epoch 277/1000\n",
            "404/404 [==============================] - 0s 238us/sample - loss: 64.8256 - mean_squared_error: 64.8256\n",
            "Epoch 278/1000\n",
            "404/404 [==============================] - 0s 246us/sample - loss: 47.6923 - mean_squared_error: 47.6923\n",
            "Epoch 279/1000\n",
            "404/404 [==============================] - 0s 232us/sample - loss: 56.8865 - mean_squared_error: 56.8865\n",
            "Epoch 280/1000\n",
            "404/404 [==============================] - 0s 246us/sample - loss: 49.6093 - mean_squared_error: 49.6093\n",
            "Epoch 281/1000\n",
            "404/404 [==============================] - 0s 230us/sample - loss: 44.0632 - mean_squared_error: 44.0632\n",
            "Epoch 282/1000\n",
            "404/404 [==============================] - 0s 222us/sample - loss: 45.9734 - mean_squared_error: 45.9734\n",
            "Epoch 283/1000\n",
            "404/404 [==============================] - 0s 250us/sample - loss: 57.5924 - mean_squared_error: 57.5924\n",
            "Epoch 284/1000\n",
            "404/404 [==============================] - 0s 241us/sample - loss: 46.8788 - mean_squared_error: 46.8788\n",
            "Epoch 285/1000\n",
            "404/404 [==============================] - 0s 231us/sample - loss: 48.0721 - mean_squared_error: 48.0721\n",
            "Epoch 286/1000\n",
            "404/404 [==============================] - 0s 232us/sample - loss: 45.8542 - mean_squared_error: 45.8542\n",
            "Epoch 287/1000\n",
            "404/404 [==============================] - 0s 243us/sample - loss: 43.9593 - mean_squared_error: 43.9593\n",
            "Epoch 288/1000\n",
            "404/404 [==============================] - 0s 235us/sample - loss: 50.4234 - mean_squared_error: 50.4234\n",
            "Epoch 289/1000\n",
            "404/404 [==============================] - 0s 232us/sample - loss: 44.5190 - mean_squared_error: 44.5190\n",
            "Epoch 290/1000\n",
            "404/404 [==============================] - 0s 222us/sample - loss: 48.1542 - mean_squared_error: 48.1542\n",
            "Epoch 291/1000\n",
            "404/404 [==============================] - 0s 228us/sample - loss: 48.2630 - mean_squared_error: 48.2630\n",
            "Epoch 292/1000\n",
            "404/404 [==============================] - 0s 223us/sample - loss: 44.0878 - mean_squared_error: 44.0878\n",
            "Epoch 293/1000\n",
            "404/404 [==============================] - 0s 236us/sample - loss: 46.9395 - mean_squared_error: 46.9395\n",
            "Epoch 294/1000\n",
            "404/404 [==============================] - 0s 235us/sample - loss: 50.5887 - mean_squared_error: 50.5887\n",
            "Epoch 295/1000\n",
            "404/404 [==============================] - 0s 231us/sample - loss: 46.6538 - mean_squared_error: 46.6538\n",
            "Epoch 296/1000\n",
            "404/404 [==============================] - 0s 261us/sample - loss: 41.9275 - mean_squared_error: 41.9275\n",
            "Epoch 297/1000\n",
            "404/404 [==============================] - 0s 239us/sample - loss: 43.2144 - mean_squared_error: 43.2144\n",
            "Epoch 298/1000\n",
            "404/404 [==============================] - 0s 249us/sample - loss: 43.6704 - mean_squared_error: 43.6704\n",
            "Epoch 299/1000\n",
            "404/404 [==============================] - 0s 242us/sample - loss: 42.5678 - mean_squared_error: 42.5678\n",
            "Epoch 300/1000\n",
            "404/404 [==============================] - 0s 253us/sample - loss: 46.5305 - mean_squared_error: 46.5305\n",
            "Epoch 301/1000\n",
            "404/404 [==============================] - 0s 253us/sample - loss: 40.2945 - mean_squared_error: 40.2945\n",
            "Epoch 302/1000\n",
            "404/404 [==============================] - 0s 232us/sample - loss: 49.5712 - mean_squared_error: 49.5713\n",
            "Epoch 303/1000\n",
            "404/404 [==============================] - 0s 273us/sample - loss: 48.8884 - mean_squared_error: 48.8885\n",
            "Epoch 304/1000\n",
            "404/404 [==============================] - 0s 227us/sample - loss: 41.3005 - mean_squared_error: 41.3005\n",
            "Epoch 305/1000\n",
            "404/404 [==============================] - 0s 243us/sample - loss: 46.7673 - mean_squared_error: 46.7674\n",
            "Epoch 306/1000\n",
            "404/404 [==============================] - 0s 286us/sample - loss: 55.0219 - mean_squared_error: 55.0219\n",
            "Epoch 307/1000\n",
            "404/404 [==============================] - 0s 261us/sample - loss: 39.2193 - mean_squared_error: 39.2193\n",
            "Epoch 308/1000\n",
            "404/404 [==============================] - 0s 244us/sample - loss: 43.9036 - mean_squared_error: 43.9036\n",
            "Epoch 309/1000\n",
            "404/404 [==============================] - 0s 235us/sample - loss: 41.2683 - mean_squared_error: 41.2682\n",
            "Epoch 310/1000\n",
            "404/404 [==============================] - 0s 236us/sample - loss: 43.1615 - mean_squared_error: 43.1615\n",
            "Epoch 311/1000\n",
            "404/404 [==============================] - 0s 230us/sample - loss: 46.1441 - mean_squared_error: 46.1441\n",
            "Epoch 312/1000\n",
            "404/404 [==============================] - 0s 242us/sample - loss: 42.7381 - mean_squared_error: 42.7381\n",
            "Epoch 313/1000\n",
            "404/404 [==============================] - 0s 235us/sample - loss: 47.8577 - mean_squared_error: 47.8577\n",
            "Epoch 314/1000\n",
            "404/404 [==============================] - 0s 261us/sample - loss: 50.4127 - mean_squared_error: 50.4127\n",
            "Epoch 315/1000\n",
            "404/404 [==============================] - 0s 234us/sample - loss: 51.7080 - mean_squared_error: 51.7080\n",
            "Epoch 316/1000\n",
            "404/404 [==============================] - 0s 246us/sample - loss: 44.5074 - mean_squared_error: 44.5074\n",
            "Epoch 317/1000\n",
            "404/404 [==============================] - 0s 252us/sample - loss: 51.6698 - mean_squared_error: 51.6698\n",
            "Epoch 318/1000\n",
            "404/404 [==============================] - 0s 240us/sample - loss: 45.2486 - mean_squared_error: 45.2486\n",
            "Epoch 319/1000\n",
            "404/404 [==============================] - 0s 217us/sample - loss: 53.4512 - mean_squared_error: 53.4512\n",
            "Epoch 320/1000\n",
            "404/404 [==============================] - 0s 235us/sample - loss: 51.7142 - mean_squared_error: 51.7142\n",
            "Epoch 321/1000\n",
            "404/404 [==============================] - 0s 239us/sample - loss: 43.2375 - mean_squared_error: 43.2375\n",
            "Epoch 322/1000\n",
            "404/404 [==============================] - 0s 224us/sample - loss: 45.1478 - mean_squared_error: 45.1478\n",
            "Epoch 323/1000\n",
            "404/404 [==============================] - 0s 239us/sample - loss: 46.3569 - mean_squared_error: 46.3569\n",
            "Epoch 324/1000\n",
            "404/404 [==============================] - 0s 237us/sample - loss: 36.8745 - mean_squared_error: 36.8745\n",
            "Epoch 325/1000\n",
            "404/404 [==============================] - 0s 249us/sample - loss: 47.7429 - mean_squared_error: 47.7429\n",
            "Epoch 326/1000\n",
            "404/404 [==============================] - 0s 224us/sample - loss: 43.9850 - mean_squared_error: 43.9850\n",
            "Epoch 327/1000\n",
            "404/404 [==============================] - 0s 237us/sample - loss: 46.6745 - mean_squared_error: 46.6745\n",
            "Epoch 328/1000\n",
            "404/404 [==============================] - 0s 231us/sample - loss: 45.8796 - mean_squared_error: 45.8796\n",
            "Epoch 329/1000\n",
            "404/404 [==============================] - 0s 232us/sample - loss: 41.6749 - mean_squared_error: 41.6749\n",
            "Epoch 330/1000\n",
            "404/404 [==============================] - 0s 242us/sample - loss: 43.9416 - mean_squared_error: 43.9416\n",
            "Epoch 331/1000\n",
            "404/404 [==============================] - 0s 227us/sample - loss: 42.6739 - mean_squared_error: 42.6738\n",
            "Epoch 332/1000\n",
            "404/404 [==============================] - 0s 222us/sample - loss: 43.0649 - mean_squared_error: 43.0649\n",
            "Epoch 333/1000\n",
            "404/404 [==============================] - 0s 237us/sample - loss: 53.8986 - mean_squared_error: 53.8986\n",
            "Epoch 334/1000\n",
            "404/404 [==============================] - 0s 224us/sample - loss: 49.9026 - mean_squared_error: 49.9026\n",
            "Epoch 335/1000\n",
            "404/404 [==============================] - 0s 242us/sample - loss: 44.9165 - mean_squared_error: 44.9165\n",
            "Epoch 336/1000\n",
            "404/404 [==============================] - 0s 261us/sample - loss: 42.9212 - mean_squared_error: 42.9212\n",
            "Epoch 337/1000\n",
            "404/404 [==============================] - 0s 243us/sample - loss: 41.7574 - mean_squared_error: 41.7573\n",
            "Epoch 338/1000\n",
            "404/404 [==============================] - 0s 234us/sample - loss: 46.3861 - mean_squared_error: 46.3861\n",
            "Epoch 339/1000\n",
            "404/404 [==============================] - 0s 227us/sample - loss: 43.9547 - mean_squared_error: 43.9547\n",
            "Epoch 340/1000\n",
            "404/404 [==============================] - 0s 238us/sample - loss: 47.9973 - mean_squared_error: 47.9973\n",
            "Epoch 341/1000\n",
            "404/404 [==============================] - 0s 218us/sample - loss: 41.5904 - mean_squared_error: 41.5904\n",
            "Epoch 342/1000\n",
            "404/404 [==============================] - 0s 237us/sample - loss: 50.3369 - mean_squared_error: 50.3369\n",
            "Epoch 343/1000\n",
            "404/404 [==============================] - 0s 223us/sample - loss: 49.7489 - mean_squared_error: 49.7489\n",
            "Epoch 344/1000\n",
            "404/404 [==============================] - 0s 241us/sample - loss: 44.0561 - mean_squared_error: 44.0561\n",
            "Epoch 345/1000\n",
            "404/404 [==============================] - 0s 241us/sample - loss: 46.5823 - mean_squared_error: 46.5823\n",
            "Epoch 346/1000\n",
            "404/404 [==============================] - 0s 241us/sample - loss: 45.9662 - mean_squared_error: 45.9662\n",
            "Epoch 347/1000\n",
            "404/404 [==============================] - 0s 241us/sample - loss: 40.0140 - mean_squared_error: 40.0140\n",
            "Epoch 348/1000\n",
            "404/404 [==============================] - 0s 240us/sample - loss: 39.3557 - mean_squared_error: 39.3557\n",
            "Epoch 349/1000\n",
            "404/404 [==============================] - 0s 242us/sample - loss: 46.5337 - mean_squared_error: 46.5337\n",
            "Epoch 350/1000\n",
            "404/404 [==============================] - 0s 231us/sample - loss: 43.4556 - mean_squared_error: 43.4556\n",
            "Epoch 351/1000\n",
            "404/404 [==============================] - 0s 233us/sample - loss: 50.1391 - mean_squared_error: 50.1391\n",
            "Epoch 352/1000\n",
            "404/404 [==============================] - 0s 238us/sample - loss: 49.2787 - mean_squared_error: 49.2787\n",
            "Epoch 353/1000\n",
            "404/404 [==============================] - 0s 233us/sample - loss: 47.3236 - mean_squared_error: 47.3236\n",
            "Epoch 354/1000\n",
            "404/404 [==============================] - 0s 218us/sample - loss: 42.6279 - mean_squared_error: 42.6279\n",
            "Epoch 355/1000\n",
            "404/404 [==============================] - 0s 231us/sample - loss: 41.6163 - mean_squared_error: 41.6163\n",
            "Epoch 356/1000\n",
            "404/404 [==============================] - 0s 251us/sample - loss: 41.3007 - mean_squared_error: 41.3007\n",
            "Epoch 357/1000\n",
            "404/404 [==============================] - 0s 243us/sample - loss: 49.7934 - mean_squared_error: 49.7934\n",
            "Epoch 358/1000\n",
            "404/404 [==============================] - 0s 228us/sample - loss: 45.7882 - mean_squared_error: 45.7882\n",
            "Epoch 359/1000\n",
            "404/404 [==============================] - 0s 225us/sample - loss: 42.5431 - mean_squared_error: 42.5431\n",
            "Epoch 360/1000\n",
            "404/404 [==============================] - 0s 239us/sample - loss: 43.1450 - mean_squared_error: 43.1450\n",
            "Epoch 361/1000\n",
            "404/404 [==============================] - 0s 250us/sample - loss: 45.8670 - mean_squared_error: 45.8670\n",
            "Epoch 362/1000\n",
            "404/404 [==============================] - 0s 228us/sample - loss: 50.3586 - mean_squared_error: 50.3586\n",
            "Epoch 363/1000\n",
            "404/404 [==============================] - 0s 219us/sample - loss: 50.3466 - mean_squared_error: 50.3466\n",
            "Epoch 364/1000\n",
            "404/404 [==============================] - 0s 232us/sample - loss: 43.0791 - mean_squared_error: 43.0791\n",
            "Epoch 365/1000\n",
            "404/404 [==============================] - 0s 228us/sample - loss: 48.7288 - mean_squared_error: 48.7288\n",
            "Epoch 366/1000\n",
            "404/404 [==============================] - 0s 221us/sample - loss: 44.6344 - mean_squared_error: 44.6344\n",
            "Epoch 367/1000\n",
            "404/404 [==============================] - 0s 227us/sample - loss: 41.8031 - mean_squared_error: 41.8031\n",
            "Epoch 368/1000\n",
            "404/404 [==============================] - 0s 229us/sample - loss: 43.9427 - mean_squared_error: 43.9427\n",
            "Epoch 369/1000\n",
            "404/404 [==============================] - 0s 233us/sample - loss: 47.4155 - mean_squared_error: 47.4155\n",
            "Epoch 370/1000\n",
            "404/404 [==============================] - 0s 249us/sample - loss: 44.5846 - mean_squared_error: 44.5846\n",
            "Epoch 371/1000\n",
            "404/404 [==============================] - 0s 226us/sample - loss: 36.9685 - mean_squared_error: 36.9685\n",
            "Epoch 372/1000\n",
            "404/404 [==============================] - 0s 240us/sample - loss: 40.0807 - mean_squared_error: 40.0807\n",
            "Epoch 373/1000\n",
            "404/404 [==============================] - 0s 219us/sample - loss: 44.9962 - mean_squared_error: 44.9962\n",
            "Epoch 374/1000\n",
            "404/404 [==============================] - 0s 235us/sample - loss: 48.4821 - mean_squared_error: 48.4821\n",
            "Epoch 375/1000\n",
            "404/404 [==============================] - 0s 236us/sample - loss: 47.1257 - mean_squared_error: 47.1257\n",
            "Epoch 376/1000\n",
            "404/404 [==============================] - 0s 220us/sample - loss: 42.8705 - mean_squared_error: 42.8705\n",
            "Epoch 377/1000\n",
            "404/404 [==============================] - 0s 248us/sample - loss: 50.6119 - mean_squared_error: 50.6119\n",
            "Epoch 378/1000\n",
            "404/404 [==============================] - 0s 285us/sample - loss: 41.7418 - mean_squared_error: 41.7418\n",
            "Epoch 379/1000\n",
            "404/404 [==============================] - 0s 263us/sample - loss: 43.0757 - mean_squared_error: 43.0757\n",
            "Epoch 380/1000\n",
            "404/404 [==============================] - 0s 242us/sample - loss: 45.8062 - mean_squared_error: 45.8062\n",
            "Epoch 381/1000\n",
            "404/404 [==============================] - 0s 239us/sample - loss: 40.3383 - mean_squared_error: 40.3383\n",
            "Epoch 382/1000\n",
            "404/404 [==============================] - 0s 243us/sample - loss: 40.4314 - mean_squared_error: 40.4314\n",
            "Epoch 383/1000\n",
            "404/404 [==============================] - 0s 235us/sample - loss: 53.4253 - mean_squared_error: 53.4253\n",
            "Epoch 384/1000\n",
            "404/404 [==============================] - 0s 236us/sample - loss: 43.9655 - mean_squared_error: 43.9655\n",
            "Epoch 385/1000\n",
            "404/404 [==============================] - 0s 239us/sample - loss: 43.7549 - mean_squared_error: 43.7549\n",
            "Epoch 386/1000\n",
            "404/404 [==============================] - 0s 258us/sample - loss: 40.9446 - mean_squared_error: 40.9446\n",
            "Epoch 387/1000\n",
            "404/404 [==============================] - 0s 229us/sample - loss: 42.7621 - mean_squared_error: 42.7621\n",
            "Epoch 388/1000\n",
            "404/404 [==============================] - 0s 227us/sample - loss: 45.0213 - mean_squared_error: 45.0213\n",
            "Epoch 389/1000\n",
            "404/404 [==============================] - 0s 225us/sample - loss: 46.0757 - mean_squared_error: 46.0757\n",
            "Epoch 390/1000\n",
            "404/404 [==============================] - 0s 235us/sample - loss: 40.3580 - mean_squared_error: 40.3580\n",
            "Epoch 391/1000\n",
            "404/404 [==============================] - 0s 238us/sample - loss: 43.5518 - mean_squared_error: 43.5518\n",
            "Epoch 392/1000\n",
            "404/404 [==============================] - 0s 233us/sample - loss: 42.7757 - mean_squared_error: 42.7757\n",
            "Epoch 393/1000\n",
            "404/404 [==============================] - 0s 229us/sample - loss: 47.2572 - mean_squared_error: 47.2572\n",
            "Epoch 394/1000\n",
            "404/404 [==============================] - 0s 231us/sample - loss: 37.2826 - mean_squared_error: 37.2826\n",
            "Epoch 395/1000\n",
            "404/404 [==============================] - 0s 242us/sample - loss: 49.1708 - mean_squared_error: 49.1709\n",
            "Epoch 396/1000\n",
            "404/404 [==============================] - 0s 240us/sample - loss: 44.0842 - mean_squared_error: 44.0842\n",
            "Epoch 397/1000\n",
            "404/404 [==============================] - 0s 235us/sample - loss: 46.0485 - mean_squared_error: 46.0485\n",
            "Epoch 398/1000\n",
            "404/404 [==============================] - 0s 237us/sample - loss: 47.3209 - mean_squared_error: 47.3209\n",
            "Epoch 399/1000\n",
            "404/404 [==============================] - 0s 246us/sample - loss: 44.5638 - mean_squared_error: 44.5638\n",
            "Epoch 400/1000\n",
            "404/404 [==============================] - 0s 226us/sample - loss: 43.5782 - mean_squared_error: 43.5782\n",
            "Epoch 401/1000\n",
            "404/404 [==============================] - 0s 229us/sample - loss: 45.0156 - mean_squared_error: 45.0156\n",
            "Epoch 402/1000\n",
            "404/404 [==============================] - 0s 222us/sample - loss: 40.4369 - mean_squared_error: 40.4369\n",
            "Epoch 403/1000\n",
            "404/404 [==============================] - 0s 233us/sample - loss: 40.1341 - mean_squared_error: 40.1341\n",
            "Epoch 404/1000\n",
            "404/404 [==============================] - 0s 235us/sample - loss: 48.6587 - mean_squared_error: 48.6587\n",
            "Epoch 405/1000\n",
            "404/404 [==============================] - 0s 244us/sample - loss: 47.5206 - mean_squared_error: 47.5206\n",
            "Epoch 406/1000\n",
            "404/404 [==============================] - 0s 225us/sample - loss: 41.5139 - mean_squared_error: 41.5139\n",
            "Epoch 407/1000\n",
            "404/404 [==============================] - 0s 251us/sample - loss: 49.2861 - mean_squared_error: 49.2861\n",
            "Epoch 408/1000\n",
            "404/404 [==============================] - 0s 242us/sample - loss: 45.7499 - mean_squared_error: 45.7499\n",
            "Epoch 409/1000\n",
            "404/404 [==============================] - 0s 251us/sample - loss: 47.3156 - mean_squared_error: 47.3156\n",
            "Epoch 410/1000\n",
            "404/404 [==============================] - 0s 221us/sample - loss: 48.4118 - mean_squared_error: 48.4118\n",
            "Epoch 411/1000\n",
            "404/404 [==============================] - 0s 233us/sample - loss: 43.1457 - mean_squared_error: 43.1457\n",
            "Epoch 412/1000\n",
            "404/404 [==============================] - 0s 223us/sample - loss: 51.8292 - mean_squared_error: 51.8292\n",
            "Epoch 413/1000\n",
            "404/404 [==============================] - 0s 225us/sample - loss: 38.8508 - mean_squared_error: 38.8508\n",
            "Epoch 414/1000\n",
            "404/404 [==============================] - 0s 224us/sample - loss: 50.3313 - mean_squared_error: 50.3313\n",
            "Epoch 415/1000\n",
            "404/404 [==============================] - 0s 236us/sample - loss: 50.1601 - mean_squared_error: 50.1601\n",
            "Epoch 416/1000\n",
            "404/404 [==============================] - 0s 237us/sample - loss: 44.4116 - mean_squared_error: 44.4116\n",
            "Epoch 417/1000\n",
            "404/404 [==============================] - 0s 241us/sample - loss: 48.7308 - mean_squared_error: 48.7308\n",
            "Epoch 418/1000\n",
            "404/404 [==============================] - 0s 248us/sample - loss: 44.4298 - mean_squared_error: 44.4298\n",
            "Epoch 419/1000\n",
            "404/404 [==============================] - 0s 245us/sample - loss: 38.4495 - mean_squared_error: 38.4495\n",
            "Epoch 420/1000\n",
            "404/404 [==============================] - 0s 225us/sample - loss: 44.7059 - mean_squared_error: 44.7059\n",
            "Epoch 421/1000\n",
            "404/404 [==============================] - 0s 228us/sample - loss: 47.1213 - mean_squared_error: 47.1213\n",
            "Epoch 422/1000\n",
            "404/404 [==============================] - 0s 235us/sample - loss: 37.7695 - mean_squared_error: 37.7695\n",
            "Epoch 423/1000\n",
            "404/404 [==============================] - 0s 216us/sample - loss: 38.7571 - mean_squared_error: 38.7571\n",
            "Epoch 424/1000\n",
            "404/404 [==============================] - 0s 233us/sample - loss: 49.8894 - mean_squared_error: 49.8894\n",
            "Epoch 425/1000\n",
            "404/404 [==============================] - 0s 228us/sample - loss: 52.6311 - mean_squared_error: 52.6311\n",
            "Epoch 426/1000\n",
            "404/404 [==============================] - 0s 242us/sample - loss: 47.2135 - mean_squared_error: 47.2135\n",
            "Epoch 427/1000\n",
            "404/404 [==============================] - 0s 242us/sample - loss: 42.5307 - mean_squared_error: 42.5307\n",
            "Epoch 428/1000\n",
            "404/404 [==============================] - 0s 231us/sample - loss: 46.8158 - mean_squared_error: 46.8158\n",
            "Epoch 429/1000\n",
            "404/404 [==============================] - 0s 262us/sample - loss: 44.6306 - mean_squared_error: 44.6306\n",
            "Epoch 430/1000\n",
            "404/404 [==============================] - 0s 235us/sample - loss: 49.1148 - mean_squared_error: 49.1148\n",
            "Epoch 431/1000\n",
            "404/404 [==============================] - 0s 234us/sample - loss: 37.8017 - mean_squared_error: 37.8017\n",
            "Epoch 432/1000\n",
            "404/404 [==============================] - 0s 231us/sample - loss: 40.6169 - mean_squared_error: 40.6169\n",
            "Epoch 433/1000\n",
            "404/404 [==============================] - 0s 229us/sample - loss: 37.5167 - mean_squared_error: 37.5167\n",
            "Epoch 434/1000\n",
            "404/404 [==============================] - 0s 231us/sample - loss: 37.4257 - mean_squared_error: 37.4257\n",
            "Epoch 435/1000\n",
            "404/404 [==============================] - 0s 245us/sample - loss: 46.3656 - mean_squared_error: 46.3656\n",
            "Epoch 436/1000\n",
            "404/404 [==============================] - 0s 244us/sample - loss: 44.5203 - mean_squared_error: 44.5203\n",
            "Epoch 437/1000\n",
            "404/404 [==============================] - 0s 244us/sample - loss: 39.5817 - mean_squared_error: 39.5817\n",
            "Epoch 438/1000\n",
            "404/404 [==============================] - 0s 223us/sample - loss: 41.0064 - mean_squared_error: 41.0064\n",
            "Epoch 439/1000\n",
            "404/404 [==============================] - 0s 238us/sample - loss: 38.8037 - mean_squared_error: 38.8036\n",
            "Epoch 440/1000\n",
            "404/404 [==============================] - 0s 236us/sample - loss: 43.3637 - mean_squared_error: 43.3637\n",
            "Epoch 441/1000\n",
            "404/404 [==============================] - 0s 233us/sample - loss: 35.0801 - mean_squared_error: 35.0801\n",
            "Epoch 442/1000\n",
            "404/404 [==============================] - 0s 230us/sample - loss: 40.3430 - mean_squared_error: 40.3430\n",
            "Epoch 443/1000\n",
            "404/404 [==============================] - 0s 230us/sample - loss: 39.6456 - mean_squared_error: 39.6456\n",
            "Epoch 444/1000\n",
            "404/404 [==============================] - 0s 236us/sample - loss: 41.9728 - mean_squared_error: 41.9728\n",
            "Epoch 445/1000\n",
            "404/404 [==============================] - 0s 229us/sample - loss: 39.0107 - mean_squared_error: 39.0107\n",
            "Epoch 446/1000\n",
            "404/404 [==============================] - 0s 231us/sample - loss: 47.0923 - mean_squared_error: 47.0923\n",
            "Epoch 447/1000\n",
            "404/404 [==============================] - 0s 228us/sample - loss: 44.0680 - mean_squared_error: 44.0680\n",
            "Epoch 448/1000\n",
            "404/404 [==============================] - 0s 223us/sample - loss: 44.3761 - mean_squared_error: 44.3761\n",
            "Epoch 449/1000\n",
            "404/404 [==============================] - 0s 214us/sample - loss: 40.7005 - mean_squared_error: 40.7005\n",
            "Epoch 450/1000\n",
            "404/404 [==============================] - 0s 227us/sample - loss: 45.3192 - mean_squared_error: 45.3192\n",
            "Epoch 451/1000\n",
            "404/404 [==============================] - 0s 241us/sample - loss: 44.8525 - mean_squared_error: 44.8525\n",
            "Epoch 452/1000\n",
            "404/404 [==============================] - 0s 236us/sample - loss: 48.7842 - mean_squared_error: 48.7842\n",
            "Epoch 453/1000\n",
            "404/404 [==============================] - 0s 219us/sample - loss: 42.6259 - mean_squared_error: 42.6259\n",
            "Epoch 454/1000\n",
            "404/404 [==============================] - 0s 226us/sample - loss: 41.6381 - mean_squared_error: 41.6381\n",
            "Epoch 455/1000\n",
            "404/404 [==============================] - 0s 221us/sample - loss: 40.6039 - mean_squared_error: 40.6039\n",
            "Epoch 456/1000\n",
            "404/404 [==============================] - 0s 218us/sample - loss: 37.0450 - mean_squared_error: 37.0450\n",
            "Epoch 457/1000\n",
            "404/404 [==============================] - 0s 230us/sample - loss: 38.1196 - mean_squared_error: 38.1196\n",
            "Epoch 458/1000\n",
            "404/404 [==============================] - 0s 230us/sample - loss: 41.0148 - mean_squared_error: 41.0148\n",
            "Epoch 459/1000\n",
            "404/404 [==============================] - 0s 217us/sample - loss: 48.8905 - mean_squared_error: 48.8904\n",
            "Epoch 460/1000\n",
            "404/404 [==============================] - 0s 234us/sample - loss: 37.5859 - mean_squared_error: 37.5859\n",
            "Epoch 461/1000\n",
            "404/404 [==============================] - 0s 244us/sample - loss: 49.9257 - mean_squared_error: 49.9257\n",
            "Epoch 462/1000\n",
            "404/404 [==============================] - 0s 236us/sample - loss: 29.8020 - mean_squared_error: 29.8019\n",
            "Epoch 463/1000\n",
            "404/404 [==============================] - 0s 229us/sample - loss: 42.1052 - mean_squared_error: 42.1052\n",
            "Epoch 464/1000\n",
            "404/404 [==============================] - 0s 229us/sample - loss: 38.4343 - mean_squared_error: 38.4342\n",
            "Epoch 465/1000\n",
            "404/404 [==============================] - 0s 240us/sample - loss: 48.9279 - mean_squared_error: 48.9279\n",
            "Epoch 466/1000\n",
            "404/404 [==============================] - 0s 241us/sample - loss: 38.3901 - mean_squared_error: 38.3901\n",
            "Epoch 467/1000\n",
            "404/404 [==============================] - 0s 224us/sample - loss: 34.6050 - mean_squared_error: 34.6050\n",
            "Epoch 468/1000\n",
            "404/404 [==============================] - 0s 235us/sample - loss: 47.9305 - mean_squared_error: 47.9305\n",
            "Epoch 469/1000\n",
            "404/404 [==============================] - 0s 232us/sample - loss: 36.0566 - mean_squared_error: 36.0567\n",
            "Epoch 470/1000\n",
            "404/404 [==============================] - 0s 217us/sample - loss: 44.0052 - mean_squared_error: 44.0052\n",
            "Epoch 471/1000\n",
            "404/404 [==============================] - 0s 220us/sample - loss: 41.3554 - mean_squared_error: 41.3554\n",
            "Epoch 472/1000\n",
            "404/404 [==============================] - 0s 218us/sample - loss: 45.8604 - mean_squared_error: 45.8604\n",
            "Epoch 473/1000\n",
            "404/404 [==============================] - 0s 224us/sample - loss: 37.2819 - mean_squared_error: 37.2819\n",
            "Epoch 474/1000\n",
            "404/404 [==============================] - 0s 231us/sample - loss: 40.4514 - mean_squared_error: 40.4514\n",
            "Epoch 475/1000\n",
            "404/404 [==============================] - 0s 236us/sample - loss: 44.1873 - mean_squared_error: 44.1873\n",
            "Epoch 476/1000\n",
            "404/404 [==============================] - 0s 236us/sample - loss: 41.7450 - mean_squared_error: 41.7450\n",
            "Epoch 477/1000\n",
            "404/404 [==============================] - 0s 238us/sample - loss: 42.1309 - mean_squared_error: 42.1309\n",
            "Epoch 478/1000\n",
            "404/404 [==============================] - 0s 227us/sample - loss: 44.1454 - mean_squared_error: 44.1454\n",
            "Epoch 479/1000\n",
            "404/404 [==============================] - 0s 222us/sample - loss: 36.1519 - mean_squared_error: 36.1519\n",
            "Epoch 480/1000\n",
            "404/404 [==============================] - 0s 222us/sample - loss: 40.4360 - mean_squared_error: 40.4360\n",
            "Epoch 481/1000\n",
            "404/404 [==============================] - 0s 219us/sample - loss: 43.9939 - mean_squared_error: 43.9939\n",
            "Epoch 482/1000\n",
            "404/404 [==============================] - 0s 221us/sample - loss: 39.1031 - mean_squared_error: 39.1031\n",
            "Epoch 483/1000\n",
            "404/404 [==============================] - 0s 227us/sample - loss: 42.6117 - mean_squared_error: 42.6117\n",
            "Epoch 484/1000\n",
            "404/404 [==============================] - 0s 240us/sample - loss: 40.1713 - mean_squared_error: 40.1713\n",
            "Epoch 485/1000\n",
            "404/404 [==============================] - 0s 237us/sample - loss: 42.1366 - mean_squared_error: 42.1366\n",
            "Epoch 486/1000\n",
            "404/404 [==============================] - 0s 243us/sample - loss: 42.7441 - mean_squared_error: 42.7441\n",
            "Epoch 487/1000\n",
            "404/404 [==============================] - 0s 244us/sample - loss: 42.2531 - mean_squared_error: 42.2531\n",
            "Epoch 488/1000\n",
            "404/404 [==============================] - 0s 229us/sample - loss: 39.0333 - mean_squared_error: 39.0333\n",
            "Epoch 489/1000\n",
            "404/404 [==============================] - 0s 230us/sample - loss: 45.9976 - mean_squared_error: 45.9976\n",
            "Epoch 490/1000\n",
            "404/404 [==============================] - 0s 227us/sample - loss: 40.1414 - mean_squared_error: 40.1414\n",
            "Epoch 491/1000\n",
            "404/404 [==============================] - 0s 226us/sample - loss: 38.9045 - mean_squared_error: 38.9045\n",
            "Epoch 492/1000\n",
            "404/404 [==============================] - 0s 214us/sample - loss: 38.5856 - mean_squared_error: 38.5856\n",
            "Epoch 493/1000\n",
            "404/404 [==============================] - 0s 213us/sample - loss: 42.9036 - mean_squared_error: 42.9036\n",
            "Epoch 494/1000\n",
            "404/404 [==============================] - 0s 216us/sample - loss: 40.4251 - mean_squared_error: 40.4251\n",
            "Epoch 495/1000\n",
            "404/404 [==============================] - 0s 215us/sample - loss: 41.6799 - mean_squared_error: 41.6799\n",
            "Epoch 496/1000\n",
            "404/404 [==============================] - 0s 221us/sample - loss: 44.5366 - mean_squared_error: 44.5366\n",
            "Epoch 497/1000\n",
            "404/404 [==============================] - 0s 219us/sample - loss: 37.2281 - mean_squared_error: 37.2281\n",
            "Epoch 498/1000\n",
            "404/404 [==============================] - 0s 220us/sample - loss: 36.4155 - mean_squared_error: 36.4155\n",
            "Epoch 499/1000\n",
            "404/404 [==============================] - 0s 230us/sample - loss: 37.7561 - mean_squared_error: 37.7560\n",
            "Epoch 500/1000\n",
            "404/404 [==============================] - 0s 217us/sample - loss: 38.2811 - mean_squared_error: 38.2811\n",
            "Epoch 501/1000\n",
            "404/404 [==============================] - 0s 220us/sample - loss: 43.9164 - mean_squared_error: 43.9164\n",
            "Epoch 502/1000\n",
            "404/404 [==============================] - 0s 219us/sample - loss: 39.0075 - mean_squared_error: 39.0075\n",
            "Epoch 503/1000\n",
            "404/404 [==============================] - 0s 217us/sample - loss: 42.9541 - mean_squared_error: 42.9541\n",
            "Epoch 504/1000\n",
            "404/404 [==============================] - 0s 226us/sample - loss: 39.8097 - mean_squared_error: 39.8097\n",
            "Epoch 505/1000\n",
            "404/404 [==============================] - 0s 233us/sample - loss: 38.0993 - mean_squared_error: 38.0993\n",
            "Epoch 506/1000\n",
            "404/404 [==============================] - 0s 244us/sample - loss: 53.8477 - mean_squared_error: 53.8477\n",
            "Epoch 507/1000\n",
            "404/404 [==============================] - 0s 219us/sample - loss: 51.0229 - mean_squared_error: 51.0229\n",
            "Epoch 508/1000\n",
            "404/404 [==============================] - 0s 233us/sample - loss: 34.5413 - mean_squared_error: 34.5413\n",
            "Epoch 509/1000\n",
            "404/404 [==============================] - 0s 232us/sample - loss: 50.1878 - mean_squared_error: 50.1878\n",
            "Epoch 510/1000\n",
            "404/404 [==============================] - 0s 223us/sample - loss: 40.8336 - mean_squared_error: 40.8336\n",
            "Epoch 511/1000\n",
            "404/404 [==============================] - 0s 239us/sample - loss: 43.8010 - mean_squared_error: 43.8010\n",
            "Epoch 512/1000\n",
            "404/404 [==============================] - 0s 224us/sample - loss: 40.8710 - mean_squared_error: 40.8710\n",
            "Epoch 513/1000\n",
            "404/404 [==============================] - 0s 230us/sample - loss: 35.1968 - mean_squared_error: 35.1968\n",
            "Epoch 514/1000\n",
            "404/404 [==============================] - 0s 239us/sample - loss: 43.9122 - mean_squared_error: 43.9122\n",
            "Epoch 515/1000\n",
            "404/404 [==============================] - 0s 235us/sample - loss: 36.3830 - mean_squared_error: 36.3830\n",
            "Epoch 516/1000\n",
            "404/404 [==============================] - 0s 241us/sample - loss: 37.4747 - mean_squared_error: 37.4747\n",
            "Epoch 517/1000\n",
            "404/404 [==============================] - 0s 226us/sample - loss: 36.9442 - mean_squared_error: 36.9442\n",
            "Epoch 518/1000\n",
            "404/404 [==============================] - 0s 230us/sample - loss: 37.1445 - mean_squared_error: 37.1445\n",
            "Epoch 519/1000\n",
            "404/404 [==============================] - 0s 232us/sample - loss: 39.5040 - mean_squared_error: 39.5040\n",
            "Epoch 520/1000\n",
            "404/404 [==============================] - 0s 232us/sample - loss: 41.8075 - mean_squared_error: 41.8075\n",
            "Epoch 521/1000\n",
            "404/404 [==============================] - 0s 225us/sample - loss: 41.4664 - mean_squared_error: 41.4664\n",
            "Epoch 522/1000\n",
            "404/404 [==============================] - 0s 231us/sample - loss: 43.3437 - mean_squared_error: 43.3437\n",
            "Epoch 523/1000\n",
            "404/404 [==============================] - 0s 221us/sample - loss: 43.1250 - mean_squared_error: 43.1250\n",
            "Epoch 524/1000\n",
            "404/404 [==============================] - 0s 220us/sample - loss: 38.6402 - mean_squared_error: 38.6402\n",
            "Epoch 525/1000\n",
            "404/404 [==============================] - 0s 225us/sample - loss: 37.5526 - mean_squared_error: 37.5526\n",
            "Epoch 526/1000\n",
            "404/404 [==============================] - 0s 222us/sample - loss: 35.2570 - mean_squared_error: 35.2570\n",
            "Epoch 527/1000\n",
            "404/404 [==============================] - 0s 238us/sample - loss: 43.1561 - mean_squared_error: 43.1562\n",
            "Epoch 528/1000\n",
            "404/404 [==============================] - 0s 222us/sample - loss: 37.1969 - mean_squared_error: 37.1969\n",
            "Epoch 529/1000\n",
            "404/404 [==============================] - 0s 230us/sample - loss: 41.6768 - mean_squared_error: 41.6768\n",
            "Epoch 530/1000\n",
            "404/404 [==============================] - 0s 230us/sample - loss: 46.6071 - mean_squared_error: 46.6071\n",
            "Epoch 531/1000\n",
            "404/404 [==============================] - 0s 226us/sample - loss: 43.4483 - mean_squared_error: 43.4483\n",
            "Epoch 532/1000\n",
            "404/404 [==============================] - 0s 230us/sample - loss: 39.9761 - mean_squared_error: 39.9761\n",
            "Epoch 533/1000\n",
            "404/404 [==============================] - 0s 230us/sample - loss: 38.0180 - mean_squared_error: 38.0180\n",
            "Epoch 534/1000\n",
            "404/404 [==============================] - 0s 226us/sample - loss: 47.3941 - mean_squared_error: 47.3941\n",
            "Epoch 535/1000\n",
            "404/404 [==============================] - 0s 235us/sample - loss: 33.3743 - mean_squared_error: 33.3743\n",
            "Epoch 536/1000\n",
            "404/404 [==============================] - 0s 220us/sample - loss: 40.8501 - mean_squared_error: 40.8501\n",
            "Epoch 537/1000\n",
            "404/404 [==============================] - 0s 226us/sample - loss: 39.0042 - mean_squared_error: 39.0042\n",
            "Epoch 538/1000\n",
            "404/404 [==============================] - 0s 216us/sample - loss: 36.7569 - mean_squared_error: 36.7569\n",
            "Epoch 539/1000\n",
            "404/404 [==============================] - 0s 227us/sample - loss: 45.8408 - mean_squared_error: 45.8408\n",
            "Epoch 540/1000\n",
            "404/404 [==============================] - 0s 230us/sample - loss: 47.4646 - mean_squared_error: 47.4646\n",
            "Epoch 541/1000\n",
            "404/404 [==============================] - 0s 240us/sample - loss: 36.4566 - mean_squared_error: 36.4566\n",
            "Epoch 542/1000\n",
            "404/404 [==============================] - 0s 232us/sample - loss: 42.1435 - mean_squared_error: 42.1435\n",
            "Epoch 543/1000\n",
            "404/404 [==============================] - 0s 229us/sample - loss: 37.6803 - mean_squared_error: 37.6803\n",
            "Epoch 544/1000\n",
            "404/404 [==============================] - 0s 226us/sample - loss: 37.7987 - mean_squared_error: 37.7987\n",
            "Epoch 545/1000\n",
            "404/404 [==============================] - 0s 223us/sample - loss: 44.5248 - mean_squared_error: 44.5248\n",
            "Epoch 546/1000\n",
            "404/404 [==============================] - 0s 232us/sample - loss: 46.0014 - mean_squared_error: 46.0014\n",
            "Epoch 547/1000\n",
            "404/404 [==============================] - 0s 253us/sample - loss: 36.7467 - mean_squared_error: 36.7467\n",
            "Epoch 548/1000\n",
            "404/404 [==============================] - 0s 237us/sample - loss: 42.3435 - mean_squared_error: 42.3435\n",
            "Epoch 549/1000\n",
            "404/404 [==============================] - 0s 255us/sample - loss: 35.9005 - mean_squared_error: 35.9004\n",
            "Epoch 550/1000\n",
            "404/404 [==============================] - 0s 240us/sample - loss: 41.4824 - mean_squared_error: 41.4824\n",
            "Epoch 551/1000\n",
            "404/404 [==============================] - 0s 227us/sample - loss: 42.4044 - mean_squared_error: 42.4044\n",
            "Epoch 552/1000\n",
            "404/404 [==============================] - 0s 232us/sample - loss: 33.7316 - mean_squared_error: 33.7316\n",
            "Epoch 553/1000\n",
            "404/404 [==============================] - 0s 223us/sample - loss: 32.2791 - mean_squared_error: 32.2791\n",
            "Epoch 554/1000\n",
            "404/404 [==============================] - 0s 227us/sample - loss: 32.3706 - mean_squared_error: 32.3706\n",
            "Epoch 555/1000\n",
            "404/404 [==============================] - 0s 217us/sample - loss: 38.6462 - mean_squared_error: 38.6462\n",
            "Epoch 556/1000\n",
            "404/404 [==============================] - 0s 233us/sample - loss: 38.1120 - mean_squared_error: 38.1120\n",
            "Epoch 557/1000\n",
            "404/404 [==============================] - 0s 219us/sample - loss: 38.1667 - mean_squared_error: 38.1667\n",
            "Epoch 558/1000\n",
            "404/404 [==============================] - 0s 238us/sample - loss: 38.3242 - mean_squared_error: 38.3242\n",
            "Epoch 559/1000\n",
            "404/404 [==============================] - 0s 249us/sample - loss: 40.0343 - mean_squared_error: 40.0343\n",
            "Epoch 560/1000\n",
            "404/404 [==============================] - 0s 243us/sample - loss: 39.0805 - mean_squared_error: 39.0805\n",
            "Epoch 561/1000\n",
            "404/404 [==============================] - 0s 248us/sample - loss: 40.3585 - mean_squared_error: 40.3585\n",
            "Epoch 562/1000\n",
            "404/404 [==============================] - 0s 230us/sample - loss: 38.3954 - mean_squared_error: 38.3954\n",
            "Epoch 563/1000\n",
            "404/404 [==============================] - 0s 237us/sample - loss: 34.5134 - mean_squared_error: 34.5134\n",
            "Epoch 564/1000\n",
            "404/404 [==============================] - 0s 232us/sample - loss: 42.8177 - mean_squared_error: 42.8177\n",
            "Epoch 565/1000\n",
            "404/404 [==============================] - 0s 230us/sample - loss: 38.4945 - mean_squared_error: 38.4945\n",
            "Epoch 566/1000\n",
            "404/404 [==============================] - 0s 223us/sample - loss: 39.1996 - mean_squared_error: 39.1996\n",
            "Epoch 567/1000\n",
            "404/404 [==============================] - 0s 232us/sample - loss: 40.8314 - mean_squared_error: 40.8314\n",
            "Epoch 568/1000\n",
            "404/404 [==============================] - 0s 243us/sample - loss: 37.0206 - mean_squared_error: 37.0206\n",
            "Epoch 569/1000\n",
            "404/404 [==============================] - 0s 249us/sample - loss: 38.0839 - mean_squared_error: 38.0839\n",
            "Epoch 570/1000\n",
            "404/404 [==============================] - 0s 233us/sample - loss: 36.5814 - mean_squared_error: 36.5814\n",
            "Epoch 571/1000\n",
            "404/404 [==============================] - 0s 239us/sample - loss: 38.3344 - mean_squared_error: 38.3344\n",
            "Epoch 572/1000\n",
            "404/404 [==============================] - 0s 230us/sample - loss: 39.5006 - mean_squared_error: 39.5006\n",
            "Epoch 573/1000\n",
            "404/404 [==============================] - 0s 237us/sample - loss: 36.5071 - mean_squared_error: 36.5071\n",
            "Epoch 574/1000\n",
            "404/404 [==============================] - 0s 230us/sample - loss: 40.6899 - mean_squared_error: 40.6899\n",
            "Epoch 575/1000\n",
            "404/404 [==============================] - 0s 220us/sample - loss: 36.8072 - mean_squared_error: 36.8072\n",
            "Epoch 576/1000\n",
            "404/404 [==============================] - 0s 260us/sample - loss: 32.8264 - mean_squared_error: 32.8264\n",
            "Epoch 577/1000\n",
            "404/404 [==============================] - 0s 222us/sample - loss: 35.6118 - mean_squared_error: 35.6118\n",
            "Epoch 578/1000\n",
            "404/404 [==============================] - 0s 232us/sample - loss: 40.3293 - mean_squared_error: 40.3293\n",
            "Epoch 579/1000\n",
            "404/404 [==============================] - 0s 312us/sample - loss: 45.6067 - mean_squared_error: 45.6067\n",
            "Epoch 580/1000\n",
            "404/404 [==============================] - 0s 236us/sample - loss: 41.4495 - mean_squared_error: 41.4495\n",
            "Epoch 581/1000\n",
            "404/404 [==============================] - 0s 229us/sample - loss: 42.8568 - mean_squared_error: 42.8568\n",
            "Epoch 582/1000\n",
            "404/404 [==============================] - 0s 227us/sample - loss: 36.3602 - mean_squared_error: 36.3602\n",
            "Epoch 583/1000\n",
            "404/404 [==============================] - 0s 229us/sample - loss: 40.2640 - mean_squared_error: 40.2640\n",
            "Epoch 584/1000\n",
            "404/404 [==============================] - 0s 224us/sample - loss: 37.5868 - mean_squared_error: 37.5868\n",
            "Epoch 585/1000\n",
            "404/404 [==============================] - 0s 216us/sample - loss: 32.5350 - mean_squared_error: 32.5350\n",
            "Epoch 586/1000\n",
            "404/404 [==============================] - 0s 218us/sample - loss: 43.0494 - mean_squared_error: 43.0494\n",
            "Epoch 587/1000\n",
            "404/404 [==============================] - 0s 226us/sample - loss: 34.7024 - mean_squared_error: 34.7024\n",
            "Epoch 588/1000\n",
            "404/404 [==============================] - 0s 240us/sample - loss: 42.0211 - mean_squared_error: 42.0211\n",
            "Epoch 589/1000\n",
            "404/404 [==============================] - 0s 251us/sample - loss: 40.4883 - mean_squared_error: 40.4883\n",
            "Epoch 590/1000\n",
            "404/404 [==============================] - 0s 233us/sample - loss: 48.8939 - mean_squared_error: 48.8939\n",
            "Epoch 591/1000\n",
            "404/404 [==============================] - 0s 220us/sample - loss: 39.3948 - mean_squared_error: 39.3948\n",
            "Epoch 592/1000\n",
            "404/404 [==============================] - 0s 235us/sample - loss: 41.9963 - mean_squared_error: 41.9963\n",
            "Epoch 593/1000\n",
            "404/404 [==============================] - 0s 239us/sample - loss: 36.8298 - mean_squared_error: 36.8298\n",
            "Epoch 594/1000\n",
            "404/404 [==============================] - 0s 228us/sample - loss: 37.4335 - mean_squared_error: 37.4335\n",
            "Epoch 595/1000\n",
            "404/404 [==============================] - 0s 228us/sample - loss: 33.7377 - mean_squared_error: 33.7377\n",
            "Epoch 596/1000\n",
            "404/404 [==============================] - 0s 219us/sample - loss: 42.6355 - mean_squared_error: 42.6355\n",
            "Epoch 597/1000\n",
            "404/404 [==============================] - 0s 240us/sample - loss: 37.9201 - mean_squared_error: 37.9201\n",
            "Epoch 598/1000\n",
            "404/404 [==============================] - 0s 231us/sample - loss: 42.3363 - mean_squared_error: 42.3363\n",
            "Epoch 599/1000\n",
            "404/404 [==============================] - 0s 256us/sample - loss: 35.8776 - mean_squared_error: 35.8775\n",
            "Epoch 600/1000\n",
            "404/404 [==============================] - 0s 242us/sample - loss: 35.7972 - mean_squared_error: 35.7972\n",
            "Epoch 601/1000\n",
            "404/404 [==============================] - 0s 227us/sample - loss: 35.1758 - mean_squared_error: 35.1758\n",
            "Epoch 602/1000\n",
            "404/404 [==============================] - 0s 227us/sample - loss: 45.2204 - mean_squared_error: 45.2204\n",
            "Epoch 603/1000\n",
            "404/404 [==============================] - 0s 221us/sample - loss: 37.0558 - mean_squared_error: 37.0558\n",
            "Epoch 604/1000\n",
            "404/404 [==============================] - 0s 219us/sample - loss: 37.1462 - mean_squared_error: 37.1462\n",
            "Epoch 605/1000\n",
            "404/404 [==============================] - 0s 230us/sample - loss: 36.2912 - mean_squared_error: 36.2912\n",
            "Epoch 606/1000\n",
            "404/404 [==============================] - 0s 228us/sample - loss: 39.6329 - mean_squared_error: 39.6329\n",
            "Epoch 607/1000\n",
            "404/404 [==============================] - 0s 240us/sample - loss: 34.9945 - mean_squared_error: 34.9945\n",
            "Epoch 608/1000\n",
            "404/404 [==============================] - 0s 230us/sample - loss: 34.6146 - mean_squared_error: 34.6146\n",
            "Epoch 609/1000\n",
            "404/404 [==============================] - 0s 240us/sample - loss: 31.7879 - mean_squared_error: 31.7879\n",
            "Epoch 610/1000\n",
            "404/404 [==============================] - 0s 266us/sample - loss: 36.4119 - mean_squared_error: 36.4119\n",
            "Epoch 611/1000\n",
            "404/404 [==============================] - 0s 233us/sample - loss: 43.1680 - mean_squared_error: 43.1680\n",
            "Epoch 612/1000\n",
            "404/404 [==============================] - 0s 230us/sample - loss: 31.7310 - mean_squared_error: 31.7310\n",
            "Epoch 613/1000\n",
            "404/404 [==============================] - 0s 228us/sample - loss: 37.3571 - mean_squared_error: 37.3571\n",
            "Epoch 614/1000\n",
            "404/404 [==============================] - 0s 237us/sample - loss: 41.9359 - mean_squared_error: 41.9359\n",
            "Epoch 615/1000\n",
            "404/404 [==============================] - 0s 233us/sample - loss: 46.2571 - mean_squared_error: 46.2571\n",
            "Epoch 616/1000\n",
            "404/404 [==============================] - 0s 237us/sample - loss: 39.6841 - mean_squared_error: 39.6841\n",
            "Epoch 617/1000\n",
            "404/404 [==============================] - 0s 235us/sample - loss: 37.5192 - mean_squared_error: 37.5192\n",
            "Epoch 618/1000\n",
            "404/404 [==============================] - 0s 221us/sample - loss: 35.9227 - mean_squared_error: 35.9227\n",
            "Epoch 619/1000\n",
            "404/404 [==============================] - 0s 227us/sample - loss: 45.5620 - mean_squared_error: 45.5620\n",
            "Epoch 620/1000\n",
            "404/404 [==============================] - 0s 233us/sample - loss: 38.8006 - mean_squared_error: 38.8006\n",
            "Epoch 621/1000\n",
            "404/404 [==============================] - 0s 253us/sample - loss: 34.8382 - mean_squared_error: 34.8382\n",
            "Epoch 622/1000\n",
            "404/404 [==============================] - 0s 221us/sample - loss: 41.8286 - mean_squared_error: 41.8286\n",
            "Epoch 623/1000\n",
            "404/404 [==============================] - 0s 221us/sample - loss: 34.8584 - mean_squared_error: 34.8584\n",
            "Epoch 624/1000\n",
            "404/404 [==============================] - 0s 216us/sample - loss: 37.3637 - mean_squared_error: 37.3637\n",
            "Epoch 625/1000\n",
            "404/404 [==============================] - 0s 244us/sample - loss: 37.2885 - mean_squared_error: 37.2885\n",
            "Epoch 626/1000\n",
            "404/404 [==============================] - 0s 239us/sample - loss: 39.1518 - mean_squared_error: 39.1518\n",
            "Epoch 627/1000\n",
            "404/404 [==============================] - 0s 222us/sample - loss: 44.8042 - mean_squared_error: 44.8042\n",
            "Epoch 628/1000\n",
            "404/404 [==============================] - 0s 239us/sample - loss: 30.8085 - mean_squared_error: 30.8085\n",
            "Epoch 629/1000\n",
            "404/404 [==============================] - 0s 240us/sample - loss: 35.4206 - mean_squared_error: 35.4205\n",
            "Epoch 630/1000\n",
            "404/404 [==============================] - 0s 230us/sample - loss: 36.0102 - mean_squared_error: 36.0102\n",
            "Epoch 631/1000\n",
            "404/404 [==============================] - 0s 251us/sample - loss: 36.0419 - mean_squared_error: 36.0419\n",
            "Epoch 632/1000\n",
            "404/404 [==============================] - 0s 236us/sample - loss: 41.7669 - mean_squared_error: 41.7669\n",
            "Epoch 633/1000\n",
            "404/404 [==============================] - 0s 232us/sample - loss: 38.5733 - mean_squared_error: 38.5734\n",
            "Epoch 634/1000\n",
            "404/404 [==============================] - 0s 231us/sample - loss: 33.6379 - mean_squared_error: 33.6379\n",
            "Epoch 635/1000\n",
            "404/404 [==============================] - 0s 224us/sample - loss: 35.9159 - mean_squared_error: 35.9159\n",
            "Epoch 636/1000\n",
            "404/404 [==============================] - 0s 225us/sample - loss: 36.1143 - mean_squared_error: 36.1143\n",
            "Epoch 637/1000\n",
            "404/404 [==============================] - 0s 229us/sample - loss: 36.7797 - mean_squared_error: 36.7797\n",
            "Epoch 638/1000\n",
            "404/404 [==============================] - 0s 235us/sample - loss: 37.3707 - mean_squared_error: 37.3707\n",
            "Epoch 639/1000\n",
            "404/404 [==============================] - 0s 226us/sample - loss: 44.1995 - mean_squared_error: 44.1995\n",
            "Epoch 640/1000\n",
            "404/404 [==============================] - 0s 243us/sample - loss: 31.8490 - mean_squared_error: 31.8490\n",
            "Epoch 641/1000\n",
            "404/404 [==============================] - 0s 229us/sample - loss: 38.5753 - mean_squared_error: 38.5753\n",
            "Epoch 642/1000\n",
            "404/404 [==============================] - 0s 226us/sample - loss: 40.6138 - mean_squared_error: 40.6138\n",
            "Epoch 643/1000\n",
            "404/404 [==============================] - 0s 246us/sample - loss: 41.1696 - mean_squared_error: 41.1696\n",
            "Epoch 644/1000\n",
            "404/404 [==============================] - 0s 240us/sample - loss: 44.1914 - mean_squared_error: 44.1915\n",
            "Epoch 645/1000\n",
            "404/404 [==============================] - 0s 233us/sample - loss: 33.5909 - mean_squared_error: 33.5909\n",
            "Epoch 646/1000\n",
            "404/404 [==============================] - 0s 238us/sample - loss: 39.8338 - mean_squared_error: 39.8338\n",
            "Epoch 647/1000\n",
            "404/404 [==============================] - 0s 281us/sample - loss: 39.9197 - mean_squared_error: 39.9197\n",
            "Epoch 648/1000\n",
            "404/404 [==============================] - 0s 222us/sample - loss: 36.5026 - mean_squared_error: 36.5026\n",
            "Epoch 649/1000\n",
            "404/404 [==============================] - 0s 228us/sample - loss: 44.2755 - mean_squared_error: 44.2755\n",
            "Epoch 650/1000\n",
            "404/404 [==============================] - 0s 236us/sample - loss: 30.9423 - mean_squared_error: 30.9423\n",
            "Epoch 651/1000\n",
            "404/404 [==============================] - 0s 234us/sample - loss: 37.7979 - mean_squared_error: 37.7979\n",
            "Epoch 652/1000\n",
            "404/404 [==============================] - 0s 233us/sample - loss: 33.4034 - mean_squared_error: 33.4034\n",
            "Epoch 653/1000\n",
            "404/404 [==============================] - 0s 247us/sample - loss: 34.4285 - mean_squared_error: 34.4285\n",
            "Epoch 654/1000\n",
            "404/404 [==============================] - 0s 238us/sample - loss: 36.5186 - mean_squared_error: 36.5186\n",
            "Epoch 655/1000\n",
            "404/404 [==============================] - 0s 234us/sample - loss: 44.3116 - mean_squared_error: 44.3116\n",
            "Epoch 656/1000\n",
            "404/404 [==============================] - 0s 225us/sample - loss: 37.2547 - mean_squared_error: 37.2547\n",
            "Epoch 657/1000\n",
            "404/404 [==============================] - 0s 232us/sample - loss: 34.6172 - mean_squared_error: 34.6172\n",
            "Epoch 658/1000\n",
            "404/404 [==============================] - 0s 229us/sample - loss: 37.4046 - mean_squared_error: 37.4046\n",
            "Epoch 659/1000\n",
            "404/404 [==============================] - 0s 238us/sample - loss: 36.7763 - mean_squared_error: 36.7763\n",
            "Epoch 660/1000\n",
            "404/404 [==============================] - 0s 227us/sample - loss: 39.1468 - mean_squared_error: 39.1468\n",
            "Epoch 661/1000\n",
            "404/404 [==============================] - 0s 224us/sample - loss: 42.5573 - mean_squared_error: 42.5573\n",
            "Epoch 662/1000\n",
            "404/404 [==============================] - 0s 222us/sample - loss: 33.5786 - mean_squared_error: 33.5786\n",
            "Epoch 663/1000\n",
            "404/404 [==============================] - 0s 227us/sample - loss: 35.8402 - mean_squared_error: 35.8402\n",
            "Epoch 664/1000\n",
            "404/404 [==============================] - 0s 227us/sample - loss: 39.2109 - mean_squared_error: 39.2109\n",
            "Epoch 665/1000\n",
            "404/404 [==============================] - 0s 247us/sample - loss: 40.2014 - mean_squared_error: 40.2014\n",
            "Epoch 666/1000\n",
            "404/404 [==============================] - 0s 249us/sample - loss: 39.3213 - mean_squared_error: 39.3213\n",
            "Epoch 667/1000\n",
            "404/404 [==============================] - 0s 235us/sample - loss: 37.4591 - mean_squared_error: 37.4591\n",
            "Epoch 668/1000\n",
            "404/404 [==============================] - 0s 225us/sample - loss: 43.1797 - mean_squared_error: 43.1797\n",
            "Epoch 669/1000\n",
            "404/404 [==============================] - 0s 226us/sample - loss: 40.0502 - mean_squared_error: 40.0502\n",
            "Epoch 670/1000\n",
            "404/404 [==============================] - 0s 239us/sample - loss: 36.8372 - mean_squared_error: 36.8372\n",
            "Epoch 671/1000\n",
            "404/404 [==============================] - 0s 226us/sample - loss: 31.4706 - mean_squared_error: 31.4706\n",
            "Epoch 672/1000\n",
            "404/404 [==============================] - 0s 232us/sample - loss: 34.7154 - mean_squared_error: 34.7154\n",
            "Epoch 673/1000\n",
            "404/404 [==============================] - 0s 238us/sample - loss: 36.9986 - mean_squared_error: 36.9986\n",
            "Epoch 674/1000\n",
            "404/404 [==============================] - 0s 224us/sample - loss: 47.2110 - mean_squared_error: 47.2110\n",
            "Epoch 675/1000\n",
            "404/404 [==============================] - 0s 251us/sample - loss: 42.4037 - mean_squared_error: 42.4037\n",
            "Epoch 676/1000\n",
            "404/404 [==============================] - 0s 242us/sample - loss: 42.7088 - mean_squared_error: 42.7088\n",
            "Epoch 677/1000\n",
            "404/404 [==============================] - 0s 219us/sample - loss: 35.8471 - mean_squared_error: 35.8471\n",
            "Epoch 678/1000\n",
            "404/404 [==============================] - 0s 240us/sample - loss: 41.6145 - mean_squared_error: 41.6145\n",
            "Epoch 679/1000\n",
            "404/404 [==============================] - 0s 239us/sample - loss: 38.9982 - mean_squared_error: 38.9982\n",
            "Epoch 680/1000\n",
            "404/404 [==============================] - 0s 241us/sample - loss: 39.0580 - mean_squared_error: 39.0580\n",
            "Epoch 681/1000\n",
            "404/404 [==============================] - 0s 228us/sample - loss: 41.2602 - mean_squared_error: 41.2602\n",
            "Epoch 682/1000\n",
            "404/404 [==============================] - 0s 232us/sample - loss: 41.6095 - mean_squared_error: 41.6095\n",
            "Epoch 683/1000\n",
            "404/404 [==============================] - 0s 236us/sample - loss: 37.5629 - mean_squared_error: 37.5629\n",
            "Epoch 684/1000\n",
            "404/404 [==============================] - 0s 225us/sample - loss: 36.8120 - mean_squared_error: 36.8120\n",
            "Epoch 685/1000\n",
            "404/404 [==============================] - 0s 231us/sample - loss: 38.7631 - mean_squared_error: 38.7631\n",
            "Epoch 686/1000\n",
            "404/404 [==============================] - 0s 226us/sample - loss: 41.2159 - mean_squared_error: 41.2159\n",
            "Epoch 687/1000\n",
            "404/404 [==============================] - 0s 241us/sample - loss: 42.3287 - mean_squared_error: 42.3287\n",
            "Epoch 688/1000\n",
            "404/404 [==============================] - 0s 232us/sample - loss: 38.4058 - mean_squared_error: 38.4058\n",
            "Epoch 689/1000\n",
            "404/404 [==============================] - 0s 264us/sample - loss: 40.9725 - mean_squared_error: 40.9725\n",
            "Epoch 690/1000\n",
            "404/404 [==============================] - 0s 222us/sample - loss: 41.0796 - mean_squared_error: 41.0796\n",
            "Epoch 691/1000\n",
            "404/404 [==============================] - 0s 283us/sample - loss: 40.1797 - mean_squared_error: 40.1797\n",
            "Epoch 692/1000\n",
            "404/404 [==============================] - 0s 229us/sample - loss: 39.3794 - mean_squared_error: 39.3794\n",
            "Epoch 693/1000\n",
            "404/404 [==============================] - 0s 221us/sample - loss: 40.2781 - mean_squared_error: 40.2781\n",
            "Epoch 694/1000\n",
            "404/404 [==============================] - 0s 239us/sample - loss: 39.3255 - mean_squared_error: 39.3255\n",
            "Epoch 695/1000\n",
            "404/404 [==============================] - 0s 242us/sample - loss: 34.2671 - mean_squared_error: 34.2671\n",
            "Epoch 696/1000\n",
            "404/404 [==============================] - 0s 234us/sample - loss: 39.8645 - mean_squared_error: 39.8645\n",
            "Epoch 697/1000\n",
            "404/404 [==============================] - 0s 257us/sample - loss: 37.9637 - mean_squared_error: 37.9637\n",
            "Epoch 698/1000\n",
            "404/404 [==============================] - 0s 229us/sample - loss: 35.0634 - mean_squared_error: 35.0634\n",
            "Epoch 699/1000\n",
            "404/404 [==============================] - 0s 228us/sample - loss: 34.5268 - mean_squared_error: 34.5268\n",
            "Epoch 700/1000\n",
            "404/404 [==============================] - 0s 230us/sample - loss: 34.7650 - mean_squared_error: 34.7650\n",
            "Epoch 701/1000\n",
            "404/404 [==============================] - 0s 222us/sample - loss: 34.8308 - mean_squared_error: 34.8308\n",
            "Epoch 702/1000\n",
            "404/404 [==============================] - 0s 217us/sample - loss: 34.9111 - mean_squared_error: 34.9111\n",
            "Epoch 703/1000\n",
            "404/404 [==============================] - 0s 217us/sample - loss: 42.7471 - mean_squared_error: 42.7471\n",
            "Epoch 704/1000\n",
            "404/404 [==============================] - 0s 220us/sample - loss: 39.9046 - mean_squared_error: 39.9046\n",
            "Epoch 705/1000\n",
            "404/404 [==============================] - 0s 238us/sample - loss: 34.3204 - mean_squared_error: 34.3204\n",
            "Epoch 706/1000\n",
            "404/404 [==============================] - 0s 237us/sample - loss: 38.7389 - mean_squared_error: 38.7389\n",
            "Epoch 707/1000\n",
            "404/404 [==============================] - 0s 224us/sample - loss: 38.9638 - mean_squared_error: 38.9638\n",
            "Epoch 708/1000\n",
            "404/404 [==============================] - 0s 224us/sample - loss: 34.2893 - mean_squared_error: 34.2893\n",
            "Epoch 709/1000\n",
            "404/404 [==============================] - 0s 230us/sample - loss: 36.6879 - mean_squared_error: 36.6880\n",
            "Epoch 710/1000\n",
            "404/404 [==============================] - 0s 248us/sample - loss: 34.6452 - mean_squared_error: 34.6452\n",
            "Epoch 711/1000\n",
            "404/404 [==============================] - 0s 226us/sample - loss: 39.2402 - mean_squared_error: 39.2402\n",
            "Epoch 712/1000\n",
            "404/404 [==============================] - 0s 245us/sample - loss: 42.8940 - mean_squared_error: 42.8940\n",
            "Epoch 713/1000\n",
            "404/404 [==============================] - 0s 244us/sample - loss: 30.0832 - mean_squared_error: 30.0832\n",
            "Epoch 714/1000\n",
            "404/404 [==============================] - 0s 220us/sample - loss: 41.6712 - mean_squared_error: 41.6712\n",
            "Epoch 715/1000\n",
            "404/404 [==============================] - 0s 233us/sample - loss: 32.1346 - mean_squared_error: 32.1346\n",
            "Epoch 716/1000\n",
            "404/404 [==============================] - 0s 220us/sample - loss: 32.3851 - mean_squared_error: 32.3851\n",
            "Epoch 717/1000\n",
            "404/404 [==============================] - 0s 232us/sample - loss: 37.9317 - mean_squared_error: 37.9318\n",
            "Epoch 718/1000\n",
            "404/404 [==============================] - 0s 228us/sample - loss: 38.2713 - mean_squared_error: 38.2713\n",
            "Epoch 719/1000\n",
            "404/404 [==============================] - 0s 233us/sample - loss: 41.3106 - mean_squared_error: 41.3106\n",
            "Epoch 720/1000\n",
            "404/404 [==============================] - 0s 254us/sample - loss: 37.4177 - mean_squared_error: 37.4177\n",
            "Epoch 721/1000\n",
            "404/404 [==============================] - 0s 228us/sample - loss: 37.8931 - mean_squared_error: 37.8931\n",
            "Epoch 722/1000\n",
            "404/404 [==============================] - 0s 226us/sample - loss: 41.4844 - mean_squared_error: 41.4844\n",
            "Epoch 723/1000\n",
            "404/404 [==============================] - 0s 235us/sample - loss: 37.2590 - mean_squared_error: 37.2590\n",
            "Epoch 724/1000\n",
            "404/404 [==============================] - 0s 229us/sample - loss: 31.9781 - mean_squared_error: 31.9781\n",
            "Epoch 725/1000\n",
            "404/404 [==============================] - 0s 231us/sample - loss: 35.2177 - mean_squared_error: 35.2177\n",
            "Epoch 726/1000\n",
            "404/404 [==============================] - 0s 231us/sample - loss: 37.6774 - mean_squared_error: 37.6774\n",
            "Epoch 727/1000\n",
            "404/404 [==============================] - 0s 268us/sample - loss: 31.7741 - mean_squared_error: 31.7741\n",
            "Epoch 728/1000\n",
            "404/404 [==============================] - 0s 236us/sample - loss: 40.2799 - mean_squared_error: 40.2799\n",
            "Epoch 729/1000\n",
            "404/404 [==============================] - 0s 274us/sample - loss: 33.4932 - mean_squared_error: 33.4932\n",
            "Epoch 730/1000\n",
            "404/404 [==============================] - 0s 239us/sample - loss: 40.6731 - mean_squared_error: 40.6731\n",
            "Epoch 731/1000\n",
            "404/404 [==============================] - 0s 224us/sample - loss: 38.5652 - mean_squared_error: 38.5652\n",
            "Epoch 732/1000\n",
            "404/404 [==============================] - 0s 217us/sample - loss: 37.8457 - mean_squared_error: 37.8457\n",
            "Epoch 733/1000\n",
            "404/404 [==============================] - 0s 226us/sample - loss: 33.6757 - mean_squared_error: 33.6757\n",
            "Epoch 734/1000\n",
            "404/404 [==============================] - 0s 219us/sample - loss: 47.7617 - mean_squared_error: 47.7617\n",
            "Epoch 735/1000\n",
            "404/404 [==============================] - 0s 222us/sample - loss: 39.8695 - mean_squared_error: 39.8695\n",
            "Epoch 736/1000\n",
            "404/404 [==============================] - 0s 218us/sample - loss: 38.1338 - mean_squared_error: 38.1339\n",
            "Epoch 737/1000\n",
            "404/404 [==============================] - 0s 225us/sample - loss: 34.6943 - mean_squared_error: 34.6943\n",
            "Epoch 738/1000\n",
            "404/404 [==============================] - 0s 236us/sample - loss: 36.7472 - mean_squared_error: 36.7472\n",
            "Epoch 739/1000\n",
            "404/404 [==============================] - 0s 236us/sample - loss: 36.8551 - mean_squared_error: 36.8551\n",
            "Epoch 740/1000\n",
            "404/404 [==============================] - 0s 231us/sample - loss: 32.2933 - mean_squared_error: 32.2933\n",
            "Epoch 741/1000\n",
            "404/404 [==============================] - 0s 251us/sample - loss: 41.7247 - mean_squared_error: 41.7247\n",
            "Epoch 742/1000\n",
            "404/404 [==============================] - 0s 234us/sample - loss: 40.4099 - mean_squared_error: 40.4099\n",
            "Epoch 743/1000\n",
            "404/404 [==============================] - 0s 220us/sample - loss: 39.9259 - mean_squared_error: 39.9259\n",
            "Epoch 744/1000\n",
            "404/404 [==============================] - 0s 219us/sample - loss: 35.0844 - mean_squared_error: 35.0844\n",
            "Epoch 745/1000\n",
            "404/404 [==============================] - 0s 232us/sample - loss: 34.2277 - mean_squared_error: 34.2277\n",
            "Epoch 746/1000\n",
            "404/404 [==============================] - 0s 241us/sample - loss: 34.0680 - mean_squared_error: 34.0680\n",
            "Epoch 747/1000\n",
            "404/404 [==============================] - 0s 230us/sample - loss: 33.9963 - mean_squared_error: 33.9963\n",
            "Epoch 748/1000\n",
            "404/404 [==============================] - 0s 229us/sample - loss: 31.4488 - mean_squared_error: 31.4488\n",
            "Epoch 749/1000\n",
            "404/404 [==============================] - 0s 231us/sample - loss: 35.3973 - mean_squared_error: 35.3973\n",
            "Epoch 750/1000\n",
            "404/404 [==============================] - 0s 235us/sample - loss: 34.3308 - mean_squared_error: 34.3308\n",
            "Epoch 751/1000\n",
            "404/404 [==============================] - 0s 231us/sample - loss: 32.2858 - mean_squared_error: 32.2858\n",
            "Epoch 752/1000\n",
            "404/404 [==============================] - 0s 232us/sample - loss: 31.5037 - mean_squared_error: 31.5037\n",
            "Epoch 753/1000\n",
            "404/404 [==============================] - 0s 231us/sample - loss: 32.2322 - mean_squared_error: 32.2322\n",
            "Epoch 754/1000\n",
            "404/404 [==============================] - 0s 248us/sample - loss: 33.3512 - mean_squared_error: 33.3512\n",
            "Epoch 755/1000\n",
            "404/404 [==============================] - 0s 246us/sample - loss: 32.6201 - mean_squared_error: 32.6201\n",
            "Epoch 756/1000\n",
            "404/404 [==============================] - 0s 218us/sample - loss: 31.8684 - mean_squared_error: 31.8684\n",
            "Epoch 757/1000\n",
            "404/404 [==============================] - 0s 223us/sample - loss: 41.9027 - mean_squared_error: 41.9027\n",
            "Epoch 758/1000\n",
            "404/404 [==============================] - 0s 227us/sample - loss: 31.4393 - mean_squared_error: 31.4393\n",
            "Epoch 759/1000\n",
            "404/404 [==============================] - 0s 238us/sample - loss: 42.8185 - mean_squared_error: 42.8185\n",
            "Epoch 760/1000\n",
            "404/404 [==============================] - 0s 236us/sample - loss: 37.9443 - mean_squared_error: 37.9443\n",
            "Epoch 761/1000\n",
            "404/404 [==============================] - 0s 243us/sample - loss: 42.3671 - mean_squared_error: 42.3671\n",
            "Epoch 762/1000\n",
            "404/404 [==============================] - 0s 224us/sample - loss: 31.8251 - mean_squared_error: 31.8251\n",
            "Epoch 763/1000\n",
            "404/404 [==============================] - 0s 233us/sample - loss: 30.9412 - mean_squared_error: 30.9412\n",
            "Epoch 764/1000\n",
            "404/404 [==============================] - 0s 228us/sample - loss: 26.7899 - mean_squared_error: 26.7899\n",
            "Epoch 765/1000\n",
            "404/404 [==============================] - 0s 238us/sample - loss: 39.8038 - mean_squared_error: 39.8038\n",
            "Epoch 766/1000\n",
            "404/404 [==============================] - 0s 230us/sample - loss: 36.9205 - mean_squared_error: 36.9205\n",
            "Epoch 767/1000\n",
            "404/404 [==============================] - 0s 246us/sample - loss: 39.6731 - mean_squared_error: 39.6731\n",
            "Epoch 768/1000\n",
            "404/404 [==============================] - 0s 258us/sample - loss: 46.4474 - mean_squared_error: 46.4474\n",
            "Epoch 769/1000\n",
            "404/404 [==============================] - 0s 229us/sample - loss: 33.9319 - mean_squared_error: 33.9319\n",
            "Epoch 770/1000\n",
            "404/404 [==============================] - 0s 226us/sample - loss: 34.5504 - mean_squared_error: 34.5504\n",
            "Epoch 771/1000\n",
            "404/404 [==============================] - 0s 220us/sample - loss: 30.6619 - mean_squared_error: 30.6619\n",
            "Epoch 772/1000\n",
            "404/404 [==============================] - 0s 245us/sample - loss: 34.7743 - mean_squared_error: 34.7743\n",
            "Epoch 773/1000\n",
            "404/404 [==============================] - 0s 232us/sample - loss: 35.4589 - mean_squared_error: 35.4589\n",
            "Epoch 774/1000\n",
            "404/404 [==============================] - 0s 226us/sample - loss: 35.8070 - mean_squared_error: 35.8070\n",
            "Epoch 775/1000\n",
            "404/404 [==============================] - 0s 235us/sample - loss: 40.1719 - mean_squared_error: 40.1719\n",
            "Epoch 776/1000\n",
            "404/404 [==============================] - 0s 253us/sample - loss: 39.7830 - mean_squared_error: 39.7830\n",
            "Epoch 777/1000\n",
            "404/404 [==============================] - 0s 220us/sample - loss: 37.3506 - mean_squared_error: 37.3506\n",
            "Epoch 778/1000\n",
            "404/404 [==============================] - 0s 231us/sample - loss: 40.0235 - mean_squared_error: 40.0235\n",
            "Epoch 779/1000\n",
            "404/404 [==============================] - 0s 219us/sample - loss: 37.3928 - mean_squared_error: 37.3928\n",
            "Epoch 780/1000\n",
            "404/404 [==============================] - 0s 244us/sample - loss: 39.0866 - mean_squared_error: 39.0866\n",
            "Epoch 781/1000\n",
            "404/404 [==============================] - 0s 237us/sample - loss: 35.2807 - mean_squared_error: 35.2807\n",
            "Epoch 782/1000\n",
            "404/404 [==============================] - 0s 226us/sample - loss: 33.0674 - mean_squared_error: 33.0674\n",
            "Epoch 783/1000\n",
            "404/404 [==============================] - 0s 223us/sample - loss: 35.3779 - mean_squared_error: 35.3779\n",
            "Epoch 784/1000\n",
            "404/404 [==============================] - 0s 231us/sample - loss: 35.5072 - mean_squared_error: 35.5072\n",
            "Epoch 785/1000\n",
            "404/404 [==============================] - 0s 243us/sample - loss: 34.5492 - mean_squared_error: 34.5492\n",
            "Epoch 786/1000\n",
            "404/404 [==============================] - 0s 230us/sample - loss: 39.9521 - mean_squared_error: 39.9522\n",
            "Epoch 787/1000\n",
            "404/404 [==============================] - 0s 235us/sample - loss: 34.0521 - mean_squared_error: 34.0521\n",
            "Epoch 788/1000\n",
            "404/404 [==============================] - 0s 230us/sample - loss: 32.9008 - mean_squared_error: 32.9007\n",
            "Epoch 789/1000\n",
            "404/404 [==============================] - 0s 234us/sample - loss: 32.6760 - mean_squared_error: 32.6760\n",
            "Epoch 790/1000\n",
            "404/404 [==============================] - 0s 245us/sample - loss: 34.6599 - mean_squared_error: 34.6599\n",
            "Epoch 791/1000\n",
            "404/404 [==============================] - 0s 229us/sample - loss: 39.7316 - mean_squared_error: 39.7316\n",
            "Epoch 792/1000\n",
            "404/404 [==============================] - 0s 232us/sample - loss: 46.0370 - mean_squared_error: 46.0370\n",
            "Epoch 793/1000\n",
            "404/404 [==============================] - 0s 221us/sample - loss: 39.1012 - mean_squared_error: 39.1012\n",
            "Epoch 794/1000\n",
            "404/404 [==============================] - 0s 228us/sample - loss: 37.1483 - mean_squared_error: 37.1483\n",
            "Epoch 795/1000\n",
            "404/404 [==============================] - 0s 234us/sample - loss: 38.4200 - mean_squared_error: 38.4200\n",
            "Epoch 796/1000\n",
            "404/404 [==============================] - 0s 223us/sample - loss: 39.2847 - mean_squared_error: 39.2847\n",
            "Epoch 797/1000\n",
            "404/404 [==============================] - 0s 248us/sample - loss: 34.6690 - mean_squared_error: 34.6690\n",
            "Epoch 798/1000\n",
            "404/404 [==============================] - 0s 231us/sample - loss: 39.0693 - mean_squared_error: 39.0693\n",
            "Epoch 799/1000\n",
            "404/404 [==============================] - 0s 236us/sample - loss: 40.4513 - mean_squared_error: 40.4513\n",
            "Epoch 800/1000\n",
            "404/404 [==============================] - 0s 237us/sample - loss: 37.6327 - mean_squared_error: 37.6327\n",
            "Epoch 801/1000\n",
            "404/404 [==============================] - 0s 232us/sample - loss: 38.3530 - mean_squared_error: 38.3530\n",
            "Epoch 802/1000\n",
            "404/404 [==============================] - 0s 221us/sample - loss: 36.6528 - mean_squared_error: 36.6528\n",
            "Epoch 803/1000\n",
            "404/404 [==============================] - 0s 217us/sample - loss: 32.4762 - mean_squared_error: 32.4762\n",
            "Epoch 804/1000\n",
            "404/404 [==============================] - 0s 223us/sample - loss: 37.3431 - mean_squared_error: 37.3431\n",
            "Epoch 805/1000\n",
            "404/404 [==============================] - 0s 226us/sample - loss: 30.5068 - mean_squared_error: 30.5068\n",
            "Epoch 806/1000\n",
            "404/404 [==============================] - 0s 226us/sample - loss: 36.2062 - mean_squared_error: 36.2062\n",
            "Epoch 807/1000\n",
            "404/404 [==============================] - 0s 242us/sample - loss: 32.0932 - mean_squared_error: 32.0932\n",
            "Epoch 808/1000\n",
            "404/404 [==============================] - 0s 233us/sample - loss: 34.8689 - mean_squared_error: 34.8689\n",
            "Epoch 809/1000\n",
            "404/404 [==============================] - 0s 232us/sample - loss: 39.0182 - mean_squared_error: 39.0182\n",
            "Epoch 810/1000\n",
            "404/404 [==============================] - 0s 254us/sample - loss: 42.7727 - mean_squared_error: 42.7727\n",
            "Epoch 811/1000\n",
            "404/404 [==============================] - 0s 240us/sample - loss: 30.9647 - mean_squared_error: 30.9647\n",
            "Epoch 812/1000\n",
            "404/404 [==============================] - 0s 223us/sample - loss: 35.5563 - mean_squared_error: 35.5563\n",
            "Epoch 813/1000\n",
            "404/404 [==============================] - 0s 251us/sample - loss: 37.5810 - mean_squared_error: 37.5810\n",
            "Epoch 814/1000\n",
            "404/404 [==============================] - 0s 238us/sample - loss: 35.5749 - mean_squared_error: 35.5749\n",
            "Epoch 815/1000\n",
            "404/404 [==============================] - 0s 275us/sample - loss: 31.6351 - mean_squared_error: 31.6351\n",
            "Epoch 816/1000\n",
            "404/404 [==============================] - 0s 240us/sample - loss: 35.5847 - mean_squared_error: 35.5847\n",
            "Epoch 817/1000\n",
            "404/404 [==============================] - 0s 293us/sample - loss: 39.7475 - mean_squared_error: 39.7475\n",
            "Epoch 818/1000\n",
            "404/404 [==============================] - 0s 250us/sample - loss: 28.6922 - mean_squared_error: 28.6922\n",
            "Epoch 819/1000\n",
            "404/404 [==============================] - 0s 247us/sample - loss: 39.0355 - mean_squared_error: 39.0355\n",
            "Epoch 820/1000\n",
            "404/404 [==============================] - 0s 255us/sample - loss: 36.9599 - mean_squared_error: 36.9599\n",
            "Epoch 821/1000\n",
            "404/404 [==============================] - 0s 228us/sample - loss: 35.7758 - mean_squared_error: 35.7758\n",
            "Epoch 822/1000\n",
            "404/404 [==============================] - 0s 226us/sample - loss: 39.9790 - mean_squared_error: 39.9790\n",
            "Epoch 823/1000\n",
            "404/404 [==============================] - 0s 242us/sample - loss: 40.0033 - mean_squared_error: 40.0033\n",
            "Epoch 824/1000\n",
            "404/404 [==============================] - 0s 233us/sample - loss: 32.8325 - mean_squared_error: 32.8325\n",
            "Epoch 825/1000\n",
            "404/404 [==============================] - 0s 242us/sample - loss: 37.9022 - mean_squared_error: 37.9023\n",
            "Epoch 826/1000\n",
            "404/404 [==============================] - 0s 265us/sample - loss: 34.5574 - mean_squared_error: 34.5574\n",
            "Epoch 827/1000\n",
            "404/404 [==============================] - 0s 238us/sample - loss: 42.8959 - mean_squared_error: 42.8959\n",
            "Epoch 828/1000\n",
            "404/404 [==============================] - 0s 231us/sample - loss: 31.1921 - mean_squared_error: 31.1921\n",
            "Epoch 829/1000\n",
            "404/404 [==============================] - 0s 268us/sample - loss: 33.2215 - mean_squared_error: 33.2215\n",
            "Epoch 830/1000\n",
            "404/404 [==============================] - 0s 240us/sample - loss: 31.9860 - mean_squared_error: 31.9860\n",
            "Epoch 831/1000\n",
            "404/404 [==============================] - 0s 242us/sample - loss: 32.3231 - mean_squared_error: 32.3231\n",
            "Epoch 832/1000\n",
            "404/404 [==============================] - 0s 238us/sample - loss: 35.0286 - mean_squared_error: 35.0286\n",
            "Epoch 833/1000\n",
            "404/404 [==============================] - 0s 232us/sample - loss: 34.5218 - mean_squared_error: 34.5218\n",
            "Epoch 834/1000\n",
            "404/404 [==============================] - 0s 230us/sample - loss: 36.1961 - mean_squared_error: 36.1961\n",
            "Epoch 835/1000\n",
            "404/404 [==============================] - 0s 234us/sample - loss: 32.2596 - mean_squared_error: 32.2596\n",
            "Epoch 836/1000\n",
            "404/404 [==============================] - 0s 221us/sample - loss: 34.7924 - mean_squared_error: 34.7924\n",
            "Epoch 837/1000\n",
            "404/404 [==============================] - 0s 258us/sample - loss: 29.8182 - mean_squared_error: 29.8182\n",
            "Epoch 838/1000\n",
            "404/404 [==============================] - 0s 254us/sample - loss: 39.2314 - mean_squared_error: 39.2314\n",
            "Epoch 839/1000\n",
            "404/404 [==============================] - 0s 238us/sample - loss: 39.6566 - mean_squared_error: 39.6566\n",
            "Epoch 840/1000\n",
            "404/404 [==============================] - 0s 239us/sample - loss: 39.8494 - mean_squared_error: 39.8494\n",
            "Epoch 841/1000\n",
            "404/404 [==============================] - 0s 251us/sample - loss: 34.3146 - mean_squared_error: 34.3146\n",
            "Epoch 842/1000\n",
            "404/404 [==============================] - 0s 226us/sample - loss: 38.1407 - mean_squared_error: 38.1407\n",
            "Epoch 843/1000\n",
            "404/404 [==============================] - 0s 247us/sample - loss: 33.7510 - mean_squared_error: 33.7510\n",
            "Epoch 844/1000\n",
            "404/404 [==============================] - 0s 248us/sample - loss: 36.1114 - mean_squared_error: 36.1114\n",
            "Epoch 845/1000\n",
            "404/404 [==============================] - 0s 241us/sample - loss: 38.5666 - mean_squared_error: 38.5666\n",
            "Epoch 846/1000\n",
            "404/404 [==============================] - 0s 243us/sample - loss: 34.4712 - mean_squared_error: 34.4712\n",
            "Epoch 847/1000\n",
            "404/404 [==============================] - 0s 233us/sample - loss: 36.2781 - mean_squared_error: 36.2781\n",
            "Epoch 848/1000\n",
            "404/404 [==============================] - 0s 247us/sample - loss: 42.7486 - mean_squared_error: 42.7486\n",
            "Epoch 849/1000\n",
            "404/404 [==============================] - 0s 244us/sample - loss: 32.0664 - mean_squared_error: 32.0664\n",
            "Epoch 850/1000\n",
            "404/404 [==============================] - 0s 256us/sample - loss: 34.9606 - mean_squared_error: 34.9606\n",
            "Epoch 851/1000\n",
            "404/404 [==============================] - 0s 240us/sample - loss: 31.5585 - mean_squared_error: 31.5585\n",
            "Epoch 852/1000\n",
            "404/404 [==============================] - 0s 226us/sample - loss: 41.1520 - mean_squared_error: 41.1520\n",
            "Epoch 853/1000\n",
            "404/404 [==============================] - 0s 227us/sample - loss: 33.2273 - mean_squared_error: 33.2273\n",
            "Epoch 854/1000\n",
            "404/404 [==============================] - 0s 269us/sample - loss: 35.6032 - mean_squared_error: 35.6032\n",
            "Epoch 855/1000\n",
            "404/404 [==============================] - 0s 243us/sample - loss: 38.1012 - mean_squared_error: 38.1012\n",
            "Epoch 856/1000\n",
            "404/404 [==============================] - 0s 237us/sample - loss: 36.7253 - mean_squared_error: 36.7253\n",
            "Epoch 857/1000\n",
            "404/404 [==============================] - 0s 219us/sample - loss: 33.6154 - mean_squared_error: 33.6154\n",
            "Epoch 858/1000\n",
            "404/404 [==============================] - 0s 253us/sample - loss: 29.5954 - mean_squared_error: 29.5954\n",
            "Epoch 859/1000\n",
            "404/404 [==============================] - 0s 243us/sample - loss: 32.4452 - mean_squared_error: 32.4452\n",
            "Epoch 860/1000\n",
            "404/404 [==============================] - 0s 250us/sample - loss: 36.1902 - mean_squared_error: 36.1902\n",
            "Epoch 861/1000\n",
            "404/404 [==============================] - 0s 240us/sample - loss: 37.6569 - mean_squared_error: 37.6569\n",
            "Epoch 862/1000\n",
            "404/404 [==============================] - 0s 224us/sample - loss: 38.6760 - mean_squared_error: 38.6760\n",
            "Epoch 863/1000\n",
            "404/404 [==============================] - 0s 242us/sample - loss: 36.3682 - mean_squared_error: 36.3682\n",
            "Epoch 864/1000\n",
            "404/404 [==============================] - 0s 231us/sample - loss: 32.0444 - mean_squared_error: 32.0444\n",
            "Epoch 865/1000\n",
            "404/404 [==============================] - 0s 233us/sample - loss: 32.7857 - mean_squared_error: 32.7857\n",
            "Epoch 866/1000\n",
            "404/404 [==============================] - 0s 238us/sample - loss: 36.4486 - mean_squared_error: 36.4486\n",
            "Epoch 867/1000\n",
            "404/404 [==============================] - 0s 226us/sample - loss: 34.5864 - mean_squared_error: 34.5864\n",
            "Epoch 868/1000\n",
            "404/404 [==============================] - 0s 252us/sample - loss: 30.8832 - mean_squared_error: 30.8832\n",
            "Epoch 869/1000\n",
            "404/404 [==============================] - 0s 237us/sample - loss: 34.5164 - mean_squared_error: 34.5164\n",
            "Epoch 870/1000\n",
            "404/404 [==============================] - 0s 237us/sample - loss: 33.8153 - mean_squared_error: 33.8153\n",
            "Epoch 871/1000\n",
            "404/404 [==============================] - 0s 229us/sample - loss: 31.4469 - mean_squared_error: 31.4469\n",
            "Epoch 872/1000\n",
            "404/404 [==============================] - 0s 228us/sample - loss: 34.5735 - mean_squared_error: 34.5735\n",
            "Epoch 873/1000\n",
            "404/404 [==============================] - 0s 251us/sample - loss: 28.8057 - mean_squared_error: 28.8057\n",
            "Epoch 874/1000\n",
            "404/404 [==============================] - 0s 232us/sample - loss: 31.5061 - mean_squared_error: 31.5061\n",
            "Epoch 875/1000\n",
            "404/404 [==============================] - 0s 236us/sample - loss: 43.3665 - mean_squared_error: 43.3665\n",
            "Epoch 876/1000\n",
            "404/404 [==============================] - 0s 234us/sample - loss: 37.1353 - mean_squared_error: 37.1353\n",
            "Epoch 877/1000\n",
            "404/404 [==============================] - 0s 229us/sample - loss: 30.3719 - mean_squared_error: 30.3719\n",
            "Epoch 878/1000\n",
            "404/404 [==============================] - 0s 248us/sample - loss: 37.2689 - mean_squared_error: 37.2689\n",
            "Epoch 879/1000\n",
            "404/404 [==============================] - 0s 256us/sample - loss: 27.5210 - mean_squared_error: 27.5210\n",
            "Epoch 880/1000\n",
            "404/404 [==============================] - 0s 220us/sample - loss: 33.7315 - mean_squared_error: 33.7315\n",
            "Epoch 881/1000\n",
            "404/404 [==============================] - 0s 221us/sample - loss: 44.4869 - mean_squared_error: 44.4869\n",
            "Epoch 882/1000\n",
            "404/404 [==============================] - 0s 228us/sample - loss: 33.5230 - mean_squared_error: 33.5230\n",
            "Epoch 883/1000\n",
            "404/404 [==============================] - 0s 227us/sample - loss: 32.2858 - mean_squared_error: 32.2858\n",
            "Epoch 884/1000\n",
            "404/404 [==============================] - 0s 257us/sample - loss: 34.6594 - mean_squared_error: 34.6594\n",
            "Epoch 885/1000\n",
            "404/404 [==============================] - 0s 251us/sample - loss: 34.0384 - mean_squared_error: 34.0384\n",
            "Epoch 886/1000\n",
            "404/404 [==============================] - 0s 248us/sample - loss: 30.2771 - mean_squared_error: 30.2771\n",
            "Epoch 887/1000\n",
            "404/404 [==============================] - 0s 233us/sample - loss: 41.0206 - mean_squared_error: 41.0206\n",
            "Epoch 888/1000\n",
            "404/404 [==============================] - 0s 239us/sample - loss: 39.6332 - mean_squared_error: 39.6332\n",
            "Epoch 889/1000\n",
            "404/404 [==============================] - 0s 247us/sample - loss: 34.4909 - mean_squared_error: 34.4909\n",
            "Epoch 890/1000\n",
            "404/404 [==============================] - 0s 233us/sample - loss: 37.3375 - mean_squared_error: 37.3375\n",
            "Epoch 891/1000\n",
            "404/404 [==============================] - 0s 247us/sample - loss: 31.3972 - mean_squared_error: 31.3972\n",
            "Epoch 892/1000\n",
            "404/404 [==============================] - 0s 233us/sample - loss: 37.7201 - mean_squared_error: 37.7201\n",
            "Epoch 893/1000\n",
            "404/404 [==============================] - 0s 242us/sample - loss: 30.0826 - mean_squared_error: 30.0826\n",
            "Epoch 894/1000\n",
            "404/404 [==============================] - 0s 223us/sample - loss: 35.8168 - mean_squared_error: 35.8168\n",
            "Epoch 895/1000\n",
            "404/404 [==============================] - 0s 239us/sample - loss: 30.6419 - mean_squared_error: 30.6419\n",
            "Epoch 896/1000\n",
            "404/404 [==============================] - 0s 239us/sample - loss: 33.2229 - mean_squared_error: 33.2229\n",
            "Epoch 897/1000\n",
            "404/404 [==============================] - 0s 231us/sample - loss: 34.0999 - mean_squared_error: 34.0999\n",
            "Epoch 898/1000\n",
            "404/404 [==============================] - 0s 286us/sample - loss: 33.1996 - mean_squared_error: 33.1996\n",
            "Epoch 899/1000\n",
            "404/404 [==============================] - 0s 242us/sample - loss: 38.2542 - mean_squared_error: 38.2542\n",
            "Epoch 900/1000\n",
            "404/404 [==============================] - 0s 222us/sample - loss: 32.8255 - mean_squared_error: 32.8255\n",
            "Epoch 901/1000\n",
            "404/404 [==============================] - 0s 222us/sample - loss: 39.8425 - mean_squared_error: 39.8425\n",
            "Epoch 902/1000\n",
            "404/404 [==============================] - 0s 237us/sample - loss: 35.1037 - mean_squared_error: 35.1037\n",
            "Epoch 903/1000\n",
            "404/404 [==============================] - 0s 239us/sample - loss: 34.9408 - mean_squared_error: 34.9408\n",
            "Epoch 904/1000\n",
            "404/404 [==============================] - 0s 241us/sample - loss: 32.9491 - mean_squared_error: 32.9491\n",
            "Epoch 905/1000\n",
            "404/404 [==============================] - 0s 223us/sample - loss: 37.7938 - mean_squared_error: 37.7938\n",
            "Epoch 906/1000\n",
            "404/404 [==============================] - 0s 224us/sample - loss: 33.5626 - mean_squared_error: 33.5626\n",
            "Epoch 907/1000\n",
            "404/404 [==============================] - 0s 228us/sample - loss: 35.5166 - mean_squared_error: 35.5166\n",
            "Epoch 908/1000\n",
            "404/404 [==============================] - 0s 238us/sample - loss: 41.0076 - mean_squared_error: 41.0076\n",
            "Epoch 909/1000\n",
            "404/404 [==============================] - 0s 223us/sample - loss: 38.4045 - mean_squared_error: 38.4045\n",
            "Epoch 910/1000\n",
            "404/404 [==============================] - 0s 240us/sample - loss: 34.3945 - mean_squared_error: 34.3945\n",
            "Epoch 911/1000\n",
            "404/404 [==============================] - 0s 237us/sample - loss: 32.5449 - mean_squared_error: 32.5449\n",
            "Epoch 912/1000\n",
            "404/404 [==============================] - 0s 228us/sample - loss: 33.5100 - mean_squared_error: 33.5100\n",
            "Epoch 913/1000\n",
            "404/404 [==============================] - 0s 228us/sample - loss: 32.6650 - mean_squared_error: 32.6650\n",
            "Epoch 914/1000\n",
            "404/404 [==============================] - 0s 256us/sample - loss: 31.1548 - mean_squared_error: 31.1549\n",
            "Epoch 915/1000\n",
            "404/404 [==============================] - 0s 242us/sample - loss: 31.3115 - mean_squared_error: 31.3115\n",
            "Epoch 916/1000\n",
            "404/404 [==============================] - 0s 220us/sample - loss: 36.4338 - mean_squared_error: 36.4338\n",
            "Epoch 917/1000\n",
            "404/404 [==============================] - 0s 223us/sample - loss: 46.7599 - mean_squared_error: 46.7599\n",
            "Epoch 918/1000\n",
            "404/404 [==============================] - 0s 236us/sample - loss: 38.8748 - mean_squared_error: 38.8748\n",
            "Epoch 919/1000\n",
            "404/404 [==============================] - 0s 231us/sample - loss: 34.8543 - mean_squared_error: 34.8543\n",
            "Epoch 920/1000\n",
            "404/404 [==============================] - 0s 241us/sample - loss: 35.8709 - mean_squared_error: 35.8709\n",
            "Epoch 921/1000\n",
            "404/404 [==============================] - 0s 262us/sample - loss: 32.0033 - mean_squared_error: 32.0033\n",
            "Epoch 922/1000\n",
            "404/404 [==============================] - 0s 228us/sample - loss: 35.4493 - mean_squared_error: 35.4493\n",
            "Epoch 923/1000\n",
            "404/404 [==============================] - 0s 225us/sample - loss: 38.9108 - mean_squared_error: 38.9108\n",
            "Epoch 924/1000\n",
            "404/404 [==============================] - 0s 239us/sample - loss: 33.9802 - mean_squared_error: 33.9802\n",
            "Epoch 925/1000\n",
            "404/404 [==============================] - 0s 234us/sample - loss: 45.1774 - mean_squared_error: 45.1774\n",
            "Epoch 926/1000\n",
            "404/404 [==============================] - 0s 244us/sample - loss: 32.8633 - mean_squared_error: 32.8633\n",
            "Epoch 927/1000\n",
            "404/404 [==============================] - 0s 234us/sample - loss: 34.4200 - mean_squared_error: 34.4200\n",
            "Epoch 928/1000\n",
            "404/404 [==============================] - 0s 242us/sample - loss: 37.3362 - mean_squared_error: 37.3362\n",
            "Epoch 929/1000\n",
            "404/404 [==============================] - 0s 224us/sample - loss: 31.6467 - mean_squared_error: 31.6467\n",
            "Epoch 930/1000\n",
            "404/404 [==============================] - 0s 234us/sample - loss: 28.5272 - mean_squared_error: 28.5272\n",
            "Epoch 931/1000\n",
            "404/404 [==============================] - 0s 244us/sample - loss: 40.5422 - mean_squared_error: 40.5422\n",
            "Epoch 932/1000\n",
            "404/404 [==============================] - 0s 233us/sample - loss: 35.1674 - mean_squared_error: 35.1674\n",
            "Epoch 933/1000\n",
            "404/404 [==============================] - 0s 250us/sample - loss: 33.6054 - mean_squared_error: 33.6054\n",
            "Epoch 934/1000\n",
            "404/404 [==============================] - 0s 225us/sample - loss: 40.5328 - mean_squared_error: 40.5328\n",
            "Epoch 935/1000\n",
            "404/404 [==============================] - 0s 251us/sample - loss: 29.8324 - mean_squared_error: 29.8324\n",
            "Epoch 936/1000\n",
            "404/404 [==============================] - 0s 229us/sample - loss: 39.9700 - mean_squared_error: 39.9700\n",
            "Epoch 937/1000\n",
            "404/404 [==============================] - 0s 234us/sample - loss: 40.8026 - mean_squared_error: 40.8026\n",
            "Epoch 938/1000\n",
            "404/404 [==============================] - 0s 232us/sample - loss: 34.3820 - mean_squared_error: 34.3820\n",
            "Epoch 939/1000\n",
            "404/404 [==============================] - 0s 245us/sample - loss: 32.1071 - mean_squared_error: 32.1071\n",
            "Epoch 940/1000\n",
            "404/404 [==============================] - 0s 220us/sample - loss: 38.7470 - mean_squared_error: 38.7470\n",
            "Epoch 941/1000\n",
            "404/404 [==============================] - 0s 241us/sample - loss: 35.9686 - mean_squared_error: 35.9686\n",
            "Epoch 942/1000\n",
            "404/404 [==============================] - 0s 233us/sample - loss: 28.2208 - mean_squared_error: 28.2208\n",
            "Epoch 943/1000\n",
            "404/404 [==============================] - 0s 230us/sample - loss: 32.3019 - mean_squared_error: 32.3019\n",
            "Epoch 944/1000\n",
            "404/404 [==============================] - 0s 233us/sample - loss: 40.0703 - mean_squared_error: 40.0703\n",
            "Epoch 945/1000\n",
            "404/404 [==============================] - 0s 230us/sample - loss: 42.7904 - mean_squared_error: 42.7904\n",
            "Epoch 946/1000\n",
            "404/404 [==============================] - 0s 255us/sample - loss: 40.1197 - mean_squared_error: 40.1197\n",
            "Epoch 947/1000\n",
            "404/404 [==============================] - 0s 248us/sample - loss: 31.4701 - mean_squared_error: 31.4701\n",
            "Epoch 948/1000\n",
            "404/404 [==============================] - 0s 238us/sample - loss: 28.8690 - mean_squared_error: 28.8690\n",
            "Epoch 949/1000\n",
            "404/404 [==============================] - 0s 229us/sample - loss: 38.4750 - mean_squared_error: 38.4750\n",
            "Epoch 950/1000\n",
            "404/404 [==============================] - 0s 226us/sample - loss: 34.5145 - mean_squared_error: 34.5145\n",
            "Epoch 951/1000\n",
            "404/404 [==============================] - 0s 243us/sample - loss: 39.6254 - mean_squared_error: 39.6254\n",
            "Epoch 952/1000\n",
            "404/404 [==============================] - 0s 237us/sample - loss: 34.2757 - mean_squared_error: 34.2757\n",
            "Epoch 953/1000\n",
            "404/404 [==============================] - 0s 257us/sample - loss: 36.0123 - mean_squared_error: 36.0123\n",
            "Epoch 954/1000\n",
            "404/404 [==============================] - 0s 230us/sample - loss: 39.4832 - mean_squared_error: 39.4832\n",
            "Epoch 955/1000\n",
            "404/404 [==============================] - 0s 287us/sample - loss: 33.6401 - mean_squared_error: 33.6401\n",
            "Epoch 956/1000\n",
            "404/404 [==============================] - 0s 236us/sample - loss: 38.4897 - mean_squared_error: 38.4897\n",
            "Epoch 957/1000\n",
            "404/404 [==============================] - 0s 238us/sample - loss: 36.9165 - mean_squared_error: 36.9165\n",
            "Epoch 958/1000\n",
            "404/404 [==============================] - 0s 229us/sample - loss: 36.8657 - mean_squared_error: 36.8657\n",
            "Epoch 959/1000\n",
            "404/404 [==============================] - 0s 221us/sample - loss: 32.5304 - mean_squared_error: 32.5304\n",
            "Epoch 960/1000\n",
            "404/404 [==============================] - 0s 222us/sample - loss: 37.8245 - mean_squared_error: 37.8245\n",
            "Epoch 961/1000\n",
            "404/404 [==============================] - 0s 228us/sample - loss: 35.9109 - mean_squared_error: 35.9109\n",
            "Epoch 962/1000\n",
            "404/404 [==============================] - 0s 228us/sample - loss: 29.4453 - mean_squared_error: 29.4453\n",
            "Epoch 963/1000\n",
            "404/404 [==============================] - 0s 215us/sample - loss: 34.7709 - mean_squared_error: 34.7709\n",
            "Epoch 964/1000\n",
            "404/404 [==============================] - 0s 249us/sample - loss: 36.1059 - mean_squared_error: 36.1059\n",
            "Epoch 965/1000\n",
            "404/404 [==============================] - 0s 237us/sample - loss: 35.4437 - mean_squared_error: 35.4437\n",
            "Epoch 966/1000\n",
            "404/404 [==============================] - 0s 227us/sample - loss: 35.4313 - mean_squared_error: 35.4314\n",
            "Epoch 967/1000\n",
            "404/404 [==============================] - 0s 225us/sample - loss: 41.6487 - mean_squared_error: 41.6487\n",
            "Epoch 968/1000\n",
            "404/404 [==============================] - 0s 236us/sample - loss: 32.3528 - mean_squared_error: 32.3528\n",
            "Epoch 969/1000\n",
            "404/404 [==============================] - 0s 238us/sample - loss: 26.9409 - mean_squared_error: 26.9409\n",
            "Epoch 970/1000\n",
            "404/404 [==============================] - 0s 231us/sample - loss: 36.5274 - mean_squared_error: 36.5274\n",
            "Epoch 971/1000\n",
            "404/404 [==============================] - 0s 242us/sample - loss: 31.1946 - mean_squared_error: 31.1946\n",
            "Epoch 972/1000\n",
            "404/404 [==============================] - 0s 232us/sample - loss: 37.6281 - mean_squared_error: 37.6281\n",
            "Epoch 973/1000\n",
            "404/404 [==============================] - 0s 244us/sample - loss: 33.5276 - mean_squared_error: 33.5276\n",
            "Epoch 974/1000\n",
            "404/404 [==============================] - 0s 234us/sample - loss: 29.5210 - mean_squared_error: 29.5210\n",
            "Epoch 975/1000\n",
            "404/404 [==============================] - 0s 236us/sample - loss: 33.6536 - mean_squared_error: 33.6536\n",
            "Epoch 976/1000\n",
            "404/404 [==============================] - 0s 235us/sample - loss: 37.4797 - mean_squared_error: 37.4797\n",
            "Epoch 977/1000\n",
            "404/404 [==============================] - 0s 226us/sample - loss: 28.6040 - mean_squared_error: 28.6040\n",
            "Epoch 978/1000\n",
            "404/404 [==============================] - 0s 242us/sample - loss: 30.9043 - mean_squared_error: 30.9043\n",
            "Epoch 979/1000\n",
            "404/404 [==============================] - 0s 228us/sample - loss: 31.1567 - mean_squared_error: 31.1567\n",
            "Epoch 980/1000\n",
            "404/404 [==============================] - 0s 242us/sample - loss: 35.5754 - mean_squared_error: 35.5754\n",
            "Epoch 981/1000\n",
            "404/404 [==============================] - 0s 236us/sample - loss: 36.7813 - mean_squared_error: 36.7813\n",
            "Epoch 982/1000\n",
            "404/404 [==============================] - 0s 226us/sample - loss: 37.3066 - mean_squared_error: 37.3066\n",
            "Epoch 983/1000\n",
            "404/404 [==============================] - 0s 230us/sample - loss: 32.1854 - mean_squared_error: 32.1854\n",
            "Epoch 984/1000\n",
            "404/404 [==============================] - 0s 218us/sample - loss: 30.6870 - mean_squared_error: 30.6870\n",
            "Epoch 985/1000\n",
            "404/404 [==============================] - 0s 229us/sample - loss: 34.1312 - mean_squared_error: 34.1312\n",
            "Epoch 986/1000\n",
            "404/404 [==============================] - 0s 241us/sample - loss: 29.1121 - mean_squared_error: 29.1121\n",
            "Epoch 987/1000\n",
            "404/404 [==============================] - 0s 232us/sample - loss: 33.8919 - mean_squared_error: 33.8919\n",
            "Epoch 988/1000\n",
            "404/404 [==============================] - 0s 220us/sample - loss: 27.6899 - mean_squared_error: 27.6899\n",
            "Epoch 989/1000\n",
            "404/404 [==============================] - 0s 254us/sample - loss: 31.5513 - mean_squared_error: 31.5513\n",
            "Epoch 990/1000\n",
            "404/404 [==============================] - 0s 248us/sample - loss: 34.0297 - mean_squared_error: 34.0297\n",
            "Epoch 991/1000\n",
            "404/404 [==============================] - 0s 229us/sample - loss: 39.0526 - mean_squared_error: 39.0526\n",
            "Epoch 992/1000\n",
            "404/404 [==============================] - 0s 223us/sample - loss: 38.5741 - mean_squared_error: 38.5741\n",
            "Epoch 993/1000\n",
            "404/404 [==============================] - 0s 220us/sample - loss: 37.5670 - mean_squared_error: 37.5670\n",
            "Epoch 994/1000\n",
            "404/404 [==============================] - 0s 218us/sample - loss: 36.1426 - mean_squared_error: 36.1426\n",
            "Epoch 995/1000\n",
            "404/404 [==============================] - 0s 237us/sample - loss: 29.1378 - mean_squared_error: 29.1378\n",
            "Epoch 996/1000\n",
            "404/404 [==============================] - 0s 247us/sample - loss: 35.5176 - mean_squared_error: 35.5176\n",
            "Epoch 997/1000\n",
            "404/404 [==============================] - 0s 224us/sample - loss: 32.3881 - mean_squared_error: 32.3881\n",
            "Epoch 998/1000\n",
            "404/404 [==============================] - 0s 237us/sample - loss: 28.9659 - mean_squared_error: 28.9659\n",
            "Epoch 999/1000\n",
            "404/404 [==============================] - 0s 235us/sample - loss: 36.6318 - mean_squared_error: 36.6318\n",
            "Epoch 1000/1000\n",
            "404/404 [==============================] - 0s 227us/sample - loss: 32.8032 - mean_squared_error: 32.8032\n",
            "Model: \"sequential_23\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "batch_normalization_26 (Batc multiple                  52        \n",
            "_________________________________________________________________\n",
            "dense_103 (Dense)            multiple                  182       \n",
            "_________________________________________________________________\n",
            "dropout_61 (Dropout)         multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_104 (Dense)            multiple                  182       \n",
            "_________________________________________________________________\n",
            "dropout_62 (Dropout)         multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_105 (Dense)            multiple                  224       \n",
            "_________________________________________________________________\n",
            "dropout_63 (Dropout)         multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_106 (Dense)            multiple                  102       \n",
            "_________________________________________________________________\n",
            "dropout_64 (Dropout)         multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_107 (Dense)            multiple                  7         \n",
            "=================================================================\n",
            "Total params: 749\n",
            "Trainable params: 723\n",
            "Non-trainable params: 26\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHemF45eBHnX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "1a30d67c-3665-4a23-b403-8fc6c17e63d1"
      },
      "source": [
        "model.evaluate(x_test, y_test)[1]"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "102/102 [==============================] - 0s 5ms/sample - loss: 38.4352 - mean_squared_error: 38.4352\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "38.435173"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-9J-YRLBHpb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "46296b21-232a-4bbc-f9b3-b6e040030012"
      },
      "source": [
        "# Plot model loss\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.plot(model_1.history['loss'], alpha=0.5)\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['loss', 'mse'], loc='upper right')\n",
        "plt.show();"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmcAAAHwCAYAAADjOch3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 720x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjoyyjTLBHxX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compare to linear regression model\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import normalize\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.pipeline import make_pipeline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1O1FKWqBHzf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = LinearRegression(normalize=True, n_jobs=-1)\n",
        "\n",
        "lr.fit(x_train, y_train)\n",
        "\n",
        "y_pred = lr.predict(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePIFe1dbBH2P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "908d7ac2-54f9-4663-da66-6788ca1cb72b"
      },
      "source": [
        "mean_squared_error(y_test, y_pred)  # Sad face D,:"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23.195599256422977"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SrciawWf8Ut",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6660531c-41bb-4566-97e0-b704b38cbd6b"
      },
      "source": [
        "from sklearn.metrics import r2_score\n",
        "r2_score(y_test, y_pred)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7213535934621553"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SfcFnOONyuNm"
      },
      "source": [
        "## Use the Keras Library to build an image recognition network using the Fashion-MNIST dataset (also comes with keras)\n",
        "\n",
        "- Load and preprocess the image data similar to how we preprocessed the MNIST data in class.\n",
        "- Make sure to one-hot encode your category labels\n",
        "- Make sure to have your final layer have as many nodes as the number of classes that you want to predict.\n",
        "- Try different hyperparameters. What is the highest accuracy that you are able to achieve.\n",
        "- Use the history object that is returned from model.fit to make graphs of the model's loss or train/validation accuracies by epoch. \n",
        "- Remember that neural networks fall prey to randomness so you may need to run your model multiple times (or use Cross Validation) in order to tell if a change to a hyperparameter is truly producing better results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "szi6-IpuzaH1",
        "colab": {}
      },
      "source": [
        "##### Your Code Here #####\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "np.random.seed(45)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMZYGrLdrlbo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "fce1e350-2261-4a9c-e042-744f5b91f5c2"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "X_train = X_train.reshape(60000, -1).astype('float32')\n",
        "X_test = X_test.reshape(10000, -1).astype('float32')\n",
        "\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255\n",
        "\n",
        "num_classes = 10\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
        "print(\"x_train shape:\", X_train.shape, \"y_train shape:\", y_train.shape)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "x_train shape: (60000, 784) y_train shape: (60000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bqYczAMrleZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "outputId": "7aa8bc9c-9f36-4f9c-e59b-5c0f7d391d1f"
      },
      "source": [
        "mnist_model = Sequential()\n",
        "# Optimizer\n",
        "sgd = keras.optimizers.SGD(learning_rate=0.02, momentum=0.86, nesterov=False)\n",
        "\n",
        "# Input => Hidden\n",
        "mnist_model.add(Dense(16, input_dim=784, activation='relu'))\n",
        "mnist_model.add(Dropout(.20))\n",
        "# Hidden\n",
        "mnist_model.add(Dense(16, activation='relu'))\n",
        "mnist_model.add(Dropout(.20))\n",
        "# Hidden\n",
        "mnist_model.add(Dense(16, activation='relu'))\n",
        "mnist_model.add(Dropout(.20))\n",
        "# Hidden\n",
        "mnist_model.add(Dense(16, activation='relu'))\n",
        "mnist_model.add(Dropout(.20))\n",
        "# Output\n",
        "mnist_model.add(Dense(10,activation='softmax'))\n",
        "\n",
        "#Compile\n",
        "mnist_model.compile(loss='categorical_crossentropy',\n",
        "                    optimizer='adam',\n",
        "                    metrics=['accuracy'])\n",
        "\n",
        "mnist_model.summary()"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_28\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_128 (Dense)            (None, 16)                12560     \n",
            "_________________________________________________________________\n",
            "dropout_77 (Dropout)         (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_129 (Dense)            (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "dropout_78 (Dropout)         (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_130 (Dense)            (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "dropout_79 (Dropout)         (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_131 (Dense)            (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "dropout_80 (Dropout)         (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_132 (Dense)            (None, 10)                170       \n",
            "=================================================================\n",
            "Total params: 13,546\n",
            "Trainable params: 13,546\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osJpGmfirlgj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8170c714-d1ba-4cd4-97e9-db9a47a348b8"
      },
      "source": [
        "history = mnist_model.fit(X_train, y_train, validation_split=0.25, \n",
        "                          batch_size=512, epochs=1000)\n",
        "scores = mnist_model.evaluate(X_test, y_test)"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 45000 samples, validate on 15000 samples\n",
            "Epoch 1/1000\n",
            "45000/45000 [==============================] - 2s 52us/sample - loss: 2.0381 - acc: 0.2448 - val_loss: 1.4124 - val_acc: 0.6320\n",
            "Epoch 2/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 1.5438 - acc: 0.4233 - val_loss: 0.9469 - val_acc: 0.6970\n",
            "Epoch 3/1000\n",
            "45000/45000 [==============================] - 1s 18us/sample - loss: 1.2647 - acc: 0.5120 - val_loss: 0.8037 - val_acc: 0.7270\n",
            "Epoch 4/1000\n",
            "45000/45000 [==============================] - 1s 20us/sample - loss: 1.1251 - acc: 0.5606 - val_loss: 0.7383 - val_acc: 0.7452\n",
            "Epoch 5/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 1.0508 - acc: 0.5893 - val_loss: 0.7125 - val_acc: 0.7545\n",
            "Epoch 6/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.9916 - acc: 0.6124 - val_loss: 0.6951 - val_acc: 0.7607\n",
            "Epoch 7/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.9502 - acc: 0.6345 - val_loss: 0.6688 - val_acc: 0.7789\n",
            "Epoch 8/1000\n",
            "45000/45000 [==============================] - 1s 18us/sample - loss: 0.9211 - acc: 0.6497 - val_loss: 0.6485 - val_acc: 0.7759\n",
            "Epoch 9/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.8902 - acc: 0.6655 - val_loss: 0.6237 - val_acc: 0.7887\n",
            "Epoch 10/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.8677 - acc: 0.6765 - val_loss: 0.6108 - val_acc: 0.7944\n",
            "Epoch 11/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.8493 - acc: 0.6826 - val_loss: 0.5955 - val_acc: 0.7955\n",
            "Epoch 12/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.8331 - acc: 0.6911 - val_loss: 0.5821 - val_acc: 0.8029\n",
            "Epoch 13/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.8129 - acc: 0.6987 - val_loss: 0.5786 - val_acc: 0.8027\n",
            "Epoch 14/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.8048 - acc: 0.7027 - val_loss: 0.5668 - val_acc: 0.8027\n",
            "Epoch 15/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.7900 - acc: 0.7065 - val_loss: 0.5569 - val_acc: 0.8061\n",
            "Epoch 16/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.7809 - acc: 0.7100 - val_loss: 0.5587 - val_acc: 0.8060\n",
            "Epoch 17/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.7751 - acc: 0.7148 - val_loss: 0.5537 - val_acc: 0.8075\n",
            "Epoch 18/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.7687 - acc: 0.7156 - val_loss: 0.5462 - val_acc: 0.8079\n",
            "Epoch 19/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.7662 - acc: 0.7143 - val_loss: 0.5416 - val_acc: 0.8068\n",
            "Epoch 20/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.7585 - acc: 0.7208 - val_loss: 0.5346 - val_acc: 0.8108\n",
            "Epoch 21/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.7526 - acc: 0.7234 - val_loss: 0.5382 - val_acc: 0.8105\n",
            "Epoch 22/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.7464 - acc: 0.7235 - val_loss: 0.5370 - val_acc: 0.8103\n",
            "Epoch 23/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.7356 - acc: 0.7284 - val_loss: 0.5324 - val_acc: 0.8107\n",
            "Epoch 24/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.7400 - acc: 0.7284 - val_loss: 0.5275 - val_acc: 0.8113\n",
            "Epoch 25/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.7312 - acc: 0.7341 - val_loss: 0.5279 - val_acc: 0.8103\n",
            "Epoch 26/1000\n",
            "45000/45000 [==============================] - 1s 18us/sample - loss: 0.7352 - acc: 0.7285 - val_loss: 0.5274 - val_acc: 0.8109\n",
            "Epoch 27/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.7232 - acc: 0.7335 - val_loss: 0.5183 - val_acc: 0.8134\n",
            "Epoch 28/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.7191 - acc: 0.7340 - val_loss: 0.5205 - val_acc: 0.8128\n",
            "Epoch 29/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.7182 - acc: 0.7361 - val_loss: 0.5167 - val_acc: 0.8137\n",
            "Epoch 30/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.7142 - acc: 0.7392 - val_loss: 0.5150 - val_acc: 0.8119\n",
            "Epoch 31/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.7121 - acc: 0.7410 - val_loss: 0.5180 - val_acc: 0.8140\n",
            "Epoch 32/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.7090 - acc: 0.7420 - val_loss: 0.5188 - val_acc: 0.8180\n",
            "Epoch 33/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.7029 - acc: 0.7446 - val_loss: 0.5099 - val_acc: 0.8185\n",
            "Epoch 34/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.7071 - acc: 0.7450 - val_loss: 0.5090 - val_acc: 0.8174\n",
            "Epoch 35/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.7037 - acc: 0.7448 - val_loss: 0.5128 - val_acc: 0.8206\n",
            "Epoch 36/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.7043 - acc: 0.7461 - val_loss: 0.5002 - val_acc: 0.8202\n",
            "Epoch 37/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6942 - acc: 0.7496 - val_loss: 0.5050 - val_acc: 0.8245\n",
            "Epoch 38/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6978 - acc: 0.7474 - val_loss: 0.4988 - val_acc: 0.8185\n",
            "Epoch 39/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6922 - acc: 0.7503 - val_loss: 0.5036 - val_acc: 0.8275\n",
            "Epoch 40/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.6875 - acc: 0.7504 - val_loss: 0.5029 - val_acc: 0.8232\n",
            "Epoch 41/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.6841 - acc: 0.7568 - val_loss: 0.5048 - val_acc: 0.8260\n",
            "Epoch 42/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6827 - acc: 0.7549 - val_loss: 0.5057 - val_acc: 0.8285\n",
            "Epoch 43/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6863 - acc: 0.7540 - val_loss: 0.4978 - val_acc: 0.8262\n",
            "Epoch 44/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6816 - acc: 0.7566 - val_loss: 0.4994 - val_acc: 0.8323\n",
            "Epoch 45/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6797 - acc: 0.7577 - val_loss: 0.4986 - val_acc: 0.8299\n",
            "Epoch 46/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.6787 - acc: 0.7586 - val_loss: 0.4974 - val_acc: 0.8329\n",
            "Epoch 47/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.6779 - acc: 0.7577 - val_loss: 0.5034 - val_acc: 0.8285\n",
            "Epoch 48/1000\n",
            "45000/45000 [==============================] - 1s 20us/sample - loss: 0.6748 - acc: 0.7595 - val_loss: 0.4941 - val_acc: 0.8310\n",
            "Epoch 49/1000\n",
            "45000/45000 [==============================] - 1s 18us/sample - loss: 0.6706 - acc: 0.7585 - val_loss: 0.4951 - val_acc: 0.8323\n",
            "Epoch 50/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.6725 - acc: 0.7608 - val_loss: 0.4910 - val_acc: 0.8299\n",
            "Epoch 51/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.6712 - acc: 0.7612 - val_loss: 0.4886 - val_acc: 0.8307\n",
            "Epoch 52/1000\n",
            "45000/45000 [==============================] - 1s 18us/sample - loss: 0.6654 - acc: 0.7615 - val_loss: 0.4887 - val_acc: 0.8315\n",
            "Epoch 53/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.6660 - acc: 0.7642 - val_loss: 0.5048 - val_acc: 0.8367\n",
            "Epoch 54/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6641 - acc: 0.7652 - val_loss: 0.4868 - val_acc: 0.8312\n",
            "Epoch 55/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.6665 - acc: 0.7645 - val_loss: 0.4905 - val_acc: 0.8311\n",
            "Epoch 56/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6611 - acc: 0.7655 - val_loss: 0.4970 - val_acc: 0.8399\n",
            "Epoch 57/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6516 - acc: 0.7701 - val_loss: 0.4875 - val_acc: 0.8363\n",
            "Epoch 58/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6625 - acc: 0.7667 - val_loss: 0.4898 - val_acc: 0.8385\n",
            "Epoch 59/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.6568 - acc: 0.7685 - val_loss: 0.4965 - val_acc: 0.8377\n",
            "Epoch 60/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6588 - acc: 0.7669 - val_loss: 0.4855 - val_acc: 0.8366\n",
            "Epoch 61/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6571 - acc: 0.7691 - val_loss: 0.4893 - val_acc: 0.8391\n",
            "Epoch 62/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.6552 - acc: 0.7675 - val_loss: 0.4909 - val_acc: 0.8346\n",
            "Epoch 63/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6534 - acc: 0.7668 - val_loss: 0.4879 - val_acc: 0.8417\n",
            "Epoch 64/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6520 - acc: 0.7705 - val_loss: 0.4888 - val_acc: 0.8371\n",
            "Epoch 65/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6521 - acc: 0.7680 - val_loss: 0.4933 - val_acc: 0.8391\n",
            "Epoch 66/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.6558 - acc: 0.7702 - val_loss: 0.4939 - val_acc: 0.8389\n",
            "Epoch 67/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6552 - acc: 0.7677 - val_loss: 0.4951 - val_acc: 0.8340\n",
            "Epoch 68/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6502 - acc: 0.7702 - val_loss: 0.4886 - val_acc: 0.8403\n",
            "Epoch 69/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6508 - acc: 0.7727 - val_loss: 0.4869 - val_acc: 0.8351\n",
            "Epoch 70/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6429 - acc: 0.7739 - val_loss: 0.4903 - val_acc: 0.8371\n",
            "Epoch 71/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6531 - acc: 0.7700 - val_loss: 0.4836 - val_acc: 0.8366\n",
            "Epoch 72/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6447 - acc: 0.7708 - val_loss: 0.4862 - val_acc: 0.8339\n",
            "Epoch 73/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6485 - acc: 0.7722 - val_loss: 0.4842 - val_acc: 0.8415\n",
            "Epoch 74/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6463 - acc: 0.7707 - val_loss: 0.4806 - val_acc: 0.8419\n",
            "Epoch 75/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.6439 - acc: 0.7743 - val_loss: 0.4918 - val_acc: 0.8355\n",
            "Epoch 76/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6467 - acc: 0.7729 - val_loss: 0.4846 - val_acc: 0.8433\n",
            "Epoch 77/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6452 - acc: 0.7733 - val_loss: 0.4905 - val_acc: 0.8358\n",
            "Epoch 78/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.6459 - acc: 0.7736 - val_loss: 0.4826 - val_acc: 0.8392\n",
            "Epoch 79/1000\n",
            "45000/45000 [==============================] - 1s 18us/sample - loss: 0.6438 - acc: 0.7739 - val_loss: 0.4853 - val_acc: 0.8407\n",
            "Epoch 80/1000\n",
            "45000/45000 [==============================] - 1s 18us/sample - loss: 0.6403 - acc: 0.7769 - val_loss: 0.4851 - val_acc: 0.8383\n",
            "Epoch 81/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.6335 - acc: 0.7777 - val_loss: 0.4832 - val_acc: 0.8403\n",
            "Epoch 82/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.6343 - acc: 0.7780 - val_loss: 0.4867 - val_acc: 0.8399\n",
            "Epoch 83/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6420 - acc: 0.7752 - val_loss: 0.4853 - val_acc: 0.8396\n",
            "Epoch 84/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6387 - acc: 0.7766 - val_loss: 0.4854 - val_acc: 0.8410\n",
            "Epoch 85/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6450 - acc: 0.7751 - val_loss: 0.4817 - val_acc: 0.8411\n",
            "Epoch 86/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.6364 - acc: 0.7783 - val_loss: 0.4872 - val_acc: 0.8392\n",
            "Epoch 87/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.6411 - acc: 0.7748 - val_loss: 0.4908 - val_acc: 0.8385\n",
            "Epoch 88/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.6355 - acc: 0.7769 - val_loss: 0.4844 - val_acc: 0.8404\n",
            "Epoch 89/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.6320 - acc: 0.7770 - val_loss: 0.4756 - val_acc: 0.8403\n",
            "Epoch 90/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6334 - acc: 0.7772 - val_loss: 0.4840 - val_acc: 0.8411\n",
            "Epoch 91/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.6317 - acc: 0.7793 - val_loss: 0.4801 - val_acc: 0.8417\n",
            "Epoch 92/1000\n",
            "45000/45000 [==============================] - 1s 20us/sample - loss: 0.6331 - acc: 0.7766 - val_loss: 0.4812 - val_acc: 0.8407\n",
            "Epoch 93/1000\n",
            "45000/45000 [==============================] - 1s 18us/sample - loss: 0.6347 - acc: 0.7777 - val_loss: 0.4777 - val_acc: 0.8414\n",
            "Epoch 94/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.6396 - acc: 0.7761 - val_loss: 0.4860 - val_acc: 0.8333\n",
            "Epoch 95/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6306 - acc: 0.7811 - val_loss: 0.4825 - val_acc: 0.8397\n",
            "Epoch 96/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6282 - acc: 0.7794 - val_loss: 0.4810 - val_acc: 0.8423\n",
            "Epoch 97/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6270 - acc: 0.7824 - val_loss: 0.4822 - val_acc: 0.8434\n",
            "Epoch 98/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.6373 - acc: 0.7750 - val_loss: 0.4792 - val_acc: 0.8399\n",
            "Epoch 99/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6314 - acc: 0.7809 - val_loss: 0.4927 - val_acc: 0.8405\n",
            "Epoch 100/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6316 - acc: 0.7806 - val_loss: 0.4785 - val_acc: 0.8421\n",
            "Epoch 101/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.6285 - acc: 0.7803 - val_loss: 0.4823 - val_acc: 0.8407\n",
            "Epoch 102/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.6368 - acc: 0.7780 - val_loss: 0.4885 - val_acc: 0.8397\n",
            "Epoch 103/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6235 - acc: 0.7824 - val_loss: 0.4867 - val_acc: 0.8401\n",
            "Epoch 104/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6285 - acc: 0.7830 - val_loss: 0.4798 - val_acc: 0.8423\n",
            "Epoch 105/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6323 - acc: 0.7812 - val_loss: 0.4819 - val_acc: 0.8403\n",
            "Epoch 106/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.6277 - acc: 0.7823 - val_loss: 0.4897 - val_acc: 0.8405\n",
            "Epoch 107/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6231 - acc: 0.7817 - val_loss: 0.4768 - val_acc: 0.8420\n",
            "Epoch 108/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6304 - acc: 0.7812 - val_loss: 0.4777 - val_acc: 0.8428\n",
            "Epoch 109/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.6243 - acc: 0.7812 - val_loss: 0.4756 - val_acc: 0.8408\n",
            "Epoch 110/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.6255 - acc: 0.7826 - val_loss: 0.4846 - val_acc: 0.8409\n",
            "Epoch 111/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.6325 - acc: 0.7803 - val_loss: 0.4817 - val_acc: 0.8408\n",
            "Epoch 112/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6303 - acc: 0.7806 - val_loss: 0.4828 - val_acc: 0.8388\n",
            "Epoch 113/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.6222 - acc: 0.7836 - val_loss: 0.4809 - val_acc: 0.8433\n",
            "Epoch 114/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.6194 - acc: 0.7851 - val_loss: 0.4787 - val_acc: 0.8424\n",
            "Epoch 115/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.6229 - acc: 0.7840 - val_loss: 0.4809 - val_acc: 0.8414\n",
            "Epoch 116/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6255 - acc: 0.7842 - val_loss: 0.4831 - val_acc: 0.8367\n",
            "Epoch 117/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6219 - acc: 0.7845 - val_loss: 0.4779 - val_acc: 0.8432\n",
            "Epoch 118/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.6220 - acc: 0.7835 - val_loss: 0.4727 - val_acc: 0.8420\n",
            "Epoch 119/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6200 - acc: 0.7851 - val_loss: 0.4760 - val_acc: 0.8437\n",
            "Epoch 120/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6232 - acc: 0.7829 - val_loss: 0.4724 - val_acc: 0.8447\n",
            "Epoch 121/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6189 - acc: 0.7857 - val_loss: 0.4759 - val_acc: 0.8459\n",
            "Epoch 122/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6191 - acc: 0.7832 - val_loss: 0.4807 - val_acc: 0.8441\n",
            "Epoch 123/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.6139 - acc: 0.7864 - val_loss: 0.4827 - val_acc: 0.8416\n",
            "Epoch 124/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.6190 - acc: 0.7839 - val_loss: 0.4773 - val_acc: 0.8404\n",
            "Epoch 125/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.6180 - acc: 0.7841 - val_loss: 0.4929 - val_acc: 0.8407\n",
            "Epoch 126/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.6193 - acc: 0.7844 - val_loss: 0.4925 - val_acc: 0.8419\n",
            "Epoch 127/1000\n",
            "45000/45000 [==============================] - 1s 20us/sample - loss: 0.6219 - acc: 0.7863 - val_loss: 0.4786 - val_acc: 0.8435\n",
            "Epoch 128/1000\n",
            "45000/45000 [==============================] - 1s 21us/sample - loss: 0.6245 - acc: 0.7837 - val_loss: 0.4846 - val_acc: 0.8392\n",
            "Epoch 129/1000\n",
            "45000/45000 [==============================] - 1s 19us/sample - loss: 0.6164 - acc: 0.7861 - val_loss: 0.4843 - val_acc: 0.8413\n",
            "Epoch 130/1000\n",
            "45000/45000 [==============================] - 1s 18us/sample - loss: 0.6095 - acc: 0.7887 - val_loss: 0.4853 - val_acc: 0.8424\n",
            "Epoch 131/1000\n",
            "45000/45000 [==============================] - 1s 18us/sample - loss: 0.6243 - acc: 0.7834 - val_loss: 0.4813 - val_acc: 0.8373\n",
            "Epoch 132/1000\n",
            "45000/45000 [==============================] - 1s 21us/sample - loss: 0.6328 - acc: 0.7820 - val_loss: 0.4752 - val_acc: 0.8415\n",
            "Epoch 133/1000\n",
            "45000/45000 [==============================] - 1s 18us/sample - loss: 0.6315 - acc: 0.7814 - val_loss: 0.4795 - val_acc: 0.8433\n",
            "Epoch 134/1000\n",
            "45000/45000 [==============================] - 1s 20us/sample - loss: 0.6173 - acc: 0.7855 - val_loss: 0.4848 - val_acc: 0.8422\n",
            "Epoch 135/1000\n",
            "45000/45000 [==============================] - 1s 18us/sample - loss: 0.6196 - acc: 0.7847 - val_loss: 0.4887 - val_acc: 0.8378\n",
            "Epoch 136/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.6087 - acc: 0.7900 - val_loss: 0.4869 - val_acc: 0.8423\n",
            "Epoch 137/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.6087 - acc: 0.7895 - val_loss: 0.4860 - val_acc: 0.8403\n",
            "Epoch 138/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6177 - acc: 0.7853 - val_loss: 0.4850 - val_acc: 0.8395\n",
            "Epoch 139/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6196 - acc: 0.7861 - val_loss: 0.4894 - val_acc: 0.8403\n",
            "Epoch 140/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6176 - acc: 0.7874 - val_loss: 0.4843 - val_acc: 0.8393\n",
            "Epoch 141/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6099 - acc: 0.7900 - val_loss: 0.4752 - val_acc: 0.8445\n",
            "Epoch 142/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.6149 - acc: 0.7868 - val_loss: 0.4769 - val_acc: 0.8439\n",
            "Epoch 143/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6087 - acc: 0.7902 - val_loss: 0.4790 - val_acc: 0.8437\n",
            "Epoch 144/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.6138 - acc: 0.7867 - val_loss: 0.4830 - val_acc: 0.8407\n",
            "Epoch 145/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.6137 - acc: 0.7859 - val_loss: 0.4805 - val_acc: 0.8409\n",
            "Epoch 146/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6140 - acc: 0.7893 - val_loss: 0.4835 - val_acc: 0.8429\n",
            "Epoch 147/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6193 - acc: 0.7859 - val_loss: 0.4720 - val_acc: 0.8448\n",
            "Epoch 148/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6136 - acc: 0.7876 - val_loss: 0.4835 - val_acc: 0.8339\n",
            "Epoch 149/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.6092 - acc: 0.7883 - val_loss: 0.4732 - val_acc: 0.8433\n",
            "Epoch 150/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6077 - acc: 0.7878 - val_loss: 0.4830 - val_acc: 0.8394\n",
            "Epoch 151/1000\n",
            "45000/45000 [==============================] - 1s 18us/sample - loss: 0.6134 - acc: 0.7874 - val_loss: 0.4852 - val_acc: 0.8415\n",
            "Epoch 152/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.6207 - acc: 0.7834 - val_loss: 0.4868 - val_acc: 0.8404\n",
            "Epoch 153/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.6096 - acc: 0.7877 - val_loss: 0.4890 - val_acc: 0.8395\n",
            "Epoch 154/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.6026 - acc: 0.7914 - val_loss: 0.4859 - val_acc: 0.8403\n",
            "Epoch 155/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.6142 - acc: 0.7894 - val_loss: 0.4877 - val_acc: 0.8407\n",
            "Epoch 156/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.6066 - acc: 0.7916 - val_loss: 0.4810 - val_acc: 0.8427\n",
            "Epoch 157/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.6127 - acc: 0.7883 - val_loss: 0.4797 - val_acc: 0.8431\n",
            "Epoch 158/1000\n",
            "45000/45000 [==============================] - 1s 18us/sample - loss: 0.6104 - acc: 0.7895 - val_loss: 0.4760 - val_acc: 0.8419\n",
            "Epoch 159/1000\n",
            "45000/45000 [==============================] - 1s 18us/sample - loss: 0.6038 - acc: 0.7917 - val_loss: 0.4855 - val_acc: 0.8382\n",
            "Epoch 160/1000\n",
            "45000/45000 [==============================] - 1s 18us/sample - loss: 0.6086 - acc: 0.7901 - val_loss: 0.4741 - val_acc: 0.8411\n",
            "Epoch 161/1000\n",
            "45000/45000 [==============================] - 1s 18us/sample - loss: 0.6044 - acc: 0.7902 - val_loss: 0.4867 - val_acc: 0.8423\n",
            "Epoch 162/1000\n",
            "45000/45000 [==============================] - 1s 18us/sample - loss: 0.6093 - acc: 0.7898 - val_loss: 0.4743 - val_acc: 0.8462\n",
            "Epoch 163/1000\n",
            "45000/45000 [==============================] - 1s 18us/sample - loss: 0.6067 - acc: 0.7902 - val_loss: 0.4749 - val_acc: 0.8430\n",
            "Epoch 164/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.6045 - acc: 0.7921 - val_loss: 0.4760 - val_acc: 0.8407\n",
            "Epoch 165/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6030 - acc: 0.7920 - val_loss: 0.4799 - val_acc: 0.8433\n",
            "Epoch 166/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6085 - acc: 0.7891 - val_loss: 0.4844 - val_acc: 0.8409\n",
            "Epoch 167/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.6089 - acc: 0.7883 - val_loss: 0.4831 - val_acc: 0.8409\n",
            "Epoch 168/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6118 - acc: 0.7883 - val_loss: 0.4797 - val_acc: 0.8427\n",
            "Epoch 169/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.6056 - acc: 0.7899 - val_loss: 0.4870 - val_acc: 0.8399\n",
            "Epoch 170/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.6140 - acc: 0.7887 - val_loss: 0.4868 - val_acc: 0.8401\n",
            "Epoch 171/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6099 - acc: 0.7896 - val_loss: 0.4833 - val_acc: 0.8428\n",
            "Epoch 172/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6099 - acc: 0.7886 - val_loss: 0.4835 - val_acc: 0.8397\n",
            "Epoch 173/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6026 - acc: 0.7913 - val_loss: 0.4857 - val_acc: 0.8413\n",
            "Epoch 174/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6075 - acc: 0.7923 - val_loss: 0.4882 - val_acc: 0.8399\n",
            "Epoch 175/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6085 - acc: 0.7902 - val_loss: 0.4846 - val_acc: 0.8421\n",
            "Epoch 176/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6062 - acc: 0.7895 - val_loss: 0.4845 - val_acc: 0.8413\n",
            "Epoch 177/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.6041 - acc: 0.7902 - val_loss: 0.4746 - val_acc: 0.8420\n",
            "Epoch 178/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.6008 - acc: 0.7923 - val_loss: 0.4750 - val_acc: 0.8440\n",
            "Epoch 179/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6038 - acc: 0.7913 - val_loss: 0.4804 - val_acc: 0.8383\n",
            "Epoch 180/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6052 - acc: 0.7923 - val_loss: 0.4726 - val_acc: 0.8435\n",
            "Epoch 181/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6025 - acc: 0.7920 - val_loss: 0.4807 - val_acc: 0.8425\n",
            "Epoch 182/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6010 - acc: 0.7923 - val_loss: 0.4843 - val_acc: 0.8426\n",
            "Epoch 183/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5976 - acc: 0.7937 - val_loss: 0.4810 - val_acc: 0.8397\n",
            "Epoch 184/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6126 - acc: 0.7888 - val_loss: 0.4815 - val_acc: 0.8417\n",
            "Epoch 185/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6019 - acc: 0.7917 - val_loss: 0.4790 - val_acc: 0.8445\n",
            "Epoch 186/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6107 - acc: 0.7874 - val_loss: 0.4743 - val_acc: 0.8433\n",
            "Epoch 187/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6058 - acc: 0.7921 - val_loss: 0.4849 - val_acc: 0.8411\n",
            "Epoch 188/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.6031 - acc: 0.7912 - val_loss: 0.4878 - val_acc: 0.8419\n",
            "Epoch 189/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6007 - acc: 0.7921 - val_loss: 0.4809 - val_acc: 0.8427\n",
            "Epoch 190/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6066 - acc: 0.7916 - val_loss: 0.4880 - val_acc: 0.8393\n",
            "Epoch 191/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5983 - acc: 0.7909 - val_loss: 0.4825 - val_acc: 0.8431\n",
            "Epoch 192/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.6035 - acc: 0.7920 - val_loss: 0.4820 - val_acc: 0.8408\n",
            "Epoch 193/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.5986 - acc: 0.7917 - val_loss: 0.4933 - val_acc: 0.8395\n",
            "Epoch 194/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6010 - acc: 0.7937 - val_loss: 0.4983 - val_acc: 0.8361\n",
            "Epoch 195/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6061 - acc: 0.7886 - val_loss: 0.4841 - val_acc: 0.8385\n",
            "Epoch 196/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6079 - acc: 0.7900 - val_loss: 0.4967 - val_acc: 0.8363\n",
            "Epoch 197/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.6014 - acc: 0.7929 - val_loss: 0.4791 - val_acc: 0.8415\n",
            "Epoch 198/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6071 - acc: 0.7898 - val_loss: 0.4764 - val_acc: 0.8421\n",
            "Epoch 199/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6013 - acc: 0.7921 - val_loss: 0.4784 - val_acc: 0.8431\n",
            "Epoch 200/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.6030 - acc: 0.7900 - val_loss: 0.4830 - val_acc: 0.8395\n",
            "Epoch 201/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5975 - acc: 0.7920 - val_loss: 0.4847 - val_acc: 0.8415\n",
            "Epoch 202/1000\n",
            "45000/45000 [==============================] - 1s 18us/sample - loss: 0.6036 - acc: 0.7928 - val_loss: 0.4782 - val_acc: 0.8425\n",
            "Epoch 203/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5929 - acc: 0.7941 - val_loss: 0.4849 - val_acc: 0.8376\n",
            "Epoch 204/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.6011 - acc: 0.7896 - val_loss: 0.5006 - val_acc: 0.8370\n",
            "Epoch 205/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.6022 - acc: 0.7904 - val_loss: 0.4864 - val_acc: 0.8419\n",
            "Epoch 206/1000\n",
            "45000/45000 [==============================] - 1s 18us/sample - loss: 0.6149 - acc: 0.7852 - val_loss: 0.4898 - val_acc: 0.8373\n",
            "Epoch 207/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.6015 - acc: 0.7905 - val_loss: 0.4806 - val_acc: 0.8395\n",
            "Epoch 208/1000\n",
            "45000/45000 [==============================] - 1s 20us/sample - loss: 0.6040 - acc: 0.7890 - val_loss: 0.4816 - val_acc: 0.8433\n",
            "Epoch 209/1000\n",
            "45000/45000 [==============================] - 1s 18us/sample - loss: 0.6049 - acc: 0.7897 - val_loss: 0.4956 - val_acc: 0.8391\n",
            "Epoch 210/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.6013 - acc: 0.7933 - val_loss: 0.4862 - val_acc: 0.8404\n",
            "Epoch 211/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5941 - acc: 0.7947 - val_loss: 0.4796 - val_acc: 0.8455\n",
            "Epoch 212/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5964 - acc: 0.7940 - val_loss: 0.4866 - val_acc: 0.8389\n",
            "Epoch 213/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5975 - acc: 0.7935 - val_loss: 0.4982 - val_acc: 0.8351\n",
            "Epoch 214/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.6065 - acc: 0.7916 - val_loss: 0.4892 - val_acc: 0.8390\n",
            "Epoch 215/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5941 - acc: 0.7943 - val_loss: 0.4810 - val_acc: 0.8427\n",
            "Epoch 216/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.6031 - acc: 0.7914 - val_loss: 0.4802 - val_acc: 0.8404\n",
            "Epoch 217/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.6019 - acc: 0.7905 - val_loss: 0.4950 - val_acc: 0.8380\n",
            "Epoch 218/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5930 - acc: 0.7950 - val_loss: 0.4936 - val_acc: 0.8386\n",
            "Epoch 219/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5947 - acc: 0.7931 - val_loss: 0.4833 - val_acc: 0.8410\n",
            "Epoch 220/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6012 - acc: 0.7906 - val_loss: 0.4920 - val_acc: 0.8417\n",
            "Epoch 221/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6015 - acc: 0.7947 - val_loss: 0.4790 - val_acc: 0.8406\n",
            "Epoch 222/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.5933 - acc: 0.7957 - val_loss: 0.4914 - val_acc: 0.8395\n",
            "Epoch 223/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5940 - acc: 0.7947 - val_loss: 0.5015 - val_acc: 0.8265\n",
            "Epoch 224/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5987 - acc: 0.7926 - val_loss: 0.4987 - val_acc: 0.8350\n",
            "Epoch 225/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6012 - acc: 0.7931 - val_loss: 0.4889 - val_acc: 0.8377\n",
            "Epoch 226/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.6069 - acc: 0.7888 - val_loss: 0.4860 - val_acc: 0.8388\n",
            "Epoch 227/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5996 - acc: 0.7915 - val_loss: 0.4836 - val_acc: 0.8412\n",
            "Epoch 228/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5955 - acc: 0.7948 - val_loss: 0.4860 - val_acc: 0.8407\n",
            "Epoch 229/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.5997 - acc: 0.7913 - val_loss: 0.4835 - val_acc: 0.8413\n",
            "Epoch 230/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5967 - acc: 0.7937 - val_loss: 0.4885 - val_acc: 0.8387\n",
            "Epoch 231/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5904 - acc: 0.7967 - val_loss: 0.4818 - val_acc: 0.8446\n",
            "Epoch 232/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5941 - acc: 0.7939 - val_loss: 0.4905 - val_acc: 0.8393\n",
            "Epoch 233/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5961 - acc: 0.7941 - val_loss: 0.4820 - val_acc: 0.8389\n",
            "Epoch 234/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5954 - acc: 0.7944 - val_loss: 0.4845 - val_acc: 0.8444\n",
            "Epoch 235/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5891 - acc: 0.7973 - val_loss: 0.4815 - val_acc: 0.8412\n",
            "Epoch 236/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6106 - acc: 0.7914 - val_loss: 0.4848 - val_acc: 0.8400\n",
            "Epoch 237/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5944 - acc: 0.7944 - val_loss: 0.4827 - val_acc: 0.8439\n",
            "Epoch 238/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5866 - acc: 0.7965 - val_loss: 0.4901 - val_acc: 0.8393\n",
            "Epoch 239/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5992 - acc: 0.7948 - val_loss: 0.4980 - val_acc: 0.8305\n",
            "Epoch 240/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5909 - acc: 0.7963 - val_loss: 0.4822 - val_acc: 0.8426\n",
            "Epoch 241/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5944 - acc: 0.7933 - val_loss: 0.4927 - val_acc: 0.8409\n",
            "Epoch 242/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5942 - acc: 0.7946 - val_loss: 0.4914 - val_acc: 0.8429\n",
            "Epoch 243/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5995 - acc: 0.7946 - val_loss: 0.4894 - val_acc: 0.8376\n",
            "Epoch 244/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.5981 - acc: 0.7928 - val_loss: 0.4900 - val_acc: 0.8415\n",
            "Epoch 245/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5913 - acc: 0.7946 - val_loss: 0.4964 - val_acc: 0.8384\n",
            "Epoch 246/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6021 - acc: 0.7914 - val_loss: 0.4977 - val_acc: 0.8339\n",
            "Epoch 247/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.5937 - acc: 0.7940 - val_loss: 0.4928 - val_acc: 0.8358\n",
            "Epoch 248/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5951 - acc: 0.7942 - val_loss: 0.4896 - val_acc: 0.8404\n",
            "Epoch 249/1000\n",
            "45000/45000 [==============================] - 1s 18us/sample - loss: 0.6055 - acc: 0.7893 - val_loss: 0.4815 - val_acc: 0.8375\n",
            "Epoch 250/1000\n",
            "45000/45000 [==============================] - 1s 20us/sample - loss: 0.5987 - acc: 0.7908 - val_loss: 0.4926 - val_acc: 0.8377\n",
            "Epoch 251/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5940 - acc: 0.7930 - val_loss: 0.4856 - val_acc: 0.8403\n",
            "Epoch 252/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5942 - acc: 0.7924 - val_loss: 0.4844 - val_acc: 0.8420\n",
            "Epoch 253/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5916 - acc: 0.7956 - val_loss: 0.4979 - val_acc: 0.8356\n",
            "Epoch 254/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6055 - acc: 0.7922 - val_loss: 0.4859 - val_acc: 0.8397\n",
            "Epoch 255/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6027 - acc: 0.7913 - val_loss: 0.4855 - val_acc: 0.8401\n",
            "Epoch 256/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.6043 - acc: 0.7924 - val_loss: 0.4941 - val_acc: 0.8394\n",
            "Epoch 257/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5943 - acc: 0.7945 - val_loss: 0.4836 - val_acc: 0.8412\n",
            "Epoch 258/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.5912 - acc: 0.7945 - val_loss: 0.4830 - val_acc: 0.8385\n",
            "Epoch 259/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.5906 - acc: 0.7952 - val_loss: 0.4900 - val_acc: 0.8421\n",
            "Epoch 260/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5917 - acc: 0.7955 - val_loss: 0.4818 - val_acc: 0.8387\n",
            "Epoch 261/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.5946 - acc: 0.7935 - val_loss: 0.4764 - val_acc: 0.8430\n",
            "Epoch 262/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.5908 - acc: 0.7940 - val_loss: 0.4876 - val_acc: 0.8393\n",
            "Epoch 263/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.5944 - acc: 0.7930 - val_loss: 0.4830 - val_acc: 0.8389\n",
            "Epoch 264/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.5924 - acc: 0.7950 - val_loss: 0.4893 - val_acc: 0.8387\n",
            "Epoch 265/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.5850 - acc: 0.7942 - val_loss: 0.4903 - val_acc: 0.8403\n",
            "Epoch 266/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5941 - acc: 0.7958 - val_loss: 0.4846 - val_acc: 0.8371\n",
            "Epoch 267/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5857 - acc: 0.7964 - val_loss: 0.4896 - val_acc: 0.8390\n",
            "Epoch 268/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.5899 - acc: 0.7921 - val_loss: 0.4914 - val_acc: 0.8359\n",
            "Epoch 269/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.5923 - acc: 0.7952 - val_loss: 0.4876 - val_acc: 0.8393\n",
            "Epoch 270/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5900 - acc: 0.7955 - val_loss: 0.4914 - val_acc: 0.8318\n",
            "Epoch 271/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5884 - acc: 0.7974 - val_loss: 0.4950 - val_acc: 0.8399\n",
            "Epoch 272/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.6102 - acc: 0.7885 - val_loss: 0.5058 - val_acc: 0.8261\n",
            "Epoch 273/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.6133 - acc: 0.7903 - val_loss: 0.5017 - val_acc: 0.8375\n",
            "Epoch 274/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.5977 - acc: 0.7933 - val_loss: 0.4831 - val_acc: 0.8385\n",
            "Epoch 275/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5957 - acc: 0.7947 - val_loss: 0.4902 - val_acc: 0.8389\n",
            "Epoch 276/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.5940 - acc: 0.7951 - val_loss: 0.4865 - val_acc: 0.8398\n",
            "Epoch 277/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5912 - acc: 0.7964 - val_loss: 0.4931 - val_acc: 0.8392\n",
            "Epoch 278/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.5871 - acc: 0.7954 - val_loss: 0.4927 - val_acc: 0.8413\n",
            "Epoch 279/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.5869 - acc: 0.7967 - val_loss: 0.4869 - val_acc: 0.8388\n",
            "Epoch 280/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.5954 - acc: 0.7942 - val_loss: 0.4922 - val_acc: 0.8389\n",
            "Epoch 281/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.5915 - acc: 0.7929 - val_loss: 0.4978 - val_acc: 0.8335\n",
            "Epoch 282/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.5950 - acc: 0.7932 - val_loss: 0.4928 - val_acc: 0.8408\n",
            "Epoch 283/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5931 - acc: 0.7944 - val_loss: 0.4952 - val_acc: 0.8373\n",
            "Epoch 284/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6098 - acc: 0.7879 - val_loss: 0.4907 - val_acc: 0.8355\n",
            "Epoch 285/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5968 - acc: 0.7918 - val_loss: 0.4927 - val_acc: 0.8397\n",
            "Epoch 286/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.5947 - acc: 0.7943 - val_loss: 0.4862 - val_acc: 0.8401\n",
            "Epoch 287/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6050 - acc: 0.7929 - val_loss: 0.4908 - val_acc: 0.8384\n",
            "Epoch 288/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.5924 - acc: 0.7954 - val_loss: 0.4867 - val_acc: 0.8364\n",
            "Epoch 289/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.6006 - acc: 0.7897 - val_loss: 0.4852 - val_acc: 0.8397\n",
            "Epoch 290/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.5915 - acc: 0.7935 - val_loss: 0.4854 - val_acc: 0.8400\n",
            "Epoch 291/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5897 - acc: 0.7935 - val_loss: 0.4831 - val_acc: 0.8408\n",
            "Epoch 292/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5975 - acc: 0.7916 - val_loss: 0.4954 - val_acc: 0.8405\n",
            "Epoch 293/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.6033 - acc: 0.7857 - val_loss: 0.4923 - val_acc: 0.8387\n",
            "Epoch 294/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.5923 - acc: 0.7932 - val_loss: 0.4882 - val_acc: 0.8397\n",
            "Epoch 295/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5855 - acc: 0.7982 - val_loss: 0.4869 - val_acc: 0.8425\n",
            "Epoch 296/1000\n",
            "45000/45000 [==============================] - 1s 19us/sample - loss: 0.5841 - acc: 0.7984 - val_loss: 0.4905 - val_acc: 0.8421\n",
            "Epoch 297/1000\n",
            "45000/45000 [==============================] - 1s 19us/sample - loss: 0.5915 - acc: 0.7945 - val_loss: 0.4948 - val_acc: 0.8391\n",
            "Epoch 298/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5974 - acc: 0.7910 - val_loss: 0.4878 - val_acc: 0.8393\n",
            "Epoch 299/1000\n",
            "45000/45000 [==============================] - 1s 18us/sample - loss: 0.5870 - acc: 0.7980 - val_loss: 0.4888 - val_acc: 0.8390\n",
            "Epoch 300/1000\n",
            "45000/45000 [==============================] - 1s 18us/sample - loss: 0.5936 - acc: 0.7938 - val_loss: 0.4909 - val_acc: 0.8389\n",
            "Epoch 301/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5955 - acc: 0.7940 - val_loss: 0.5002 - val_acc: 0.8379\n",
            "Epoch 302/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5919 - acc: 0.7954 - val_loss: 0.4897 - val_acc: 0.8391\n",
            "Epoch 303/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5939 - acc: 0.7935 - val_loss: 0.4922 - val_acc: 0.8409\n",
            "Epoch 304/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5877 - acc: 0.7964 - val_loss: 0.4881 - val_acc: 0.8424\n",
            "Epoch 305/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5895 - acc: 0.7950 - val_loss: 0.4928 - val_acc: 0.8425\n",
            "Epoch 306/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5931 - acc: 0.7936 - val_loss: 0.5000 - val_acc: 0.8339\n",
            "Epoch 307/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5903 - acc: 0.7939 - val_loss: 0.4981 - val_acc: 0.8355\n",
            "Epoch 308/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5915 - acc: 0.7967 - val_loss: 0.4882 - val_acc: 0.8403\n",
            "Epoch 309/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.5875 - acc: 0.7956 - val_loss: 0.4936 - val_acc: 0.8443\n",
            "Epoch 310/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.5908 - acc: 0.7990 - val_loss: 0.4861 - val_acc: 0.8416\n",
            "Epoch 311/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.5855 - acc: 0.7949 - val_loss: 0.4980 - val_acc: 0.8373\n",
            "Epoch 312/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.5885 - acc: 0.7958 - val_loss: 0.4891 - val_acc: 0.8396\n",
            "Epoch 313/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5959 - acc: 0.7929 - val_loss: 0.4987 - val_acc: 0.8345\n",
            "Epoch 314/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6021 - acc: 0.7886 - val_loss: 0.5024 - val_acc: 0.8371\n",
            "Epoch 315/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6014 - acc: 0.7892 - val_loss: 0.4904 - val_acc: 0.8379\n",
            "Epoch 316/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.5924 - acc: 0.7931 - val_loss: 0.4926 - val_acc: 0.8406\n",
            "Epoch 317/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5870 - acc: 0.7975 - val_loss: 0.4870 - val_acc: 0.8400\n",
            "Epoch 318/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6113 - acc: 0.7908 - val_loss: 0.4991 - val_acc: 0.8365\n",
            "Epoch 319/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5936 - acc: 0.7950 - val_loss: 0.4927 - val_acc: 0.8378\n",
            "Epoch 320/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.5924 - acc: 0.7946 - val_loss: 0.4924 - val_acc: 0.8401\n",
            "Epoch 321/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5912 - acc: 0.7942 - val_loss: 0.4894 - val_acc: 0.8416\n",
            "Epoch 322/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.6019 - acc: 0.7926 - val_loss: 0.4948 - val_acc: 0.8379\n",
            "Epoch 323/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5913 - acc: 0.7960 - val_loss: 0.4892 - val_acc: 0.8397\n",
            "Epoch 324/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5837 - acc: 0.7970 - val_loss: 0.4835 - val_acc: 0.8413\n",
            "Epoch 325/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5868 - acc: 0.7956 - val_loss: 0.4821 - val_acc: 0.8396\n",
            "Epoch 326/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.6077 - acc: 0.7860 - val_loss: 0.4914 - val_acc: 0.8371\n",
            "Epoch 327/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5873 - acc: 0.7959 - val_loss: 0.4965 - val_acc: 0.8403\n",
            "Epoch 328/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.5916 - acc: 0.7962 - val_loss: 0.5023 - val_acc: 0.8400\n",
            "Epoch 329/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5829 - acc: 0.7995 - val_loss: 0.4948 - val_acc: 0.8394\n",
            "Epoch 330/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5805 - acc: 0.7987 - val_loss: 0.4891 - val_acc: 0.8387\n",
            "Epoch 331/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5868 - acc: 0.7964 - val_loss: 0.4836 - val_acc: 0.8441\n",
            "Epoch 332/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5917 - acc: 0.7979 - val_loss: 0.4850 - val_acc: 0.8429\n",
            "Epoch 333/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5804 - acc: 0.7989 - val_loss: 0.4960 - val_acc: 0.8356\n",
            "Epoch 334/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5885 - acc: 0.7964 - val_loss: 0.5056 - val_acc: 0.8391\n",
            "Epoch 335/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5865 - acc: 0.7993 - val_loss: 0.4980 - val_acc: 0.8373\n",
            "Epoch 336/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5901 - acc: 0.7954 - val_loss: 0.5039 - val_acc: 0.8382\n",
            "Epoch 337/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.5870 - acc: 0.7970 - val_loss: 0.5021 - val_acc: 0.8360\n",
            "Epoch 338/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.5971 - acc: 0.7953 - val_loss: 0.4917 - val_acc: 0.8426\n",
            "Epoch 339/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.5831 - acc: 0.7982 - val_loss: 0.4981 - val_acc: 0.8371\n",
            "Epoch 340/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.5857 - acc: 0.7966 - val_loss: 0.4848 - val_acc: 0.8401\n",
            "Epoch 341/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5790 - acc: 0.8002 - val_loss: 0.4907 - val_acc: 0.8410\n",
            "Epoch 342/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5800 - acc: 0.7986 - val_loss: 0.4879 - val_acc: 0.8389\n",
            "Epoch 343/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5874 - acc: 0.7950 - val_loss: 0.4913 - val_acc: 0.8351\n",
            "Epoch 344/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.5902 - acc: 0.7946 - val_loss: 0.4869 - val_acc: 0.8397\n",
            "Epoch 345/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5872 - acc: 0.7955 - val_loss: 0.4968 - val_acc: 0.8382\n",
            "Epoch 346/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5819 - acc: 0.7992 - val_loss: 0.4907 - val_acc: 0.8369\n",
            "Epoch 347/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5857 - acc: 0.7966 - val_loss: 0.4859 - val_acc: 0.8400\n",
            "Epoch 348/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5886 - acc: 0.7978 - val_loss: 0.4831 - val_acc: 0.8400\n",
            "Epoch 349/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5848 - acc: 0.7982 - val_loss: 0.4891 - val_acc: 0.8397\n",
            "Epoch 350/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5846 - acc: 0.7972 - val_loss: 0.4889 - val_acc: 0.8313\n",
            "Epoch 351/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5914 - acc: 0.7951 - val_loss: 0.4851 - val_acc: 0.8393\n",
            "Epoch 352/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5820 - acc: 0.7989 - val_loss: 0.4913 - val_acc: 0.8380\n",
            "Epoch 353/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5882 - acc: 0.7960 - val_loss: 0.4976 - val_acc: 0.8407\n",
            "Epoch 354/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5868 - acc: 0.7986 - val_loss: 0.4953 - val_acc: 0.8372\n",
            "Epoch 355/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5888 - acc: 0.7938 - val_loss: 0.4969 - val_acc: 0.8361\n",
            "Epoch 356/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5892 - acc: 0.7972 - val_loss: 0.5027 - val_acc: 0.8358\n",
            "Epoch 357/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.5807 - acc: 0.7964 - val_loss: 0.4890 - val_acc: 0.8416\n",
            "Epoch 358/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.5890 - acc: 0.7958 - val_loss: 0.4824 - val_acc: 0.8403\n",
            "Epoch 359/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5886 - acc: 0.7964 - val_loss: 0.4960 - val_acc: 0.8374\n",
            "Epoch 360/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.5882 - acc: 0.7980 - val_loss: 0.4903 - val_acc: 0.8392\n",
            "Epoch 361/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5808 - acc: 0.7976 - val_loss: 0.4928 - val_acc: 0.8420\n",
            "Epoch 362/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5836 - acc: 0.8013 - val_loss: 0.4934 - val_acc: 0.8416\n",
            "Epoch 363/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5944 - acc: 0.7950 - val_loss: 0.4897 - val_acc: 0.8395\n",
            "Epoch 364/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5800 - acc: 0.7986 - val_loss: 0.4855 - val_acc: 0.8390\n",
            "Epoch 365/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5928 - acc: 0.7944 - val_loss: 0.4918 - val_acc: 0.8330\n",
            "Epoch 366/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5863 - acc: 0.7967 - val_loss: 0.4903 - val_acc: 0.8419\n",
            "Epoch 367/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5891 - acc: 0.7966 - val_loss: 0.4845 - val_acc: 0.8425\n",
            "Epoch 368/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5772 - acc: 0.8020 - val_loss: 0.4842 - val_acc: 0.8423\n",
            "Epoch 369/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5830 - acc: 0.7988 - val_loss: 0.4830 - val_acc: 0.8422\n",
            "Epoch 370/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5964 - acc: 0.7902 - val_loss: 0.4997 - val_acc: 0.8365\n",
            "Epoch 371/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5773 - acc: 0.7998 - val_loss: 0.4863 - val_acc: 0.8433\n",
            "Epoch 372/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5904 - acc: 0.7908 - val_loss: 0.4974 - val_acc: 0.8357\n",
            "Epoch 373/1000\n",
            "45000/45000 [==============================] - 1s 18us/sample - loss: 0.5867 - acc: 0.7948 - val_loss: 0.4910 - val_acc: 0.8395\n",
            "Epoch 374/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5975 - acc: 0.7930 - val_loss: 0.5097 - val_acc: 0.8363\n",
            "Epoch 375/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5981 - acc: 0.7923 - val_loss: 0.5112 - val_acc: 0.8307\n",
            "Epoch 376/1000\n",
            "45000/45000 [==============================] - 1s 18us/sample - loss: 0.5957 - acc: 0.7953 - val_loss: 0.4969 - val_acc: 0.8348\n",
            "Epoch 377/1000\n",
            "45000/45000 [==============================] - 1s 18us/sample - loss: 0.5952 - acc: 0.7942 - val_loss: 0.4896 - val_acc: 0.8387\n",
            "Epoch 378/1000\n",
            "45000/45000 [==============================] - 1s 18us/sample - loss: 0.5834 - acc: 0.7986 - val_loss: 0.4835 - val_acc: 0.8388\n",
            "Epoch 379/1000\n",
            "45000/45000 [==============================] - 1s 18us/sample - loss: 0.5831 - acc: 0.7959 - val_loss: 0.4943 - val_acc: 0.8382\n",
            "Epoch 380/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5832 - acc: 0.7957 - val_loss: 0.4893 - val_acc: 0.8410\n",
            "Epoch 381/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5783 - acc: 0.8007 - val_loss: 0.4962 - val_acc: 0.8373\n",
            "Epoch 382/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5865 - acc: 0.7974 - val_loss: 0.4884 - val_acc: 0.8420\n",
            "Epoch 383/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5878 - acc: 0.7967 - val_loss: 0.4899 - val_acc: 0.8377\n",
            "Epoch 384/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5878 - acc: 0.7967 - val_loss: 0.4875 - val_acc: 0.8383\n",
            "Epoch 385/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5900 - acc: 0.7970 - val_loss: 0.4909 - val_acc: 0.8314\n",
            "Epoch 386/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5918 - acc: 0.7928 - val_loss: 0.4970 - val_acc: 0.8333\n",
            "Epoch 387/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5829 - acc: 0.7971 - val_loss: 0.4869 - val_acc: 0.8391\n",
            "Epoch 388/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5834 - acc: 0.7978 - val_loss: 0.4928 - val_acc: 0.8359\n",
            "Epoch 389/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5834 - acc: 0.7976 - val_loss: 0.4866 - val_acc: 0.8435\n",
            "Epoch 390/1000\n",
            "45000/45000 [==============================] - 1s 18us/sample - loss: 0.5847 - acc: 0.7977 - val_loss: 0.4870 - val_acc: 0.8380\n",
            "Epoch 391/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5844 - acc: 0.7982 - val_loss: 0.4919 - val_acc: 0.8408\n",
            "Epoch 392/1000\n",
            "45000/45000 [==============================] - 1s 18us/sample - loss: 0.5855 - acc: 0.7958 - val_loss: 0.4874 - val_acc: 0.8403\n",
            "Epoch 393/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5750 - acc: 0.8001 - val_loss: 0.4932 - val_acc: 0.8425\n",
            "Epoch 394/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5875 - acc: 0.7957 - val_loss: 0.4973 - val_acc: 0.8374\n",
            "Epoch 395/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5850 - acc: 0.7986 - val_loss: 0.4961 - val_acc: 0.8397\n",
            "Epoch 396/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5996 - acc: 0.7944 - val_loss: 0.5123 - val_acc: 0.8296\n",
            "Epoch 397/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5831 - acc: 0.7979 - val_loss: 0.4897 - val_acc: 0.8403\n",
            "Epoch 398/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5855 - acc: 0.7978 - val_loss: 0.5158 - val_acc: 0.8297\n",
            "Epoch 399/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5898 - acc: 0.7929 - val_loss: 0.4874 - val_acc: 0.8417\n",
            "Epoch 400/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5812 - acc: 0.7997 - val_loss: 0.4969 - val_acc: 0.8394\n",
            "Epoch 401/1000\n",
            "45000/45000 [==============================] - 1s 18us/sample - loss: 0.5775 - acc: 0.7997 - val_loss: 0.4887 - val_acc: 0.8387\n",
            "Epoch 402/1000\n",
            "45000/45000 [==============================] - 1s 21us/sample - loss: 0.5822 - acc: 0.7981 - val_loss: 0.4935 - val_acc: 0.8396\n",
            "Epoch 403/1000\n",
            "45000/45000 [==============================] - 1s 18us/sample - loss: 0.5788 - acc: 0.8004 - val_loss: 0.4907 - val_acc: 0.8358\n",
            "Epoch 404/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5881 - acc: 0.7936 - val_loss: 0.4984 - val_acc: 0.8349\n",
            "Epoch 405/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5834 - acc: 0.7984 - val_loss: 0.5016 - val_acc: 0.8352\n",
            "Epoch 406/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5835 - acc: 0.7972 - val_loss: 0.4884 - val_acc: 0.8374\n",
            "Epoch 407/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5868 - acc: 0.7972 - val_loss: 0.4984 - val_acc: 0.8391\n",
            "Epoch 408/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5926 - acc: 0.7966 - val_loss: 0.5005 - val_acc: 0.8371\n",
            "Epoch 409/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5913 - acc: 0.7946 - val_loss: 0.4889 - val_acc: 0.8389\n",
            "Epoch 410/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.5784 - acc: 0.8003 - val_loss: 0.5006 - val_acc: 0.8378\n",
            "Epoch 411/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5906 - acc: 0.7958 - val_loss: 0.4964 - val_acc: 0.8395\n",
            "Epoch 412/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5894 - acc: 0.7952 - val_loss: 0.4924 - val_acc: 0.8406\n",
            "Epoch 413/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5849 - acc: 0.7961 - val_loss: 0.4845 - val_acc: 0.8351\n",
            "Epoch 414/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6027 - acc: 0.7941 - val_loss: 0.4935 - val_acc: 0.8373\n",
            "Epoch 415/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5919 - acc: 0.7932 - val_loss: 0.4884 - val_acc: 0.8351\n",
            "Epoch 416/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5873 - acc: 0.7961 - val_loss: 0.4887 - val_acc: 0.8377\n",
            "Epoch 417/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5887 - acc: 0.7952 - val_loss: 0.4962 - val_acc: 0.8404\n",
            "Epoch 418/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5869 - acc: 0.7931 - val_loss: 0.4970 - val_acc: 0.8365\n",
            "Epoch 419/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5883 - acc: 0.7984 - val_loss: 0.4928 - val_acc: 0.8375\n",
            "Epoch 420/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5852 - acc: 0.7978 - val_loss: 0.4949 - val_acc: 0.8377\n",
            "Epoch 421/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5822 - acc: 0.7972 - val_loss: 0.4980 - val_acc: 0.8367\n",
            "Epoch 422/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5797 - acc: 0.7990 - val_loss: 0.4984 - val_acc: 0.8377\n",
            "Epoch 423/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.5874 - acc: 0.7977 - val_loss: 0.4866 - val_acc: 0.8393\n",
            "Epoch 424/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.5731 - acc: 0.8002 - val_loss: 0.4911 - val_acc: 0.8403\n",
            "Epoch 425/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.5817 - acc: 0.7987 - val_loss: 0.4871 - val_acc: 0.8392\n",
            "Epoch 426/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.5812 - acc: 0.7994 - val_loss: 0.4916 - val_acc: 0.8393\n",
            "Epoch 427/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.5862 - acc: 0.8002 - val_loss: 0.4894 - val_acc: 0.8395\n",
            "Epoch 428/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5820 - acc: 0.7994 - val_loss: 0.5008 - val_acc: 0.8338\n",
            "Epoch 429/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5850 - acc: 0.7980 - val_loss: 0.5027 - val_acc: 0.8378\n",
            "Epoch 430/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5818 - acc: 0.7950 - val_loss: 0.4849 - val_acc: 0.8373\n",
            "Epoch 431/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.5746 - acc: 0.8000 - val_loss: 0.4937 - val_acc: 0.8418\n",
            "Epoch 432/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.5798 - acc: 0.7994 - val_loss: 0.4896 - val_acc: 0.8385\n",
            "Epoch 433/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5872 - acc: 0.7988 - val_loss: 0.4933 - val_acc: 0.8411\n",
            "Epoch 434/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5853 - acc: 0.7976 - val_loss: 0.4912 - val_acc: 0.8389\n",
            "Epoch 435/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5832 - acc: 0.7961 - val_loss: 0.5026 - val_acc: 0.8378\n",
            "Epoch 436/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5902 - acc: 0.7930 - val_loss: 0.4873 - val_acc: 0.8375\n",
            "Epoch 437/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5878 - acc: 0.7966 - val_loss: 0.4900 - val_acc: 0.8368\n",
            "Epoch 438/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5799 - acc: 0.8008 - val_loss: 0.4903 - val_acc: 0.8394\n",
            "Epoch 439/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.5805 - acc: 0.7982 - val_loss: 0.4898 - val_acc: 0.8415\n",
            "Epoch 440/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5859 - acc: 0.7972 - val_loss: 0.4967 - val_acc: 0.8411\n",
            "Epoch 441/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5823 - acc: 0.7972 - val_loss: 0.4904 - val_acc: 0.8398\n",
            "Epoch 442/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5733 - acc: 0.8013 - val_loss: 0.4877 - val_acc: 0.8415\n",
            "Epoch 443/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5792 - acc: 0.7977 - val_loss: 0.4958 - val_acc: 0.8377\n",
            "Epoch 444/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5780 - acc: 0.7999 - val_loss: 0.4867 - val_acc: 0.8413\n",
            "Epoch 445/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5787 - acc: 0.8008 - val_loss: 0.4883 - val_acc: 0.8411\n",
            "Epoch 446/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.5815 - acc: 0.7952 - val_loss: 0.5007 - val_acc: 0.8377\n",
            "Epoch 447/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5893 - acc: 0.7944 - val_loss: 0.4941 - val_acc: 0.8413\n",
            "Epoch 448/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.5822 - acc: 0.7979 - val_loss: 0.4900 - val_acc: 0.8409\n",
            "Epoch 449/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5763 - acc: 0.7984 - val_loss: 0.4951 - val_acc: 0.8417\n",
            "Epoch 450/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5850 - acc: 0.7962 - val_loss: 0.5009 - val_acc: 0.8374\n",
            "Epoch 451/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5843 - acc: 0.7975 - val_loss: 0.4944 - val_acc: 0.8389\n",
            "Epoch 452/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5802 - acc: 0.7989 - val_loss: 0.4900 - val_acc: 0.8417\n",
            "Epoch 453/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5807 - acc: 0.7974 - val_loss: 0.4963 - val_acc: 0.8406\n",
            "Epoch 454/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5959 - acc: 0.7935 - val_loss: 0.5041 - val_acc: 0.8337\n",
            "Epoch 455/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5765 - acc: 0.7995 - val_loss: 0.4952 - val_acc: 0.8411\n",
            "Epoch 456/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5905 - acc: 0.7953 - val_loss: 0.4884 - val_acc: 0.8388\n",
            "Epoch 457/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5895 - acc: 0.7962 - val_loss: 0.4998 - val_acc: 0.8371\n",
            "Epoch 458/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5818 - acc: 0.8001 - val_loss: 0.4945 - val_acc: 0.8357\n",
            "Epoch 459/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5777 - acc: 0.8004 - val_loss: 0.5053 - val_acc: 0.8359\n",
            "Epoch 460/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5782 - acc: 0.7990 - val_loss: 0.4969 - val_acc: 0.8405\n",
            "Epoch 461/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5849 - acc: 0.7990 - val_loss: 0.4913 - val_acc: 0.8407\n",
            "Epoch 462/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5816 - acc: 0.8002 - val_loss: 0.4911 - val_acc: 0.8384\n",
            "Epoch 463/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5868 - acc: 0.7967 - val_loss: 0.4888 - val_acc: 0.8381\n",
            "Epoch 464/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5848 - acc: 0.7980 - val_loss: 0.4930 - val_acc: 0.8400\n",
            "Epoch 465/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5877 - acc: 0.7962 - val_loss: 0.4940 - val_acc: 0.8402\n",
            "Epoch 466/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5862 - acc: 0.7949 - val_loss: 0.5087 - val_acc: 0.8319\n",
            "Epoch 467/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6030 - acc: 0.7881 - val_loss: 0.4958 - val_acc: 0.8361\n",
            "Epoch 468/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5823 - acc: 0.7966 - val_loss: 0.4983 - val_acc: 0.8344\n",
            "Epoch 469/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5768 - acc: 0.7967 - val_loss: 0.4932 - val_acc: 0.8383\n",
            "Epoch 470/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5747 - acc: 0.8006 - val_loss: 0.4900 - val_acc: 0.8377\n",
            "Epoch 471/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5834 - acc: 0.7960 - val_loss: 0.4932 - val_acc: 0.8381\n",
            "Epoch 472/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5958 - acc: 0.7946 - val_loss: 0.4999 - val_acc: 0.8321\n",
            "Epoch 473/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.6217 - acc: 0.7814 - val_loss: 0.4998 - val_acc: 0.8372\n",
            "Epoch 474/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5886 - acc: 0.7962 - val_loss: 0.5050 - val_acc: 0.8332\n",
            "Epoch 475/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6000 - acc: 0.7928 - val_loss: 0.4969 - val_acc: 0.8329\n",
            "Epoch 476/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5902 - acc: 0.7979 - val_loss: 0.4824 - val_acc: 0.8346\n",
            "Epoch 477/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5887 - acc: 0.7954 - val_loss: 0.4907 - val_acc: 0.8370\n",
            "Epoch 478/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5817 - acc: 0.8006 - val_loss: 0.4950 - val_acc: 0.8367\n",
            "Epoch 479/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5771 - acc: 0.7990 - val_loss: 0.4872 - val_acc: 0.8383\n",
            "Epoch 480/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5844 - acc: 0.7965 - val_loss: 0.5105 - val_acc: 0.8357\n",
            "Epoch 481/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5870 - acc: 0.7959 - val_loss: 0.4935 - val_acc: 0.8381\n",
            "Epoch 482/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.5882 - acc: 0.7952 - val_loss: 0.4973 - val_acc: 0.8337\n",
            "Epoch 483/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5874 - acc: 0.7956 - val_loss: 0.4956 - val_acc: 0.8378\n",
            "Epoch 484/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5836 - acc: 0.7996 - val_loss: 0.4904 - val_acc: 0.8401\n",
            "Epoch 485/1000\n",
            "45000/45000 [==============================] - 1s 18us/sample - loss: 0.5697 - acc: 0.8011 - val_loss: 0.5003 - val_acc: 0.8421\n",
            "Epoch 486/1000\n",
            "45000/45000 [==============================] - 1s 18us/sample - loss: 0.5837 - acc: 0.7956 - val_loss: 0.4952 - val_acc: 0.8360\n",
            "Epoch 487/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5756 - acc: 0.7989 - val_loss: 0.4921 - val_acc: 0.8355\n",
            "Epoch 488/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5732 - acc: 0.7994 - val_loss: 0.4908 - val_acc: 0.8360\n",
            "Epoch 489/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5784 - acc: 0.7984 - val_loss: 0.4870 - val_acc: 0.8391\n",
            "Epoch 490/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5828 - acc: 0.7980 - val_loss: 0.4900 - val_acc: 0.8406\n",
            "Epoch 491/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5835 - acc: 0.7964 - val_loss: 0.5099 - val_acc: 0.8370\n",
            "Epoch 492/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5849 - acc: 0.7983 - val_loss: 0.5007 - val_acc: 0.8354\n",
            "Epoch 493/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5878 - acc: 0.7963 - val_loss: 0.4944 - val_acc: 0.8385\n",
            "Epoch 494/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5879 - acc: 0.7961 - val_loss: 0.4903 - val_acc: 0.8383\n",
            "Epoch 495/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5890 - acc: 0.7959 - val_loss: 0.4965 - val_acc: 0.8409\n",
            "Epoch 496/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5770 - acc: 0.7986 - val_loss: 0.4973 - val_acc: 0.8411\n",
            "Epoch 497/1000\n",
            "45000/45000 [==============================] - 1s 18us/sample - loss: 0.5722 - acc: 0.8044 - val_loss: 0.4946 - val_acc: 0.8358\n",
            "Epoch 498/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5751 - acc: 0.8008 - val_loss: 0.4931 - val_acc: 0.8404\n",
            "Epoch 499/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5862 - acc: 0.7944 - val_loss: 0.4940 - val_acc: 0.8388\n",
            "Epoch 500/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.5753 - acc: 0.7993 - val_loss: 0.4974 - val_acc: 0.8382\n",
            "Epoch 501/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5758 - acc: 0.7980 - val_loss: 0.4943 - val_acc: 0.8391\n",
            "Epoch 502/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5844 - acc: 0.7952 - val_loss: 0.4860 - val_acc: 0.8389\n",
            "Epoch 503/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5956 - acc: 0.7932 - val_loss: 0.4842 - val_acc: 0.8410\n",
            "Epoch 504/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5772 - acc: 0.7988 - val_loss: 0.4978 - val_acc: 0.8406\n",
            "Epoch 505/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5827 - acc: 0.8000 - val_loss: 0.5251 - val_acc: 0.8229\n",
            "Epoch 506/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.6104 - acc: 0.7892 - val_loss: 0.5094 - val_acc: 0.8311\n",
            "Epoch 507/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5906 - acc: 0.7927 - val_loss: 0.4923 - val_acc: 0.8362\n",
            "Epoch 508/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5908 - acc: 0.7947 - val_loss: 0.4884 - val_acc: 0.8403\n",
            "Epoch 509/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5858 - acc: 0.7961 - val_loss: 0.4958 - val_acc: 0.8345\n",
            "Epoch 510/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5869 - acc: 0.7968 - val_loss: 0.4899 - val_acc: 0.8393\n",
            "Epoch 511/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5795 - acc: 0.7989 - val_loss: 0.4865 - val_acc: 0.8391\n",
            "Epoch 512/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5790 - acc: 0.7978 - val_loss: 0.4956 - val_acc: 0.8397\n",
            "Epoch 513/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5765 - acc: 0.8006 - val_loss: 0.4917 - val_acc: 0.8399\n",
            "Epoch 514/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5820 - acc: 0.7972 - val_loss: 0.4874 - val_acc: 0.8379\n",
            "Epoch 515/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5837 - acc: 0.7997 - val_loss: 0.4893 - val_acc: 0.8384\n",
            "Epoch 516/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5922 - acc: 0.7946 - val_loss: 0.4974 - val_acc: 0.8314\n",
            "Epoch 517/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5861 - acc: 0.7977 - val_loss: 0.4901 - val_acc: 0.8408\n",
            "Epoch 518/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5779 - acc: 0.7986 - val_loss: 0.4962 - val_acc: 0.8406\n",
            "Epoch 519/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5744 - acc: 0.8024 - val_loss: 0.4956 - val_acc: 0.8383\n",
            "Epoch 520/1000\n",
            "45000/45000 [==============================] - 1s 19us/sample - loss: 0.5806 - acc: 0.7980 - val_loss: 0.4878 - val_acc: 0.8412\n",
            "Epoch 521/1000\n",
            "45000/45000 [==============================] - 1s 21us/sample - loss: 0.5781 - acc: 0.7995 - val_loss: 0.4911 - val_acc: 0.8340\n",
            "Epoch 522/1000\n",
            "45000/45000 [==============================] - 1s 19us/sample - loss: 0.5761 - acc: 0.8007 - val_loss: 0.4952 - val_acc: 0.8403\n",
            "Epoch 523/1000\n",
            "45000/45000 [==============================] - 1s 19us/sample - loss: 0.5771 - acc: 0.8004 - val_loss: 0.4929 - val_acc: 0.8299\n",
            "Epoch 524/1000\n",
            "45000/45000 [==============================] - 1s 18us/sample - loss: 0.5794 - acc: 0.7978 - val_loss: 0.4902 - val_acc: 0.8376\n",
            "Epoch 525/1000\n",
            "45000/45000 [==============================] - 1s 18us/sample - loss: 0.5724 - acc: 0.8015 - val_loss: 0.4889 - val_acc: 0.8425\n",
            "Epoch 526/1000\n",
            "45000/45000 [==============================] - 1s 18us/sample - loss: 0.5862 - acc: 0.7966 - val_loss: 0.4864 - val_acc: 0.8380\n",
            "Epoch 527/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5664 - acc: 0.8052 - val_loss: 0.4832 - val_acc: 0.8423\n",
            "Epoch 528/1000\n",
            "45000/45000 [==============================] - 1s 18us/sample - loss: 0.5731 - acc: 0.8028 - val_loss: 0.4915 - val_acc: 0.8359\n",
            "Epoch 529/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5794 - acc: 0.7957 - val_loss: 0.4974 - val_acc: 0.8398\n",
            "Epoch 530/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5745 - acc: 0.8011 - val_loss: 0.4913 - val_acc: 0.8413\n",
            "Epoch 531/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5819 - acc: 0.7984 - val_loss: 0.4936 - val_acc: 0.8377\n",
            "Epoch 532/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5679 - acc: 0.8023 - val_loss: 0.4884 - val_acc: 0.8403\n",
            "Epoch 533/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5747 - acc: 0.8020 - val_loss: 0.4985 - val_acc: 0.8405\n",
            "Epoch 534/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.5801 - acc: 0.8026 - val_loss: 0.5020 - val_acc: 0.8375\n",
            "Epoch 535/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.5800 - acc: 0.8006 - val_loss: 0.4930 - val_acc: 0.8405\n",
            "Epoch 536/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5752 - acc: 0.8023 - val_loss: 0.4849 - val_acc: 0.8401\n",
            "Epoch 537/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5928 - acc: 0.7952 - val_loss: 0.4996 - val_acc: 0.8381\n",
            "Epoch 538/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5894 - acc: 0.7946 - val_loss: 0.5038 - val_acc: 0.8368\n",
            "Epoch 539/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5875 - acc: 0.7997 - val_loss: 0.4905 - val_acc: 0.8405\n",
            "Epoch 540/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5797 - acc: 0.8018 - val_loss: 0.4923 - val_acc: 0.8393\n",
            "Epoch 541/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.5819 - acc: 0.8019 - val_loss: 0.4815 - val_acc: 0.8399\n",
            "Epoch 542/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5864 - acc: 0.7950 - val_loss: 0.5011 - val_acc: 0.8332\n",
            "Epoch 543/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5875 - acc: 0.7977 - val_loss: 0.4914 - val_acc: 0.8409\n",
            "Epoch 544/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5799 - acc: 0.7981 - val_loss: 0.5005 - val_acc: 0.8369\n",
            "Epoch 545/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5802 - acc: 0.8002 - val_loss: 0.4952 - val_acc: 0.8362\n",
            "Epoch 546/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5868 - acc: 0.7958 - val_loss: 0.4831 - val_acc: 0.8440\n",
            "Epoch 547/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5720 - acc: 0.8021 - val_loss: 0.4886 - val_acc: 0.8406\n",
            "Epoch 548/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.5759 - acc: 0.7998 - val_loss: 0.5025 - val_acc: 0.8312\n",
            "Epoch 549/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5804 - acc: 0.7978 - val_loss: 0.4904 - val_acc: 0.8392\n",
            "Epoch 550/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5685 - acc: 0.8022 - val_loss: 0.4904 - val_acc: 0.8388\n",
            "Epoch 551/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5888 - acc: 0.7990 - val_loss: 0.4970 - val_acc: 0.8340\n",
            "Epoch 552/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5694 - acc: 0.7998 - val_loss: 0.5001 - val_acc: 0.8403\n",
            "Epoch 553/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5776 - acc: 0.8016 - val_loss: 0.4881 - val_acc: 0.8364\n",
            "Epoch 554/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5712 - acc: 0.8019 - val_loss: 0.4934 - val_acc: 0.8396\n",
            "Epoch 555/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5749 - acc: 0.7993 - val_loss: 0.5094 - val_acc: 0.8342\n",
            "Epoch 556/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5749 - acc: 0.8005 - val_loss: 0.4906 - val_acc: 0.8371\n",
            "Epoch 557/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5732 - acc: 0.8008 - val_loss: 0.4919 - val_acc: 0.8391\n",
            "Epoch 558/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.5720 - acc: 0.7991 - val_loss: 0.5012 - val_acc: 0.8386\n",
            "Epoch 559/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.5955 - acc: 0.7889 - val_loss: 0.4990 - val_acc: 0.8393\n",
            "Epoch 560/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5900 - acc: 0.7927 - val_loss: 0.5024 - val_acc: 0.8373\n",
            "Epoch 561/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5895 - acc: 0.7962 - val_loss: 0.4978 - val_acc: 0.8402\n",
            "Epoch 562/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5756 - acc: 0.8016 - val_loss: 0.4874 - val_acc: 0.8398\n",
            "Epoch 563/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5793 - acc: 0.7994 - val_loss: 0.5046 - val_acc: 0.8361\n",
            "Epoch 564/1000\n",
            "45000/45000 [==============================] - 1s 18us/sample - loss: 0.5957 - acc: 0.7945 - val_loss: 0.5045 - val_acc: 0.8304\n",
            "Epoch 565/1000\n",
            "45000/45000 [==============================] - 1s 18us/sample - loss: 0.5801 - acc: 0.8004 - val_loss: 0.4941 - val_acc: 0.8396\n",
            "Epoch 566/1000\n",
            "45000/45000 [==============================] - 1s 19us/sample - loss: 0.5755 - acc: 0.8016 - val_loss: 0.4911 - val_acc: 0.8393\n",
            "Epoch 567/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5770 - acc: 0.7990 - val_loss: 0.4939 - val_acc: 0.8391\n",
            "Epoch 568/1000\n",
            "45000/45000 [==============================] - 1s 18us/sample - loss: 0.6012 - acc: 0.7949 - val_loss: 0.4964 - val_acc: 0.8395\n",
            "Epoch 569/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.6023 - acc: 0.7899 - val_loss: 0.5033 - val_acc: 0.8347\n",
            "Epoch 570/1000\n",
            "45000/45000 [==============================] - 1s 20us/sample - loss: 0.5785 - acc: 0.7994 - val_loss: 0.4970 - val_acc: 0.8401\n",
            "Epoch 571/1000\n",
            "45000/45000 [==============================] - 1s 18us/sample - loss: 0.5717 - acc: 0.8042 - val_loss: 0.4886 - val_acc: 0.8377\n",
            "Epoch 572/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5816 - acc: 0.8013 - val_loss: 0.4982 - val_acc: 0.8352\n",
            "Epoch 573/1000\n",
            "45000/45000 [==============================] - 1s 18us/sample - loss: 0.5736 - acc: 0.8032 - val_loss: 0.4894 - val_acc: 0.8391\n",
            "Epoch 574/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5825 - acc: 0.7996 - val_loss: 0.4895 - val_acc: 0.8377\n",
            "Epoch 575/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5748 - acc: 0.8001 - val_loss: 0.4953 - val_acc: 0.8425\n",
            "Epoch 576/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5778 - acc: 0.7970 - val_loss: 0.5009 - val_acc: 0.8367\n",
            "Epoch 577/1000\n",
            "45000/45000 [==============================] - 1s 18us/sample - loss: 0.5791 - acc: 0.7975 - val_loss: 0.4917 - val_acc: 0.8395\n",
            "Epoch 578/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5761 - acc: 0.8005 - val_loss: 0.4954 - val_acc: 0.8390\n",
            "Epoch 579/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5720 - acc: 0.8042 - val_loss: 0.4929 - val_acc: 0.8387\n",
            "Epoch 580/1000\n",
            "45000/45000 [==============================] - 1s 18us/sample - loss: 0.5784 - acc: 0.8010 - val_loss: 0.4968 - val_acc: 0.8381\n",
            "Epoch 581/1000\n",
            "45000/45000 [==============================] - 1s 18us/sample - loss: 0.5891 - acc: 0.7927 - val_loss: 0.5065 - val_acc: 0.8344\n",
            "Epoch 582/1000\n",
            "45000/45000 [==============================] - 1s 18us/sample - loss: 0.5813 - acc: 0.7988 - val_loss: 0.5008 - val_acc: 0.8368\n",
            "Epoch 583/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5663 - acc: 0.8052 - val_loss: 0.4919 - val_acc: 0.8381\n",
            "Epoch 584/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5825 - acc: 0.7992 - val_loss: 0.4942 - val_acc: 0.8351\n",
            "Epoch 585/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5861 - acc: 0.7951 - val_loss: 0.4862 - val_acc: 0.8364\n",
            "Epoch 586/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5760 - acc: 0.7991 - val_loss: 0.4923 - val_acc: 0.8379\n",
            "Epoch 587/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5762 - acc: 0.8006 - val_loss: 0.4986 - val_acc: 0.8300\n",
            "Epoch 588/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5680 - acc: 0.8037 - val_loss: 0.4857 - val_acc: 0.8373\n",
            "Epoch 589/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5778 - acc: 0.8015 - val_loss: 0.4967 - val_acc: 0.8378\n",
            "Epoch 590/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5871 - acc: 0.7954 - val_loss: 0.4918 - val_acc: 0.8348\n",
            "Epoch 591/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5756 - acc: 0.7993 - val_loss: 0.4977 - val_acc: 0.8369\n",
            "Epoch 592/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5768 - acc: 0.8014 - val_loss: 0.4918 - val_acc: 0.8385\n",
            "Epoch 593/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5898 - acc: 0.7951 - val_loss: 0.5000 - val_acc: 0.8371\n",
            "Epoch 594/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5715 - acc: 0.8020 - val_loss: 0.5011 - val_acc: 0.8369\n",
            "Epoch 595/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5698 - acc: 0.8029 - val_loss: 0.4935 - val_acc: 0.8364\n",
            "Epoch 596/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5818 - acc: 0.7969 - val_loss: 0.4995 - val_acc: 0.8343\n",
            "Epoch 597/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5736 - acc: 0.7991 - val_loss: 0.4942 - val_acc: 0.8375\n",
            "Epoch 598/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5725 - acc: 0.8018 - val_loss: 0.4875 - val_acc: 0.8367\n",
            "Epoch 599/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5753 - acc: 0.7980 - val_loss: 0.5017 - val_acc: 0.8361\n",
            "Epoch 600/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5762 - acc: 0.8023 - val_loss: 0.4974 - val_acc: 0.8355\n",
            "Epoch 601/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5715 - acc: 0.8011 - val_loss: 0.4972 - val_acc: 0.8398\n",
            "Epoch 602/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.5802 - acc: 0.7994 - val_loss: 0.5005 - val_acc: 0.8377\n",
            "Epoch 603/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5749 - acc: 0.7998 - val_loss: 0.4997 - val_acc: 0.8367\n",
            "Epoch 604/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5727 - acc: 0.7992 - val_loss: 0.5082 - val_acc: 0.8331\n",
            "Epoch 605/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5863 - acc: 0.7909 - val_loss: 0.5124 - val_acc: 0.8313\n",
            "Epoch 606/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.5768 - acc: 0.8004 - val_loss: 0.5022 - val_acc: 0.8373\n",
            "Epoch 607/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5827 - acc: 0.7998 - val_loss: 0.5054 - val_acc: 0.8349\n",
            "Epoch 608/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5840 - acc: 0.7979 - val_loss: 0.4986 - val_acc: 0.8355\n",
            "Epoch 609/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5738 - acc: 0.8013 - val_loss: 0.4884 - val_acc: 0.8393\n",
            "Epoch 610/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5786 - acc: 0.7992 - val_loss: 0.4992 - val_acc: 0.8375\n",
            "Epoch 611/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5947 - acc: 0.7947 - val_loss: 0.4985 - val_acc: 0.8371\n",
            "Epoch 612/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5805 - acc: 0.8012 - val_loss: 0.4903 - val_acc: 0.8373\n",
            "Epoch 613/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5908 - acc: 0.7931 - val_loss: 0.5033 - val_acc: 0.8351\n",
            "Epoch 614/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5810 - acc: 0.8008 - val_loss: 0.4990 - val_acc: 0.8375\n",
            "Epoch 615/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5815 - acc: 0.7972 - val_loss: 0.4946 - val_acc: 0.8348\n",
            "Epoch 616/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5793 - acc: 0.7986 - val_loss: 0.4978 - val_acc: 0.8373\n",
            "Epoch 617/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5682 - acc: 0.8042 - val_loss: 0.4941 - val_acc: 0.8373\n",
            "Epoch 618/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5715 - acc: 0.8008 - val_loss: 0.5095 - val_acc: 0.8382\n",
            "Epoch 619/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5757 - acc: 0.7988 - val_loss: 0.4966 - val_acc: 0.8411\n",
            "Epoch 620/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5810 - acc: 0.7981 - val_loss: 0.4989 - val_acc: 0.8402\n",
            "Epoch 621/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.5944 - acc: 0.7972 - val_loss: 0.5048 - val_acc: 0.8369\n",
            "Epoch 622/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5777 - acc: 0.7996 - val_loss: 0.5001 - val_acc: 0.8387\n",
            "Epoch 623/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5733 - acc: 0.8002 - val_loss: 0.4963 - val_acc: 0.8394\n",
            "Epoch 624/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.5876 - acc: 0.7909 - val_loss: 0.4930 - val_acc: 0.8389\n",
            "Epoch 625/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.5705 - acc: 0.7994 - val_loss: 0.5002 - val_acc: 0.8347\n",
            "Epoch 626/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5739 - acc: 0.8017 - val_loss: 0.4858 - val_acc: 0.8410\n",
            "Epoch 627/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.5695 - acc: 0.8020 - val_loss: 0.4897 - val_acc: 0.8373\n",
            "Epoch 628/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5753 - acc: 0.7993 - val_loss: 0.4984 - val_acc: 0.8373\n",
            "Epoch 629/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5737 - acc: 0.8012 - val_loss: 0.4978 - val_acc: 0.8373\n",
            "Epoch 630/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5855 - acc: 0.7976 - val_loss: 0.5034 - val_acc: 0.8379\n",
            "Epoch 631/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5825 - acc: 0.7969 - val_loss: 0.4923 - val_acc: 0.8394\n",
            "Epoch 632/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5659 - acc: 0.8019 - val_loss: 0.4993 - val_acc: 0.8355\n",
            "Epoch 633/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6067 - acc: 0.7926 - val_loss: 0.5020 - val_acc: 0.8378\n",
            "Epoch 634/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5790 - acc: 0.7995 - val_loss: 0.4988 - val_acc: 0.8385\n",
            "Epoch 635/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5879 - acc: 0.7930 - val_loss: 0.5002 - val_acc: 0.8373\n",
            "Epoch 636/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5978 - acc: 0.7905 - val_loss: 0.5126 - val_acc: 0.8364\n",
            "Epoch 637/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5944 - acc: 0.7930 - val_loss: 0.4949 - val_acc: 0.8397\n",
            "Epoch 638/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5718 - acc: 0.8037 - val_loss: 0.4973 - val_acc: 0.8385\n",
            "Epoch 639/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.5784 - acc: 0.8002 - val_loss: 0.4993 - val_acc: 0.8376\n",
            "Epoch 640/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.5858 - acc: 0.7942 - val_loss: 0.5246 - val_acc: 0.8195\n",
            "Epoch 641/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.5958 - acc: 0.7861 - val_loss: 0.5429 - val_acc: 0.8207\n",
            "Epoch 642/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6164 - acc: 0.7805 - val_loss: 0.5061 - val_acc: 0.8339\n",
            "Epoch 643/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5845 - acc: 0.7956 - val_loss: 0.4928 - val_acc: 0.8383\n",
            "Epoch 644/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5947 - acc: 0.7956 - val_loss: 0.4951 - val_acc: 0.8357\n",
            "Epoch 645/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5923 - acc: 0.7962 - val_loss: 0.4949 - val_acc: 0.8359\n",
            "Epoch 646/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5910 - acc: 0.7930 - val_loss: 0.4931 - val_acc: 0.8389\n",
            "Epoch 647/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5794 - acc: 0.8006 - val_loss: 0.4905 - val_acc: 0.8417\n",
            "Epoch 648/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5898 - acc: 0.7963 - val_loss: 0.4936 - val_acc: 0.8391\n",
            "Epoch 649/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5751 - acc: 0.7987 - val_loss: 0.4901 - val_acc: 0.8399\n",
            "Epoch 650/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5752 - acc: 0.8011 - val_loss: 0.4890 - val_acc: 0.8400\n",
            "Epoch 651/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5724 - acc: 0.8024 - val_loss: 0.4924 - val_acc: 0.8360\n",
            "Epoch 652/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5752 - acc: 0.7999 - val_loss: 0.5013 - val_acc: 0.8403\n",
            "Epoch 653/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5780 - acc: 0.7982 - val_loss: 0.4918 - val_acc: 0.8362\n",
            "Epoch 654/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5704 - acc: 0.8033 - val_loss: 0.4986 - val_acc: 0.8364\n",
            "Epoch 655/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5730 - acc: 0.8020 - val_loss: 0.4967 - val_acc: 0.8361\n",
            "Epoch 656/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5766 - acc: 0.7995 - val_loss: 0.5010 - val_acc: 0.8337\n",
            "Epoch 657/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5840 - acc: 0.7960 - val_loss: 0.5134 - val_acc: 0.8274\n",
            "Epoch 658/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5683 - acc: 0.8044 - val_loss: 0.5061 - val_acc: 0.8363\n",
            "Epoch 659/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5892 - acc: 0.7968 - val_loss: 0.4999 - val_acc: 0.8347\n",
            "Epoch 660/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5773 - acc: 0.8019 - val_loss: 0.4899 - val_acc: 0.8411\n",
            "Epoch 661/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5736 - acc: 0.8010 - val_loss: 0.4945 - val_acc: 0.8406\n",
            "Epoch 662/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5954 - acc: 0.7940 - val_loss: 0.5045 - val_acc: 0.8363\n",
            "Epoch 663/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.6175 - acc: 0.7836 - val_loss: 0.4976 - val_acc: 0.8362\n",
            "Epoch 664/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.5784 - acc: 0.8015 - val_loss: 0.4980 - val_acc: 0.8386\n",
            "Epoch 665/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5727 - acc: 0.8028 - val_loss: 0.5022 - val_acc: 0.8364\n",
            "Epoch 666/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5746 - acc: 0.8025 - val_loss: 0.4925 - val_acc: 0.8372\n",
            "Epoch 667/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5813 - acc: 0.7972 - val_loss: 0.4860 - val_acc: 0.8394\n",
            "Epoch 668/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5759 - acc: 0.8026 - val_loss: 0.5166 - val_acc: 0.8301\n",
            "Epoch 669/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5845 - acc: 0.8002 - val_loss: 0.4980 - val_acc: 0.8395\n",
            "Epoch 670/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5749 - acc: 0.8010 - val_loss: 0.4974 - val_acc: 0.8363\n",
            "Epoch 671/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5816 - acc: 0.7992 - val_loss: 0.4884 - val_acc: 0.8393\n",
            "Epoch 672/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5809 - acc: 0.7970 - val_loss: 0.4954 - val_acc: 0.8372\n",
            "Epoch 673/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5843 - acc: 0.7960 - val_loss: 0.4942 - val_acc: 0.8366\n",
            "Epoch 674/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5813 - acc: 0.7975 - val_loss: 0.5027 - val_acc: 0.8348\n",
            "Epoch 675/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5812 - acc: 0.7981 - val_loss: 0.4918 - val_acc: 0.8414\n",
            "Epoch 676/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5673 - acc: 0.8034 - val_loss: 0.4921 - val_acc: 0.8417\n",
            "Epoch 677/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5677 - acc: 0.8048 - val_loss: 0.5009 - val_acc: 0.8389\n",
            "Epoch 678/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5857 - acc: 0.7971 - val_loss: 0.5055 - val_acc: 0.8365\n",
            "Epoch 679/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5765 - acc: 0.8014 - val_loss: 0.4952 - val_acc: 0.8382\n",
            "Epoch 680/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5718 - acc: 0.8013 - val_loss: 0.4959 - val_acc: 0.8401\n",
            "Epoch 681/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5737 - acc: 0.8036 - val_loss: 0.4905 - val_acc: 0.8396\n",
            "Epoch 682/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5711 - acc: 0.8025 - val_loss: 0.4981 - val_acc: 0.8394\n",
            "Epoch 683/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5754 - acc: 0.8015 - val_loss: 0.4858 - val_acc: 0.8411\n",
            "Epoch 684/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5729 - acc: 0.8037 - val_loss: 0.4949 - val_acc: 0.8384\n",
            "Epoch 685/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5866 - acc: 0.7943 - val_loss: 0.5013 - val_acc: 0.8384\n",
            "Epoch 686/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5822 - acc: 0.8004 - val_loss: 0.4921 - val_acc: 0.8401\n",
            "Epoch 687/1000\n",
            "45000/45000 [==============================] - 1s 18us/sample - loss: 0.5642 - acc: 0.8038 - val_loss: 0.4992 - val_acc: 0.8369\n",
            "Epoch 688/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5803 - acc: 0.7985 - val_loss: 0.4960 - val_acc: 0.8366\n",
            "Epoch 689/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5765 - acc: 0.8005 - val_loss: 0.4964 - val_acc: 0.8351\n",
            "Epoch 690/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5626 - acc: 0.8040 - val_loss: 0.4990 - val_acc: 0.8405\n",
            "Epoch 691/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5686 - acc: 0.8042 - val_loss: 0.4986 - val_acc: 0.8392\n",
            "Epoch 692/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5704 - acc: 0.8022 - val_loss: 0.4973 - val_acc: 0.8397\n",
            "Epoch 693/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5817 - acc: 0.7985 - val_loss: 0.4917 - val_acc: 0.8393\n",
            "Epoch 694/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5713 - acc: 0.8042 - val_loss: 0.4980 - val_acc: 0.8391\n",
            "Epoch 695/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5895 - acc: 0.7965 - val_loss: 0.5087 - val_acc: 0.8359\n",
            "Epoch 696/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5916 - acc: 0.7975 - val_loss: 0.4926 - val_acc: 0.8402\n",
            "Epoch 697/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5798 - acc: 0.8013 - val_loss: 0.4955 - val_acc: 0.8333\n",
            "Epoch 698/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5626 - acc: 0.8038 - val_loss: 0.4943 - val_acc: 0.8413\n",
            "Epoch 699/1000\n",
            "45000/45000 [==============================] - 1s 18us/sample - loss: 0.5821 - acc: 0.7986 - val_loss: 0.4955 - val_acc: 0.8347\n",
            "Epoch 700/1000\n",
            "45000/45000 [==============================] - 1s 20us/sample - loss: 0.5763 - acc: 0.7997 - val_loss: 0.4985 - val_acc: 0.8355\n",
            "Epoch 701/1000\n",
            "45000/45000 [==============================] - 1s 19us/sample - loss: 0.5758 - acc: 0.8017 - val_loss: 0.4892 - val_acc: 0.8385\n",
            "Epoch 702/1000\n",
            "45000/45000 [==============================] - 1s 18us/sample - loss: 0.5693 - acc: 0.8020 - val_loss: 0.4968 - val_acc: 0.8386\n",
            "Epoch 703/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5721 - acc: 0.8024 - val_loss: 0.4888 - val_acc: 0.8397\n",
            "Epoch 704/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5656 - acc: 0.8031 - val_loss: 0.4986 - val_acc: 0.8364\n",
            "Epoch 705/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5690 - acc: 0.8025 - val_loss: 0.5138 - val_acc: 0.8330\n",
            "Epoch 706/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5846 - acc: 0.7986 - val_loss: 0.5092 - val_acc: 0.8383\n",
            "Epoch 707/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5823 - acc: 0.7963 - val_loss: 0.4960 - val_acc: 0.8402\n",
            "Epoch 708/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5940 - acc: 0.7890 - val_loss: 0.5136 - val_acc: 0.8377\n",
            "Epoch 709/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5795 - acc: 0.7984 - val_loss: 0.5169 - val_acc: 0.8356\n",
            "Epoch 710/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5830 - acc: 0.7979 - val_loss: 0.4978 - val_acc: 0.8375\n",
            "Epoch 711/1000\n",
            "45000/45000 [==============================] - 1s 18us/sample - loss: 0.5839 - acc: 0.7971 - val_loss: 0.4947 - val_acc: 0.8378\n",
            "Epoch 712/1000\n",
            "45000/45000 [==============================] - 1s 19us/sample - loss: 0.5754 - acc: 0.8013 - val_loss: 0.4891 - val_acc: 0.8402\n",
            "Epoch 713/1000\n",
            "45000/45000 [==============================] - 1s 18us/sample - loss: 0.5609 - acc: 0.8055 - val_loss: 0.4933 - val_acc: 0.8415\n",
            "Epoch 714/1000\n",
            "45000/45000 [==============================] - 1s 18us/sample - loss: 0.5700 - acc: 0.8013 - val_loss: 0.4987 - val_acc: 0.8372\n",
            "Epoch 715/1000\n",
            "45000/45000 [==============================] - 1s 18us/sample - loss: 0.5820 - acc: 0.7990 - val_loss: 0.4945 - val_acc: 0.8369\n",
            "Epoch 716/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5784 - acc: 0.8016 - val_loss: 0.4936 - val_acc: 0.8386\n",
            "Epoch 717/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5758 - acc: 0.8009 - val_loss: 0.4904 - val_acc: 0.8388\n",
            "Epoch 718/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5778 - acc: 0.8004 - val_loss: 0.5004 - val_acc: 0.8383\n",
            "Epoch 719/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5781 - acc: 0.7975 - val_loss: 0.4952 - val_acc: 0.8375\n",
            "Epoch 720/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5894 - acc: 0.7927 - val_loss: 0.5278 - val_acc: 0.8303\n",
            "Epoch 721/1000\n",
            "45000/45000 [==============================] - 1s 18us/sample - loss: 0.5799 - acc: 0.7972 - val_loss: 0.5162 - val_acc: 0.8321\n",
            "Epoch 722/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5683 - acc: 0.8030 - val_loss: 0.4968 - val_acc: 0.8406\n",
            "Epoch 723/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5777 - acc: 0.8024 - val_loss: 0.4962 - val_acc: 0.8369\n",
            "Epoch 724/1000\n",
            "45000/45000 [==============================] - 1s 18us/sample - loss: 0.5728 - acc: 0.8006 - val_loss: 0.4927 - val_acc: 0.8386\n",
            "Epoch 725/1000\n",
            "45000/45000 [==============================] - 1s 21us/sample - loss: 0.5622 - acc: 0.8067 - val_loss: 0.5056 - val_acc: 0.8347\n",
            "Epoch 726/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5711 - acc: 0.8021 - val_loss: 0.5047 - val_acc: 0.8369\n",
            "Epoch 727/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5667 - acc: 0.8029 - val_loss: 0.5068 - val_acc: 0.8381\n",
            "Epoch 728/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5753 - acc: 0.7977 - val_loss: 0.4998 - val_acc: 0.8391\n",
            "Epoch 729/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5737 - acc: 0.8014 - val_loss: 0.5010 - val_acc: 0.8384\n",
            "Epoch 730/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5911 - acc: 0.7975 - val_loss: 0.5020 - val_acc: 0.8371\n",
            "Epoch 731/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5755 - acc: 0.7998 - val_loss: 0.4981 - val_acc: 0.8381\n",
            "Epoch 732/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5673 - acc: 0.8026 - val_loss: 0.5024 - val_acc: 0.8372\n",
            "Epoch 733/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5765 - acc: 0.7993 - val_loss: 0.5112 - val_acc: 0.8345\n",
            "Epoch 734/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5820 - acc: 0.7987 - val_loss: 0.4986 - val_acc: 0.8397\n",
            "Epoch 735/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5790 - acc: 0.7957 - val_loss: 0.4997 - val_acc: 0.8369\n",
            "Epoch 736/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5724 - acc: 0.8014 - val_loss: 0.5014 - val_acc: 0.8386\n",
            "Epoch 737/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5967 - acc: 0.7900 - val_loss: 0.4958 - val_acc: 0.8411\n",
            "Epoch 738/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5604 - acc: 0.8083 - val_loss: 0.4950 - val_acc: 0.8419\n",
            "Epoch 739/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5795 - acc: 0.7970 - val_loss: 0.4956 - val_acc: 0.8372\n",
            "Epoch 740/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6029 - acc: 0.7935 - val_loss: 0.4917 - val_acc: 0.8403\n",
            "Epoch 741/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5819 - acc: 0.7971 - val_loss: 0.4916 - val_acc: 0.8394\n",
            "Epoch 742/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5816 - acc: 0.7991 - val_loss: 0.4923 - val_acc: 0.8369\n",
            "Epoch 743/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5729 - acc: 0.8015 - val_loss: 0.5028 - val_acc: 0.8393\n",
            "Epoch 744/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5710 - acc: 0.8016 - val_loss: 0.5037 - val_acc: 0.8331\n",
            "Epoch 745/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5603 - acc: 0.8076 - val_loss: 0.5055 - val_acc: 0.8378\n",
            "Epoch 746/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5757 - acc: 0.8002 - val_loss: 0.5018 - val_acc: 0.8341\n",
            "Epoch 747/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5729 - acc: 0.8008 - val_loss: 0.4915 - val_acc: 0.8399\n",
            "Epoch 748/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5637 - acc: 0.8085 - val_loss: 0.4980 - val_acc: 0.8393\n",
            "Epoch 749/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5771 - acc: 0.7998 - val_loss: 0.4996 - val_acc: 0.8398\n",
            "Epoch 750/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5849 - acc: 0.7910 - val_loss: 0.5264 - val_acc: 0.8229\n",
            "Epoch 751/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5867 - acc: 0.7911 - val_loss: 0.5039 - val_acc: 0.8403\n",
            "Epoch 752/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5692 - acc: 0.8015 - val_loss: 0.4955 - val_acc: 0.8381\n",
            "Epoch 753/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5664 - acc: 0.8024 - val_loss: 0.4935 - val_acc: 0.8393\n",
            "Epoch 754/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5705 - acc: 0.8054 - val_loss: 0.4946 - val_acc: 0.8385\n",
            "Epoch 755/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5731 - acc: 0.8001 - val_loss: 0.5006 - val_acc: 0.8379\n",
            "Epoch 756/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5798 - acc: 0.7987 - val_loss: 0.4968 - val_acc: 0.8382\n",
            "Epoch 757/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5658 - acc: 0.8055 - val_loss: 0.4984 - val_acc: 0.8411\n",
            "Epoch 758/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5741 - acc: 0.8031 - val_loss: 0.4953 - val_acc: 0.8412\n",
            "Epoch 759/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5812 - acc: 0.7973 - val_loss: 0.5033 - val_acc: 0.8376\n",
            "Epoch 760/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5855 - acc: 0.7953 - val_loss: 0.5082 - val_acc: 0.8347\n",
            "Epoch 761/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5810 - acc: 0.7975 - val_loss: 0.4999 - val_acc: 0.8406\n",
            "Epoch 762/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5708 - acc: 0.8050 - val_loss: 0.4995 - val_acc: 0.8379\n",
            "Epoch 763/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5800 - acc: 0.8012 - val_loss: 0.4933 - val_acc: 0.8387\n",
            "Epoch 764/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5812 - acc: 0.7981 - val_loss: 0.5225 - val_acc: 0.8282\n",
            "Epoch 765/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5834 - acc: 0.7979 - val_loss: 0.4926 - val_acc: 0.8399\n",
            "Epoch 766/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5682 - acc: 0.8041 - val_loss: 0.4901 - val_acc: 0.8405\n",
            "Epoch 767/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5703 - acc: 0.8010 - val_loss: 0.4990 - val_acc: 0.8385\n",
            "Epoch 768/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5790 - acc: 0.7980 - val_loss: 0.4939 - val_acc: 0.8383\n",
            "Epoch 769/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5642 - acc: 0.8052 - val_loss: 0.5015 - val_acc: 0.8392\n",
            "Epoch 770/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5750 - acc: 0.8005 - val_loss: 0.4961 - val_acc: 0.8393\n",
            "Epoch 771/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5724 - acc: 0.8017 - val_loss: 0.4935 - val_acc: 0.8403\n",
            "Epoch 772/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5707 - acc: 0.8036 - val_loss: 0.4972 - val_acc: 0.8413\n",
            "Epoch 773/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5658 - acc: 0.8056 - val_loss: 0.4920 - val_acc: 0.8403\n",
            "Epoch 774/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5655 - acc: 0.8040 - val_loss: 0.5027 - val_acc: 0.8346\n",
            "Epoch 775/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5747 - acc: 0.8029 - val_loss: 0.5045 - val_acc: 0.8373\n",
            "Epoch 776/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5736 - acc: 0.8023 - val_loss: 0.5053 - val_acc: 0.8379\n",
            "Epoch 777/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5828 - acc: 0.8010 - val_loss: 0.4971 - val_acc: 0.8395\n",
            "Epoch 778/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5667 - acc: 0.8022 - val_loss: 0.4929 - val_acc: 0.8405\n",
            "Epoch 779/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.6032 - acc: 0.7857 - val_loss: 0.5206 - val_acc: 0.8303\n",
            "Epoch 780/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5930 - acc: 0.7908 - val_loss: 0.5099 - val_acc: 0.8355\n",
            "Epoch 781/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5661 - acc: 0.8042 - val_loss: 0.4972 - val_acc: 0.8359\n",
            "Epoch 782/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5728 - acc: 0.8012 - val_loss: 0.4951 - val_acc: 0.8396\n",
            "Epoch 783/1000\n",
            "45000/45000 [==============================] - 1s 18us/sample - loss: 0.5667 - acc: 0.8043 - val_loss: 0.5029 - val_acc: 0.8410\n",
            "Epoch 784/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5746 - acc: 0.8027 - val_loss: 0.5076 - val_acc: 0.8365\n",
            "Epoch 785/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5751 - acc: 0.8010 - val_loss: 0.5031 - val_acc: 0.8405\n",
            "Epoch 786/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5731 - acc: 0.8044 - val_loss: 0.4981 - val_acc: 0.8401\n",
            "Epoch 787/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5659 - acc: 0.8040 - val_loss: 0.4906 - val_acc: 0.8411\n",
            "Epoch 788/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5681 - acc: 0.8022 - val_loss: 0.4997 - val_acc: 0.8387\n",
            "Epoch 789/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5704 - acc: 0.8051 - val_loss: 0.4969 - val_acc: 0.8398\n",
            "Epoch 790/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5665 - acc: 0.8035 - val_loss: 0.4923 - val_acc: 0.8439\n",
            "Epoch 791/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5672 - acc: 0.8026 - val_loss: 0.5098 - val_acc: 0.8356\n",
            "Epoch 792/1000\n",
            "45000/45000 [==============================] - 1s 18us/sample - loss: 0.5707 - acc: 0.8043 - val_loss: 0.4966 - val_acc: 0.8416\n",
            "Epoch 793/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5622 - acc: 0.8069 - val_loss: 0.5031 - val_acc: 0.8392\n",
            "Epoch 794/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5651 - acc: 0.8030 - val_loss: 0.5053 - val_acc: 0.8383\n",
            "Epoch 795/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5769 - acc: 0.8004 - val_loss: 0.4999 - val_acc: 0.8377\n",
            "Epoch 796/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5673 - acc: 0.8026 - val_loss: 0.5054 - val_acc: 0.8399\n",
            "Epoch 797/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5713 - acc: 0.8032 - val_loss: 0.4961 - val_acc: 0.8377\n",
            "Epoch 798/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5824 - acc: 0.7981 - val_loss: 0.5117 - val_acc: 0.8301\n",
            "Epoch 799/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5994 - acc: 0.7903 - val_loss: 0.5048 - val_acc: 0.8363\n",
            "Epoch 800/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6030 - acc: 0.7910 - val_loss: 0.5062 - val_acc: 0.8356\n",
            "Epoch 801/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5934 - acc: 0.7936 - val_loss: 0.5186 - val_acc: 0.8355\n",
            "Epoch 802/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5915 - acc: 0.7964 - val_loss: 0.4974 - val_acc: 0.8408\n",
            "Epoch 803/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5875 - acc: 0.7960 - val_loss: 0.5053 - val_acc: 0.8397\n",
            "Epoch 804/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5889 - acc: 0.7960 - val_loss: 0.5047 - val_acc: 0.8388\n",
            "Epoch 805/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5702 - acc: 0.8052 - val_loss: 0.4984 - val_acc: 0.8355\n",
            "Epoch 806/1000\n",
            "45000/45000 [==============================] - 1s 18us/sample - loss: 0.5681 - acc: 0.8013 - val_loss: 0.5045 - val_acc: 0.8404\n",
            "Epoch 807/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5679 - acc: 0.8045 - val_loss: 0.4969 - val_acc: 0.8416\n",
            "Epoch 808/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5839 - acc: 0.7976 - val_loss: 0.5102 - val_acc: 0.8363\n",
            "Epoch 809/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5737 - acc: 0.8004 - val_loss: 0.5030 - val_acc: 0.8383\n",
            "Epoch 810/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5724 - acc: 0.8015 - val_loss: 0.4989 - val_acc: 0.8395\n",
            "Epoch 811/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5739 - acc: 0.7994 - val_loss: 0.5375 - val_acc: 0.8329\n",
            "Epoch 812/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5836 - acc: 0.7976 - val_loss: 0.4990 - val_acc: 0.8407\n",
            "Epoch 813/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5701 - acc: 0.8050 - val_loss: 0.5045 - val_acc: 0.8429\n",
            "Epoch 814/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5747 - acc: 0.7992 - val_loss: 0.4930 - val_acc: 0.8413\n",
            "Epoch 815/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5643 - acc: 0.8042 - val_loss: 0.4948 - val_acc: 0.8387\n",
            "Epoch 816/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5688 - acc: 0.8033 - val_loss: 0.4977 - val_acc: 0.8395\n",
            "Epoch 817/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5652 - acc: 0.8041 - val_loss: 0.4913 - val_acc: 0.8396\n",
            "Epoch 818/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5718 - acc: 0.8026 - val_loss: 0.5158 - val_acc: 0.8357\n",
            "Epoch 819/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5747 - acc: 0.8012 - val_loss: 0.5119 - val_acc: 0.8351\n",
            "Epoch 820/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5886 - acc: 0.7950 - val_loss: 0.4931 - val_acc: 0.8404\n",
            "Epoch 821/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5771 - acc: 0.8003 - val_loss: 0.5038 - val_acc: 0.8325\n",
            "Epoch 822/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5907 - acc: 0.7951 - val_loss: 0.5103 - val_acc: 0.8331\n",
            "Epoch 823/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5746 - acc: 0.8007 - val_loss: 0.5059 - val_acc: 0.8391\n",
            "Epoch 824/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5700 - acc: 0.8001 - val_loss: 0.4969 - val_acc: 0.8403\n",
            "Epoch 825/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5655 - acc: 0.8038 - val_loss: 0.4937 - val_acc: 0.8373\n",
            "Epoch 826/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5749 - acc: 0.8037 - val_loss: 0.5018 - val_acc: 0.8341\n",
            "Epoch 827/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5815 - acc: 0.7985 - val_loss: 0.4993 - val_acc: 0.8383\n",
            "Epoch 828/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5749 - acc: 0.8003 - val_loss: 0.4955 - val_acc: 0.8369\n",
            "Epoch 829/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5675 - acc: 0.8049 - val_loss: 0.5044 - val_acc: 0.8373\n",
            "Epoch 830/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5740 - acc: 0.8000 - val_loss: 0.4957 - val_acc: 0.8404\n",
            "Epoch 831/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5698 - acc: 0.8016 - val_loss: 0.4891 - val_acc: 0.8414\n",
            "Epoch 832/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5638 - acc: 0.8028 - val_loss: 0.5070 - val_acc: 0.8408\n",
            "Epoch 833/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5590 - acc: 0.8053 - val_loss: 0.4936 - val_acc: 0.8399\n",
            "Epoch 834/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5690 - acc: 0.8030 - val_loss: 0.4945 - val_acc: 0.8396\n",
            "Epoch 835/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5585 - acc: 0.8066 - val_loss: 0.4983 - val_acc: 0.8373\n",
            "Epoch 836/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5733 - acc: 0.8024 - val_loss: 0.5008 - val_acc: 0.8393\n",
            "Epoch 837/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5709 - acc: 0.8019 - val_loss: 0.4974 - val_acc: 0.8392\n",
            "Epoch 838/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5673 - acc: 0.8027 - val_loss: 0.5205 - val_acc: 0.8261\n",
            "Epoch 839/1000\n",
            "45000/45000 [==============================] - 1s 18us/sample - loss: 0.5929 - acc: 0.7910 - val_loss: 0.5089 - val_acc: 0.8297\n",
            "Epoch 840/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5747 - acc: 0.8009 - val_loss: 0.5054 - val_acc: 0.8349\n",
            "Epoch 841/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5832 - acc: 0.7939 - val_loss: 0.5008 - val_acc: 0.8315\n",
            "Epoch 842/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5706 - acc: 0.8000 - val_loss: 0.5077 - val_acc: 0.8378\n",
            "Epoch 843/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5739 - acc: 0.8013 - val_loss: 0.5016 - val_acc: 0.8342\n",
            "Epoch 844/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5657 - acc: 0.8061 - val_loss: 0.4984 - val_acc: 0.8405\n",
            "Epoch 845/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5623 - acc: 0.8047 - val_loss: 0.4991 - val_acc: 0.8408\n",
            "Epoch 846/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5670 - acc: 0.8022 - val_loss: 0.5012 - val_acc: 0.8401\n",
            "Epoch 847/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5583 - acc: 0.8084 - val_loss: 0.5118 - val_acc: 0.8328\n",
            "Epoch 848/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5734 - acc: 0.8000 - val_loss: 0.4959 - val_acc: 0.8345\n",
            "Epoch 849/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5682 - acc: 0.8030 - val_loss: 0.5007 - val_acc: 0.8380\n",
            "Epoch 850/1000\n",
            "45000/45000 [==============================] - 1s 18us/sample - loss: 0.5755 - acc: 0.8016 - val_loss: 0.5035 - val_acc: 0.8377\n",
            "Epoch 851/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5859 - acc: 0.7997 - val_loss: 0.5004 - val_acc: 0.8384\n",
            "Epoch 852/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5744 - acc: 0.8006 - val_loss: 0.5077 - val_acc: 0.8371\n",
            "Epoch 853/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5637 - acc: 0.8035 - val_loss: 0.5010 - val_acc: 0.8409\n",
            "Epoch 854/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5791 - acc: 0.7997 - val_loss: 0.5045 - val_acc: 0.8404\n",
            "Epoch 855/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5722 - acc: 0.8006 - val_loss: 0.5075 - val_acc: 0.8383\n",
            "Epoch 856/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5663 - acc: 0.8037 - val_loss: 0.5069 - val_acc: 0.8365\n",
            "Epoch 857/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5635 - acc: 0.8038 - val_loss: 0.5066 - val_acc: 0.8357\n",
            "Epoch 858/1000\n",
            "45000/45000 [==============================] - 1s 18us/sample - loss: 0.5745 - acc: 0.8004 - val_loss: 0.5005 - val_acc: 0.8352\n",
            "Epoch 859/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5685 - acc: 0.8021 - val_loss: 0.5319 - val_acc: 0.8303\n",
            "Epoch 860/1000\n",
            "45000/45000 [==============================] - 1s 18us/sample - loss: 0.5868 - acc: 0.7968 - val_loss: 0.4955 - val_acc: 0.8387\n",
            "Epoch 861/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5684 - acc: 0.8029 - val_loss: 0.4972 - val_acc: 0.8393\n",
            "Epoch 862/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5579 - acc: 0.8063 - val_loss: 0.4935 - val_acc: 0.8405\n",
            "Epoch 863/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5691 - acc: 0.8032 - val_loss: 0.5029 - val_acc: 0.8387\n",
            "Epoch 864/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5699 - acc: 0.8037 - val_loss: 0.5369 - val_acc: 0.8278\n",
            "Epoch 865/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.5815 - acc: 0.8002 - val_loss: 0.5011 - val_acc: 0.8415\n",
            "Epoch 866/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5781 - acc: 0.7971 - val_loss: 0.5235 - val_acc: 0.8279\n",
            "Epoch 867/1000\n",
            "45000/45000 [==============================] - 1s 18us/sample - loss: 0.5899 - acc: 0.7890 - val_loss: 0.5187 - val_acc: 0.8333\n",
            "Epoch 868/1000\n",
            "45000/45000 [==============================] - 1s 18us/sample - loss: 0.6052 - acc: 0.7883 - val_loss: 0.4942 - val_acc: 0.8368\n",
            "Epoch 869/1000\n",
            "45000/45000 [==============================] - 1s 18us/sample - loss: 0.5739 - acc: 0.8013 - val_loss: 0.5020 - val_acc: 0.8382\n",
            "Epoch 870/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5778 - acc: 0.8011 - val_loss: 0.5336 - val_acc: 0.8274\n",
            "Epoch 871/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5979 - acc: 0.7946 - val_loss: 0.5273 - val_acc: 0.8248\n",
            "Epoch 872/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5917 - acc: 0.7950 - val_loss: 0.5118 - val_acc: 0.8361\n",
            "Epoch 873/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5915 - acc: 0.7952 - val_loss: 0.5354 - val_acc: 0.8302\n",
            "Epoch 874/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5873 - acc: 0.7945 - val_loss: 0.5110 - val_acc: 0.8350\n",
            "Epoch 875/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5733 - acc: 0.7995 - val_loss: 0.5089 - val_acc: 0.8336\n",
            "Epoch 876/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5744 - acc: 0.7975 - val_loss: 0.5389 - val_acc: 0.8233\n",
            "Epoch 877/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5967 - acc: 0.7872 - val_loss: 0.5084 - val_acc: 0.8327\n",
            "Epoch 878/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5799 - acc: 0.7991 - val_loss: 0.5012 - val_acc: 0.8365\n",
            "Epoch 879/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.5644 - acc: 0.8032 - val_loss: 0.4966 - val_acc: 0.8393\n",
            "Epoch 880/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.5663 - acc: 0.8014 - val_loss: 0.5074 - val_acc: 0.8389\n",
            "Epoch 881/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5893 - acc: 0.7882 - val_loss: 0.5375 - val_acc: 0.8169\n",
            "Epoch 882/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.6004 - acc: 0.7821 - val_loss: 0.5177 - val_acc: 0.8315\n",
            "Epoch 883/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5954 - acc: 0.7844 - val_loss: 0.5130 - val_acc: 0.8306\n",
            "Epoch 884/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5784 - acc: 0.7946 - val_loss: 0.5026 - val_acc: 0.8401\n",
            "Epoch 885/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5740 - acc: 0.8010 - val_loss: 0.4980 - val_acc: 0.8402\n",
            "Epoch 886/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5633 - acc: 0.8026 - val_loss: 0.4962 - val_acc: 0.8391\n",
            "Epoch 887/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5770 - acc: 0.8000 - val_loss: 0.5086 - val_acc: 0.8331\n",
            "Epoch 888/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5775 - acc: 0.8021 - val_loss: 0.4981 - val_acc: 0.8361\n",
            "Epoch 889/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5740 - acc: 0.8028 - val_loss: 0.4960 - val_acc: 0.8405\n",
            "Epoch 890/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.5757 - acc: 0.8011 - val_loss: 0.4987 - val_acc: 0.8403\n",
            "Epoch 891/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5706 - acc: 0.7998 - val_loss: 0.4992 - val_acc: 0.8403\n",
            "Epoch 892/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5544 - acc: 0.8052 - val_loss: 0.4982 - val_acc: 0.8417\n",
            "Epoch 893/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5636 - acc: 0.8078 - val_loss: 0.5043 - val_acc: 0.8405\n",
            "Epoch 894/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5732 - acc: 0.8042 - val_loss: 0.5028 - val_acc: 0.8370\n",
            "Epoch 895/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5703 - acc: 0.8019 - val_loss: 0.5000 - val_acc: 0.8397\n",
            "Epoch 896/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5652 - acc: 0.8044 - val_loss: 0.5055 - val_acc: 0.8377\n",
            "Epoch 897/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.5900 - acc: 0.7986 - val_loss: 0.5063 - val_acc: 0.8389\n",
            "Epoch 898/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5765 - acc: 0.8016 - val_loss: 0.5021 - val_acc: 0.8400\n",
            "Epoch 899/1000\n",
            "45000/45000 [==============================] - 1s 18us/sample - loss: 0.5712 - acc: 0.8045 - val_loss: 0.5092 - val_acc: 0.8382\n",
            "Epoch 900/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5838 - acc: 0.7961 - val_loss: 0.5007 - val_acc: 0.8366\n",
            "Epoch 901/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5668 - acc: 0.8032 - val_loss: 0.5036 - val_acc: 0.8407\n",
            "Epoch 902/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5660 - acc: 0.8056 - val_loss: 0.5039 - val_acc: 0.8410\n",
            "Epoch 903/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5924 - acc: 0.7992 - val_loss: 0.5116 - val_acc: 0.8359\n",
            "Epoch 904/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5937 - acc: 0.7973 - val_loss: 0.5086 - val_acc: 0.8386\n",
            "Epoch 905/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5757 - acc: 0.7989 - val_loss: 0.5095 - val_acc: 0.8329\n",
            "Epoch 906/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5666 - acc: 0.8007 - val_loss: 0.5223 - val_acc: 0.8317\n",
            "Epoch 907/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5700 - acc: 0.8013 - val_loss: 0.5024 - val_acc: 0.8393\n",
            "Epoch 908/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.5626 - acc: 0.8056 - val_loss: 0.4978 - val_acc: 0.8389\n",
            "Epoch 909/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5755 - acc: 0.7992 - val_loss: 0.5101 - val_acc: 0.8381\n",
            "Epoch 910/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5786 - acc: 0.7991 - val_loss: 0.5022 - val_acc: 0.8403\n",
            "Epoch 911/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5719 - acc: 0.8030 - val_loss: 0.5009 - val_acc: 0.8384\n",
            "Epoch 912/1000\n",
            "45000/45000 [==============================] - 1s 20us/sample - loss: 0.5850 - acc: 0.7991 - val_loss: 0.4995 - val_acc: 0.8381\n",
            "Epoch 913/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5893 - acc: 0.7978 - val_loss: 0.5077 - val_acc: 0.8349\n",
            "Epoch 914/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5786 - acc: 0.7984 - val_loss: 0.5104 - val_acc: 0.8399\n",
            "Epoch 915/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5774 - acc: 0.8001 - val_loss: 0.5004 - val_acc: 0.8351\n",
            "Epoch 916/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5775 - acc: 0.7999 - val_loss: 0.5161 - val_acc: 0.8359\n",
            "Epoch 917/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5741 - acc: 0.8049 - val_loss: 0.4995 - val_acc: 0.8374\n",
            "Epoch 918/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5775 - acc: 0.7990 - val_loss: 0.5069 - val_acc: 0.8383\n",
            "Epoch 919/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5764 - acc: 0.7992 - val_loss: 0.5108 - val_acc: 0.8373\n",
            "Epoch 920/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5782 - acc: 0.7984 - val_loss: 0.5050 - val_acc: 0.8365\n",
            "Epoch 921/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5700 - acc: 0.8029 - val_loss: 0.5020 - val_acc: 0.8417\n",
            "Epoch 922/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5791 - acc: 0.7985 - val_loss: 0.5137 - val_acc: 0.8393\n",
            "Epoch 923/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5649 - acc: 0.8041 - val_loss: 0.4988 - val_acc: 0.8397\n",
            "Epoch 924/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5598 - acc: 0.8060 - val_loss: 0.4993 - val_acc: 0.8397\n",
            "Epoch 925/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5682 - acc: 0.8045 - val_loss: 0.5176 - val_acc: 0.8377\n",
            "Epoch 926/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5679 - acc: 0.8040 - val_loss: 0.5079 - val_acc: 0.8345\n",
            "Epoch 927/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5750 - acc: 0.8013 - val_loss: 0.4962 - val_acc: 0.8420\n",
            "Epoch 928/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5825 - acc: 0.7950 - val_loss: 0.5240 - val_acc: 0.8330\n",
            "Epoch 929/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5970 - acc: 0.7926 - val_loss: 0.4993 - val_acc: 0.8361\n",
            "Epoch 930/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5772 - acc: 0.8016 - val_loss: 0.5095 - val_acc: 0.8365\n",
            "Epoch 931/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.5624 - acc: 0.8060 - val_loss: 0.4990 - val_acc: 0.8361\n",
            "Epoch 932/1000\n",
            "45000/45000 [==============================] - 1s 18us/sample - loss: 0.5803 - acc: 0.7967 - val_loss: 0.4996 - val_acc: 0.8365\n",
            "Epoch 933/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5722 - acc: 0.8036 - val_loss: 0.5056 - val_acc: 0.8393\n",
            "Epoch 934/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.6240 - acc: 0.7897 - val_loss: 0.4971 - val_acc: 0.8391\n",
            "Epoch 935/1000\n",
            "45000/45000 [==============================] - 1s 18us/sample - loss: 0.5649 - acc: 0.8060 - val_loss: 0.4945 - val_acc: 0.8383\n",
            "Epoch 936/1000\n",
            "45000/45000 [==============================] - 1s 18us/sample - loss: 0.5685 - acc: 0.8034 - val_loss: 0.4962 - val_acc: 0.8402\n",
            "Epoch 937/1000\n",
            "45000/45000 [==============================] - 1s 18us/sample - loss: 0.5727 - acc: 0.8027 - val_loss: 0.4990 - val_acc: 0.8383\n",
            "Epoch 938/1000\n",
            "45000/45000 [==============================] - 1s 18us/sample - loss: 0.5793 - acc: 0.8001 - val_loss: 0.4985 - val_acc: 0.8416\n",
            "Epoch 939/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5640 - acc: 0.8080 - val_loss: 0.4914 - val_acc: 0.8409\n",
            "Epoch 940/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5716 - acc: 0.8050 - val_loss: 0.5045 - val_acc: 0.8378\n",
            "Epoch 941/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5637 - acc: 0.8077 - val_loss: 0.4948 - val_acc: 0.8391\n",
            "Epoch 942/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5799 - acc: 0.7999 - val_loss: 0.5177 - val_acc: 0.8337\n",
            "Epoch 943/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5777 - acc: 0.7975 - val_loss: 0.4983 - val_acc: 0.8451\n",
            "Epoch 944/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5783 - acc: 0.7987 - val_loss: 0.4962 - val_acc: 0.8415\n",
            "Epoch 945/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5701 - acc: 0.8047 - val_loss: 0.4913 - val_acc: 0.8415\n",
            "Epoch 946/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.5659 - acc: 0.8043 - val_loss: 0.4968 - val_acc: 0.8377\n",
            "Epoch 947/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5799 - acc: 0.8006 - val_loss: 0.5048 - val_acc: 0.8383\n",
            "Epoch 948/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5675 - acc: 0.8027 - val_loss: 0.4885 - val_acc: 0.8403\n",
            "Epoch 949/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5687 - acc: 0.8027 - val_loss: 0.4997 - val_acc: 0.8375\n",
            "Epoch 950/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5625 - acc: 0.8074 - val_loss: 0.4956 - val_acc: 0.8376\n",
            "Epoch 951/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5649 - acc: 0.8045 - val_loss: 0.4994 - val_acc: 0.8393\n",
            "Epoch 952/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5641 - acc: 0.8035 - val_loss: 0.5007 - val_acc: 0.8395\n",
            "Epoch 953/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5664 - acc: 0.8026 - val_loss: 0.4995 - val_acc: 0.8399\n",
            "Epoch 954/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5660 - acc: 0.8052 - val_loss: 0.4975 - val_acc: 0.8377\n",
            "Epoch 955/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5707 - acc: 0.8022 - val_loss: 0.5004 - val_acc: 0.8394\n",
            "Epoch 956/1000\n",
            "45000/45000 [==============================] - 1s 18us/sample - loss: 0.5675 - acc: 0.8036 - val_loss: 0.4974 - val_acc: 0.8421\n",
            "Epoch 957/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5633 - acc: 0.8044 - val_loss: 0.5024 - val_acc: 0.8347\n",
            "Epoch 958/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5818 - acc: 0.7978 - val_loss: 0.4918 - val_acc: 0.8417\n",
            "Epoch 959/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5815 - acc: 0.8007 - val_loss: 0.5098 - val_acc: 0.8405\n",
            "Epoch 960/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5826 - acc: 0.7974 - val_loss: 0.5064 - val_acc: 0.8388\n",
            "Epoch 961/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5835 - acc: 0.7986 - val_loss: 0.5046 - val_acc: 0.8393\n",
            "Epoch 962/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5790 - acc: 0.8012 - val_loss: 0.5009 - val_acc: 0.8385\n",
            "Epoch 963/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5796 - acc: 0.8001 - val_loss: 0.4993 - val_acc: 0.8379\n",
            "Epoch 964/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5712 - acc: 0.8026 - val_loss: 0.5048 - val_acc: 0.8373\n",
            "Epoch 965/1000\n",
            "45000/45000 [==============================] - 1s 15us/sample - loss: 0.5885 - acc: 0.7956 - val_loss: 0.5096 - val_acc: 0.8354\n",
            "Epoch 966/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5791 - acc: 0.7990 - val_loss: 0.5112 - val_acc: 0.8373\n",
            "Epoch 967/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5823 - acc: 0.7977 - val_loss: 0.5097 - val_acc: 0.8351\n",
            "Epoch 968/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5795 - acc: 0.7971 - val_loss: 0.5390 - val_acc: 0.8240\n",
            "Epoch 969/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5911 - acc: 0.7937 - val_loss: 0.5148 - val_acc: 0.8326\n",
            "Epoch 970/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5891 - acc: 0.7922 - val_loss: 0.5165 - val_acc: 0.8318\n",
            "Epoch 971/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5814 - acc: 0.7948 - val_loss: 0.5129 - val_acc: 0.8323\n",
            "Epoch 972/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5795 - acc: 0.7980 - val_loss: 0.5129 - val_acc: 0.8334\n",
            "Epoch 973/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5764 - acc: 0.8010 - val_loss: 0.5115 - val_acc: 0.8365\n",
            "Epoch 974/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5844 - acc: 0.7971 - val_loss: 0.5088 - val_acc: 0.8323\n",
            "Epoch 975/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5862 - acc: 0.7979 - val_loss: 0.4976 - val_acc: 0.8420\n",
            "Epoch 976/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5796 - acc: 0.7986 - val_loss: 0.5028 - val_acc: 0.8377\n",
            "Epoch 977/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5827 - acc: 0.7964 - val_loss: 0.4985 - val_acc: 0.8395\n",
            "Epoch 978/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5640 - acc: 0.8051 - val_loss: 0.4990 - val_acc: 0.8395\n",
            "Epoch 979/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5750 - acc: 0.7978 - val_loss: 0.5074 - val_acc: 0.8359\n",
            "Epoch 980/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5729 - acc: 0.8015 - val_loss: 0.5000 - val_acc: 0.8383\n",
            "Epoch 981/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5746 - acc: 0.8006 - val_loss: 0.5121 - val_acc: 0.8369\n",
            "Epoch 982/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5965 - acc: 0.7960 - val_loss: 0.5215 - val_acc: 0.8335\n",
            "Epoch 983/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5857 - acc: 0.7977 - val_loss: 0.5063 - val_acc: 0.8323\n",
            "Epoch 984/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5828 - acc: 0.7963 - val_loss: 0.4994 - val_acc: 0.8397\n",
            "Epoch 985/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5719 - acc: 0.8017 - val_loss: 0.5057 - val_acc: 0.8351\n",
            "Epoch 986/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5757 - acc: 0.7999 - val_loss: 0.5102 - val_acc: 0.8358\n",
            "Epoch 987/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5755 - acc: 0.8032 - val_loss: 0.5112 - val_acc: 0.8331\n",
            "Epoch 988/1000\n",
            "45000/45000 [==============================] - 1s 16us/sample - loss: 0.5845 - acc: 0.7966 - val_loss: 0.4988 - val_acc: 0.8357\n",
            "Epoch 989/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5679 - acc: 0.8031 - val_loss: 0.4979 - val_acc: 0.8401\n",
            "Epoch 990/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5925 - acc: 0.7940 - val_loss: 0.5097 - val_acc: 0.8409\n",
            "Epoch 991/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5751 - acc: 0.8004 - val_loss: 0.5024 - val_acc: 0.8385\n",
            "Epoch 992/1000\n",
            "45000/45000 [==============================] - 1s 18us/sample - loss: 0.5789 - acc: 0.8012 - val_loss: 0.5289 - val_acc: 0.8306\n",
            "Epoch 993/1000\n",
            "45000/45000 [==============================] - 1s 18us/sample - loss: 0.5762 - acc: 0.8028 - val_loss: 0.5032 - val_acc: 0.8410\n",
            "Epoch 994/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5794 - acc: 0.7997 - val_loss: 0.4957 - val_acc: 0.8405\n",
            "Epoch 995/1000\n",
            "45000/45000 [==============================] - 1s 18us/sample - loss: 0.5854 - acc: 0.7998 - val_loss: 0.5041 - val_acc: 0.8408\n",
            "Epoch 996/1000\n",
            "45000/45000 [==============================] - 1s 19us/sample - loss: 0.5898 - acc: 0.7925 - val_loss: 0.5136 - val_acc: 0.8359\n",
            "Epoch 997/1000\n",
            "45000/45000 [==============================] - 1s 18us/sample - loss: 0.5790 - acc: 0.7988 - val_loss: 0.5078 - val_acc: 0.8410\n",
            "Epoch 998/1000\n",
            "45000/45000 [==============================] - 1s 17us/sample - loss: 0.5713 - acc: 0.8042 - val_loss: 0.5099 - val_acc: 0.8415\n",
            "Epoch 999/1000\n",
            "45000/45000 [==============================] - 1s 18us/sample - loss: 0.6159 - acc: 0.7839 - val_loss: 0.5448 - val_acc: 0.8259\n",
            "Epoch 1000/1000\n",
            "45000/45000 [==============================] - 1s 18us/sample - loss: 0.6005 - acc: 0.7902 - val_loss: 0.5201 - val_acc: 0.8312\n",
            "10000/10000 [==============================] - 1s 52us/sample - loss: 0.5316 - acc: 0.8207\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UteN9qb5rljX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c0b7bdb7-4364-4f45-ea26-94d1ec3e420f"
      },
      "source": [
        "# Plot model loss\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.plot(history.history['loss'], alpha=0.5)\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['loss', 'mse'], loc='upper right')\n",
        "plt.show();\n",
        "\n",
        "#Plot model accuracy\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.plot(history.history['acc'], alpha=0.5)\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['accuracy', 'mse'], loc='upper right')\n",
        "plt.show();"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmQAAAHwCAYAAAAIDnN0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngwAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 720x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmQAAAHwCAYAAAAIDnN0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzs3Xl0m9d57/vvg5HzTGqgBkqyJEuW\nJcuSbVkeYsdx4jZx7KRNMzd2mrlp097m5KS9bU9W23Nvz1onPbdN0564beYmThrHOW6byY7t2I7n\neZJkybIkUhLFeSZADPv+AeAlQIIkKBEgJf8+a2mJAF4AGyAI/PDs592vOecQERERkcXjW+wBiIiI\niLzeKZCJiIiILDIFMhEREZFFpkAmIiIissgUyEREREQWmQKZiIiIyCJTIBORs4KZfd3M/qrAbY+Y\n2ZuKPSYRkYWiQCYiIiKyyBTIRERKyMwCiz0GEVl6FMhEZMGkpwr/i5k9b2ajZvYvZrbMzH5iZsNm\ndo+Z1Wdt/3Yze8nMBszsfjPbknXZTjN7On297wFlU+7rbWb2bPq6D5vZ9gLH+FYze8bMhsys3cy+\nMOXyK9O3N5C+/Jb0+eVm9kUzO2pmg2b2UPq8a8ysI8/z8Kb0z18wsx+Y2bfNbAi4xcwuNbNH0vdx\n0sz+3sxCWde/wMzuNrM+MztlZn9iZsvNbMzMGrO2u9jMus0sWMhjF5GlS4FMRBbabwDXA5uAG4Gf\nAH8CNJN6z/l9ADPbBHwX+IP0ZT8G/t3MQulw8iPgW0AD8G/p2yV93Z3AV4GPA43AV4C7zCxcwPhG\ngd8G6oC3Ap80s5vTt7s2Pd4vpcd0EfBs+nr/E9gF7E2P6XNAssDn5CbgB+n7/FcgAfwh0ARcDlwH\nfCo9hmrgHuCnwErgPOAXzrlO4H7gt7Ju94PA7c65WIHjEJElSoFMRBbal5xzp5xzx4EHgcecc884\n5yLAncDO9HbvBv7TOXd3OlD8T6CcVODZAwSB/885F3PO/QB4Ius+PgZ8xTn3mHMu4Zz7BhBNX29W\nzrn7nXMvOOeSzrnnSYXCN6Qvfh9wj3Puu+n77XXOPWtmPuDDwGecc8fT9/mwcy5a4HPyiHPuR+n7\nHHfOPeWce9Q5F3fOHSEVKDNjeBvQ6Zz7onMu4pwbds49lr7sG8AHAMzMD7yXVGgVkbOcApmILLRT\nWT+P5zldlf55JXA0c4FzLgm0A63py44751zWdY9m/bwW+KP0lN+AmQ0Aq9PXm5WZXWZm96Wn+gaB\nT5CqVJG+jVfzXK2J1JRpvssK0T5lDJvM7D/MrDM9jfn/FDAGgP8DbDWzdaSqkIPOucdPc0wisoQo\nkInIYjlBKlgBYGZGKowcB04CrenzMtZk/dwO/HfnXF3Wvwrn3HcLuN/vAHcBq51ztcD/BjL30w5s\nyHOdHiAyw2WjQEXW4/CTmu7M5qac/kdgP7DROVdDako3ewzr8w08XWX8Pqkq2QdRdUzknKFAJiKL\n5fvAW83sunRT+h+RmnZ8GHgEiAO/b2ZBM3sncGnWdf8J+ES62mVmVplu1q8u4H6rgT7nXMTMLiU1\nTZnxr8CbzOy3zCxgZo1mdlG6evdV4G/MbKWZ+c3s8nTP2itAWfr+g8CfAnP1slUDQ8CImZ0PfDLr\nsv8AVpjZH5hZ2MyqzeyyrMu/CdwCvB0FMpFzhgKZiCwK59wBUpWeL5GqQN0I3Oicm3DOTQDvJBU8\n+kj1m/0w67pPAh8F/h7oBw6lty3Ep4C/MLNh4M9JBcPM7R4Dfp1UOOwj1dC/I33xZ4EXSPWy9QH/\nA/A55wbTt/nPpKp7o0DOXpd5fJZUEBwmFS6/lzWGYVLTkTcCncBB4Nqsy39FameCp51z2dO4InIW\ns9wWDRERWerM7F7gO865f17ssYjIwlAgExE5i5jZJcDdpHrghhd7PCKyMDRlKSJyljCzb5Bao+wP\nFMZEzi2qkImIiIgsMlXIRERERBaZApmIiIjIIgss9gDmq6mpybW1tS32MERERETm9NRTT/U456Yu\nFj3NWRfI2traePLJJxd7GCIiIiJzMrOC1gvUlKWIiIjIIlMgExEREVlkCmQiIiIii+ys6yETERGR\nhReLxejo6CASiSz2UM5KZWVlrFq1imAweFrXVyATEREROjo6qK6upq2tDTNb7OGcVZxz9Pb20tHR\nwbp1607rNjRlKSIiIkQiERobGxXGToOZ0djYeEbVRQUyERERAVAYOwNn+twpkImIiIgsMgUyERER\neV2Jx+OLPYRpFMhERERkybj55pvZtWsXF1xwAbfddhsAP/3pT7n44ovZsWMH1113HQAjIyPceuut\nXHjhhWzfvp077rgDgKqqKu+2fvCDH3DLLbcAcMstt/CJT3yCyy67jM997nM8/vjjXH755ezcuZO9\ne/dy4MABABKJBJ/97GfZtm0b27dv50tf+hL33nsvN998s3e7d999N+94xzsW9HFrL0sRERHJcf+B\nLrqHowt6m83VYa7Z3DLndl/96ldpaGhgfHycSy65hJtuuomPfvSjPPDAA6xbt46+vj4A/vIv/5La\n2lpeeOEFAPr7++e87Y6ODh5++GH8fj9DQ0M8+OCDBAIB7rnnHv7kT/6EO+64g9tuu40jR47w7LPP\nEggE6Ovro76+nk996lN0d3fT3NzM1772NT784Q+f2RMyhQKZiIiILBl/93d/x5133glAe3s7t912\nG1dffbW3nERDQwMA99xzD7fffrt3vfr6+jlv+13vehd+vx+AwcFBPvShD3Hw4EHMjFgs5t3uJz7x\nCQKBQM79ffCDH+Tb3/42t956K4888gjf/OY3F+gRpyiQiYiISI5CKlnFcP/993PPPffwyCOPUFFR\nwTXXXMNFF13E/v37C76N7L0dpy5DUVlZ6f38Z3/2Z1x77bXceeedHDlyhGuuuWbW27311lu58cYb\nKSsr413vepcX2BaKeshERERkSRgcHKS+vp6Kigr279/Po48+SiQS4YEHHuC1114D8KYsr7/+er78\n5S97181MWS5btox9+/aRTCa9SttM99Xa2grA17/+de/866+/nq985Ste43/m/lauXMnKlSv5q7/6\nK2699daFe9BpCmQiIiKyJNxwww3E43G2bNnC5z//efbs2UNzczO33XYb73znO9mxYwfvfve7AfjT\nP/1T+vv72bZtGzt27OC+++4D4K//+q9529vext69e1mxYsWM9/W5z32OP/7jP2bnzp05e11+5CMf\nYc2aNWzfvp0dO3bwne98x7vs/e9/P6tXr2bLli0L/tjNObfgN1pMu3fvdk8++eRiD0NEROScsm/f\nvqIEjXPJpz/9aXbu3Mnv/M7v5L0833NoZk8553bPddvqIRMRERGZw65du6isrOSLX/xiUW5fgUxE\nRM5p8USSbz16lGs3t9DWVEkklqB/bILbH29nz/pGLt/QuNhDPCM/f6mTRNLxaxfOPD13upJJRySe\noDzoX/DDKjnnGI3GwYzyoB+/z7zz40lH0L+0uqqeeuqpot7+0nq0IiIip2l/5xBPHe2bdv5wJM7A\nWIz7DnQBcMfTHdz+eDsAjx7uXfBxjE8k+O7jx+gaOv0DTefz9LF+Xjk17J12ztHeN8ZLJ4bY3zmc\n9zrOOZ7vGCASS5zWfQ5FYgxH4sQSk+1N82l1SiYd8UTSOx1LJHHOEUskSToYnUgwGo0zOB7zthmJ\nxukbnSCeTOa7yXOWApmIvG4555iIn96b/kQ8yS/2nWJsonSHYHmufYCXTwyV7P4KFU8kiSVmfx6d\ncxzoHJ7x+ZrPh/y9+0/xwCvd087/yQudPPBKz/TbTv+fSKZ+6hqaXPDUZ4Zzjh8+3cHdL5/i6796\njWg8wSunhr1ANRKNc+/+U7T3jXHbA6/SNzqRM+5kMhUwRtPbPX2sn87BCI8fyQ2HzjnuP9DFkZ5R\nbyzPtQ/k3N5Ux3rH6B2J8sirvfzyQDf/+fxJ77IjvWP84KmOWZ+rU0NRfrGvi1/s65p1u+wxZssE\nsUyQiieS9I5OMDiWGnP/6AT9Y7nPx9hEnGT6dvrHJugdnSDpHIlkkr7RCYYjqcA19XmMJZIkkkkm\n0q+lyESSofEYiaTzbm+usQ9HYgVtWwxn2pNf1ClLM7sB+FvAD/yzc+6vp1y+BvgGUJfe5vPOuR8X\nc0wiIhmPv9bHw6/28slrNlAW9M/rusf6Rnm+Y5DxWIK3bV+5oOP61qNHqQj6uWHbcirDAb7/RDs1\n5UH2nUyFsfXNlfzqUA97NzRRHvKTSDqccwQKmOJ55lg/D7/ay6eu2TDnFNTzHQNUlwVZ11SZ9/KB\nsQmSDu585jhD4zH+8PpNM97Wsb4xfvzCSbavqqWuIkh5MMDA+ASRWILyYICnjvZRHgowNB7jPZeu\n5rn2Aa7fuhwDBsZjNFSGvNt6rn0QgKs3NXvnDY7lVliqwpMfb5lKSyYEZTODofE4R3vHJsfaO+YF\nn43Lqjh4aiTnfn91qIcbd6ykezjKtx89CkBteTCnygPgHHT0j7GythyfzxiJxnnm2ADPHBvg4rX1\n7N3QyL37J4PSG89vYcfqOu8+xiYSvHh8cNqYnXOYWU4QAojEEgyMxRiJxtnfOURDRYjqsiAAr5wa\n5qpIEzXp01Ov1z82QVlZGb29vTQ2NmLpoJoJGSPROCPRyTCdSDpqwQtPiaTD7zOi8STDkTiJpKMi\n5Ceefs6HxmOUp//GxtPVuuzg5DPzAlogPXU5mg7v47HUlGlN+fSxT30cYxOp28487kyY85mRvlkc\n0D0cpaYsQHloYWKQc47e3l7KyspO+zaKFsjMzA98Gbge6ACeMLO7nHMvZ232p8D3nXP/aGZbgR8D\nbcUak4hMOto7SkPl5Bv269FL6WpT93CU1Q0Vs247Go3z4MEertncTFnQTzRdWTsxMM6hrmEef62f\n0Wic3W31bGip4mjPGJuWVxHy+3imfYD6ihAjkTjLa8sYjcZpS4ecRDJVUagKBxiOxqkMBehJH7Lm\nB0918P7L1nB8YJzjA+PeWF4+OcTzHYP4fcZVG5v5l4cOU1cR4orzmnj5xBCXtNVTVxGa/iCA+w+k\nKkt9oxM0VoUB6BqK0D0SZeuKGjqHIlSGA9SUBb2qytSgNRyJ8dDBnmnTZCcHxwkH/HzviXaSznFe\nSxVvuWA5AIe6Rrzn+vmO6SEDIJYONJnpxLamSg50DnO4e5SrNjaxu60hp8I2FIlRUxakZyTKtx45\n6p3/Tw8c5uNvWM+/PdnBm7YuIxM7E1kBI8NncKR3NOe8I1nhLDuoZRzqGuG7jx/LCTdTw1hmu0Nd\nI1y/dRnbWmuJxCariMd6R9myvDpn+3v3d7F5eTV+n/H4a9OnXjP+9hcH+chV6xmYEsj+8f5Xp20b\nDk6G9Bc6BrnivKZp29x/oJt9J4f47ctWM9TbydHjqZ40h5ssL+bRWxZgOJL6fRwBykN+nEsFI7/P\nvADs8xnJpCMc8Hl/N9lSXwwc2b8aM3JO+8yoKguQSDrGYwkqQ9N72ibiSSKxBEG/Lz0W540PIBTw\nEU86yoN+RqNxfD7LCe5nqqysjFWrVp329YtZIbsUOOScOwxgZrcDNwHZgcwBNemfa4ETRRyPyDkp\nEksQT7o531iSScff/uIg12xuZseqOn749HEqQn4+/oYNOduNTyR4vmOAS9oa8Pmmv+GFApNv8M45\nOvrHaa1LVQDGJxJE44m8YSCeSBKNJ0k4R2UogIF3+4PjMV4+MURzdYh/f+4ku9vqWV1f4YWWbF1D\nEa/Zt64i6H2Tf/nkEJuWVRP0+3DO8eLxIc5rqaI85E9/qI9Ma3ouD/kZHI/RNRzxAlk8kfQqTbFE\nkgOdw1ywsobHj/Sx7+QQo9E4lWE/+06mwshoNMG/Pzc5jXT/gW5e7R6lvW8Mh6OxKswvD0yfXtuy\nopqda+p5tXuExw73sa6pktd6RvnNXZNv6H2jE3Tm6UPKTLm9dGKIZ44NpMcxzvefSAWZV04N87vX\nnkfXUITDPaPsPzlEPOmoLpt8jZwcjFBfEWI4EudfHzsGwC/2dZFIOspDfj6R9bpIJh0+nxFPJNl3\ncpiDXcN5g8rtj7ezqr7c61fKTK++5YLlDKQrWCcHC++r+skLnWQ+cw92jbC7rYHekckQ8i8Pvsa2\n1lrW5AnTX/nlYQDu3XeKnvR1kknHI6/m9oyZ2bQ+spODk+F36pT2u3av4okjfRzpGaNzymOpLQ+y\ntrGC6rIgSTd5X5nKT3YfV8/IhPe8A+zd0MjDr/by4MEefHkKl8tqyrjyvCbueLoD5+B7T7QT8BnV\nWaEon2gsSXN1mFgiSedghBc6BnnwUDc3bl/pveYz4zvUM0ZLTQsPHDqecxvbV9XmDdFXbWzi4eOT\nU8QXrakjFk/yUu8QoYDPe+5u2Lacn77YSUXI71Wwsq1vruRwd24ovmVvG51DEZ5rH/BeM1dvak5P\nVQe46aKVrG9OHUT8ySN9mIHf5+PhdMXxivOaONw9kvf19qYty3h43ylWN1Twm1tOP0AttGIGslag\nPet0B3DZlG2+APzczH4PqATeVMTxiCxJ8USSruEoK+vKZ93u5RNDxBJJ2poqOdY7RmXYz/rmKn74\n9HFODUX4/es2sr8zFULCAT9dQxFqK4KE/D7MjL70t+mHX+1lfVPqjWxsIsHf33uQj79hA0G/j1gi\nyYMHu3npxBBN1WE2pN/wANr7Uv0q79jZSltTJY8e7vU+cK7b0sL2VXX862NHGY7Ep1VUxicS/OjZ\n494H2JqGCgbHY1SE/Lzj4lbuP9CV84b85JF+Dp4a4cNXriOZdJwcitA7EqVvdMILIIA3liO9Y/z8\npVP0jkxw9aZmBsZi3LPvFM91DPC+S9fw4xdSgSng93Fhay3La8u85x7ggVd6aK2r4HBPKhx98poN\nhPw+fvh0BycGItz98ilv2u5Y3/QgAniBKvNcAXT0j8/Yu7Pv5DBDkbhXvclc95n2gZzt/u3J6T1C\nmanLmfrfJuJJ/uH+Q0RjuZdnf3Af7hnlsdf6GMqq7GQqGuMTCa+iBanAXF8Z4rmOgbw9Wtk6+sdz\nTr98Yohda+sZyLqfTcuqqasI5lSBsqcGs/36hSs4ORjhhY4BkklHz0juAa9fPD5I32jqPJ8Z21pr\ncsJDT1aASyRhX+dwToiZiCeZAMqCfi8wZYe+bK315ayqr6C+IsRtDxz2zr/2/Bb6RqPsWd9IRXoK\nbHAs5v19ZB77+CyN9eevqOHFE0N5pygBdrfVs6axgvddtobvPHbM+71de34LteVBfvRMbojKrjBV\nhv3Ulpex7+QwVWUBorEkx/rGMEuF98zjHptI5ITRjJ1r6jGbnLLNePBg7mvhte5Rr1KY/drM/O3k\nC2MAjZVh7++/Khzg0nUN1FeGqK8MsWVFDfft7+LZ9oGcvsFXTo14t5sZxyVtDd7lvzo08+v0nn2n\nAKgIza9NodgWe9mL9wJfd8590cwuB75lZtuccznvImb2MeBjAGvWrFmEYcq5IFPqXogS9cDYBLXl\nwYJ2A3fO8f0n25lIODa2VLG+qZKWmsk+g/sOdPPi8UE+fMU6aiuCDI7FCAbMe2PP+NlLndNu+5rN\nzZxKV1AeO9zLY6/18fOXTtFaV+5NcV21sYlda+u95t+JeDLntmIJx0gkTn1liC/fd8h7E+8bnWBD\ncyoonBwc57HDqQ/PO585zoraspxvnr/Y14XfZ96HXCSWoCyY6m264+kOuoYiOXtpZULN4HiMn790\nKu80RjSe5PbHj81aUbnzmeN8/A3rvQ+B4Ugc5xx3v5x6w+0ejtKd9QH+4vFBDnYNE/AZ12xuyZlm\n+u7jk9WKkWic9r4xTgxM3ncmMM2kpSbM+ubKnAB2IM+eb1tWVDMSTTAciXG8f5zW+twgfrg7FUo+\nsGet15+Uz9TfQbZlNWXe62Imr3blhp+pt/fvz01OWGQC2UR88nc4U7UjWziYqpI8MSX4Xba+gUgs\nkRPI9qxvzBvINjRXEU84YgnHD57u4Hj/OGbQXB3GMPpGo5wYiBAO+vjUNedxqGtkxinRpHMMjce4\nfusyWuvKOdg14n1w71hd673GZ/KudPWyMhxg07Jqb4/HLSuqCQfqcratrQjyqWs38NMXO70G+PEZ\nnq9QwEd1OOD1TgFcsLLGm1K/6aKVXvgoC+SGiHWNldSUB3jHzlZ8ZozFUg3z21fV0dE/xk9e6CSZ\nhBW15TzXPuh9KRqOxPn5S6dy/gai8dTOGWVBPzfuWEFjZZiDXcPUVwSpnKHX6i0XLOf+V7qIxpLe\nbdVVBL2KKKTCbr7Xyzt2tlIZDjAcmdz2Q3vbcqrwkBvkMrez7+QQjVUhNrZMfml84sjsv7/qsgDj\nEwmvry0cWFr7NRYzkB0HVmedXpU+L9vvADcAOOceMbMyoAnI+UrpnLsNuA1SK/UXa8Bybsg0l2Yc\n6x3jYNcwE/Ek+zuH2bO+kVgiyYWttdRX5u+zyWckGmf/ySEqQgF+9lInN120kjUNFTx+pI+TAxGu\n29KSd6puKBL3Pth7hqM8driPW65o43D3CK115d434vb+MWoravnqr17zphKP9Izy4MFuLl2Xf52k\n+7Omwp7P+mad3W/04MGead9ksy+H1BvxRDyZ07Px0MEeHjqY/1tmviDw85dOeT/v7xzmvJYqOvrH\nOJ5VMblsfQO71tbzD/elel1W1ZfnVGKyRWIJTg5O/wArD/m5ZW+b1y/z6OFe74M8nkzy+Gt9OY/v\nsSm9ONFYkijk7K021Ugkzgt5KhWr6stpa6okGktOe/PfvbaB9v781TOAxqpUj1em6vhCxyD37Ds1\nbWmEzO+gsTLENZubuf9Ad07AzjivpSrv7+GStgYu39DI3/3iIEDO1FHG+/es4Y6njudMob3n0jX8\nr7tfyTv24UicaDzBq92Tv6v371nLY4d7SSSdFxwyKsN+RqMJdqyq49RQZFqvWX1FKKf/6Z0Xt9JU\nFea3LlntTbv+xsWraKwK4fcZqxtSoTXzWqqvCPHeS1Jfzn/4zHHa+8a8XsgVtZNfdjLPXzafGee1\nVFEW9OdM4TZVhbllb1tOSLt4bT2dg+OsrCtPBcCsL2ABf+pnMwjNsDNFOJBqRD8+ME7XUISH0rd7\n2boGHnutj11r63nqaL+3g0X2Tgcbl1WzrbWWynCA2qxm9qlhpTKc6qXKN72fCVGhgI/l6S+BmenJ\n4UiMsqA/J5BNJJLE4knqK4Ksqk9NZ25flQqau9saWFZTxp1ZlbhQwMeWFdVsWVFN/1iM/3zhJJe2\nNbCxpYpjfWN0j0S930dVWWBaIKsI+2muDlNXESQU8LGhuWra44PUVGgm/L7lguXeGB462JO3Shz0\nm/cFMPuLRsBnXLWpmfvS05r5dvJYTMUMZE8AG81sHakg9h7gfVO2OQZcB3zdzLYAZcD0ZguRPIYi\nMSbiSRoqQiSd4+ljA7RUh/nPF06yZ30ju9bWc7R3lB8+nfs9INMv8lz7ADfvbCUc8HkVqyM9o9z5\nzHE+ctU6uoejPHq4j7bGClbUlU+bEhiNJnj41V6eOpo6oO1TR/u5amMzQb/x0okhTgyM8+YLlufs\n/QWpb+lffSh1kNzsb8R3v3zKe/Mam0iwv3OIXx3qZWg85k25bWipwmBaiAkFfN6378yb/FT1FUEG\nx+N5dwl/rmMgp4JRW57qgclUvG69oo2v/erItOtduq7Bq3I0VYe9ZvT79nd5b3qQ6v3Yvqp22kKP\n157f4jVj71nfSHN1iOW15Rw8Nex9kJpBeXDy23VteZCyoJ9fu3A5P3mhM2ca5XD3aM7UZ11FMKcS\n1FITZseqOq+CZgZB//TA8uDBbnpHJnjb9hU0VIb4ZnqMv7lrlfehXFUW4OCpYTr6x7lyYxOhgC9v\n9dVnRtI5Prhnbc4Helkw06c2+ftYWVfmVXt8PuOClbUAbFlRM61he+peoVdtbGJba+20899zyWpv\n/AA37lhBS3UZt17RxrPtAzk9VbfsbePrDx+Z9hgOdQ970zyQ6vmpCge4bssyOvrHvCnuaCzBcCTO\nspoyLlvXSEt1mOMD4xztHWPvhka2tdYyMB7D7zPKs6aL1jamwkRrXTkXrKyhpaaMNY2TfWHVZUHv\n9dVaV86bti7z+g8bK0O0943RkP4yVBkO8IfXb2JsIk550M/Dr/bm/H4rQn7vOSrPeq7KAn7qK0Ns\nXlbtBbI3ZO3FOVUmhAXTLQEzqQylpgh/+Uo3E/Ek1WUB9p7X5C1Ge9XGJu/62X+bVeEAzdXhabc3\ntaoz2561rXXlXLaugR2r66a9LqZOLUOqej4ajdNYNf2Lpd+XCn1+n9FYFeLtO1biM/PG3lAZ4oN7\n1nrbtzVV5oTE6rIgXUNR6iuC9KffE7Ofw49ctW7GYNtaV84fvGkjI9H4tJ2QHn+tj1DAxxvPb+G1\nnlFCfh8Xr63nG+nX8VWbmvnJCycZjsTx+31UhSefh/jrJZA55+Jm9mngZ6SWtPiqc+4lM/sL4Enn\n3F3AHwH/ZGZ/SKrB/xZ3th1cU87YE0f6WFad+wY8Go3z5NF+LlvXQNDvw+8z7nn5FKGAj6s3NZNM\nOr73eHvObtjZHnilm+W1ZdPCWLZ40uWs4XPVxibvm/59B7q9D/KZpn5ePJEq/5eH/OlG+EGe7xjM\n2f29IhRgtlnNqW8Iz3VM9g/95IXcKcoNLVW8fUdqeYVYIsn9B7oZjyV44/kt7D85xIMHe7xVx1tq\nwhztHfOaqm/csZJV9eW0943xH+nK0NsvWsldz6ampbLXtrpqYxMbW6opD/n58n2HAKirCHHrFW0M\njsdyntPsv9brtyzju48fyztdtnVFTU4Ye9v2FTx1tJ+GihDhoI9oLMny2jJvWib1Ad3NmoYK3rGz\nlZ+91OlVWd62PdWYf/7yGqrLgl5FZbLhl/TpJrasqOEX+7rY0FyF32esqi+nMhxgW2stQ5EY0ViS\n5zsGpk1x9YxMsHFZFRuXpfaC8/uMynAg54P3otV17FhVy2s9o7SlA0VDZYiAz6ivDLGttZaDp4Z5\n6/YVjETj0z60sz8gMz1NaxoqOTEQ8YJCKOBj55r6nOvt3dBIwG9sXl7theikS1Uw8ikP+dmyosbr\nO1vTUOnd/8aWqpxAVl8Zylu7tjkWAAAgAElEQVSNO9KTW/m76aJW7+dV9RV84g0bKA/5+dEzxxmO\nxAn5fV6f3uqGCj529Xoq0nvFVaZDa2bqbVlN7jIBb07vlTlVZchPD7CmsSJnCYya8tTtTQ0qmSn/\nD+1t45+y+r0cudOuGZmAXFsRZM/6Rm/8M8lUyOaa9srcR0f/OOubK7l+6zKAvCHuzVuXc8fTHayq\nL895jNmm7mgzG5/P2Ju1V2V2n1w+E/EkI9E4axtn3uP4d689L2eHnELVV6SC1NrGSvrHUu9z2WEy\nHJi9n8vMvDD2nktXE/T7uOOpDsYmErTWlbNlRQ1bVtR423/8Deu918CNO1bynceOUVMW8F5/8DoK\nZADpNcV+POW8P8/6+WXgimKOQUonnkgST6YOhVFfEaJ3dIJXTg2zfVWt94d0cnA8vddaLffuP4WZ\nedMQN2xbzqmhCMtqyvjpi6kw8nS60rNzTZ03hXT1pmZODkVmDGOZcnXmgxpSH3jrmiq9D963XLB8\nWk9W9rTeq10jBHzGzTtbvdC2ZUW1t2edz4zOwQj1FUF++/I2DveMeHvaZU8BZKa1Aj7z/vgz/RVb\nVlQzMBbj6k3NLK8p438/8Oq0ptnsx5P9zS7o93lv7JD6MN66ssb7ID9/eQ3nL69h87JqjvaNcV66\nz2Ljsmo+dW0F/aMxKsLT3wC3r6qd8YO9riJEXUWID1+5jkNdwzzwSg+15UH2bmikfyzG8toyPnr1\neipDftr7xrnj6cmwWxbM/dDauKzaCzvnNVelKixZ38obKkPcku4l8fmMXW31HOkd4/171uR8Q27M\n+tBqnbJTxK61qcdx4478a4TVlAWhLFUFuWh1HYe6Rng4K5xsS1enIPXm7svzAWpm3p5ekPq9fOra\n84gnk4QDfi5Kryk1tR8Qcpcj+I2LV+HzmVdNLZ9lTbTL1k9OX+/Ns4TBVGUBP2+5YBlD4zGOD4zn\nTAmV52lqzjclNhpNzHh59u1kQubUqk1lvsqhz3jPpaupn2F5jqkybQhTn5vyYOq2s6cfs2VXLesq\ngjlrl2U//nDW7RZyKKXMF4zAHMEk+7FvXVGT97WQsaaxYta13Kaa6bU981hSgWzLimqu2dzC+ETC\nq4hWhPyMxxJMxJOzvv788wxiGavqK3jySH9Ov2jQf3q3taI29bfeWBVmrG+MVfXTd4jKfp5bqsPe\nF7Tsaml8jsWMS22xm/rlLJApWpqZd1yzqW8qD7zSnTNNlmlUPt4/TiLpuHpTM845b32hl08OTdsD\nLBPC8snes+7F44N0pHt1fv3CFd50Xsby2nKGI7GcptL3XbaGcMDP8x2DNFSG2LqyhvOXV3N8YHzG\nla4vXdfA6oYKPnPdRk4ORVhZW0Y46GcinuRIzyhjEwnamirx+YwNzVXcvLPVm9ac+iFWEQ541YzM\nWKZqqgrn9Fu9YXMzkViCkUicl04Mzblwab43+qnTBpD6Jrq81j9tZfXNy6unTdG899I10z6Aa8uD\nXLymnmU1ZbTWled80898+K1prOCjV68n5PcxkUjOOqXzxvNbuGh13bSpiOz+vpbqMj55zYapV82p\nTtRVTF7/6k1zB5WMgN9HY1WYhsoQO1bXeVOD2W/yc317z+b3GX7f3Ntn/z4zy3d4oSNPUHr3Jau9\nqsx8ZCoZ77i4ddpeflMbxAHetHUZDx/q8arFy2rKvGng37587ayvw0zwLnScmQ/WQmQCcXhKuD9/\neTUTiSTbVtbku1qOW69Yl3M6Z8oyOL8G70wgm2vHnsqs3+Vca93N13lZDe2FyDzecDA1bZtbpQ16\nle35LpJciLUNFezd0MiWlZPV2qDvzJrq33h+C3e/3MnmKeu5TWVm3he08qDjsvUNvHxiiPa+ccYm\n4rOG5FJaGqOQJScaT+AzI+j38ZMXOznWN8YNWc2UF62uY1V9uVflmNqzlB0sDnePcKBzOKeiFY0l\nqQj5edfu1TzwSre3B1t5yM+mZVWUBwPT1gbKrFWT6f8JBXxsXl5NY1WIXx7oZjgSYygSZ9faeoJ+\n85YLuHHHCu8P7jd3raIpvRimz2epdWh2reLx1/o41jfGrrX1XNLWwKvdI1752+czr/py7eYWAK/5\nOfMGa2Y5q5lfvak5Z8ox4DPefclqDnaNzNgn0VgZ4nj/OOUhP8tqwlywsoZwwO/1Ys0nFBQiewrx\nhm3Lc8r9GTNN25iZ1/Q7k0w4y1dRyRbw+3L2Op2P7A/D7HCWmUKc721lfxAVsur9mcgOQ5nHUZnu\nb8pXoZhrWZSp3rZ9BV3Dk3uYBv2+aT18Pp+xa219zmu3KhzgzRcsp6N/fNr6XvUVoVmnqjLPn3+B\nD0INk5WZqYc39PnMq0TONq58U3UBv4/dbfUYNuPf5Uwy1Z25DoCd+aLRWle+YEHnui0tc/5d5ZN5\nHwznGXN1WYBT6c6FYgQyn89yqruZ885EQ2WId18yv5UXzIy9G5ro6B9nOBLnxeNDXLou/6xAqSmQ\nSV4/fPo49RVBbti2wtt1P7up99n2AZ5tH6Cpuo/z83w7uW5LCxPxJImky5kGylx2vH+ca89voSzo\nZ0VtmRfIrt+6zNsLLRPILlvfQEt1mFX1FTmNzbvXpnprmqrCvPPiVE9L5oMt8+Z70Zo6zmuZHF++\nb6irGyrw+4yxWIJda+spD/nZ1lo7bbt81s7wjXdDcxV71jcSChgPvNJDIulYWVc+64dqZtX0C1bW\ncNXG6c3EZ/jeldetV7RRHvIveNhbDNnhLHgGu7M3VYdZOUf/0ELIfKBnVznMjBt3rKA6fOZHT8ie\nFp7N1TM0rn/4ylQ16eFXU1P5AZ/N+QGaCQmJIrQCb15ezYHOYZbVTG90n8tvX76W0RlaHPL9rRUi\nkK7uVOaZ+s9WHvLzO1eto2oBqzCZPR/nK9Nvl2/aMXvKd77Vwvl6/541nBqMzr1hEWU+I2aa6l4M\nS2cksqgisQQHOofZsqKGZ9sH6ByMpHrCsqa18q0G3TMc5aH0t/Drty5jbCLB5uXV3m7ayWTqmGvx\nZNKrMq1trMx5Q7mkrYGB9ErtDVn9JB/Ys5ag33KWkrhyYxMPHezhgpU1Od+28jVMz+dNcGVdec4e\nQnP5wJ61xLJWdM94ywXLOT4wTtDv4/INjd6SBoXsXr1tZU2q1+00qjuna6bD65xNbti2fNru9POt\ndmSbz+vgTJgZn7xmw7QKy1yVx1LLVFUKaYDO9FMlEgsfyDY0V/GZ6zaeVlWlMhzI28d2JjJT/oVM\nd+U7fuRiuHx9IwGfj/OXT1bDVzdU0N43lvNeUIwKWbaW6jJaqov/pWc24xMKZLJEvNAxSENViGTS\n8cDBbu9QLE8c6fOC1+B4zNsjL2Pz8mo6ByNe4/qe9Y1eJau5Ojxtjymfz+YsB/t8xpu3LmPPukZq\ns/qA8u3ynflmV0i5vphvgvnGBrB1ZQ1bs3pZMtMVM+0xlS3g9+WsjJ/RWl/Os+0DM97n612+qda5\nppGWimJ/8C2EynmsZp7p8yrW3mtnOsW1kDLvRWfT32Ug/UUx2407VjA4Hsvpec3XW3iuGfcqZEsj\nLIMC2etCJJYgHJhcK6dzMJIz/ZgtuwoWSzhvKvHSdQ1UhCb3GusajqbWo6kMeYGscR6LrE5lZjlh\nbCZbV9TQORjJOUTGUlYe8nPzztacxSrna9OyalZcVbak3jiWutPdE0ymqykv/HWXaeZfagtuFkNm\nKZdNy+bXWL/UhAN+Wqr99NjkFGJZ6Oz4QnMmMrPqC3lw8TO1dEYiC+ZY7xjHB8a5fEOjd/xBSH0T\neunEEN3pKcbzl1fzyqmRnMUId7fVM5IOZZl1n644r2lalSu7EnbR6jo6BsaL3gQNqYrCr085QPRS\nty7PCtrzpTAmi6V2HoFsTUMF5SE/u9bWz73xWc7nszn37jubZE/dnQs9pXN5z6Wrae8bX1Jf3hTI\nzjEHTw1704zjsfiUY9NNTj+21pfzaxeu4NcuTB3vz+8zasoCXqhyznFiMMLQeGzO6s6157cU4ZGI\nyFIwn+P9VYQCfOIN05cnkaUvHPCzqr583ktpnK1W1JbPa9mVUlAgO0ecHBynfzSWMxWZWWS0PORn\n74ZGxiYSPHW0n4l4ks1Ze1/l64EwMz6wZw3H+8fzLronshR9+Ip109bakjOTWQ7kTKbd5ezwrt2r\n595IikaB7CzUNRxh/8nUCvj37Ovims3N3oKr+YT8Pm+vxkvbGhidmH48sHzCAX/OKuQiS11tRZBa\nNL270PItyisiC0uB7CwzGo3z3cfaSTrnLcb6rawDB0OqCXdoPEYo4GNVfTk7V0/2c/h8pn4kERGR\nJebc35XiHOKc40jvaE4TfsblGxq9psxMD0DAZ9x0UWvOQbtFRERk6VGFbAkbGJvgwYM9vGnLMn75\nSje9o1H8ZpSH/Fx5XhP37u8ikXTUVQS5bF0De9Y3MjYRJ+T3caRnlCs3Fn48PxEREVk8CmRL2P95\n9gR9oxOYwcFTI0BqQdQrz2tiW2tt3sP7ZFaN/tDetlIOVURERM6AAtkSEEsk8Znh9xnJpKOjf5y6\nyiB9oxPAZBhbVV/OjTtWnhWre4uIiEjhFMiWgL+/9xBrGyvYu6GJl04M8nzH4LRtzFLHilQYExER\nOfcokC2yzAFqj/aOcbT32LTLf+uS1fjNWK41gERERM5ZCmSLrH9sYsbLNrRU0VqnRVlFRETOdQpk\ni6hnJOodZzIc9LFleQ3VZQGaq8OsbTzz4x+KiIjI2UGBbJE45/iP504QjSVprArxgcvW4ltCBzkV\nERGR0lEgWySD4zH6x2JctLqOyzc0KoyJiIi8jmml/kUwOB7jJy92AnDR6jrtOSkiIvI6pwpZifWM\nRPnWI0cxg7dcsJz6ytBiD0lEREQWmQJZCT16uJdHXu0FYHlNGVtX1izyiERERGQpUCArMucc9+zr\noros4IWx1rpy3nzBskUemYiIiCwVCmRFFo0nefF4auX9sqCfD1/ZRjignjERERGZpKb+IhuKxLyf\nm6vDCmMiIiIyjSpkRTYSiQOwvrmSy9c3LvJoREREZClSICuy9v5xAN54fgvVZcFFHo2IiIgsRQpk\nReKc46cvdrK/cxgzqAzpqRYREZH81ENWJP1jMfZ3DgNw/dZlWolfREREZqRAViSdgxHv503Lqhdx\nJCIiIrLUaR6tCNr7xrjvQBd+n/HBPWsJ+pV7RUREZGYKZAtsJBrnh08fJ+kcV21s0qGRREREZE4K\nZAvsWO8YSed41+5VtNaVL/ZwRERE5CygubQFlEg6njzaR3VZgNa6cszUyC8iIiJzUyBbQIe6Rugd\nmeCazS0KYyIiIlIwBbIFdKhrhKpwgA3NlYs9FBERETmLKJAtEOccJwbGWVWvqUoRERGZHwWyBdI/\nFmMkGmelGvlFRERknrSX5RmKxhP825MdJJIOs9RBxEVERETmQ4HsDJ0ajNI9HAVg8/JqHUBcRERE\n5k1TlmdoPJbwfr5odd0ijkRERETOVgpkZ2goEvN+rq/QqvwiIiIyfwpkZyAaT/DQwR7vdFlQT6eI\niIjMn3rIzkDXUKp3bGVdGZe0NWi5CxERETktCmRnYGAsNV15w7YV1JarmV9EREROj+bYzsDhnhEC\nPqM6rFwrIiIip0+B7DSdGopwuHuUxqowPp+mKkVEROT0KZCdpsPdowDcdNHKRR6JiIiInO0UyE7T\nqaEITdVhKjVdKSIiImdIgew0DUfj1JQpjImIiMiZUyA7TSORONUKZCIiIrIAlCjmyTnH/a90E4kl\nqAprqQsRERE5c6qQzdOpoSjPHhsAIBzQ0yciIiJnTolinrqHU6vzX9LWwPkrqhd5NCIiInIu0JTl\nPPWMRAkFfFxxXqMOlSQiIiILQhWyeeoeidJcFVYYExERkQWjQDYPzjl6RqI0VYcWeygiIiJyDlEg\nm4fhaJxoLElTVXixhyIiIiLnEAWyeehJN/QrkImIiMhCKmogM7MbzOyAmR0ys8/nufx/mdmz6X+v\nmNlAMcdzpnpGJgBorNKUpYiIiCycou1laWZ+4MvA9UAH8ISZ3eWcezmzjXPuD7O2/z1gZ7HGsxB6\nRqLUlgcJB/yLPRQRERE5hxSzQnYpcMg5d9g5NwHcDtw0y/bvBb5bxPGcsVRDv6YrRUREZGEVM5C1\nAu1ZpzvS501jZmuBdcC9RRzPGYknkvSNTtCk6UoRERFZYEulqf89wA+cc4l8F5rZx8zsSTN7sru7\nu8RDS+kbncA5NfSLiIjIwitmIDsOrM46vSp9Xj7vYZbpSufcbc653c653c3NzQs4xMKNROMAVJfp\n4AYiIiKysIoZyJ4ANprZOjMLkQpdd03dyMzOB+qBR4o4ljM2NpEq3lWEFMhERERkYRUtkDnn4sCn\ngZ8B+4DvO+deMrO/MLO3Z236HuB255wr1lgWwmQg0x6WIiIisrCKWu5xzv0Y+PGU8/58yukvFHMM\nC2V0Ik4o4CPoXyptdyIiInKuULoo0PhEgkpVx0RERKQIFMgKNBqNq39MREREikKBrEBjEwkqwqqQ\niYiIyMJTICvQ2ERCDf0iIiJSFApkBUgkHZFYQlOWIiIiUhQKZAUYm0gtCqsKmYiIiBSDAlkBtCis\niIiIFJMCWQEyh02qCiuQiYiIyMJTICvAcETHsRQREZHiUSArwHAkRsBn6iETERGRolAgK8BwJE51\nWQAzW+yhiIiIyDlIgawAI9E4leofExERkSJRICtANJagLKjpShERESkOBbICRONJwgE9VSIiIlIc\nShkFiKhCJiIiIkWkQDaHRNIRSzhVyERERKRolDLmEI2nVukPq0ImIiIiRaJANodILAlAWVBPlYiI\niBSHUsYcvApZQBUyERERKQ4FsjlMxFMVspB6yERERKRIlDLmEEukA5lfT5WIiIgUh1LGHCbiDlAg\nExERkeJRyphDpkIWDOg4liIiIlIcCmRz8AKZKmQiIiJSJEoZc5hIJDGDgE8VMhERESkOBbI5xBKO\noN+HmQKZiIiIFIcC2Rxi8aQa+kVERKSolDTmEEskCfpVHRMREZHiUSCbw0QiSUAVMhERESkiJY05\nxBJOU5YiIiJSVEoac4glklqDTERERIpKgWwOqR4yPU0iIiJSPEoac5iIK5CJiIhIcSlpzEE9ZCIi\nIlJsShpz0JSliIiIFJuSxiwSSUci6bQOmYiIiBSVAtksvAOLB/Q0iYiISPEoacxiIh3I1EMmIiIi\nxaSkMYtYPF0hUyATERGRIlLSmEUs4QDUQyYiIiJFpUA2C6+HTBUyERERKSIljVkokImIiEgpKGnM\nIpFMTVn6fZqyFBERkeJRIJtFPB3IAgpkIiIiUkQKZLPwKmRq6hcREZEiUiCbhddD5tPTJCIiIsWj\npDEL9ZCJiIhIKSiQzUI9ZCIiIlIKCmSzSCQdPjN8CmQiIiJSRApks4gnHQE19IuIiEiRKZDNIp5I\narpSREREik6BbBbxpFNDv4iIiBSdAtksEkmnCpmIiIgUnQLZLOJJh1/HsRQREZEiU9qYRSKpHjIR\nEREpPgWyWcQSmrIUERGR4lMgm0VCTf0iIiJSAgpks1AgExERkVJQIJtFai9LPUUiIiJSXEobs0hV\nyBZ7FCIiInKuU9yYRSqQ6SkSERGR4ipq2jCzG8zsgJkdMrPPz7DNb5nZy2b2kpl9p5jjma+4KmQi\nIiJSAoFi3bCZ+YEvA9cDHcATZnaXc+7lrG02An8MXOGc6zezlmKN53QknSpkIiIiUnzFTBuXAoec\nc4edcxPA7cBNU7b5KPBl51w/gHOuq4jjmbe41iETERGREihmIGsF2rNOd6TPy7YJ2GRmvzKzR83s\nhiKOZ16ccySdw2cKZCIiIlJcRZuynMf9bwSuAVYBD5jZhc65geyNzOxjwMcA1qxZU5KBxZMuNUC/\nApmIiIgUVzErZMeB1VmnV6XPy9YB3OWciznnXgNeIRXQcjjnbnPO7XbO7W5ubi7agLMl0oFMFTIR\nEREptmIGsieAjWa2zsxCwHuAu6Zs8yNS1THMrInUFObhIo6pYJlAph4yERERKbaiBTLnXBz4NPAz\nYB/wfefcS2b2F2b29vRmPwN6zexl4D7gvzjneos1pvnITFnq0EkiIiJSbEXtIXPO/Rj48ZTz/jzr\nZwf8X+l/S0pSgUxERERKRItszSCuKUsREREpEQWyGSRduqlfgUxERESKTIFsBqqQiYiISKkokM0g\nkdCyFyIiIlIaCmQzSDgtDCsiIiKloUA2g0QyCWgvSxERESk+BbIZJFJ5DL+mLEVERKTIFMhmEE9X\nyAI+PUUiIiJSXEobM0jnMZTHREREpNgUN2agCpmIiIiUitLGDBI6dJKIiIiUiALZDBTIREREpFQU\nyGaQSDrMQHlMREREik2BbAYJ5/CbYVr2QkRERIpMgWwG8aTDr1X6RUREpAQUyGaQTDotCisiIiIl\noUA2g3jSqaFfRERESkKBbAaJpCOgQCYiIiIloEA2g4QqZCIiIlIiCmQzSAUyPT0iIiJSfEocM0gF\nssUehYiIiLweKHLMQBUyERERKRUljhkknCpkIiIiUhqKHDNIOodP65CJiIhICSiQzSDpUCATERGR\nklAgm4FThUxERERKpKBAZmY/NLO3mtnrJsAlkw7lMRERESmFQgPWPwDvAw6a2V+b2eYijmlJSE1Z\nLvYoRERE5PWgoEDmnLvHOfd+4GLgCHCPmT1sZreaWbCYA1wsSecwlchERESkBAqegjSzRuAW4CPA\nM8DfkgpodxdlZIvMqalfRERESiRQyEZmdiewGfgWcKNz7mT6ou+Z2ZPFGtxiSi17sdijEBERkdeD\nggIZ8HfOufvyXeCc272A41kytOyFiIiIlEqhU5Zbzawuc8LM6s3sU0Ua05KQ6iFb7FGIiIjI60Gh\ngeyjzrmBzAnnXD/w0eIMaelQhUxERERKodBA5resXQ7NzA+EijOkpSGZ1MKwIiIiUhqF9pD9lFQD\n/1fSpz+ePu+cpXXIREREpFQKDWT/lVQI+2T69N3APxdlREuAc07rkImIiEjJFBTInHNJ4B/T/855\nzqX+Vx4TERGRUih0HbKNwP8LbAXKMuc759YXaVyLKplOZOohExERkVIotKn/a6SqY3HgWuCbwLeL\nNajFlkxXyNRDJiIiIqVQaCArd879AjDn3FHn3BeAtxZvWIsrUyFTD5mIiIiUQqFN/VEz8wEHzezT\nwHGgqnjDWlxOFTIREREpoUIrZJ8BKoDfB3YBHwA+VKxBLTb1kImIiEgpzVkhSy8C+27n3GeBEeDW\noo9qkSmQiYiISCnNWSFzziWAK0swliUjPWOpZS9ERESkJArtIXvGzO4C/g0YzZzpnPthUUa1yFwy\n9b8qZCIiIlIKhQayMqAXeGPWeQ44JwOZN2VZaIediIiIyBkodKX+c75vLJt6yERERKSUCl2p/2tM\ntlZ5nHMfXvARLQGZhWEVx0RERKQUCp2y/I+sn8uAdwAnFn44S4PTwrAiIiJSQoVOWd6RfdrMvgs8\nVJQRLQE6dJKIiIiU0um2rW8EWhZyIEuJeshERESklArtIRsmt4esE/ivRRnREqBAJiIiIqVU6JRl\ndbEHspRkjmWpPCYiIiKlUNCUpZm9w8xqs07XmdnNxRvW4ppch0yJTERERIqv0B6y/+acG8yccM4N\nAP+tOENafE5N/SIiIlJChQayfNsVumTGWSdTITOtRCYiIiIlUGgge9LM/sbMNqT//Q3wVDEHtpgy\ney+oQiYiIiKlUGgg+z1gAvgecDsQAX63WINabJkpSxXIREREpBQK3ctyFPh8kceyZDhNWYqIiEgJ\nFbqX5d1mVpd1ut7Mfla8YS0ur0CmPCYiIiIlUOiUZVN6z0oAnHP9FLBSv5ndYGYHzOyQmU2rsJnZ\nLWbWbWbPpv99pPChF4/TwcVFRESkhArdUzJpZmucc8cAzKyN3JX7pzEzP/Bl4HqgA3jCzO5yzr08\nZdPvOec+Pa9RF5lDBxcXERGR0ik0kP3fwENm9ktShaOrgI/NcZ1LgUPOucMAZnY7cBMwNZAtOaqQ\niYiISCkVNGXpnPspsBs4AHwX+CNgfI6rtQLtWac70udN9Rtm9ryZ/cDMVhcynmLToZNERESklAo9\nuPhHgM8Aq4BngT3AI8Abz/D+/x34rnMuamYfB76R7zbN7GOkK3Jr1qw5w7ucmzdlqRqZiIiIlECh\nTf2fAS4BjjrnrgV2AgOzX4XjQHbFa1X6PI9zrtc5F02f/GdgV74bcs7d5pzb7Zzb3dzcXOCQT5/W\nIRMREZFSKjSQRZxzEQAzCzvn9gOb57jOE8BGM1tnZiHgPcBd2RuY2Yqsk28H9hU4npLQlKWIiIiU\nQqFN/R3pdch+BNxtZv3A0dmu4JyLm9mngZ8BfuCrzrmXzOwvgCedc3cBv29mbwfiQB9wy2k+jgWl\npn4REREppUJX6n9H+scvmNl9QC3w0wKu92Pgx1PO+/Osn/8Y+OOCR1siWvZCRERESqnQCpnHOffL\nYgxkKVGFTEREREqp0B6y1xUdOklERERKSYEsj8zBxX1KZCIiIlICCmR5zHpMKBEREZEFpkCWh1bq\nFxERkVJSIMtLK/WLiIhI6SiQ5aEKmYiIiJSSAlkeOnKSiIiIlJICWR6TFTJFMhERESk+BbI8Mste\nKI6JiIhIKSiQ5aGFYUVERKSUFMjycFqITEREREpIgSwP5xxm6iETERGR0lAgy8OhNchERESkdBTI\n8nBO/WMiIiJSOgpkeTic6mMiIiJSMgpkeahCJiIiIqWkQJaHQw39IiIiUjoKZHk4rXshIiIiJaRA\nlkeqQrbYoxAREZHXCwWyfJyWvRAREZHSUSDLw+FUIRMREZGSUSDLwzkdWFxERERKR4EsDy17ISIi\nIqWkQJaHA3xKZCIiIlIiCmR5aNkLERERKSUFsjy0MKyIiIiUkgJZHmrqFxERkVJSIMtLy16IiIhI\n6SiQ5aEKmYiIiJSSAsdgtT4AAA5mSURBVFke6iETERGRUlIgy0PrkImIiEgpKZDl4XCashQREZGS\nUSDLw6XmLBd7GCIiIvI6oUCWR9KpQiYiIiKlo0A2AxXIREREpFQUyPJILXuhRCYiIiKloUCWh9PC\nsCIiIlJCCmR5aGFYERERKSUFsjy0DpmIiIiUkgJZHg71kImIiEjpKJDl4TRnKSIiIiWkQJZHqkIm\nIiIiUhoKZPk4HVxcRERESkeBLA8dy1JERERKSYEsD+1lKSIiIqWkQJaHji0uIiIipaRAlodz4FMi\nExERkRJRIMvD4RZ7CCIiIvI6okCWh1MeExERkRJSIMsj1UOmKUsREREpDQUyERERkUWmQJaP0zpk\nIiIiUjoKZCIiIiKLTIEsD61DJiIiIqWkQCYiIiKyyBTI8nAOTF1kIiIiUiIKZCIiIiKLTIEsD+ec\neshERESkZBTIRERERBaZAlkeDtRBJiIiIiVT1EBmZjeY2QEzO2Rmn59lu98wM2dmu4s5HhEREZGl\nqGiBzMz8wJeBXwO2Au81s615tqsGPgM8VqyxzJdzWodMRERESqeYFbJLgUPOucPOuQngduCmPNv9\nJfA/gEgRxyIiIiKyZBUzkLUC7VmnO9LneczsYmC1c+4/iziOeXOAushERESkVBatqd/MfMDfAH9U\nwLYfM7MnzezJ7u7u4g9OREREpISKGciOw//f3v3H7F7WdQB/fzxHQNSBxMkZPwSVVWSJxpCyGlNn\nmg74gwpTY2RjbbqwH0ttpsvNP2pNq8VMpygWiUZYzLGMyCj/AEEhFdHBSAWnQoH4oyWin/64v8/h\nOXfPmRw89/e6Oc/rtZ2d53vd393P9dzXrue8z/X9fK9vjtl0fPTUtuGxSZ6a5F+r6nNJTk1y+VaF\n/d399u4+ubtP3rVr1wq7vPv7qSEDAGazykB2XZITqur4qjooydlJLt94sbvv7e4ju/u47j4uyTVJ\nTu/u61fYJwCAtbOyQNbd9yd5ZZIPJbk5yfu7+6aqemNVnb6q77u/WCADAOayc5Vv3t1XJLliqe31\nezn3tFX2BQBgXdmpfwuLfciskQEA8xDIAAAGE8i20Gk1ZADAbAQyAIDBBLIteJYlADAngQwAYDCB\nbAsdK2QAwHwEsi10J6WsHwCYiUAGADCYQLaFTnt2EgAwG4EMAGAwgWwLbYEMAJiRQAYAMJhAthce\nLg4AzEUgAwAYTCDbQreHiwMA8xHIAAAGE8i24OHiAMCcBDIAgMEEsi10PMsSAJiPQAYAMJhAtgU1\nZADAnAQyAIDBBLItdOxDBgDMRyADABhMINtCL26zBACYhUAGADCYQLaku5PYhwwAmI9ABgAwmEC2\nZFogsw8ZADAbgQwAYDCBbMm0QKaCDACYjUAGADCYQLZk912WisgAgJkIZAAAgwlkS3bXkFkgAwBm\nIpDthTwGAMxFIFuysQ8ZAMBcBLIlnY2i/sEdAQC2DYEMAGAwgWzJA5csLZEBAPMQyAAABhPI9kIN\nGQAwF4EMAGAwgWzJRg2ZBTIAYC4CGQDAYALZkgf2IbNGBgDMQyADABhMIFuihgwAmJtABgAwmEC2\nZGOjfiVkAMBcBDIAgMEEsiU9FZGVKjIAYCYCGQDAYALZEjVkAMDcBDIAgMEEsiUb+5ABAMxFIAMA\nGEwgW7axU78aMgBgJgIZAMBgAtmSjn3IAIB5CWQAAIOtNJBV1fOr6rNVdWtVvWaL13+jqj5ZVTdW\n1Ueq6sRV9ufBaDVkAMDMVhbIqmpHkguSvCDJiUlevEXg+pvu/vHuPinJHyd586r6AwCwrla5QnZK\nklu7+7buvi/JJUnO2HxCd39t0+Gj88BG+cPYqR8AmNvOFb73UUlu33R8R5JnLp9UVa9I8ttJDkry\n7K3eqKrOS3Jekhx77LH7vaMAACMNL+rv7gu6+8lJXp3kdXs55+3dfXJ3n7xr165V9yeJuywBgPms\nMpB9Mckxm46Pntr25pIkZ66wP/vEJUsAYC6rDGTXJTmhqo6vqoOSnJ3k8s0nVNUJmw5fmOSWFfbn\nQRlexAYAbDsrqyHr7vur6pVJPpRkR5ILu/umqnpjkuu7+/Ikr6yq5yb5dpJ7kpyzqv48WLu3vRjb\nDQBgG1llUX+6+4okVyy1vX7T1+ev8vsDADwcDC/qXze7H51kiQwAmIlABgAwmEC2bHdVvyUyAGAe\nAhkAwGAC2RKPTgIA5iaQAQAMJpAtsQ8ZADA3gQwAYDCBbMkD+5BZIwMA5iGQAQAMJpAtUUMGAMxN\nIAMAGEwgW2IfMgBgbgIZAMBgAtmSnorIShUZADATgQwAYDCBbMnuuywtkAEAMxHIAAAGE8gAAAYT\nyAAABhPIlqghAwDmJpABAAwmkC3paa/+skQGAMxEIAMAGEwgW7K7hmxsNwCAbUQgAwAYTCBbMi2Q\nucsSAJiNQLYXHi4OAMxFIFvSG0VkAAAzEciWuGQJAMxNIAMAGEwgW2LbCwBgbgIZAMBgAtmSg3c+\nIk847JA8coePBgCYx87RHVg3xxxxaM4+5djR3QAAthHLQAAAgwlkAACDCWQAAIMJZAAAgwlkAACD\nCWQAAIMJZAAAgwlkAACDCWQAAIMJZAAAgwlkAACDCWQAAIMJZAAAgwlkAACDCWQAAIMJZAAAgwlk\nAACDCWQAAINVd4/uwz6pqruSfH7F3+bIJP+14u/BvjMu68m4rB9jsp6My/qZY0ye2N27vtdJD7tA\nNoequr67Tx7dD/ZkXNaTcVk/xmQ9GZf1s05j4pIlAMBgAhkAwGAC2dbeProDbMm4rCfjsn6MyXoy\nLutnbcZEDRkAwGBWyAAABhPIllTV86vqs1V1a1W9ZnR/touqOqaqPlxVn66qm6rq/Kn9iKq6sqpu\nmf5+3NReVfXn0zh9oqqeMfYnOLBV1Y6quqGqPjgdH19V106f//uq6qCp/eDp+Nbp9eNG9vtAVVWH\nV9WlVfWZqrq5qn7KXBmvqn5r+v31qap6b1UdYq7Mr6ourKo7q+pTm9r2eX5U1TnT+bdU1Tmr7rdA\ntklV7UhyQZIXJDkxyYur6sSxvdo27k/yO919YpJTk7xi+uxfk+Sq7j4hyVXTcbIYoxOmP+cleev8\nXd5Wzk9y86bjP0rylu5+SpJ7krx8an95knum9rdM57H//VmSf+zuH0nytCzGxlwZqKqOSvKbSU7u\n7qcm2ZHk7JgrI7w7yfOX2vZpflTVEUnekOSZSU5J8oaNELcqAtmeTklya3ff1t33JbkkyRmD+7Qt\ndPeXuvvj09dfz+IfmKOy+Pwvmk67KMmZ09dnJHlPL1yT5PCqesLM3d4WquroJC9M8o7puJI8O8ml\n0ynL47IxXpcmec50PvtJVR2W5OeSvDNJuvu+7v5qzJV1sDPJo6pqZ5JDk3wp5srsuvvfkty91Lyv\n8+Pnk1zZ3Xd39z1Jrsz/D3n7lUC2p6OS3L7p+I6pjRlNS/dPT3Jtksd395eml76c5PHT18ZqPn+a\n5PeSfHc6/oEkX+3u+6fjzZ/97nGZXr93Op/95/gkdyV513QZ+R1V9eiYK0N19xeT/EmSL2QRxO5N\n8rGYK+tiX+fH7PNGIGOtVNVjkvxdkld199c2v9aLW4LdFjyjqnpRkju7+2Oj+8JuO5M8I8lbu/vp\nSb6ZBy6/JDFXRpguZ52RRWD+oSSPzopXVHho1nV+CGR7+mKSYzYdHz21MYOqemQWYezi7r5sav7K\nxuWV6e87p3ZjNY9nJTm9qj6XxSX8Z2dRv3T4dFkm2fOz3z0u0+uHJfnvOTu8DdyR5I7uvnY6vjSL\ngGaujPXcJP/Z3Xd197eTXJbF/DFX1sO+zo/Z541Atqfrkpww3RVzUBYFmZcP7tO2MNVOvDPJzd39\n5k0vXZ5k4+6Wc5L8w6b2X53ukDk1yb2blqPZT7r7td19dHcfl8V8+JfufkmSDyc5azpteVw2xuus\n6fy1+5/ow1l3fznJ7VX1w1PTc5J8OubKaF9IcmpVHTr9PtsYF3NlPezr/PhQkudV1eOm1c/nTW0r\nY2PYJVX1C1nUzOxIcmF3v2lwl7aFqvqZJP+e5JN5oFbp97OoI3t/kmOTfD7JL3X33dMvvL/I4pLA\n/yQ5t7uvn73j20hVnZbkd7v7RVX1pCxWzI5IckOSl3b3t6rqkCR/lUUN4N1Jzu7u20b1+UBVVSdl\ncZPFQUluS3JuFv/BNlcGqqo/TPLLWdw1fkOSX8+i7shcmVFVvTfJaUmOTPKVLO6W/Pvs4/yoql/L\n4t+hJHlTd79rpf0WyAAAxnLJEgBgMIEMAGAwgQwAYDCBDABgMIEMAGAwgQzgQaiq06rqg6P7ARyY\nBDIAgMEEMuCAUlUvraqPVtWNVfW2qtpRVd+oqrdU1U1VdVVV7ZrOPamqrqmqT1TVB6YduVNVT6mq\nf66q/6iqj1fVk6e3f0xVXVpVn6mqi6dNJQG+bwIZcMCoqh/NYqf0Z3X3SUm+k+QlWTzo+fru/rEk\nV2exc3eSvCfJq7v7J7J4SsRG+8VJLujupyX56SQbjxp6epJXJTkxyZOyeFYhwPdt5/c+BeBh4zlJ\nfjLJddPi1aOyeIjwd5O8bzrnr5NcVlWHJTm8u6+e2i9K8rdV9dgkR3X3B5Kku/83Sab3+2h33zEd\n35jkuCQfWf2PBRzoBDLgQFJJLuru1+7RWPUHS+c91GfGfWvT19+J36HAfuKSJXAguSrJWVX1g0lS\nVUdU1ROz+F131nTOryT5SHffm+SeqvrZqf1lSa7u7q8nuaOqzpze4+CqOnTWnwLYdvzvDjhgdPen\nq+p1Sf6pqh6R5NtJXpHkm0lOmV67M4s6syQ5J8lfToHrtiTnTu0vS/K2qnrj9B6/OOOPAWxD1f1Q\nV+4BHh6q6hvd/ZjR/QDYG5csAQAGs0IGADCYFTIAgMEEMgCAwQQyAIDBBDIAgMEEMgCAwQQyAIDB\n/g/kZmY3kiaYmAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 720x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zv_3xNMjzdLI"
      },
      "source": [
        "## Stretch Goals:\n",
        "\n",
        "- Use Hyperparameter Tuning to make the accuracy of your models as high as possible. (error as low as possible)\n",
        "- Use Cross Validation techniques to get more consistent results with your model.\n",
        "- Use GridSearchCV to try different combinations of hyperparameters. \n",
        "- Start looking into other types of Keras layers for CNNs and RNNs maybe try and build a CNN model for fashion-MNIST to see how the results compare."
      ]
    }
  ]
}