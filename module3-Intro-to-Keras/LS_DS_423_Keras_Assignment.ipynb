{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LS_DS_433_Keras_Assignment.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pBQsZEJmubLs"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "\n",
        "# Neural Network Framework (Keras)\n",
        "\n",
        "## *Data Science Unit 4 Sprint 2 Assignment 3*\n",
        "\n",
        "## Use the Keras Library to build a Multi-Layer Perceptron Model on the Boston Housing dataset\n",
        "\n",
        "- The Boston Housing dataset comes with the Keras library so use Keras to import it into your notebook. \n",
        "- Normalize the data (all features should have roughly the same scale)\n",
        "- Import the type of model and layers that you will need from Keras.\n",
        "- Instantiate a model object and use `model.add()` to add layers to your model\n",
        "- Since this is a regression model you will have a single output node in the final layer.\n",
        "- Use activation functions that are appropriate for this task\n",
        "- Compile your model\n",
        "- Fit your model and report its accuracy in terms of Mean Squared Error\n",
        "- Use the history object that is returned from model.fit to make graphs of the model's loss or train/validation accuracies by epoch. \n",
        "- Run this same data through a linear regression model. Which achieves higher accuracy?\n",
        "- Do a little bit of feature engineering and see how that affects your neural network model. (you will need to change your model to accept more inputs)\n",
        "- After feature engineering, which model sees a greater accuracy boost due to the new features?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8NLTAR87uYJ-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "068800f8-3243-4ce3-fdcd-127a79f865ee"
      },
      "source": [
        "##### Your Code Here #####\n",
        "\n",
        "#from tensorflow.keras.datasets import Boston - didn't work\n",
        "#Import libraries\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import boston_housing\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Found this to break out into train/test from inception\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = boston_housing.load_data()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
            "57344/57026 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8F6sf4sdf35",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d85208e5-54ff-4e74-e02a-2afa93cbfc97"
      },
      "source": [
        "#Taking a look at the shape of the data\n",
        "\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((404, 13), (102, 13), (404,), (102,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbIdDLpQdgA4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "395b8429-1262-4aa6-d7d6-5c5b0e6803da"
      },
      "source": [
        "#create the model\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim = 13, activation = 'relu'))\n",
        "model.add(Dense(1, activation = \"sigmoid\"))\n",
        "\n",
        "#taking a look at the summary of the model\n",
        "model.summary()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_2 (Dense)              (None, 12)                168       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 13        \n",
            "=================================================================\n",
            "Total params: 181\n",
            "Trainable params: 181\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZyyNtfUdgDp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#compile\n",
        "\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URbOs8xBdgGA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create EarlyStopping to help avoid overfitting\n",
        "\n",
        "stop = EarlyStopping(monitor='val_loss', min_delta=0.01, patience=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8qKOmtWdgIZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "68c7ee99-4e53-4acd-f58d-0563afcb1f7e"
      },
      "source": [
        "#Fit the model\n",
        "\n",
        "model.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test), callbacks=[stop])\n",
        "\n",
        "#not sure why I am getting these numbers?"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 544.0403 - val_loss: 652.2457\n",
            "Epoch 2/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 547.4968 - val_loss: 652.2457\n",
            "Epoch 3/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 538.8947 - val_loss: 652.2457\n",
            "Epoch 4/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 543.5858 - val_loss: 652.2457\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f24f44a5ba8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCewG51SdgKo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SfcFnOONyuNm"
      },
      "source": [
        "## Use the Keras Library to build an image recognition network using the Fashion-MNIST dataset (also comes with keras)\n",
        "\n",
        "- Load and preprocess the image data similar to how we preprocessed the MNIST data in class.\n",
        "- Make sure to one-hot encode your category labels\n",
        "- The number of nodes in your output layer should equal the number of classes you want to predict for Fashion-MNIST.\n",
        "- Try different hyperparameters. What is the highest accuracy that you are able to achieve.\n",
        "- Use the history object that is returned from model.fit to make graphs of the model's loss or train/validation accuracies by epoch. \n",
        "- Remember that neural networks fall prey to randomness so you may need to run your model multiple times (or use Cross Validation) in order to tell if a change to a hyperparameter is truly producing better results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_EwBEfTdfNh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "23fe3e07-9954-48d8-bdbd-70f2c3c1c242"
      },
      "source": [
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "\n",
        "#use the same code from before to break into train/test\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "szi6-IpuzaH1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "26238d4b-c1cf-439c-bd81-1d1d06ca5cff"
      },
      "source": [
        "#looking at the shape\n",
        "\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28), (10000, 28, 28), (60000,), (10000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8nLPTz2epuL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#define model\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(28,28)))\n",
        "model.add(Dense(1280, activation='relu'))\n",
        "model.add(Dense(20, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RilmbbOFfGHm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "731b3acf-9529-4aba-d238-c17d88184beb"
      },
      "source": [
        "#summary of the model\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1280)              1004800   \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 20)                25620     \n",
            "=================================================================\n",
            "Total params: 1,030,420\n",
            "Trainable params: 1,030,420\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EG6u5E3Aep0I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#compile\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAlImUT2ep5h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#EarlyStopping\n",
        "\n",
        "stop = EarlyStopping(monitor='val_accuracy', min_delta=0.01, patience=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lMSsTTPep8J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "1aa6104e-d606-489c-8ee9-30e72b8b0b5d"
      },
      "source": [
        "#fit the model\n",
        "\n",
        "model.fit(X_train, y_train, epochs = 100, validation_data=(X_test, y_test), callbacks=[stop])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1875/1875 [==============================] - 16s 9ms/step - loss: 7.0850 - accuracy: 0.7786 - val_loss: 0.6096 - val_accuracy: 0.8020\n",
            "Epoch 2/100\n",
            "1875/1875 [==============================] - 16s 9ms/step - loss: 0.5336 - accuracy: 0.8201 - val_loss: 0.8189 - val_accuracy: 0.7478\n",
            "Epoch 3/100\n",
            "1875/1875 [==============================] - 16s 9ms/step - loss: 0.5266 - accuracy: 0.8269 - val_loss: 0.5806 - val_accuracy: 0.8012\n",
            "Epoch 4/100\n",
            "1875/1875 [==============================] - 16s 8ms/step - loss: 0.5021 - accuracy: 0.8348 - val_loss: 0.5999 - val_accuracy: 0.8163\n",
            "Epoch 5/100\n",
            "1875/1875 [==============================] - 16s 9ms/step - loss: 0.4934 - accuracy: 0.8392 - val_loss: 0.5574 - val_accuracy: 0.8209\n",
            "Epoch 6/100\n",
            "1875/1875 [==============================] - 16s 8ms/step - loss: 0.4645 - accuracy: 0.8436 - val_loss: 0.5430 - val_accuracy: 0.8155\n",
            "Epoch 7/100\n",
            "1875/1875 [==============================] - 16s 8ms/step - loss: 0.4627 - accuracy: 0.8460 - val_loss: 0.5344 - val_accuracy: 0.8335\n",
            "Epoch 8/100\n",
            "1875/1875 [==============================] - 16s 8ms/step - loss: 0.4568 - accuracy: 0.8475 - val_loss: 0.5065 - val_accuracy: 0.8354\n",
            "Epoch 9/100\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.4543 - accuracy: 0.8483 - val_loss: 0.5018 - val_accuracy: 0.8403\n",
            "Epoch 10/100\n",
            "1875/1875 [==============================] - 16s 8ms/step - loss: 0.4339 - accuracy: 0.8524 - val_loss: 0.5400 - val_accuracy: 0.8307\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f24f4d106d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFjzrY7Jep-w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "85f19106-3c86-411a-9e6e-28945bb837e2"
      },
      "source": [
        "#Can we see a visual?\n",
        "\n",
        "plt.imshow(X_train[7])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f24f3b2dc50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kl74ZDtIeqA5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zv_3xNMjzdLI"
      },
      "source": [
        "## Stretch Goals:\n",
        "\n",
        "- Use Hyperparameter Tuning to make the accuracy of your models as high as possible. (error as low as possible)\n",
        "- Use Cross Validation techniques to get more consistent results with your model.\n",
        "- Use GridSearchCV to try different combinations of hyperparameters. \n",
        "- Start looking into other types of Keras layers for CNNs and RNNs maybe try and build a CNN model for fashion-MNIST to see how the results compare."
      ]
    }
  ]
}