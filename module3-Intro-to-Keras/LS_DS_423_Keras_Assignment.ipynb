{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pBQsZEJmubLs"
   },
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "\n",
    "# Neural Network Framework (Keras)\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2 Assignmnet 3*\n",
    "\n",
    "## Use the Keras Library to build a Multi-Layer Perceptron Model on the Boston Housing dataset\n",
    "\n",
    "- The Boston Housing dataset comes with the Keras library so use Keras to import it into your notebook. \n",
    "- Normalize the data (all features should have roughly the same scale)\n",
    "- Import the type of model and layers that you will need from Keras.\n",
    "- Instantiate a model object and use `model.add()` to add layers to your model\n",
    "- Since this is a regression model you will have a single output node in the final layer.\n",
    "- Use activation functions that are appropriate for this task\n",
    "- Compile your model\n",
    "- Fit your model and report its accuracy in terms of Mean Squared Error\n",
    "- Use the history object that is returned from model.fit to make graphs of the model's loss or train/validation accuracies by epoch. \n",
    "- Run this same data through a linear regression model. Which achieves higher accuracy?\n",
    "- Do a little bit of feature engineering and see how that affects your neural network model. (you will need to change your model to accept more inputs)\n",
    "- After feature engineering, which model sees a greater accuracy boost due to the new features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8NLTAR87uYJ-"
   },
   "outputs": [],
   "source": [
    "# import needed stuff\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data.\n",
    "df = pd.read_csv('amesHousePrice.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass MSZoning  LotFrontage  LotArea Street LotShape LandContour  \\\n",
       "0          60       RL         65.0     8450   Pave      Reg         Lvl   \n",
       "1          20       RL         80.0     9600   Pave      Reg         Lvl   \n",
       "2          60       RL         68.0    11250   Pave      IR1         Lvl   \n",
       "3          70       RL         60.0     9550   Pave      IR1         Lvl   \n",
       "4          60       RL         84.0    14260   Pave      IR1         Lvl   \n",
       "\n",
       "  Utilities LotConfig LandSlope  ... PoolArea PoolQC Fence MiscFeature  \\\n",
       "0    AllPub    Inside       Gtl  ...        0    NaN   NaN         NaN   \n",
       "1    AllPub       FR2       Gtl  ...        0    NaN   NaN         NaN   \n",
       "2    AllPub    Inside       Gtl  ...        0    NaN   NaN         NaN   \n",
       "3    AllPub    Corner       Gtl  ...        0    NaN   NaN         NaN   \n",
       "4    AllPub       FR2       Gtl  ...        0    NaN   NaN         NaN   \n",
       "\n",
       "  MiscVal  MoSold  YrSold  SaleType  SaleCondition SalePrice  \n",
       "0       0       2    2008        WD         Normal    208500  \n",
       "1       0       5    2007        WD         Normal    181500  \n",
       "2       0       9    2008        WD         Normal    223500  \n",
       "3       0       2    2006        WD        Abnorml    140000  \n",
       "4       0      12    2008        WD         Normal    250000  \n",
       "\n",
       "[5 rows x 79 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dropping the ID column\n",
    "df = df.drop('Id', axis=1)\n",
    "df = df.drop('Alley', axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PoolQC           1453\n",
       "MiscFeature      1406\n",
       "Fence            1179\n",
       "FireplaceQu       690\n",
       "LotFrontage       259\n",
       "GarageType         81\n",
       "GarageFinish       81\n",
       "GarageQual         81\n",
       "GarageCond         81\n",
       "GarageYrBlt        81\n",
       "BsmtExposure       38\n",
       "BsmtFinType2       38\n",
       "BsmtQual           37\n",
       "BsmtCond           37\n",
       "BsmtFinType1       37\n",
       "MasVnrArea          8\n",
       "MasVnrType          8\n",
       "Electrical          1\n",
       "RoofStyle           0\n",
       "RoofMatl            0\n",
       "ExterQual           0\n",
       "Exterior1st         0\n",
       "Exterior2nd         0\n",
       "YearBuilt           0\n",
       "ExterCond           0\n",
       "Foundation          0\n",
       "YearRemodAdd        0\n",
       "SalePrice           0\n",
       "OverallCond         0\n",
       "OverallQual         0\n",
       "                 ... \n",
       "GarageArea          0\n",
       "PavedDrive          0\n",
       "WoodDeckSF          0\n",
       "OpenPorchSF         0\n",
       "3SsnPorch           0\n",
       "BsmtUnfSF           0\n",
       "ScreenPorch         0\n",
       "PoolArea            0\n",
       "MiscVal             0\n",
       "MoSold              0\n",
       "YrSold              0\n",
       "SaleType            0\n",
       "Functional          0\n",
       "TotRmsAbvGrd        0\n",
       "KitchenQual         0\n",
       "KitchenAbvGr        0\n",
       "BedroomAbvGr        0\n",
       "HalfBath            0\n",
       "FullBath            0\n",
       "BsmtHalfBath        0\n",
       "BsmtFullBath        0\n",
       "GrLivArea           0\n",
       "LowQualFinSF        0\n",
       "2ndFlrSF            0\n",
       "1stFlrSF            0\n",
       "SaleCondition       0\n",
       "HeatingQC           0\n",
       "Heating             0\n",
       "TotalBsmtSF         0\n",
       "MSSubClass          0\n",
       "Length: 79, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking null values\n",
    "df.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SalePrice       0\n",
       "BsmtQual        0\n",
       "Exterior1st     0\n",
       "Exterior2nd     0\n",
       "MasVnrType      0\n",
       "MasVnrArea      0\n",
       "ExterQual       0\n",
       "ExterCond       0\n",
       "Foundation      0\n",
       "BsmtCond        0\n",
       "RoofStyle       0\n",
       "BsmtExposure    0\n",
       "BsmtFinType1    0\n",
       "BsmtFinSF1      0\n",
       "BsmtFinType2    0\n",
       "BsmtFinSF2      0\n",
       "BsmtUnfSF       0\n",
       "TotalBsmtSF     0\n",
       "RoofMatl        0\n",
       "YearRemodAdd    0\n",
       "HeatingQC       0\n",
       "LotConfig       0\n",
       "MSZoning        0\n",
       "LotFrontage     0\n",
       "LotArea         0\n",
       "Street          0\n",
       "LotShape        0\n",
       "LandContour     0\n",
       "Utilities       0\n",
       "LandSlope       0\n",
       "               ..\n",
       "PoolArea        0\n",
       "GarageCars      0\n",
       "PoolQC          0\n",
       "Fence           0\n",
       "MiscFeature     0\n",
       "MiscVal         0\n",
       "MoSold          0\n",
       "YrSold          0\n",
       "SaleType        0\n",
       "GarageArea      0\n",
       "GarageFinish    0\n",
       "Electrical      0\n",
       "HalfBath        0\n",
       "1stFlrSF        0\n",
       "2ndFlrSF        0\n",
       "LowQualFinSF    0\n",
       "GrLivArea       0\n",
       "BsmtFullBath    0\n",
       "BsmtHalfBath    0\n",
       "FullBath        0\n",
       "BedroomAbvGr    0\n",
       "GarageYrBlt     0\n",
       "KitchenAbvGr    0\n",
       "KitchenQual     0\n",
       "TotRmsAbvGrd    0\n",
       "Functional      0\n",
       "Fireplaces      0\n",
       "FireplaceQu     0\n",
       "GarageType      0\n",
       "MSSubClass      0\n",
       "Length: 79, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# will replace NaN values depending on column type.\n",
    "# if numeric, will replace with 0. Since they're home prices, we'll probably want to replace with mean or median.\n",
    "# but we'll do that before we do any major manipulations\n",
    "# if categorical, will replace with \"Unknown\"\n",
    "\n",
    "df_2 = df.copy()\n",
    "\n",
    "for column in df_2.columns:\n",
    "    if df_2[column].dtype=='O':\n",
    "        df_2[column] = df_2[column].fillna(value='Unknown')\n",
    "    else:\n",
    "        df_2[column] = df_2[column].fillna(value=0)\n",
    "\n",
    "# checking\n",
    "df_2.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>20</td>\n",
       "      <td>FV</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4403</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR2</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>New</td>\n",
       "      <td>Partial</td>\n",
       "      <td>222000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>70.0</td>\n",
       "      <td>8750</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>200500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>80</td>\n",
       "      <td>RL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11333</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>146800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>73.0</td>\n",
       "      <td>9300</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>167500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8885</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Low</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Mod</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>131000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MSSubClass MSZoning  LotFrontage  LotArea Street LotShape LandContour  \\\n",
       "412           20       FV          0.0     4403   Pave      IR2         Lvl   \n",
       "871           60       RL         70.0     8750   Pave      Reg         Lvl   \n",
       "791           80       RL          0.0    11333   Pave      IR1         Lvl   \n",
       "1026          20       RL         73.0     9300   Pave      Reg         Lvl   \n",
       "908           20       RL          0.0     8885   Pave      IR1         Low   \n",
       "\n",
       "     Utilities LotConfig LandSlope  ... PoolArea   PoolQC    Fence  \\\n",
       "412     AllPub    Inside       Gtl  ...        0  Unknown  Unknown   \n",
       "871     AllPub    Inside       Gtl  ...        0  Unknown  Unknown   \n",
       "791     AllPub    Corner       Gtl  ...        0  Unknown  Unknown   \n",
       "1026    AllPub    Inside       Gtl  ...        0  Unknown  Unknown   \n",
       "908     AllPub    Inside       Mod  ...        0  Unknown    MnPrv   \n",
       "\n",
       "     MiscFeature MiscVal  MoSold  YrSold  SaleType  SaleCondition SalePrice  \n",
       "412      Unknown       0       6    2010       New        Partial    222000  \n",
       "871      Unknown       0       6    2010        WD         Normal    200500  \n",
       "791      Unknown       0       5    2007        WD         Normal    146800  \n",
       "1026     Unknown       0       4    2010        WD         Normal    167500  \n",
       "908      Unknown       0       6    2006        WD         Normal    131000  \n",
       "\n",
       "[5 rows x 79 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = train_test_split(df_2)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>...</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>20</td>\n",
       "      <td>FV</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4403</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR2</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>New</td>\n",
       "      <td>Partial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>70.0</td>\n",
       "      <td>8750</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>80</td>\n",
       "      <td>RL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11333</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>73.0</td>\n",
       "      <td>9300</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>143</td>\n",
       "      <td>0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8885</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Low</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Mod</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MSSubClass MSZoning  LotFrontage  LotArea Street LotShape LandContour  \\\n",
       "412           20       FV          0.0     4403   Pave      IR2         Lvl   \n",
       "871           60       RL         70.0     8750   Pave      Reg         Lvl   \n",
       "791           80       RL          0.0    11333   Pave      IR1         Lvl   \n",
       "1026          20       RL         73.0     9300   Pave      Reg         Lvl   \n",
       "908           20       RL          0.0     8885   Pave      IR1         Low   \n",
       "\n",
       "     Utilities LotConfig LandSlope  ... ScreenPorch PoolArea   PoolQC  \\\n",
       "412     AllPub    Inside       Gtl  ...           0        0  Unknown   \n",
       "871     AllPub    Inside       Gtl  ...           0        0  Unknown   \n",
       "791     AllPub    Corner       Gtl  ...           0        0  Unknown   \n",
       "1026    AllPub    Inside       Gtl  ...         143        0  Unknown   \n",
       "908     AllPub    Inside       Mod  ...           0        0  Unknown   \n",
       "\n",
       "        Fence MiscFeature  MiscVal  MoSold  YrSold  SaleType SaleCondition  \n",
       "412   Unknown     Unknown        0       6    2010       New       Partial  \n",
       "871   Unknown     Unknown        0       6    2010        WD        Normal  \n",
       "791   Unknown     Unknown        0       5    2007        WD        Normal  \n",
       "1026  Unknown     Unknown        0       4    2010        WD        Normal  \n",
       "908     MnPrv     Unknown        0       6    2006        WD        Normal  \n",
       "\n",
       "[5 rows x 78 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making X and y sets\n",
    "\n",
    "# training data set\n",
    "y_train = train['SalePrice']\n",
    "X_train = train.drop('SalePrice', axis=1)\n",
    "\n",
    "# test data set\n",
    "y_test = test['SalePrice']\n",
    "X_test = test.drop('SalePrice', axis=1)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# between one-hot encoding and ordinal encoding, ordinal encoding will probably give us a better output\n",
    "# It'll also give us a chance to change all the numeric 0 values to something more helpful (the mean)\n",
    "# We'll do the ordinal encoding, then normalize (squishify) the data\n",
    "\n",
    "# instantiating classes\n",
    "encoder = OrdinalEncoder()\n",
    "normalizer = Normalizer()\n",
    "\n",
    "# encoding then normalizing data\n",
    "X_train_encoded = encoder.fit_transform(X_train)\n",
    "X_train_normalized = normalizer.fit_transform(X_train_encoded)\n",
    "\n",
    "X_test_encoded = encoder.fit_transform(X_test)\n",
    "X_test_normalized = normalizer.fit_transform(X_test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 10)                790       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 1,021\n",
      "Trainable params: 1,021\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# for this model, tried including all dense layers as without the .add method\n",
    "model = Sequential([\n",
    "    Dense(10, input_dim=78, activation='relu'),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(1, activation='relu')\n",
    "])\n",
    "model.compile(loss='mean_squared_error', optimizer='adam',\n",
    "              metrics=['mean_squared_error'])\n",
    "\n",
    "# checking summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1095/1095 [==============================] - 0s 385us/sample - loss: 39796761062.2831 - mean_squared_error: 39796760576.0000\n",
      "Epoch 2/100\n",
      "1095/1095 [==============================] - 0s 97us/sample - loss: 39796589748.4858 - mean_squared_error: 39796588544.0000\n",
      "Epoch 3/100\n",
      "1095/1095 [==============================] - 0s 91us/sample - loss: 39795932503.2037 - mean_squared_error: 39795937280.0000\n",
      "Epoch 4/100\n",
      "1095/1095 [==============================] - 0s 95us/sample - loss: 39794015044.0329 - mean_squared_error: 39794020352.0000\n",
      "Epoch 5/100\n",
      "1095/1095 [==============================] - 0s 91us/sample - loss: 39790075748.7635 - mean_squared_error: 39790075904.0000\n",
      "Epoch 6/100\n",
      "1095/1095 [==============================] - 0s 91us/sample - loss: 39781899696.9790 - mean_squared_error: 39781900288.0000\n",
      "Epoch 7/100\n",
      "1095/1095 [==============================] - 0s 104us/sample - loss: 39766850873.2785 - mean_squared_error: 39766855680.0000\n",
      "Epoch 8/100\n",
      "1095/1095 [==============================] - 0s 101us/sample - loss: 39742026543.4594 - mean_squared_error: 39742025728.0000\n",
      "Epoch 9/100\n",
      "1095/1095 [==============================] - 0s 91us/sample - loss: 39704175312.0731 - mean_squared_error: 39704170496.0000\n",
      "Epoch 10/100\n",
      "1095/1095 [==============================] - 0s 84us/sample - loss: 39649202931.6091 - mean_squared_error: 39649202176.0000\n",
      "Epoch 11/100\n",
      "1095/1095 [==============================] - 0s 102us/sample - loss: 39571146553.7461 - mean_squared_error: 39571152896.0000\n",
      "Epoch 12/100\n",
      "1095/1095 [==============================] - 0s 95us/sample - loss: 39464839181.0922 - mean_squared_error: 39464833024.0000\n",
      "Epoch 13/100\n",
      "1095/1095 [==============================] - 0s 106us/sample - loss: 39325262568.3872 - mean_squared_error: 39325257728.0000\n",
      "Epoch 14/100\n",
      "1095/1095 [==============================] - 0s 102us/sample - loss: 39147176184.7525 - mean_squared_error: 39147180032.0000\n",
      "Epoch 15/100\n",
      "1095/1095 [==============================] - 0s 106us/sample - loss: 38924951379.9306 - mean_squared_error: 38924959744.0000\n",
      "Epoch 16/100\n",
      "1095/1095 [==============================] - 0s 88us/sample - loss: 38651191509.2164 - mean_squared_error: 38651191296.0000\n",
      "Epoch 17/100\n",
      "1095/1095 [==============================] - 0s 91us/sample - loss: 38323641193.4393 - mean_squared_error: 38323634176.0000\n",
      "Epoch 18/100\n",
      "1095/1095 [==============================] - 0s 102us/sample - loss: 37933913118.8603 - mean_squared_error: 37933907968.0000\n",
      "Epoch 19/100\n",
      "1095/1095 [==============================] - 0s 88us/sample - loss: 37477186933.1288 - mean_squared_error: 37477195776.0000\n",
      "Epoch 20/100\n",
      "1095/1095 [==============================] - 0s 97us/sample - loss: 36950329618.9370 - mean_squared_error: 36950331392.0000\n",
      "Epoch 21/100\n",
      "1095/1095 [==============================] - 0s 93us/sample - loss: 36345153414.4292 - mean_squared_error: 36345155584.0000\n",
      "Epoch 22/100\n",
      "1095/1095 [==============================] - 0s 96us/sample - loss: 35666596165.4356 - mean_squared_error: 35666604032.0000\n",
      "Epoch 23/100\n",
      "1095/1095 [==============================] - 0s 90us/sample - loss: 34907617236.9826 - mean_squared_error: 34907619328.0000\n",
      "Epoch 24/100\n",
      "1095/1095 [==============================] - 0s 96us/sample - loss: 34061059512.4603 - mean_squared_error: 34061058048.0000\n",
      "Epoch 25/100\n",
      "1095/1095 [==============================] - 0s 90us/sample - loss: 33139754467.4776 - mean_squared_error: 33139755008.0000\n",
      "Epoch 26/100\n",
      "1095/1095 [==============================] - 0s 107us/sample - loss: 32127356099.4484 - mean_squared_error: 32127361024.0000\n",
      "Epoch 27/100\n",
      "1095/1095 [==============================] - 0s 103us/sample - loss: 31040068337.7388 - mean_squared_error: 31040071680.0000\n",
      "Epoch 28/100\n",
      "1095/1095 [==============================] - 0s 111us/sample - loss: 29879284617.2347 - mean_squared_error: 29879285760.0000\n",
      "Epoch 29/100\n",
      "1095/1095 [==============================] - 0s 111us/sample - loss: 28653377345.2274 - mean_squared_error: 28653381632.0000\n",
      "Epoch 30/100\n",
      "1095/1095 [==============================] - 0s 96us/sample - loss: 27363509475.2438 - mean_squared_error: 27363508224.0000\n",
      "Epoch 31/100\n",
      "1095/1095 [==============================] - 0s 103us/sample - loss: 26022904655.2548 - mean_squared_error: 26022907904.0000\n",
      "Epoch 32/100\n",
      "1095/1095 [==============================] - 0s 92us/sample - loss: 24635083815.7443 - mean_squared_error: 24635082752.0000\n",
      "Epoch 33/100\n",
      "1095/1095 [==============================] - 0s 93us/sample - loss: 23235385095.2475 - mean_squared_error: 23235385344.0000\n",
      "Epoch 34/100\n",
      "1095/1095 [==============================] - 0s 108us/sample - loss: 21814773697.3443 - mean_squared_error: 21814771712.0000\n",
      "Epoch 35/100\n",
      "1095/1095 [==============================] - 0s 102us/sample - loss: 20380765413.1142 - mean_squared_error: 20380766208.0000\n",
      "Epoch 36/100\n",
      "1095/1095 [==============================] - 0s 105us/sample - loss: 18971706711.2037 - mean_squared_error: 18971707392.0000\n",
      "Epoch 37/100\n",
      "1095/1095 [==============================] - 0s 104us/sample - loss: 17601011934.5680 - mean_squared_error: 17601011712.0000\n",
      "Epoch 38/100\n",
      "1095/1095 [==============================] - 0s 105us/sample - loss: 16233624114.9662 - mean_squared_error: 16233624576.0000\n",
      "Epoch 39/100\n",
      "1095/1095 [==============================] - 0s 92us/sample - loss: 14953340563.2877 - mean_squared_error: 14953340928.0000\n",
      "Epoch 40/100\n",
      "1095/1095 [==============================] - 0s 103us/sample - loss: 13731378190.0274 - mean_squared_error: 13731376128.0000\n",
      "Epoch 41/100\n",
      "1095/1095 [==============================] - 0s 112us/sample - loss: 12594435735.9635 - mean_squared_error: 12594435072.0000\n",
      "Epoch 42/100\n",
      "1095/1095 [==============================] - 0s 103us/sample - loss: 11542680588.6247 - mean_squared_error: 11542680576.0000\n",
      "Epoch 43/100\n",
      "1095/1095 [==============================] - 0s 151us/sample - loss: 10609777361.0082 - mean_squared_error: 10609775616.0000\n",
      "Epoch 44/100\n",
      "1095/1095 [==============================] - 0s 153us/sample - loss: 9769912095.7954 - mean_squared_error: 9769910272.0000\n",
      "Epoch 45/100\n",
      "1095/1095 [==============================] - 0s 158us/sample - loss: 9051049787.0320 - mean_squared_error: 9051049984.0000\n",
      "Epoch 46/100\n",
      "1095/1095 [==============================] - ETA: 0s - loss: 8289840672.0000 - mean_squared_error: 8289840640.00 - 0s 165us/sample - loss: 8421836877.6183 - mean_squared_error: 8421836800.0000\n",
      "Epoch 47/100\n",
      "1095/1095 [==============================] - 0s 163us/sample - loss: 7886311616.6429 - mean_squared_error: 7886312960.0000\n",
      "Epoch 48/100\n",
      "1095/1095 [==============================] - 0s 162us/sample - loss: 7444102275.5068 - mean_squared_error: 7444102656.0000\n",
      "Epoch 49/100\n",
      "1095/1095 [==============================] - 0s 163us/sample - loss: 7081292714.9005 - mean_squared_error: 7081293312.0000\n",
      "Epoch 50/100\n",
      "1095/1095 [==============================] - 0s 158us/sample - loss: 6796902783.6493 - mean_squared_error: 6796902912.0000\n",
      "Epoch 51/100\n",
      "1095/1095 [==============================] - 0s 172us/sample - loss: 6577411736.4311 - mean_squared_error: 6577410560.0000\n",
      "Epoch 52/100\n",
      "1095/1095 [==============================] - 0s 156us/sample - loss: 6396770197.3918 - mean_squared_error: 6396770304.0000\n",
      "Epoch 53/100\n",
      "1095/1095 [==============================] - 0s 182us/sample - loss: 6258209380.0621 - mean_squared_error: 6258209280.0000\n",
      "Epoch 54/100\n",
      "1095/1095 [==============================] - 0s 152us/sample - loss: 6154142878.0420 - mean_squared_error: 6154142208.0000\n",
      "Epoch 55/100\n",
      "1095/1095 [==============================] - 0s 183us/sample - loss: 6081699205.0265 - mean_squared_error: 6081700352.0000\n",
      "Epoch 56/100\n",
      "1095/1095 [==============================] - 0s 171us/sample - loss: 6024655967.3863 - mean_squared_error: 6024656384.0000\n",
      "Epoch 57/100\n",
      "1095/1095 [==============================] - 0s 172us/sample - loss: 5980249682.2941 - mean_squared_error: 5980250112.0000\n",
      "Epoch 58/100\n",
      "1095/1095 [==============================] - 0s 155us/sample - loss: 5948945379.0100 - mean_squared_error: 5948945920.0000\n",
      "Epoch 59/100\n",
      "1095/1095 [==============================] - 0s 166us/sample - loss: 5920138885.2603 - mean_squared_error: 5920138752.0000\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1095/1095 [==============================] - 0s 151us/sample - loss: 5897686961.4466 - mean_squared_error: 5897687040.0000\n",
      "Epoch 61/100\n",
      "1095/1095 [==============================] - 0s 154us/sample - loss: 5876375778.5425 - mean_squared_error: 5876375552.0000\n",
      "Epoch 62/100\n",
      "1095/1095 [==============================] - 0s 169us/sample - loss: 5861267951.8685 - mean_squared_error: 5861267968.0000\n",
      "Epoch 63/100\n",
      "1095/1095 [==============================] - 0s 171us/sample - loss: 5847218322.9370 - mean_squared_error: 5847217664.0000\n",
      "Epoch 64/100\n",
      "1095/1095 [==============================] - 0s 175us/sample - loss: 5833792364.2447 - mean_squared_error: 5833792512.0000\n",
      "Epoch 65/100\n",
      "1095/1095 [==============================] - 0s 166us/sample - loss: 5822547539.1123 - mean_squared_error: 5822546944.0000\n",
      "Epoch 66/100\n",
      "1095/1095 [==============================] - 0s 168us/sample - loss: 5809005342.6265 - mean_squared_error: 5809005056.0000\n",
      "Epoch 67/100\n",
      "1095/1095 [==============================] - 0s 161us/sample - loss: 5797026396.9315 - mean_squared_error: 5797026304.0000\n",
      "Epoch 68/100\n",
      "1095/1095 [==============================] - 0s 163us/sample - loss: 5783099697.7973 - mean_squared_error: 5783099904.0000\n",
      "Epoch 69/100\n",
      "1095/1095 [==============================] - 0s 187us/sample - loss: 5771819662.2612 - mean_squared_error: 5771819008.0000\n",
      "Epoch 70/100\n",
      "1095/1095 [==============================] - 0s 454us/sample - loss: 5759828218.1553 - mean_squared_error: 5759828480.0000\n",
      "Epoch 71/100\n",
      "1095/1095 [==============================] - 0s 433us/sample - loss: 5748531957.9470 - mean_squared_error: 5748532224.0000\n",
      "Epoch 72/100\n",
      "1095/1095 [==============================] - 1s 517us/sample - loss: 5735097329.0374 - mean_squared_error: 5735097344.0000\n",
      "Epoch 73/100\n",
      "1095/1095 [==============================] - 0s 434us/sample - loss: 5722865975.4082 - mean_squared_error: 5722865664.0000\n",
      "Epoch 74/100\n",
      "1095/1095 [==============================] - 0s 451us/sample - loss: 5710066677.7132 - mean_squared_error: 5710066688.0000\n",
      "Epoch 75/100\n",
      "1095/1095 [==============================] - 0s 451us/sample - loss: 5697707101.9836 - mean_squared_error: 5697706496.0000\n",
      "Epoch 76/100\n",
      "1095/1095 [==============================] - 1s 466us/sample - loss: 5685264641.6365 - mean_squared_error: 5685264384.0000\n",
      "Epoch 77/100\n",
      "1095/1095 [==============================] - 1s 462us/sample - loss: 5673109326.3196 - mean_squared_error: 5673108992.0000\n",
      "Epoch 78/100\n",
      "1095/1095 [==============================] - 0s 439us/sample - loss: 5660610730.9005 - mean_squared_error: 5660610048.0000\n",
      "Epoch 79/100\n",
      "1095/1095 [==============================] - 0s 443us/sample - loss: 5651151716.9973 - mean_squared_error: 5651151872.0000\n",
      "Epoch 80/100\n",
      "1095/1095 [==============================] - 1s 496us/sample - loss: 5636520402.8785 - mean_squared_error: 5636519936.0000\n",
      "Epoch 81/100\n",
      "1095/1095 [==============================] - 0s 389us/sample - loss: 5623510544.5991 - mean_squared_error: 5623510016.0000\n",
      "Epoch 82/100\n",
      "1095/1095 [==============================] - 0s 450us/sample - loss: 5611486199.8174 - mean_squared_error: 5611485696.0000\n",
      "Epoch 83/100\n",
      "1095/1095 [==============================] - 1s 470us/sample - loss: 5599056225.7242 - mean_squared_error: 5599055360.0000\n",
      "Epoch 84/100\n",
      "1095/1095 [==============================] - 0s 442us/sample - loss: 5588078619.5872 - mean_squared_error: 5588079104.0000\n",
      "Epoch 85/100\n",
      "1095/1095 [==============================] - 1s 463us/sample - loss: 5575381402.1845 - mean_squared_error: 5575380992.0000\n",
      "Epoch 86/100\n",
      "1095/1095 [==============================] - 1s 494us/sample - loss: 5564264078.8457 - mean_squared_error: 5564264448.0000\n",
      "Epoch 87/100\n",
      "1095/1095 [==============================] - 0s 408us/sample - loss: 5551773673.2055 - mean_squared_error: 5551774208.0000\n",
      "Epoch 88/100\n",
      "1095/1095 [==============================] - 0s 436us/sample - loss: 5539121028.0913 - mean_squared_error: 5539121152.0000\n",
      "Epoch 89/100\n",
      "1095/1095 [==============================] - 1s 531us/sample - loss: 5527539844.0913 - mean_squared_error: 5527540736.0000\n",
      "Epoch 90/100\n",
      "1095/1095 [==============================] - 1s 652us/sample - loss: 5515081460.0767 - mean_squared_error: 5515081216.0000\n",
      "Epoch 91/100\n",
      "1095/1095 [==============================] - 1s 695us/sample - loss: 5505694974.1297 - mean_squared_error: 5505695232.0000\n",
      "Epoch 92/100\n",
      "1095/1095 [==============================] - 1s 596us/sample - loss: 5491036914.4402 - mean_squared_error: 5491036672.0000\n",
      "Epoch 93/100\n",
      "1095/1095 [==============================] - 1s 551us/sample - loss: 5479906123.5142 - mean_squared_error: 5479905280.0000\n",
      "Epoch 94/100\n",
      "1095/1095 [==============================] - 1s 670us/sample - loss: 5466703546.5644 - mean_squared_error: 5466703872.0000\n",
      "Epoch 95/100\n",
      "1095/1095 [==============================] - 1s 694us/sample - loss: 5454600021.3333 - mean_squared_error: 5454600192.0000\n",
      "Epoch 96/100\n",
      "1095/1095 [==============================] - 1s 679us/sample - loss: 5442112431.5763 - mean_squared_error: 5442113024.0000\n",
      "Epoch 97/100\n",
      "1095/1095 [==============================] - 1s 620us/sample - loss: 5429858506.9297 - mean_squared_error: 5429857280.0000\n",
      "Epoch 98/100\n",
      "1095/1095 [==============================] - 1s 664us/sample - loss: 5416797670.2831 - mean_squared_error: 5416798720.0000\n",
      "Epoch 99/100\n",
      "1095/1095 [==============================] - 1s 670us/sample - loss: 5405562386.8201 - mean_squared_error: 5405560832.0000\n",
      "Epoch 100/100\n",
      "1095/1095 [==============================] - 1s 671us/sample - loss: 5392268753.7096 - mean_squared_error: 5392268800.0000\n"
     ]
    }
   ],
   "source": [
    "fitted = model.fit(X_train_normalized, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "365/365 [==============================] - 1s 2ms/sample - loss: 4890288847.6055 - mean_squared_error: 4890288640.0000\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test_normalized, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualizing loss of pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(fitted.history['loss'])\n",
    "plt.title('Neural network training epochs')\n",
    "plt.xlabel('Epoch #')\n",
    "plt.ylabel('Mean Squared Error (Billion)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SfcFnOONyuNm"
   },
   "source": [
    "## Use the Keras Library to build an image recognition network using the Fashion-MNIST dataset (also comes with keras)\n",
    "\n",
    "- Load and preprocess the image data similar to how we preprocessed the MNIST data in class.\n",
    "- Make sure to one-hot encode your category labels\n",
    "- Make sure to have your final layer have as many nodes as the number of classes that you want to predict.\n",
    "- Try different hyperparameters. What is the highest accuracy that you are able to achieve.\n",
    "- Use the history object that is returned from model.fit to make graphs of the model's loss or train/validation accuracies by epoch. \n",
    "- Remember that neural networks fall prey to randomness so you may need to run your model multiple times (or use Cross Validation) in order to tell if a change to a hyperparameter is truly producing better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "szi6-IpuzaH1"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making training and test data from the mnist data\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8),\n",
       " array([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train, return_counts=True)\n",
    "# using the above query, we can see that there are ten total classes (possible outputs) in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to reshape the vectors into 1 dimensional arrays from 28x28 dimensional images\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "\n",
    "# Change dtypes to force floats\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# encode target to a categorical\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_11 (Dense)             (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 89,610\n",
      "Trainable params: 89,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mnist_nn = Sequential()\n",
    "\n",
    "mnist_nn.add(Dense(100, activation='relu', input_dim=784))\n",
    "mnist_nn.add(Dense(100, activation='relu'))\n",
    "# softmax was helpful for strictly multi-class classification\n",
    "mnist_nn.add(Dense(10, activation='softmax'))\n",
    "\n",
    "mnist_nn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "mnist_nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/100\n",
      "54000/54000 [==============================] - 5s 97us/sample - loss: 0.4593 - acc: 0.8444 - val_loss: 0.5822 - val_acc: 0.8302\n",
      "Epoch 2/100\n",
      "54000/54000 [==============================] - 5s 94us/sample - loss: 0.4257 - acc: 0.8513 - val_loss: 0.5745 - val_acc: 0.8325\n",
      "Epoch 3/100\n",
      "54000/54000 [==============================] - 5s 94us/sample - loss: 0.4151 - acc: 0.8554 - val_loss: 0.5562 - val_acc: 0.8368\n",
      "Epoch 4/100\n",
      "54000/54000 [==============================] - 5s 97us/sample - loss: 0.4036 - acc: 0.8575 - val_loss: 0.5229 - val_acc: 0.8402\n",
      "Epoch 5/100\n",
      "54000/54000 [==============================] - 7s 122us/sample - loss: 0.3824 - acc: 0.8628 - val_loss: 0.5097 - val_acc: 0.8428\n",
      "Epoch 6/100\n",
      "54000/54000 [==============================] - 7s 129us/sample - loss: 0.3667 - acc: 0.8665 - val_loss: 0.4933 - val_acc: 0.8507\n",
      "Epoch 7/100\n",
      "54000/54000 [==============================] - 6s 117us/sample - loss: 0.3580 - acc: 0.8710 - val_loss: 0.5465 - val_acc: 0.8415\n",
      "Epoch 8/100\n",
      "54000/54000 [==============================] - 6s 118us/sample - loss: 0.3528 - acc: 0.8710 - val_loss: 0.5030 - val_acc: 0.8478\n",
      "Epoch 9/100\n",
      "54000/54000 [==============================] - 6s 108us/sample - loss: 0.3427 - acc: 0.8739 - val_loss: 0.5122 - val_acc: 0.8483\n",
      "Epoch 10/100\n",
      "54000/54000 [==============================] - 5s 93us/sample - loss: 0.3451 - acc: 0.8750 - val_loss: 0.4904 - val_acc: 0.8500\n",
      "Epoch 11/100\n",
      "54000/54000 [==============================] - 5s 93us/sample - loss: 0.3395 - acc: 0.8767 - val_loss: 0.5172 - val_acc: 0.8470\n",
      "Epoch 12/100\n",
      "54000/54000 [==============================] - 5s 96us/sample - loss: 0.3568 - acc: 0.8711 - val_loss: 0.5033 - val_acc: 0.8517\n",
      "Epoch 13/100\n",
      "54000/54000 [==============================] - 2s 36us/sample - loss: 0.3319 - acc: 0.8790 - val_loss: 0.5511 - val_acc: 0.8368\n",
      "Epoch 14/100\n",
      "54000/54000 [==============================] - 1s 15us/sample - loss: 0.3221 - acc: 0.8823 - val_loss: 0.5072 - val_acc: 0.8540\n",
      "Epoch 15/100\n",
      "54000/54000 [==============================] - 1s 15us/sample - loss: 0.3265 - acc: 0.8819 - val_loss: 0.5523 - val_acc: 0.8463\n",
      "Epoch 16/100\n",
      "54000/54000 [==============================] - 1s 15us/sample - loss: 0.3226 - acc: 0.8817 - val_loss: 0.4756 - val_acc: 0.8653\n",
      "Epoch 17/100\n",
      "54000/54000 [==============================] - 1s 15us/sample - loss: 0.3357 - acc: 0.8793 - val_loss: 0.4808 - val_acc: 0.8570\n",
      "Epoch 18/100\n",
      "54000/54000 [==============================] - 1s 16us/sample - loss: 0.3110 - acc: 0.8849 - val_loss: 0.4952 - val_acc: 0.8525\n",
      "Epoch 19/100\n",
      "54000/54000 [==============================] - 1s 15us/sample - loss: 0.3080 - acc: 0.8855 - val_loss: 0.4891 - val_acc: 0.8593\n",
      "Epoch 20/100\n",
      "54000/54000 [==============================] - 1s 15us/sample - loss: 0.3171 - acc: 0.8835 - val_loss: 0.5033 - val_acc: 0.8513\n",
      "Epoch 21/100\n",
      "54000/54000 [==============================] - 1s 15us/sample - loss: 0.3027 - acc: 0.8897 - val_loss: 0.4874 - val_acc: 0.8627\n",
      "Epoch 22/100\n",
      "54000/54000 [==============================] - 1s 15us/sample - loss: 0.3061 - acc: 0.8882 - val_loss: 0.5169 - val_acc: 0.8555\n",
      "Epoch 23/100\n",
      "54000/54000 [==============================] - 1s 15us/sample - loss: 0.2862 - acc: 0.8937 - val_loss: 0.4927 - val_acc: 0.8568\n",
      "Epoch 24/100\n",
      "54000/54000 [==============================] - 1s 15us/sample - loss: 0.3001 - acc: 0.8896 - val_loss: 0.4632 - val_acc: 0.8610\n",
      "Epoch 25/100\n",
      "54000/54000 [==============================] - 1s 15us/sample - loss: 0.3120 - acc: 0.8864 - val_loss: 0.4810 - val_acc: 0.8547\n",
      "Epoch 26/100\n",
      "54000/54000 [==============================] - 1s 16us/sample - loss: 0.2908 - acc: 0.8931 - val_loss: 0.4780 - val_acc: 0.8645\n",
      "Epoch 27/100\n",
      "54000/54000 [==============================] - 1s 16us/sample - loss: 0.2894 - acc: 0.8942 - val_loss: 0.4981 - val_acc: 0.8460\n",
      "Epoch 28/100\n",
      "54000/54000 [==============================] - 1s 15us/sample - loss: 0.2825 - acc: 0.8943 - val_loss: 0.5501 - val_acc: 0.8547\n",
      "Epoch 29/100\n",
      "54000/54000 [==============================] - 1s 15us/sample - loss: 0.2832 - acc: 0.8958 - val_loss: 0.4827 - val_acc: 0.8592\n",
      "Epoch 30/100\n",
      "54000/54000 [==============================] - 1s 15us/sample - loss: 0.2769 - acc: 0.8975 - val_loss: 0.5066 - val_acc: 0.8537\n",
      "Epoch 31/100\n",
      "54000/54000 [==============================] - 1s 15us/sample - loss: 0.2779 - acc: 0.8983 - val_loss: 0.4633 - val_acc: 0.8673\n",
      "Epoch 32/100\n",
      "54000/54000 [==============================] - 1s 15us/sample - loss: 0.2751 - acc: 0.8971 - val_loss: 0.4827 - val_acc: 0.8678\n",
      "Epoch 33/100\n",
      "54000/54000 [==============================] - 1s 16us/sample - loss: 0.2718 - acc: 0.8974 - val_loss: 0.4885 - val_acc: 0.8533\n",
      "Epoch 34/100\n",
      "54000/54000 [==============================] - 1s 16us/sample - loss: 0.2809 - acc: 0.8960 - val_loss: 0.5215 - val_acc: 0.8535\n",
      "Epoch 35/100\n",
      "54000/54000 [==============================] - 1s 15us/sample - loss: 0.2915 - acc: 0.8961 - val_loss: 0.5069 - val_acc: 0.8457\n",
      "Epoch 36/100\n",
      "54000/54000 [==============================] - 1s 15us/sample - loss: 0.2742 - acc: 0.8974 - val_loss: 0.4810 - val_acc: 0.8605\n",
      "Epoch 37/100\n",
      "54000/54000 [==============================] - 1s 16us/sample - loss: 0.2693 - acc: 0.9006 - val_loss: 0.4848 - val_acc: 0.8682\n",
      "Epoch 38/100\n",
      "54000/54000 [==============================] - 1s 15us/sample - loss: 0.2599 - acc: 0.9028 - val_loss: 0.4646 - val_acc: 0.8700\n",
      "Epoch 39/100\n",
      "54000/54000 [==============================] - 1s 15us/sample - loss: 0.2716 - acc: 0.9008 - val_loss: 0.4765 - val_acc: 0.8655\n",
      "Epoch 40/100\n",
      "54000/54000 [==============================] - 1s 15us/sample - loss: 0.2784 - acc: 0.9008 - val_loss: 0.4780 - val_acc: 0.8677\n",
      "Epoch 41/100\n",
      "54000/54000 [==============================] - 1s 15us/sample - loss: 0.2582 - acc: 0.9057 - val_loss: 0.5129 - val_acc: 0.8588\n",
      "Epoch 42/100\n",
      "54000/54000 [==============================] - 1s 15us/sample - loss: 0.2539 - acc: 0.9052 - val_loss: 0.4921 - val_acc: 0.8655\n",
      "Epoch 43/100\n",
      "54000/54000 [==============================] - 1s 15us/sample - loss: 0.2589 - acc: 0.9037 - val_loss: 0.4921 - val_acc: 0.8693\n",
      "Epoch 44/100\n",
      "54000/54000 [==============================] - 1s 15us/sample - loss: 0.2435 - acc: 0.9109 - val_loss: 0.4696 - val_acc: 0.8702\n",
      "Epoch 45/100\n",
      "54000/54000 [==============================] - 1s 15us/sample - loss: 0.2493 - acc: 0.9077 - val_loss: 0.4938 - val_acc: 0.8702\n",
      "Epoch 46/100\n",
      "54000/54000 [==============================] - 1s 16us/sample - loss: 0.2445 - acc: 0.9094 - val_loss: 0.4759 - val_acc: 0.8662\n",
      "Epoch 47/100\n",
      "54000/54000 [==============================] - 1s 16us/sample - loss: 0.2535 - acc: 0.9059 - val_loss: 0.5232 - val_acc: 0.8607\n",
      "Epoch 48/100\n",
      "54000/54000 [==============================] - 1s 15us/sample - loss: 0.2497 - acc: 0.9081 - val_loss: 0.4843 - val_acc: 0.8697\n",
      "Epoch 49/100\n",
      "54000/54000 [==============================] - 1s 16us/sample - loss: 0.2373 - acc: 0.9123 - val_loss: 0.5013 - val_acc: 0.8678\n",
      "Epoch 50/100\n",
      "54000/54000 [==============================] - 1s 15us/sample - loss: 0.2364 - acc: 0.9118 - val_loss: 0.4788 - val_acc: 0.8647\n",
      "Epoch 51/100\n",
      "54000/54000 [==============================] - 1s 15us/sample - loss: 0.2486 - acc: 0.9086 - val_loss: 0.4611 - val_acc: 0.8692\n",
      "Epoch 52/100\n",
      "54000/54000 [==============================] - 1s 15us/sample - loss: 0.2332 - acc: 0.9133 - val_loss: 0.4821 - val_acc: 0.8665\n",
      "Epoch 53/100\n",
      "54000/54000 [==============================] - 1s 15us/sample - loss: 0.2390 - acc: 0.9114 - val_loss: 0.4962 - val_acc: 0.8710\n",
      "Epoch 54/100\n",
      "54000/54000 [==============================] - 1s 16us/sample - loss: 0.2506 - acc: 0.9082 - val_loss: 0.5224 - val_acc: 0.8645\n",
      "Epoch 55/100\n",
      "54000/54000 [==============================] - 1s 16us/sample - loss: 0.2462 - acc: 0.9087 - val_loss: 0.5151 - val_acc: 0.8645\n",
      "Epoch 56/100\n",
      "54000/54000 [==============================] - 1s 16us/sample - loss: 0.2308 - acc: 0.9134 - val_loss: 0.4926 - val_acc: 0.8660\n",
      "Epoch 57/100\n",
      "54000/54000 [==============================] - 1s 15us/sample - loss: 0.2335 - acc: 0.9127 - val_loss: 0.4841 - val_acc: 0.8672\n",
      "Epoch 58/100\n",
      "54000/54000 [==============================] - 1s 15us/sample - loss: 0.2167 - acc: 0.9184 - val_loss: 0.5248 - val_acc: 0.8607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "54000/54000 [==============================] - 1s 16us/sample - loss: 0.2213 - acc: 0.9174 - val_loss: 0.4979 - val_acc: 0.8660\n",
      "Epoch 60/100\n",
      "54000/54000 [==============================] - 1s 15us/sample - loss: 0.2212 - acc: 0.9169 - val_loss: 0.4943 - val_acc: 0.8710\n",
      "Epoch 61/100\n",
      "54000/54000 [==============================] - 1s 18us/sample - loss: 0.2343 - acc: 0.9125 - val_loss: 0.5353 - val_acc: 0.8647\n",
      "Epoch 62/100\n",
      "54000/54000 [==============================] - 1s 20us/sample - loss: 0.2242 - acc: 0.9160 - val_loss: 0.5198 - val_acc: 0.8700\n",
      "Epoch 63/100\n",
      "54000/54000 [==============================] - 1s 19us/sample - loss: 0.2246 - acc: 0.9175 - val_loss: 0.4831 - val_acc: 0.8698\n",
      "Epoch 64/100\n",
      "54000/54000 [==============================] - 1s 20us/sample - loss: 0.2246 - acc: 0.9155 - val_loss: 0.5120 - val_acc: 0.8670\n",
      "Epoch 65/100\n",
      "54000/54000 [==============================] - 1s 20us/sample - loss: 0.2255 - acc: 0.9157 - val_loss: 0.4955 - val_acc: 0.8743\n",
      "Epoch 66/100\n",
      "54000/54000 [==============================] - 2s 35us/sample - loss: 0.2191 - acc: 0.9185 - val_loss: 0.4797 - val_acc: 0.8807\n",
      "Epoch 67/100\n",
      "54000/54000 [==============================] - 2s 34us/sample - loss: 0.2124 - acc: 0.9207 - val_loss: 0.5000 - val_acc: 0.8708\n",
      "Epoch 68/100\n",
      "54000/54000 [==============================] - 3s 57us/sample - loss: 0.2163 - acc: 0.9197 - val_loss: 0.5125 - val_acc: 0.8672\n",
      "Epoch 69/100\n",
      "54000/54000 [==============================] - 5s 99us/sample - loss: 0.2038 - acc: 0.9232 - val_loss: 0.5040 - val_acc: 0.8693\n",
      "Epoch 70/100\n",
      "54000/54000 [==============================] - 5s 97us/sample - loss: 0.2058 - acc: 0.9228 - val_loss: 0.5228 - val_acc: 0.8715\n",
      "Epoch 71/100\n",
      "54000/54000 [==============================] - 5s 97us/sample - loss: 0.2161 - acc: 0.9194 - val_loss: 0.5005 - val_acc: 0.8738\n",
      "Epoch 72/100\n",
      "54000/54000 [==============================] - 5s 97us/sample - loss: 0.2154 - acc: 0.9209 - val_loss: 0.5155 - val_acc: 0.8740\n",
      "Epoch 73/100\n",
      "54000/54000 [==============================] - 5s 94us/sample - loss: 0.2104 - acc: 0.9208 - val_loss: 0.5135 - val_acc: 0.8725\n",
      "Epoch 74/100\n",
      "54000/54000 [==============================] - 5s 96us/sample - loss: 0.2139 - acc: 0.9198 - val_loss: 0.5465 - val_acc: 0.8667\n",
      "Epoch 75/100\n",
      "54000/54000 [==============================] - 5s 94us/sample - loss: 0.2029 - acc: 0.9245 - val_loss: 0.5284 - val_acc: 0.8737\n",
      "Epoch 76/100\n",
      "54000/54000 [==============================] - 5s 94us/sample - loss: 0.2013 - acc: 0.9240 - val_loss: 0.5381 - val_acc: 0.8740\n",
      "Epoch 77/100\n",
      "54000/54000 [==============================] - 5s 94us/sample - loss: 0.2024 - acc: 0.9233 - val_loss: 0.5459 - val_acc: 0.8655\n",
      "Epoch 78/100\n",
      "54000/54000 [==============================] - 5s 94us/sample - loss: 0.1915 - acc: 0.9277 - val_loss: 0.5462 - val_acc: 0.8673\n",
      "Epoch 79/100\n",
      "54000/54000 [==============================] - 5s 98us/sample - loss: 0.1991 - acc: 0.9254 - val_loss: 0.5077 - val_acc: 0.8748\n",
      "Epoch 80/100\n",
      "54000/54000 [==============================] - 5s 91us/sample - loss: 0.2014 - acc: 0.9244 - val_loss: 0.5526 - val_acc: 0.8655\n",
      "Epoch 81/100\n",
      "54000/54000 [==============================] - 5s 95us/sample - loss: 0.1981 - acc: 0.9250 - val_loss: 0.5392 - val_acc: 0.8673\n",
      "Epoch 82/100\n",
      "54000/54000 [==============================] - 5s 95us/sample - loss: 0.1928 - acc: 0.9274 - val_loss: 0.5854 - val_acc: 0.8473\n",
      "Epoch 83/100\n",
      "54000/54000 [==============================] - 5s 91us/sample - loss: 0.1966 - acc: 0.9262 - val_loss: 0.5171 - val_acc: 0.8707\n",
      "Epoch 84/100\n",
      "54000/54000 [==============================] - 7s 125us/sample - loss: 0.1901 - acc: 0.9287 - val_loss: 0.5388 - val_acc: 0.8752\n",
      "Epoch 85/100\n",
      "54000/54000 [==============================] - 7s 124us/sample - loss: 0.1924 - acc: 0.9276 - val_loss: 0.5431 - val_acc: 0.8690\n",
      "Epoch 86/100\n",
      "54000/54000 [==============================] - 7s 123us/sample - loss: 0.1954 - acc: 0.9269 - val_loss: 0.5535 - val_acc: 0.8705\n",
      "Epoch 87/100\n",
      "54000/54000 [==============================] - 7s 130us/sample - loss: 0.1943 - acc: 0.9269 - val_loss: 0.5937 - val_acc: 0.8667\n",
      "Epoch 88/100\n",
      "54000/54000 [==============================] - 6s 110us/sample - loss: 0.1928 - acc: 0.9256 - val_loss: 0.5413 - val_acc: 0.8673\n",
      "Epoch 89/100\n",
      "54000/54000 [==============================] - 5s 97us/sample - loss: 0.1922 - acc: 0.9274 - val_loss: 0.5782 - val_acc: 0.8692\n",
      "Epoch 90/100\n",
      "54000/54000 [==============================] - 5s 99us/sample - loss: 0.1835 - acc: 0.9307 - val_loss: 0.5510 - val_acc: 0.8783\n",
      "Epoch 91/100\n",
      "54000/54000 [==============================] - 5s 100us/sample - loss: 0.1844 - acc: 0.9303 - val_loss: 0.5819 - val_acc: 0.8670\n",
      "Epoch 92/100\n",
      "54000/54000 [==============================] - 5s 98us/sample - loss: 0.1912 - acc: 0.9278 - val_loss: 0.5980 - val_acc: 0.8692\n",
      "Epoch 93/100\n",
      "54000/54000 [==============================] - 5s 97us/sample - loss: 0.1888 - acc: 0.9298 - val_loss: 0.5649 - val_acc: 0.8702\n",
      "Epoch 94/100\n",
      "54000/54000 [==============================] - 5s 94us/sample - loss: 0.1796 - acc: 0.9324 - val_loss: 0.5947 - val_acc: 0.8668\n",
      "Epoch 95/100\n",
      "54000/54000 [==============================] - 5s 94us/sample - loss: 0.1948 - acc: 0.9275 - val_loss: 0.5812 - val_acc: 0.8653\n",
      "Epoch 96/100\n",
      "54000/54000 [==============================] - 5s 94us/sample - loss: 0.1846 - acc: 0.9301 - val_loss: 0.5602 - val_acc: 0.8727\n",
      "Epoch 97/100\n",
      "54000/54000 [==============================] - 5s 94us/sample - loss: 0.1804 - acc: 0.9316 - val_loss: 0.5943 - val_acc: 0.8715\n",
      "Epoch 98/100\n",
      "54000/54000 [==============================] - 5s 94us/sample - loss: 0.1828 - acc: 0.9319 - val_loss: 0.5612 - val_acc: 0.8733\n",
      "Epoch 99/100\n",
      "54000/54000 [==============================] - 5s 94us/sample - loss: 0.1951 - acc: 0.9273 - val_loss: 0.5344 - val_acc: 0.8768\n",
      "Epoch 100/100\n",
      "54000/54000 [==============================] - 5s 98us/sample - loss: 0.1794 - acc: 0.9325 - val_loss: 0.5365 - val_acc: 0.8790\n"
     ]
    }
   ],
   "source": [
    "# took forever to run without batching\n",
    "mnist_run = mnist_nn.fit(x_train, y_train, epochs=100, validation_split=.10,batch_size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation loss values\n",
    "plt.plot(mnist_run.history['loss'])\n",
    "plt.plot(mnist_run.history['val_loss'])\n",
    "plt.title('Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 4s 445us/sample - loss: 0.5564 - acc: 0.8707\n"
     ]
    }
   ],
   "source": [
    "scores = mnist_nn.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuacy: 87.07000017166138\n"
     ]
    }
   ],
   "source": [
    "# accuracy of only 10%?\n",
    "# edit: tweaked the model and got accuracy of 87%!\n",
    "print(\"Accuacy:\",scores[1]*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zv_3xNMjzdLI"
   },
   "source": [
    "## Stretch Goals:\n",
    "\n",
    "- Use Hyperparameter Tuning to make the accuracy of your models as high as possible. (error as low as possible)\n",
    "- Use Cross Validation techniques to get more consistent results with your model.\n",
    "- Use GridSearchCV to try different combinations of hyperparameters. \n",
    "- Start looking into other types of Keras layers for CNNs and RNNs maybe try and build a CNN model for fashion-MNIST to see how the results compare."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "LS_DS_433_Keras_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
