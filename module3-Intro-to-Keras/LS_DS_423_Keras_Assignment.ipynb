{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pBQsZEJmubLs"
   },
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "\n",
    "# Neural Network Framework (Keras)\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2 Assignmnet 3*\n",
    "\n",
    "## Use the Keras Library to build a Multi-Layer Perceptron Model on the Boston Housing dataset\n",
    "\n",
    "- The Boston Housing dataset comes with the Keras library so use Keras to import it into your notebook. \n",
    "- Normalize the data (all features should have roughly the same scale)\n",
    "- Import the type of model and layers that you will need from Keras.\n",
    "- Instantiate a model object and use `model.add()` to add layers to your model\n",
    "- Since this is a regression model you will have a single output node in the final layer.\n",
    "- Use activation functions that are appropriate for this task\n",
    "- Compile your model\n",
    "- Fit your model and report its accuracy in terms of Mean Squared Error\n",
    "- Use the history object that is returned from model.fit to make graphs of the model's loss or train/validation accuracies by epoch. \n",
    "- Run this same data through a linear regression model. Which achieves higher accuracy?\n",
    "- Do a little bit of feature engineering and see how that affects your neural network model. (you will need to change your model to accept more inputs)\n",
    "- After feature engineering, which model sees a greater accuracy boost due to the new features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting category_encoders\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a0/52/c54191ad3782de633ea3d6ee3bb2837bda0cf3bc97644bb6375cf14150a0/category_encoders-2.1.0-py2.py3-none-any.whl (100kB)\n",
      "\u001b[K    100% |████████████████████████████████| 102kB 3.1MB/s a 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.11.3 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from category_encoders) (1.16.4)\n",
      "Requirement already satisfied: patsy>=0.4.1 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from category_encoders) (0.5.0)\n",
      "Requirement already satisfied: scipy>=0.19.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from category_encoders) (1.3.1)\n",
      "Requirement already satisfied: pandas>=0.21.1 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from category_encoders) (0.24.2)\n",
      "Requirement already satisfied: statsmodels>=0.6.1 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from category_encoders) (0.9.0)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from category_encoders) (0.21.3)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from patsy>=0.4.1->category_encoders) (1.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from pandas>=0.21.1->category_encoders) (2.7.3)\n",
      "Requirement already satisfied: pytz>=2011k in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from pandas>=0.21.1->category_encoders) (2018.4)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from scikit-learn>=0.20.0->category_encoders) (0.13.2)\n",
      "Installing collected packages: category-encoders\n",
      "Successfully installed category-encoders-2.1.0\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import category_encoders as ce\n",
    "from sklearn.preprocessing import MinMaxScaler, Normalizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8NLTAR87uYJ-"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 81)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading my dataset\n",
    "url = 'https://raw.githubusercontent.com/VeraMendes/DS-Unit-4-Sprint-2-Neural-Networks/master/module3-Intro-to-Keras/amesHousePrice.csv'\n",
    "\n",
    "dataset = pd.read_csv(url, header=0)\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looking at my dataset\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.drop(['Id', 'Alley'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass MSZoning  LotFrontage  LotArea Street LotShape LandContour  \\\n",
       "0          60       RL         65.0     8450   Pave      Reg         Lvl   \n",
       "1          20       RL         80.0     9600   Pave      Reg         Lvl   \n",
       "2          60       RL         68.0    11250   Pave      IR1         Lvl   \n",
       "3          70       RL         60.0     9550   Pave      IR1         Lvl   \n",
       "4          60       RL         84.0    14260   Pave      IR1         Lvl   \n",
       "\n",
       "  Utilities LotConfig LandSlope  ... PoolArea PoolQC Fence MiscFeature  \\\n",
       "0    AllPub    Inside       Gtl  ...        0    NaN   NaN         NaN   \n",
       "1    AllPub       FR2       Gtl  ...        0    NaN   NaN         NaN   \n",
       "2    AllPub    Inside       Gtl  ...        0    NaN   NaN         NaN   \n",
       "3    AllPub    Corner       Gtl  ...        0    NaN   NaN         NaN   \n",
       "4    AllPub       FR2       Gtl  ...        0    NaN   NaN         NaN   \n",
       "\n",
       "  MiscVal  MoSold  YrSold  SaleType  SaleCondition SalePrice  \n",
       "0       0       2    2008        WD         Normal    208500  \n",
       "1       0       5    2007        WD         Normal    181500  \n",
       "2       0       9    2008        WD         Normal    223500  \n",
       "3       0       2    2006        WD        Abnorml    140000  \n",
       "4       0      12    2008        WD         Normal    250000  \n",
       "\n",
       "[5 rows x 79 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test split\n",
    "train, test = train_test_split(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train[['SalePrice']].values\n",
    "y_test = test[['SalePrice']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[142500],\n",
       "       [225000],\n",
       "       [165000],\n",
       "       ...,\n",
       "       [181000],\n",
       "       [223500],\n",
       "       [107400]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separating features from initial df\n",
    "features = list(dataset)[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting X_train and X_test df's \n",
    "X_train = train[features]\n",
    "X_test = test[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSSubClass         int64\n",
       "MSZoning          object\n",
       "LotFrontage      float64\n",
       "LotArea            int64\n",
       "Street            object\n",
       "LotShape          object\n",
       "LandContour       object\n",
       "Utilities         object\n",
       "LotConfig         object\n",
       "LandSlope         object\n",
       "Neighborhood      object\n",
       "Condition1        object\n",
       "Condition2        object\n",
       "BldgType          object\n",
       "HouseStyle        object\n",
       "OverallQual        int64\n",
       "OverallCond        int64\n",
       "YearBuilt          int64\n",
       "YearRemodAdd       int64\n",
       "RoofStyle         object\n",
       "RoofMatl          object\n",
       "Exterior1st       object\n",
       "Exterior2nd       object\n",
       "MasVnrType        object\n",
       "MasVnrArea       float64\n",
       "ExterQual         object\n",
       "ExterCond         object\n",
       "Foundation        object\n",
       "BsmtQual          object\n",
       "BsmtCond          object\n",
       "                  ...   \n",
       "BedroomAbvGr       int64\n",
       "KitchenAbvGr       int64\n",
       "KitchenQual       object\n",
       "TotRmsAbvGrd       int64\n",
       "Functional        object\n",
       "Fireplaces         int64\n",
       "FireplaceQu       object\n",
       "GarageType        object\n",
       "GarageYrBlt      float64\n",
       "GarageFinish      object\n",
       "GarageCars         int64\n",
       "GarageArea         int64\n",
       "GarageQual        object\n",
       "GarageCond        object\n",
       "PavedDrive        object\n",
       "WoodDeckSF         int64\n",
       "OpenPorchSF        int64\n",
       "EnclosedPorch      int64\n",
       "3SsnPorch          int64\n",
       "ScreenPorch        int64\n",
       "PoolArea           int64\n",
       "PoolQC            object\n",
       "Fence             object\n",
       "MiscFeature       object\n",
       "MiscVal            int64\n",
       "MoSold             int64\n",
       "YrSold             int64\n",
       "SaleType          object\n",
       "SaleCondition     object\n",
       "SalePrice          int64\n",
       "Length: 79, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([('encoder', ce.OrdinalEncoder()),\n",
    "                     ('imputer',SimpleImputer(strategy='mean')),\n",
    "                     ('normalizer', Normalizer())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_clean = pipeline.fit_transform(X_train)\n",
    "X_test_clean = pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1095, 78)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.44184599e-03, 7.20922997e-05, 4.54181488e-03, 9.42390542e-01,\n",
       "        7.20922997e-05, 7.20922997e-05, 7.20922997e-05, 7.20922997e-05,\n",
       "        7.20922997e-05, 7.20922997e-05, 7.20922997e-05, 7.20922997e-05,\n",
       "        7.20922997e-05, 7.20922997e-05, 7.20922997e-05, 4.32553798e-04,\n",
       "        3.60461499e-04, 1.44545061e-01, 1.44545061e-01, 7.20922997e-05,\n",
       "        7.20922997e-05, 7.20922997e-05, 7.20922997e-05, 7.20922997e-05,\n",
       "        0.00000000e+00, 7.20922997e-05, 7.20922997e-05, 7.20922997e-05,\n",
       "        7.20922997e-05, 7.20922997e-05, 7.20922997e-05, 7.20922997e-05,\n",
       "        0.00000000e+00, 7.20922997e-05, 0.00000000e+00, 8.22573140e-02,\n",
       "        8.22573140e-02, 7.20922997e-05, 7.20922997e-05, 7.20922997e-05,\n",
       "        7.20922997e-05, 8.22573140e-02, 0.00000000e+00, 0.00000000e+00,\n",
       "        8.22573140e-02, 0.00000000e+00, 0.00000000e+00, 7.20922997e-05,\n",
       "        7.20922997e-05, 2.16276899e-04, 7.20922997e-05, 7.20922997e-05,\n",
       "        4.32553798e-04, 7.20922997e-05, 0.00000000e+00, 7.20922997e-05,\n",
       "        7.20922997e-05, 1.44545061e-01, 7.20922997e-05, 1.44184599e-04,\n",
       "        3.48926731e-02, 7.20922997e-05, 7.20922997e-05, 7.20922997e-05,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 7.20922997e-05, 7.20922997e-05,\n",
       "        7.20922997e-05, 0.00000000e+00, 2.16276899e-04, 1.44617153e-01,\n",
       "        7.20922997e-05, 7.20922997e-05],\n",
       "       [4.17341248e-03, 6.95568747e-05, 8.06859747e-03, 9.37209330e-01,\n",
       "        6.95568747e-05, 6.95568747e-05, 6.95568747e-05, 6.95568747e-05,\n",
       "        6.95568747e-05, 6.95568747e-05, 6.95568747e-05, 1.39113749e-04,\n",
       "        6.95568747e-05, 6.95568747e-05, 1.39113749e-04, 4.86898123e-04,\n",
       "        3.47784374e-04, 1.38418181e-01, 1.38487738e-01, 6.95568747e-05,\n",
       "        6.95568747e-05, 1.39113749e-04, 1.39113749e-04, 1.39113749e-04,\n",
       "        1.71109912e-02, 6.95568747e-05, 6.95568747e-05, 1.39113749e-04,\n",
       "        6.95568747e-05, 6.95568747e-05, 6.95568747e-05, 1.39113749e-04,\n",
       "        4.86898123e-02, 6.95568747e-05, 0.00000000e+00, 0.00000000e+00,\n",
       "        4.86898123e-02, 6.95568747e-05, 1.39113749e-04, 6.95568747e-05,\n",
       "        6.95568747e-05, 7.80428134e-02, 7.79732566e-02, 0.00000000e+00,\n",
       "        1.56016070e-01, 6.95568747e-05, 0.00000000e+00, 1.39113749e-04,\n",
       "        6.95568747e-05, 2.78227499e-04, 6.95568747e-05, 1.39113749e-04,\n",
       "        5.56454998e-04, 6.95568747e-05, 6.95568747e-05, 1.39113749e-04,\n",
       "        1.39113749e-04, 1.38418181e-01, 1.39113749e-04, 2.08670624e-04,\n",
       "        5.18894285e-02, 6.95568747e-05, 6.95568747e-05, 6.95568747e-05,\n",
       "        8.83372309e-03, 3.06050249e-03, 1.55807399e-02, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 6.95568747e-05, 6.95568747e-05,\n",
       "        6.95568747e-05, 0.00000000e+00, 4.17341248e-04, 1.39600648e-01,\n",
       "        6.95568747e-05, 1.39113749e-04],\n",
       "       [1.64500556e-03, 8.22502781e-05, 5.74026160e-03, 9.25315629e-01,\n",
       "        8.22502781e-05, 1.64500556e-04, 8.22502781e-05, 8.22502781e-05,\n",
       "        8.22502781e-05, 8.22502781e-05, 1.64500556e-04, 2.46750834e-04,\n",
       "        8.22502781e-05, 8.22502781e-05, 8.22502781e-05, 4.93501669e-04,\n",
       "        4.93501669e-04, 1.62608800e-01, 1.62608800e-01, 8.22502781e-05,\n",
       "        8.22502781e-05, 2.46750834e-04, 1.64500556e-04, 8.22502781e-05,\n",
       "        0.00000000e+00, 8.22502781e-05, 8.22502781e-05, 1.64500556e-04,\n",
       "        8.22502781e-05, 8.22502781e-05, 8.22502781e-05, 1.64500556e-04,\n",
       "        6.30859633e-02, 8.22502781e-05, 0.00000000e+00, 3.62723727e-02,\n",
       "        9.93583360e-02, 8.22502781e-05, 2.46750834e-04, 8.22502781e-05,\n",
       "        8.22502781e-05, 9.93583360e-02, 0.00000000e+00, 0.00000000e+00,\n",
       "        9.93583360e-02, 8.22502781e-05, 0.00000000e+00, 8.22502781e-05,\n",
       "        8.22502781e-05, 2.46750834e-04, 8.22502781e-05, 8.22502781e-05,\n",
       "        4.93501669e-04, 8.22502781e-05, 8.22502781e-05, 1.64500556e-04,\n",
       "        1.64500556e-04, 1.62608800e-01, 1.64500556e-04, 1.64500556e-04,\n",
       "        4.49086519e-02, 8.22502781e-05, 8.22502781e-05, 8.22502781e-05,\n",
       "        1.62855551e-02, 3.45451168e-03, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 8.22502781e-05, 8.22502781e-05,\n",
       "        8.22502781e-05, 0.00000000e+00, 4.93501669e-04, 1.64994058e-01,\n",
       "        8.22502781e-05, 1.64500556e-04],\n",
       "       [8.86223339e-03, 1.18163112e-04, 6.26264493e-03, 8.42266662e-01,\n",
       "        1.18163112e-04, 1.18163112e-04, 1.18163112e-04, 1.18163112e-04,\n",
       "        1.18163112e-04, 1.18163112e-04, 3.54489336e-04, 3.54489336e-04,\n",
       "        1.18163112e-04, 1.18163112e-04, 3.54489336e-04, 8.27141783e-04,\n",
       "        5.90815560e-04, 2.29354600e-01, 2.30418068e-01, 1.18163112e-04,\n",
       "        1.18163112e-04, 4.72652448e-04, 3.54489336e-04, 1.18163112e-04,\n",
       "        0.00000000e+00, 2.36326224e-04, 2.36326224e-04, 2.36326224e-04,\n",
       "        2.36326224e-04, 1.18163112e-04, 1.18163112e-04, 3.54489336e-04,\n",
       "        4.30113727e-02, 1.18163112e-04, 0.00000000e+00, 6.54623640e-02,\n",
       "        1.08473737e-01, 1.18163112e-04, 2.36326224e-04, 1.18163112e-04,\n",
       "        1.18163112e-04, 1.08473737e-01, 8.60227455e-02, 0.00000000e+00,\n",
       "        1.94496482e-01, 0.00000000e+00, 0.00000000e+00, 2.36326224e-04,\n",
       "        0.00000000e+00, 4.72652448e-04, 1.18163112e-04, 1.18163112e-04,\n",
       "        8.27141783e-04, 1.18163112e-04, 2.36326224e-04, 3.54489336e-04,\n",
       "        1.18163112e-04, 2.29354600e-01, 1.18163112e-04, 1.18163112e-04,\n",
       "        2.83591469e-02, 1.18163112e-04, 1.18163112e-04, 1.18163112e-04,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        1.48885521e-02, 0.00000000e+00, 1.18163112e-04, 2.36326224e-04,\n",
       "        1.18163112e-04, 0.00000000e+00, 9.45304895e-04, 2.37153366e-01,\n",
       "        1.18163112e-04, 2.36326224e-04],\n",
       "       [8.36840453e-03, 9.29822726e-05, 6.50875908e-03, 9.15131527e-01,\n",
       "        9.29822726e-05, 9.29822726e-05, 9.29822726e-05, 9.29822726e-05,\n",
       "        1.85964545e-04, 9.29822726e-05, 3.71929090e-04, 2.78946818e-04,\n",
       "        9.29822726e-05, 1.85964545e-04, 9.29822726e-05, 3.71929090e-04,\n",
       "        4.64911363e-04, 1.82431219e-01, 1.82431219e-01, 9.29822726e-05,\n",
       "        9.29822726e-05, 1.85964545e-04, 3.71929090e-04, 9.29822726e-05,\n",
       "        0.00000000e+00, 1.85964545e-04, 9.29822726e-05, 2.78946818e-04,\n",
       "        2.78946818e-04, 1.85964545e-04, 1.85964545e-04, 3.71929090e-04,\n",
       "        0.00000000e+00, 1.85964545e-04, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 9.29822726e-05, 2.78946818e-04, 9.29822726e-05,\n",
       "        9.29822726e-05, 1.13810302e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        1.13810302e-01, 0.00000000e+00, 0.00000000e+00, 1.85964545e-04,\n",
       "        0.00000000e+00, 1.85964545e-04, 1.85964545e-04, 9.29822726e-05,\n",
       "        5.57893636e-04, 9.29822726e-05, 0.00000000e+00, 9.29822726e-05,\n",
       "        2.78946818e-04, 1.82431219e-01, 9.29822726e-05, 1.85964545e-04,\n",
       "        4.29578099e-02, 9.29822726e-05, 9.29822726e-05, 9.29822726e-05,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 9.29822726e-05, 9.29822726e-05,\n",
       "        9.29822726e-05, 0.00000000e+00, 2.78946818e-04, 1.86615421e-01,\n",
       "        9.29822726e-05, 1.85964545e-04]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_clean[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Model: \"nn_test\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 40)                3160      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                820       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 4,421\n",
      "Trainable params: 4,421\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential(name=\"nn_test\") \n",
    "model.add(Dense(40, input_dim=78, activation='relu')) \n",
    "model.add(Dense(20, activation='relu')) \n",
    "model.add(Dense(20, activation='relu')) \n",
    "model.add(Dense(1, activation='relu'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['mean_squared_error'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1095/1095 [==============================] - 1s 680us/sample - loss: 2801806.0176 - mean_squared_error: 39283269632.0000\n",
      "Epoch 2/150\n",
      "1095/1095 [==============================] - 0s 90us/sample - loss: 2801805.9888 - mean_squared_error: 39283265536.0000\n",
      "Epoch 3/150\n",
      "1095/1095 [==============================] - 0s 104us/sample - loss: 2801805.9715 - mean_squared_error: 39283265536.0000\n",
      "Epoch 4/150\n",
      "1095/1095 [==============================] - 0s 91us/sample - loss: 2801805.9696 - mean_squared_error: 39283269632.0000\n",
      "Epoch 5/150\n",
      "1095/1095 [==============================] - 0s 89us/sample - loss: 2801805.9758 - mean_squared_error: 39283269632.0000\n",
      "Epoch 6/150\n",
      "1095/1095 [==============================] - 0s 91us/sample - loss: 2801805.9637 - mean_squared_error: 39283261440.0000\n",
      "Epoch 7/150\n",
      "1095/1095 [==============================] - 0s 91us/sample - loss: 2801805.9769 - mean_squared_error: 39283273728.0000\n",
      "Epoch 8/150\n",
      "1095/1095 [==============================] - 0s 87us/sample - loss: 2801805.9584 - mean_squared_error: 39283261440.0000\n",
      "Epoch 9/150\n",
      "1095/1095 [==============================] - 0s 84us/sample - loss: 2801805.9653 - mean_squared_error: 39283269632.0000\n",
      "Epoch 10/150\n",
      "1095/1095 [==============================] - 0s 89us/sample - loss: 2801805.9909 - mean_squared_error: 39283273728.0000\n",
      "Epoch 11/150\n",
      "1095/1095 [==============================] - 0s 89us/sample - loss: 2801805.9817 - mean_squared_error: 39283261440.0000\n",
      "Epoch 12/150\n",
      "1095/1095 [==============================] - 0s 93us/sample - loss: 2801805.9767 - mean_squared_error: 39283265536.0000\n",
      "Epoch 13/150\n",
      "1095/1095 [==============================] - 0s 90us/sample - loss: 2801805.9495 - mean_squared_error: 39283265536.0000\n",
      "Epoch 14/150\n",
      "1095/1095 [==============================] - 0s 91us/sample - loss: 2801805.9507 - mean_squared_error: 39283269632.0000\n",
      "Epoch 15/150\n",
      "1095/1095 [==============================] - 0s 90us/sample - loss: 2801805.9829 - mean_squared_error: 39283265536.0000\n",
      "Epoch 16/150\n",
      "1095/1095 [==============================] - 0s 92us/sample - loss: 2801806.0034 - mean_squared_error: 39283261440.0000\n",
      "Epoch 17/150\n",
      "1095/1095 [==============================] - 0s 92us/sample - loss: 2801805.9943 - mean_squared_error: 39283269632.0000\n",
      "Epoch 18/150\n",
      "1095/1095 [==============================] - 0s 90us/sample - loss: 2801805.9838 - mean_squared_error: 39283265536.0000\n",
      "Epoch 19/150\n",
      "1095/1095 [==============================] - 0s 91us/sample - loss: 2801805.9779 - mean_squared_error: 39283269632.0000\n",
      "Epoch 20/150\n",
      "1095/1095 [==============================] - 0s 90us/sample - loss: 2801805.9703 - mean_squared_error: 39283269632.0000\n",
      "Epoch 21/150\n",
      "1095/1095 [==============================] - 0s 89us/sample - loss: 2801805.9769 - mean_squared_error: 39283265536.0000\n",
      "Epoch 22/150\n",
      "1095/1095 [==============================] - 0s 102us/sample - loss: 2801805.9616 - mean_squared_error: 39283265536.0000\n",
      "Epoch 23/150\n",
      "1095/1095 [==============================] - 0s 91us/sample - loss: 2801805.9818 - mean_squared_error: 39283269632.0000\n",
      "Epoch 24/150\n",
      "1095/1095 [==============================] - 0s 89us/sample - loss: 2801806.0235 - mean_squared_error: 39283257344.0000\n",
      "Epoch 25/150\n",
      "1095/1095 [==============================] - 0s 90us/sample - loss: 2801805.9447 - mean_squared_error: 39283265536.0000\n",
      "Epoch 26/150\n",
      "1095/1095 [==============================] - 0s 91us/sample - loss: 2801805.9806 - mean_squared_error: 39283269632.0000\n",
      "Epoch 27/150\n",
      "1095/1095 [==============================] - 0s 88us/sample - loss: 2801805.9744 - mean_squared_error: 39283269632.0000\n",
      "Epoch 28/150\n",
      "1095/1095 [==============================] - 0s 88us/sample - loss: 2801805.9890 - mean_squared_error: 39283265536.0000\n",
      "Epoch 29/150\n",
      "1095/1095 [==============================] - 0s 92us/sample - loss: 2801805.9676 - mean_squared_error: 39283265536.0000\n",
      "Epoch 30/150\n",
      "1095/1095 [==============================] - 0s 89us/sample - loss: 2801805.9961 - mean_squared_error: 39283269632.0000\n",
      "Epoch 31/150\n",
      "1095/1095 [==============================] - 0s 89us/sample - loss: 2801805.9836 - mean_squared_error: 39283265536.0000\n",
      "Epoch 32/150\n",
      "1095/1095 [==============================] - 0s 90us/sample - loss: 2801805.9575 - mean_squared_error: 39283269632.0000\n",
      "Epoch 33/150\n",
      "1095/1095 [==============================] - 0s 89us/sample - loss: 2801806.0041 - mean_squared_error: 39283273728.0000\n",
      "Epoch 34/150\n",
      "1095/1095 [==============================] - 0s 90us/sample - loss: 2801805.9740 - mean_squared_error: 39283269632.0000\n",
      "Epoch 35/150\n",
      "1095/1095 [==============================] - 0s 89us/sample - loss: 2801805.9647 - mean_squared_error: 39283265536.0000\n",
      "Epoch 36/150\n",
      "1095/1095 [==============================] - 0s 89us/sample - loss: 2801805.9705 - mean_squared_error: 39283269632.0000\n",
      "Epoch 37/150\n",
      "1095/1095 [==============================] - 0s 90us/sample - loss: 2801805.9612 - mean_squared_error: 39283277824.0000\n",
      "Epoch 38/150\n",
      "1095/1095 [==============================] - 0s 89us/sample - loss: 2801805.9605 - mean_squared_error: 39283265536.0000\n",
      "Epoch 39/150\n",
      "1095/1095 [==============================] - 0s 91us/sample - loss: 2801805.9573 - mean_squared_error: 39283265536.0000\n",
      "Epoch 40/150\n",
      "1095/1095 [==============================] - 0s 88us/sample - loss: 2801805.9676 - mean_squared_error: 39283261440.0000\n",
      "Epoch 41/150\n",
      "1095/1095 [==============================] - 0s 93us/sample - loss: 2801805.9432 - mean_squared_error: 39283265536.0000\n",
      "Epoch 42/150\n",
      "1095/1095 [==============================] - 0s 95us/sample - loss: 2801806.0064 - mean_squared_error: 39283257344.0000\n",
      "Epoch 43/150\n",
      "1095/1095 [==============================] - 0s 91us/sample - loss: 2801806.0080 - mean_squared_error: 39283269632.0000\n",
      "Epoch 44/150\n",
      "1095/1095 [==============================] - 0s 88us/sample - loss: 2801805.9749 - mean_squared_error: 39283265536.0000\n",
      "Epoch 45/150\n",
      "1095/1095 [==============================] - 0s 90us/sample - loss: 2801806.0059 - mean_squared_error: 39283265536.0000\n",
      "Epoch 46/150\n",
      "1095/1095 [==============================] - 0s 89us/sample - loss: 2801805.9998 - mean_squared_error: 39283269632.0000\n",
      "Epoch 47/150\n",
      "1095/1095 [==============================] - 0s 90us/sample - loss: 2801805.9703 - mean_squared_error: 39283265536.0000\n",
      "Epoch 48/150\n",
      "1095/1095 [==============================] - 0s 91us/sample - loss: 2801805.9938 - mean_squared_error: 39283269632.0000\n",
      "Epoch 49/150\n",
      "1095/1095 [==============================] - 0s 89us/sample - loss: 2801805.9920 - mean_squared_error: 39283265536.0000\n",
      "Epoch 50/150\n",
      "1095/1095 [==============================] - 0s 92us/sample - loss: 2801805.9874 - mean_squared_error: 39283273728.0000\n",
      "Epoch 51/150\n",
      "1095/1095 [==============================] - 0s 90us/sample - loss: 2801805.9397 - mean_squared_error: 39283269632.0000\n",
      "Epoch 52/150\n",
      "1095/1095 [==============================] - 0s 92us/sample - loss: 2801806.0128 - mean_squared_error: 39283261440.0000\n",
      "Epoch 53/150\n",
      "1095/1095 [==============================] - 0s 90us/sample - loss: 2801805.9842 - mean_squared_error: 39283265536.0000\n",
      "Epoch 54/150\n",
      "1095/1095 [==============================] - 0s 92us/sample - loss: 2801805.9950 - mean_squared_error: 39283265536.0000\n",
      "Epoch 55/150\n",
      "1095/1095 [==============================] - 0s 91us/sample - loss: 2801805.9651 - mean_squared_error: 39283265536.0000\n",
      "Epoch 56/150\n",
      "1095/1095 [==============================] - 0s 90us/sample - loss: 2801805.9646 - mean_squared_error: 39283269632.0000\n",
      "Epoch 57/150\n",
      "1095/1095 [==============================] - 0s 91us/sample - loss: 2801805.9979 - mean_squared_error: 39283269632.0000\n",
      "Epoch 58/150\n",
      "1095/1095 [==============================] - 0s 90us/sample - loss: 2801806.0244 - mean_squared_error: 39283269632.0000\n",
      "Epoch 59/150\n",
      "1095/1095 [==============================] - 0s 90us/sample - loss: 2801805.9493 - mean_squared_error: 39283265536.0000\n",
      "Epoch 60/150\n",
      "1095/1095 [==============================] - 0s 91us/sample - loss: 2801805.9669 - mean_squared_error: 39283269632.0000\n",
      "Epoch 61/150\n",
      "1095/1095 [==============================] - 0s 95us/sample - loss: 2801805.9774 - mean_squared_error: 39283257344.0000\n",
      "Epoch 62/150\n",
      "1095/1095 [==============================] - 0s 93us/sample - loss: 2801805.9724 - mean_squared_error: 39283265536.0000\n",
      "Epoch 63/150\n",
      "1095/1095 [==============================] - 0s 91us/sample - loss: 2801805.9397 - mean_squared_error: 39283261440.0000\n",
      "Epoch 64/150\n",
      "1095/1095 [==============================] - 0s 92us/sample - loss: 2801805.9687 - mean_squared_error: 39283269632.0000\n",
      "Epoch 65/150\n",
      "1095/1095 [==============================] - 0s 93us/sample - loss: 2801805.9749 - mean_squared_error: 39283265536.0000\n",
      "Epoch 66/150\n",
      "1095/1095 [==============================] - 0s 90us/sample - loss: 2801805.9925 - mean_squared_error: 39283261440.0000\n",
      "Epoch 67/150\n",
      "1095/1095 [==============================] - 0s 83us/sample - loss: 2801805.9532 - mean_squared_error: 39283265536.0000\n",
      "Epoch 68/150\n",
      "1095/1095 [==============================] - 0s 88us/sample - loss: 2801805.9532 - mean_squared_error: 39283273728.0000\n",
      "Epoch 69/150\n",
      "1095/1095 [==============================] - 0s 89us/sample - loss: 2801805.9804 - mean_squared_error: 39283265536.0000\n",
      "Epoch 70/150\n",
      "1095/1095 [==============================] - 0s 91us/sample - loss: 2801805.9868 - mean_squared_error: 39283265536.0000\n",
      "Epoch 71/150\n",
      "1095/1095 [==============================] - 0s 113us/sample - loss: 2801805.9721 - mean_squared_error: 39283265536.0000\n",
      "Epoch 72/150\n",
      "1095/1095 [==============================] - 0s 90us/sample - loss: 2801805.9785 - mean_squared_error: 39283265536.0000\n",
      "Epoch 73/150\n",
      "1095/1095 [==============================] - 0s 92us/sample - loss: 2801805.9767 - mean_squared_error: 39283265536.0000\n",
      "Epoch 74/150\n",
      "1095/1095 [==============================] - 0s 90us/sample - loss: 2801805.9427 - mean_squared_error: 39283265536.0000\n",
      "Epoch 75/150\n",
      "1095/1095 [==============================] - 0s 91us/sample - loss: 2801805.9678 - mean_squared_error: 39283269632.0000\n",
      "Epoch 76/150\n",
      "1095/1095 [==============================] - 0s 89us/sample - loss: 2801806.0094 - mean_squared_error: 39283261440.0000\n",
      "Epoch 77/150\n",
      "1095/1095 [==============================] - 0s 91us/sample - loss: 2801805.9806 - mean_squared_error: 39283273728.0000\n",
      "Epoch 78/150\n",
      "1095/1095 [==============================] - 0s 89us/sample - loss: 2801805.9941 - mean_squared_error: 39283261440.0000\n",
      "Epoch 79/150\n",
      "1095/1095 [==============================] - 0s 90us/sample - loss: 2801806.0203 - mean_squared_error: 39283273728.0000\n",
      "Epoch 80/150\n",
      "1095/1095 [==============================] - 0s 97us/sample - loss: 2801805.9856 - mean_squared_error: 39283277824.0000\n",
      "Epoch 81/150\n",
      "1095/1095 [==============================] - 0s 91us/sample - loss: 2801805.9868 - mean_squared_error: 39283265536.0000\n",
      "Epoch 82/150\n",
      "1095/1095 [==============================] - 0s 93us/sample - loss: 2801805.9925 - mean_squared_error: 39283261440.0000\n",
      "Epoch 83/150\n",
      "1095/1095 [==============================] - 0s 89us/sample - loss: 2801805.9920 - mean_squared_error: 39283265536.0000\n",
      "Epoch 84/150\n",
      "1095/1095 [==============================] - 0s 91us/sample - loss: 2801806.0066 - mean_squared_error: 39283269632.0000\n",
      "Epoch 85/150\n",
      "1095/1095 [==============================] - 0s 88us/sample - loss: 2801805.9783 - mean_squared_error: 39283265536.0000\n",
      "Epoch 86/150\n",
      "1095/1095 [==============================] - 0s 88us/sample - loss: 2801805.9705 - mean_squared_error: 39283269632.0000\n",
      "Epoch 87/150\n",
      "1095/1095 [==============================] - 0s 89us/sample - loss: 2801805.9774 - mean_squared_error: 39283269632.0000\n",
      "Epoch 88/150\n",
      "1095/1095 [==============================] - 0s 91us/sample - loss: 2801805.9788 - mean_squared_error: 39283265536.0000\n",
      "Epoch 89/150\n",
      "1095/1095 [==============================] - 0s 92us/sample - loss: 2801806.0132 - mean_squared_error: 39283273728.0000\n",
      "Epoch 90/150\n",
      "1095/1095 [==============================] - 0s 92us/sample - loss: 2801805.9824 - mean_squared_error: 39283273728.0000\n",
      "Epoch 91/150\n",
      "1095/1095 [==============================] - 0s 87us/sample - loss: 2801806.0110 - mean_squared_error: 39283269632.0000\n",
      "Epoch 92/150\n",
      "1095/1095 [==============================] - 0s 88us/sample - loss: 2801805.9731 - mean_squared_error: 39283261440.0000\n",
      "Epoch 93/150\n",
      "1095/1095 [==============================] - 0s 90us/sample - loss: 2801805.9856 - mean_squared_error: 39283261440.0000\n",
      "Epoch 94/150\n",
      "1095/1095 [==============================] - 0s 91us/sample - loss: 2801806.0148 - mean_squared_error: 39283273728.0000\n",
      "Epoch 95/150\n",
      "1095/1095 [==============================] - 0s 91us/sample - loss: 2801806.0153 - mean_squared_error: 39283261440.0000\n",
      "Epoch 96/150\n",
      "1095/1095 [==============================] - 0s 85us/sample - loss: 2801805.9984 - mean_squared_error: 39283273728.0000\n",
      "Epoch 97/150\n",
      "1095/1095 [==============================] - 0s 87us/sample - loss: 2801806.0121 - mean_squared_error: 39283273728.0000\n",
      "Epoch 98/150\n",
      "1095/1095 [==============================] - 0s 94us/sample - loss: 2801805.9692 - mean_squared_error: 39283261440.0000\n",
      "Epoch 99/150\n",
      "1095/1095 [==============================] - 0s 88us/sample - loss: 2801806.0078 - mean_squared_error: 39283273728.0000\n",
      "Epoch 100/150\n",
      "1095/1095 [==============================] - 0s 94us/sample - loss: 2801805.9977 - mean_squared_error: 39283273728.0000\n",
      "Epoch 101/150\n",
      "1095/1095 [==============================] - 0s 90us/sample - loss: 2801805.9502 - mean_squared_error: 39283261440.0000\n",
      "Epoch 102/150\n",
      "1095/1095 [==============================] - 0s 88us/sample - loss: 2801805.9511 - mean_squared_error: 39283265536.0000\n",
      "Epoch 103/150\n",
      "1095/1095 [==============================] - 0s 92us/sample - loss: 2801805.9909 - mean_squared_error: 39283269632.0000\n",
      "Epoch 104/150\n",
      "1095/1095 [==============================] - 0s 89us/sample - loss: 2801806.0014 - mean_squared_error: 39283273728.0000\n",
      "Epoch 105/150\n",
      "1095/1095 [==============================] - 0s 88us/sample - loss: 2801805.9831 - mean_squared_error: 39283265536.0000\n",
      "Epoch 106/150\n",
      "1095/1095 [==============================] - 0s 88us/sample - loss: 2801805.9831 - mean_squared_error: 39283269632.0000\n",
      "Epoch 107/150\n",
      "1095/1095 [==============================] - 0s 91us/sample - loss: 2801805.9671 - mean_squared_error: 39283261440.0000\n",
      "Epoch 108/150\n",
      "1095/1095 [==============================] - 0s 91us/sample - loss: 2801805.9559 - mean_squared_error: 39283265536.0000\n",
      "Epoch 109/150\n",
      "1095/1095 [==============================] - 0s 89us/sample - loss: 2801805.9763 - mean_squared_error: 39283261440.0000\n",
      "Epoch 110/150\n",
      "1095/1095 [==============================] - 0s 90us/sample - loss: 2801805.9954 - mean_squared_error: 39283265536.0000\n",
      "Epoch 111/150\n",
      "1095/1095 [==============================] - 0s 89us/sample - loss: 2801805.9811 - mean_squared_error: 39283265536.0000\n",
      "Epoch 112/150\n",
      "1095/1095 [==============================] - 0s 89us/sample - loss: 2801805.9527 - mean_squared_error: 39283269632.0000\n",
      "Epoch 113/150\n",
      "1095/1095 [==============================] - 0s 89us/sample - loss: 2801805.9564 - mean_squared_error: 39283269632.0000\n",
      "Epoch 114/150\n",
      "1095/1095 [==============================] - 0s 90us/sample - loss: 2801805.9852 - mean_squared_error: 39283265536.0000\n",
      "Epoch 115/150\n",
      "1095/1095 [==============================] - 0s 91us/sample - loss: 2801805.9788 - mean_squared_error: 39283261440.0000\n",
      "Epoch 116/150\n",
      "1095/1095 [==============================] - 0s 85us/sample - loss: 2801806.0016 - mean_squared_error: 39283269632.0000\n",
      "Epoch 117/150\n",
      "1095/1095 [==============================] - 0s 89us/sample - loss: 2801805.9765 - mean_squared_error: 39283265536.0000\n",
      "Epoch 118/150\n",
      "1095/1095 [==============================] - 0s 92us/sample - loss: 2801805.9886 - mean_squared_error: 39283273728.0000\n",
      "Epoch 119/150\n",
      "1095/1095 [==============================] - 0s 101us/sample - loss: 2801805.9717 - mean_squared_error: 39283269632.0000\n",
      "Epoch 120/150\n",
      "1095/1095 [==============================] - 0s 88us/sample - loss: 2801805.9586 - mean_squared_error: 39283269632.0000\n",
      "Epoch 121/150\n",
      "1095/1095 [==============================] - 0s 89us/sample - loss: 2801805.9852 - mean_squared_error: 39283269632.0000\n",
      "Epoch 122/150\n",
      "1095/1095 [==============================] - 0s 89us/sample - loss: 2801805.9912 - mean_squared_error: 39283269632.0000\n",
      "Epoch 123/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1095/1095 [==============================] - 0s 88us/sample - loss: 2801805.9543 - mean_squared_error: 39283269632.0000\n",
      "Epoch 124/150\n",
      "1095/1095 [==============================] - 0s 90us/sample - loss: 2801805.9646 - mean_squared_error: 39283273728.0000\n",
      "Epoch 125/150\n",
      "1095/1095 [==============================] - 0s 92us/sample - loss: 2801805.9824 - mean_squared_error: 39283269632.0000\n",
      "Epoch 126/150\n",
      "1095/1095 [==============================] - 0s 91us/sample - loss: 2801805.9623 - mean_squared_error: 39283261440.0000\n",
      "Epoch 127/150\n",
      "1095/1095 [==============================] - 0s 89us/sample - loss: 2801805.9660 - mean_squared_error: 39283269632.0000\n",
      "Epoch 128/150\n",
      "1095/1095 [==============================] - 0s 89us/sample - loss: 2801805.9685 - mean_squared_error: 39283265536.0000\n",
      "Epoch 129/150\n",
      "1095/1095 [==============================] - 0s 90us/sample - loss: 2801805.9986 - mean_squared_error: 39283265536.0000\n",
      "Epoch 130/150\n",
      "1095/1095 [==============================] - 0s 89us/sample - loss: 2801805.9858 - mean_squared_error: 39283269632.0000\n",
      "Epoch 131/150\n",
      "1095/1095 [==============================] - 0s 91us/sample - loss: 2801805.9769 - mean_squared_error: 39283269632.0000\n",
      "Epoch 132/150\n",
      "1095/1095 [==============================] - 0s 89us/sample - loss: 2801805.9751 - mean_squared_error: 39283265536.0000\n",
      "Epoch 133/150\n",
      "1095/1095 [==============================] - 0s 91us/sample - loss: 2801805.9573 - mean_squared_error: 39283261440.0000\n",
      "Epoch 134/150\n",
      "1095/1095 [==============================] - 0s 88us/sample - loss: 2801805.9667 - mean_squared_error: 39283273728.0000\n",
      "Epoch 135/150\n",
      "1095/1095 [==============================] - 0s 90us/sample - loss: 2801805.9676 - mean_squared_error: 39283269632.0000\n",
      "Epoch 136/150\n",
      "1095/1095 [==============================] - 0s 85us/sample - loss: 2801805.9737 - mean_squared_error: 39283269632.0000\n",
      "Epoch 137/150\n",
      "1095/1095 [==============================] - 0s 93us/sample - loss: 2801805.9660 - mean_squared_error: 39283265536.0000\n",
      "Epoch 138/150\n",
      "1095/1095 [==============================] - 0s 93us/sample - loss: 2801805.9868 - mean_squared_error: 39283269632.0000\n",
      "Epoch 139/150\n",
      "1095/1095 [==============================] - 0s 90us/sample - loss: 2801805.9847 - mean_squared_error: 39283265536.0000\n",
      "Epoch 140/150\n",
      "1095/1095 [==============================] - 0s 90us/sample - loss: 2801805.9598 - mean_squared_error: 39283265536.0000\n",
      "Epoch 141/150\n",
      "1095/1095 [==============================] - 0s 87us/sample - loss: 2801805.9854 - mean_squared_error: 39283265536.0000\n",
      "Epoch 142/150\n",
      "1095/1095 [==============================] - 0s 87us/sample - loss: 2801805.9418 - mean_squared_error: 39283265536.0000\n",
      "Epoch 143/150\n",
      "1095/1095 [==============================] - 0s 90us/sample - loss: 2801805.9683 - mean_squared_error: 39283265536.0000\n",
      "Epoch 144/150\n",
      "1095/1095 [==============================] - 0s 89us/sample - loss: 2801805.9920 - mean_squared_error: 39283265536.0000\n",
      "Epoch 145/150\n",
      "1095/1095 [==============================] - 0s 88us/sample - loss: 2801805.9963 - mean_squared_error: 39283261440.0000\n",
      "Epoch 146/150\n",
      "1095/1095 [==============================] - 0s 85us/sample - loss: 2801805.9300 - mean_squared_error: 39283265536.0000\n",
      "Epoch 147/150\n",
      "1095/1095 [==============================] - 0s 90us/sample - loss: 2801805.9963 - mean_squared_error: 39283265536.0000\n",
      "Epoch 148/150\n",
      "1095/1095 [==============================] - 0s 89us/sample - loss: 2801805.9879 - mean_squared_error: 39283265536.0000\n",
      "Epoch 149/150\n",
      "1095/1095 [==============================] - 0s 94us/sample - loss: 2801805.9938 - mean_squared_error: 39283265536.0000\n",
      "Epoch 150/150\n",
      "1095/1095 [==============================] - 0s 91us/sample - loss: 2801805.9747 - mean_squared_error: 39283261440.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f918062b390>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_clean, y_train, epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "365/365 [==============================] - 0s 362us/sample - loss: 2757382.6767 - mean_squared_error: 38307270656.0000\n",
      "mean_squared_error: 3830727065600.0\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test_clean, y_test)\n",
    "print(f\"{model.metrics_names[1]}: {scores[1]*100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SfcFnOONyuNm"
   },
   "source": [
    "## Use the Keras Library to build an image recognition network using the Fashion-MNIST dataset (also comes with keras)\n",
    "\n",
    "- Load and preprocess the image data similar to how we preprocessed the MNIST data in class.\n",
    "- Make sure to one-hot encode your category labels\n",
    "- Make sure to have your final layer have as many nodes as the number of classes that you want to predict.\n",
    "- Try different hyperparameters. What is the highest accuracy that you are able to achieve.\n",
    "- Use the history object that is returned from model.fit to make graphs of the model's loss or train/validation accuracies by epoch. \n",
    "- Remember that neural networks fall prey to randomness so you may need to run your model multiple times (or use Cross Validation) in order to tell if a change to a hyperparameter is truly producing better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "szi6-IpuzaH1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:61: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "8192/5148 [===============================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "df = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Data\n",
    "(X_train, y_train), (X_test, y_test) = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 28, 28), (60000, 28, 28))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new dimensions reshape for 28**2=784\n",
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 784), (60000, 784))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000,), (10000,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10 classes to be predicted\n",
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct Encoding on Y\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 10), (10000, 10))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 32)                25120     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                130       \n",
      "=================================================================\n",
      "Total params: 25,646\n",
      "Trainable params: 25,646\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "fashion_model = Sequential()\n",
    "\n",
    "# Input => Hidden layer\n",
    "fashion_model.add(Dense(32, input_dim=784, activation='relu'))\n",
    "fashion_model.add(Dropout(0.2))\n",
    "fashion_model.add(Dense(12, activation='relu'))\n",
    "fashion_model.add(Dropout(0.2))\n",
    "# Output layer\n",
    "fashion_model.add(Dense(10, activation='relu'))\n",
    "\n",
    "\n",
    "#Compile\n",
    "fashion_model.compile(loss='categorical_crossentropy',\n",
    "                    optimizer='adam',\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "fashion_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/150\n",
      "60000/60000 [==============================] - 5s 86us/sample - loss: 3.0502 - acc: 0.3905\n",
      "Epoch 2/150\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: nan - acc: 0.2939\n",
      "Epoch 3/150\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 4/150\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 5/150\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 6/150\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 7/150\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 8/150\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 9/150\n",
      "60000/60000 [==============================] - 5s 91us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 10/150\n",
      "60000/60000 [==============================] - 5s 77us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 11/150\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 12/150\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 13/150\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 14/150\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 15/150\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 16/150\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 17/150\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 18/150\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 19/150\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 20/150\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 21/150\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 22/150\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 23/150\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 24/150\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 25/150\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 26/150\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 27/150\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 28/150\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 29/150\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 30/150\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 31/150\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 32/150\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 33/150\n",
      "60000/60000 [==============================] - 11s 190us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 34/150\n",
      "60000/60000 [==============================] - 51s 857us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 35/150\n",
      "60000/60000 [==============================] - 62s 1ms/sample - loss: nan - acc: 0.1000\n",
      "Epoch 36/150\n",
      "60000/60000 [==============================] - 16s 269us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 37/150\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 38/150\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 39/150\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 40/150\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 41/150\n",
      "60000/60000 [==============================] - 4s 74us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 42/150\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 43/150\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 44/150\n",
      "60000/60000 [==============================] - 5s 89us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 45/150\n",
      "60000/60000 [==============================] - 27s 447us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 46/150\n",
      "60000/60000 [==============================] - 50s 830us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 47/150\n",
      "60000/60000 [==============================] - 69s 1ms/sample - loss: nan - acc: 0.1000\n",
      "Epoch 48/150\n",
      "60000/60000 [==============================] - 52s 868us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 49/150\n",
      "60000/60000 [==============================] - 50s 825us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 50/150\n",
      "60000/60000 [==============================] - 19s 321us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 51/150\n",
      "60000/60000 [==============================] - 5s 77us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 52/150\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 53/150\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 54/150\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 55/150\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 56/150\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 57/150\n",
      "60000/60000 [==============================] - 5s 76us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 58/150\n",
      "60000/60000 [==============================] - 8s 132us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 59/150\n",
      "60000/60000 [==============================] - 48s 804us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 60/150\n",
      "60000/60000 [==============================] - 51s 857us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 61/150\n",
      "60000/60000 [==============================] - 66s 1ms/sample - loss: nan - acc: 0.1000\n",
      "Epoch 62/150\n",
      "60000/60000 [==============================] - 50s 827us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 63/150\n",
      "60000/60000 [==============================] - 41s 690us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 64/150\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 65/150\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 66/150\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 67/150\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 68/150\n",
      "60000/60000 [==============================] - 4s 74us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 69/150\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 70/150\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 71/150\n",
      "60000/60000 [==============================] - 5s 77us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 72/150\n",
      "60000/60000 [==============================] - 8s 132us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 73/150\n",
      "60000/60000 [==============================] - 65s 1ms/sample - loss: nan - acc: 0.1000\n",
      "Epoch 74/150\n",
      "60000/60000 [==============================] - 50s 826us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 75/150\n",
      "60000/60000 [==============================] - 51s 850us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 76/150\n",
      "60000/60000 [==============================] - 67s 1ms/sample - loss: nan - acc: 0.1000\n",
      "Epoch 77/150\n",
      "60000/60000 [==============================] - 25s 421us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 78/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 4s 74us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 79/150\n",
      "60000/60000 [==============================] - 4s 75us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 80/150\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 81/150\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 82/150\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 83/150\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 84/150\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 85/150\n",
      "60000/60000 [==============================] - 5s 90us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 86/150\n",
      "60000/60000 [==============================] - 25s 419us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 87/150\n",
      "60000/60000 [==============================] - 55s 919us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 88/150\n",
      "60000/60000 [==============================] - 60s 1ms/sample - loss: nan - acc: 0.1000\n",
      "Epoch 89/150\n",
      "60000/60000 [==============================] - 51s 858us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 90/150\n",
      "60000/60000 [==============================] - 54s 894us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 91/150\n",
      "60000/60000 [==============================] - 20s 327us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 92/150\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 93/150\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 94/150\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 95/150\n",
      "60000/60000 [==============================] - 4s 74us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 96/150\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 97/150\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 98/150\n",
      "60000/60000 [==============================] - 4s 74us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 99/150\n",
      "60000/60000 [==============================] - 7s 115us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 100/150\n",
      "60000/60000 [==============================] - 40s 671us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 101/150\n",
      "60000/60000 [==============================] - 51s 857us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 102/150\n",
      "60000/60000 [==============================] - 62s 1ms/sample - loss: nan - acc: 0.1000\n",
      "Epoch 103/150\n",
      "60000/60000 [==============================] - 55s 924us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 104/150\n",
      "60000/60000 [==============================] - 49s 816us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 105/150\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 106/150\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 107/150\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 108/150\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 109/150\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 110/150\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 111/150\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 112/150\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 113/150\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 114/150\n",
      "60000/60000 [==============================] - 59s 980us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 115/150\n",
      "60000/60000 [==============================] - 52s 867us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 116/150\n",
      "60000/60000 [==============================] - 50s 840us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 117/150\n",
      "60000/60000 [==============================] - 63s 1ms/sample - loss: nan - acc: 0.1000\n",
      "Epoch 118/150\n",
      "60000/60000 [==============================] - 35s 577us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 119/150\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 120/150\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 121/150\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 122/150\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 123/150\n",
      "60000/60000 [==============================] - 4s 74us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 124/150\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 125/150\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 126/150\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 127/150\n",
      "60000/60000 [==============================] - 14s 240us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 128/150\n",
      "60000/60000 [==============================] - 52s 867us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 129/150\n",
      "60000/60000 [==============================] - 64s 1ms/sample - loss: nan - acc: 0.1000\n",
      "Epoch 130/150\n",
      "60000/60000 [==============================] - 49s 818us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 131/150\n",
      "60000/60000 [==============================] - 50s 834us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 132/150\n",
      "60000/60000 [==============================] - 35s 591us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 133/150\n",
      "60000/60000 [==============================] - 6s 92us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 134/150\n",
      "60000/60000 [==============================] - 4s 74us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 135/150\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 136/150\n",
      "60000/60000 [==============================] - 4s 74us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 137/150\n",
      "60000/60000 [==============================] - 4s 74us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 138/150\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 139/150\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 140/150\n",
      "60000/60000 [==============================] - 6s 99us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 141/150\n",
      "60000/60000 [==============================] - 35s 576us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 142/150\n",
      "60000/60000 [==============================] - 53s 880us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 143/150\n",
      "60000/60000 [==============================] - 51s 853us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 144/150\n",
      "60000/60000 [==============================] - 61s 1ms/sample - loss: nan - acc: 0.1000\n",
      "Epoch 145/150\n",
      "60000/60000 [==============================] - 50s 827us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 146/150\n",
      "60000/60000 [==============================] - 14s 232us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 147/150\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 148/150\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 149/150\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: nan - acc: 0.1000\n",
      "Epoch 150/150\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: nan - acc: 0.1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6e4b954b38>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fashion_model.fit(X_train,y_train, epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 48us/sample - loss: nan - acc: 0.1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[nan, 0.1]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fashion_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = fashion_model.fit(X_train, y_train, batch_size=32, epochs=150, validation_split=.1, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = fashion_model.history.epoch\n",
    "loss = fashion_model.history.history['loss']\n",
    "accuracy = fashion_model.history,history['acc']\n",
    "\n",
    "results_accuracy = pd.DataFrame({'epochs':epochs,'accuracy':accuracy})\n",
    "results_loss = pd.DataFrame({'epochs':epochs,'loss': loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_accuracy.plot.line(x='epochs', y='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_loss.plot.line(x='epochs', y='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zv_3xNMjzdLI"
   },
   "source": [
    "## Stretch Goals:\n",
    "\n",
    "- Use Hyperparameter Tuning to make the accuracy of your models as high as possible. (error as low as possible)\n",
    "- Use Cross Validation techniques to get more consistent results with your model.\n",
    "- Use GridSearchCV to try different combinations of hyperparameters. \n",
    "- Start looking into other types of Keras layers for CNNs and RNNs maybe try and build a CNN model for fashion-MNIST to see how the results compare."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "LS_DS_433_Keras_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
