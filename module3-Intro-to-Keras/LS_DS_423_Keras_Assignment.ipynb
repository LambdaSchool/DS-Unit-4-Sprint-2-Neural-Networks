{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LS_DS_433_Keras_Assignment.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pBQsZEJmubLs"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "\n",
        "# Neural Network Framework (Keras)\n",
        "\n",
        "## *Data Science Unit 4 Sprint 2 Assignment 3*\n",
        "\n",
        "## Use the Keras Library to build a Multi-Layer Perceptron Model on the Boston Housing dataset\n",
        "\n",
        "- The Boston Housing dataset comes with the Keras library so use Keras to import it into your notebook. \n",
        "- Normalize the data (all features should have roughly the same scale)\n",
        "- Import the type of model and layers that you will need from Keras.\n",
        "- Instantiate a model object and use `model.add()` to add layers to your model\n",
        "- Since this is a regression model you will have a single output node in the final layer.\n",
        "- Use activation functions that are appropriate for this task\n",
        "- Compile your model\n",
        "- Fit your model and report its accuracy in terms of Mean Squared Error\n",
        "- Use the history object that is returned from model.fit to make graphs of the model's loss or train/validation accuracies by epoch. \n",
        "- Run this same data through a linear regression model. Which achieves higher accuracy?\n",
        "- Do a little bit of feature engineering and see how that affects your neural network model. (you will need to change your model to accept more inputs)\n",
        "- After feature engineering, which model sees a greater accuracy boost due to the new features?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8NLTAR87uYJ-",
        "colab": {}
      },
      "source": [
        "##### Your Code Here #####\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import boston_housing\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "import numpy as np "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80XlhRP_LHEH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d32617db-f06a-46e4-d667-82a9fdb9e008"
      },
      "source": [
        "# train/test\n",
        "(X_train, y_train), (X_test, y_test) = boston_housing.load_data()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
            "57344/57026 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05X3Kp1cLcmQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "336922fe-97e8-4c2c-b201-aea93b5c1571"
      },
      "source": [
        "print(X_train.shape, y_train.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(404, 13) (404,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8frRyCq_LQ4d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
        "stop = EarlyStopping(monitor='val_accuracy', min_delta=0.01, patience=3)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(10, input_dim=13, activation = 'selu'))\n",
        "model.add(Dense(1, activation='linear'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-va82M5L-wE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 819
        },
        "outputId": "8778312a-5631-4abc-b7aa-9bed953b0bde"
      },
      "source": [
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "\n",
        "model.fit(X_train, y_train, epochs=15, \n",
        "          validation_data=(X_test,y_test),\n",
        "          callbacks=[stop])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            " 1/13 [=>............................] - ETA: 0s - loss: 4505.9395WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,val_loss\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 2947.4038 - val_loss: 1970.7661\n",
            "Epoch 2/15\n",
            " 1/13 [=>............................] - ETA: 0s - loss: 2894.3999WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,val_loss\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 2160.8953 - val_loss: 1356.2853\n",
            "Epoch 3/15\n",
            " 1/13 [=>............................] - ETA: 0s - loss: 876.6644WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,val_loss\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 1611.6306 - val_loss: 940.5709\n",
            "Epoch 4/15\n",
            " 1/13 [=>............................] - ETA: 0s - loss: 1491.7562WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,val_loss\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 1229.4425 - val_loss: 684.1331\n",
            "Epoch 5/15\n",
            " 1/13 [=>............................] - ETA: 0s - loss: 285.4409WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,val_loss\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 972.4364 - val_loss: 552.7971\n",
            "Epoch 6/15\n",
            " 1/13 [=>............................] - ETA: 0s - loss: 627.8146WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,val_loss\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 815.4077 - val_loss: 480.8260\n",
            "Epoch 7/15\n",
            " 1/13 [=>............................] - ETA: 0s - loss: 831.9277WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,val_loss\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 711.1106 - val_loss: 434.9244\n",
            "Epoch 8/15\n",
            " 1/13 [=>............................] - ETA: 0s - loss: 1007.0330WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,val_loss\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 630.3768 - val_loss: 403.3676\n",
            "Epoch 9/15\n",
            " 1/13 [=>............................] - ETA: 0s - loss: 325.6566WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,val_loss\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 570.3771 - val_loss: 379.0565\n",
            "Epoch 10/15\n",
            " 1/13 [=>............................] - ETA: 0s - loss: 371.6007WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,val_loss\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 522.6172 - val_loss: 358.2575\n",
            "Epoch 11/15\n",
            " 1/13 [=>............................] - ETA: 0s - loss: 1130.5159WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,val_loss\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 481.1939 - val_loss: 338.3866\n",
            "Epoch 12/15\n",
            " 1/13 [=>............................] - ETA: 0s - loss: 316.2631WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,val_loss\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 443.3602 - val_loss: 319.4721\n",
            "Epoch 13/15\n",
            " 1/13 [=>............................] - ETA: 0s - loss: 421.6985WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,val_loss\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 408.1791 - val_loss: 300.8390\n",
            "Epoch 14/15\n",
            " 1/13 [=>............................] - ETA: 0s - loss: 547.1962WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,val_loss\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 379.9638 - val_loss: 286.2618\n",
            "Epoch 15/15\n",
            " 1/13 [=>............................] - ETA: 0s - loss: 275.5135WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,val_loss\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 353.6600 - val_loss: 270.0778\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3a0fd56588>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SfcFnOONyuNm"
      },
      "source": [
        "## Use the Keras Library to build an image recognition network using the Fashion-MNIST dataset (also comes with keras)\n",
        "\n",
        "- Load and preprocess the image data similar to how we preprocessed the MNIST data in class.\n",
        "- Make sure to one-hot encode your category labels\n",
        "- The number of nodes in your output layer should equal the number of classes you want to predict for Fashion-MNIST.\n",
        "- Try different hyperparameters. What is the highest accuracy that you are able to achieve.\n",
        "- Use the history object that is returned from model.fit to make graphs of the model's loss or train/validation accuracies by epoch. \n",
        "- Remember that neural networks fall prey to randomness so you may need to run your model multiple times (or use Cross Validation) in order to tell if a change to a hyperparameter is truly producing better results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxKJcZT6OOEu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6fa521fe-32dd-453c-8aec-4a67d971dd59"
      },
      "source": [
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "print(X_train.shape, y_train.shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28) (60000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "szi6-IpuzaH1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "7a4e8d37-c70a-4c10-f473-e00873224e7f"
      },
      "source": [
        "stop = EarlyStopping(monitor='val_accuracy', min_delta=0.01, patience=3)\n",
        "\n",
        "# model, compile, fit\n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(28,28)))\n",
        "model.add(Dense(10, input_dim=28, activation=\"relu\"))\n",
        "model.add(Dense(15, activation='softmax'))\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.fit(x=X_train, \n",
        "        y=y_train, \n",
        "        epochs=5, \n",
        "        validation_data=(X_test, y_test), \n",
        "        callbacks=[stop])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 2.2383 - accuracy: 0.1944 - val_loss: 1.8396 - val_accuracy: 0.2278\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 1.7426 - accuracy: 0.2722 - val_loss: 1.7117 - val_accuracy: 0.3176\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 1.6301 - accuracy: 0.3256 - val_loss: 1.5713 - val_accuracy: 0.3515\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 1.5632 - accuracy: 0.3479 - val_loss: 1.5371 - val_accuracy: 0.3614\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 1.5316 - accuracy: 0.3583 - val_loss: 1.5165 - val_accuracy: 0.3618\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3a10cb9dd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcXUn0_LPJDe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "72cc406d-5708-48b0-b43a-e61cb967b280"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_1 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 10)                7850      \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 15)                165       \n",
            "=================================================================\n",
            "Total params: 8,015\n",
            "Trainable params: 8,015\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F98VW4dLPEpf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "67064826-ac08-46c9-8687-ecb987f2aa6f"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(X_train[5])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f3a10a63eb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zv_3xNMjzdLI"
      },
      "source": [
        "## Stretch Goals:\n",
        "\n",
        "- Use Hyperparameter Tuning to make the accuracy of your models as high as possible. (error as low as possible)\n",
        "- Use Cross Validation techniques to get more consistent results with your model.\n",
        "- Use GridSearchCV to try different combinations of hyperparameters. \n",
        "- Start looking into other types of Keras layers for CNNs and RNNs maybe try and build a CNN model for fashion-MNIST to see how the results compare."
      ]
    }
  ]
}