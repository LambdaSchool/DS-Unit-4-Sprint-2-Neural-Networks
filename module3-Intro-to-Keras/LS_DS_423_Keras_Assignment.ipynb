{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pBQsZEJmubLs"
   },
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "\n",
    "# Neural Network Framework (Keras)\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2 Assignment 3*\n",
    "\n",
    "## Use the Keras Library to build a Multi-Layer Perceptron Model on the Boston Housing dataset\n",
    "\n",
    "- The Boston Housing dataset comes with the Keras library so use Keras to import it into your notebook. \n",
    "- Normalize the data (all features should have roughly the same scale)\n",
    "- Import the type of model and layers that you will need from Keras.\n",
    "- Instantiate a model object and use `model.add()` to add layers to your model\n",
    "- Since this is a regression model you will have a single output node in the final layer.\n",
    "- Use activation functions that are appropriate for this task\n",
    "- Compile your model\n",
    "- Fit your model and report its accuracy in terms of Mean Squared Error\n",
    "- Use the history object that is returned from model.fit to make graphs of the model's loss or train/validation accuracies by epoch. \n",
    "- Run this same data through a linear regression model. Which achieves higher accuracy?\n",
    "- Do a little bit of feature engineering and see how that affects your neural network model. (you will need to change your model to accept more inputs)\n",
    "- After feature engineering, which model sees a greater accuracy boost due to the new features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8NLTAR87uYJ-",
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "##### Your Code Here #####\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.datasets import boston_housing\n",
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n57344/57026 [==============================] - 0s 1us/step\n"
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The shape of the x train is:  (404, 13)\nThe shape of the y_train is: (404,)\nThe shape of the x_test is : (102, 13)\nThe shape of the y_test is: (102,)\n"
    }
   ],
   "source": [
    "print(f\"The shape of the x train is:  {x_train.shape}\")\n",
    "print(f\"The shape of the y_train is: {y_train.shape}\")\n",
    "print(f\"The shape of the x_test is : {x_test.shape}\")\n",
    "print(f\"The shape of the y_test is: {y_test.shape}\")\n",
    "# Will not need to flatten anything becuase it is only a two dimensional array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[  1.23247,   0.     ,   8.14   ,   0.     ,   0.538  ,   6.142  ,\n         91.7    ,   3.9769 ,   4.     , 307.     ,  21.     , 396.9    ,\n         18.72   ]])"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# looking at the shape of one row of the data\n",
    "# and what is in it\n",
    "x_train[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "numpy.ndarray"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "type(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that will do the normalization\n",
    "def normalization(num_array):\n",
    "     arr =  num_array/np.amax(num_array, axis=0)\n",
    "     return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing the normalization\n",
    "x_train_norm = normalization(x_train)\n",
    "x_test_norm = normalization(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([  1.23247,   0.     ,   8.14   ,   0.     ,   0.538  ,   6.142  ,\n        91.7    ,   3.9769 ,   4.     , 307.     ,  21.     , 396.9    ,\n        18.72   ])"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "# Looking at the difference between the non normalized and the \n",
    "# normalized version\n",
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([0.72205254, 0.        , 0.65248738, 0.        , 0.77956372,\n       0.73280182, 1.        , 0.15129675, 1.        , 0.93670886,\n       0.95283019, 0.06865709, 0.90809628])"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "x_test_norm[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciating the model\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the callback function that I want to use\n",
    "the_callback = EarlyStopping(patience=1, monitor=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Builing the model\n",
    "# adding layers to the model\n",
    "model.add(Dense(64, input_shape=(13,), activation=\"relu\"))\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "#model.add(Dense(128, activation=\"relu\"))\n",
    "#model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dense(1, activation=\"linear\"))\n",
    "\n",
    "# Doing the compiliation of the model\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\", metrics=['mse', \"mae\", ], callbacks=[the_callback] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 64)                896       \n_________________________________________________________________\ndense_1 (Dense)              (None, 64)                4160      \n_________________________________________________________________\ndense_2 (Dense)              (None, 1)                 65        \n=================================================================\nTotal params: 5,121\nTrainable params: 5,121\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "# looking at the summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 404 samples, validate on 102 samples\nEpoch 1/10\n404/404 [==============================] - 1s 1ms/sample - loss: 479.8048 - mse: 479.8048 - mae: 19.6642 - val_loss: 301.9253 - val_mse: 301.9253 - val_mae: 14.9092\nEpoch 2/10\n404/404 [==============================] - 0s 82us/sample - loss: 165.0206 - mse: 165.0206 - mae: 9.6716 - val_loss: 93.5754 - val_mse: 93.5754 - val_mae: 7.1195\nEpoch 3/10\n404/404 [==============================] - 0s 84us/sample - loss: 99.8971 - mse: 99.8971 - mae: 8.0765 - val_loss: 93.4820 - val_mse: 93.4820 - val_mae: 7.3892\nEpoch 4/10\n404/404 [==============================] - 0s 82us/sample - loss: 84.1717 - mse: 84.1717 - mae: 6.8542 - val_loss: 88.6042 - val_mse: 88.6042 - val_mae: 6.8175\nEpoch 5/10\n404/404 [==============================] - 0s 82us/sample - loss: 80.5323 - mse: 80.5323 - mae: 6.4372 - val_loss: 78.8232 - val_mse: 78.8232 - val_mae: 6.4409\nEpoch 6/10\n404/404 [==============================] - 0s 94us/sample - loss: 75.2753 - mse: 75.2753 - mae: 6.4787 - val_loss: 74.2272 - val_mse: 74.2272 - val_mae: 6.2803\nEpoch 7/10\n404/404 [==============================] - 0s 87us/sample - loss: 70.7225 - mse: 70.7225 - mae: 6.0883 - val_loss: 72.3052 - val_mse: 72.3052 - val_mae: 6.0771\nEpoch 8/10\n404/404 [==============================] - 0s 77us/sample - loss: 68.1761 - mse: 68.1761 - mae: 5.8901 - val_loss: 66.3743 - val_mse: 66.3743 - val_mae: 5.9562\nEpoch 9/10\n404/404 [==============================] - 0s 87us/sample - loss: 64.1484 - mse: 64.1484 - mae: 5.8096 - val_loss: 64.1718 - val_mse: 64.1718 - val_mae: 5.7518\nEpoch 10/10\n404/404 [==============================] - 0s 79us/sample - loss: 61.5412 - mse: 61.5412 - mae: 5.5166 - val_loss: 60.9666 - val_mse: 60.9666 - val_mae: 5.6351\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x1ed550e1cf8>"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "# Doing the fitting of the model\n",
    "model.fit(x=x_train_norm, y=y_train, epochs=10,  validation_data=(x_test_norm, y_test)\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will be training the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SfcFnOONyuNm"
   },
   "source": [
    "## Use the Keras Library to build an image recognition network using the Fashion-MNIST dataset (also comes with keras)\n",
    "\n",
    "- Load and preprocess the image data similar to how we preprocessed the MNIST data in class.\n",
    "- Make sure to one-hot encode your category labels\n",
    "- The number of nodes in your output layer should equal the number of classes you want to predict for Fashion-MNIST.\n",
    "- Try different hyperparameters. What is the highest accuracy that you are able to achieve.\n",
    "- Use the history object that is returned from model.fit to make graphs of the model's loss or train/validation accuracies by epoch. \n",
    "- Remember that neural networks fall prey to randomness so you may need to run your model multiple times (or use Cross Validation) in order to tell if a change to a hyperparameter is truly producing better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "szi6-IpuzaH1"
   },
   "outputs": [],
   "source": [
    "# Doing the Fashion-Minst\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.layers import Flatten\n",
    "# Doing an import to show an image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n32768/29515 [=================================] - 0s 1us/step\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n26427392/26421880 [==============================] - 5s 0us/step\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n8192/5148 [===============================================] - 0s 0us/step\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n4423680/4422102 [==============================] - 1s 0us/step\n"
    }
   ],
   "source": [
    "# Loading the data set \n",
    "(x_train, y_train), (x_test, y_test) =  fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The shape of the x_train is:  (60000, 28, 28)\nThe shape of the y_train is: (60000,)\nThe shape of the x_test is: (10000, 28, 28)\nThe shape of the y_test is: (10000,)\n"
    }
   ],
   "source": [
    "# Looking at the shapes of the data\n",
    "print(f\"The shape of the x_train is:  {x_train.shape}\")\n",
    "print(f\"The shape of the y_train is: {y_train.shape}\")\n",
    "print(f\"The shape of the x_test is: {x_test.shape}\")\n",
    "print(f\"The shape of the y_test is: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x1ed6092b278>"
     },
     "metadata": {},
     "execution_count": 27
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 251.565 248.518125\" width=\"251.565pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <defs>\r\n  <style type=\"text/css\">\r\n*{stroke-linecap:butt;stroke-linejoin:round;}\r\n  </style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 248.518125 \r\nL 251.565 248.518125 \r\nL 251.565 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 26.925 224.64 \r\nL 244.365 224.64 \r\nL 244.365 7.2 \r\nL 26.925 7.2 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g clip-path=\"url(#pfd451e123a)\">\r\n    <image height=\"218\" id=\"image570c3b9b8f\" transform=\"scale(1 -1)translate(0 -218)\" width=\"218\" x=\"26.925\" xlink:href=\"data:image/png;base64,\r\niVBORw0KGgoAAAANSUhEUgAAANoAAADaCAYAAADAHVzbAAAABHNCSVQICAgIfAhkiAAAC7RJREFUeJzt3V9s3WUdx/Hv+Z3z6zmn7Wm7dltLWVkZdG7ggCkbfxSmMAYSDBrmn4SYcGGiMRpj/JcoJnqJifFGDEbEKwhREp0aVHQLi1ucI24gMBiwrZusbGvX9c96zmnPPy+88Or5PJrDvhN9v24/e9qe0336S843z/Nktma2twzABZVc7B8A+H9A0QAHFA1wQNEABxQNcEDRAAcUDXBA0QAHFA1wQNEABxQNcEDRAAcUDXBA0QAHFA1wkLvYP8CFktm0QeaVoaLM82cXZT6/Wq/vObIQzJLFulzbfOEVmeOdhyca4ICiAQ4oGuCAogEOKBrggKIBDnKWZPW/aDYu2DdfuO8Gmd/wjed0XjoSzNZ17JNrU2vKvJDReVeSkXm1FT7FL/bXbU9lROaNyFfYdW69zGut8PrT5R65Ns229/+h2Qq/b5V6KtfOVgoyzyb65MTqs8tlPnCoFszyT+v/izE80QAHFA1wQNEABxQNcEDRAAcUDXBA0QAHmXavbZq9/8ZgtuZzh+XazX3HZH5g7jKZn5jvD2a1pv4bkiZ6TtaZLsm8kA3PXMzMOsS8KTH9ljdNz+i6svpn68rpLT49uWowK2XDmZlZEpkvxmTFa98/O9rW1y5FXnddzA/NzG7qDc9lHzt2s1zbe/cbMueJBjigaIADigY4oGiAA4oGOKBogAOKBjiIztGOPnST/ALfuvfnwWz3zDq59s2FPpnPLeVlvqIzfKTbqs4ZubY/Da81M+vNlWVeyOgj42Yb4ePoOhM9B2tE5minFntlXml2yLzWDO9BXBSZmVkxMj+sNPSesr60Eszm63q/2biYm5qZTUzr96W7U88I+4rh/K6hl+Xax390p8x5ogEOKBrggKIBDiga4ICiAQ4oGuCAogEOcs0tG+U/+Ni2vTJ/6vT1wWywMC/X3jP0oswPl4dkPlEJn0E4V9MzGTVLMjM7WdUzvpV5/douy58NZqUkPEsyM+vI6LMTh1M9I7y6Y0LmJ+rLgtmpun7dh8rDMh/Oz8r8xbnw+nJdz/+SjN7Ht7z3vMx783qOtqn/eDArN/RMt7JS/2w80QAHFA1wQNEABxQNcEDRAAcUDXBA0QAHufkRPR+IzS5uW/5qMJuqleTa5+f1PWCriudkvqY4GcyuzJ+Sa2Pzot9NXi3z2NmKU0n4tR+u6fngWPGMzO/sPiTz753eKvOP9h8IZh/uek2uvaWozy88tKRf2+r8VDCbaXTKtYtNvdft8rx+32qtnMyz4s68oZyeD/7hhVtkzhMNcEDRAAcUDXBA0QAHFA1wQNEAB7nyoO7aPT3Py/yJ6fC1TSOFabn2mv4TMh/I6m0PSinRWyK2FMPbWMzMuhJ9BdCzkaP0BtPwx8GrOvT78oFO/RH6A1/6sszrBX1c3Z7R8Naoepce5/Rcq9+3L1y5S+aFTPi4OpWZmZXEdVNm+kooM7Ns5OtnxZVUsSMAe17U7wtPNMABRQMcUDTAAUUDHFA0wAFFAxxQNMBB5o70k3L4cO1z+nqi20vh62zKLb0FpxrZ9jBRCx+LFpNP9MzkTC18VN3bYW0hvE1nU0HPD+//9ldkPn27nicdue2nMt9ZCR+1N1nX78svp/TxhAdO6K1PN44eC2YbSifl2tm63kZTyur3JbaNpi8JX9VVben/qw+PrZU5TzTAAUUDHFA0wAFFAxxQNMABRQMcUDTAQWZrZrucoy1+aJP8Aiu/eTSYXdfzplx7VVHPTWJztoKYlR2qXCrXlpv6iqBLOvTVSLGZjtrbdGZJH8P322NXyXzn5kdk/uDEXTK/rBjeD/fuov6d3dc9J/OYJ+fDs9E1HXrOdXRppcxjc1e1R9DMbDQNH184luqrtj418j6Z80QDHFA0wAFFAxxQNMABRQMcUDTAAUUDHETnaBdS7hJ9xU/t8kGZT68Pz7LKQ/ocvuvufkXmDwzukflkQ+/bSjPhfXzzjaJcO5TqGd6uWT1n687pMyl7s+GZ0HuK43LtTFPPD4dz+qqtr7+xPZgNds7LtY+uflrmtVZ4dmlmdrim90eWkvBVXH8qXynX/uKqFTLniQY4oGiAA4oGOKBogAOKBjigaICD6Mf7mZy+yb5V18fRvVNV7t0s879/pCHz+zfuD2a3dr8q1+4vXyFz9fG8mdmKnN7Koo5Om1jSW03U1iQzs/6cvmqrLxs+0q3R0n/3FyJbm8pN/fH9UGSbzPX58BGB2/Z/Vq4d2f6SzHmiAQ4oGuCAogEOKBrggKIBDiga4ICiAQ70kMz+jTlZJrwdJZPTx8VlspGeJzpvVsV2kKaec8UUd4TnYGZma3fo9c9Z+Gqkj4/r7SAbO8dlfqrWJ/M0o197Io7CW9VxVq6NzdGakVnYGXEt1EBWz+AuTfUWnNcX9barmYbe4rMq1x3MSr/SRwTG8EQDHFA0wAFFAxxQNMABRQMcUDTAAUUDHETnaFGt8Ha2Vi18fNc/87a/+wWTSfXep9hrU774mc/L/PuPPCzz1PScrCMyR1tqhWd8o3l91N1k5Ki8A5XLZV6K7KWTa5OqzGPzw9h+t4fOjgWzxV59fGEMTzTAAUUDHFA0wAFFAxxQNMABRQMcUDTAQftztP9RsTlZUijIvFkNz3ymNugZ3fKsHjC+VtP7qmot/WutiTnas/Pr5drzDX124s2lN2Su9oTFrrNqmJ5lxfbK3VY8LvMtj381mJW2Tcm1S69vkjlPNMABRQMcUDTAAUUDHFA0wAFFAxxQNMABc7QQcV6lWXv3wo385BWZ7/r0qMyzGXmlnU3W9RmE6o6ytxZ75dqXz+qzE+/u+5vMjy6uDGbDHfrcxtg+u4mavtvtwNJymW/beiCYjRSm5dpnarfKnCca4ICiAQ4oGuCAogEOKBrggKIBDvh4P0Qco2fW3sf7jXP6Y+zdM+tk/onlf5G52gZjprejlHL6SLf+Yng0YGb26uIlMk+T8Ps2XQ9fm2QW30YzkuqP4GcaXTL/2uDOYPbw2ffLtbmdf5U5TzTAAUUDHFA0wAFFAxxQNMABRQMcUDTAAXO0/0KTi3qeVG2lMl+KHDc3nIbneO/KT8i1AwMLMp9s6C066mdX10mZxbfJVJv6fSlk9HF0avXe02vk2i47KnOeaIADigY4oGiAA4oGOKBogAOKBjigaIAD5mghkePm2hLZ6zbWfUbmA9nzbeVZC3//hZa+Umq8po9si1FH4cWum3r09Ztlfv6oPiovqevf6R0fPBjMvjO2Q679rm3Q31umAN4WFA1wQNEABxQNcEDRAAcUDXBA0QAHzNFCIrOuqDbmcPse2izzZQ/qsxXXF/SesvlmIZjF9rLF/ODwFpkviFlXshR5zyJxa3BJ5vWafq7se2xjMHvh3mG5NnPfCpnzRAMcUDTAAUUDHFA0wAFFAxxQNMABRQMcZLZmtrc5MIK3Y09eI/Of3fBjmf9m/tpgtntyTK49uWtE5o1r9F64NA2fzdg8qPeTDbykz3XsOfiWzKduvVTmk+8NV2Fwn1xqy/54ROY80QAHFA1wQNEABxQNcEDRAAcUDXDANpmLICmEt6mYmTWrVZl3HNTXOj217nqZ750MX0F0/LUhubZ1hd6KkjveJfPVPzwZzOrjL8u1MfVI3jd+QuYDv14WDht6tNCYm5M5TzTAAUUDHFA0wAFFAxxQNMABRQMcUDTAAXO0i6BVj018tJHfz8j88dGbZJ5Uwn9fV+1uyrW5iowtfebPMm/rlUeO8Mtks5H1+rnSOHfuP/2J/vWlc7pKPNEABxQNcEDRAAcUDXBA0QAHFA1wQNEABxw3dzHErnRq88qo7EC/zM/duTaY9TwROVctJjbryqXBrFXTe90uuDau2or9zniiAQ4oGuCAogEOKBrggKIBDiga4ICiAQ6YowEOeKIBDiga4ICiAQ4oGuCAogEOKBrggKIBDiga4ICiAQ4oGuCAogEOKBrggKIBDiga4ICiAQ4oGuCAogEOKBrggKIBDiga4ICiAQ4oGuDgH1KqoiL0Lpl9AAAAAElFTkSuQmCC\" y=\"-6.64\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"mb0ca4cc5c2\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.807857\" xlink:href=\"#mb0ca4cc5c2\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 0 -->\r\n      <defs>\r\n       <path d=\"M 31.78125 66.40625 \r\nQ 24.171875 66.40625 20.328125 58.90625 \r\nQ 16.5 51.421875 16.5 36.375 \r\nQ 16.5 21.390625 20.328125 13.890625 \r\nQ 24.171875 6.390625 31.78125 6.390625 \r\nQ 39.453125 6.390625 43.28125 13.890625 \r\nQ 47.125 21.390625 47.125 36.375 \r\nQ 47.125 51.421875 43.28125 58.90625 \r\nQ 39.453125 66.40625 31.78125 66.40625 \r\nz\r\nM 31.78125 74.21875 \r\nQ 44.046875 74.21875 50.515625 64.515625 \r\nQ 56.984375 54.828125 56.984375 36.375 \r\nQ 56.984375 17.96875 50.515625 8.265625 \r\nQ 44.046875 -1.421875 31.78125 -1.421875 \r\nQ 19.53125 -1.421875 13.0625 8.265625 \r\nQ 6.59375 17.96875 6.59375 36.375 \r\nQ 6.59375 54.828125 13.0625 64.515625 \r\nQ 19.53125 74.21875 31.78125 74.21875 \r\nz\r\n\" id=\"DejaVuSans-48\"/>\r\n      </defs>\r\n      <g transform=\"translate(27.626607 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_2\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"69.636429\" xlink:href=\"#mb0ca4cc5c2\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 5 -->\r\n      <defs>\r\n       <path d=\"M 10.796875 72.90625 \r\nL 49.515625 72.90625 \r\nL 49.515625 64.59375 \r\nL 19.828125 64.59375 \r\nL 19.828125 46.734375 \r\nQ 21.96875 47.46875 24.109375 47.828125 \r\nQ 26.265625 48.1875 28.421875 48.1875 \r\nQ 40.625 48.1875 47.75 41.5 \r\nQ 54.890625 34.8125 54.890625 23.390625 \r\nQ 54.890625 11.625 47.5625 5.09375 \r\nQ 40.234375 -1.421875 26.90625 -1.421875 \r\nQ 22.3125 -1.421875 17.546875 -0.640625 \r\nQ 12.796875 0.140625 7.71875 1.703125 \r\nL 7.71875 11.625 \r\nQ 12.109375 9.234375 16.796875 8.0625 \r\nQ 21.484375 6.890625 26.703125 6.890625 \r\nQ 35.15625 6.890625 40.078125 11.328125 \r\nQ 45.015625 15.765625 45.015625 23.390625 \r\nQ 45.015625 31 40.078125 35.4375 \r\nQ 35.15625 39.890625 26.703125 39.890625 \r\nQ 22.75 39.890625 18.8125 39.015625 \r\nQ 14.890625 38.140625 10.796875 36.28125 \r\nz\r\n\" id=\"DejaVuSans-53\"/>\r\n      </defs>\r\n      <g transform=\"translate(66.455179 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_3\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"108.465\" xlink:href=\"#mb0ca4cc5c2\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 10 -->\r\n      <defs>\r\n       <path d=\"M 12.40625 8.296875 \r\nL 28.515625 8.296875 \r\nL 28.515625 63.921875 \r\nL 10.984375 60.40625 \r\nL 10.984375 69.390625 \r\nL 28.421875 72.90625 \r\nL 38.28125 72.90625 \r\nL 38.28125 8.296875 \r\nL 54.390625 8.296875 \r\nL 54.390625 0 \r\nL 12.40625 0 \r\nz\r\n\" id=\"DejaVuSans-49\"/>\r\n      </defs>\r\n      <g transform=\"translate(102.1025 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"147.293571\" xlink:href=\"#mb0ca4cc5c2\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 15 -->\r\n      <g transform=\"translate(140.931071 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_5\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"186.122143\" xlink:href=\"#mb0ca4cc5c2\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 20 -->\r\n      <defs>\r\n       <path d=\"M 19.1875 8.296875 \r\nL 53.609375 8.296875 \r\nL 53.609375 0 \r\nL 7.328125 0 \r\nL 7.328125 8.296875 \r\nQ 12.9375 14.109375 22.625 23.890625 \r\nQ 32.328125 33.6875 34.8125 36.53125 \r\nQ 39.546875 41.84375 41.421875 45.53125 \r\nQ 43.3125 49.21875 43.3125 52.78125 \r\nQ 43.3125 58.59375 39.234375 62.25 \r\nQ 35.15625 65.921875 28.609375 65.921875 \r\nQ 23.96875 65.921875 18.8125 64.3125 \r\nQ 13.671875 62.703125 7.8125 59.421875 \r\nL 7.8125 69.390625 \r\nQ 13.765625 71.78125 18.9375 73 \r\nQ 24.125 74.21875 28.421875 74.21875 \r\nQ 39.75 74.21875 46.484375 68.546875 \r\nQ 53.21875 62.890625 53.21875 53.421875 \r\nQ 53.21875 48.921875 51.53125 44.890625 \r\nQ 49.859375 40.875 45.40625 35.40625 \r\nQ 44.1875 33.984375 37.640625 27.21875 \r\nQ 31.109375 20.453125 19.1875 8.296875 \r\nz\r\n\" id=\"DejaVuSans-50\"/>\r\n      </defs>\r\n      <g transform=\"translate(179.759643 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_6\">\r\n     <g id=\"line2d_6\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"224.950714\" xlink:href=\"#mb0ca4cc5c2\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 25 -->\r\n      <g transform=\"translate(218.588214 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_7\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"m688ca5c92d\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m688ca5c92d\" y=\"11.082857\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(13.5625 14.882076)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_8\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m688ca5c92d\" y=\"49.911429\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- 5 -->\r\n      <g transform=\"translate(13.5625 53.710647)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_9\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m688ca5c92d\" y=\"88.74\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 10 -->\r\n      <g transform=\"translate(7.2 92.539219)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_10\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m688ca5c92d\" y=\"127.568571\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 15 -->\r\n      <g transform=\"translate(7.2 131.36779)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_11\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m688ca5c92d\" y=\"166.397143\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_11\">\r\n      <!-- 20 -->\r\n      <g transform=\"translate(7.2 170.196362)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_6\">\r\n     <g id=\"line2d_12\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m688ca5c92d\" y=\"205.225714\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_12\">\r\n      <!-- 25 -->\r\n      <g transform=\"translate(7.2 209.024933)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 26.925 224.64 \r\nL 26.925 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 244.365 224.64 \r\nL 244.365 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 26.925 224.64 \r\nL 244.365 224.64 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 26.925 7.2 \r\nL 244.365 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"pfd451e123a\">\r\n   <rect height=\"217.44\" width=\"217.44\" x=\"26.925\" y=\"7.2\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "# Looking at the shoe, this is just one of the images\n",
    "plt.imshow(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,\n          0,   0,  13,  73,   0,   0,   1,   4,   0,   0,   0,   0,   1,\n          1,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n          0,  36, 136, 127,  62,  54,   0,   0,   0,   1,   3,   4,   0,\n          0,   3],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,\n          0, 102, 204, 176, 134, 144, 123,  23,   0,   0,   0,   0,  12,\n         10,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0, 155, 236, 207, 178, 107, 156, 161, 109,  64,  23,  77, 130,\n         72,  15],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,\n         69, 207, 223, 218, 216, 216, 163, 127, 121, 122, 146, 141,  88,\n        172,  66],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   1,   1,   0,\n        200, 232, 232, 233, 229, 223, 223, 215, 213, 164, 127, 123, 196,\n        229,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n        183, 225, 216, 223, 228, 235, 227, 224, 222, 224, 221, 223, 245,\n        173,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n        193, 228, 218, 213, 198, 180, 212, 210, 211, 213, 223, 220, 243,\n        202,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   3,   0,  12,\n        219, 220, 212, 218, 192, 169, 227, 208, 218, 224, 212, 226, 197,\n        209,  52],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,   0,  99,\n        244, 222, 220, 218, 203, 198, 221, 215, 213, 222, 220, 245, 119,\n        167,  56],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,  55,\n        236, 228, 230, 228, 240, 232, 213, 218, 223, 234, 217, 217, 209,\n         92,   0],\n       [  0,   0,   1,   4,   6,   7,   2,   0,   0,   0,   0,   0, 237,\n        226, 217, 223, 222, 219, 222, 221, 216, 223, 229, 215, 218, 255,\n         77,   0],\n       [  0,   3,   0,   0,   0,   0,   0,   0,   0,  62, 145, 204, 228,\n        207, 213, 221, 218, 208, 211, 218, 224, 223, 219, 215, 224, 244,\n        159,   0],\n       [  0,   0,   0,   0,  18,  44,  82, 107, 189, 228, 220, 222, 217,\n        226, 200, 205, 211, 230, 224, 234, 176, 188, 250, 248, 233, 238,\n        215,   0],\n       [  0,  57, 187, 208, 224, 221, 224, 208, 204, 214, 208, 209, 200,\n        159, 245, 193, 206, 223, 255, 255, 221, 234, 221, 211, 220, 232,\n        246,   0],\n       [  3, 202, 228, 224, 221, 211, 211, 214, 205, 205, 205, 220, 240,\n         80, 150, 255, 229, 221, 188, 154, 191, 210, 204, 209, 222, 228,\n        225,   0],\n       [ 98, 233, 198, 210, 222, 229, 229, 234, 249, 220, 194, 215, 217,\n        241,  65,  73, 106, 117, 168, 219, 221, 215, 217, 223, 223, 224,\n        229,  29],\n       [ 75, 204, 212, 204, 193, 205, 211, 225, 216, 185, 197, 206, 198,\n        213, 240, 195, 227, 245, 239, 223, 218, 212, 209, 222, 220, 221,\n        230,  67],\n       [ 48, 203, 183, 194, 213, 197, 185, 190, 194, 192, 202, 214, 219,\n        221, 220, 236, 225, 216, 199, 206, 186, 181, 177, 172, 181, 205,\n        206, 115],\n       [  0, 122, 219, 193, 179, 171, 183, 196, 204, 210, 213, 207, 211,\n        210, 200, 196, 194, 191, 195, 191, 198, 192, 176, 156, 167, 177,\n        210,  92],\n       [  0,   0,  74, 189, 212, 191, 175, 172, 175, 181, 185, 188, 189,\n        188, 193, 198, 204, 209, 210, 210, 211, 188, 188, 194, 192, 216,\n        170,   0],\n       [  2,   0,   0,   0,  66, 200, 222, 237, 239, 242, 246, 243, 244,\n        221, 220, 193, 191, 179, 182, 182, 181, 176, 166, 168,  99,  58,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,  40,  61,  44,  72,  41,  35,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0]], dtype=uint8)"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "# Looking at one the arrays\n",
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function used to normalize the data\n",
    "def normalize_img(num_array):\n",
    "    arry = num_array/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_norm = normalize_img(x_train)\n",
    "x_test_norm = normalize_img(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function that will create the model\n",
    "def create_model(input_shape = (28,28), flatten=False ):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # if the flatten flage is set to true will flatten the array\n",
    "    if flatten == True:\n",
    "        model.add(Flatten(input_shape=input_shape)))\n",
    "        input_shape = None\n",
    "    if input_shape != None:\n",
    "        model.add(Dense(128, input_shape=input_shape))\n",
    "    else:\n",
    "        model.add(Dense(128))\n",
    "    model.compile()\n",
    "    model.add(Dense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the model\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zv_3xNMjzdLI"
   },
   "source": [
    "## Stretch Goals:\n",
    "\n",
    "- Use Hyperparameter Tuning to make the accuracy of your models as high as possible. (error as low as possible)\n",
    "- Use Cross Validation techniques to get more consistent results with your model.\n",
    "- Use GridSearchCV to try different combinations of hyperparameters. \n",
    "- Start looking into other types of Keras layers for CNNs and RNNs maybe try and build a CNN model for fashion-MNIST to see how the results compare."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "LS_DS_433_Keras_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "lam4-nnf-s2 (Python3)",
   "language": "python",
   "name": "lam4-nnf-s2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}