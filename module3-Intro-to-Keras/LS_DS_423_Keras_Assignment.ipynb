{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pBQsZEJmubLs"
   },
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "\n",
    "# Neural Network Framework (Keras)\n",
    "\n",
    "# reduce hidden layers slower, dont drop NAN columns",
    "\n",
    "## *Data Science Unit 4 Sprint 2 Assignmnet 3*\n",
    "\n",
    "## Use the Keras Library to build a Multi-Layer Perceptron Model on the Boston Housing dataset\n",
    "\n",
    "- The Boston Housing dataset comes with the Keras library so use Keras to import it into your notebook. \n",
    "- Normalize the data (all features should have roughly the same scale)\n",
    "- Import the type of model and layers that you will need from Keras.\n",
    "- Instantiate a model object and use `model.add()` to add layers to your model\n",
    "- Since this is a regression model you will have a single output node in the final layer.\n",
    "- Use activation functions that are appropriate for this task\n",
    "- Compile your model\n",
    "- Fit your model and report its accuracy in terms of Mean Squared Error\n",
    "- Use the history object that is returned from model.fit to make graphs of the model's loss or train/validation accuracies by epoch. \n",
    "- Run this same data through a linear regression model. Which achieves higher accuracy?\n",
    "- Do a little bit of feature engineering and see how that affects your neural network model. (you will need to change your model to accept more inputs)\n",
    "- After feature engineering, which model sees a greater accuracy boost due to the new features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8NLTAR87uYJ-"
   },
   "outputs": [],
   "source": [
    "# from tensorflow.keras.datasets import boston_housing (Not using this)\n",
    "# from tensorflow.keras.datasets.mnist import load_data\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./amesHousePrice.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 81)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Condition1</th>\n",
       "      <th>Condition2</th>\n",
       "      <th>BldgType</th>\n",
       "      <th>HouseStyle</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>RoofStyle</th>\n",
       "      <th>RoofMatl</th>\n",
       "      <th>Exterior1st</th>\n",
       "      <th>Exterior2nd</th>\n",
       "      <th>MasVnrType</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>ExterQual</th>\n",
       "      <th>ExterCond</th>\n",
       "      <th>Foundation</th>\n",
       "      <th>BsmtQual</th>\n",
       "      <th>BsmtCond</th>\n",
       "      <th>BsmtExposure</th>\n",
       "      <th>BsmtFinType1</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinType2</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>Heating</th>\n",
       "      <th>HeatingQC</th>\n",
       "      <th>CentralAir</th>\n",
       "      <th>Electrical</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>LowQualFinSF</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>HalfBath</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>KitchenAbvGr</th>\n",
       "      <th>KitchenQual</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>Functional</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>FireplaceQu</th>\n",
       "      <th>GarageType</th>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <th>GarageFinish</th>\n",
       "      <th>GarageCars</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>GarageQual</th>\n",
       "      <th>GarageCond</th>\n",
       "      <th>PavedDrive</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460</td>\n",
       "      <td>1201.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460</td>\n",
       "      <td>91</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1452</td>\n",
       "      <td>1452.000000</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1423</td>\n",
       "      <td>1423</td>\n",
       "      <td>1422</td>\n",
       "      <td>1423</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1422</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1459</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>770</td>\n",
       "      <td>1379</td>\n",
       "      <td>1379.000000</td>\n",
       "      <td>1379</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1379</td>\n",
       "      <td>1379</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>281</td>\n",
       "      <td>54</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Grvl</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NAmes</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1Story</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>PConc</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>No</td>\n",
       "      <td>Unf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gd</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>Shed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1151</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1454</td>\n",
       "      <td>50</td>\n",
       "      <td>925</td>\n",
       "      <td>1311</td>\n",
       "      <td>1459</td>\n",
       "      <td>1052</td>\n",
       "      <td>1382</td>\n",
       "      <td>225</td>\n",
       "      <td>1260</td>\n",
       "      <td>1445</td>\n",
       "      <td>1220</td>\n",
       "      <td>726</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1141</td>\n",
       "      <td>1434</td>\n",
       "      <td>515</td>\n",
       "      <td>504</td>\n",
       "      <td>864</td>\n",
       "      <td>NaN</td>\n",
       "      <td>906</td>\n",
       "      <td>1282</td>\n",
       "      <td>647</td>\n",
       "      <td>649</td>\n",
       "      <td>1311</td>\n",
       "      <td>953</td>\n",
       "      <td>430</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1428</td>\n",
       "      <td>741</td>\n",
       "      <td>1365</td>\n",
       "      <td>1334</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>735</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1360</td>\n",
       "      <td>NaN</td>\n",
       "      <td>380</td>\n",
       "      <td>870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>605</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1311</td>\n",
       "      <td>1326</td>\n",
       "      <td>1340</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>157</td>\n",
       "      <td>49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1267</td>\n",
       "      <td>1198</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>730.500000</td>\n",
       "      <td>56.897260</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.049958</td>\n",
       "      <td>10516.828082</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.099315</td>\n",
       "      <td>5.575342</td>\n",
       "      <td>1971.267808</td>\n",
       "      <td>1984.865753</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>103.685262</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>443.639726</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.549315</td>\n",
       "      <td>567.240411</td>\n",
       "      <td>1057.429452</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1162.626712</td>\n",
       "      <td>346.992466</td>\n",
       "      <td>5.844521</td>\n",
       "      <td>1515.463699</td>\n",
       "      <td>0.425342</td>\n",
       "      <td>0.057534</td>\n",
       "      <td>1.565068</td>\n",
       "      <td>0.382877</td>\n",
       "      <td>2.866438</td>\n",
       "      <td>1.046575</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.517808</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.613014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1978.506164</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.767123</td>\n",
       "      <td>472.980137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94.244521</td>\n",
       "      <td>46.660274</td>\n",
       "      <td>21.954110</td>\n",
       "      <td>3.409589</td>\n",
       "      <td>15.060959</td>\n",
       "      <td>2.758904</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.489041</td>\n",
       "      <td>6.321918</td>\n",
       "      <td>2007.815753</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>180921.195890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>421.610009</td>\n",
       "      <td>42.300571</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.284752</td>\n",
       "      <td>9981.264932</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.382997</td>\n",
       "      <td>1.112799</td>\n",
       "      <td>30.202904</td>\n",
       "      <td>20.645407</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>181.066207</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>456.098091</td>\n",
       "      <td>NaN</td>\n",
       "      <td>161.319273</td>\n",
       "      <td>441.866955</td>\n",
       "      <td>438.705324</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>386.587738</td>\n",
       "      <td>436.528436</td>\n",
       "      <td>48.623081</td>\n",
       "      <td>525.480383</td>\n",
       "      <td>0.518911</td>\n",
       "      <td>0.238753</td>\n",
       "      <td>0.550916</td>\n",
       "      <td>0.502885</td>\n",
       "      <td>0.815778</td>\n",
       "      <td>0.220338</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.625393</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.644666</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.689725</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.747315</td>\n",
       "      <td>213.804841</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>125.338794</td>\n",
       "      <td>66.256028</td>\n",
       "      <td>61.119149</td>\n",
       "      <td>29.317331</td>\n",
       "      <td>55.757415</td>\n",
       "      <td>40.177307</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>496.123024</td>\n",
       "      <td>2.703626</td>\n",
       "      <td>1.328095</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79442.502883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1300.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1872.000000</td>\n",
       "      <td>1950.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>334.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>334.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1900.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2006.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34900.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>365.750000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>7553.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1954.000000</td>\n",
       "      <td>1967.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>223.000000</td>\n",
       "      <td>795.750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>882.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1129.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1961.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>334.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2007.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>129975.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>730.500000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>9478.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1973.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>383.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>477.500000</td>\n",
       "      <td>991.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1087.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1464.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1980.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2008.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>163000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1095.250000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>11601.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2004.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>712.250000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>808.000000</td>\n",
       "      <td>1298.250000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1391.250000</td>\n",
       "      <td>728.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1776.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2002.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>576.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2009.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>214000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1460.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>313.000000</td>\n",
       "      <td>215245.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5644.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1474.000000</td>\n",
       "      <td>2336.000000</td>\n",
       "      <td>6110.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4692.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>572.000000</td>\n",
       "      <td>5642.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1418.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>857.000000</td>\n",
       "      <td>547.000000</td>\n",
       "      <td>552.000000</td>\n",
       "      <td>508.000000</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>738.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15500.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>755000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Id   MSSubClass MSZoning  LotFrontage        LotArea Street  \\\n",
       "count   1460.000000  1460.000000     1460  1201.000000    1460.000000   1460   \n",
       "unique          NaN          NaN        5          NaN            NaN      2   \n",
       "top             NaN          NaN       RL          NaN            NaN   Pave   \n",
       "freq            NaN          NaN     1151          NaN            NaN   1454   \n",
       "mean     730.500000    56.897260      NaN    70.049958   10516.828082    NaN   \n",
       "std      421.610009    42.300571      NaN    24.284752    9981.264932    NaN   \n",
       "min        1.000000    20.000000      NaN    21.000000    1300.000000    NaN   \n",
       "25%      365.750000    20.000000      NaN    59.000000    7553.500000    NaN   \n",
       "50%      730.500000    50.000000      NaN    69.000000    9478.500000    NaN   \n",
       "75%     1095.250000    70.000000      NaN    80.000000   11601.500000    NaN   \n",
       "max     1460.000000   190.000000      NaN   313.000000  215245.000000    NaN   \n",
       "\n",
       "       Alley LotShape LandContour Utilities LotConfig LandSlope Neighborhood  \\\n",
       "count     91     1460        1460      1460      1460      1460         1460   \n",
       "unique     2        4           4         2         5         3           25   \n",
       "top     Grvl      Reg         Lvl    AllPub    Inside       Gtl        NAmes   \n",
       "freq      50      925        1311      1459      1052      1382          225   \n",
       "mean     NaN      NaN         NaN       NaN       NaN       NaN          NaN   \n",
       "std      NaN      NaN         NaN       NaN       NaN       NaN          NaN   \n",
       "min      NaN      NaN         NaN       NaN       NaN       NaN          NaN   \n",
       "25%      NaN      NaN         NaN       NaN       NaN       NaN          NaN   \n",
       "50%      NaN      NaN         NaN       NaN       NaN       NaN          NaN   \n",
       "75%      NaN      NaN         NaN       NaN       NaN       NaN          NaN   \n",
       "max      NaN      NaN         NaN       NaN       NaN       NaN          NaN   \n",
       "\n",
       "       Condition1 Condition2 BldgType HouseStyle  OverallQual  OverallCond  \\\n",
       "count        1460       1460     1460       1460  1460.000000  1460.000000   \n",
       "unique          9          8        5          8          NaN          NaN   \n",
       "top          Norm       Norm     1Fam     1Story          NaN          NaN   \n",
       "freq         1260       1445     1220        726          NaN          NaN   \n",
       "mean          NaN        NaN      NaN        NaN     6.099315     5.575342   \n",
       "std           NaN        NaN      NaN        NaN     1.382997     1.112799   \n",
       "min           NaN        NaN      NaN        NaN     1.000000     1.000000   \n",
       "25%           NaN        NaN      NaN        NaN     5.000000     5.000000   \n",
       "50%           NaN        NaN      NaN        NaN     6.000000     5.000000   \n",
       "75%           NaN        NaN      NaN        NaN     7.000000     6.000000   \n",
       "max           NaN        NaN      NaN        NaN    10.000000     9.000000   \n",
       "\n",
       "          YearBuilt  YearRemodAdd RoofStyle RoofMatl Exterior1st Exterior2nd  \\\n",
       "count   1460.000000   1460.000000      1460     1460        1460        1460   \n",
       "unique          NaN           NaN         6        8          15          16   \n",
       "top             NaN           NaN     Gable  CompShg     VinylSd     VinylSd   \n",
       "freq            NaN           NaN      1141     1434         515         504   \n",
       "mean    1971.267808   1984.865753       NaN      NaN         NaN         NaN   \n",
       "std       30.202904     20.645407       NaN      NaN         NaN         NaN   \n",
       "min     1872.000000   1950.000000       NaN      NaN         NaN         NaN   \n",
       "25%     1954.000000   1967.000000       NaN      NaN         NaN         NaN   \n",
       "50%     1973.000000   1994.000000       NaN      NaN         NaN         NaN   \n",
       "75%     2000.000000   2004.000000       NaN      NaN         NaN         NaN   \n",
       "max     2010.000000   2010.000000       NaN      NaN         NaN         NaN   \n",
       "\n",
       "       MasVnrType   MasVnrArea ExterQual ExterCond Foundation BsmtQual  \\\n",
       "count        1452  1452.000000      1460      1460       1460     1423   \n",
       "unique          4          NaN         4         5          6        4   \n",
       "top          None          NaN        TA        TA      PConc       TA   \n",
       "freq          864          NaN       906      1282        647      649   \n",
       "mean          NaN   103.685262       NaN       NaN        NaN      NaN   \n",
       "std           NaN   181.066207       NaN       NaN        NaN      NaN   \n",
       "min           NaN     0.000000       NaN       NaN        NaN      NaN   \n",
       "25%           NaN     0.000000       NaN       NaN        NaN      NaN   \n",
       "50%           NaN     0.000000       NaN       NaN        NaN      NaN   \n",
       "75%           NaN   166.000000       NaN       NaN        NaN      NaN   \n",
       "max           NaN  1600.000000       NaN       NaN        NaN      NaN   \n",
       "\n",
       "       BsmtCond BsmtExposure BsmtFinType1   BsmtFinSF1 BsmtFinType2  \\\n",
       "count      1423         1422         1423  1460.000000         1422   \n",
       "unique        4            4            6          NaN            6   \n",
       "top          TA           No          Unf          NaN          Unf   \n",
       "freq       1311          953          430          NaN         1256   \n",
       "mean        NaN          NaN          NaN   443.639726          NaN   \n",
       "std         NaN          NaN          NaN   456.098091          NaN   \n",
       "min         NaN          NaN          NaN     0.000000          NaN   \n",
       "25%         NaN          NaN          NaN     0.000000          NaN   \n",
       "50%         NaN          NaN          NaN   383.500000          NaN   \n",
       "75%         NaN          NaN          NaN   712.250000          NaN   \n",
       "max         NaN          NaN          NaN  5644.000000          NaN   \n",
       "\n",
       "         BsmtFinSF2    BsmtUnfSF  TotalBsmtSF Heating HeatingQC CentralAir  \\\n",
       "count   1460.000000  1460.000000  1460.000000    1460      1460       1460   \n",
       "unique          NaN          NaN          NaN       6         5          2   \n",
       "top             NaN          NaN          NaN    GasA        Ex          Y   \n",
       "freq            NaN          NaN          NaN    1428       741       1365   \n",
       "mean      46.549315   567.240411  1057.429452     NaN       NaN        NaN   \n",
       "std      161.319273   441.866955   438.705324     NaN       NaN        NaN   \n",
       "min        0.000000     0.000000     0.000000     NaN       NaN        NaN   \n",
       "25%        0.000000   223.000000   795.750000     NaN       NaN        NaN   \n",
       "50%        0.000000   477.500000   991.500000     NaN       NaN        NaN   \n",
       "75%        0.000000   808.000000  1298.250000     NaN       NaN        NaN   \n",
       "max     1474.000000  2336.000000  6110.000000     NaN       NaN        NaN   \n",
       "\n",
       "       Electrical     1stFlrSF     2ndFlrSF  LowQualFinSF    GrLivArea  \\\n",
       "count        1459  1460.000000  1460.000000   1460.000000  1460.000000   \n",
       "unique          5          NaN          NaN           NaN          NaN   \n",
       "top         SBrkr          NaN          NaN           NaN          NaN   \n",
       "freq         1334          NaN          NaN           NaN          NaN   \n",
       "mean          NaN  1162.626712   346.992466      5.844521  1515.463699   \n",
       "std           NaN   386.587738   436.528436     48.623081   525.480383   \n",
       "min           NaN   334.000000     0.000000      0.000000   334.000000   \n",
       "25%           NaN   882.000000     0.000000      0.000000  1129.500000   \n",
       "50%           NaN  1087.000000     0.000000      0.000000  1464.000000   \n",
       "75%           NaN  1391.250000   728.000000      0.000000  1776.750000   \n",
       "max           NaN  4692.000000  2065.000000    572.000000  5642.000000   \n",
       "\n",
       "        BsmtFullBath  BsmtHalfBath     FullBath     HalfBath  BedroomAbvGr  \\\n",
       "count    1460.000000   1460.000000  1460.000000  1460.000000   1460.000000   \n",
       "unique           NaN           NaN          NaN          NaN           NaN   \n",
       "top              NaN           NaN          NaN          NaN           NaN   \n",
       "freq             NaN           NaN          NaN          NaN           NaN   \n",
       "mean        0.425342      0.057534     1.565068     0.382877      2.866438   \n",
       "std         0.518911      0.238753     0.550916     0.502885      0.815778   \n",
       "min         0.000000      0.000000     0.000000     0.000000      0.000000   \n",
       "25%         0.000000      0.000000     1.000000     0.000000      2.000000   \n",
       "50%         0.000000      0.000000     2.000000     0.000000      3.000000   \n",
       "75%         1.000000      0.000000     2.000000     1.000000      3.000000   \n",
       "max         3.000000      2.000000     3.000000     2.000000      8.000000   \n",
       "\n",
       "        KitchenAbvGr KitchenQual  TotRmsAbvGrd Functional   Fireplaces  \\\n",
       "count    1460.000000        1460   1460.000000       1460  1460.000000   \n",
       "unique           NaN           4           NaN          7          NaN   \n",
       "top              NaN          TA           NaN        Typ          NaN   \n",
       "freq             NaN         735           NaN       1360          NaN   \n",
       "mean        1.046575         NaN      6.517808        NaN     0.613014   \n",
       "std         0.220338         NaN      1.625393        NaN     0.644666   \n",
       "min         0.000000         NaN      2.000000        NaN     0.000000   \n",
       "25%         1.000000         NaN      5.000000        NaN     0.000000   \n",
       "50%         1.000000         NaN      6.000000        NaN     1.000000   \n",
       "75%         1.000000         NaN      7.000000        NaN     1.000000   \n",
       "max         3.000000         NaN     14.000000        NaN     3.000000   \n",
       "\n",
       "       FireplaceQu GarageType  GarageYrBlt GarageFinish   GarageCars  \\\n",
       "count          770       1379  1379.000000         1379  1460.000000   \n",
       "unique           5          6          NaN            3          NaN   \n",
       "top             Gd     Attchd          NaN          Unf          NaN   \n",
       "freq           380        870          NaN          605          NaN   \n",
       "mean           NaN        NaN  1978.506164          NaN     1.767123   \n",
       "std            NaN        NaN    24.689725          NaN     0.747315   \n",
       "min            NaN        NaN  1900.000000          NaN     0.000000   \n",
       "25%            NaN        NaN  1961.000000          NaN     1.000000   \n",
       "50%            NaN        NaN  1980.000000          NaN     2.000000   \n",
       "75%            NaN        NaN  2002.000000          NaN     2.000000   \n",
       "max            NaN        NaN  2010.000000          NaN     4.000000   \n",
       "\n",
       "         GarageArea GarageQual GarageCond PavedDrive   WoodDeckSF  \\\n",
       "count   1460.000000       1379       1379       1460  1460.000000   \n",
       "unique          NaN          5          5          3          NaN   \n",
       "top             NaN         TA         TA          Y          NaN   \n",
       "freq            NaN       1311       1326       1340          NaN   \n",
       "mean     472.980137        NaN        NaN        NaN    94.244521   \n",
       "std      213.804841        NaN        NaN        NaN   125.338794   \n",
       "min        0.000000        NaN        NaN        NaN     0.000000   \n",
       "25%      334.500000        NaN        NaN        NaN     0.000000   \n",
       "50%      480.000000        NaN        NaN        NaN     0.000000   \n",
       "75%      576.000000        NaN        NaN        NaN   168.000000   \n",
       "max     1418.000000        NaN        NaN        NaN   857.000000   \n",
       "\n",
       "        OpenPorchSF  EnclosedPorch    3SsnPorch  ScreenPorch     PoolArea  \\\n",
       "count   1460.000000    1460.000000  1460.000000  1460.000000  1460.000000   \n",
       "unique          NaN            NaN          NaN          NaN          NaN   \n",
       "top             NaN            NaN          NaN          NaN          NaN   \n",
       "freq            NaN            NaN          NaN          NaN          NaN   \n",
       "mean      46.660274      21.954110     3.409589    15.060959     2.758904   \n",
       "std       66.256028      61.119149    29.317331    55.757415    40.177307   \n",
       "min        0.000000       0.000000     0.000000     0.000000     0.000000   \n",
       "25%        0.000000       0.000000     0.000000     0.000000     0.000000   \n",
       "50%       25.000000       0.000000     0.000000     0.000000     0.000000   \n",
       "75%       68.000000       0.000000     0.000000     0.000000     0.000000   \n",
       "max      547.000000     552.000000   508.000000   480.000000   738.000000   \n",
       "\n",
       "       PoolQC  Fence MiscFeature       MiscVal       MoSold       YrSold  \\\n",
       "count       7    281          54   1460.000000  1460.000000  1460.000000   \n",
       "unique      3      4           4           NaN          NaN          NaN   \n",
       "top        Gd  MnPrv        Shed           NaN          NaN          NaN   \n",
       "freq        3    157          49           NaN          NaN          NaN   \n",
       "mean      NaN    NaN         NaN     43.489041     6.321918  2007.815753   \n",
       "std       NaN    NaN         NaN    496.123024     2.703626     1.328095   \n",
       "min       NaN    NaN         NaN      0.000000     1.000000  2006.000000   \n",
       "25%       NaN    NaN         NaN      0.000000     5.000000  2007.000000   \n",
       "50%       NaN    NaN         NaN      0.000000     6.000000  2008.000000   \n",
       "75%       NaN    NaN         NaN      0.000000     8.000000  2009.000000   \n",
       "max       NaN    NaN         NaN  15500.000000    12.000000  2010.000000   \n",
       "\n",
       "       SaleType SaleCondition      SalePrice  \n",
       "count      1460          1460    1460.000000  \n",
       "unique        9             6            NaN  \n",
       "top          WD        Normal            NaN  \n",
       "freq       1267          1198            NaN  \n",
       "mean        NaN           NaN  180921.195890  \n",
       "std         NaN           NaN   79442.502883  \n",
       "min         NaN           NaN   34900.000000  \n",
       "25%         NaN           NaN  129975.000000  \n",
       "50%         NaN           NaN  163000.000000  \n",
       "75%         NaN           NaN  214000.000000  \n",
       "max         NaN           NaN  755000.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('max_columns', None)\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LotFrontage',\n",
       " 'Alley',\n",
       " 'MasVnrType',\n",
       " 'MasVnrArea',\n",
       " 'BsmtQual',\n",
       " 'BsmtCond',\n",
       " 'BsmtExposure',\n",
       " 'BsmtFinType1',\n",
       " 'BsmtFinType2',\n",
       " 'Electrical',\n",
       " 'FireplaceQu',\n",
       " 'GarageType',\n",
       " 'GarageYrBlt',\n",
       " 'GarageFinish',\n",
       " 'GarageQual',\n",
       " 'GarageCond',\n",
       " 'PoolQC',\n",
       " 'Fence',\n",
       " 'MiscFeature']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('max_rows', None)\n",
    "nan_list = []\n",
    "for item in df.columns:\n",
    "    if (df[item].isnull().sum() != 0) == True:\n",
    "        nan_list.append(item)\n",
    "nan_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id               0\n",
       "MSSubClass       0\n",
       "MSZoning         0\n",
       "LotArea          0\n",
       "Street           0\n",
       "LotShape         0\n",
       "LandContour      0\n",
       "Utilities        0\n",
       "LotConfig        0\n",
       "LandSlope        0\n",
       "Neighborhood     0\n",
       "Condition1       0\n",
       "Condition2       0\n",
       "BldgType         0\n",
       "HouseStyle       0\n",
       "OverallQual      0\n",
       "OverallCond      0\n",
       "YearBuilt        0\n",
       "YearRemodAdd     0\n",
       "RoofStyle        0\n",
       "RoofMatl         0\n",
       "Exterior1st      0\n",
       "Exterior2nd      0\n",
       "ExterQual        0\n",
       "ExterCond        0\n",
       "Foundation       0\n",
       "BsmtFinSF1       0\n",
       "BsmtFinSF2       0\n",
       "BsmtUnfSF        0\n",
       "TotalBsmtSF      0\n",
       "Heating          0\n",
       "HeatingQC        0\n",
       "CentralAir       0\n",
       "1stFlrSF         0\n",
       "2ndFlrSF         0\n",
       "LowQualFinSF     0\n",
       "GrLivArea        0\n",
       "BsmtFullBath     0\n",
       "BsmtHalfBath     0\n",
       "FullBath         0\n",
       "HalfBath         0\n",
       "BedroomAbvGr     0\n",
       "KitchenAbvGr     0\n",
       "KitchenQual      0\n",
       "TotRmsAbvGrd     0\n",
       "Functional       0\n",
       "Fireplaces       0\n",
       "GarageCars       0\n",
       "GarageArea       0\n",
       "PavedDrive       0\n",
       "WoodDeckSF       0\n",
       "OpenPorchSF      0\n",
       "EnclosedPorch    0\n",
       "3SsnPorch        0\n",
       "ScreenPorch      0\n",
       "PoolArea         0\n",
       "MiscVal          0\n",
       "MoSold           0\n",
       "YrSold           0\n",
       "SaleType         0\n",
       "SaleCondition    0\n",
       "SalePrice        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy = df.drop(columns = nan_list)\n",
    "df_copy.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_test = train_test_split(df_copy, test_size=0.2, random_state=436824)\n",
    "X_train = df_train.drop(columns=['SalePrice', 'Id'])\n",
    "X_test = df_test.drop(columns=['SalePrice', 'Id'])\n",
    "y_train = df_train['SalePrice']\n",
    "y_test = df_train['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_copy_dummy = pd.get_dummies(df_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6139722508.826568"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "baseline = [y_train.mean()] * len(y_train)\n",
    "\n",
    "mean_squared_error(y_train, baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns == X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "encoder = OneHotEncoder(categories='auto')\n",
    "normalizer = Normalizer()\n",
    "\n",
    "X_train_encoded = encoder.fit_transform(X_train)\n",
    "# X_test_encoded = encoder.transform(X_test)\n",
    "\n",
    "X_train_norm = normalizer.fit_transform(X_train_encoded)\n",
    "# X_test_norm = normalizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Scary Sundays\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_205 (Dense)            (None, 6)                 36714     \n",
      "_________________________________________________________________\n",
      "dense_206 (Dense)            (None, 3)                 21        \n",
      "_________________________________________________________________\n",
      "dense_207 (Dense)            (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 36,739\n",
      "Trainable params: 36,739\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential(name=\"Scary Sundays\")\n",
    "\n",
    "model.add(Dense(6, input_dim=6118, activation='relu'))\n",
    "model.add(Dense(3, activation='relu'))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "\n",
    "model.compile(loss='MSE', optimizer='adam', metrics=['mean_squared_error'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'scipy.sparse.csr.csr_matrix'>, <class 'NoneType'>\n",
      "Train on 1168 samples\n",
      "Epoch 1/150\n",
      "1168/1168 [==============================] - 0s 355us/sample - loss: 38688841110.7945 - mean_squared_error: 38688841728.0000\n",
      "Epoch 2/150\n",
      "1168/1168 [==============================] - 0s 191us/sample - loss: 38688840718.0274 - mean_squared_error: 38688845824.0000\n",
      "Epoch 3/150\n",
      "1168/1168 [==============================] - 0s 160us/sample - loss: 38688840774.1370 - mean_squared_error: 38688837632.0000\n",
      "Epoch 4/150\n",
      "1168/1168 [==============================] - 0s 171us/sample - loss: 38688841026.6301 - mean_squared_error: 38688837632.0000\n",
      "Epoch 5/150\n",
      "1168/1168 [==============================] - 0s 172us/sample - loss: 38688840605.8082 - mean_squared_error: 38688837632.0000\n",
      "Epoch 6/150\n",
      "1168/1168 [==============================] - 0s 164us/sample - loss: 38688840942.4658 - mean_squared_error: 38688829440.0000\n",
      "Epoch 7/150\n",
      "1168/1168 [==============================] - 0s 169us/sample - loss: 38688840549.6986 - mean_squared_error: 38688845824.0000\n",
      "Epoch 8/150\n",
      "1168/1168 [==============================] - 0s 164us/sample - loss: 38688840549.6986 - mean_squared_error: 38688841728.0000\n",
      "Epoch 9/150\n",
      "1168/1168 [==============================] - 0s 171us/sample - loss: 38688840605.8082 - mean_squared_error: 38688841728.0000\n",
      "Epoch 10/150\n",
      "1168/1168 [==============================] - 0s 167us/sample - loss: 38688840661.9178 - mean_squared_error: 38688845824.0000\n",
      "Epoch 11/150\n",
      "1168/1168 [==============================] - 0s 164us/sample - loss: 38688840605.8082 - mean_squared_error: 38688841728.0000\n",
      "Epoch 12/150\n",
      "1168/1168 [==============================] - 0s 164us/sample - loss: 38688841166.9041 - mean_squared_error: 38688845824.0000\n",
      "Epoch 13/150\n",
      "1168/1168 [==============================] - 0s 164us/sample - loss: 38688840689.9726 - mean_squared_error: 38688837632.0000\n",
      "Epoch 14/150\n",
      "1168/1168 [==============================] - 0s 163us/sample - loss: 38688840718.0274 - mean_squared_error: 38688849920.0000\n",
      "Epoch 15/150\n",
      "1168/1168 [==============================] - 0s 167us/sample - loss: 38688840886.3562 - mean_squared_error: 38688837632.0000\n",
      "Epoch 16/150\n",
      "1168/1168 [==============================] - 0s 168us/sample - loss: 38688840802.1918 - mean_squared_error: 38688845824.0000\n",
      "Epoch 17/150\n",
      "1168/1168 [==============================] - 0s 163us/sample - loss: 38688840549.6986 - mean_squared_error: 38688845824.0000\n",
      "Epoch 18/150\n",
      "1168/1168 [==============================] - 0s 163us/sample - loss: 38688840774.1370 - mean_squared_error: 38688833536.0000\n",
      "Epoch 19/150\n",
      "1168/1168 [==============================] - 0s 174us/sample - loss: 38688841054.6849 - mean_squared_error: 38688837632.0000\n",
      "Epoch 20/150\n",
      "1168/1168 [==============================] - 0s 164us/sample - loss: 38688840774.1370 - mean_squared_error: 38688845824.0000\n",
      "Epoch 21/150\n",
      "1168/1168 [==============================] - 0s 160us/sample - loss: 38688841223.0137 - mean_squared_error: 38688837632.0000\n",
      "Epoch 22/150\n",
      "1168/1168 [==============================] - 0s 165us/sample - loss: 38688841307.1781 - mean_squared_error: 38688841728.0000\n",
      "Epoch 23/150\n",
      "1168/1168 [==============================] - 0s 158us/sample - loss: 38688840802.1918 - mean_squared_error: 38688837632.0000\n",
      "Epoch 24/150\n",
      "1168/1168 [==============================] - 0s 164us/sample - loss: 38688840718.0274 - mean_squared_error: 38688837632.0000\n",
      "Epoch 25/150\n",
      "1168/1168 [==============================] - 0s 163us/sample - loss: 38688841503.5616 - mean_squared_error: 38688837632.0000\n",
      "Epoch 26/150\n",
      "1168/1168 [==============================] - 0s 164us/sample - loss: 38688840942.4658 - mean_squared_error: 38688833536.0000\n",
      "Epoch 27/150\n",
      "1168/1168 [==============================] - 0s 162us/sample - loss: 38688840774.1370 - mean_squared_error: 38688841728.0000\n",
      "Epoch 28/150\n",
      "1168/1168 [==============================] - 0s 165us/sample - loss: 38688841054.6849 - mean_squared_error: 38688841728.0000\n",
      "Epoch 29/150\n",
      "1168/1168 [==============================] - 0s 167us/sample - loss: 38688840942.4658 - mean_squared_error: 38688841728.0000\n",
      "Epoch 30/150\n",
      "1168/1168 [==============================] - 0s 163us/sample - loss: 38688840858.3014 - mean_squared_error: 38688837632.0000\n",
      "Epoch 31/150\n",
      "1168/1168 [==============================] - 0s 175us/sample - loss: 38688840437.4795 - mean_squared_error: 38688841728.0000\n",
      "Epoch 32/150\n",
      "1168/1168 [==============================] - 0s 155us/sample - loss: 38688840886.3562 - mean_squared_error: 38688841728.0000\n",
      "Epoch 33/150\n",
      "1168/1168 [==============================] - 0s 179us/sample - loss: 38688840970.5205 - mean_squared_error: 38688841728.0000\n",
      "Epoch 34/150\n",
      "1168/1168 [==============================] - 0s 165us/sample - loss: 38688840942.4658 - mean_squared_error: 38688833536.0000\n",
      "Epoch 35/150\n",
      "1168/1168 [==============================] - 0s 165us/sample - loss: 38688840269.1507 - mean_squared_error: 38688837632.0000\n",
      "Epoch 36/150\n",
      "1168/1168 [==============================] - 0s 168us/sample - loss: 38688841279.1233 - mean_squared_error: 38688841728.0000\n",
      "Epoch 37/150\n",
      "1168/1168 [==============================] - 0s 160us/sample - loss: 38688841082.7397 - mean_squared_error: 38688841728.0000\n",
      "Epoch 38/150\n",
      "1168/1168 [==============================] - 0s 168us/sample - loss: 38688840942.4658 - mean_squared_error: 38688841728.0000\n",
      "Epoch 39/150\n",
      "1168/1168 [==============================] - 0s 167us/sample - loss: 38688840718.0274 - mean_squared_error: 38688845824.0000\n",
      "Epoch 40/150\n",
      "1168/1168 [==============================] - 0s 172us/sample - loss: 38688840718.0274 - mean_squared_error: 38688837632.0000\n",
      "Epoch 41/150\n",
      "1168/1168 [==============================] - 0s 167us/sample - loss: 38688840942.4658 - mean_squared_error: 38688845824.0000\n",
      "Epoch 42/150\n",
      "1168/1168 [==============================] - 0s 172us/sample - loss: 38688841054.6849 - mean_squared_error: 38688837632.0000\n",
      "Epoch 43/150\n",
      "1168/1168 [==============================] - 0s 171us/sample - loss: 38688840886.3562 - mean_squared_error: 38688837632.0000\n",
      "Epoch 44/150\n",
      "1168/1168 [==============================] - 0s 181us/sample - loss: 38688841054.6849 - mean_squared_error: 38688837632.0000\n",
      "Epoch 45/150\n",
      "1168/1168 [==============================] - 0s 172us/sample - loss: 38688841559.6712 - mean_squared_error: 38688837632.0000\n",
      "Epoch 46/150\n",
      "1168/1168 [==============================] - 0s 168us/sample - loss: 38688840830.2466 - mean_squared_error: 38688837632.0000\n",
      "Epoch 47/150\n",
      "1168/1168 [==============================] - 0s 195us/sample - loss: 38688840605.8082 - mean_squared_error: 38688845824.0000\n",
      "Epoch 48/150\n",
      "1168/1168 [==============================] - 0s 180us/sample - loss: 38688841335.2329 - mean_squared_error: 38688845824.0000\n",
      "Epoch 49/150\n",
      "1168/1168 [==============================] - 0s 169us/sample - loss: 38688840774.1370 - mean_squared_error: 38688833536.0000\n",
      "Epoch 50/150\n",
      "1168/1168 [==============================] - 0s 174us/sample - loss: 38688840493.5890 - mean_squared_error: 38688837632.0000\n",
      "Epoch 51/150\n",
      "1168/1168 [==============================] - 0s 180us/sample - loss: 38688841054.6849 - mean_squared_error: 38688849920.0000\n",
      "Epoch 52/150\n",
      "1168/1168 [==============================] - 0s 193us/sample - loss: 38688840886.3562 - mean_squared_error: 38688849920.0000\n",
      "Epoch 53/150\n",
      "1168/1168 [==============================] - 0s 161us/sample - loss: 38688840998.5753 - mean_squared_error: 38688841728.0000\n",
      "Epoch 54/150\n",
      "1168/1168 [==============================] - 0s 177us/sample - loss: 38688841082.7397 - mean_squared_error: 38688841728.0000\n",
      "Epoch 55/150\n",
      "1168/1168 [==============================] - 0s 175us/sample - loss: 38688840942.4658 - mean_squared_error: 38688837632.0000\n",
      "Epoch 56/150\n",
      "1168/1168 [==============================] - 0s 167us/sample - loss: 38688841251.0685 - mean_squared_error: 38688837632.0000\n",
      "Epoch 57/150\n",
      "1168/1168 [==============================] - 0s 173us/sample - loss: 38688840830.2466 - mean_squared_error: 38688849920.0000\n",
      "Epoch 58/150\n",
      "1168/1168 [==============================] - 0s 169us/sample - loss: 38688841279.1233 - mean_squared_error: 38688837632.0000\n",
      "Epoch 59/150\n",
      "1168/1168 [==============================] - 0s 192us/sample - loss: 38688840998.5753 - mean_squared_error: 38688849920.0000\n",
      "Epoch 60/150\n",
      "1168/1168 [==============================] - 0s 185us/sample - loss: 38688841054.6849 - mean_squared_error: 38688837632.0000\n",
      "Epoch 61/150\n",
      "1168/1168 [==============================] - 0s 170us/sample - loss: 38688841223.0137 - mean_squared_error: 38688854016.0000\n",
      "Epoch 62/150\n",
      "1168/1168 [==============================] - 0s 162us/sample - loss: 38688840830.2466 - mean_squared_error: 38688841728.0000\n",
      "Epoch 63/150\n",
      "1168/1168 [==============================] - 0s 162us/sample - loss: 38688840718.0274 - mean_squared_error: 38688833536.0000\n",
      "Epoch 64/150\n",
      "1168/1168 [==============================] - 0s 172us/sample - loss: 38688841166.9041 - mean_squared_error: 38688837632.0000\n",
      "Epoch 65/150\n",
      "1168/1168 [==============================] - 0s 167us/sample - loss: 38688841054.6849 - mean_squared_error: 38688841728.0000\n",
      "Epoch 66/150\n",
      "1168/1168 [==============================] - 0s 166us/sample - loss: 38688840718.0274 - mean_squared_error: 38688837632.0000\n",
      "Epoch 67/150\n",
      "1168/1168 [==============================] - 0s 173us/sample - loss: 38688840998.5753 - mean_squared_error: 38688841728.0000\n",
      "Epoch 68/150\n",
      "1168/1168 [==============================] - 0s 171us/sample - loss: 38688840661.9178 - mean_squared_error: 38688833536.0000\n",
      "Epoch 69/150\n",
      "1168/1168 [==============================] - 0s 172us/sample - loss: 38688841223.0137 - mean_squared_error: 38688837632.0000\n",
      "Epoch 70/150\n",
      "1168/1168 [==============================] - 0s 176us/sample - loss: 38688841166.9041 - mean_squared_error: 38688837632.0000\n",
      "Epoch 71/150\n",
      "1168/1168 [==============================] - 0s 167us/sample - loss: 38688840718.0274 - mean_squared_error: 38688837632.0000\n",
      "Epoch 72/150\n",
      "1168/1168 [==============================] - 0s 163us/sample - loss: 38688840942.4658 - mean_squared_error: 38688841728.0000\n",
      "Epoch 73/150\n",
      "1168/1168 [==============================] - 0s 177us/sample - loss: 38688840437.4795 - mean_squared_error: 38688841728.0000\n",
      "Epoch 74/150\n",
      "1168/1168 [==============================] - 0s 174us/sample - loss: 38688840549.6986 - mean_squared_error: 38688841728.0000\n",
      "Epoch 75/150\n",
      "1168/1168 [==============================] - 0s 164us/sample - loss: 38688840886.3562 - mean_squared_error: 38688841728.0000\n",
      "Epoch 76/150\n",
      "1168/1168 [==============================] - 0s 165us/sample - loss: 38688840886.3562 - mean_squared_error: 38688833536.0000\n",
      "Epoch 77/150\n",
      "1168/1168 [==============================] - 0s 162us/sample - loss: 38688840830.2466 - mean_squared_error: 38688845824.0000\n",
      "Epoch 78/150\n",
      "1168/1168 [==============================] - 0s 160us/sample - loss: 38688840437.4795 - mean_squared_error: 38688845824.0000\n",
      "Epoch 79/150\n",
      "1168/1168 [==============================] - 0s 168us/sample - loss: 38688841279.1233 - mean_squared_error: 38688845824.0000\n",
      "Epoch 80/150\n",
      "1168/1168 [==============================] - 0s 161us/sample - loss: 38688840746.0822 - mean_squared_error: 38688841728.0000\n",
      "Epoch 81/150\n",
      "1168/1168 [==============================] - 0s 159us/sample - loss: 38688840746.0822 - mean_squared_error: 38688837632.0000\n",
      "Epoch 82/150\n",
      "1168/1168 [==============================] - 0s 163us/sample - loss: 38688841054.6849 - mean_squared_error: 38688845824.0000\n",
      "Epoch 83/150\n",
      "1168/1168 [==============================] - 0s 172us/sample - loss: 38688840549.6986 - mean_squared_error: 38688845824.0000\n",
      "Epoch 84/150\n",
      "1168/1168 [==============================] - 0s 172us/sample - loss: 38688840493.5890 - mean_squared_error: 38688841728.0000\n",
      "Epoch 85/150\n",
      "1168/1168 [==============================] - 0s 163us/sample - loss: 38688840437.4795 - mean_squared_error: 38688837632.0000\n",
      "Epoch 86/150\n",
      "1168/1168 [==============================] - 0s 162us/sample - loss: 38688841054.6849 - mean_squared_error: 38688841728.0000\n",
      "Epoch 87/150\n",
      "1168/1168 [==============================] - 0s 163us/sample - loss: 38688840493.5890 - mean_squared_error: 38688841728.0000\n",
      "Epoch 88/150\n",
      "1168/1168 [==============================] - ETA: 0s - loss: 38954765741.4194 - mean_squared_error: 38954762240.00 - 0s 158us/sample - loss: 38688841279.1233 - mean_squared_error: 38688837632.0000\n",
      "Epoch 89/150\n",
      "1168/1168 [==============================] - 0s 164us/sample - loss: 38688840549.6986 - mean_squared_error: 38688841728.0000\n",
      "Epoch 90/150\n",
      "1168/1168 [==============================] - 0s 165us/sample - loss: 38688840774.1370 - mean_squared_error: 38688841728.0000\n",
      "Epoch 91/150\n",
      "1168/1168 [==============================] - 0s 159us/sample - loss: 38688840661.9178 - mean_squared_error: 38688833536.0000\n",
      "Epoch 92/150\n",
      "1168/1168 [==============================] - 0s 168us/sample - loss: 38688840830.2466 - mean_squared_error: 38688849920.0000\n",
      "Epoch 93/150\n",
      "1168/1168 [==============================] - 0s 160us/sample - loss: 38688840493.5890 - mean_squared_error: 38688841728.0000\n",
      "Epoch 94/150\n",
      "1168/1168 [==============================] - 0s 174us/sample - loss: 38688840718.0274 - mean_squared_error: 38688833536.0000\n",
      "Epoch 95/150\n",
      "1168/1168 [==============================] - 0s 161us/sample - loss: 38688841447.4521 - mean_squared_error: 38688849920.0000\n",
      "Epoch 96/150\n",
      "1168/1168 [==============================] - 0s 165us/sample - loss: 38688840830.2466 - mean_squared_error: 38688845824.0000\n",
      "Epoch 97/150\n",
      "1168/1168 [==============================] - 0s 168us/sample - loss: 38688840830.2466 - mean_squared_error: 38688833536.0000\n",
      "Epoch 98/150\n",
      "1168/1168 [==============================] - 0s 162us/sample - loss: 38688840661.9178 - mean_squared_error: 38688845824.0000\n",
      "Epoch 99/150\n",
      "1168/1168 [==============================] - 0s 165us/sample - loss: 38688840493.5890 - mean_squared_error: 38688833536.0000\n",
      "Epoch 100/150\n",
      "1168/1168 [==============================] - 0s 161us/sample - loss: 38688840661.9178 - mean_squared_error: 38688837632.0000\n",
      "Epoch 101/150\n",
      "1168/1168 [==============================] - 0s 164us/sample - loss: 38688840549.6986 - mean_squared_error: 38688845824.0000\n",
      "Epoch 102/150\n",
      "1168/1168 [==============================] - 0s 160us/sample - loss: 38688840774.1370 - mean_squared_error: 38688837632.0000\n",
      "Epoch 103/150\n",
      "1168/1168 [==============================] - 0s 168us/sample - loss: 38688841223.0137 - mean_squared_error: 38688837632.0000\n",
      "Epoch 104/150\n",
      "1168/1168 [==============================] - 0s 160us/sample - loss: 38688840942.4658 - mean_squared_error: 38688837632.0000\n",
      "Epoch 105/150\n",
      "1168/1168 [==============================] - 0s 162us/sample - loss: 38688840689.9726 - mean_squared_error: 38688837632.0000\n",
      "Epoch 106/150\n",
      "1168/1168 [==============================] - 0s 163us/sample - loss: 38688840998.5753 - mean_squared_error: 38688841728.0000\n",
      "Epoch 107/150\n",
      "1168/1168 [==============================] - 0s 160us/sample - loss: 38688841110.7945 - mean_squared_error: 38688849920.0000\n",
      "Epoch 108/150\n",
      "1168/1168 [==============================] - 0s 164us/sample - loss: 38688841223.0137 - mean_squared_error: 38688849920.0000\n",
      "Epoch 109/150\n",
      "1168/1168 [==============================] - 0s 162us/sample - loss: 38688840409.4247 - mean_squared_error: 38688833536.0000\n",
      "Epoch 110/150\n",
      "1168/1168 [==============================] - 0s 161us/sample - loss: 38688840886.3562 - mean_squared_error: 38688845824.0000\n",
      "Epoch 111/150\n",
      "1168/1168 [==============================] - 0s 159us/sample - loss: 38688840605.8082 - mean_squared_error: 38688845824.0000\n",
      "Epoch 112/150\n",
      "1168/1168 [==============================] - 0s 160us/sample - loss: 38688840998.5753 - mean_squared_error: 38688837632.0000\n",
      "Epoch 113/150\n",
      "1168/1168 [==============================] - 0s 161us/sample - loss: 38688840044.7123 - mean_squared_error: 38688841728.0000\n",
      "Epoch 114/150\n",
      "1168/1168 [==============================] - 0s 179us/sample - loss: 38688840886.3562 - mean_squared_error: 38688845824.0000\n",
      "Epoch 115/150\n",
      "1168/1168 [==============================] - 0s 159us/sample - loss: 38688840718.0274 - mean_squared_error: 38688829440.0000\n",
      "Epoch 116/150\n",
      "1168/1168 [==============================] - 0s 161us/sample - loss: 38688840942.4658 - mean_squared_error: 38688841728.0000\n",
      "Epoch 117/150\n",
      "1168/1168 [==============================] - 0s 157us/sample - loss: 38688840689.9726 - mean_squared_error: 38688845824.0000\n",
      "Epoch 118/150\n",
      "1168/1168 [==============================] - 0s 157us/sample - loss: 38688840774.1370 - mean_squared_error: 38688833536.0000\n",
      "Epoch 119/150\n",
      "1168/1168 [==============================] - 0s 158us/sample - loss: 38688841166.9041 - mean_squared_error: 38688849920.0000\n",
      "Epoch 120/150\n",
      "1168/1168 [==============================] - 0s 163us/sample - loss: 38688840661.9178 - mean_squared_error: 38688837632.0000\n",
      "Epoch 121/150\n",
      "1168/1168 [==============================] - 0s 158us/sample - loss: 38688840998.5753 - mean_squared_error: 38688837632.0000\n",
      "Epoch 122/150\n",
      "1168/1168 [==============================] - 0s 160us/sample - loss: 38688840774.1370 - mean_squared_error: 38688841728.0000\n",
      "Epoch 123/150\n",
      "1168/1168 [==============================] - 0s 160us/sample - loss: 38688840746.0822 - mean_squared_error: 38688845824.0000\n",
      "Epoch 124/150\n",
      "1168/1168 [==============================] - 0s 164us/sample - loss: 38688840718.0274 - mean_squared_error: 38688837632.0000\n",
      "Epoch 125/150\n",
      "1168/1168 [==============================] - 0s 158us/sample - loss: 38688841082.7397 - mean_squared_error: 38688829440.0000\n",
      "Epoch 126/150\n",
      "1168/1168 [==============================] - 0s 164us/sample - loss: 38688840830.2466 - mean_squared_error: 38688837632.0000\n",
      "Epoch 127/150\n",
      "1168/1168 [==============================] - 0s 160us/sample - loss: 38688840718.0274 - mean_squared_error: 38688845824.0000\n",
      "Epoch 128/150\n",
      "1168/1168 [==============================] - 0s 156us/sample - loss: 38688840998.5753 - mean_squared_error: 38688845824.0000\n",
      "Epoch 129/150\n",
      "1168/1168 [==============================] - 0s 161us/sample - loss: 38688840437.4795 - mean_squared_error: 38688837632.0000\n",
      "Epoch 130/150\n",
      "1168/1168 [==============================] - 0s 167us/sample - loss: 38688840437.4795 - mean_squared_error: 38688841728.0000\n",
      "Epoch 131/150\n",
      "1168/1168 [==============================] - 0s 162us/sample - loss: 38688841166.9041 - mean_squared_error: 38688841728.0000\n",
      "Epoch 132/150\n",
      "1168/1168 [==============================] - 0s 160us/sample - loss: 38688840718.0274 - mean_squared_error: 38688833536.0000\n",
      "Epoch 133/150\n",
      "1168/1168 [==============================] - 0s 162us/sample - loss: 38688840661.9178 - mean_squared_error: 38688833536.0000\n",
      "Epoch 134/150\n",
      "1168/1168 [==============================] - 0s 163us/sample - loss: 38688840493.5890 - mean_squared_error: 38688841728.0000\n",
      "Epoch 135/150\n",
      "1168/1168 [==============================] - 0s 163us/sample - loss: 38688840718.0274 - mean_squared_error: 38688837632.0000\n",
      "Epoch 136/150\n",
      "1168/1168 [==============================] - 0s 166us/sample - loss: 38688840605.8082 - mean_squared_error: 38688841728.0000\n",
      "Epoch 137/150\n",
      "1168/1168 [==============================] - 0s 164us/sample - loss: 38688840942.4658 - mean_squared_error: 38688841728.0000\n",
      "Epoch 138/150\n",
      "1168/1168 [==============================] - 0s 162us/sample - loss: 38688840269.1507 - mean_squared_error: 38688841728.0000\n",
      "Epoch 139/150\n",
      "1168/1168 [==============================] - 0s 164us/sample - loss: 38688840689.9726 - mean_squared_error: 38688833536.0000\n",
      "Epoch 140/150\n",
      "1168/1168 [==============================] - 0s 164us/sample - loss: 38688840942.4658 - mean_squared_error: 38688837632.0000\n",
      "Epoch 141/150\n",
      "1168/1168 [==============================] - 0s 167us/sample - loss: 38688840437.4795 - mean_squared_error: 38688841728.0000\n",
      "Epoch 142/150\n",
      "1168/1168 [==============================] - 0s 162us/sample - loss: 38688840493.5890 - mean_squared_error: 38688841728.0000\n",
      "Epoch 143/150\n",
      "1168/1168 [==============================] - 0s 160us/sample - loss: 38688841166.9041 - mean_squared_error: 38688841728.0000\n",
      "Epoch 144/150\n",
      "1168/1168 [==============================] - 0s 163us/sample - loss: 38688840942.4658 - mean_squared_error: 38688845824.0000\n",
      "Epoch 145/150\n",
      "1168/1168 [==============================] - 0s 172us/sample - loss: 38688840718.0274 - mean_squared_error: 38688837632.0000\n",
      "Epoch 146/150\n",
      "1168/1168 [==============================] - 0s 161us/sample - loss: 38688840886.3562 - mean_squared_error: 38688841728.0000\n",
      "Epoch 147/150\n",
      "1168/1168 [==============================] - 0s 163us/sample - loss: 38688840886.3562 - mean_squared_error: 38688845824.0000\n",
      "Epoch 148/150\n",
      "1168/1168 [==============================] - 0s 168us/sample - loss: 38688841110.7945 - mean_squared_error: 38688837632.0000\n",
      "Epoch 149/150\n",
      "1168/1168 [==============================] - 0s 161us/sample - loss: 38688840605.8082 - mean_squared_error: 38688841728.0000\n",
      "Epoch 150/150\n",
      "1168/1168 [==============================] - 0s 164us/sample - loss: 38688840718.0274 - mean_squared_error: 38688841728.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f74a310e48>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_norm, y_train, epochs=150, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0013340393771833939"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg = LinearRegression()\n",
    "\n",
    "lin_reg.fit(X_train_norm, y_train)\n",
    "lin_reg_pred = lin_reg.predict(X_train_norm) \n",
    "\n",
    "mean_squared_error(y_train, lin_reg_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PhatDeluxe\\Anaconda3\\envs\\tensor_flow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "                      max_features='auto', max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                      n_jobs=None, oob_score=False, random_state=None,\n",
       "                      verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest = RandomForestRegressor()\n",
    "\n",
    "forest.fit(X_train_norm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "213471794.19827056"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_pred = forest.predict(X_train_norm)\n",
    "mean_squared_error(y_train, last_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SfcFnOONyuNm"
   },
   "source": [
    "## Use the Keras Library to build an image recognition network using the Fashion-MNIST dataset (also comes with keras)\n",
    "\n",
    "- Load and preprocess the image data similar to how we preprocessed the MNIST data in class.\n",
    "- Make sure to one-hot encode your category labels\n",
    "- Make sure to have your final layer have as many nodes as the number of classes that you want to predict.\n",
    "- Try different hyperparameters. What is the highest accuracy that you are able to achieve.\n",
    "- Use the history object that is returned from model.fit to make graphs of the model's loss or train/validation accuracies by epoch. \n",
    "- Remember that neural networks fall prey to randomness so you may need to run your model multiple times (or use Cross Validation) in order to tell if a change to a hyperparameter is truly producing better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "szi6-IpuzaH1"
   },
   "outputs": [],
   "source": [
    "##### Your Code Here #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zv_3xNMjzdLI"
   },
   "source": [
    "## Stretch Goals:\n",
    "\n",
    "- Use Hyperparameter Tuning to make the accuracy of your models as high as possible. (error as low as possible)\n",
    "- Use Cross Validation techniques to get more consistent results with your model.\n",
    "- Use GridSearchCV to try different combinations of hyperparameters. \n",
    "- Start looking into other types of Keras layers for CNNs and RNNs maybe try and build a CNN model for fashion-MNIST to see how the results compare."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "LS_DS_433_Keras_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
