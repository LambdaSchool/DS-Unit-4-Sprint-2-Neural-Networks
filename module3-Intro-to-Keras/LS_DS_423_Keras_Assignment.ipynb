{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pBQsZEJmubLs"
   },
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "\n",
    "# Neural Network Framework (Keras)\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2 Assignment 3*\n",
    "\n",
    "## Use the Keras Library to build a Multi-Layer Perceptron Model on the Boston Housing dataset\n",
    "\n",
    "- The Boston Housing dataset comes with the Keras library so use Keras to import it into your notebook. \n",
    "- Normalize the data (all features should have roughly the same scale)\n",
    "- Import the type of model and layers that you will need from Keras.\n",
    "- Instantiate a model object and use `model.add()` to add layers to your model\n",
    "- Since this is a regression model you will have a single output node in the final layer.\n",
    "- Use activation functions that are appropriate for this task\n",
    "- Compile your model\n",
    "- Fit your model and report its accuracy in terms of Mean Squared Error\n",
    "- Use the history object that is returned from model.fit to make graphs of the model's loss or train/validation accuracies by epoch. \n",
    "- Run this same data through a linear regression model. Which achieves higher accuracy?\n",
    "- Do a little bit of feature engineering and see how that affects your neural network model. (you will need to change your model to accept more inputs)\n",
    "- After feature engineering, which model sees a greater accuracy boost due to the new features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8NLTAR87uYJ-"
   },
   "outputs": [],
   "source": [
    "##### Your Code Here #####\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import boston_housing\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
      "57344/57026 [==============================] - 0s 1us/step\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=13, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 10)                140       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 151\n",
      "Trainable params: 151\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = EarlyStopping(monitor='val_loss', min_delta=0.01, patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 404 samples, validate on 102 samples\n",
      "Epoch 1/1000\n",
      "404/404 [==============================] - 0s 827us/sample - loss: 14211.9419 - val_loss: 11738.6088\n",
      "Epoch 2/1000\n",
      "404/404 [==============================] - 0s 66us/sample - loss: 9082.0765 - val_loss: 7287.1563\n",
      "Epoch 3/1000\n",
      "404/404 [==============================] - 0s 76us/sample - loss: 5524.0660 - val_loss: 4354.4045\n",
      "Epoch 4/1000\n",
      "404/404 [==============================] - 0s 71us/sample - loss: 3251.6329 - val_loss: 2464.9421\n",
      "Epoch 5/1000\n",
      "404/404 [==============================] - 0s 71us/sample - loss: 1831.7303 - val_loss: 1376.6206\n",
      "Epoch 6/1000\n",
      "404/404 [==============================] - 0s 76us/sample - loss: 1037.3342 - val_loss: 814.7824\n",
      "Epoch 7/1000\n",
      "404/404 [==============================] - 0s 81us/sample - loss: 655.7459 - val_loss: 538.8914\n",
      "Epoch 8/1000\n",
      "404/404 [==============================] - 0s 71us/sample - loss: 474.1028 - val_loss: 422.7641\n",
      "Epoch 9/1000\n",
      "404/404 [==============================] - 0s 77us/sample - loss: 397.3030 - val_loss: 370.9660\n",
      "Epoch 10/1000\n",
      "404/404 [==============================] - 0s 83us/sample - loss: 359.2115 - val_loss: 342.9066\n",
      "Epoch 11/1000\n",
      "404/404 [==============================] - 0s 77us/sample - loss: 336.0643 - val_loss: 321.8798\n",
      "Epoch 12/1000\n",
      "404/404 [==============================] - 0s 79us/sample - loss: 314.5502 - val_loss: 304.2797\n",
      "Epoch 13/1000\n",
      "404/404 [==============================] - 0s 73us/sample - loss: 295.7193 - val_loss: 287.4499\n",
      "Epoch 14/1000\n",
      "404/404 [==============================] - 0s 78us/sample - loss: 278.7780 - val_loss: 270.8510\n",
      "Epoch 15/1000\n",
      "404/404 [==============================] - 0s 87us/sample - loss: 261.2392 - val_loss: 256.5683\n",
      "Epoch 16/1000\n",
      "404/404 [==============================] - 0s 84us/sample - loss: 246.5112 - val_loss: 242.4915\n",
      "Epoch 17/1000\n",
      "404/404 [==============================] - 0s 79us/sample - loss: 231.9563 - val_loss: 228.7987\n",
      "Epoch 18/1000\n",
      "404/404 [==============================] - 0s 79us/sample - loss: 218.2273 - val_loss: 216.5826\n",
      "Epoch 19/1000\n",
      "404/404 [==============================] - 0s 79us/sample - loss: 206.1014 - val_loss: 205.0692\n",
      "Epoch 20/1000\n",
      "404/404 [==============================] - 0s 74us/sample - loss: 194.4045 - val_loss: 195.0811\n",
      "Epoch 21/1000\n",
      "404/404 [==============================] - 0s 68us/sample - loss: 183.9379 - val_loss: 185.4358\n",
      "Epoch 22/1000\n",
      "404/404 [==============================] - 0s 69us/sample - loss: 174.1993 - val_loss: 176.3343\n",
      "Epoch 23/1000\n",
      "404/404 [==============================] - 0s 74us/sample - loss: 165.5190 - val_loss: 167.6996\n",
      "Epoch 24/1000\n",
      "404/404 [==============================] - 0s 74us/sample - loss: 157.0378 - val_loss: 160.0241\n",
      "Epoch 25/1000\n",
      "404/404 [==============================] - 0s 79us/sample - loss: 149.3402 - val_loss: 152.9218\n",
      "Epoch 26/1000\n",
      "404/404 [==============================] - 0s 90us/sample - loss: 142.2878 - val_loss: 146.1623\n",
      "Epoch 27/1000\n",
      "404/404 [==============================] - 0s 74us/sample - loss: 135.8562 - val_loss: 140.3054\n",
      "Epoch 28/1000\n",
      "404/404 [==============================] - 0s 67us/sample - loss: 130.4383 - val_loss: 134.6745\n",
      "Epoch 29/1000\n",
      "404/404 [==============================] - 0s 76us/sample - loss: 124.8757 - val_loss: 129.7978\n",
      "Epoch 30/1000\n",
      "404/404 [==============================] - 0s 71us/sample - loss: 120.2890 - val_loss: 125.4069\n",
      "Epoch 31/1000\n",
      "404/404 [==============================] - 0s 76us/sample - loss: 115.7972 - val_loss: 121.3181\n",
      "Epoch 32/1000\n",
      "404/404 [==============================] - 0s 74us/sample - loss: 111.8929 - val_loss: 117.3687\n",
      "Epoch 33/1000\n",
      "404/404 [==============================] - 0s 86us/sample - loss: 108.2783 - val_loss: 113.8836\n",
      "Epoch 34/1000\n",
      "404/404 [==============================] - 0s 68us/sample - loss: 105.2061 - val_loss: 110.8106\n",
      "Epoch 35/1000\n",
      "404/404 [==============================] - 0s 113us/sample - loss: 101.9261 - val_loss: 107.7173\n",
      "Epoch 36/1000\n",
      "404/404 [==============================] - 0s 77us/sample - loss: 99.5683 - val_loss: 105.1066\n",
      "Epoch 37/1000\n",
      "404/404 [==============================] - 0s 79us/sample - loss: 96.8456 - val_loss: 102.5621\n",
      "Epoch 38/1000\n",
      "404/404 [==============================] - 0s 78us/sample - loss: 94.7621 - val_loss: 100.1774\n",
      "Epoch 39/1000\n",
      "404/404 [==============================] - 0s 75us/sample - loss: 92.5225 - val_loss: 98.2732\n",
      "Epoch 40/1000\n",
      "404/404 [==============================] - 0s 70us/sample - loss: 90.7166 - val_loss: 96.6622\n",
      "Epoch 41/1000\n",
      "404/404 [==============================] - 0s 73us/sample - loss: 89.0944 - val_loss: 94.8633\n",
      "Epoch 42/1000\n",
      "404/404 [==============================] - 0s 69us/sample - loss: 87.4468 - val_loss: 93.4547\n",
      "Epoch 43/1000\n",
      "404/404 [==============================] - 0s 83us/sample - loss: 86.0024 - val_loss: 91.8444\n",
      "Epoch 44/1000\n",
      "404/404 [==============================] - 0s 80us/sample - loss: 84.6510 - val_loss: 90.5115\n",
      "Epoch 45/1000\n",
      "404/404 [==============================] - 0s 68us/sample - loss: 83.3648 - val_loss: 89.1138\n",
      "Epoch 46/1000\n",
      "404/404 [==============================] - 0s 76us/sample - loss: 82.1648 - val_loss: 88.1822\n",
      "Epoch 47/1000\n",
      "404/404 [==============================] - 0s 72us/sample - loss: 81.0967 - val_loss: 87.0083\n",
      "Epoch 48/1000\n",
      "404/404 [==============================] - 0s 80us/sample - loss: 80.2344 - val_loss: 86.0306\n",
      "Epoch 49/1000\n",
      "404/404 [==============================] - 0s 68us/sample - loss: 79.0571 - val_loss: 85.0532\n",
      "Epoch 50/1000\n",
      "404/404 [==============================] - 0s 73us/sample - loss: 78.1934 - val_loss: 84.1964\n",
      "Epoch 51/1000\n",
      "404/404 [==============================] - 0s 69us/sample - loss: 77.2928 - val_loss: 83.4905\n",
      "Epoch 52/1000\n",
      "404/404 [==============================] - 0s 81us/sample - loss: 76.1559 - val_loss: 82.5083\n",
      "Epoch 53/1000\n",
      "404/404 [==============================] - 0s 72us/sample - loss: 75.3527 - val_loss: 81.6627\n",
      "Epoch 54/1000\n",
      "404/404 [==============================] - 0s 65us/sample - loss: 74.5056 - val_loss: 81.0435\n",
      "Epoch 55/1000\n",
      "404/404 [==============================] - 0s 84us/sample - loss: 73.5734 - val_loss: 80.4548\n",
      "Epoch 56/1000\n",
      "404/404 [==============================] - 0s 79us/sample - loss: 73.1772 - val_loss: 79.9358\n",
      "Epoch 57/1000\n",
      "404/404 [==============================] - 0s 60us/sample - loss: 72.1663 - val_loss: 79.0511\n",
      "Epoch 58/1000\n",
      "404/404 [==============================] - 0s 67us/sample - loss: 71.6718 - val_loss: 78.4194\n",
      "Epoch 59/1000\n",
      "404/404 [==============================] - 0s 77us/sample - loss: 70.8733 - val_loss: 78.0420\n",
      "Epoch 60/1000\n",
      "404/404 [==============================] - 0s 68us/sample - loss: 70.1584 - val_loss: 77.5309\n",
      "Epoch 61/1000\n",
      "404/404 [==============================] - 0s 89us/sample - loss: 69.5761 - val_loss: 77.0331\n",
      "Epoch 62/1000\n",
      "404/404 [==============================] - 0s 74us/sample - loss: 69.1279 - val_loss: 76.6551\n",
      "Epoch 63/1000\n",
      "404/404 [==============================] - 0s 71us/sample - loss: 68.4776 - val_loss: 76.1230\n",
      "Epoch 64/1000\n",
      "404/404 [==============================] - 0s 88us/sample - loss: 67.8815 - val_loss: 75.7867\n",
      "Epoch 65/1000\n",
      "404/404 [==============================] - 0s 100us/sample - loss: 67.5233 - val_loss: 75.4246\n",
      "Epoch 66/1000\n",
      "404/404 [==============================] - 0s 80us/sample - loss: 66.9541 - val_loss: 75.0833\n",
      "Epoch 67/1000\n",
      "404/404 [==============================] - 0s 110us/sample - loss: 66.5495 - val_loss: 74.8307\n",
      "Epoch 68/1000\n",
      "404/404 [==============================] - 0s 92us/sample - loss: 66.2267 - val_loss: 74.4115\n",
      "Epoch 69/1000\n",
      "404/404 [==============================] - 0s 85us/sample - loss: 65.8525 - val_loss: 74.2186\n",
      "Epoch 70/1000\n",
      "404/404 [==============================] - 0s 91us/sample - loss: 65.2951 - val_loss: 73.8387\n",
      "Epoch 71/1000\n",
      "404/404 [==============================] - 0s 61us/sample - loss: 65.5037 - val_loss: 73.6574\n",
      "Epoch 72/1000\n",
      "404/404 [==============================] - 0s 58us/sample - loss: 64.6516 - val_loss: 73.3861\n",
      "Epoch 73/1000\n",
      "404/404 [==============================] - 0s 61us/sample - loss: 64.3467 - val_loss: 73.0881\n",
      "Epoch 74/1000\n",
      "404/404 [==============================] - 0s 66us/sample - loss: 63.9673 - val_loss: 72.7717\n",
      "Epoch 75/1000\n",
      "404/404 [==============================] - 0s 111us/sample - loss: 63.6733 - val_loss: 72.4550\n",
      "Epoch 76/1000\n",
      "404/404 [==============================] - 0s 75us/sample - loss: 63.5299 - val_loss: 72.0828\n",
      "Epoch 77/1000\n",
      "404/404 [==============================] - 0s 72us/sample - loss: 63.2251 - val_loss: 71.8682\n",
      "Epoch 78/1000\n",
      "404/404 [==============================] - 0s 68us/sample - loss: 62.9880 - val_loss: 71.7062\n",
      "Epoch 79/1000\n",
      "404/404 [==============================] - 0s 92us/sample - loss: 62.7207 - val_loss: 71.3435\n",
      "Epoch 80/1000\n",
      "404/404 [==============================] - 0s 107us/sample - loss: 62.4170 - val_loss: 71.0655\n",
      "Epoch 81/1000\n",
      "404/404 [==============================] - 0s 86us/sample - loss: 62.1660 - val_loss: 70.7671\n",
      "Epoch 82/1000\n",
      "404/404 [==============================] - 0s 111us/sample - loss: 61.9627 - val_loss: 70.5488\n",
      "Epoch 83/1000\n",
      "404/404 [==============================] - 0s 92us/sample - loss: 61.7020 - val_loss: 70.3851\n",
      "Epoch 84/1000\n",
      "404/404 [==============================] - 0s 107us/sample - loss: 61.5414 - val_loss: 70.0997\n",
      "Epoch 85/1000\n",
      "404/404 [==============================] - 0s 77us/sample - loss: 61.2180 - val_loss: 69.8832\n",
      "Epoch 86/1000\n",
      "404/404 [==============================] - 0s 68us/sample - loss: 61.0242 - val_loss: 69.6358\n",
      "Epoch 87/1000\n",
      "404/404 [==============================] - 0s 71us/sample - loss: 60.8993 - val_loss: 69.4645\n",
      "Epoch 88/1000\n",
      "404/404 [==============================] - 0s 76us/sample - loss: 60.6199 - val_loss: 69.2564\n",
      "Epoch 89/1000\n",
      "404/404 [==============================] - 0s 68us/sample - loss: 60.2217 - val_loss: 69.0958\n",
      "Epoch 90/1000\n",
      "404/404 [==============================] - 0s 85us/sample - loss: 60.1257 - val_loss: 68.9042\n",
      "Epoch 91/1000\n",
      "404/404 [==============================] - 0s 66us/sample - loss: 59.7009 - val_loss: 68.7355\n",
      "Epoch 92/1000\n",
      "404/404 [==============================] - 0s 75us/sample - loss: 59.4845 - val_loss: 68.4923\n",
      "Epoch 93/1000\n",
      "404/404 [==============================] - 0s 65us/sample - loss: 59.2269 - val_loss: 68.2324\n",
      "Epoch 94/1000\n",
      "404/404 [==============================] - 0s 72us/sample - loss: 58.9359 - val_loss: 68.0697\n",
      "Epoch 95/1000\n",
      "404/404 [==============================] - 0s 91us/sample - loss: 58.7673 - val_loss: 67.9454\n",
      "Epoch 96/1000\n",
      "404/404 [==============================] - 0s 102us/sample - loss: 58.6723 - val_loss: 67.4485\n",
      "Epoch 97/1000\n",
      "404/404 [==============================] - 0s 88us/sample - loss: 58.2284 - val_loss: 67.3350\n",
      "Epoch 98/1000\n",
      "404/404 [==============================] - 0s 93us/sample - loss: 58.0905 - val_loss: 66.8452\n",
      "Epoch 99/1000\n",
      "404/404 [==============================] - 0s 75us/sample - loss: 57.8631 - val_loss: 66.6419\n",
      "Epoch 100/1000\n",
      "404/404 [==============================] - 0s 75us/sample - loss: 57.6073 - val_loss: 66.5202\n",
      "Epoch 101/1000\n",
      "404/404 [==============================] - 0s 63us/sample - loss: 57.5431 - val_loss: 66.2987\n",
      "Epoch 102/1000\n",
      "404/404 [==============================] - 0s 59us/sample - loss: 57.4484 - val_loss: 66.0707\n",
      "Epoch 103/1000\n",
      "404/404 [==============================] - 0s 68us/sample - loss: 57.4715 - val_loss: 66.1501\n",
      "Epoch 104/1000\n",
      "404/404 [==============================] - 0s 57us/sample - loss: 56.8113 - val_loss: 65.4766\n",
      "Epoch 105/1000\n",
      "404/404 [==============================] - 0s 76us/sample - loss: 56.6566 - val_loss: 65.2970\n",
      "Epoch 106/1000\n",
      "404/404 [==============================] - 0s 67us/sample - loss: 56.6234 - val_loss: 65.0276\n",
      "Epoch 107/1000\n",
      "404/404 [==============================] - 0s 66us/sample - loss: 56.2860 - val_loss: 64.6686\n",
      "Epoch 108/1000\n",
      "404/404 [==============================] - 0s 71us/sample - loss: 56.0720 - val_loss: 64.6083\n",
      "Epoch 109/1000\n",
      "404/404 [==============================] - 0s 66us/sample - loss: 55.8973 - val_loss: 64.4977\n",
      "Epoch 110/1000\n",
      "404/404 [==============================] - 0s 65us/sample - loss: 55.7866 - val_loss: 64.2260\n",
      "Epoch 111/1000\n",
      "404/404 [==============================] - 0s 68us/sample - loss: 55.5650 - val_loss: 64.0171\n",
      "Epoch 112/1000\n",
      "404/404 [==============================] - 0s 69us/sample - loss: 55.4646 - val_loss: 63.6855\n",
      "Epoch 113/1000\n",
      "404/404 [==============================] - 0s 73us/sample - loss: 55.2878 - val_loss: 63.6366\n",
      "Epoch 114/1000\n",
      "404/404 [==============================] - 0s 75us/sample - loss: 55.1529 - val_loss: 63.4415\n",
      "Epoch 115/1000\n",
      "404/404 [==============================] - 0s 68us/sample - loss: 54.9501 - val_loss: 63.0186\n",
      "Epoch 116/1000\n",
      "404/404 [==============================] - 0s 76us/sample - loss: 54.9024 - val_loss: 62.9245\n",
      "Epoch 117/1000\n",
      "404/404 [==============================] - 0s 61us/sample - loss: 54.5617 - val_loss: 62.7331\n",
      "Epoch 118/1000\n",
      "404/404 [==============================] - 0s 60us/sample - loss: 54.2835 - val_loss: 62.4041\n",
      "Epoch 119/1000\n",
      "404/404 [==============================] - 0s 78us/sample - loss: 54.2232 - val_loss: 62.2602\n",
      "Epoch 120/1000\n",
      "404/404 [==============================] - 0s 57us/sample - loss: 53.9953 - val_loss: 62.0850\n",
      "Epoch 121/1000\n",
      "404/404 [==============================] - 0s 86us/sample - loss: 53.7824 - val_loss: 61.8123\n",
      "Epoch 122/1000\n",
      "404/404 [==============================] - 0s 75us/sample - loss: 53.6278 - val_loss: 61.7519\n",
      "Epoch 123/1000\n",
      "404/404 [==============================] - 0s 59us/sample - loss: 53.7327 - val_loss: 61.5227\n",
      "Epoch 124/1000\n",
      "404/404 [==============================] - 0s 72us/sample - loss: 53.5508 - val_loss: 61.6193\n",
      "Epoch 125/1000\n",
      "404/404 [==============================] - 0s 72us/sample - loss: 53.5476 - val_loss: 61.2075\n",
      "Epoch 126/1000\n",
      "404/404 [==============================] - 0s 66us/sample - loss: 53.1128 - val_loss: 61.5363\n",
      "Epoch 127/1000\n",
      "404/404 [==============================] - 0s 99us/sample - loss: 52.7861 - val_loss: 61.0493\n",
      "Epoch 128/1000\n",
      "404/404 [==============================] - 0s 74us/sample - loss: 52.5541 - val_loss: 60.7290\n",
      "Epoch 129/1000\n",
      "404/404 [==============================] - 0s 89us/sample - loss: 52.3354 - val_loss: 60.5213\n",
      "Epoch 130/1000\n",
      "404/404 [==============================] - 0s 91us/sample - loss: 52.2586 - val_loss: 60.0993\n",
      "Epoch 131/1000\n",
      "404/404 [==============================] - 0s 72us/sample - loss: 52.0729 - val_loss: 60.2736\n",
      "Epoch 132/1000\n",
      "404/404 [==============================] - 0s 62us/sample - loss: 51.9739 - val_loss: 59.9894\n",
      "Epoch 133/1000\n",
      "404/404 [==============================] - 0s 60us/sample - loss: 51.6238 - val_loss: 59.9128\n",
      "Epoch 134/1000\n",
      "404/404 [==============================] - 0s 75us/sample - loss: 51.4880 - val_loss: 59.6936\n",
      "Epoch 135/1000\n",
      "404/404 [==============================] - 0s 63us/sample - loss: 51.5299 - val_loss: 59.2862\n",
      "Epoch 136/1000\n",
      "404/404 [==============================] - 0s 77us/sample - loss: 51.1917 - val_loss: 59.0392\n",
      "Epoch 137/1000\n",
      "404/404 [==============================] - 0s 64us/sample - loss: 51.0015 - val_loss: 58.8964\n",
      "Epoch 138/1000\n",
      "404/404 [==============================] - 0s 73us/sample - loss: 50.8866 - val_loss: 58.8253\n",
      "Epoch 139/1000\n",
      "404/404 [==============================] - 0s 68us/sample - loss: 50.8804 - val_loss: 58.7247\n",
      "Epoch 140/1000\n",
      "404/404 [==============================] - 0s 61us/sample - loss: 50.6130 - val_loss: 58.4779\n",
      "Epoch 141/1000\n",
      "404/404 [==============================] - 0s 106us/sample - loss: 50.6909 - val_loss: 58.0628\n",
      "Epoch 142/1000\n",
      "404/404 [==============================] - 0s 79us/sample - loss: 50.1075 - val_loss: 58.2150\n",
      "Epoch 143/1000\n",
      "404/404 [==============================] - 0s 120us/sample - loss: 50.6297 - val_loss: 58.4081\n",
      "Epoch 144/1000\n",
      "404/404 [==============================] - 0s 70us/sample - loss: 50.0667 - val_loss: 57.7944\n",
      "Epoch 145/1000\n",
      "404/404 [==============================] - 0s 65us/sample - loss: 50.0086 - val_loss: 57.6019\n",
      "Epoch 146/1000\n",
      "404/404 [==============================] - 0s 73us/sample - loss: 49.6130 - val_loss: 57.1303\n",
      "Epoch 147/1000\n",
      "404/404 [==============================] - 0s 80us/sample - loss: 49.6305 - val_loss: 57.0774\n",
      "Epoch 148/1000\n",
      "404/404 [==============================] - 0s 59us/sample - loss: 49.3657 - val_loss: 56.9468\n",
      "Epoch 149/1000\n",
      "404/404 [==============================] - 0s 73us/sample - loss: 49.6595 - val_loss: 56.8672\n",
      "Epoch 150/1000\n",
      "404/404 [==============================] - 0s 63us/sample - loss: 49.1890 - val_loss: 56.7763\n",
      "Epoch 151/1000\n",
      "404/404 [==============================] - 0s 74us/sample - loss: 49.0436 - val_loss: 56.3739\n",
      "Epoch 152/1000\n",
      "404/404 [==============================] - 0s 77us/sample - loss: 48.8156 - val_loss: 56.3530\n",
      "Epoch 153/1000\n",
      "404/404 [==============================] - 0s 76us/sample - loss: 48.5321 - val_loss: 55.9337\n",
      "Epoch 154/1000\n",
      "404/404 [==============================] - 0s 64us/sample - loss: 48.4433 - val_loss: 55.9209\n",
      "Epoch 155/1000\n",
      "404/404 [==============================] - 0s 62us/sample - loss: 48.3558 - val_loss: 55.7772\n",
      "Epoch 156/1000\n",
      "404/404 [==============================] - 0s 73us/sample - loss: 48.0222 - val_loss: 55.7289\n",
      "Epoch 157/1000\n",
      "404/404 [==============================] - 0s 64us/sample - loss: 48.0751 - val_loss: 55.4725\n",
      "Epoch 158/1000\n",
      "404/404 [==============================] - 0s 64us/sample - loss: 47.9637 - val_loss: 55.1208\n",
      "Epoch 159/1000\n",
      "404/404 [==============================] - 0s 69us/sample - loss: 47.8728 - val_loss: 55.5489\n",
      "Epoch 160/1000\n",
      "404/404 [==============================] - 0s 73us/sample - loss: 47.5742 - val_loss: 54.9108\n",
      "Epoch 161/1000\n",
      "404/404 [==============================] - 0s 59us/sample - loss: 47.6821 - val_loss: 54.7587\n",
      "Epoch 162/1000\n",
      "404/404 [==============================] - 0s 71us/sample - loss: 47.5435 - val_loss: 54.7226\n",
      "Epoch 163/1000\n",
      "404/404 [==============================] - 0s 81us/sample - loss: 47.5426 - val_loss: 54.2613\n",
      "Epoch 164/1000\n",
      "404/404 [==============================] - 0s 80us/sample - loss: 47.0714 - val_loss: 54.1368\n",
      "Epoch 165/1000\n",
      "404/404 [==============================] - 0s 96us/sample - loss: 47.3506 - val_loss: 54.2135\n",
      "Epoch 166/1000\n",
      "404/404 [==============================] - 0s 82us/sample - loss: 46.4899 - val_loss: 53.9835\n",
      "Epoch 167/1000\n",
      "404/404 [==============================] - 0s 92us/sample - loss: 46.8619 - val_loss: 53.7817\n",
      "Epoch 168/1000\n",
      "404/404 [==============================] - 0s 94us/sample - loss: 46.4886 - val_loss: 53.4675\n",
      "Epoch 169/1000\n",
      "404/404 [==============================] - 0s 75us/sample - loss: 46.3973 - val_loss: 53.4520\n",
      "Epoch 170/1000\n",
      "404/404 [==============================] - 0s 87us/sample - loss: 46.0977 - val_loss: 53.7725\n",
      "Epoch 171/1000\n",
      "404/404 [==============================] - 0s 63us/sample - loss: 46.1471 - val_loss: 53.1422\n",
      "Epoch 172/1000\n",
      "404/404 [==============================] - 0s 66us/sample - loss: 46.0079 - val_loss: 53.0241\n",
      "Epoch 173/1000\n",
      "404/404 [==============================] - 0s 89us/sample - loss: 45.7432 - val_loss: 52.8056\n",
      "Epoch 174/1000\n",
      "404/404 [==============================] - 0s 56us/sample - loss: 45.6944 - val_loss: 52.6395\n",
      "Epoch 175/1000\n",
      "404/404 [==============================] - 0s 92us/sample - loss: 45.4871 - val_loss: 52.4388\n",
      "Epoch 176/1000\n",
      "404/404 [==============================] - 0s 62us/sample - loss: 45.4429 - val_loss: 52.3240\n",
      "Epoch 177/1000\n",
      "404/404 [==============================] - 0s 80us/sample - loss: 45.2975 - val_loss: 52.3618\n",
      "Epoch 178/1000\n",
      "404/404 [==============================] - 0s 71us/sample - loss: 45.1287 - val_loss: 52.1694\n",
      "Epoch 179/1000\n",
      "404/404 [==============================] - 0s 85us/sample - loss: 45.0905 - val_loss: 52.3290\n",
      "Epoch 180/1000\n",
      "404/404 [==============================] - 0s 69us/sample - loss: 45.1000 - val_loss: 51.6915\n",
      "Epoch 181/1000\n",
      "404/404 [==============================] - 0s 87us/sample - loss: 45.1413 - val_loss: 51.4090\n",
      "Epoch 182/1000\n",
      "404/404 [==============================] - 0s 62us/sample - loss: 44.5711 - val_loss: 51.6132\n",
      "Epoch 183/1000\n",
      "404/404 [==============================] - 0s 73us/sample - loss: 44.7443 - val_loss: 51.1592\n",
      "Epoch 184/1000\n",
      "404/404 [==============================] - 0s 65us/sample - loss: 44.3317 - val_loss: 51.0709\n",
      "Epoch 185/1000\n",
      "404/404 [==============================] - 0s 76us/sample - loss: 44.2497 - val_loss: 50.9525\n",
      "Epoch 186/1000\n",
      "404/404 [==============================] - 0s 73us/sample - loss: 44.2506 - val_loss: 50.7852\n",
      "Epoch 187/1000\n",
      "404/404 [==============================] - 0s 68us/sample - loss: 44.1961 - val_loss: 50.5391\n",
      "Epoch 188/1000\n",
      "404/404 [==============================] - 0s 82us/sample - loss: 44.0155 - val_loss: 50.4737\n",
      "Epoch 189/1000\n",
      "404/404 [==============================] - 0s 74us/sample - loss: 43.8465 - val_loss: 50.5458\n",
      "Epoch 190/1000\n",
      "404/404 [==============================] - 0s 81us/sample - loss: 43.6050 - val_loss: 50.1783\n",
      "Epoch 191/1000\n",
      "404/404 [==============================] - 0s 91us/sample - loss: 43.5807 - val_loss: 50.1621\n",
      "Epoch 192/1000\n",
      "404/404 [==============================] - 0s 101us/sample - loss: 44.3356 - val_loss: 50.3339\n",
      "Epoch 193/1000\n",
      "404/404 [==============================] - 0s 88us/sample - loss: 44.5961 - val_loss: 49.6698\n",
      "Epoch 194/1000\n",
      "404/404 [==============================] - 0s 77us/sample - loss: 43.1649 - val_loss: 50.2485\n",
      "Epoch 195/1000\n",
      "404/404 [==============================] - 0s 75us/sample - loss: 43.0692 - val_loss: 49.4819\n",
      "Epoch 196/1000\n",
      "404/404 [==============================] - 0s 80us/sample - loss: 42.9791 - val_loss: 49.2862\n",
      "Epoch 197/1000\n",
      "404/404 [==============================] - 0s 79us/sample - loss: 43.1315 - val_loss: 49.1191\n",
      "Epoch 198/1000\n",
      "404/404 [==============================] - 0s 79us/sample - loss: 42.9045 - val_loss: 49.0453\n",
      "Epoch 199/1000\n",
      "404/404 [==============================] - 0s 82us/sample - loss: 42.5906 - val_loss: 48.9822\n",
      "Epoch 200/1000\n",
      "404/404 [==============================] - 0s 65us/sample - loss: 42.8707 - val_loss: 49.0120\n",
      "Epoch 201/1000\n",
      "404/404 [==============================] - 0s 61us/sample - loss: 42.5864 - val_loss: 48.6656\n",
      "Epoch 202/1000\n",
      "404/404 [==============================] - 0s 76us/sample - loss: 42.2116 - val_loss: 48.5422\n",
      "Epoch 203/1000\n",
      "404/404 [==============================] - 0s 69us/sample - loss: 42.0955 - val_loss: 48.5532\n",
      "Epoch 204/1000\n",
      "404/404 [==============================] - 0s 75us/sample - loss: 42.4093 - val_loss: 48.2966\n",
      "Epoch 205/1000\n",
      "404/404 [==============================] - 0s 80us/sample - loss: 41.9227 - val_loss: 48.4260\n",
      "Epoch 206/1000\n",
      "404/404 [==============================] - 0s 75us/sample - loss: 42.4084 - val_loss: 48.0592\n",
      "Epoch 207/1000\n",
      "404/404 [==============================] - 0s 81us/sample - loss: 43.1684 - val_loss: 47.7573\n",
      "Epoch 208/1000\n",
      "404/404 [==============================] - 0s 89us/sample - loss: 42.0762 - val_loss: 47.9341\n",
      "Epoch 209/1000\n",
      "404/404 [==============================] - 0s 80us/sample - loss: 42.6130 - val_loss: 47.6360\n",
      "Epoch 210/1000\n",
      "404/404 [==============================] - 0s 73us/sample - loss: 41.6186 - val_loss: 47.9979\n",
      "Epoch 211/1000\n",
      "404/404 [==============================] - 0s 79us/sample - loss: 41.9006 - val_loss: 47.3304\n",
      "Epoch 212/1000\n",
      "404/404 [==============================] - 0s 79us/sample - loss: 40.9307 - val_loss: 47.8247\n",
      "Epoch 213/1000\n",
      "404/404 [==============================] - 0s 66us/sample - loss: 41.2592 - val_loss: 47.1586\n",
      "Epoch 214/1000\n",
      "404/404 [==============================] - 0s 85us/sample - loss: 40.9675 - val_loss: 47.1034\n",
      "Epoch 215/1000\n",
      "404/404 [==============================] - 0s 65us/sample - loss: 41.0822 - val_loss: 46.8912\n",
      "Epoch 216/1000\n",
      "404/404 [==============================] - 0s 88us/sample - loss: 40.9794 - val_loss: 46.6153\n",
      "Epoch 217/1000\n",
      "404/404 [==============================] - 0s 75us/sample - loss: 40.8331 - val_loss: 46.5208\n",
      "Epoch 218/1000\n",
      "404/404 [==============================] - 0s 87us/sample - loss: 40.6869 - val_loss: 46.9861\n",
      "Epoch 219/1000\n",
      "404/404 [==============================] - 0s 72us/sample - loss: 40.9349 - val_loss: 46.4000\n",
      "Epoch 220/1000\n",
      "404/404 [==============================] - 0s 107us/sample - loss: 40.7737 - val_loss: 46.5799\n",
      "Epoch 221/1000\n",
      "404/404 [==============================] - 0s 75us/sample - loss: 41.5628 - val_loss: 46.0739\n",
      "Epoch 222/1000\n",
      "404/404 [==============================] - 0s 93us/sample - loss: 41.2948 - val_loss: 46.5796\n",
      "Epoch 223/1000\n",
      "404/404 [==============================] - 0s 77us/sample - loss: 40.1475 - val_loss: 45.8770\n",
      "Epoch 224/1000\n",
      "404/404 [==============================] - 0s 86us/sample - loss: 39.9935 - val_loss: 46.1540\n",
      "Epoch 225/1000\n",
      "404/404 [==============================] - 0s 94us/sample - loss: 40.0227 - val_loss: 45.6768\n",
      "Epoch 226/1000\n",
      "404/404 [==============================] - 0s 66us/sample - loss: 39.9125 - val_loss: 45.6388\n",
      "Epoch 227/1000\n",
      "404/404 [==============================] - 0s 74us/sample - loss: 39.7394 - val_loss: 45.3996\n",
      "Epoch 228/1000\n",
      "404/404 [==============================] - 0s 118us/sample - loss: 39.6512 - val_loss: 45.5308\n",
      "Epoch 229/1000\n",
      "404/404 [==============================] - 0s 67us/sample - loss: 40.2943 - val_loss: 45.5760\n",
      "Epoch 230/1000\n",
      "404/404 [==============================] - 0s 53us/sample - loss: 40.6805 - val_loss: 45.4640\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7feedc44ff90>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=1000, validation_data=(X_test, y_test), callbacks=[stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SfcFnOONyuNm"
   },
   "source": [
    "## Use the Keras Library to build an image recognition network using the Fashion-MNIST dataset (also comes with keras)\n",
    "\n",
    "- Load and preprocess the image data similar to how we preprocessed the MNIST data in class.\n",
    "- Make sure to one-hot encode your category labels\n",
    "- The number of nodes in your output layer should equal the number of classes you want to predict for Fashion-MNIST.\n",
    "- Try different hyperparameters. What is the highest accuracy that you are able to achieve.\n",
    "- Use the history object that is returned from model.fit to make graphs of the model's loss or train/validation accuracies by epoch. \n",
    "- Remember that neural networks fall prey to randomness so you may need to run your model multiple times (or use Cross Validation) in order to tell if a change to a hyperparameter is truly producing better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "szi6-IpuzaH1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 1s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "8192/5148 [===============================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "##### Your Code Here #####\n",
    "\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 11s 186us/sample - loss: 4.7101 - accuracy: 0.7831 - val_loss: 0.6079 - val_accuracy: 0.7978\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 11s 178us/sample - loss: 0.5027 - accuracy: 0.8269 - val_loss: 0.5111 - val_accuracy: 0.8313\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 10s 175us/sample - loss: 0.5116 - accuracy: 0.8277 - val_loss: 0.6707 - val_accuracy: 0.8169\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 10s 173us/sample - loss: 0.4958 - accuracy: 0.8336 - val_loss: 0.6431 - val_accuracy: 0.8088\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 11s 175us/sample - loss: 0.4923 - accuracy: 0.8352 - val_loss: 0.5498 - val_accuracy: 0.8217\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7feed457a810>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(28,28)))\n",
    "model.add(Dense(1280, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "stop = EarlyStopping(monitor='val_accuracy', min_delta=0.01, patience=3)\n",
    "model.fit(X_train, y_train, epochs = 100, validation_data=(X_test, y_test), callbacks=[stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1280)              1004800   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                12810     \n",
      "=================================================================\n",
      "Total params: 1,017,610\n",
      "Trainable params: 1,017,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fee84026210>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X_train[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fee60064c50>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_test[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected flatten_input to have 3 dimensions, but got array with shape (28, 28)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-3ae8e0f01ba6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/share/virtualenvs/lambda-NHOSnBo2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1011\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/lambda-NHOSnBo2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m         workers=workers, use_multiprocessing=use_multiprocessing, **kwargs)\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/lambda-NHOSnBo2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_model_iteration\u001b[0;34m(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    424\u001b[0m           \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m           use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    427\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madapter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m       \u001b[0muse_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_samples\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/lambda-NHOSnBo2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[0;34m(model, mode, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    644\u001b[0m     \u001b[0mstandardize_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m     x, y, sample_weights = standardize(\n\u001b[0;32m--> 646\u001b[0;31m         x, y, sample_weight=sample_weights)\n\u001b[0m\u001b[1;32m    647\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0madapter_cls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mdata_adapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mListsOfScalarsDataAdapter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0mstandardize_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstandardize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/lambda-NHOSnBo2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2381\u001b[0m         \u001b[0mis_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2382\u001b[0m         \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2383\u001b[0;31m         batch_size=batch_size)\n\u001b[0m\u001b[1;32m   2384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2385\u001b[0m   def _standardize_tensors(self, x, y, sample_weight, run_eagerly, dict_inputs,\n",
      "\u001b[0;32m~/.local/share/virtualenvs/lambda-NHOSnBo2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_tensors\u001b[0;34m(self, x, y, sample_weight, run_eagerly, dict_inputs, is_dataset, class_weight, batch_size)\u001b[0m\n\u001b[1;32m   2408\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2409\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2410\u001b[0;31m           exception_prefix='input')\n\u001b[0m\u001b[1;32m   2411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2412\u001b[0m     \u001b[0;31m# Get typespecs for the input data and sanitize it if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/lambda-NHOSnBo2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    571\u001b[0m                            \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m                            \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m                            'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    574\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m           \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected flatten_input to have 3 dimensions, but got array with shape (28, 28)"
     ]
    }
   ],
   "source": [
    "img = model.predict(X_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fee60117050>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zv_3xNMjzdLI"
   },
   "source": [
    "## Stretch Goals:\n",
    "\n",
    "- Use Hyperparameter Tuning to make the accuracy of your models as high as possible. (error as low as possible)\n",
    "- Use Cross Validation techniques to get more consistent results with your model.\n",
    "- Use GridSearchCV to try different combinations of hyperparameters. \n",
    "- Start looking into other types of Keras layers for CNNs and RNNs maybe try and build a CNN model for fashion-MNIST to see how the results compare."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "LS_DS_433_Keras_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
