{
  "cells": [
    {
      "metadata": {
        "colab_type": "text",
        "id": "pBQsZEJmubLs"
      },
      "cell_type": "markdown",
      "source": "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n<br></br>\n\n# Neural Network Framework (Keras)\n\n## *Data Science Unit 4 Sprint 2 Assignmnet 3*\n\n## Use the Keras Library to build a Multi-Layer Perceptron Model on the Boston Housing dataset\n\n- The Boston Housing dataset comes with the Keras library so use Keras to import it into your notebook. \n- Normalize the data (all features should have roughly the same scale)\n- Import the type of model and layers that you will need from Keras.\n- Instantiate a model object and use `model.add()` to add layers to your model\n- Since this is a regression model you will have a single output node in the final layer.\n- Use activation functions that are appropriate for this task\n- Compile your model\n- Fit your model and report its accuracy in terms of Mean Squared Error\n- Use the history object that is returned from model.fit to make graphs of the model's loss or train/validation accuracies by epoch. \n- Run this same data through a linear regression model. Which achieves higher accuracy?\n- Do a little bit of feature engineering and see how that affects your neural network model. (you will need to change your model to accept more inputs)\n- After feature engineering, which model sees a greater accuracy boost due to the new features?"
    },
    {
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "8NLTAR87uYJ-",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom keras.datasets import boston_housing\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Load the Data\n(X_train, y_train), (X_test, y_test) = boston_housing.load_data()",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Downloading data from https://s3.amazonaws.com/keras-datasets/boston_housing.npz\n57344/57026 [==============================] - 0s     \n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "\n\n\n\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "SfcFnOONyuNm"
      },
      "cell_type": "markdown",
      "source": "## Use the Keras Library to build an image recognition network using the Fashion-MNIST dataset (also comes with keras)\n\n- Load and preprocess the image data similar to how we preprocessed the MNIST data in class.\n- Make sure to one-hot encode your category labels\n- Make sure to have your final layer have as many nodes as the number of classes that you want to predict.\n- Try different hyperparameters. What is the highest accuracy that you are able to achieve.\n- Use the history object that is returned from model.fit to make graphs of the model's loss or train/validation accuracies by epoch. \n- Remember that neural networks fall prey to randomness so you may need to run your model multiple times (or use Cross Validation) in order to tell if a change to a hyperparameter is truly producing better results."
    },
    {
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "szi6-IpuzaH1",
        "trusted": true
      },
      "cell_type": "code",
      "source": "from keras.datasets import mnist",
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Hyper Parameters\nbatch_size = 64\nnum_classes = 10\nepochs = 20",
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Load the Data\n(X_train, y_train), (X_test, y_test) = mnist.load_data()",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n11321344/11490434 [============================>.] - ETA: 0s",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "X_train[0].shape",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "(28, 28)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "X_train.shape",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/plain": "(60000, 28, 28)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Reshape the data\nX_train = X_train.reshape(60000, 784)\nX_test = X_test.reshape(10000, 784)",
      "execution_count": 12,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# X Variable Types\nX_train = X_train.astype('float32')\nX_test = X_test.astype('float32')",
      "execution_count": 13,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "y_train[2]",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 14,
          "data": {
            "text/plain": "4"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "y_train[2]",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 15,
          "data": {
            "text/plain": "4"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "mnist_model = Sequential()\n\n# Input => Hidden\nmnist_model.add(Dense(16, input_dim=784, activation='relu'))\n# Hidden\nmnist_model.add(Dense(16, activation='relu'))\n# Hidden\nmnist_model.add(Dense(16, activation='relu'))\n# Hidden\nmnist_model.add(Dense(16, activation='relu'))\n# Output\nmnist_model.add(Dense(10,activation='softmax'))\n\n#Compile\nmnist_model.compile(loss='categorical_crossentropy',\n                    optimizer='adam',\n                    metrics=['accuracy'])\n\nmnist_model.summary()",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": "_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_1 (Dense)              (None, 16)                12560     \n_________________________________________________________________\ndense_2 (Dense)              (None, 16)                272       \n_________________________________________________________________\ndense_3 (Dense)              (None, 16)                272       \n_________________________________________________________________\ndense_4 (Dense)              (None, 16)                272       \n_________________________________________________________________\ndense_5 (Dense)              (None, 10)                170       \n=================================================================\nTotal params: 13,546\nTrainable params: 13,546\nNon-trainable params: 0\n_________________________________________________________________\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def neural_network(X):\n    \n    dense1 = Dense(8, activation='relu', input=X)\n    dense2 = Dense(8, activation='relu')(X)\n    \n    \n    return dense2 #or return model",
      "execution_count": 17,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "16 *  784",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 18,
          "data": {
            "text/plain": "12544"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "y_test.shape",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 19,
          "data": {
            "text/plain": "(10000,)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "history = mnist_model.fit(X_train, y_train, batch_size=32, epochs=100, verbose=False)\nscores = mnist_model.evaluate(X_test, y_test)\n#print(f'{mnist_model.metrics_names[1]}: {scores[1]*100}')",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Error when checking target: expected dense_5 to have shape (None, 10) but got array with shape (60000, 1)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-fd0808510929>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnist_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnist_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#print(f'{mnist_model.metrics_names[1]}: {scores[1]*100}')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3_420/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    865\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 867\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
            "\u001b[0;32m~/anaconda3_420/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1520\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1521\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1522\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1523\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1524\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3_420/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1380\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1381\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m                                     exception_prefix='target')\n\u001b[0m\u001b[1;32m   1383\u001b[0m         sample_weights = _standardize_sample_weights(sample_weight,\n\u001b[1;32m   1384\u001b[0m                                                      self._feed_output_names)\n",
            "\u001b[0;32m~/anaconda3_420/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    142\u001b[0m                             \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                             \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m                             str(array.shape))\n\u001b[0m\u001b[1;32m    145\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected dense_5 to have shape (None, 10) but got array with shape (60000, 1)"
          ]
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "zv_3xNMjzdLI"
      },
      "cell_type": "markdown",
      "source": "## Stretch Goals:\n\n- Use Hyperparameter Tuning to make the accuracy of your models as high as possible. (error as low as possible)\n- Use Cross Validation techniques to get more consistent results with your model.\n- Use GridSearchCV to try different combinations of hyperparameters. \n- Start looking into other types of Keras layers for CNNs and RNNs maybe try and build a CNN model for fashion-MNIST to see how the results compare."
    }
  ],
  "metadata": {
    "colab": {
      "name": "LS_DS_433_Keras_Assignment.ipynb",
      "provenance": [],
      "version": "0.3.2"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "file_extension": ".py",
      "version": "3.5.4",
      "pygments_lexer": "ipython3",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}