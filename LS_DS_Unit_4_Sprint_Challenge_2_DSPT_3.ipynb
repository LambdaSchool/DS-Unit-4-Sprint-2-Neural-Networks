{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2*\n",
    "\n",
    "# Sprint Challenge - Neural Network Foundations\n",
    "\n",
    "Table of Problems\n",
    "\n",
    "1. [Defining Neural Networks](#Q1)\n",
    "2. [Simple Perceptron](#Q2)\n",
    "    - Perceptron\n",
    "    - Multilayer Perceptron\n",
    "    - Analyze and Compare\n",
    "4. [Keras MMP](#Q3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Q1\"></a>\n",
    "## 1. Defining Neural Networks \n",
    "\n",
    "Write *your own* definitions for the following terms:\n",
    "\n",
    "- **Neuron:** Core of a neural networks which takes the inputs, multiplies them by weights, and performs sum on the calculation processed by data to yield the output\n",
    "- **Input Layer:** Receives data and feeds into the model\n",
    "- **Hidden Layer:** Receives signals from input layers and processes them into the output layer given weights and biases\n",
    "- **Output Layer:** Receives signals from hidden layers and yield the resulting classification or prediction values\n",
    "- **Activation Function:** Defines the output of the neuron with provided input. It's used to perform the calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain how back propagation works as if you were explaining it to a five year-old. Use your own words, but feel free to reference external materials for this question. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# It's a system of neural networks in which a specific process is being supervised and adjusted to minimize the loss or fault of the neural networks\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember our Simple Perceptron Class from Monday. In a simple prediction describe the process of making a prediction. How do you go from inputs to predicted output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your Answer Here - Change the Cell to Markdown\n",
    "Architecture: Firstly, input layers are builts. The input layer neurons should be the same as features in terms of quantity, minus the target feature. Since this is a simple perceptron class, hidden layers will not present in the networks, hence output layers with one neuron will be the next ones. Next, weights will be initialized to a random number. Finally, the activation function will be implemented and applied to the output layer.\n",
    "\n",
    "Feed-foward: As the architecture is built, training data will be fed thoughout the network. The process will create some error values, representing the difference between network's output and expected output\n",
    "\n",
    "Back propagation: The error value is then processed by the activation function derivative. The derivative function adjusts the weights with respect to the error\n",
    "\n",
    "More train: The feed-forward and back propagation(or epoch) processes are repeated multiple times until the output of the loss function no longer shows significant changes. Weights are then calibrated for a prediction\n",
    "\n",
    "Test: The second to last step is to push a hold out test set with yielded outputs through network one time to determine the accuracy of the network.\n",
    "\n",
    "Prediction: Lastly, as the model's accuracy is acceptable, given data will be passed into the model for a prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Q2\"></a>\n",
    "## 2. Simple Perceptron\n",
    "\n",
    "In this question, you will build two neural networks using Tensorflow Keras. After you build these two models, compare the results of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Our Dataset\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "xx, yy = np.meshgrid(np.linspace(-3, 3, 50),\n",
    "                     np.linspace(-3, 3, 50))\n",
    "rng = np.random.RandomState(0)\n",
    "\n",
    "\"Use this X & y in the following 2 models\"\n",
    "X = rng.randn(300, 2)\n",
    "y = np.array(np.logical_xor(X[:, 0] > 0, X[:, 1] > 0), \n",
    "             dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Perceptron\n",
    "Construct a simple perceptron using Keras. You model should have 1 dense layer with a single neuron and a sigmoid activation function. Your model should be called `model1` and make sure to save the results of your fit statement to a variable called `h1`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Essential packages\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "#Tensorflow packages\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 300 samples\n",
      "Epoch 1/50\n",
      "300/300 [==============================] - 0s 1ms/sample - loss: 0.3137 - accuracy: 0.4733\n",
      "Epoch 2/50\n",
      "300/300 [==============================] - 0s 43us/sample - loss: 0.3112 - accuracy: 0.4733\n",
      "Epoch 3/50\n",
      "300/300 [==============================] - 0s 47us/sample - loss: 0.3089 - accuracy: 0.4733\n",
      "Epoch 4/50\n",
      "300/300 [==============================] - 0s 53us/sample - loss: 0.3066 - accuracy: 0.4733\n",
      "Epoch 5/50\n",
      "300/300 [==============================] - 0s 43us/sample - loss: 0.3042 - accuracy: 0.4733\n",
      "Epoch 6/50\n",
      "300/300 [==============================] - 0s 53us/sample - loss: 0.3020 - accuracy: 0.4733\n",
      "Epoch 7/50\n",
      "300/300 [==============================] - 0s 50us/sample - loss: 0.2999 - accuracy: 0.4733\n",
      "Epoch 8/50\n",
      "300/300 [==============================] - 0s 50us/sample - loss: 0.2978 - accuracy: 0.4733\n",
      "Epoch 9/50\n",
      "300/300 [==============================] - 0s 47us/sample - loss: 0.2957 - accuracy: 0.4733\n",
      "Epoch 10/50\n",
      "300/300 [==============================] - 0s 47us/sample - loss: 0.2937 - accuracy: 0.4733\n",
      "Epoch 11/50\n",
      "300/300 [==============================] - 0s 47us/sample - loss: 0.2919 - accuracy: 0.4733\n",
      "Epoch 12/50\n",
      "300/300 [==============================] - 0s 40us/sample - loss: 0.2899 - accuracy: 0.4733\n",
      "Epoch 13/50\n",
      "300/300 [==============================] - 0s 47us/sample - loss: 0.2881 - accuracy: 0.4733\n",
      "Epoch 14/50\n",
      "300/300 [==============================] - 0s 46us/sample - loss: 0.2863 - accuracy: 0.4733\n",
      "Epoch 15/50\n",
      "300/300 [==============================] - 0s 40us/sample - loss: 0.2846 - accuracy: 0.4733\n",
      "Epoch 16/50\n",
      "300/300 [==============================] - 0s 47us/sample - loss: 0.2830 - accuracy: 0.4733\n",
      "Epoch 17/50\n",
      "300/300 [==============================] - 0s 39us/sample - loss: 0.2813 - accuracy: 0.4733\n",
      "Epoch 18/50\n",
      "300/300 [==============================] - 0s 37us/sample - loss: 0.2796 - accuracy: 0.4733\n",
      "Epoch 19/50\n",
      "300/300 [==============================] - 0s 46us/sample - loss: 0.2781 - accuracy: 0.4733\n",
      "Epoch 20/50\n",
      "300/300 [==============================] - 0s 40us/sample - loss: 0.2766 - accuracy: 0.4767\n",
      "Epoch 21/50\n",
      "300/300 [==============================] - 0s 46us/sample - loss: 0.2752 - accuracy: 0.4767\n",
      "Epoch 22/50\n",
      "300/300 [==============================] - 0s 43us/sample - loss: 0.2738 - accuracy: 0.4667\n",
      "Epoch 23/50\n",
      "300/300 [==============================] - 0s 37us/sample - loss: 0.2725 - accuracy: 0.4667\n",
      "Epoch 24/50\n",
      "300/300 [==============================] - 0s 49us/sample - loss: 0.2713 - accuracy: 0.4633\n",
      "Epoch 25/50\n",
      "300/300 [==============================] - 0s 40us/sample - loss: 0.2700 - accuracy: 0.4633\n",
      "Epoch 26/50\n",
      "300/300 [==============================] - 0s 40us/sample - loss: 0.2689 - accuracy: 0.4633\n",
      "Epoch 27/50\n",
      "300/300 [==============================] - 0s 40us/sample - loss: 0.2678 - accuracy: 0.4633\n",
      "Epoch 28/50\n",
      "300/300 [==============================] - 0s 40us/sample - loss: 0.2668 - accuracy: 0.4633\n",
      "Epoch 29/50\n",
      "300/300 [==============================] - 0s 41us/sample - loss: 0.2658 - accuracy: 0.4600\n",
      "Epoch 30/50\n",
      "300/300 [==============================] - 0s 40us/sample - loss: 0.2648 - accuracy: 0.4600\n",
      "Epoch 31/50\n",
      "300/300 [==============================] - 0s 40us/sample - loss: 0.2638 - accuracy: 0.4667\n",
      "Epoch 32/50\n",
      "300/300 [==============================] - 0s 43us/sample - loss: 0.2629 - accuracy: 0.4667\n",
      "Epoch 33/50\n",
      "300/300 [==============================] - 0s 46us/sample - loss: 0.2619 - accuracy: 0.4633\n",
      "Epoch 34/50\n",
      "300/300 [==============================] - 0s 40us/sample - loss: 0.2610 - accuracy: 0.4633\n",
      "Epoch 35/50\n",
      "300/300 [==============================] - 0s 40us/sample - loss: 0.2603 - accuracy: 0.4633\n",
      "Epoch 36/50\n",
      "300/300 [==============================] - 0s 43us/sample - loss: 0.2594 - accuracy: 0.4533\n",
      "Epoch 37/50\n",
      "300/300 [==============================] - 0s 40us/sample - loss: 0.2587 - accuracy: 0.4500\n",
      "Epoch 38/50\n",
      "300/300 [==============================] - 0s 40us/sample - loss: 0.2579 - accuracy: 0.4467\n",
      "Epoch 39/50\n",
      "300/300 [==============================] - 0s 40us/sample - loss: 0.2572 - accuracy: 0.4500\n",
      "Epoch 40/50\n",
      "300/300 [==============================] - 0s 43us/sample - loss: 0.2566 - accuracy: 0.4533\n",
      "Epoch 41/50\n",
      "300/300 [==============================] - 0s 40us/sample - loss: 0.2559 - accuracy: 0.4467\n",
      "Epoch 42/50\n",
      "300/300 [==============================] - 0s 40us/sample - loss: 0.2553 - accuracy: 0.4467\n",
      "Epoch 43/50\n",
      "300/300 [==============================] - 0s 37us/sample - loss: 0.2547 - accuracy: 0.4400\n",
      "Epoch 44/50\n",
      "300/300 [==============================] - 0s 40us/sample - loss: 0.2542 - accuracy: 0.4467\n",
      "Epoch 45/50\n",
      "300/300 [==============================] - 0s 43us/sample - loss: 0.2536 - accuracy: 0.4467\n",
      "Epoch 46/50\n",
      "300/300 [==============================] - 0s 33us/sample - loss: 0.2532 - accuracy: 0.4533\n",
      "Epoch 47/50\n",
      "300/300 [==============================] - 0s 42us/sample - loss: 0.2526 - accuracy: 0.4567\n",
      "Epoch 48/50\n",
      "300/300 [==============================] - 0s 43us/sample - loss: 0.2522 - accuracy: 0.4633\n",
      "Epoch 49/50\n",
      "300/300 [==============================] - 0s 40us/sample - loss: 0.2518 - accuracy: 0.4600\n",
      "Epoch 50/50\n",
      "300/300 [==============================] - 0s 43us/sample - loss: 0.2514 - accuracy: 0.4567\n"
     ]
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Dense(2, input_dim=2, activation='sigmoid'))\n",
    "model1.add(Dense(1, activation='sigmoid'))\n",
    "model1.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "h1 = model1.fit(X,y, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Layer Perceptron\n",
    "Now construct a multi-layer perceptron using Keras. Here are some architecture suggestions: \n",
    "- 2 Hidden Layers\n",
    "- 5-32 Neurons in the Hidden Layers\n",
    "- Your pick of activation function and optimizer\n",
    "- Incorporate the Callback function below into your model\n",
    "\n",
    "Your model should be called `model2` and make sure to save the results of your fit statement to a variable called `h2`. You must also monitor the metric 'accuracy'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class myCallback(tf.keras.callbacks.Callback): \n",
    "    def on_epoch_end(self, epoch, logs={}): \n",
    "        if(logs.get('accuracy') > .99999):   \n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 300 samples\n",
      "Epoch 1/50\n",
      "300/300 [==============================] - 1s 3ms/sample - loss: 0.2438 - accuracy: 0.6000\n",
      "Epoch 2/50\n",
      "300/300 [==============================] - 0s 50us/sample - loss: 0.2271 - accuracy: 0.7300\n",
      "Epoch 3/50\n",
      "300/300 [==============================] - 0s 66us/sample - loss: 0.2116 - accuracy: 0.7367\n",
      "Epoch 4/50\n",
      "300/300 [==============================] - 0s 57us/sample - loss: 0.1964 - accuracy: 0.7600\n",
      "Epoch 5/50\n",
      "300/300 [==============================] - 0s 57us/sample - loss: 0.1821 - accuracy: 0.8333\n",
      "Epoch 6/50\n",
      "300/300 [==============================] - 0s 59us/sample - loss: 0.1685 - accuracy: 0.9000\n",
      "Epoch 7/50\n",
      "300/300 [==============================] - 0s 57us/sample - loss: 0.1559 - accuracy: 0.9233\n",
      "Epoch 8/50\n",
      "300/300 [==============================] - 0s 50us/sample - loss: 0.1435 - accuracy: 0.9333\n",
      "Epoch 9/50\n",
      "300/300 [==============================] - 0s 56us/sample - loss: 0.1321 - accuracy: 0.9567\n",
      "Epoch 10/50\n",
      "300/300 [==============================] - 0s 49us/sample - loss: 0.1210 - accuracy: 0.9567\n",
      "Epoch 11/50\n",
      "300/300 [==============================] - 0s 53us/sample - loss: 0.1113 - accuracy: 0.9700\n",
      "Epoch 12/50\n",
      "300/300 [==============================] - 0s 53us/sample - loss: 0.1025 - accuracy: 0.9700\n",
      "Epoch 13/50\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0991 - accuracy: 1.00 - 0s 60us/sample - loss: 0.0944 - accuracy: 0.9733\n",
      "Epoch 14/50\n",
      "300/300 [==============================] - 0s 56us/sample - loss: 0.0874 - accuracy: 0.9733\n",
      "Epoch 15/50\n",
      "300/300 [==============================] - 0s 50us/sample - loss: 0.0811 - accuracy: 0.9767\n",
      "Epoch 16/50\n",
      "300/300 [==============================] - 0s 50us/sample - loss: 0.0759 - accuracy: 0.9700\n",
      "Epoch 17/50\n",
      "300/300 [==============================] - 0s 57us/sample - loss: 0.0710 - accuracy: 0.9800\n",
      "Epoch 18/50\n",
      "300/300 [==============================] - 0s 50us/sample - loss: 0.0668 - accuracy: 0.9767\n",
      "Epoch 19/50\n",
      "300/300 [==============================] - 0s 50us/sample - loss: 0.0631 - accuracy: 0.9767\n",
      "Epoch 20/50\n",
      "300/300 [==============================] - 0s 47us/sample - loss: 0.0604 - accuracy: 0.9800\n",
      "Epoch 21/50\n",
      "300/300 [==============================] - 0s 50us/sample - loss: 0.0571 - accuracy: 0.9767\n",
      "Epoch 22/50\n",
      "300/300 [==============================] - 0s 46us/sample - loss: 0.0545 - accuracy: 0.9767\n",
      "Epoch 23/50\n",
      "300/300 [==============================] - 0s 47us/sample - loss: 0.0523 - accuracy: 0.9800\n",
      "Epoch 24/50\n",
      "300/300 [==============================] - 0s 40us/sample - loss: 0.0502 - accuracy: 0.9767\n",
      "Epoch 25/50\n",
      "300/300 [==============================] - 0s 40us/sample - loss: 0.0485 - accuracy: 0.9767\n",
      "Epoch 26/50\n",
      "300/300 [==============================] - 0s 43us/sample - loss: 0.0469 - accuracy: 0.9767\n",
      "Epoch 27/50\n",
      "300/300 [==============================] - 0s 40us/sample - loss: 0.0451 - accuracy: 0.9767\n",
      "Epoch 28/50\n",
      "300/300 [==============================] - 0s 43us/sample - loss: 0.0438 - accuracy: 0.9767\n",
      "Epoch 29/50\n",
      "300/300 [==============================] - 0s 43us/sample - loss: 0.0423 - accuracy: 0.9767\n",
      "Epoch 30/50\n",
      "300/300 [==============================] - 0s 43us/sample - loss: 0.0411 - accuracy: 0.9767\n",
      "Epoch 31/50\n",
      "300/300 [==============================] - 0s 40us/sample - loss: 0.0400 - accuracy: 0.9767\n",
      "Epoch 32/50\n",
      "300/300 [==============================] - 0s 45us/sample - loss: 0.0389 - accuracy: 0.9767\n",
      "Epoch 33/50\n",
      "300/300 [==============================] - 0s 43us/sample - loss: 0.0380 - accuracy: 0.9767\n",
      "Epoch 34/50\n",
      "300/300 [==============================] - 0s 47us/sample - loss: 0.0366 - accuracy: 0.9767\n",
      "Epoch 35/50\n",
      "300/300 [==============================] - 0s 43us/sample - loss: 0.0358 - accuracy: 0.9767\n",
      "Epoch 36/50\n",
      "300/300 [==============================] - 0s 53us/sample - loss: 0.0351 - accuracy: 0.9800\n",
      "Epoch 37/50\n",
      "300/300 [==============================] - 0s 47us/sample - loss: 0.0347 - accuracy: 0.9833\n",
      "Epoch 38/50\n",
      "300/300 [==============================] - 0s 47us/sample - loss: 0.0335 - accuracy: 0.9767\n",
      "Epoch 39/50\n",
      "300/300 [==============================] - 0s 43us/sample - loss: 0.0329 - accuracy: 0.9800\n",
      "Epoch 40/50\n",
      "300/300 [==============================] - 0s 50us/sample - loss: 0.0320 - accuracy: 0.9767\n",
      "Epoch 41/50\n",
      "300/300 [==============================] - 0s 40us/sample - loss: 0.0314 - accuracy: 0.9767\n",
      "Epoch 42/50\n",
      "300/300 [==============================] - 0s 40us/sample - loss: 0.0308 - accuracy: 0.9800\n",
      "Epoch 43/50\n",
      "300/300 [==============================] - 0s 43us/sample - loss: 0.0303 - accuracy: 0.9800\n",
      "Epoch 44/50\n",
      "300/300 [==============================] - 0s 40us/sample - loss: 0.0299 - accuracy: 0.9800\n",
      "Epoch 45/50\n",
      "300/300 [==============================] - 0s 45us/sample - loss: 0.0293 - accuracy: 0.9833\n",
      "Epoch 46/50\n",
      "300/300 [==============================] - 0s 43us/sample - loss: 0.0289 - accuracy: 0.9833\n",
      "Epoch 47/50\n",
      "300/300 [==============================] - 0s 43us/sample - loss: 0.0284 - accuracy: 0.9800\n",
      "Epoch 48/50\n",
      "300/300 [==============================] - 0s 40us/sample - loss: 0.0280 - accuracy: 0.9800\n",
      "Epoch 49/50\n",
      "300/300 [==============================] - 0s 47us/sample - loss: 0.0275 - accuracy: 0.9833\n",
      "Epoch 50/50\n",
      "300/300 [==============================] - 0s 43us/sample - loss: 0.0271 - accuracy: 0.9800\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Dense(2, input_dim=2, activation='selu'))\n",
    "model2.add(Dense(32, activation='relu'))\n",
    "model2.add(Dense(32, activation='relu'))\n",
    "model2.add(Dense(1, activation='sigmoid'))\n",
    "model2.compile(loss='mse', optimizer='nadam', metrics=['accuracy'])\n",
    "h2 = model2.fit(X,y, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze and Compare\n",
    "\n",
    "**Before you Start**: You will need to install an additional library for this next segment. Install the package `mlxtend` into the environment you are using for the sprint challenge.\n",
    "\n",
    "\n",
    "The cells below generate decision boundary plots of your models (`model1` & `model2`). Review the plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting upgrade\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ERROR: Could not find a version that satisfies the requirement upgrade (from versions: none)\n",
      "ERROR: No matching distribution found for upgrade\n"
     ]
    }
   ],
   "source": [
    "!pip install upgrade mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "C:\\Users\\Predator\\Anaconda3\\envs\\U4-S1-NLP\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Do Not change anything in this cell\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "\n",
    "h = .02  # step size in the mesh\n",
    "\n",
    "# create a mesh to plot in\n",
    "x_min, x_max = X[:, 0].min() - .2, X[:, 0].max() + .2\n",
    "y_min, y_max = X[:, 1].min() - .2, X[:, 1].max() + .2\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "\n",
    "fig = plt.figure(figsize=(12,6))\n",
    "\n",
    "\n",
    "for clf, hist, name, grd in zip([model1,model2], [h1, h2],['Perceptron', 'Multi-Layer Perceptron'],[1,2]):\n",
    "\n",
    "    ax = plt.subplot(1,2, grd)\n",
    "    fig = plot_decision_regions(X=X, y=y, clf=clf, legend=2)\n",
    "    title = f\"{name} with {hist.history['accuracy'][-1]:,.2f} Accuracy\"\n",
    "    plt.title(title)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why does the Perceptron (`model1`) only achieve ~70% accuracy? What is the architectural property of the Multi-Layer Perceptron that allows it more accurately learn the relationship between X and y? \n",
    "\n",
    "Why might this property be useful in more complex data such as images?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your Answer Here - Change the Cell to Markdown\n",
    "Perceptron's are only single layered networks. The MLP's hidden layers allow it to add non-linearity to the input data that is magnitudes different than a single layered perceptron. Each layer can 'learn' different aspects of the data set that is impossible to do in a single layer.\n",
    "\n",
    "If we were to take the MNIST data set as an example. The first hidden layer may generalize the edges of the numbers in the first layer, corners and loops in the second, and digit fragments in the third. These generalizations simply cannot be done in a single layer perceptron. Thus it stands to reason that the more complex or noisy the images in a dataset are, the more useful it is to have additional hidden layers to help generalize the different attributes of the images independently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Keras MMP <a id=\"Q3\"></a>\n",
    "\n",
    "Implement a Multilayer Perceptron architecture of your choosing using the Keras library. Train your model and report its baseline accuracy. Then hyperparameter tune at least two parameters and report your model's accuracy.\n",
    "Use the Heart Disease Dataset (binary classification)\n",
    "Use an appropriate loss function for a binary classification task\n",
    "Use an appropriate activation function on the final layer of your network.\n",
    "Train your model using verbose output for ease of grading.\n",
    "Use GridSearchCV or RandomSearchCV to hyperparameter tune your model. (for at least two hyperparameters)\n",
    "When hyperparameter tuning, show you work by adding code cells for each new experiment.\n",
    "Report the accuracy for each combination of hyperparameters as you test them so that we can easily see which resulted in the highest accuracy.\n",
    "You must hyperparameter tune at least 3 parameters in order to get a 3 on this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "\n",
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(303, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "      <td>1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>138</td>\n",
       "      <td>282</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>276</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>118</td>\n",
       "      <td>210</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>192</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>166</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "201   60    1   0       125   258    0        0      141      1      2.8   \n",
       "222   65    1   3       138   282    1        0      174      0      1.4   \n",
       "179   57    1   0       150   276    0        0      112      1      0.6   \n",
       "125   34    0   1       118   210    0        1      192      0      0.7   \n",
       "279   61    1   0       138   166    0        0      125      1      3.6   \n",
       "\n",
       "     slope  ca  thal  target  \n",
       "201      1   1     3       0  \n",
       "222      1   1     2       0  \n",
       "179      1   1     1       0  \n",
       "125      2   0     2       1  \n",
       "279      1   1     2       0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/ryanleeallred/datasets/master/heart.csv')\n",
    "df = df.sample(frac=1)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(242, 13)\n",
      "(61, 13)\n",
      "(242,)\n",
      "(61,)\n"
     ]
    }
   ],
   "source": [
    "# Your Code Here\n",
    "#Initialize X_train, y_train, X_test, y_test\n",
    "#Create features and target columns\n",
    "feats= list(df)[:-1]\n",
    "target= list(df)[-1]\n",
    "\n",
    "#Initialize X, y\n",
    "X = df[feats].values\n",
    "y = df[target].values\n",
    "\n",
    "#Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#Check the shape of newly created sets\n",
    "for i in X_train, X_test, y_train, y_test:\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.42749948 -1.47790748  1.06904497 ... -0.61986954 -0.69631062\n",
      "   1.09108945]\n",
      " [ 0.6526888  -1.47790748  2.04900285 ...  1.01065685 -0.69631062\n",
      "  -0.50917508]\n",
      " [ 0.20993985  0.67663234 -0.89087081 ... -0.61986954  0.26111648\n",
      "  -0.50917508]\n",
      " ...\n",
      " [ 1.206125    0.67663234 -0.89087081 ... -0.61986954  0.26111648\n",
      "   1.09108945]\n",
      " [-0.23280911  0.67663234 -0.89087081 ...  1.01065685  2.1759707\n",
      "   1.09108945]\n",
      " [ 0.32062709 -1.47790748 -0.89087081 ... -0.61986954 -0.69631062\n",
      "   1.09108945]]\n",
      "[[ 0.54200157  0.67663234  2.04900285  0.22457514 -0.78579859 -0.41119597\n",
      "   0.94475611  0.54799951 -0.70929937 -0.21738548  1.01065685  1.21854359\n",
      "  -0.50917508]\n",
      " [-0.34349635  0.67663234 -0.89087081  0.57901329  0.29435146 -0.41119597\n",
      "  -0.99279455  1.60190056  1.40984195 -0.91417074  1.01065685 -0.69631062\n",
      "  -0.50917508]\n",
      " [ 0.54200157  0.67663234 -0.89087081  0.57901329 -1.29744861 -0.41119597\n",
      "   0.94475611  0.54799951  1.40984195 -0.91417074  1.01065685  0.26111648\n",
      "   1.09108945]\n",
      " [-0.34349635  0.67663234 -0.89087081  0.57901329  1.01445149 -0.41119597\n",
      "   0.94475611  1.03103749  1.40984195  0.47939977  1.01065685 -0.69631062\n",
      "   1.09108945]\n",
      " [-1.56105598  0.67663234 -0.89087081  1.28788959 -0.42574857 -0.41119597\n",
      "   0.94475611  1.38233784 -0.70929937 -0.91417074  1.01065685 -0.69631062\n",
      "   1.09108945]\n",
      " [ 1.31681224 -1.47790748 -0.89087081  2.82378824 -0.33099857  2.43193045\n",
      "   0.94475611  0.67973714  1.40984195 -0.04318917 -0.61986954  1.21854359\n",
      "   1.09108945]\n",
      " [-1.45036875  0.67663234  0.08908708 -1.19317747 -0.19834856 -0.41119597\n",
      "   0.94475611  0.15278662 -0.70929937 -0.91417074  1.01065685 -0.69631062\n",
      "  -0.50917508]\n",
      " [-0.23280911  0.67663234  1.06904497  2.46935009 -0.88054859  2.43193045\n",
      "   0.94475611  0.54799951 -0.70929937 -0.47867995  1.01065685 -0.69631062\n",
      "   1.09108945]\n",
      " [-0.01143463  0.67663234  1.06904497 -0.30708209  0.52175147 -0.41119597\n",
      "  -0.99279455  0.10887408 -0.70929937 -0.47867995 -2.25039593  0.26111648\n",
      "  -0.50917508]\n",
      " [ 0.43131433  0.67663234 -0.89087081 -0.30708209  1.03340149 -0.41119597\n",
      "  -0.99279455  0.9432124  -0.70929937 -0.91417074  1.01065685  1.21854359\n",
      "   1.09108945]\n",
      " [-0.78624531  0.67663234 -0.89087081 -1.19317747  0.55965147 -0.41119597\n",
      "  -0.99279455 -1.38415241  1.40984195 -0.04318917 -0.61986954  0.26111648\n",
      "  -0.50917508]\n",
      " [ 1.31681224 -1.47790748  1.06904497  0.93345144  0.61650147 -0.41119597\n",
      "  -0.99279455  0.10887408 -0.70929937 -0.91417074 -0.61986954  0.26111648\n",
      "  -0.50917508]\n",
      " [-1.8931177   0.67663234  1.06904497 -0.01171696  0.08590145 -0.41119597\n",
      "   0.94475611  1.6458131  -0.70929937  2.13426476 -2.25039593 -0.69631062\n",
      "  -0.50917508]\n",
      " [-1.67174322  0.67663234  1.06904497  0.57901329  1.43135151 -0.41119597\n",
      "  -0.99279455  1.42625038 -0.70929937 -0.91417074  1.01065685 -0.69631062\n",
      "  -0.50917508]\n",
      " [ 1.64887396  0.67663234  2.04900285  1.76047379 -0.21729856  2.43193045\n",
      "  -0.99279455 -0.81328934 -0.70929937 -0.82707258 -0.61986954  0.26111648\n",
      "  -0.50917508]\n",
      " [ 0.54200157  0.67663234  1.06904497  1.16974354 -0.63419858  2.43193045\n",
      "   0.94475611  0.32843679 -0.70929937  0.47939977  1.01065685 -0.69631062\n",
      "  -0.50917508]\n",
      " [ 0.09925261 -1.47790748 -0.89087081  2.94193429  1.54505152 -0.41119597\n",
      "   2.88230677 -1.42806495  1.40984195  2.0471666  -0.61986954 -0.69631062\n",
      "  -0.50917508]\n",
      " [-0.45418359  0.67663234 -0.89087081  1.16974354 -0.04674856 -0.41119597\n",
      "  -0.99279455 -0.94502697 -0.70929937  1.35038135 -0.61986954 -0.69631062\n",
      "   1.09108945]\n",
      " [-0.23280911  0.67663234  0.08908708  0.22457514 -0.84264859 -0.41119597\n",
      "   0.94475611  0.37234934 -0.70929937 -0.21738548  1.01065685  0.26111648\n",
      "  -0.50917508]\n",
      " [ 0.32062709  0.67663234 -0.89087081  0.10642909 -0.72894859 -0.41119597\n",
      "   0.94475611  0.81147477  1.40984195 -0.91417074  1.01065685 -0.69631062\n",
      "   1.09108945]\n",
      " [ 0.87406328  0.67663234 -0.89087081 -0.60244722  0.40805147 -0.41119597\n",
      "   0.94475611 -2.21849074  1.40984195  0.65359609 -0.61986954  1.21854359\n",
      "   1.09108945]\n",
      " [ 0.43131433  0.67663234 -0.89087081 -0.95688537  1.37450151 -0.41119597\n",
      "   2.88230677 -0.41807645 -0.70929937  2.91814817 -2.25039593  2.1759707\n",
      "  -2.10943961]\n",
      " [-1.45036875 -1.47790748  0.08908708 -0.24800906  1.1471015  -0.41119597\n",
      "   0.94475611  0.59191205 -0.70929937 -0.91417074  1.01065685 -0.69631062\n",
      "  -0.50917508]\n",
      " [ 1.09543776  0.67663234  2.04900285  2.35120404 -0.34994857 -0.41119597\n",
      "  -0.99279455  0.24061171 -0.70929937 -0.3915818  -0.61986954 -0.69631062\n",
      "   1.09108945]\n",
      " [-0.12212187 -1.47790748 -0.89087081  0.46086724 -0.21729856 -0.41119597\n",
      "  -0.99279455  0.46017442 -0.70929937 -0.91417074  1.01065685 -0.69631062\n",
      "  -0.50917508]\n",
      " [ 0.76337604  0.67663234 -0.89087081 -0.60244722  0.27540146 -0.41119597\n",
      "   0.94475611 -0.41807645  1.40984195  2.22136292 -0.61986954  0.26111648\n",
      "   1.09108945]\n",
      " [ 0.32062709  0.67663234  1.06904497 -0.12986301 -0.31204857 -0.41119597\n",
      "  -0.99279455  0.02104899 -0.70929937 -0.56577811 -0.61986954  0.26111648\n",
      "   1.09108945]\n",
      " [-1.8931177  -1.47790748  1.06904497 -0.60244722 -0.57734858 -0.41119597\n",
      "   0.94475611  0.89929986 -0.70929937 -0.91417074  1.01065685 -0.69631062\n",
      "  -0.50917508]\n",
      " [-0.23280911  0.67663234  0.08908708 -0.12986301 -0.76684859  2.43193045\n",
      "   0.94475611  1.51407547 -0.70929937 -0.91417074  1.01065685 -0.69631062\n",
      "  -0.50917508]\n",
      " [-0.01143463 -1.47790748  1.06904497  1.76047379 -0.84264859 -0.41119597\n",
      "   0.94475611  0.59191205 -0.70929937 -0.91417074  1.01065685  0.26111648\n",
      "  -0.50917508]\n",
      " [ 0.43131433  0.67663234  1.06904497 -1.48854259 -0.10359856 -0.41119597\n",
      "  -0.99279455  0.19669916  1.40984195 -0.3915818  -0.61986954 -0.69631062\n",
      "   1.09108945]\n",
      " [-0.01143463  0.67663234 -0.89087081 -0.36615511  0.38910146 -0.41119597\n",
      "  -0.99279455 -1.7793653   1.40984195  1.00198872 -0.61986954  0.26111648\n",
      "   1.09108945]\n",
      " [-0.78624531  0.67663234  1.06904497 -0.01171696  0.14275145 -0.41119597\n",
      "   0.94475611  1.29451275 -0.70929937 -0.91417074  1.01065685 -0.69631062\n",
      "  -0.50917508]\n",
      " [ 1.206125   -1.47790748 -0.89087081  1.16974354 -0.38784857 -0.41119597\n",
      "  -0.99279455 -1.55980258 -0.70929937 -0.04318917 -0.61986954  2.1759707\n",
      "   1.09108945]\n",
      " [ 1.87024844 -1.47790748  0.08908708  1.76047379  1.0713015  -0.41119597\n",
      "   0.94475611  0.54799951 -0.70929937 -0.56577811  1.01065685  1.21854359\n",
      "  -0.50917508]\n",
      " [ 0.32062709  0.67663234  0.08908708  1.40603564 -0.25519857 -0.41119597\n",
      "  -0.99279455  0.6358246  -0.70929937 -0.91417074  1.01065685  0.26111648\n",
      "  -0.50917508]\n",
      " [ 1.7595612   0.67663234 -0.89087081  0.87437841 -1.35429862 -0.41119597\n",
      "   0.94475611 -1.0767646   1.40984195  1.35038135 -2.25039593 -0.69631062\n",
      "   1.09108945]\n",
      " [ 0.43131433 -1.47790748 -0.89087081  2.35120404 -0.38784857  2.43193045\n",
      "  -0.99279455 -0.15460119  1.40984195  1.52457766 -0.61986954  1.21854359\n",
      "  -2.10943961]\n",
      " [ 1.09543776 -1.47790748 -0.89087081  2.94193429  1.50715152 -0.41119597\n",
      "   0.94475611  0.19669916  1.40984195 -0.91417074  1.01065685 -0.69631062\n",
      "  -0.50917508]\n",
      " [ 1.09543776  0.67663234  1.06904497  0.57901329  1.69665153 -0.41119597\n",
      "   0.94475611  0.37234934 -0.70929937 -0.91417074  1.01065685 -0.69631062\n",
      "  -0.50917508]\n",
      " [ 2.20231016 -1.47790748  0.08908708 -0.60244722  0.44595147 -0.41119597\n",
      "  -0.99279455 -1.25241478  1.40984195 -0.73997443  1.01065685  0.26111648\n",
      "  -0.50917508]\n",
      " [ 0.87406328 -1.47790748  1.06904497 -0.01171696  0.33225146 -0.41119597\n",
      "   0.94475611 -2.30631582 -0.70929937  0.13100715 -0.61986954  0.26111648\n",
      "   1.09108945]\n",
      " [-1.22899427  0.67663234  1.06904497 -0.01171696  1.31765151 -0.41119597\n",
      "   0.94475611  0.54799951 -0.70929937  0.74069425  1.01065685  0.26111648\n",
      "  -0.50917508]\n",
      " [-0.67555807 -1.47790748  1.06904497 -0.01171696  0.55965147 -0.41119597\n",
      "   0.94475611 -0.46198899 -0.70929937 -0.73997443  1.01065685 -0.69631062\n",
      "  -0.50917508]\n",
      " [-1.00761979  0.67663234  2.04900285 -1.19317747  0.35120146 -0.41119597\n",
      "   0.94475611 -0.7693768  -0.70929937  0.13100715 -0.61986954 -0.69631062\n",
      "   1.09108945]\n",
      " [-0.01143463  0.67663234  1.06904497  1.16974354 -0.25519857 -0.41119597\n",
      "  -0.99279455  0.67973714 -0.70929937  0.47939977  1.01065685 -0.69631062\n",
      "   1.09108945]\n",
      " [-0.89693255  0.67663234  1.06904497  1.16974354 -0.27414857 -0.41119597\n",
      "   0.94475611 -0.11068864 -0.70929937  2.22136292 -0.61986954 -0.69631062\n",
      "  -0.50917508]\n",
      " [-1.45036875  0.67663234  1.06904497 -0.01171696 -0.59629858 -0.41119597\n",
      "  -0.99279455  0.81147477 -0.70929937  0.8277924  -0.61986954 -0.69631062\n",
      "  -0.50917508]\n",
      " [-0.23280911  0.67663234 -0.89087081 -1.07503142 -0.29309857 -0.41119597\n",
      "   0.94475611  0.46017442 -0.70929937 -0.91417074  1.01065685  0.26111648\n",
      "  -0.50917508]\n",
      " [-0.34349635 -1.47790748  1.06904497 -0.01171696  0.19960146 -0.41119597\n",
      "  -0.99279455 -0.02286356 -0.70929937 -0.47867995  1.01065685 -0.69631062\n",
      "  -0.50917508]\n",
      " [ 0.76337604  0.67663234  1.06904497  1.16974354 -0.04674856  2.43193045\n",
      "   0.94475611 -0.54981408  1.40984195 -0.04318917 -0.61986954 -0.69631062\n",
      "  -0.50917508]\n",
      " [-1.00761979 -1.47790748  0.08908708 -1.07503142 -1.61959863 -0.41119597\n",
      "   0.94475611 -0.50590154 -0.70929937 -0.91417074 -0.61986954 -0.69631062\n",
      "  -0.50917508]\n",
      " [ 1.206125   -1.47790748  1.06904497  0.57901329  3.2505516   2.43193045\n",
      "  -0.99279455  0.32843679 -0.70929937 -0.21738548  1.01065685  0.26111648\n",
      "  -0.50917508]\n",
      " [ 0.98475052  0.67663234 -0.89087081  0.57901329 -1.10794861 -0.41119597\n",
      "  -0.99279455 -0.24242627  1.40984195  2.56975555  1.01065685  1.21854359\n",
      "   1.09108945]\n",
      " [ 1.64887396  0.67663234  1.06904497  0.57901329  0.16170145 -0.41119597\n",
      "  -0.99279455 -0.15460119 -0.70929937  0.8277924  -0.61986954  2.1759707\n",
      "   1.09108945]\n",
      " [ 0.6526888  -1.47790748  1.06904497 -0.60244722 -1.27849861  2.43193045\n",
      "   0.94475611 -2.35022837 -0.70929937 -0.91417074  1.01065685 -0.69631062\n",
      "  -0.50917508]\n",
      " [ 0.32062709 -1.47790748 -0.89087081 -0.12986301  1.0902515  -0.41119597\n",
      "  -0.99279455  0.41626188 -0.70929937 -0.91417074  1.01065685  0.26111648\n",
      "  -0.50917508]\n",
      " [ 1.42749948  0.67663234 -0.89087081  1.76047379  0.76810148 -0.41119597\n",
      "  -0.99279455 -1.82327784  1.40984195  0.39230162 -0.61986954  2.1759707\n",
      "  -0.50917508]\n",
      " [-0.67555807  0.67663234  1.06904497 -0.36615511  0.18065145  2.43193045\n",
      "   0.94475611  1.11886258 -0.70929937 -0.91417074  1.01065685  1.21854359\n",
      "  -0.50917508]\n",
      " [ 1.53818672 -1.47790748  1.06904497 -0.60244722 -0.65314858 -0.41119597\n",
      "  -0.99279455 -1.51589004 -0.70929937  0.39230162 -0.61986954 -0.69631062\n",
      "  -0.50917508]\n",
      " [-0.23280911  0.67663234  2.04900285 -0.72059327 -1.12689861 -0.41119597\n",
      "  -0.99279455  1.77755073 -0.70929937 -0.91417074 -0.61986954 -0.69631062\n",
      "  -2.10943961]]\n"
     ]
    }
   ],
   "source": [
    "#Scale the data\n",
    "ss = StandardScaler()\n",
    "X_train = ss.fit_transform(X_train)\n",
    "X_test = ss.transform(X_test)\n",
    "print(X_train)\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 242 samples, validate on 61 samples\n",
      "Epoch 1/200\n",
      "242/242 [==============================] - 1s 2ms/sample - loss: 0.4628 - mse: 0.4628 - mae: 0.4628 - val_loss: 0.4262 - val_mse: 0.4262 - val_mae: 0.4262\n",
      "Epoch 2/200\n",
      "242/242 [==============================] - 0s 386us/sample - loss: 0.4628 - mse: 0.4628 - mae: 0.4628 - val_loss: 0.4262 - val_mse: 0.4262 - val_mae: 0.4262\n",
      "Epoch 3/200\n",
      "242/242 [==============================] - 0s 353us/sample - loss: 0.4628 - mse: 0.4628 - mae: 0.4628 - val_loss: 0.4262 - val_mse: 0.4262 - val_mae: 0.4262\n",
      "Epoch 4/200\n",
      "242/242 [==============================] - 0s 375us/sample - loss: 0.4628 - mse: 0.4628 - mae: 0.4628 - val_loss: 0.4262 - val_mse: 0.4262 - val_mae: 0.4262\n"
     ]
    }
   ],
   "source": [
    "#Build a model\n",
    "\n",
    "inputs = X_train.shape[1]\n",
    "epochs = 200\n",
    "batch_size = 10\n",
    "stop = EarlyStopping(monitor='val_mae', min_delta=0.01, patience=3)\n",
    "\n",
    "model = Sequential([\n",
    "    Flatten(),\n",
    "    Dense(64, activation='selu', input_shape=(inputs,)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(1, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='mse', optimizer='adamax', metrics=['mse', 'mae'])\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=batch_size, callbacks=[tensorboard_callback, stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best 0.7727880676587423 using {'learn_rate': 0.01}\n",
      "Mean :0.7727880676587423, Stdev:[0.02268619 0.0151247  0.16016963 0.05919104 0.02042447 0.04873682], with:{'learn_rate': 0.01}\n",
      "Mean :0.5619855920473734, Stdev:[0.02268619 0.0151247  0.16016963 0.05919104 0.02042447 0.04873682], with:{'learn_rate': 0.1}\n",
      "Mean :0.6947530806064606, Stdev:[0.02268619 0.0151247  0.16016963 0.05919104 0.02042447 0.04873682], with:{'learn_rate': 0.2}\n",
      "Mean :0.48379628856976825, Stdev:[0.02268619 0.0151247  0.16016963 0.05919104 0.02042447 0.04873682], with:{'learn_rate': 0.3}\n",
      "Mean :0.4421296219031016, Stdev:[0.02268619 0.0151247  0.16016963 0.05919104 0.02042447 0.04873682], with:{'learn_rate': 0.4}\n",
      "Mean :0.46270575126012164, Stdev:[0.02268619 0.0151247  0.16016963 0.05919104 0.02042447 0.04873682], with:{'learn_rate': 0.5}\n"
     ]
    }
   ],
   "source": [
    "#Hyperparameter tune with GridsearchCV\n",
    "#First tune learning rate\n",
    "from tensorflow.keras.optimizers import Adamax, Adam, Nadam, Adadelta, Adagrad\n",
    "inputs = X_train.shape[1]\n",
    "\n",
    "def model1(learn_rate=0.01):\n",
    "    model = Sequential([\n",
    "        Flatten(),\n",
    "        Dense(64, activation='selu', input_shape=(inputs,)),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(1, activation='tanh')\n",
    "    ])\n",
    "    model.compile(loss='squared_hinge', optimizer=Nadam(lr=learn_rate), metrics=['accuracy', 'mse'])\n",
    "    return model\n",
    "\n",
    "#Initialize model\n",
    "model1 = KerasClassifier(build_fn = model1, verbose=0)\n",
    "lr = [0.01, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "param_grid = dict(learn_rate=lr)\n",
    "\n",
    "#GridSearchCV\n",
    "grid = GridSearchCV(estimator = model1, param_grid = param_grid, n_jobs = -1, cv = 3)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "#Print out report\n",
    "print(f'Best {grid_result.best_score_} using {grid_result.best_params_}')\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f'Mean :{mean}, Stdev:{stds}, with:{param}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best 0.7894547382990519 using {'activation': 'tanh'}\n",
      "Mean :0.46270575126012164, Stdev:[0.04873682 0.04873682 0.02764409 0.06890025 0.03543703 0.04873682\n",
      " 0.04873682 0.04928751], with:{'activation': 'softmax'}\n",
      "Mean :0.46270575126012164, Stdev:[0.04873682 0.04873682 0.02764409 0.06890025 0.03543703 0.04873682\n",
      " 0.04873682 0.04928751], with:{'activation': 'softplus'}\n",
      "Mean :0.7767489751180013, Stdev:[0.04873682 0.04873682 0.02764409 0.06890025 0.03543703 0.04873682\n",
      " 0.04873682 0.04928751], with:{'activation': 'softsign'}\n",
      "Mean :0.5209876596927643, Stdev:[0.04873682 0.04873682 0.02764409 0.06890025 0.03543703 0.04873682\n",
      " 0.04873682 0.04928751], with:{'activation': 'relu'}\n",
      "Mean :0.7894547382990519, Stdev:[0.04873682 0.04873682 0.02764409 0.06890025 0.03543703 0.04873682\n",
      " 0.04873682 0.04928751], with:{'activation': 'tanh'}\n",
      "Mean :0.46270575126012164, Stdev:[0.04873682 0.04873682 0.02764409 0.06890025 0.03543703 0.04873682\n",
      " 0.04873682 0.04928751], with:{'activation': 'sigmoid'}\n",
      "Mean :0.46270575126012164, Stdev:[0.04873682 0.04873682 0.02764409 0.06890025 0.03543703 0.04873682\n",
      " 0.04873682 0.04928751], with:{'activation': 'hard_sigmoid'}\n",
      "Mean :0.7852366169293722, Stdev:[0.04873682 0.04873682 0.02764409 0.06890025 0.03543703 0.04873682\n",
      " 0.04873682 0.04928751], with:{'activation': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "#Second tune activation\n",
    "def model2(activation='relu'):\n",
    "    model = Sequential([\n",
    "        Flatten(),\n",
    "        Dense(64, activation = activation, kernel_initializer='uniform', input_shape=(inputs,)),\n",
    "        Dense(128, activation = 'selu'),\n",
    "        Dense(128, activation = 'selu'),\n",
    "        Dense(1, activation = 'sigmoid', kernel_initializer='uniform')\n",
    "    ])\n",
    "    model.compile(loss = 'squared_hinge', optimizer='nadam', metrics=['accuracy', 'mse'])\n",
    "    return model\n",
    "\n",
    "seed = 10\n",
    "np.random.seed(seed)\n",
    "\n",
    "#Initialize model\n",
    "model2 = KerasClassifier(build_fn=model2, verbose=0)\n",
    "activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n",
    "param_grid = dict(activation=activation)\n",
    "\n",
    "#GridSearchCV\n",
    "grid = GridSearchCV(estimator=model2, param_grid = param_grid, n_jobs=1, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "#Print out report\n",
    "print(f'Best {grid_result.best_score_} using {grid_result.best_params_}')\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f'Mean :{mean}, Stdev:{stds}, with:{param}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best 80.58127562204996% using {'neurons': 5}\n",
      "Mean :0.7893518606821696, Stdev:[0.02596844 0.02070752 0.02930069 0.04131712 0.01571769 0.014303\n",
      " 0.10144513], with:{'neurons': 1}\n",
      "Mean :0.8058127562204996, Stdev:[0.02596844 0.02070752 0.02930069 0.04131712 0.01571769 0.014303\n",
      " 0.10144513], with:{'neurons': 5}\n",
      "Mean :0.7770061691602071, Stdev:[0.02596844 0.02070752 0.02930069 0.04131712 0.01571769 0.014303\n",
      " 0.10144513], with:{'neurons': 10}\n",
      "Mean :0.7976851662000021, Stdev:[0.02596844 0.02070752 0.02930069 0.04131712 0.01571769 0.014303\n",
      " 0.10144513], with:{'neurons': 15}\n",
      "Mean :0.7685699661572775, Stdev:[0.02596844 0.02070752 0.02930069 0.04131712 0.01571769 0.014303\n",
      " 0.10144513], with:{'neurons': 20}\n",
      "Mean :0.7810699741045634, Stdev:[0.02596844 0.02070752 0.02930069 0.04131712 0.01571769 0.014303\n",
      " 0.10144513], with:{'neurons': 25}\n",
      "Mean :0.7358024716377258, Stdev:[0.02596844 0.02070752 0.02930069 0.04131712 0.01571769 0.014303\n",
      " 0.10144513], with:{'neurons': 30}\n"
     ]
    }
   ],
   "source": [
    "#Third tune number of neuron\n",
    "\n",
    "def model3(neurons=1):\n",
    "    model = Sequential([\n",
    "        Flatten(),\n",
    "        Dense(64, activation = 'relu', kernel_initializer='uniform', input_shape=(inputs,)),\n",
    "        Dense(128, activation = 'selu'),\n",
    "        Dense(128, activation = 'selu'),\n",
    "        Dense(1, activation = 'sigmoid', kernel_initializer='uniform')\n",
    "    ])\n",
    "    model.compile(loss = 'mse', optimizer='adam', metrics=['accuracy', 'mse'])\n",
    "    return model\n",
    "\n",
    "seed = 10\n",
    "np.random.seed(seed)\n",
    "\n",
    "#Initialize model\n",
    "model3 = KerasClassifier(build_fn=model3, verbose=0)\n",
    "neurons = [1, 5, 10, 15, 20, 25, 30]\n",
    "param_grid = dict(neurons=neurons)\n",
    "\n",
    "#GridSearchCV\n",
    "grid = GridSearchCV(estimator=model3, param_grid = param_grid, n_jobs=1, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "#Print out report\n",
    "print(f'Best {(grid_result.best_score_)*100}% using {grid_result.best_params_}')\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f'Mean :{mean}, Stdev:{stds}, with:{param}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**My best score is 80.58%**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "U4-S1-NLP (Python3)",
   "language": "python",
   "name": "u4-s1-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "nteract": {
   "version": "0.22.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
