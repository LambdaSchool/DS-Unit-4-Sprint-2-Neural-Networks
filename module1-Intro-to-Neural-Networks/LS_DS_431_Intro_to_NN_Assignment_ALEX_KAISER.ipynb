{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LS_DS_431_Intro_to_NN_Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dVfaLrjLvxvQ"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "# Neural Networks\n",
        "\n",
        "## *Data Science Unit 4 Sprint 2 Assignment 1*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wxtoY12mwmih"
      },
      "source": [
        "## Define the Following:\n",
        "You can add image, diagrams, whatever you need to ensure that you understand the concepts below.\n",
        "\n",
        "### Input Layer: also termed visible layer, receives input from data.\n",
        "### Hidden Layer: Layer between input and output. No direct interaction, as it only can be accessed via input layer.\n",
        "### Output Layer: final output from neural network. typically a vector of predictions.\n",
        "### Neuron:The basic unit of a neural network. Receives numerous inputs at varying weights, and provides a output.\n",
        "### Weight: Strenght of a connection between layers. Could be seen as a bias distribution for all inputs.\n",
        "### Activation Function: Activation functions introduce non-linearity into a neural network. Trigger for neural spike/firing.\n",
        "### Node Map: Node maps are visual diagrams of the layout of a neural network.\n",
        "### Perceptron: A perceptron is the simplest Neural Network consisting of a single node or neuron with nothing else taking any number of inputs which are integrated into a single output.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NXuy9WcWzxa4"
      },
      "source": [
        "## Inputs -> Outputs\n",
        "\n",
        "### Explain the flow of information through a neural network from inputs to outputs. Be sure to include: inputs, weights, bias, and activation functions. How does it all flow from beginning to end?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PlSwIJMC0A8F"
      },
      "source": [
        "**An input is received by the network, and multiplied by a weight. A bias of 1 is introduced as another input to offset a case where all other inputs would be zero (input stimulus). A neuron will continue to fire if it fits a given activation function (eg Sigmoid). These steps then lead to an output.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6sWR43PTwhSk"
      },
      "source": [
        "## Write your own perceptron code that can correctly classify (99.0% accuracy) a NAND gate. \n",
        "\n",
        "| x1 | x2 | y |\n",
        "|----|----|---|\n",
        "| 0  | 0  | 1 |\n",
        "| 1  | 0  | 1 |\n",
        "| 0  | 1  | 1 |\n",
        "| 1  | 1  | 0 |"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQ_nD7sOgCS2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "data = { 'x1': [0,1,0,1],\n",
        "         'x2': [0,0,1,1],\n",
        "         'y':  [1,1,1,0]\n",
        "       }\n",
        "\n",
        "df = pd.DataFrame.from_dict(data).astype('int')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Sgh7VFGwnXGH",
        "colab": {}
      },
      "source": [
        "##### Your Code Here #####\n",
        "# Defining activation functions (sigmoid)\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    sx = sigmoid(x)\n",
        "    return sx * (1-sx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "by8B86yJgCS7",
        "colab_type": "code",
        "outputId": "02f43cac-77e2-45d2-c613-d1af1671769a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# inputs\n",
        "i1 = df['x1'].to_list()\n",
        "i2 = df['x2'].to_list()\n",
        "inputs = np.array([i1,i2])\n",
        "inputs"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 1, 0, 1],\n",
              "       [0, 0, 1, 1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fx5vXfcijVC",
        "colab_type": "code",
        "outputId": "e0734122-fbc1-4562-a2b6-03868e44583d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# outputs\n",
        "outputs = np.array([df['y'].to_list()])\n",
        "outputs"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 1, 1, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3IeXeJbijXq",
        "colab_type": "code",
        "outputId": "570c9169-597a-4428-f928-614ad8703763",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "# random weights for each input\n",
        "weights = np.random.random((4,1))\n",
        "weights"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.65434526],\n",
              "       [0.73781127],\n",
              "       [0.6010425 ],\n",
              "       [0.44139222]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99C7H9x-jdmM",
        "colab_type": "code",
        "outputId": "bc1f8289-ceef-492e-fc49-e0bd7aa57fb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# weighted sum of inputs and weights\n",
        "weighted_sum = np.dot(inputs, weights)\n",
        "weighted_sum"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.17920348],\n",
              "       [1.04243472]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YS-I5sVLjzEp",
        "colab_type": "code",
        "outputId": "2eebba15-f542-47b7-b912-ea92a79e931c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# sigmoid activation\n",
        "activated_output = sigmoid(weighted_sum)\n",
        "activated_output"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.76480456],\n",
              "       [0.73931951]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcZcoZm4jzLZ",
        "colab_type": "code",
        "outputId": "48526a4e-1d03-47b3-c7f8-a11bc4d70e24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# error\n",
        "error = outputs - activated_output\n",
        "error"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.23519544,  0.23519544,  0.23519544, -0.76480456],\n",
              "       [ 0.26068049,  0.26068049,  0.26068049, -0.73931951]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZ5w8ijhkDI1",
        "colab_type": "code",
        "outputId": "43b9a3d1-a2d2-419c-bc5f-d60cc34dfd78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# gradient descent/backpropagation\n",
        "adjustments = error * sigmoid_derivative(weighted_sum)\n",
        "adjustments"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.04230661,  0.04230661,  0.04230661, -0.13757193],\n",
              "       [ 0.05023995,  0.05023995,  0.05023995, -0.14248622]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LrUI4AskDL9",
        "colab_type": "code",
        "outputId": "82b1b145-74f3-40f4-d9b8-d96c9541122d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "weights = weights + np.dot(inputs.T, adjustments)\n",
        "weights"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.65434526, 0.65434526, 0.65434526, 0.65434526],\n",
              "       [0.78011788, 0.78011788, 0.78011788, 0.60023933],\n",
              "       [0.65128245, 0.65128245, 0.65128245, 0.45855628],\n",
              "       [0.53393878, 0.53393878, 0.53393878, 0.16133407]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbz8ZbZWkecA",
        "colab_type": "code",
        "outputId": "60d5561a-f4bc-461d-c7c5-061921714e0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "source": [
        "# iteration to reduce error\n",
        "for iteration in range(10000):\n",
        "    \n",
        "    # Weighted sum of inputs / weights\n",
        "    weighted_sum = np.dot(inputs, weights)\n",
        "    \n",
        "    # Activate!\n",
        "    activated_output = sigmoid(weighted_sum)\n",
        "    \n",
        "    # Cac error\n",
        "    error = outputs - activated_output\n",
        "    \n",
        "    adjustments = error * sigmoid_derivative(weighted_sum)\n",
        "    \n",
        "    # Update the Weights\n",
        "    weights += np.dot(inputs.T, adjustments)\n",
        "    \n",
        "print(\"Weights after training\")\n",
        "print(weights)\n",
        "\n",
        "print(\"Output after training\")\n",
        "print(activated_output)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Weights after training\n",
            "[[ 0.65434526  0.65434526  0.65434526  0.65434526]\n",
            " [ 2.13373186  2.13373186  2.13373186 -1.52679241]\n",
            " [ 2.12399057  2.12399057  2.12399057 -1.53406681]\n",
            " [ 3.36026088  3.36026088  3.36026088 -3.95832077]]\n",
            "Output after training\n",
            "[[0.99590523 0.99590523 0.99590523 0.00413114]\n",
            " [0.99586531 0.99586531 0.99586531 0.00410132]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Xf7sdqVs0s4x"
      },
      "source": [
        "## Implement your own Perceptron Class and use it to classify a binary dataset: \n",
        "- [The Pima Indians Diabetes dataset](https://raw.githubusercontent.com/ryanleeallred/datasets/master/diabetes.csv) \n",
        "\n",
        "You may need to search for other's implementations in order to get inspiration for your own. There are *lots* of perceptron implementations on the internet with varying levels of sophistication and complexity. Whatever your approach, make sure you understand **every** line of your implementation and what its purpose is."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMrLUapsgCS9",
        "colab_type": "code",
        "outputId": "9416b3af-7170-472b-ea9b-bebb3b8e8599",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "diabetes = pd.read_csv('https://raw.githubusercontent.com/ryanleeallred/datasets/master/diabetes.csv')\n",
        "diabetes.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Pregnancies  Glucose  BloodPressure  ...  DiabetesPedigreeFunction  Age  Outcome\n",
              "0            6      148             72  ...                     0.627   50        1\n",
              "1            1       85             66  ...                     0.351   31        0\n",
              "2            8      183             64  ...                     0.672   32        1\n",
              "3            1       89             66  ...                     0.167   21        0\n",
              "4            0      137             40  ...                     2.288   33        1\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAFxhsZ-nxMg",
        "colab_type": "code",
        "outputId": "7016487e-b550-438e-ea3d-6748d5bcd074",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        }
      },
      "source": [
        "# plot outcome\n",
        "%matplotlib inline\n",
        "diabetes['Outcome'].value_counts().plot(kind='bar')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f857c1b4860>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD1CAYAAACrz7WZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAMAklEQVR4nO3dX4zl5V3H8fdHtlRjTfk3bnB3cUhY0+BFKZkgpl4oROWPcbloCY2RDdlkb2jSpiZ29caYeAE3oiSGuJHGxWgpqTZsKKmSBWKMgTJYpKVYGQm4uwF2SgFtSFXarxfzkB62szuzO2dm2C/vVzI5v9/zPGfOM8nmvb/89pzZVBWSpF5+bLM3IEmaPuMuSQ0Zd0lqyLhLUkPGXZIaMu6S1NCWzd4AwAUXXFCzs7ObvQ1JOqM8+eST366qmeXm3hVxn52dZX5+frO3IUlnlCQvnmjO2zKS1JBxl6SGjLskNWTcJakh4y5JDa0q7kleSPL1JE8lmR9j5yV5KMlz4/HcMZ4kdyZZSPJ0ksvX8weQJP2oU7ly/5Wquqyq5sb5PuBQVe0EDo1zgGuBneNrL3DXtDYrSVqdtdyW2QUcGMcHgBsmxu+pJY8B5yS5cA2vI0k6Rav9EFMB/5CkgD+vqv3A1qp6acy/DGwdx9uAwxPPPTLGXpoYI8lelq7sueiii05v9xtsdt+XN3sLrbxw2/WbvQWprdXG/Zeq6miSnwYeSvJvk5NVVSP8qzb+gtgPMDc3538HJUlTtKrbMlV1dDweA74EXAG88vbtlvF4bCw/CuyYePr2MSZJ2iArxj3JTyb5qbePgV8DvgEcBHaPZbuB+8fxQeDm8a6ZK4E3Jm7fSJI2wGpuy2wFvpTk7fV/U1VfSfIEcF+SPcCLwI1j/YPAdcAC8CZwy9R3LUk6qRXjXlXPAx9eZvxV4Oplxgu4dSq7kySdFj+hKkkNGXdJasi4S1JDxl2SGjLuktSQcZekhoy7JDVk3CWpIeMuSQ0Zd0lqyLhLUkPGXZIaMu6S1JBxl6SGjLskNWTcJakh4y5JDRl3SWrIuEtSQ8Zdkhoy7pLUkHGXpIaMuyQ1ZNwlqSHjLkkNGXdJasi4S1JDxl2SGjLuktSQcZekhoy7JDVk3CWpoVXHPclZSb6W5IFxfnGSx5MsJPlCkrPH+PvH+cKYn12frUuSTuRUrtw/BTw7cX47cEdVXQK8BuwZ43uA18b4HWOdJGkDrSruSbYD1wN/Mc4DXAV8cSw5ANwwjneNc8b81WO9JGmDrPbK/U+A3wV+MM7PB16vqrfG+RFg2zjeBhwGGPNvjPWSpA2yYtyT/AZwrKqenOYLJ9mbZD7J/OLi4jS/tSS9563myv2jwG8meQG4l6XbMX8KnJNky1izHTg6jo8COwDG/AeBV4//plW1v6rmqmpuZmZmTT+EJOmdVox7Vf1eVW2vqlngJuDhqvot4BHgY2PZbuD+cXxwnDPmH66qmuquJUkntZb3uX8W+EySBZbuqd89xu8Gzh/jnwH2rW2LkqRTtWXlJT9UVY8Cj47j54ErllnzPeDjU9ibJOk0+QlVSWrIuEtSQ8Zdkhoy7pLUkHGXpIaMuyQ1ZNwlqSHjLkkNGXdJasi4S1JDxl2SGjLuktSQcZekhoy7JDVk3CWpIeMuSQ0Zd0lqyLhLUkPGXZIaMu6S1JBxl6SGjLskNWTcJakh4y5JDRl3SWrIuEtSQ8Zdkhoy7pLUkHGXpIaMuyQ1ZNwlqSHjLkkNrRj3JD+e5KtJ/jXJM0n+cIxfnOTxJAtJvpDk7DH+/nG+MOZn1/dHkCQdbzVX7v8DXFVVHwYuA65JciVwO3BHVV0CvAbsGev3AK+N8TvGOknSBlox7rXku+P0feOrgKuAL47xA8AN43jXOGfMX50kU9uxJGlFq7rnnuSsJE8Bx4CHgP8AXq+qt8aSI8C2cbwNOAww5t8Azp/mpiVJJ7equFfV96vqMmA7cAXwobW+cJK9SeaTzC8uLq7120mSJpzSu2Wq6nXgEeAXgXOSbBlT24Gj4/gosANgzH8QeHWZ77W/quaqam5mZuY0ty9JWs5q3i0zk+SccfwTwK8Cz7IU+Y+NZbuB+8fxwXHOmH+4qmqam5YkndyWlZdwIXAgyVks/WVwX1U9kOSbwL1J/gj4GnD3WH838FdJFoDvADetw74lSSexYtyr6mngI8uMP8/S/ffjx78HfHwqu5MknRY/oSpJDRl3SWrIuEtSQ8Zdkhoy7pLUkHGXpIaMuyQ1ZNwlqaHVfEJV0rvc7L4vb/YWWnnhtus3ewtr5pW7JDVk3CWpIeMuSQ0Zd0lqyLhLUkPGXZIaMu6S1JBxl6SGjLskNWTcJakh4y5JDRl3SWrIuEtSQ8Zdkhoy7pLUkHGXpIaMuyQ1ZNwlqSHjLkkNGXdJasi4S1JDxl2SGjLuktSQcZekhlaMe5IdSR5J8s0kzyT51Bg/L8lDSZ4bj+eO8SS5M8lCkqeTXL7eP4Qk6Z1Wc+X+FvA7VXUpcCVwa5JLgX3AoaraCRwa5wDXAjvH117grqnvWpJ0UivGvapeqqp/Gcf/DTwLbAN2AQfGsgPADeN4F3BPLXkMOCfJhVPfuSTphE7pnnuSWeAjwOPA1qp6aUy9DGwdx9uAwxNPOzLGJEkbZNVxT/IB4G+BT1fVf03OVVUBdSovnGRvkvkk84uLi6fyVEnSClYV9yTvYynsf11VfzeGX3n7dst4PDbGjwI7Jp6+fYy9Q1Xtr6q5qpqbmZk53f1LkpaxmnfLBLgbeLaq/nhi6iCwexzvBu6fGL95vGvmSuCNids3kqQNsGUVaz4K/Dbw9SRPjbHfB24D7kuyB3gRuHHMPQhcBywAbwK3THXHkqQVrRj3qvonICeYvnqZ9QXcusZ9SZLWwE+oSlJDxl2SGjLuktSQcZekhoy7JDVk3CWpIeMuSQ0Zd0lqyLhLUkPGXZIaMu6S1JBxl6SGjLskNWTcJakh4y5JDRl3SWrIuEtSQ8Zdkhoy7pLUkHGXpIaMuyQ1ZNwlqSHjLkkNGXdJasi4S1JDxl2SGjLuktSQcZekhoy7JDVk3CWpIeMuSQ0Zd0lqaMW4J/lckmNJvjExdl6Sh5I8Nx7PHeNJcmeShSRPJ7l8PTcvSVreaq7c/xK45rixfcChqtoJHBrnANcCO8fXXuCu6WxTknQqVox7Vf0j8J3jhncBB8bxAeCGifF7asljwDlJLpzWZiVJq3O699y3VtVL4/hlYOs43gYcnlh3ZIxJkjbQmv9BtaoKqFN9XpK9SeaTzC8uLq51G5KkCacb91fevt0yHo+N8aPAjol128fYj6iq/VU1V1VzMzMzp7kNSdJyTjfuB4Hd43g3cP/E+M3jXTNXAm9M3L6RJG2QLSstSPJ54JeBC5IcAf4AuA24L8ke4EXgxrH8QeA6YAF4E7hlHfYsSVrBinGvqk+cYOrqZdYWcOtaNyVJWhs/oSpJDRl3SWrIuEtSQ8Zdkhoy7pLUkHGXpIaMuyQ1ZNwlqSHjLkkNGXdJasi4S1JDxl2SGjLuktSQcZekhoy7JDVk3CWpIeMuSQ0Zd0lqyLhLUkPGXZIaMu6S1JBxl6SGjLskNWTcJakh4y5JDRl3SWrIuEtSQ8Zdkhoy7pLUkHGXpIaMuyQ1ZNwlqSHjLkkNrUvck1yT5FtJFpLsW4/XkCSd2NTjnuQs4M+Aa4FLgU8kuXTaryNJOrH1uHK/Alioquer6n+Be4Fd6/A6kqQT2LIO33MbcHji/AjwC8cvSrIX2DtOv5vkW+uwl/eqC4Bvb/YmVpLbN3sH2gT+2Zyunz3RxHrEfVWqaj+wf7Nev7Mk81U1t9n7kI7nn82Nsx63ZY4COybOt48xSdIGWY+4PwHsTHJxkrOBm4CD6/A6kqQTmPptmap6K8kngb8HzgI+V1XPTPt1dFLe7tK7lX82N0iqarP3IEmaMj+hKkkNGXdJasi4S1JDm/Y+d01Hkg+x9AngbWPoKHCwqp7dvF1J2mxeuZ/BknyWpV/vEOCr4yvA5/2FbXo3S3LLZu+hO98tcwZL8u/Az1fV/x03fjbwTFXt3JydSSeX5D+r6qLN3kdn3pY5s/0A+BngxePGLxxz0qZJ8vSJpoCtG7mX9yLjfmb7NHAoyXP88Je1XQRcAnxy03YlLdkK/Drw2nHjAf5547fz3mLcz2BV9ZUkP8fSr1me/AfVJ6rq+5u3MwmAB4APVNVTx08keXTjt/Pe4j13SWrId8tIUkPGXZIaMu6S1JBxl6SGjLskNfT/IOCYRTrLJCAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hW3iC_y8oS3M",
        "colab_type": "code",
        "outputId": "fc8e0b0b-d095-40c8-bbf0-0557877dd19c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "source": [
        "diabetes['Outcome'].describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    768.000000\n",
              "mean       0.348958\n",
              "std        0.476951\n",
              "min        0.000000\n",
              "25%        0.000000\n",
              "50%        0.000000\n",
              "75%        1.000000\n",
              "max        1.000000\n",
              "Name: Outcome, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z22UhSongCTB",
        "colab_type": "text"
      },
      "source": [
        "Although neural networks can handle non-normalized data, scaling or normalizing your data will improve your neural network's learning speed. Try to apply the sklearn `MinMaxScaler` or `Normalizer` to your diabetes dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9x7CctJCgCTC",
        "colab_type": "code",
        "outputId": "01fab6ea-a43b-4f86-e64e-28852d3da7e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler, Normalizer\n",
        "\n",
        "feats = list(diabetes)[:-1]\n",
        "\n",
        "# test splits\n",
        "X = diabetes.drop('Outcome', axis=1)\n",
        "y = diabetes['Outcome']\n",
        "\n",
        "# scale the data\n",
        "mmscaler = MinMaxScaler()\n",
        "\n",
        "# fit the data\n",
        "X_scaled = pd.DataFrame(mmscaler.fit_transform(X), columns=feats)\n",
        "X_scaled.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.352941</td>\n",
              "      <td>0.743719</td>\n",
              "      <td>0.590164</td>\n",
              "      <td>0.353535</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500745</td>\n",
              "      <td>0.234415</td>\n",
              "      <td>0.483333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.058824</td>\n",
              "      <td>0.427136</td>\n",
              "      <td>0.540984</td>\n",
              "      <td>0.292929</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.396423</td>\n",
              "      <td>0.116567</td>\n",
              "      <td>0.166667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.470588</td>\n",
              "      <td>0.919598</td>\n",
              "      <td>0.524590</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.347243</td>\n",
              "      <td>0.253629</td>\n",
              "      <td>0.183333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.058824</td>\n",
              "      <td>0.447236</td>\n",
              "      <td>0.540984</td>\n",
              "      <td>0.232323</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.418778</td>\n",
              "      <td>0.038002</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.688442</td>\n",
              "      <td>0.327869</td>\n",
              "      <td>0.353535</td>\n",
              "      <td>0.198582</td>\n",
              "      <td>0.642325</td>\n",
              "      <td>0.943638</td>\n",
              "      <td>0.200000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Pregnancies   Glucose  ...  DiabetesPedigreeFunction       Age\n",
              "0     0.352941  0.743719  ...                  0.234415  0.483333\n",
              "1     0.058824  0.427136  ...                  0.116567  0.166667\n",
              "2     0.470588  0.919598  ...                  0.253629  0.183333\n",
              "3     0.058824  0.447236  ...                  0.038002  0.000000\n",
              "4     0.000000  0.688442  ...                  0.943638  0.200000\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-W0tiX1F1hh2",
        "colab": {}
      },
      "source": [
        "##### Update this Class #####\n",
        "\n",
        "class Perceptron:\n",
        "    \n",
        "    def __init__(self, niter = 10):\n",
        "        self.niter = niter\n",
        "    \n",
        "    def __sigmoid(self, x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "    \n",
        "    def __sigmoid_derivative(self, x):\n",
        "        sig_x = self.__sigmoid(x)\n",
        "        return sig_x * (1 - sig_x)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"Fit training data\n",
        "        X : Training vectors, X.shape : [#samples, #features]\n",
        "        y : Target values, y.shape : [#samples]\n",
        "        \"\"\"\n",
        "\n",
        "        # Randomly Initialize Weights\n",
        "        self.weights = np.random.random((X.shape[1], 1))\n",
        "        self.inputs = X.values.tolist()\n",
        "        self.outputs = y.values.tolist()\n",
        "\n",
        "\n",
        "        for i in range(self.niter):\n",
        "            # Weighted sum of inputs / weights\n",
        "            self.weighted_sum = np.dot(self.inputs, self.weights)\n",
        "\n",
        "            # Activate!\n",
        "            self.activated_outputs = self.__sigmoid(self.weighted_sum)\n",
        "\n",
        "            # Cac error\n",
        "            self.error = self.outputs - self.activated_outputs\n",
        "            self.adjustments = self.error * self.__sigmoid_derivative(self.weighted_sum)\n",
        "\n",
        "            # Update the Weights\n",
        "            self.weights = self.weights + np.dot(np.array(self.inputs).T, self.adjustments)\n",
        "\n",
        "        return self\n",
        "\n",
        "    def net_input(self, X):\n",
        "        return np.dot(X, self.weights)\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"Return class label after unit step\"\"\"\n",
        "        return np.where(self.net_input(X) >= 0.0, 1, -1)[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnAonjLnq35d",
        "colab_type": "code",
        "outputId": "603b6a40-55dd-44df-8499-4694a90cdb6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJSQRrurq319",
        "colab_type": "code",
        "outputId": "2e010e32-6a18-4741-a667-00ff74a61842",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 834
        }
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "perc_neur = Perceptron(768)\n",
        "perc_neur.fit(X_scaled, y)\n",
        "\n",
        "y_predict = perc_neur.predict(X_scaled)\n",
        "y_predict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1, -1,  1, -1,  1, -1,  1, -1,  1,  1, -1,  1, -1,  1,  1,  1,  1,\n",
              "        1, -1,  1, -1, -1,  1,  1,  1,  1,  1, -1, -1, -1, -1,  1, -1, -1,\n",
              "       -1, -1, -1,  1,  1,  1, -1, -1, -1,  1, -1,  1, -1, -1,  1, -1, -1,\n",
              "       -1, -1,  1, -1, -1,  1, -1, -1, -1, -1,  1, -1, -1,  1, -1,  1, -1,\n",
              "       -1, -1,  1, -1,  1, -1, -1, -1, -1, -1,  1, -1, -1, -1, -1, -1,  1,\n",
              "       -1, -1, -1,  1, -1, -1, -1, -1,  1, -1, -1, -1, -1, -1,  1,  1, -1,\n",
              "       -1, -1, -1, -1, -1, -1, -1,  1,  1,  1, -1, -1,  1,  1,  1, -1, -1,\n",
              "       -1,  1, -1, -1, -1,  1,  1, -1, -1,  1,  1,  1,  1,  1, -1, -1, -1,\n",
              "       -1, -1, -1, -1, -1, -1, -1,  1, -1, -1, -1, -1, -1, -1, -1, -1,  1,\n",
              "       -1,  1,  1, -1, -1, -1,  1, -1, -1, -1, -1,  1,  1, -1, -1, -1, -1,\n",
              "        1,  1, -1, -1, -1,  1, -1,  1, -1,  1, -1, -1, -1, -1, -1,  1,  1,\n",
              "        1,  1,  1, -1, -1,  1,  1, -1,  1, -1,  1,  1,  1, -1, -1, -1, -1,\n",
              "       -1, -1,  1,  1, -1,  1, -1, -1, -1,  1,  1,  1,  1, -1,  1,  1,  1,\n",
              "        1, -1, -1, -1, -1, -1,  1, -1, -1,  1,  1, -1, -1, -1,  1,  1,  1,\n",
              "        1, -1, -1, -1,  1,  1, -1,  1, -1, -1, -1, -1, -1, -1, -1, -1,  1,\n",
              "        1, -1, -1, -1,  1, -1,  1, -1, -1,  1, -1,  1, -1, -1,  1,  1, -1,\n",
              "       -1, -1, -1, -1,  1, -1, -1, -1,  1, -1, -1,  1,  1, -1, -1,  1, -1,\n",
              "       -1, -1,  1,  1,  1, -1, -1,  1, -1,  1, -1,  1,  1, -1,  1, -1, -1,\n",
              "        1, -1,  1,  1, -1, -1,  1, -1,  1, -1, -1,  1, -1,  1, -1,  1,  1,\n",
              "        1, -1, -1,  1, -1,  1, -1, -1, -1,  1, -1, -1, -1, -1,  1,  1,  1,\n",
              "       -1, -1, -1, -1, -1, -1, -1, -1, -1,  1, -1, -1, -1, -1, -1,  1,  1,\n",
              "        1, -1,  1,  1, -1, -1,  1, -1, -1,  1, -1, -1,  1,  1, -1, -1, -1,\n",
              "       -1,  1, -1, -1,  1, -1, -1, -1, -1, -1, -1, -1,  1,  1,  1, -1, -1,\n",
              "        1, -1, -1,  1, -1, -1,  1, -1,  1,  1, -1,  1, -1,  1, -1,  1, -1,\n",
              "        1,  1, -1, -1, -1, -1,  1,  1, -1,  1, -1,  1, -1, -1, -1, -1,  1,\n",
              "        1, -1,  1, -1,  1, -1, -1, -1, -1, -1,  1, -1, -1, -1, -1,  1, -1,\n",
              "       -1,  1,  1,  1, -1, -1,  1, -1, -1,  1, -1, -1, -1,  1, -1, -1,  1,\n",
              "       -1, -1, -1, -1, -1, -1, -1, -1, -1,  1, -1, -1, -1, -1, -1, -1, -1,\n",
              "        1, -1, -1, -1,  1, -1, -1, -1,  1,  1, -1, -1, -1, -1, -1, -1, -1,\n",
              "        1, -1, -1, -1, -1,  1, -1, -1, -1,  1, -1, -1, -1,  1, -1, -1, -1,\n",
              "        1, -1, -1, -1, -1,  1,  1, -1, -1, -1, -1, -1, -1,  1, -1, -1, -1,\n",
              "       -1, -1, -1, -1, -1, -1, -1, -1,  1, -1, -1, -1,  1,  1,  1,  1, -1,\n",
              "       -1,  1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1,\n",
              "        1, -1, -1, -1, -1, -1, -1, -1,  1, -1, -1, -1, -1, -1, -1, -1,  1,\n",
              "       -1,  1,  1, -1, -1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1, -1,\n",
              "        1, -1, -1,  1, -1, -1, -1, -1,  1,  1, -1,  1, -1, -1, -1, -1,  1,\n",
              "        1, -1,  1, -1, -1, -1,  1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
              "       -1,  1, -1, -1, -1, -1,  1, -1, -1,  1, -1, -1, -1,  1, -1, -1, -1,\n",
              "        1,  1,  1, -1, -1, -1, -1, -1, -1,  1, -1, -1, -1,  1, -1,  1,  1,\n",
              "        1,  1, -1,  1,  1, -1, -1, -1, -1, -1, -1, -1,  1,  1, -1,  1, -1,\n",
              "       -1,  1, -1,  1, -1, -1, -1, -1, -1,  1, -1,  1, -1,  1, -1,  1,  1,\n",
              "       -1, -1, -1, -1,  1,  1, -1, -1, -1,  1, -1,  1,  1, -1, -1,  1, -1,\n",
              "       -1,  1,  1, -1, -1,  1, -1, -1,  1, -1, -1, -1, -1, -1, -1, -1,  1,\n",
              "        1,  1, -1, -1, -1, -1, -1, -1,  1,  1, -1, -1,  1, -1, -1,  1, -1,\n",
              "        1,  1,  1, -1, -1,  1,  1,  1, -1,  1, -1,  1, -1,  1, -1, -1, -1,\n",
              "       -1,  1, -1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xf9qELTcq3_V",
        "colab_type": "code",
        "outputId": "effb137b-46bf-4cfa-d2d7-525b15b94c47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "accuracy_score(y, y_predict)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3489583333333333"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6QR4oAW1xdyu"
      },
      "source": [
        "## Stretch Goals:\n",
        "\n",
        "- Research \"backpropagation\" to learn how weights get updated in neural networks (tomorrow's lecture). \n",
        "- Implement a multi-layer perceptron. (for non-linearly separable classes)\n",
        "- Try and implement your own backpropagation algorithm.\n",
        "- What are the pros and cons of the different activation functions? How should you decide between them for the different layers of a neural network?"
      ]
    }
  ]
}