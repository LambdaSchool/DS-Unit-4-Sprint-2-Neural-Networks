{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dVfaLrjLvxvQ"
   },
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "# Neural Networks\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2 Assignment 1*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wxtoY12mwmih"
   },
   "source": [
    "## Define the Following:\n",
    "You can add image, diagrams, whatever you need to ensure that you understand the concepts below.\n",
    "reference I read: https://towardsdatascience.com/everything-you-need-to-know-about-neural-networks-and-backpropagation-machine-learning-made-easy-e5285bc2be3a\n",
    "### Input Layer:\n",
    "initial data for the neural network\n",
    "\n",
    "### Hidden Layer:\n",
    "intermediate layer between input and output layer and place where all the computation is done\n",
    "\n",
    "### Output Layer:\n",
    "produce the result for given inputs\n",
    "\n",
    "### Neuron:\n",
    "it holds a number, or it is a function\n",
    "### Weight:\n",
    "weight is a cost, that gets multiplied through\n",
    "\n",
    "### Activation Function:\n",
    "In Neural Network the activation function defines if given node should be activated or not based on the weighted sum. e.g. sigmoid function or ReLU\n",
    "\n",
    "### Node Map:\n",
    "y = Wx\n",
    "visual diagram of the architecture or topology of our neurl network\n",
    "\n",
    "### Perceptron:\n",
    "a single layer neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NXuy9WcWzxa4"
   },
   "source": [
    "## Inputs -> Outputs\n",
    "\n",
    "### Explain the flow of information through a neural network from inputs to outputs. Be sure to include: inputs, weights, bias, and activation functions. How does it all flow from beginning to end?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PlSwIJMC0A8F"
   },
   "source": [
    "#### Your Answer Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6sWR43PTwhSk"
   },
   "source": [
    "## Write your own perceptron code that can correctly classify (99.0% accuracy) a NAND gate. \n",
    "\n",
    "| x1 | x2 | y |\n",
    "|----|----|---|\n",
    "| 0  | 0  | 1 |\n",
    "| 1  | 0  | 1 |\n",
    "| 0  | 1  | 1 |\n",
    "| 1  | 1  | 0 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = { 'x1': [0,1,0,1],\n",
    "         'x2': [0,0,1,1],\n",
    "         'y':  [1,1,1,0]\n",
    "       }\n",
    "\n",
    "df = pd.DataFrame.from_dict(data).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.29090673, 0.99830427])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = np.random.random(2)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 2)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inputs = np.array([data['x1'], data['x2']])\n",
    "inputs = df[['x1', 'x2']]\n",
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.29090673, 0.99830427, 1.289211  ])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_sum = np.dot(inputs, weights)\n",
    "weighted_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sgh7VFGwnXGH"
   },
   "outputs": [],
   "source": [
    "##### Your Code Here #####\n",
    "\n",
    "def sigmoid(x):\n",
    "  return 1/(1+np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "  sx = sigmoid(x)\n",
    "  return sx*(1-sx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5       , 0.5722181 , 0.73072505, 0.78401361])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activated_outputs = sigmoid(weighted_sum)\n",
    "activated_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.500000\n",
       "1    0.427782\n",
       "2    0.269275\n",
       "3   -0.784014\n",
       "Name: y, dtype: float64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error = df['y'] - activated_outputs\n",
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.125000\n",
       "1    0.104714\n",
       "2    0.052984\n",
       "3   -0.132762\n",
       "Name: y, dtype: float64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjustments = error*sigmoid_derivative(weighted_sum)\n",
    "adjustments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.26285919, 0.91852647])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = weights + np.dot(inputs.T, adjustments)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xf7sdqVs0s4x"
   },
   "source": [
    "## Implement your own Perceptron Class and use it to classify a binary dataset: \n",
    "- [The Pima Indians Diabetes dataset](https://raw.githubusercontent.com/ryanleeallred/datasets/master/diabetes.csv) \n",
    "\n",
    "You may need to search for other's implementations in order to get inspiration for your own. There are *lots* of perceptron implementations on the internet with varying levels of sophistication and complexity. Whatever your approach, make sure you understand **every** line of your implementation and what its purpose is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes = pd.read_csv('https://raw.githubusercontent.com/ryanleeallred/datasets/master/diabetes.csv')\n",
    "diabetes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although neural networks can handle non-normalized data, scaling or normalizing your data will improve your neural network's learning speed. Try to apply the sklearn `MinMaxScaler` or `Normalizer` to your diabetes dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, Normalizer\n",
    "\n",
    "feats = list(diabetes)[:-1]\n",
    "\n",
    "X = MinMaxScaler().fit_transform(diabetes[feats])\n",
    "y = diabetes['Outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.35294118, 0.74371859, 0.59016393, ..., 0.50074516, 0.23441503,\n",
       "        0.48333333],\n",
       "       [0.05882353, 0.42713568, 0.54098361, ..., 0.39642325, 0.11656704,\n",
       "        0.16666667],\n",
       "       [0.47058824, 0.91959799, 0.52459016, ..., 0.34724292, 0.25362938,\n",
       "        0.18333333],\n",
       "       ...,\n",
       "       [0.29411765, 0.6080402 , 0.59016393, ..., 0.390462  , 0.07130658,\n",
       "        0.15      ],\n",
       "       [0.05882353, 0.63316583, 0.49180328, ..., 0.4485842 , 0.11571307,\n",
       "        0.43333333],\n",
       "       [0.05882353, 0.46733668, 0.57377049, ..., 0.45305514, 0.10119556,\n",
       "        0.03333333]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-W0tiX1F1hh2"
   },
   "outputs": [],
   "source": [
    "##### Update this Class #####\n",
    "\n",
    "class Perceptron:\n",
    "    \n",
    "    def __init__(self, rate = 0.01, niter = 10):\n",
    "        self.rate = rate\n",
    "        self.niter = niter\n",
    "        # Randomly Initialize Weights\n",
    "        self.weight = np.random.random(1 + X.shape[1])\n",
    "    def __sigmoid(self, x):\n",
    "        return None\n",
    "    \n",
    "    def __sigmoid_derivative(self, x):\n",
    "        return None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit training data\n",
    "        X : Training vectors, X.shape : [#samples, #features]\n",
    "        y : Target values, y.shape : [#samples]\n",
    "        \"\"\"\n",
    "        \n",
    "\n",
    "\n",
    "        # Number of misclassficiations\n",
    "        self.errors = []\n",
    "\n",
    "        for i in range(self.niter):\n",
    "            err = 0\n",
    "            for xi, target in zip(X, y):\n",
    "                # Weighted sum of inputs / weights\n",
    "                predictions = self.predict(xi)\n",
    "                delta_w = self.rate * (target - predictions)\n",
    "                self.weight[1:] += delta_w * xi\n",
    "                self.weight[0] += delta_w\n",
    "                if delta_w != 0.0:\n",
    "                    err = err + 1\n",
    "                self.errors.append(err)\n",
    "            return self\n",
    "\n",
    "    def net_input(self, X):\n",
    "        \"\"\"Calculate net input\"\"\"\n",
    "        return np.dot(X, self.weight[1:]) + self.weight[0]\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Return class label after unit step\"\"\"\n",
    "        return np.where(self.net_input(X) >= 0.0, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pn = Perceptron(0.1, 10)\n",
    "pn.fit(X, y)\n",
    "plt.plot(range(1, len(pn.errors) + 1), pn.errors, marker='o')\n",
    "plt.xlabel('X Inputs')\n",
    "plt.ylabel('y')\n",
    "plt.show()\n",
    "\n",
    "# I don't think i'm doing this right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6QR4oAW1xdyu"
   },
   "source": [
    "## Stretch Goals:\n",
    "\n",
    "- Research \"backpropagation\" to learn how weights get updated in neural networks (tomorrow's lecture). \n",
    "- Implement a multi-layer perceptron. (for non-linearly separable classes)\n",
    "- Try and implement your own backpropagation algorithm.\n",
    "- What are the pros and cons of the different activation functions? How should you decide between them for the different layers of a neural network?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_431_Intro_to_NN_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
