{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dVfaLrjLvxvQ"
   },
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "# Neural Networks\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2 Assignment 1*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wxtoY12mwmih"
   },
   "source": [
    "## Define the Following:\n",
    "You can add image, diagrams, whatever you need to ensure that you understand the concepts below.\n",
    "\n",
    "### Input Layer:\n",
    "The input layer is the only layer that is exposed to our raw data. It will pass information further into the network and has weights and bias applied to it over time as the network updates. The number of input layers is associated with the number of variables.\n",
    "### Hidden Layer:\n",
    "A hidden layer is any layer that is not an input or output layer. This is part of what makes neural networks \"black box\" type solutions as we do not investigate the changes in the weights in these layers. They do apply transformations though that over epochs will increase the efficiency of our models\n",
    "### Output Layer:\n",
    "The final layer of a network, will have a transformation function applied to it so it can properly address the target the network is attempting to solve.\n",
    "### Neuron:\n",
    "A node within the neural network, it can be on any layer of the network, and represents where a transformation occurs of the data.\n",
    "### Weight:\n",
    "A vector transformation applied to the neuron, iterated overtime and is a source of optimization of a neural network over epochs.\n",
    "### Activation Function:\n",
    "A transformtaion applied ot the output layer. There are many types such as a stepwise (binary) as well as sigmoid (similar to a logistic regression) and tanh which has a steeper center portion of the curve than the sigmoid. It only determins if that given node will activate the next portion of a neural network, conrolling how much ifnormation is passed downstream within the network.\n",
    "### Node Map\n",
    "A visual representation of how each layer of the network interacts with the others.\n",
    "### Perceptron:\n",
    "The simpliest neural network. A single node with no hidden layers, it can take any number of inputs and at this simplest level looks very similar to linear regression.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NXuy9WcWzxa4"
   },
   "source": [
    "## Inputs -> Outputs\n",
    "\n",
    "### Explain the flow of information through a neural network from inputs to outputs. Be sure to include: inputs, weights, bias, and activation functions. How does it all flow from beginning to end?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PlSwIJMC0A8F"
   },
   "source": [
    "#### Data enters a neural network through the input nodes. Depending on the type of nerual network there may be additional layers called hidden layers. Each layer of the network will have weights and biases applied to them. A weight is a vector that is applied to the node by multiplication, and bias is an additaional kind of weight but is a static value instead of a vector transformation. Finally when the data arrives to the final node in the network, the output node, an activation function is applied which then makes a final transformation of the data to determine if the neuron fires or not, or depending on the function, some percentage (sigmoid) of the information is to be passed further on downstream into the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6sWR43PTwhSk"
   },
   "source": [
    "## Write your own perceptron code that can correctly classify (99.0% accuracy) a NAND gate. \n",
    "\n",
    "| x1 | x2 | y |\n",
    "|----|----|---|\n",
    "| 0  | 0  | 1 |\n",
    "| 1  | 0  | 1 |\n",
    "| 0  | 1  | 1 |\n",
    "| 1  | 1  | 0 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x1  x2  y\n",
       "0   0   0  1\n",
       "1   1   0  1\n",
       "2   0   1  1\n",
       "3   1   1  0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = { 'x1': [0,1,0,1],\n",
    "         'x2': [0,0,1,1],\n",
    "         'y':  [1,1,1,0]\n",
    "       }\n",
    "\n",
    "df = pd.DataFrame.from_dict(data).astype('int')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remember, the final column of all 1's represents our \"bias\" value\n",
    "inputs = np.array([\n",
    "    [0,0,1],\n",
    "    [1,0,1],\n",
    "    [0,1,1],\n",
    "    [1,1,1]\n",
    "])\n",
    "\n",
    "correct_outputs = [[1],[1],[1],[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sgh7VFGwnXGH"
   },
   "outputs": [],
   "source": [
    "##### Your Code Here #####\n",
    "\n",
    "import numpy as np\n",
    "#defining our sigmoid functions for our activation functions\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    sx = sigmoid(x)\n",
    "    return sx * (1-sx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.50218023],\n",
       "       [-0.53708896],\n",
       "       [ 0.14244743]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#generating weights between 0 and 1\n",
    "weights = 2 * np.random.random((3,1)) - 1\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.14244743],\n",
       "       [ 0.64462766],\n",
       "       [-0.39464154],\n",
       "       [ 0.1075387 ]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#applying our weights to our input values\n",
    "weighted_sum = np.dot(inputs,weights) \n",
    "weighted_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with our weights applied, we can enter our output layer with a sigmoid function\n",
    "activated_output = sigmoid(weighted_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.46444824],\n",
       "       [ 0.3442012 ],\n",
       "       [ 0.59739955],\n",
       "       [-0.5268588 ]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#then we can find the error on the output and our true values\n",
    "error = correct_outputs - activated_output\n",
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.10816877],\n",
       "       [ 0.07742325],\n",
       "       [ 0.14345778],\n",
       "       [-0.12298117]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#with our error values measured we can make adjustments, using gradient descent and backpropogation\n",
    "adjustments = error * sigmoid_derivative(activated_output)\n",
    "adjustments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with the adjustments determined, we can apply them to our original weights\n",
    "weights += np.dot(inputs.T,adjustments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.45662232],\n",
       "       [-0.51661235],\n",
       "       [ 0.34851606]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights after training\n",
      "[[-11.83977024]\n",
      " [-11.83977024]\n",
      " [ 17.80851995]]\n",
      "Output after training\n",
      "[[0.99999998]\n",
      " [0.99744883]\n",
      " [0.99744883]\n",
      " [0.00281235]]\n"
     ]
    }
   ],
   "source": [
    "#now we can iterate across this to increase our accuracy\n",
    "for iteration in range(10000):\n",
    "    \n",
    "    # Weighted sum of inputs / weights\n",
    "    weighted_sum = np.dot(inputs, weights)\n",
    "    \n",
    "    # Activate!\n",
    "    activated_output = sigmoid(weighted_sum)\n",
    "    \n",
    "    # Cac error\n",
    "    error = correct_outputs - activated_output\n",
    "    \n",
    "    adjustments = error * sigmoid_derivative(activated_output)\n",
    "    \n",
    "    # Update the Weights\n",
    "    weights += np.dot(inputs.T, adjustments)\n",
    "    \n",
    "print(\"Weights after training\")\n",
    "print(weights)\n",
    "\n",
    "print(\"Output after training\")\n",
    "print(activated_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xf7sdqVs0s4x"
   },
   "source": [
    "## Implement your own Perceptron Class and use it to classify a binary dataset: \n",
    "- [The Pima Indians Diabetes dataset](https://raw.githubusercontent.com/ryanleeallred/datasets/master/diabetes.csv) \n",
    "\n",
    "You may need to search for other's implementations in order to get inspiration for your own. There are *lots* of perceptron implementations on the internet with varying levels of sophistication and complexity. Whatever your approach, make sure you understand **every** line of your implementation and what its purpose is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes = pd.read_csv('https://raw.githubusercontent.com/ryanleeallred/datasets/master/diabetes.csv')\n",
    "diabetes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although neural networks can handle non-normalized data, scaling or normalizing your data will improve your neural network's learning speed. Try to apply the sklearn `MinMaxScaler` or `Normalizer` to your diabetes dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, Normalizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "feats = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
    "       'BMI', 'DiabetesPedigreeFunction', 'Age', 'bias']\n",
    "target = 'Outcome'\n",
    "diabetes['bias'] = np.ones(diabetes.shape[0])\n",
    "\n",
    "#converting our pandas dataframe into split numpy arrays into features and target\n",
    "X = diabetes[feats].to_numpy()\n",
    "y = diabetes[target].to_numpy()\n",
    "y = y * 2 - 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nueral Networks typically work with standardized data so we should apply a transformation to our features for more efficient models\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-W0tiX1F1hh2"
   },
   "outputs": [],
   "source": [
    "##### Update this Class #####\n",
    "\n",
    "class Perceptron(object):\n",
    "    \n",
    "    def __init__(self, rate = 0.1, niter = 10):\n",
    "        self.rate = rate\n",
    "        self.niter = niter\n",
    "    \n",
    "    def __sigmoid(self, x):\n",
    "        \n",
    "        return 1 / (1 + np.exp(-X))\n",
    "    \n",
    "    def __sigmoid_derivative(self, x):\n",
    "        sx = self.__sigmoid(X)\n",
    "        return sx * (1-sx)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit training data\n",
    "        X : Training vectors, X.shape : [#samples, #features]\n",
    "        y : Target values, y.shape : [#samples]\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Randomly Initialize Weights\n",
    "        #assign weights of 0 for the length of features + 1 (bias)\n",
    "        self.weight = np.zeros(1 + X.shape[1])\n",
    "        \n",
    "            \n",
    "        #initialize errors\n",
    "        self.errors = []\n",
    "\n",
    "\n",
    "        for i in range(self.niter):\n",
    "            #reset errors for function calling\n",
    "            err = 0\n",
    "            for xi, target in zip(X, y):\n",
    "                #the delta for each pass\n",
    "                delta_w = self.rate * (target - self.predict(xi))\n",
    "                # Weighted sum of inputs / weights\n",
    "                self.weight[1:] += delta_w * xi\n",
    "                self.weight[0] += delta_w\n",
    "                err += int(delta_w != 0.0)\n",
    "                self.errors.append(err)\n",
    "        return self\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Return class label after unit step\"\"\"\n",
    "        #takes dot product for all of the inputs and the optimized weights plus the bias (first value in the weights vector)\n",
    "        return np.dot(X, self.weight[1:]) + self.weight[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#initializating the perceptron class\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "nn = Perceptron()\n",
    "\n",
    "#fitting on the diabetes data\n",
    "nn.fit(X_scaled,y)\n",
    "plt.plot(range(1, len(nn.errors) + 1), nn.errors, marker='o')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Number of misclassifications')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6QR4oAW1xdyu"
   },
   "source": [
    "## Stretch Goals:\n",
    "\n",
    "- Research \"backpropagation\" to learn how weights get updated in neural networks (tomorrow's lecture). \n",
    "- Implement a multi-layer perceptron. (for non-linearly separable classes)\n",
    "- Try and implement your own backpropagation algorithm.\n",
    "- What are the pros and cons of the different activation functions? How should you decide between them for the different layers of a neural network?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_431_Intro_to_NN_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
