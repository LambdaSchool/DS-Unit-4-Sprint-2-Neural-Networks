{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dVfaLrjLvxvQ"
   },
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "# Neural Networks\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2 Assignment 1*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wxtoY12mwmih"
   },
   "source": [
    "## Define the Following:\n",
    "You can add image, diagrams, whatever you need to ensure that you understand the concepts below.\n",
    "\n",
    "### Input Layer:\n",
    "### Hidden Layer:\n",
    "### Output Layer:\n",
    "### Neuron:\n",
    "### Weight:\n",
    "### Activation Function:\n",
    "### Node Map:\n",
    "### Perceptron:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NXuy9WcWzxa4"
   },
   "source": [
    "## Inputs -> Outputs\n",
    "\n",
    "### Explain the flow of information through a neural network from inputs to outputs. Be sure to include: inputs, weights, bias, and activation functions. How does it all flow from beginning to end?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PlSwIJMC0A8F"
   },
   "source": [
    "#### Your Answer Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6sWR43PTwhSk"
   },
   "source": [
    "## Write your own perceptron code that can correctly classify (99.0% accuracy) a NAND gate. \n",
    "\n",
    "| x1 | x2 | y |\n",
    "|----|----|---|\n",
    "| 0  | 0  | 1 |\n",
    "| 1  | 0  | 1 |\n",
    "| 0  | 1  | 1 |\n",
    "| 1  | 1  | 0 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "data = { 'x1': [0,1,0,1],\n",
    "         'x2': [0,0,1,1],\n",
    "         'y':  [1,1,1,0]\n",
    "       }\n",
    "\n",
    "df = pd.DataFrame.from_dict(data).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y</th>\n",
       "      <th>bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x1  x2  y  bias\n",
       "0   0   0  1     1\n",
       "1   1   0  1     1\n",
       "2   0   1  1     1\n",
       "3   1   1  0     1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['bias'] = [1, 1, 1, 1]\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sgh7VFGwnXGH"
   },
   "outputs": [],
   "source": [
    "# okay I think the intent is to do this piece meal and then below I will\n",
    "# create a reusable class\n",
    "\n",
    "#sigmoid function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "#derivative function\n",
    "def sigmoid_derivative(x):\n",
    "    sx = sigmoid(x)\n",
    "    return sx * (1 - sx)\n",
    "\n",
    "#we are going to randomly initialize some weights.  This is starting as random\n",
    "# because I have no prior input.  The more we iterate over this perceptron, \n",
    "# these we will adjust these weights\n",
    "weights = 2 * np.random.random((3, 1)) - 1\n",
    "\n",
    "# weights = pd.DataFrame(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.25091976],\n",
       "       [ 0.90142861],\n",
       "       [ 0.46398788]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#okay this shape should be fine for workint withour dataframe.\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights after training:\n",
      "[[-10.3952784]\n",
      " [-10.3952784]\n",
      " [ 15.6777464]]\n",
      "Output after training\n",
      "[[0.99999984]\n",
      " [0.99494577]\n",
      " [0.99494577]\n",
      " [0.00598316]]\n"
     ]
    }
   ],
   "source": [
    "verbose = False\n",
    "\n",
    "inputs = df[['x1', 'x2', 'bias']].values\n",
    "correct_outputs = df['y'].values.reshape((4, 1))\n",
    "if verbose: print(inputs, correct_outputs)\n",
    "\n",
    "\n",
    "for iteration in range(100000):\n",
    "    \n",
    "    # multiplying our inputs (the x columns) by our weights\n",
    "    weighted_sum = np.dot(inputs, weights)\n",
    "    if verbose: print(weighted_sum)\n",
    "    \n",
    "    # I'm using a sigmoid function because my end output should be a 0 or a 1\n",
    "    # (true or false)\n",
    "    activated_output = sigmoid(weighted_sum)\n",
    "    if verbose: print(activated_output)\n",
    "    \n",
    "    # Next we need to calculate error.  Basically the difference between our\n",
    "    # prediction and our truth\n",
    "    error = correct_outputs - activated_output\n",
    "    if verbose: print(error)\n",
    "    \n",
    "    # good, now we know how much of a mistake we made in predicting, but it is\n",
    "    # in terms of outputs.  I need to understand what to input to our next\n",
    "    # epoch. The derivative will give me the instantaneous rate of change. \n",
    "    # so multiply our error by the rate of change, and I now have my error\n",
    "    # \"scaled\" in a way that is meaningful as an input.\n",
    "    adjustments = error * sigmoid_derivative(weighted_sum)\n",
    "    if verbose: print(adjustments)\n",
    "    \n",
    "    # Now lets adjust our weights by what we learned this epoch.  Effectively \n",
    "    # we learned how far off our prediction is from our truth (error) so we\n",
    "    # need to adjust our weights to minimize that error\n",
    "    weights += np.dot(inputs.T, adjustments)\n",
    "    if verbose: print(weights)\n",
    "    \n",
    "print('Weights after training:')\n",
    "print(weights)\n",
    "\n",
    "print('Output after training')\n",
    "print(activated_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xf7sdqVs0s4x"
   },
   "source": [
    "## Implement your own Perceptron Class and use it to classify a binary dataset: \n",
    "- [The Pima Indians Diabetes dataset](https://raw.githubusercontent.com/ryanleeallred/datasets/master/diabetes.csv) \n",
    "\n",
    "You may need to search for other's implementations in order to get inspiration for your own. There are *lots* of perceptron implementations on the internet with varying levels of sophistication and complexity. Whatever your approach, make sure you understand **every** line of your implementation and what its purpose is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes = pd.read_csv('https://raw.githubusercontent.com/ryanleeallred/datasets/master/diabetes.csv')\n",
    "diabetes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although neural networks can handle non-normalized data, scaling or normalizing your data will improve your neural network's learning speed. Try to apply the sklearn `MinMaxScaler` or `Normalizer` to your diabetes dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 8) (768,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.271471</td>\n",
       "      <td>0.572045</td>\n",
       "      <td>0.453936</td>\n",
       "      <td>0.271928</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385158</td>\n",
       "      <td>0.180305</td>\n",
       "      <td>0.371765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.067347</td>\n",
       "      <td>0.489028</td>\n",
       "      <td>0.619373</td>\n",
       "      <td>0.335375</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.453866</td>\n",
       "      <td>0.133458</td>\n",
       "      <td>0.190817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.376673</td>\n",
       "      <td>0.736073</td>\n",
       "      <td>0.419897</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.277943</td>\n",
       "      <td>0.203012</td>\n",
       "      <td>0.146745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.068414</td>\n",
       "      <td>0.520154</td>\n",
       "      <td>0.629186</td>\n",
       "      <td>0.270201</td>\n",
       "      <td>0.129227</td>\n",
       "      <td>0.487056</td>\n",
       "      <td>0.044198</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.476330</td>\n",
       "      <td>0.226851</td>\n",
       "      <td>0.244610</td>\n",
       "      <td>0.137398</td>\n",
       "      <td>0.444422</td>\n",
       "      <td>0.652899</td>\n",
       "      <td>0.138379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Pregnancies   Glucose BloodPressure SkinThickness   Insulin       BMI  \\\n",
       "0    0.271471  0.572045      0.453936      0.271928  0.000000  0.385158   \n",
       "1    0.067347  0.489028      0.619373      0.335375  0.000000  0.453866   \n",
       "2    0.376673  0.736073      0.419897      0.000000  0.000000  0.277943   \n",
       "3    0.068414  0.520154      0.629186      0.270201  0.129227  0.487056   \n",
       "4    0.000000  0.476330      0.226851      0.244610  0.137398  0.444422   \n",
       "\n",
       "  DiabetesPedigreeFunction       Age  \n",
       "0                 0.180305  0.371765  \n",
       "1                 0.133458  0.190817  \n",
       "2                 0.203012  0.146745  \n",
       "3                 0.044198  0.000000  \n",
       "4                 0.652899  0.138379  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, Normalizer\n",
    "\n",
    "# Min Max Scaler is better for scaling on a column, Normalizer is better for \n",
    "# normalizing a row. For my purposes minmax will do\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "normal = Normalizer()\n",
    "\n",
    "feats = list(diabetes)[:-1]\n",
    "\n",
    "y = diabetes['Outcome']\n",
    "\n",
    "scaler.fit(diabetes.drop(columns = ['Outcome']))\n",
    "X = scaler.transform(diabetes.drop(columns = ['Outcome']))\n",
    "\n",
    "normal.fit(X)\n",
    "X = normal.transform(X)\n",
    "\n",
    "X = pd.DataFrame(X, columns = [feats])\n",
    "\n",
    "print(X.shape, y.shape)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-W0tiX1F1hh2"
   },
   "outputs": [],
   "source": [
    "from random import uniform\n",
    "\n",
    "class Perceptron(object):\n",
    "    \n",
    "    def __init__(self, niter = 10, verbose = False):\n",
    "        '''\n",
    "        Warning, verbose is very verbose.  Only use with small iterations, small\n",
    "        dataframes or debugging\n",
    "        '''\n",
    "        self.niter = niter\n",
    "        self.verbose = verbose\n",
    "    \n",
    "    def __sigmoid(self, x):\n",
    "        return 1.0 / (1.0 + np.exp(-x))\n",
    "    \n",
    "    def __sigmoid_derivative(self, x):\n",
    "        sx = self.__sigmoid(x)\n",
    "        return sx * (1.0 - sx)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit training data\n",
    "        Assumes X and Y are dataframes and series respectively, there is \n",
    "        no bias added to the inputs X, and that X has been\n",
    "        scaled or normalized to some degree\n",
    "        X : Training vectors, X.shape : [#samples, #features]\n",
    "        y : Target values, y.shape : [#samples]\n",
    "        \"\"\"\n",
    "        # making a copy, adding a bias column, storing the width after bias and\n",
    "        # transforming to a numpy array\n",
    "        inputs = X.copy()\n",
    "        bias = [0.0] * X.shape[0]\n",
    "        inputs['bias'] = bias\n",
    "        #print(inputs.head())\n",
    "        width = inputs.shape[1]\n",
    "        inputs = inputs.values\n",
    "        \n",
    "        # transforming to a numpy array\n",
    "        y_width = y.shape[0]\n",
    "        correct_outputs = y.values.reshape((y_width, 1))\n",
    "\n",
    "        # Randomly Initialize Weights\n",
    "        weights = 2.0 * np.random.random((width, 1)) - 1.0\n",
    "\n",
    "        for i in range(self.niter):\n",
    "            # Weighted sum of inputs / weights\n",
    "            weighted_sum = np.dot(inputs, weights)\n",
    "            if self.verbose: print(weighted_sum)\n",
    "                \n",
    "            # Activate!\n",
    "            activated_output = self.__sigmoid(weighted_sum)\n",
    "            if self.verbose: print(activated_output)\n",
    "            \n",
    "            # Cac error\n",
    "            error = correct_outputs - activated_output\n",
    "            if self.verbose: print(error)\n",
    "            \n",
    "            # Update the Weights\n",
    "            adjustments = error * self.__sigmoid_derivative(weighted_sum)\n",
    "            if self.verbose: print(adjustments)\n",
    "                \n",
    "            weights += np.dot(inputs.T, adjustments)\n",
    "            if self.verbose: print(weights)\n",
    "                \n",
    "        self.weights = weights\n",
    "        #print(activated_output)\n",
    "        return self\n",
    "    \n",
    "    def net_input(self, X):\n",
    "        # My bias is the last entry of my weights\n",
    "        return np.dot(X, self.weights[:-1]) + self.weights[-1]\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.where(self.net_input(X) >= 0.5, 1, 0)\n",
    "\n",
    "#     def predict(self, X):\n",
    "#         \"\"\"Return class label after unit step\"\"\"\n",
    "#         # candidate for a helper function\n",
    "#         try:\n",
    "#             inputs = X.copy()\n",
    "#             inputs['bias'] = self.bias\n",
    "#             width = inputs.shape[1]\n",
    "#             inputs = inputs.values\n",
    "\n",
    "#             weighted_sum = np.dot(inputs, self.weights)\n",
    "#             if self.verbose: print(weighted_sum)\n",
    "\n",
    "#             activated_output = self.__sigmoid(weighted_sum)\n",
    "#             if verbose: print(activated_output)\n",
    "                \n",
    "#             return activated_output\n",
    "#         except:\n",
    "#             print(\"Perceptron hasn't been fit yet\")\n",
    "#             return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is:  0.6510416666666666\n",
      "Accuracy is:  0.6497395833333334\n",
      "Accuracy is:  0.6510416666666666\n",
      "Accuracy is:  0.58203125\n",
      "Accuracy is:  0.6510416666666666\n",
      "Accuracy is:  0.6510416666666666\n",
      "Accuracy is:  0.6510416666666666\n",
      "Accuracy is:  0.3489583333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "ptrons = []\n",
    "\n",
    "for i, col in enumerate(feats):\n",
    "\n",
    "    ptron = Perceptron(niter = 100000)\n",
    "\n",
    "    ptrons.append(ptron.fit(X[[col]], y))\n",
    "\n",
    "    y_pred = pd.DataFrame(ptrons[i].predict(X[[col]]), columns = ['Predictions'])\n",
    "\n",
    "    print('Accuracy is: ', accuracy_score(y, y_pred))\n",
    "    y_pred['Predictions'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6QR4oAW1xdyu"
   },
   "source": [
    "## Stretch Goals:\n",
    "\n",
    "- Research \"backpropagation\" to learn how weights get updated in neural networks (tomorrow's lecture). \n",
    "- Implement a multi-layer perceptron. (for non-linearly separable classes)\n",
    "- Try and implement your own backpropagation algorithm.\n",
    "- What are the pros and cons of the different activation functions? How should you decide between them for the different layers of a neural network?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_431_Intro_to_NN_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
