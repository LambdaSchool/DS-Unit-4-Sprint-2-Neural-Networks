{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dVfaLrjLvxvQ"
   },
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "# Neural Networks\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2 Assignment 1*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wxtoY12mwmih"
   },
   "source": [
    "## Define the Following:\n",
    "You can add image, diagrams, whatever you need to ensure that you understand the concepts below.\n",
    "\n",
    "### Input Layer: This is where data interacts with the NN directly. It is the only part exposed to our data.\n",
    "### Hidden Layer: These are the layers between the input layer and output layer that do all the magic, but are never interacted with directly.\n",
    "### Output Layer: The output layer produces one or more values in a format useful for the problem that is being attempted.\n",
    "### Neuron: Neurons receive inputs, apply a function to the inputs, and pass the outputs to the next layer of neurons.\n",
    "### Weight: A constant coefficient on an input; it is basically a simple linear function.\n",
    "### Activation Function: A function that determines how much signal any individual node sends to the next layer.\n",
    "### Node Map: A visual diagram showing the type of and relations between each cell.\n",
    "### Perceptron: A simple neural network consisting of a single node, that takes each input value, multiplies it by a weight coefficient, and passes the result through an activation function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NXuy9WcWzxa4"
   },
   "source": [
    "## Inputs -> Outputs\n",
    "\n",
    "### Explain the flow of information through a neural network from inputs to outputs. Be sure to include: inputs, weights, bias, and activation functions. How does it all flow from beginning to end?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PlSwIJMC0A8F"
   },
   "source": [
    "Information first flows into a network through the input nodes, which accept raw input data and insert it into the network. Next, once that data is passed onto the first hidden layer, each node that interacts with it applies weights to each input, adds a bias, and then runs the output through an activation function to determine how much of the output is passed on to the next layer. Next, each node passes on their information to the next hidden layer, and the process repeats. If there are no more hidden layers, the data passes to the output nodes, which parses the information into a format useful for solving the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6sWR43PTwhSk"
   },
   "source": [
    "## Write your own perceptron code that can correctly classify (99.0% accuracy) a NAND gate. \n",
    "\n",
    "| x1 | x2 | y |\n",
    "|----|----|---|\n",
    "| 0  | 0  | 1 |\n",
    "| 1  | 0  | 1 |\n",
    "| 0  | 1  | 1 |\n",
    "| 1  | 1  | 0 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = { 'x1': [0,1,0,1],\n",
    "         'x2': [0,0,1,1],\n",
    "         'y':  [1,1,1,0]\n",
    "       }\n",
    "\n",
    "df = pd.DataFrame.from_dict(data).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sgh7VFGwnXGH"
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    sx = sigmoid(x)\n",
    "    return sx * (1 - sx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[0, 0, 1],\n",
      "       [1, 0, 1],\n",
      "       [0, 1, 1],\n",
      "       [1, 1, 0]])\n",
      "array([[1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0]])\n"
     ]
    }
   ],
   "source": [
    "inputs = df.values\n",
    "correct_outputs = df['y'].values.reshape(-1, 1)\n",
    "print(repr(inputs))\n",
    "print(repr(correct_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.09762701],\n",
       "       [0.43037873],\n",
       "       [0.20552675]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = 2 * np.random.random((3, 1)) - 1\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.20552675],\n",
       "       [0.30315376],\n",
       "       [0.63590548],\n",
       "       [0.52800574]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_sum = np.dot(inputs, weights)\n",
    "weighted_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.55120158],\n",
       "       [0.5752133 ],\n",
       "       [0.6538273 ],\n",
       "       [0.62901786]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activated_output = sigmoid(weighted_sum)\n",
    "activated_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.44879842],\n",
       "       [ 0.4247867 ],\n",
       "       [ 0.3461727 ],\n",
       "       [-0.62901786]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error = correct_outputs - activated_output\n",
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.11102303],\n",
       "       [ 0.10379364],\n",
       "       [ 0.07835174],\n",
       "       [-0.14678408]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjustments = error * sigmoid_derivative(weighted_sum)\n",
    "adjustments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05463657],\n",
       "       [0.3619464 ],\n",
       "       [0.49869517]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights += np.dot(inputs.T, adjustments)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iteration in range(10000):\n",
    "    weighted_sum = np.dot(inputs, weights)\n",
    "    \n",
    "    activated_output = sigmoid(weighted_sum)\n",
    "    \n",
    "    error = correct_outputs - activated_output\n",
    "    \n",
    "    adjustments = error * sigmoid_derivative(weighted_sum)\n",
    "    \n",
    "    weights += np.dot(inputs.T, adjustments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights after training:\n",
      "array([[-2.41089422],\n",
      "       [-2.40961964],\n",
      "       [ 7.49030711]])\n",
      "Output after training\n",
      "array([[0.9994418 ],\n",
      "       [0.99381462],\n",
      "       [0.99382245],\n",
      "       [0.00799856]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Weights after training:\")\n",
    "print(repr(weights))\n",
    "\n",
    "print(\"Output after training\")\n",
    "print(repr(activated_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xf7sdqVs0s4x"
   },
   "source": [
    "## Implement your own Perceptron Class and use it to classify a binary dataset: \n",
    "- [The Pima Indians Diabetes dataset](https://raw.githubusercontent.com/ryanleeallred/datasets/master/diabetes.csv) \n",
    "\n",
    "You may need to search for other's implementations in order to get inspiration for your own. There are *lots* of perceptron implementations on the internet with varying levels of sophistication and complexity. Whatever your approach, make sure you understand **every** line of your implementation and what its purpose is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes = pd.read_csv('https://raw.githubusercontent.com/ryanleeallred/datasets/master/diabetes.csv')\n",
    "diabetes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although neural networks can handle non-normalized data, scaling or normalizing your data will improve your neural network's learning speed. Try to apply the sklearn `MinMaxScaler` or `Normalizer` to your diabetes dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, Normalizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "feats = list(diabetes)[:-1]\n",
    "\n",
    "train, test = train_test_split(diabetes, random_state=0)\n",
    "\n",
    "X_train = train[feats]\n",
    "y_train = train[\"Outcome\"].values\n",
    "X_test = test[feats]\n",
    "y_test = test[\"Outcome\"].values\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    Normalizer(norm='max')\n",
    ")\n",
    "\n",
    "X_train_transformed = pipeline.fit_transform(X_train, y_train)\n",
    "X_test_transformed = pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-W0tiX1F1hh2"
   },
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, niter = 10):\n",
    "        self.niter = niter\n",
    "    \n",
    "    def __sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def __sigmoid_derivative(self, x):\n",
    "        sx = self.__sigmoid(x)\n",
    "        return sx * (1 - sx)\n",
    "    \n",
    "    def __loop(self, X, y=None, weights=None):\n",
    "        # Weighted sum of inputs / weights\n",
    "        if weights is None:\n",
    "            weights = self.weights_\n",
    "        weighted_sum = np.dot(X, weights)\n",
    "        # Activate!\n",
    "        activated_output = self.__sigmoid(weighted_sum)\n",
    "        if y is None:\n",
    "            return activated_output#.round()\n",
    "        else:\n",
    "            # Calc error\n",
    "            error = y - activated_output\n",
    "            # Update the Weights\n",
    "            adjustments = error * self.__sigmoid_derivative(weighted_sum)\n",
    "            return weights + np.dot(X.T, adjustments)\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit training data\n",
    "        X : Training vectors, X.shape : [#samples, #features]\n",
    "        y : Target values, y.shape : [#samples]\n",
    "        \"\"\"\n",
    "        \n",
    "        if y.ndim == 1:\n",
    "            y_ = y.reshape(-1, 1)\n",
    "        else:\n",
    "            y_ = y.copy()\n",
    "            \n",
    "        # Randomly Initialize Weights\n",
    "        weights = 2 * np.random.random((X.shape[1], 1)) - 1\n",
    "        self.weights_ = weights.T\n",
    "        \n",
    "        for i in range(self.niter):\n",
    "            weights = self.__loop(X, y_, weights)\n",
    "        self.weights_ = weights\n",
    "        self.outputs_ = activated_output\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Return class label after unit step\"\"\"\n",
    "        return(self.__loop(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron = Perceptron(niter=100).fit(X_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9994418 ],\n",
       "       [0.99381462],\n",
       "       [0.99382245],\n",
       "       [0.00799856]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron.outputs_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.32175438e-13],\n",
       "       [9.89786374e-17],\n",
       "       [8.79700300e-17],\n",
       "       [4.84762897e-14],\n",
       "       [1.73797412e-14],\n",
       "       [1.06713556e-17],\n",
       "       [7.64223240e-14],\n",
       "       [4.81577346e-15],\n",
       "       [7.74902940e-08],\n",
       "       [1.39934127e-10],\n",
       "       [2.75952216e-10],\n",
       "       [1.79515792e-13],\n",
       "       [1.54809886e-15],\n",
       "       [1.75720827e-12],\n",
       "       [2.26173725e-18],\n",
       "       [3.47193182e-15],\n",
       "       [3.68565932e-14],\n",
       "       [1.24939402e-15],\n",
       "       [8.14515237e-16],\n",
       "       [5.04165546e-16],\n",
       "       [8.49406355e-15],\n",
       "       [3.29953348e-15],\n",
       "       [2.04637699e-11],\n",
       "       [7.24553299e-17],\n",
       "       [6.64806849e-12],\n",
       "       [4.27331750e-14],\n",
       "       [2.97523659e-15],\n",
       "       [6.50566927e-16],\n",
       "       [1.22097595e-14],\n",
       "       [9.47932107e-15],\n",
       "       [7.87207993e-16],\n",
       "       [1.41577818e-16],\n",
       "       [3.20277552e-17],\n",
       "       [3.86719507e-12],\n",
       "       [5.90022964e-14],\n",
       "       [5.29558515e-13],\n",
       "       [3.01144045e-16],\n",
       "       [2.55468664e-16],\n",
       "       [2.72464163e-14],\n",
       "       [3.55965544e-13],\n",
       "       [3.17094311e-15],\n",
       "       [6.57333239e-17],\n",
       "       [8.08744436e-16],\n",
       "       [9.37159649e-13],\n",
       "       [2.42226890e-06],\n",
       "       [5.55088085e-15],\n",
       "       [3.04048686e-15],\n",
       "       [4.94340402e-15],\n",
       "       [2.67078486e-16],\n",
       "       [8.72529579e-15],\n",
       "       [5.64782977e-14],\n",
       "       [7.65193173e-15],\n",
       "       [2.31739989e-09],\n",
       "       [1.75664843e-15],\n",
       "       [9.53725885e-09],\n",
       "       [1.39061872e-10],\n",
       "       [9.65955772e-17],\n",
       "       [8.27748117e-17],\n",
       "       [9.11413537e-14],\n",
       "       [4.59190801e-10],\n",
       "       [2.62122619e-12],\n",
       "       [1.56135176e-08],\n",
       "       [7.74640571e-14],\n",
       "       [1.63007604e-10],\n",
       "       [7.59207367e-13],\n",
       "       [1.14213418e-12],\n",
       "       [3.97997159e-14],\n",
       "       [6.76959964e-15],\n",
       "       [1.89002191e-14],\n",
       "       [3.58824344e-18],\n",
       "       [1.75657180e-14],\n",
       "       [9.00049598e-11],\n",
       "       [5.95163617e-17],\n",
       "       [5.97985420e-14],\n",
       "       [3.63342919e-13],\n",
       "       [1.56429853e-14],\n",
       "       [8.55530861e-16],\n",
       "       [2.02358889e-12],\n",
       "       [6.67344006e-18],\n",
       "       [1.47932690e-16],\n",
       "       [1.59545860e-16],\n",
       "       [4.07384433e-11],\n",
       "       [6.60758394e-15],\n",
       "       [6.02957802e-16],\n",
       "       [8.83311054e-16],\n",
       "       [4.05073908e-17],\n",
       "       [8.95169080e-13],\n",
       "       [1.07021142e-14],\n",
       "       [3.33025026e-14],\n",
       "       [1.04054027e-14],\n",
       "       [6.65496431e-15],\n",
       "       [1.02821430e-14],\n",
       "       [1.71292234e-14],\n",
       "       [1.63898115e-16],\n",
       "       [8.52487741e-15],\n",
       "       [7.49322278e-15],\n",
       "       [4.61723141e-18],\n",
       "       [1.67549441e-09],\n",
       "       [2.65263987e-10],\n",
       "       [3.42589590e-15],\n",
       "       [5.75055829e-08],\n",
       "       [2.77715361e-15],\n",
       "       [1.86436191e-16],\n",
       "       [9.06216808e-16],\n",
       "       [1.98716236e-14],\n",
       "       [3.49341647e-15],\n",
       "       [3.53262958e-16],\n",
       "       [3.83554222e-14],\n",
       "       [7.75930256e-17],\n",
       "       [1.99921688e-12],\n",
       "       [7.95604695e-16],\n",
       "       [8.57656539e-12],\n",
       "       [8.50676694e-14],\n",
       "       [1.13492163e-16],\n",
       "       [1.44387567e-06],\n",
       "       [4.00991968e-14],\n",
       "       [3.75848240e-07],\n",
       "       [1.49921705e-07],\n",
       "       [6.45810953e-16],\n",
       "       [2.97543793e-14],\n",
       "       [2.69558675e-16],\n",
       "       [1.25886871e-18],\n",
       "       [1.10155020e-13],\n",
       "       [8.64092301e-16],\n",
       "       [2.80304771e-14],\n",
       "       [3.92172315e-15],\n",
       "       [8.57410994e-14],\n",
       "       [1.88551991e-15],\n",
       "       [1.01462406e-13],\n",
       "       [2.83472538e-13],\n",
       "       [8.51393705e-15],\n",
       "       [5.82382482e-10],\n",
       "       [2.45799348e-16],\n",
       "       [1.28852098e-05],\n",
       "       [2.66772170e-17],\n",
       "       [6.91177277e-17],\n",
       "       [4.38623281e-14],\n",
       "       [7.45194028e-16],\n",
       "       [2.03701988e-10],\n",
       "       [1.81761642e-13],\n",
       "       [2.01207313e-16],\n",
       "       [8.99967986e-15],\n",
       "       [4.41921996e-14],\n",
       "       [1.01612384e-16],\n",
       "       [6.49192752e-15],\n",
       "       [1.48242062e-14],\n",
       "       [1.43160114e-16],\n",
       "       [1.33062461e-17],\n",
       "       [1.37811185e-15],\n",
       "       [1.50902705e-10],\n",
       "       [1.30085621e-16],\n",
       "       [1.56810293e-14],\n",
       "       [7.32834225e-16],\n",
       "       [2.27500167e-16],\n",
       "       [1.39727364e-15],\n",
       "       [3.96189661e-15],\n",
       "       [3.66782341e-05],\n",
       "       [1.10457151e-12],\n",
       "       [6.72125436e-11],\n",
       "       [3.12179938e-11],\n",
       "       [1.86791920e-14],\n",
       "       [4.21101920e-13],\n",
       "       [7.28568595e-16],\n",
       "       [7.25509480e-15],\n",
       "       [5.56003742e-13],\n",
       "       [1.34938605e-10],\n",
       "       [3.12759600e-17],\n",
       "       [4.82945242e-14],\n",
       "       [1.49563916e-13],\n",
       "       [7.27370233e-17],\n",
       "       [3.34463567e-13],\n",
       "       [7.42597981e-20],\n",
       "       [2.12420830e-15],\n",
       "       [3.12363185e-16],\n",
       "       [5.43173640e-15],\n",
       "       [1.31112291e-17],\n",
       "       [5.11673157e-17],\n",
       "       [4.92538856e-19],\n",
       "       [1.71820381e-16],\n",
       "       [8.53767081e-16],\n",
       "       [2.25577727e-16],\n",
       "       [1.50574556e-15],\n",
       "       [7.94799185e-18],\n",
       "       [4.99726487e-13],\n",
       "       [9.75827436e-14],\n",
       "       [4.24246097e-16],\n",
       "       [9.54777766e-11],\n",
       "       [2.32291905e-14],\n",
       "       [2.13850565e-14],\n",
       "       [6.82666460e-10],\n",
       "       [6.41460394e-15],\n",
       "       [1.21175793e-17]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron.predict(X_test_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6QR4oAW1xdyu"
   },
   "source": [
    "## Stretch Goals:\n",
    "\n",
    "- Research \"backpropagation\" to learn how weights get updated in neural networks (tomorrow's lecture). \n",
    "- Implement a multi-layer perceptron. (for non-linearly separable classes)\n",
    "- Try and implement your own backpropagation algorithm.\n",
    "- What are the pros and cons of the different activation functions? How should you decide between them for the different layers of a neural network?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_431_Intro_to_NN_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
