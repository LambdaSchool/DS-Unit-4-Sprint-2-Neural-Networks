{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dVfaLrjLvxvQ"
   },
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "# Neural Networks\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2 Assignment 1*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wxtoY12mwmih"
   },
   "source": [
    "## Define the Following:\n",
    "You can add image, diagrams, whatever you need to ensure that you understand the concepts below.\n",
    "\n",
    "### Input Layer: The input layer is where certain information is passed to the neural network\n",
    "### Hidden Layer: A hidden layer is where information from the previous layer is transformed in some way and passed to the next layer. It is neither the input or output layer.\n",
    "### Output Layer: The output layer is where the results of the neural network end up to be used.\n",
    "### Neuron: A neuron is an individual node of a layer\n",
    "### Weight: How strong of an impact a given input has on a given node\n",
    "### Activation Function: The mapping of input(s) to output(s) for a given node\n",
    "### Node Map: A diagram showing how all of the nodes connect to each other\n",
    "### Perceptron: A perceptron is just a single node mapping input(s) to output(s) according to the weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NXuy9WcWzxa4"
   },
   "source": [
    "## Inputs -> Outputs\n",
    "\n",
    "### Explain the flow of information through a neural network from inputs to outputs. Be sure to include: inputs, weights, bias, and activation functions. How does it all flow from beginning to end?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PlSwIJMC0A8F"
   },
   "source": [
    "#### Inputs are passed to the input layer. Then inside the neural network, the inputs are passed to the next (hidden) layer. Each node in that hidden layer processes the input(s) it receives according to the weights in that node's activation function. The node then passes its output to the next layer according to the node map. This process continues until all output nodes have received a value. At each layer in the neural network, there may be a bias input to the layer that is taken as an input by some or all nodes in that layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6sWR43PTwhSk"
   },
   "source": [
    "## Write your own perceptron code that can correctly classify a NAND gate. \n",
    "\n",
    "| x1 | x2 | y |\n",
    "|----|----|---|\n",
    "| 0  | 0  | 1 |\n",
    "| 1  | 0  | 1 |\n",
    "| 0  | 1  | 1 |\n",
    "| 1  | 1  | 0 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    sx = sigmoid(x)\n",
    "    return sx * (1-sx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sgh7VFGwnXGH"
   },
   "outputs": [],
   "source": [
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-11.83940805 -11.83940805  17.80797679]\n",
      "(3,) (3,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17.807976794620327"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Perceptron(object):\n",
    "    \n",
    "    def __init__(self, niter = 10):\n",
    "        self.niter = niter\n",
    "    \n",
    "    def __sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def __sigmoid_derivative(self, x):\n",
    "        sx = self.__sigmoid(x)\n",
    "        return sx * (1-sx)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit training data\n",
    "        X : Training vectors, X.shape : [#samples, #features]\n",
    "        y : Target values, y.shape : [#samples]\n",
    "        \"\"\"\n",
    "        # Randomly Initialize Weights\n",
    "        X['ones'] = np.ones(X.shape[0])\n",
    "        weights = np.zeros(X.shape[1])\n",
    "\n",
    "        for i in range(self.niter):\n",
    "            # Weighted sum of inputs / weights\n",
    "            weighted = np.dot(X, weights)\n",
    "            \n",
    "            # Activate!\n",
    "            pred = self.__sigmoid(weighted)\n",
    "            \n",
    "            # Calc error\n",
    "            errors = y.values - pred.reshape(-1,1)\n",
    "\n",
    "            # Update the Weights\n",
    "            adjustments = errors*self.__sigmoid_derivative(pred).reshape(-1,1)\n",
    "            weights += np.dot(X.T, adjustments).reshape(3)\n",
    "\n",
    "        self.weights = weights\n",
    "            \n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        print(self.weights)\n",
    "        print(self.weights.shape, X.shape)\n",
    "        pred = np.dot(self.weights, X)\n",
    "        return pred\n",
    "    \n",
    "p = Perceptron(niter = 10000)\n",
    "p.fit(X,y)\n",
    "p.predict(X.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.46722186 -0.46722186  1.17752266]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (3,) and (4,) not aligned: 3 (dim 0) != 4 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-112-d141557216a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-111-3da3f7dbb81d>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (3,) and (4,) not aligned: 3 (dim 0) != 4 (dim 0)"
     ]
    }
   ],
   "source": [
    "p.predict(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.0\n",
      "1       0.0\n",
      "ones    1.0\n",
      "Name: 0, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(X.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "X = pd.DataFrame([[0,0]\n",
    "    ,[1,0]\n",
    "    ,[0,1]\n",
    "    ,[1,1]])\n",
    "\n",
    "y = pd.DataFrame([[1],[1],[1],[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0.])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros(3)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.Perceptron at 0x1208cff28>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pn = Perceptron(0.1, 1000)\n",
    "pn.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range(1, len(pn.errors) +1), pn.errors, marker = 'o')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Number of misclassifications')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pn.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xf7sdqVs0s4x"
   },
   "source": [
    "## Implement your own Perceptron Class and use it to classify a binary dataset like: \n",
    "- [The Pima Indians Diabetes dataset](https://raw.githubusercontent.com/ryanleeallred/datasets/master/diabetes.csv) \n",
    "- [Titanic](https://raw.githubusercontent.com/ryanleeallred/datasets/master/titanic.csv)\n",
    "- [A two-class version of the Iris dataset](https://raw.githubusercontent.com/ryanleeallred/datasets/master/Iris.csv)\n",
    "\n",
    "You may need to search for other's implementations in order to get inspiration for your own. There are *lots* of perceptron implementations on the internet with varying levels of sophistication and complexity. Whatever your approach, make sure you understand **every** line of your implementation and what its purpose is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-W0tiX1F1hh2"
   },
   "outputs": [],
   "source": [
    "##### Your Code Here #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6QR4oAW1xdyu"
   },
   "source": [
    "## Stretch Goals:\n",
    "\n",
    "- Research \"backpropagation\" to learn how weights get updated in neural networks (tomorrow's lecture). \n",
    "- Implement a multi-layer perceptron. (for non-linearly separable classes)\n",
    "- Try and implement your own backpropagation algorithm.\n",
    "- What are the pros and cons of the different activation functions? How should you decide between them for the different layers of a neural network?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_431_Intro_to_NN_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
