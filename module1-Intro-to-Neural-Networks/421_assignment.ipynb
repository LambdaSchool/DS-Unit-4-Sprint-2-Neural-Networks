{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dVfaLrjLvxvQ"
   },
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "# Neural Networks\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2 Assignment 1*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wxtoY12mwmih"
   },
   "source": [
    "## Define the Following:\n",
    "You can add image, diagrams, whatever you need to ensure that you understand the concepts below.\n",
    "\n",
    "### - Input Layer:\n",
    "Nodes (visible) which consist of received data from a dataset (or whatever input medium we want to use).\n",
    "### - Hidden Layer:\n",
    "Nodes which are 'invisible' to us. They receive input from input node, or another hidden node's output among maybe more exotic cases. They typically help increase the accuracy of the model by allowing the neural network to adapt to more non-linear problems.\n",
    "### - Output Layer:\n",
    "Three forms of an output layer: Regression, Binary, Multiclass. All have a special activation function, sometimes called an transfer, to determine if the output should be passed along to affect the outcome or not.\n",
    "### - Neuron: \n",
    "The biological unit that allows and uses electrochemical signals to pass information from one part of a system to another (or in the bio case, brain). Has things called dendrites that connect to axon terminals via axons surrounded by myelin sheathes, inside the cell body next to the dendrites is the nucleus which determines whether or not to pass a signal. Remove all the bio stuff and you got the computer stuff ayo\n",
    "![Neuron](https://img.tfd.com/medical/Davis/Tabers/n15.jpg)\n",
    "\n",
    "### Weight:\n",
    "A weight is a number to modify an input value.\n",
    "### Activation Function:\n",
    "An activation function, or transfer function, can update weights using back propogation to create a better outcome. An activation function at its core is typically the same throughout all layers of the NN. It determines how much signal to 'transfer' to the next layer...doesn't seem to be a 1 or 0 type of situation strictly but instead a _long_ number between two values, ala tan, relu, etc.\n",
    "![RELU](https://upload.wikimedia.org/wikipedia/commons/thumb/f/fe/Activation_rectified_linear.svg/1024px-Activation_rectified_linear.svg.png)\n",
    "### Node Map:\n",
    "![Node map!](http://www.asimovinstitute.org/wp-content/uploads/2016/09/ff.png)\n",
    "A way of drawing a neural network.\n",
    "### Perceptron:\n",
    "A type of NN that has the following properties: (n) inputs, 0 hidden layers, 1 output; goes one direction, left-to-right; inputs multiplied by weight, sum all products and pass sum through activation function and outputs as result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NXuy9WcWzxa4"
   },
   "source": [
    "## Inputs -> Outputs\n",
    "\n",
    "#### Explain the flow of information through a neural network from inputs to outputs. Be sure to include: inputs, weights, bias, and activation functions. How does it all flow from beginning to end?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PlSwIJMC0A8F"
   },
   "source": [
    "- _Inputs_: First has weight applied to it via multiplication, then after added to other inputs in the system, has the total summed along with the bias. After that the end result either goes into the apropos hidden layer or straight to our output.\n",
    "- _Hidden Layers_: receives input from the the node 'above' it, and uses an activation function to determine whether or not to update weights using back propagation or to pass the value along, modified or not.\n",
    "- _Output_: Three possible forms -> Regression, Binary, Multiclass. They give us values betwixt the apropos forms. One thing to ponder though is that can an output inform the hidden layers and stuff? Like, are output nodes a very distinct thing, or can the definition become muddled with more complex Neural Networks?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6sWR43PTwhSk"
   },
   "source": [
    "## Write your own perceptron code that can correctly classify (99.0% accuracy) a NAND gate. \n",
    "\n",
    "| x1 | x2 | y |\n",
    "|----|----|---|\n",
    "| 0  | 0  | 1 |\n",
    "| 1  | 0  | 1 |\n",
    "| 0  | 1  | 1 |\n",
    "| 1  | 1  | 0 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = { 'x1': [0,1,0,1],\n",
    "         'x2': [0,0,1,1],\n",
    "         'y':  [1,1,1,0]\n",
    "       }\n",
    "\n",
    "df = pd.DataFrame.from_dict(data).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x1  x2  y\n",
       "0   0   0  1\n",
       "1   1   0  1\n",
       "2   0   1  1\n",
       "3   1   1  0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = [[1],[1],[1],[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sgh7VFGwnXGH"
   },
   "outputs": [],
   "source": [
    "##### Your Code Here #####\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def sigmoid_d(x):\n",
    "    sx = sigmoid(x)\n",
    "    return sx*(1-sx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.9966568 ],\n",
       "       [ 0.59535109],\n",
       "       [-0.48397041]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since we have correct outputs as y and input data, all we need to do is get random weights\n",
    "wgt = 2 * np.random.random((3,1)) - 1\n",
    "wgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1],\n",
       "       [1, 0, 1],\n",
       "       [0, 1, 1],\n",
       "       [1, 1, 0]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inputs\n",
    "inputs = df.values\n",
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calc weighted sum of inputs and weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.48397041],\n",
       "       [ 0.51268639],\n",
       "       [ 0.11138068],\n",
       "       [ 1.59200788]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wgt_sum = np.dot(inputs, wgt)\n",
    "wgt_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output 'activated' value for end of first training epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.38131501],\n",
       "       [0.62543601],\n",
       "       [0.52781642],\n",
       "       [0.83089841]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_out = sigmoid(wgt_sum)\n",
    "act_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahhh only last one is above .5 ... uh ohhhh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take diff of output and true values to calc error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.61868499],\n",
       "       [ 0.37456399],\n",
       "       [ 0.47218358],\n",
       "       [-0.83089841]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err = corr - act_out\n",
    "err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A little confused on how to interpret this output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's gradient descent, or backprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.1491824 ],\n",
       "       [ 0.08504914],\n",
       "       [ 0.11019149],\n",
       "       [-0.17562709]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj = err * sigmoid_d(act_out)\n",
    "adj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update weights based off adjustments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.90607885],\n",
       "       [ 0.52991549],\n",
       "       [-0.13954737]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wgt += np.dot(inputs.T, adj)\n",
    "wgt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also a little lost as to interpreting this output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a function (from teach) to automate a large iteration of the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for itr in range(3):\n",
    "    # weighted sum of inputs / weights\n",
    "    wgt_sum = np.dot(inputs, wgt)\n",
    "    # activate\n",
    "    act_out = sigmoid(wgt_sum)\n",
    "    # calc error\n",
    "    err = corr - act_out\n",
    "    # adjust (backprop/grad desc)\n",
    "    adj = err * sigmoid_d(act_out)\n",
    "    # update weights based off adjustment\n",
    "    wgt += np.dot(inputs.T, adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Weight after training: \n",
      "[[-0.93874668]\n",
      " [-1.06308873]\n",
      " [ 3.4970989 ]]\n",
      "Output after training: \n",
      "[[0.96950729]\n",
      " [0.92663123]\n",
      " [0.91757225]\n",
      " [0.12209553]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'''\n",
    "Weight after training: \\n{wgt}\n",
    "Output after training: \\n{act_out}\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output and weights make sense I think! It's classifying this as a NAND as the fourth output is clearly at 0...I'm guessing that means it's able to determine that this is a NAND? not sure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xf7sdqVs0s4x"
   },
   "source": [
    "## Implement your own Perceptron Class and use it to classify a binary dataset: \n",
    "- [The Pima Indians Diabetes dataset](https://raw.githubusercontent.com/ryanleeallred/datasets/master/diabetes.csv) \n",
    "\n",
    "You may need to search for other's implementations in order to get inspiration for your own. There are *lots* of perceptron implementations on the internet with varying levels of sophistication and complexity. Whatever your approach, make sure you understand **every** line of your implementation and what its purpose is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes = pd.read_csv('https://raw.githubusercontent.com/ryanleeallred/datasets/master/diabetes.csv')\n",
    "diabetes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(diabetes.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although neural networks can handle non-normalized data, scaling or normalizing your data will improve your neural network's learning speed. Try to apply the sklearn `MinMaxScaler` or `Normalizer` to your diabetes dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = pd.read_csv('https://raw.githubusercontent.com/ryanleeallred/datasets/master/diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, Normalizer\n",
    "\n",
    "feats = list(diabetes)[:-1]\n",
    "scaley = MinMaxScaler()\n",
    "# Fit transform with features\n",
    "X = scaley.fit_transform(diabetes[feats])\n",
    "d_norm = pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split it up\n",
    "X_test = d_norm.iloc[500:]\n",
    "X_train = d_norm.iloc[0:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalized!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Btw EPOCHS are the number of times to run thru the training data while updating our weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SEMI-AUTOMATICALLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not related to the class cause don't make sense to try and figure out how to write a class for it AND do this assignment at the same time.\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "\n",
    "y_train = np.array(diabetes.iloc[0:500].Outcome).reshape(-1,1)\n",
    "y_test = np.array(diabetes.iloc[500:].Outcome).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 8) & (500, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f'''{X_train.shape} & {y_train.shape}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(268, 8) & (268, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f'''{X_test.shape} & {y_test.shape}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the target and inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ygeun/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,\n",
       "           fit_intercept=True, max_iter=1000, n_iter_no_change=5, n_jobs=-1,\n",
       "           penalty=None, random_state=444, shuffle=True, tol=0.001,\n",
       "           validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test first\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "clf = Perceptron(tol=1e-3, random_state=444, n_jobs=-1)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7686567164179104"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ok well, this technically worked..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MANUALLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = d_norm.values\n",
    "y = np.array(diabetes.Outcome).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "length: 8\n",
      "nums  : \n",
      "[0.3529411764705882, 0.7437185929648241, 0.5901639344262295, 0.3535353535353536, 0.0, 0.5007451564828614, 0.23441502988898377, 0.4833333333333334]\n",
      "\n",
      "[0.35294118 0.74371859 0.59016393 0.35353535 0.         0.50074516\n",
      " 0.23441503 0.48333333]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "# NOT MY FUNCTION \n",
    "def perceptron_sgd_plot(X, Y):\n",
    "    '''\n",
    "    train perceptron and plot the total loss in each epoch.\n",
    "    \n",
    "    :param X: data samples\n",
    "    :param Y: data labels\n",
    "    :return: weight vector as a numpy array\n",
    "    '''\n",
    "    w = np.zeros(len(X[0]))\n",
    "    eta = 1\n",
    "    n = 30\n",
    "    errors = []\n",
    "\n",
    "    for t in range(n):\n",
    "        total_error = 0\n",
    "        for i, x in enumerate(X):\n",
    "            if (np.dot(X[i], w)*Y[i]) <= 0:\n",
    "                total_error += (np.dot(X[i], w)*Y[i])\n",
    "                w = w + eta*X[i]*Y[i]\n",
    "        errors.append(total_error*-1)\n",
    "        \n",
    "    plt.plot(errors)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Total Loss')\n",
    "    \n",
    "    return w\n",
    "\n",
    "w = ptron(X,y)\n",
    "w_cool = [float(i) for i in w]\n",
    "print(f'''\n",
    "length: {len(w_cool)}\n",
    "nums  : \\n{w_cool}\n",
    "''')\n",
    "\n",
    "print(perceptron_sgd_plot(X,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying to understand teacher's function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Perceptron_teacher(object):\n",
    "  def __init__(self, rate = 0.01, niter = 10):\n",
    "    self.rate = rate\n",
    "    self.niter = niter\n",
    "\n",
    "  def fit(self, X, y):\n",
    "    \"\"\"Fit training data\n",
    "    X : Training vectors, X.shape : [#samples, #features]\n",
    "    y : Target values, y.shape : [#samples]\n",
    "    \"\"\"\n",
    "\n",
    "    # weights\n",
    "    self.weight = np.zeros(1 + X.shape[1])\n",
    "\n",
    "    # Number of misclassifications\n",
    "    self.errors = []  # Number of misclassifications\n",
    "\n",
    "    for i in range(self.niter):\n",
    "      err = 0\n",
    "      for xi, target in zip(X, y):\n",
    "        delta_w = self.rate * (target - self.predict(xi))\n",
    "        self.weight[1:] += delta_w * xi\n",
    "        self.weight[0] += delta_w\n",
    "        err += int(delta_w != 0.0)\n",
    "      self.errors.append(err)\n",
    "    return self\n",
    "\n",
    "  def net_input(self, X):\n",
    "    \"\"\"Calculate net input\"\"\"\n",
    "    return np.dot(X, self.weight[1:]) + self.weight[0]\n",
    "\n",
    "  def predict(self, X):\n",
    "    \"\"\"Return class label after unit step\"\"\"\n",
    "    return np.where(self.net_input(X) >= 0.0, 1, -1)\n",
    "\n",
    "pn = Perceptron_teacher(.01)\n",
    "pn.fit(X, y)\n",
    "plt.plot(range(1, len(pn.errors) + 1), pn.errors, marker='o')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Number of misclassifications')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This graph looks sooo good, like I maybe got something right but I doubt it cause the misclassification rate is legit most of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hand-made stuff...that kinda isn't working out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.743719</td>\n",
       "      <td>0.590164</td>\n",
       "      <td>0.353535</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500745</td>\n",
       "      <td>0.234415</td>\n",
       "      <td>0.483333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.427136</td>\n",
       "      <td>0.540984</td>\n",
       "      <td>0.292929</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.396423</td>\n",
       "      <td>0.116567</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.919598</td>\n",
       "      <td>0.524590</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.347243</td>\n",
       "      <td>0.253629</td>\n",
       "      <td>0.183333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.447236</td>\n",
       "      <td>0.540984</td>\n",
       "      <td>0.232323</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.418778</td>\n",
       "      <td>0.038002</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.688442</td>\n",
       "      <td>0.327869</td>\n",
       "      <td>0.353535</td>\n",
       "      <td>0.198582</td>\n",
       "      <td>0.642325</td>\n",
       "      <td>0.943638</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>763</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.507538</td>\n",
       "      <td>0.622951</td>\n",
       "      <td>0.484848</td>\n",
       "      <td>0.212766</td>\n",
       "      <td>0.490313</td>\n",
       "      <td>0.039710</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>764</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.613065</td>\n",
       "      <td>0.573770</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.548435</td>\n",
       "      <td>0.111870</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>765</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.608040</td>\n",
       "      <td>0.590164</td>\n",
       "      <td>0.232323</td>\n",
       "      <td>0.132388</td>\n",
       "      <td>0.390462</td>\n",
       "      <td>0.071307</td>\n",
       "      <td>0.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>766</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.633166</td>\n",
       "      <td>0.491803</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.448584</td>\n",
       "      <td>0.115713</td>\n",
       "      <td>0.433333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>767</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.467337</td>\n",
       "      <td>0.573770</td>\n",
       "      <td>0.313131</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.453055</td>\n",
       "      <td>0.101196</td>\n",
       "      <td>0.033333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    0.352941  0.743719  0.590164  0.353535  0.000000  0.500745  0.234415   \n",
       "1    0.058824  0.427136  0.540984  0.292929  0.000000  0.396423  0.116567   \n",
       "2    0.470588  0.919598  0.524590  0.000000  0.000000  0.347243  0.253629   \n",
       "3    0.058824  0.447236  0.540984  0.232323  0.111111  0.418778  0.038002   \n",
       "4    0.000000  0.688442  0.327869  0.353535  0.198582  0.642325  0.943638   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "763  0.588235  0.507538  0.622951  0.484848  0.212766  0.490313  0.039710   \n",
       "764  0.117647  0.613065  0.573770  0.272727  0.000000  0.548435  0.111870   \n",
       "765  0.294118  0.608040  0.590164  0.232323  0.132388  0.390462  0.071307   \n",
       "766  0.058824  0.633166  0.491803  0.000000  0.000000  0.448584  0.115713   \n",
       "767  0.058824  0.467337  0.573770  0.313131  0.000000  0.453055  0.101196   \n",
       "\n",
       "            7  \n",
       "0    0.483333  \n",
       "1    0.166667  \n",
       "2    0.183333  \n",
       "3    0.000000  \n",
       "4    0.200000  \n",
       "..        ...  \n",
       "763  0.700000  \n",
       "764  0.100000  \n",
       "765  0.150000  \n",
       "766  0.433333  \n",
       "767  0.033333  \n",
       "\n",
       "[768 rows x 8 columns]"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((768, 8), (768, 1))"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-W0tiX1F1hh2"
   },
   "outputs": [],
   "source": [
    "##### Update this Class #####\n",
    "\n",
    "class Perceptron(object):\n",
    "    \n",
    "    def __init__(self, niter = 10):\n",
    "        # What's niter? The material?\n",
    "        self.niter = niter\n",
    "    \n",
    "    def __sigmoid(self, x):\n",
    "        \"\"\"\n",
    "        Does something...\n",
    "        \"\"\"\n",
    "        return 1/(1+np.exp(-x))\n",
    "        \n",
    "    def __sigmoid_derivative(self, x):\n",
    "        \"\"\"\n",
    "        Takes the sigmoid and times it by\n",
    "        1 minus itself.\n",
    "        \"\"\"\n",
    "        sx = sigmoid(x)\n",
    "        return sx*(1-sx)\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit training data\n",
    "        X : Training vectors, X.shape : [#samples, #features]\n",
    "        y : Target values, y.shape : [#samples]\n",
    "        \"\"\"\n",
    "        # Unsure if I just copy-paste from JC's notebook...but idk that seems\n",
    "        # like it isn't working either. \n",
    "\n",
    "    # Randomly Initialize Weights\n",
    "    self.weight = 2 * np.random.random((8,1)) - 1\n",
    "\n",
    "    for i in range(self.niter):\n",
    "        # weighted sum of inputs / weights\n",
    "        wgt_sum = np.dot(X, self.weight)\n",
    "        # activate\n",
    "        act_out = sigmoid(wgt_sum)\n",
    "        # calc error\n",
    "        err = y - act_out\n",
    "        # adjust\n",
    "        adj = err * sigmoid_d(act_out)\n",
    "        # update the Weights\n",
    "        self.weight += np.dot(X.T, adj)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Return class label after unit step\"\"\"\n",
    "        return np.where(self.net_input(X) >= 0.0, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "pn = Perceptron()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "pn.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (768,8) and (7,1) not aligned: 8 (dim 1) != 7 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-253-dfc06b7c3eb4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-175-351b27a4a5f3>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;34m\"\"\"Return class label after unit step\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-175-351b27a4a5f3>\u001b[0m in \u001b[0;36mnet_input\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnet_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;34m\"\"\"Calculate net input\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (768,8) and (7,1) not aligned: 8 (dim 1) != 7 (dim 0)"
     ]
    }
   ],
   "source": [
    "pn.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6QR4oAW1xdyu"
   },
   "source": [
    "## Stretch Goals:\n",
    "\n",
    "- Research \"backpropagation\" to learn how weights get updated in neural networks (tomorrow's lecture). \n",
    "- Implement a multi-layer perceptron. (for non-linearly separable classes)\n",
    "- Try and implement your own backpropagation algorithm.\n",
    "- What are the pros and cons of the different activation functions? How should you decide between them for the different layers of a neural network?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good [article](https://towardsdatascience.com/coding-neural-network-forward-propagation-and-backpropagtion-ccf8cf369f76) about coding it...but it's quite long and it's 5pm lmao."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Updating weights through gradient descent. Throwing the results back at all the weights in the hidden and input nodes, they change slightly and the NN runs again. Then each time it reruns you can make it do backpropagation again and again, correcting ever-so-slightly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pros and Cons of activation functions\n",
    "From [this](https://datascience.stackexchange.com/questions/14349/difference-of-activation-functions-in-neural-networks-in-general) stack overflow answer it seems like Sigmoid activation functions are a little out-of-use because of the fact that they kill gradients. So what that means is that if the local gradient is really small, when backpropagating, the sigmoid will just axe the gradient and nothing will get through the node. This makes the neurons oversaturated and then the NN won't learn nothin'.\n",
    "\n",
    "Tanh seems to be generally preferred over sigmoid cause it's centered at zero (?) because it's just a scaled sigmoid neuron(?)!\n",
    "\n",
    "ReLU is popular cause it seems to accelerate stochastic gradient descent(?) compared to the above two, and doesn't have expensive exponent based ops. ReLU can die though and will never rise above zero again, effectively killing itself if the learning rate is too too high."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sigmoid seems to suck and people seem to want to only use ReLU non-linearity and sometimes Leaky ReLU or Maxout or whatever."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deciding between them for diff layers of NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not really sure. It seems like just no one uses Sigmoid or Tanh, just ReLU."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_431_Intro_to_NN_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
