{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dVfaLrjLvxvQ"
   },
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "# Neural Networks\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2 Assignment 1*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wxtoY12mwmih"
   },
   "source": [
    "## Define the Following:\n",
    "You can add image, diagrams, whatever you need to ensure that you understand the concepts below.\n",
    "\n",
    "## Input Layer:\n",
    "### Input layer is the most basic layer of a neural network that receives the external data.\n",
    "\n",
    "## Hidden Layer:\n",
    "### Hidden layer are the \"inbetweeners\" of input and output, they generally do not interact directly with the data. It takes a set of inputs and gives an output.\n",
    "\n",
    "## Output Layer:\n",
    "### The output layer is what the network returns in (presumably) a way to understand and interpret data in a form that attempts to solve the problem we are asking.\n",
    "\n",
    "## Neuron:\n",
    "### The most basic form of a gate in a neural network. It is synoymous with node. The behavior is similar to a neuron in the brain in that it \"fires\" after achieving a certain activation point.\n",
    "\n",
    "## Weight:\n",
    "### Weight is the modifier of a given node. In it's most basic form, it's a coeffecient attached to a linear variable that modifies the original value by a static one.\n",
    "\n",
    "\n",
    "## Activation Function:\n",
    "### Each node has an activation function, that basically turns every neuron into a binary choice: on or off. A good way to determine this is called a sigmoid function. There are many other different types of activation functions. I think of it as the closest approximation to a \"yes or no\" answer to a question, even if it involves a lot of nuance.\n",
    "\n",
    "\n",
    "## Node Map:\n",
    "### A visual diagram of the topology of the NN. A flow chart that shows the path a neuron can take between input and output. They can be simple (perceptron) or very very complex (DCIGN). \n",
    "\n",
    "\n",
    "## Perceptron:\n",
    "### The most basic form of a neural network. Usually mapped as input to output, with very few or no hidden layers.\n",
    "\n",
    "## Inputs -> Outputs\n",
    "### The path a piece of data takes inside of a neural network. It goes from the raw form, to the form the network attempts to turn it into in order to solve a given problem.\n",
    "\n",
    "## Explain the flow of information through a neural network from inputs to outputs. Be sure to include: inputs, weights, bias, and activation functions. How does it all flow from beginning to end?\n",
    "### Data is taken in from the inputs, a weight and a bias are possibly applied. In many networks they are then processed through an activation function, and then the data is reinterpeted using this data. Even using random sampling, basic neural networks seem to achieve interesting complexity and accuracy once this process is completed enough times, and then an output is given after x iterations of this, called an \"epoch\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6sWR43PTwhSk"
   },
   "source": [
    "## Write your own perceptron code that can correctly classify (99.0% accuracy) a NAND gate. \n",
    "\n",
    "| x1 | x2 | y |\n",
    "|----|----|---|\n",
    "| 0  | 0  | 1 |\n",
    "| 1  | 0  | 1 |\n",
    "| 0  | 1  | 1 |\n",
    "| 1  | 1  | 0 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = { 'x1': [0,1,0,1],\n",
    "         'x2': [0,0,1,1],\n",
    "         'y':  [1,1,1,0]\n",
    "       }\n",
    "\n",
    "df = pd.DataFrame.from_dict(data).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sgh7VFGwnXGH"
   },
   "outputs": [],
   "source": [
    "##### Your Code Here #####\n",
    "import numpy as np\n",
    "\n",
    "def nand(x1, x2):\n",
    "    weights = [-1, -1]\n",
    "    weighted_sum = np.dot([x1, x2], weights) +1\n",
    "    if (weighted_sum < 0):\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nand ff: 1\n",
      "nand tf: 1\n",
      "nand ft: 1\n",
      "nand tt: 0\n"
     ]
    }
   ],
   "source": [
    "print('nand ff:', nand(0,0))\n",
    "print('nand tf:', nand(1,0))\n",
    "print('nand ft:', nand(0,1))\n",
    "print('nand tt:', nand(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron(object):\n",
    "    \n",
    "    def __init__(self, learning_rate, epochs=100):\n",
    "        self.lr = learning_rate\n",
    "        self.epochs = epochs\n",
    "        \n",
    "    def predict(self, row):\n",
    "        # calculates weighted sum and returns activation value\n",
    "        return(np.dot(row, self.weight[1:]) + self.weight[0]) >= 0\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # Initialize weights\n",
    "        self.weight = np.array([np.random.random() for _ in range(X.shape[1] +1)])\n",
    "        \n",
    "        self.errors_ = []\n",
    "        \n",
    "        for _ in range(self.epochs):\n",
    "            error = 0\n",
    "            for row, label in zip(X, y):\n",
    "                \n",
    "                # Check current prediction against label to get error.\n",
    "                # Multiply the result by learning rate\n",
    "                \n",
    "                adjustment = self.lr * (label - self.predict(row))\n",
    "                \n",
    "                # Adjust weight and bias\n",
    "                self.weight[1:] += adjustment * row\n",
    "                self.weight[0] += adjustment\n",
    "                \n",
    "                # Add up errors for each epoch\n",
    "                error += adjustment != 0.0\n",
    "                \n",
    "            # Make list of errors per epoch\n",
    "            self.errors_.append(error)\n",
    "            \n",
    "        return self "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([np.array([0, 0]),\n",
    "                 np.array([0, 1]),\n",
    "                 np.array([1, 0]),\n",
    "                 np.array([1, 1])\n",
    "                ])\n",
    "y = np.array([1, 1, 1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<zip at 0x7f730694a690>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "gate = Perceptron()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Perceptron at 0x7f7306945450>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gate.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, False])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gate.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xf7sdqVs0s4x"
   },
   "source": [
    "## Implement your own Perceptron Class and use it to classify a binary dataset: \n",
    "- [The Pima Indians Diabetes dataset](https://raw.githubusercontent.com/ryanleeallred/datasets/master/diabetes.csv) \n",
    "\n",
    "You may need to search for other's implementations in order to get inspiration for your own. There are *lots* of perceptron implementations on the internet with varying levels of sophistication and complexity. Whatever your approach, make sure you understand **every** line of your implementation and what its purpose is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes = pd.read_csv('https://raw.githubusercontent.com/ryanleeallred/datasets/master/diabetes.csv')\n",
    "diabetes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although neural networks can handle non-normalized data, scaling or normalizing your data will improve your neural network's learning speed. Try to apply the sklearn `MinMaxScaler` or `Normalizer` to your diabetes dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.35294118, 0.74371859, 0.59016393, ..., 0.23441503, 0.48333333,\n",
       "        1.        ],\n",
       "       [0.05882353, 0.42713568, 0.54098361, ..., 0.11656704, 0.16666667,\n",
       "        0.        ],\n",
       "       [0.47058824, 0.91959799, 0.52459016, ..., 0.25362938, 0.18333333,\n",
       "        1.        ],\n",
       "       ...,\n",
       "       [0.29411765, 0.6080402 , 0.59016393, ..., 0.07130658, 0.15      ,\n",
       "        0.        ],\n",
       "       [0.05882353, 0.63316583, 0.49180328, ..., 0.11571307, 0.43333333,\n",
       "        1.        ],\n",
       "       [0.05882353, 0.46733668, 0.57377049, ..., 0.10119556, 0.03333333,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, Normalizer\n",
    "\n",
    "feats = list(diabetes)[:-1]\n",
    "target = 'Outcome'\n",
    "\n",
    "# introduce bias into workflow\n",
    "diabetes['bias'] = np.ones(diabetes.shape[0])\n",
    "\n",
    "# convert pandas df into split np arrays\n",
    "X = diabetes[feats].to_numpy()\n",
    "y = diabetes[target].to_numpy()\n",
    "y = y * 2 - 1\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-W0tiX1F1hh2"
   },
   "outputs": [],
   "source": [
    "##### Update this Class #####\n",
    "\n",
    "class Perceptron:\n",
    "    \n",
    "    def __init__(self, rate = 0.1, niter = 10):\n",
    "        self.rate = rate\n",
    "        self.niter = niter\n",
    "    \n",
    "    def __sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def __sigmoid_derivative(self, x):\n",
    "        sx = sigmoid(x)\n",
    "        return sx * (1-sx)\n",
    "\n",
    "    def fit(self, X, y):    \n",
    "        # Randomly Initialize Weights\n",
    "        # assign weight of 0 for length of features + 1 (bias)\n",
    "        self.weight = np.zeros(1 + X.shape[1])\n",
    "        \n",
    "        \n",
    "        # initialize erros\n",
    "        self.errors = []\n",
    "\n",
    "        for i in range(self.niter):\n",
    "            # Weighted sum of inputs / weights\n",
    "            err = 0\n",
    "            for xi, target in zip(X,y):\n",
    "                # for loop that breaks out for each predict\n",
    "                \n",
    "                # the delta for each pass\n",
    "                delta_w = self.rate * (target - self.predict(xi))\n",
    "                # Weighted sum of inputs /weights\n",
    "                self.weight[1:] += delta_w * xi\n",
    "                self.weight[0] += delta_w\n",
    "                err += int(delta_w != 0.0)\n",
    "            self.errors.append(err)\n",
    "        return self\n",
    "    \n",
    "    def weighted_sum(self, X):\n",
    "        # calc weighted sum of neuron\n",
    "        return np.dot(X, self.weight[1:]) + self.weight[0]\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # return what the class is, 0 or 1\n",
    "        return np.where(self.weighted_sum(X) >= 0.0, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEGCAYAAABvtY4XAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAde0lEQVR4nO3dfZRcdZ3n8fenO52k0115IOlUQ0JIgFSNz+JkfGJHBWfEEVeRWVfd0eM6zrI7x6OMelDwzA561JVZ1gfYcfeYFRSPIOMgRmVZhfEBzoyKJAZEHjpBCEIgT0BI57nT/d0/6jbphHT3TXfdulW3Pq9z6lTV7aq6nxTk2ze/+72/nyICMzMrno68A5iZWTZc4M3MCsoF3sysoFzgzcwKygXezKygZuQdYKxFixbF8uXL845hZtYy1q1btyMi+o71s6Yq8MuXL2ft2rV5xzAzaxmSHhnvZx6iMTMrKBd4M7OCcoE3MysoF3gzs4JygTczK6hMu2gkbQIGgWHgUESsqvc+1qzfzOU/GuDxnfs4aX43F51T5bwzltR7N2ZmLacRbZJnRcSOLD54zfrNXHLjPewbGgZg8859XHLjPQAu8mbW9lp6iObyHw08W9xH7Rsa5vIfDeSUyMyseWRd4AO4RdI6SRcc6wWSLpC0VtLa7du3H9eHP75z33FtNzNrJ1kX+DMj4mXAnwEfkPSao18QEasjYlVErOrrO+bVtuM6aX73cW03M2snmRb4iHg8ud8GfBd4eT0//6JzqnR3dR6xrburk4vOqdZzN2ZmLSmzAi+pR1Jp9DHwBuC39dzHeWcs4XPnv4h53V0A9M+dxefOf5FPsJqZkW0XTRn4rqTR/VwXET+s907OO2MJJ86bzTtW/5LL/vzFvK66uN67MDNrSZkV+Ih4CHhJVp8/VqVcAmDD1kEXeDOzREu3SY5a0DOTvtIsNmzdnXcUM7OmUYgCD1Atl9iwdTDvGGZmTaMwBb6SFPiRkcg7iplZUyhMga/297J/aIRHn96bdxQzs6ZQmAI/eqJ1YIuHaczMoEAFfmVS4Ddu84lWMzMoUIHvnTWDJfO7fQRvZpYoTIEHqPa7k8bMbFShCnylXOJ323czNDySdxQzs9wVqsBX+3sZGg427diTdxQzs9wVqsCvXDw6ZYFPtJqZFarAn764lw7BgMfhzcyKVeBnd3WyfGEPG9xJY2ZWrAIPh6csMDNrdwUs8L1senIP+49ajNvMrN0Ur8D3lxgJ+N12n2g1s/ZWuAJfHbP4h5lZOytcgV++qIeuTjGwxUfwZtbeClfguzo7OK2v10fwZtb2ClfgoTazpCcdM7N2V8gCXy33snnnPnYfOJR3FDOz3BSywI8u/rHRwzRm1sYKWeCr/e6kMTObtMBLOk3SrOTx6yR9SNL87KNN3ckL5jC7q8OdNGbW1tIcwX8HGJZ0OnAVsAK4LtNU09TRIVYu9pQFZtbe0hT4kYg4BLwN+FJEfBg4MdtY0+c5acys3aUp8EOS3gW8F7gp2daVXaT6qPb3sm3wAE/vOZh3FDOzXKQp8O8DXgV8NiIelrQC+Ga2saav4ikLzKzNTVrgI+K+iPhQRHwref5wRFyWfbTpcSeNmbW7GZO9QNKZwCeBU5LXC4iIODXbaNPTP3c2pVkzvHyfmbWtSQs8tc6ZDwPrgJaZZF0Slf6Sl+8zs7aVZgz+mYj4fxGxLSKeHL2l3YGkTknrJd00+avra7STJiIavWszs9ylKfA/lXS5pFdJetno7Tj2cSFw/xTzTUu13MvOvUNsHzyQx+7NzHKVZojmFcn9qjHbAjh7sjdKWgqcC3wW+Mhxp5umSnKidWDrIIvnzm707s3McjVpgY+Is6bx+V8CPgaUxnuBpAuACwCWLVs2jV091+FWyd388cq+un62mVmzSzMXzTxJX5C0Nrl9XtK8FO97M7AtItZN9LqIWB0RqyJiVV9ffYvwot5ZLOyZyQbPDW9mbSjNGPzVwCDw75PbLuBrKd53JvAWSZuA64GzJTX8AqlK2Z00Ztae0hT40yLi0oh4KLl9Cpi0Bz4iLomIpRGxHHgn8JOIePc08x63an+JjVsHGRlxJ42ZtZc0BX6fpH8z+iS58GlfdpHqq1IusefgMJt3tkxkM7O6SNNF89fANcm4u4CngP94PDuJiJ8BPzvObHVRKfcCsHHbICefMCePCGZmuUjTRXMX8BJJc5PnuzJPVUcrk06agS27OfsPyjmnMTNrnHELvKR3R8Q3JX3kqO0ARMQXMs5WF/O6uzhx3mxPOmZmbWeiI/ie5P5YPewtdcayUi4x4FZJM2sz4xb4iPhK8vCfI+Jfx/4sOdHaMqr9JX7x0JMMjwSdHco7jplZQ6TpovmfKbc1rZWLezl4aIRHntyTdxQzs4aZaAz+VcCrgb6jxuHnAp1ZB6unsYt/nNrXm3MaM7PGmOgIfibQS+2XQGnMbRfw77KPVj+nL+5FqnXSmJm1i4nG4G8DbpP09Yh4pIGZ6m7OzBksO2GOO2nMrK2kudBpr6TLgRcAz865GxGTThfcTDwnjZm1mzQnWa8FHgBWAJ8CNgF3ZpgpE5VyL5t27OHAoZZZddDMbFrSFPiFEXEVMBQRt0XEXwKvzDhX3VXKJQ6NBA/vcCeNmbWHNAV+KLl/QtK5ks4AlmaYKROjnTS+4MnM2kWaMfjPJBONfZRa//tc4MOZpsrAqYt6mdEhn2g1s7aRZrKxm5KHzwDTWb4vVzNndLBiUY9bJc2sbaRZsu8aSfPHPF8g6epsY2WjUi6xcZuP4M2sPaQZg39xROwcfRIRTwNnZBcpO5Vyid8/tZe9Bw/lHcXMLHNpCnyHpAWjTySdQLqx+6ZT7e8lAh7c5mEaMyu+NIX688DPJd2QPH878NnsImWnUj7cSfPipfMnebWZWWtLc5L1G5LWAmdTW7Lv/Ii4L/NkGThlYQ8zZ3S4k8bM2sJEs0nOjYhdyZDMFuC6MT87ISKeakTAeursEKf39bJhq4dozKz4JjqCvw54M7COI1dwUvL81AxzZabaX+KXDz2Zdwwzs8xNVOAvS+6fFxH7GxGmESrlEt9dv5ln9g0xr7sr7zhmZpmZqIvmiuT+540I0ijV/tqCHxs9Dm9mBTfREfyQpK8BSyVdefQPI+JD2cXKzmgnzYatu1m1/ISc05iZZWeiAv9m4E+odc+sa0yc7C2Z303PzE530phZ4U20otMO4HpJ90fE3Q3MlClJrCyXPKukmRXeRG2SH4uI/w78laQ4+uetOkQDUC2X+Of7t+Ydw8wsUxMN0dyf3K9tRJBGqvSX+Me1j7Jj9wEW9c7KO46ZWSYmGqL5QXJ/zeg2SR1Ab0TsakC2zFSfPdE66AJvZoWVZrrg6yTNldQD3AcMSLoo+2jZqZRrrZIbPA5vZgWWZjbJ5ydH7OcBNwPLgPdM9iZJsyX9StLdku6V9KlpZq2bvtIs5s/pYsBTFphZgaUp8F2SuqgV+O9FxBBHTl0wngPA2RHxEuClwBslNcVi3ZKolEtulTSzQktT4L8CbAJ6gNslnQJMOgYfNaOHyF3JLc0vhoaolkts2DJIRNNEMjOrq0kLfERcGRFLIuJNSdF+hJRrs0rqlHQXsA24NSLuOMZrLpC0VtLa7du3H/cfYKoq/SUGDxxiy67CTLNjZnaENCdZL0xOskrSVZJ+Te3q1klFxHBEvBRYCrxc0guP8ZrVEbEqIlb19fUd9x9gqiqLaydafcGTmRVVmiGav0xOsr4B6APex+GZJlNJ1nT9GfDG4w2YlcqYVkkzsyJKU+CV3L8J+FoybYEmeH3tTVKfpPnJ425q89o8MNWg9bagZyaLS7MY2OJOGjMrpjRrsq6TdAuwArhEUgkYSfG+E4FrJHVS+0Xy7Yi4aepR66/a704aMyuuNAX+/dTaHB+KiL2SFlIbpplQRPwGOGOa+TJVKZe49o5HGBkJOjom/UeJmVlLSbPo9oikh4GKpNkNyNQwlXIv+4dGePTpvZyysCfvOGZmdTVpgZf0V8CF1Dph7gJeCfyClJ00zWz0ROvAlkEXeDMrnDQnWS8E/gh4JCLOojbs0riG9QytdCeNmRVYmgK/f3TRbUmzIuIBoJptrMbonTWDpQu6PSeNmRVSmpOsjyXtjmuAWyU9DTyebazGqZZLXoDbzAopzUnWtyUPPynpp8A84IeZpmqgleUSt2/cztDwCF2daf5BY2bWGiZasu+EY2y+J7nvBZ7KJFGDVft7GRoONu3Y8+yYvJlZEUx0BL+O2uyPYxvER58HcGqGuRrm2U6arYMu8GZWKBMt2beikUHyclpfLx1KVnd6cd5pzMzqJ81skm+TNG/M8/mSzss2VuPM7upk+cIeNriTxswKJs1ZxUsj4pnRJ8nMkJdmF6nxvLqTmRVRmgJ/rNekaa9sGZX+Epue3MP+oeG8o5iZ1U2aAr9W0hcknSbpVElfpHYCtjCq5RIjAQ9u8zCNmRVHmgL/QeAg8I/APwH7gQ9kGarRqv211Z08TGNmRZLmQqc9wMVQW2MV6Em2FcYpC3vo6pRPtJpZoaTporkuWZO1B7gXGJB0UfbRGqers4PT+np9BG9mhZJmiOb5yZqs5wE3A8uA92SaKgeVcskLcJtZoaQp8F2SuqgV+O9FxBC1K1kLpdpfYvPOfew+cCjvKGZmdZGmwH8F2AT0ALdLOgXYlWWoPIxOWeCZJc2sKCYt8BFxZUQsiYg3Rc0jwFkNyNZQlbI7acysWCaaTfLdEfFNSR8Z5yVfyChTLk5eMIfZXR0MbHEnjZkVw0RtkqOLlLbFFIsdHfKUBWZWKBPNJvmV5P5TjYuTr0q5xG0bCrHcrJnZ5Bc6SVpB7WrW5WNfHxFvyS5WPqrlEjese4yn9xxkQc/MvOOYmU1LmknD1gBXAT8ARrKNk6+VY060vuLUhTmnMTObnjQFfn9EXJl5kiZQ7a+dbnCBN7MiSFPgr5B0KXALcGB0Y0T8OrNUOemfO5vS7BkM+ESrmRVAmgL/ImpTE5zN4SGaSJ4XiiSq5RIb3CppZgWQpsC/DTg1Ig5mHaYZVPpL3HzPE0QEkiZ/g5lZk0ozVcHdwPysgzSLyuJedu4dYvvggclfbGbWxNIcwZeBByTdyZFj8IVrk4TaETzAwNZBFs+dnXMaM7OpS1Pgp7TAtqSTgW8A/dTG7ldHxBVT+axGqiaTjg1sGeSPV/blnMbMbOrSrOh02xQ/+xDw0Yj4taQSsE7SrRFx3xQ/ryEW9s5iUe9MT1lgZi0vzRj8lETEE6OtlBExCNwPLMlqf/VUm5PGnTRm1toyK/BjSVoOnAHccYyfXSBpraS127c3xzwwlXKJjVsHGRkp3LomZtZGxi3wkn6c3P/9dHYgqRf4DvA3ydJ/R4iI1RGxKiJW9fU1x5h3pVxiz8FhNu/cl3cUM7Mpm2gM/kRJrwXeIul64Iim8DRXsiZL/X0HuDYibpxW0gaq9h+ek+bkE+bknMbMbGomKvB/B1wMLOW5i3tMeiWralcJXQXcHxEttTjIyvLhVsnXP6+ccxozs6mZaD74G4AbJP3XiPj0FD77TGpTHNwj6a5k2yci4uYpfFZDzZ3dxUnzZrPRJ1rNrIWlaZP8tKS3AK9JNv0sIm5K8b5/4ahhnVayslxiYItbJc2sdU3aRSPpc8CFwH3J7cJkW6FV+0s8uH03h4YLPQW+mRVYmitZzwVeGhEjAJKuAdYDl2QZLG+VcomDh0Z45Km9nNbXm3ccM7PjlrYPfuxkY/OyCNJsRqcs2OBhGjNrUWkK/OeA9ZK+nhy9rwP+W7ax8nf64l4kfEWrmbWsNCdZvyXpZ8AfUTtp+vGI2JJ1sLx1z+xk2QlzPCeNmbWsNGPwRMQTwPczztJ0KuWSl+8zs5bVkLloWlW1XOLhHXs4cGg47yhmZsfNBX4Clf4SwyPBQ9v35B3FzOy4TVjgJXVI+m2jwjSbZztpPExjZi1owgKf9L7fLWlZg/I0lRWLepjRIRd4M2tJaU6yngjcK+lXwLNjFUVdk3WsmTM6WLGoh4EtbpU0s9aTpsB/KvMUTazSX+Kex57JO4aZ2XGb9CRrsibrJqAreXwnMOlc8EVRLZd49Om97D14KO8oZmbHJc1kY/8JuAH4SrJpCbAmy1DNpFIuEQEPbvMwjZm1ljRtkh+gNrf7LoCI2AgszjJUM6mUaxONeepgM2s1aQr8gYg4OPpE0gxqKzq1hVMW9jBzRoc7acys5aQp8LdJ+gTQLelPgX8CfpBtrObR2SFWLu5lwJOOmVmLSVPgLwa2A/cA/xm4GfjbLEM1m2q5xEYfwZtZi0kzm+RIMk3wHdSGZgYiom2GaKDWKnnj+s08s2+Ied1deccxM0slTRfNucDvgCuBfwAelPRnWQdrJqMnWn0Ub2atJM0QzeeBsyLidRHxWuAs4IvZxmoulWROGk8dbGatJE2B3xYRD455/hCwLaM8TWnJ/G56ZnZ6+T4zaynjjsFLOj95eK+km4FvUxuDfzu1q1nbhiQq/SUv32dmLWWik6z/dszjrcBrk8fbgQWZJWpS1XKJW+/bmncMM7PUxi3wEfG+RgZpdivLJa6/81F27D7Aot5ZeccxM5vUpG2SklYAHwSWj319O0wXPNazi39sGWTR6S7wZtb80kwXvAa4itrVqyPZxmlelf5kTpqtg7z69EU5pzEzm1yaAr8/Iq7MPEmT6+udxYI5XT7RamYtI02Bv0LSpcAtwIHRjRHRNnPCQ9JJUy550jEzaxlpCvyLgPcAZ3N4iCaS522lUi6xZv1mIgJJeccxM5tQmgL/NuDUsVMGpyHpauDN1C6UeuFUwjWbSn+JwQOHeOKZ/Zw0vzvvOGZmE0pzJevdwPwpfPbXgTdO4X1Nq+opC8yshaQ5gi8DD0i6kyPH4Cdsk4yI2yUtn1a6JjN20rGzqm2zqJWZtag0Bf7SLANIugC4AGDZsmVZ7mra5s+ZSXnuLAa2uJPGzJpfmvngb8syQESsBlYDrFq1qunnmXcnjZm1ijTzwQ9K2pXc9ksalrSrEeGaUaVcYuO2QYZHmv53kZm1uTRH8KWxzyWdB7w8s0RNrlousX9ohEef2svyRT15xzEzG1eaLpojRMQaUvTAS/oW8AugKukxSe+fQr6mU+lP5qTxMI2ZNbk0k42dP+ZpB7CK2oVOE4qId00jV9NaubjWSbNh6yBveEF/zmnMzMaXpotm7Lzwh4BNwFszSdMCembNYOmCbgY8J42ZNbk0Y/CeF/4o1XLJy/eZWdObaMm+v5vgfRERn84gT0uo9Je4feN2hoZH6Oo87tMYZmYNMVF12nOMG8D7gY9nnKupVcslhoaDTTv2TP5iM7OcTLRk3+dHH0sqARcC7wOuBz4/3vvawcry4cU/VpZLk7zazCwfE44vSDpB0meA31D7ZfCyiPh4RGxrSLomdVpfLx3C4/Bm1tQmGoO/HDif2jQCL4oIt40kZnd1snxRj2eVNLOmNtER/EeBk4C/BR4fM13BYDtPVTCqWi6x0a2SZtbEJhqDd3vIBCrlEj+6dwv7h4aZ3dWZdxwzs+dwEZ+iSrnESMCD23wUb2bNyQV+iqr9h6csMDNrRi7wU3TKwh5mdnb4RKuZNS0X+Cnq6uzg1L4en2g1s6blAj8N1f4SA+6FN7Mm5QI/DZVyic079zG4fyjvKGZmz+ECPw2VZJqCje6kMbMm5AI/DdWkwHvKAjNrRi7w07B0QTfdXZ1s8IlWM2tCLvDT0NEhKuVe98KbWVNygZ+mleWSe+HNrCm5wE9TtVxi++ABntpzMO8oZmZHcIGfpkp/cqLVR/Fm1mRc4KdptJNmowu8mTUZF/hpKs+dxdzZMzwOb2ZNxwV+miRRKZfYsMWtkmbWXFzg66DSX+ukiYi8o5iZPcsFvg6q5RLP7Bti2+CBvKOYmT3LBb4ORuekcSeNmTUTF/g6qJRrqzt56mAzayYu8HWwsHcWi3pn+gjezJqKC3ydVMolBjzpmJk1kRlZfrikNwJXAJ3AVyPisiz3l6fODvGbR3ey4uL/y0nzu7nonCrnnbGkoRnWrN/M5T8a4PGd+3LL4BzO0Qo5miFDI3JkVuAldQJfBv4UeAy4U9L3I+K+rPaZlzXrN/PLh55ktEly8859XHLjPQAN+59mzfrNXHLjPewbGs4tg3M4RyvkaIYMjcqhrHq3Jb0K+GREnJM8vwQgIj433ntWrVoVa9euzSRPls687Cds3rnvOdtndIgVi3oakuHhHXs4NPLc/5aNzOAcztEKOZohw0Q5lszv5l8vPjv150haFxGrjvWzLIdolgCPjnn+GPCKo18k6QLgAoBly5ZlGCc7jx+juAMcGglWJh02WRtv2cBGZnAO52iFHM2QYaIc49WTqciywOsY257z6yoiVgOroXYEn2GezJw0v/uYR/BL5nfzv/7iDxuSYbx/RTQyg3M4RyvkaIYME+U4aX533faRZRfNY8DJY54vBR7PcH+5ueicKt1dnUds6+7q5KJzqm2VwTmcoxVyNEOGRuXI8gj+TmClpBXAZuCdwH/IcH+5GT0hkudZ+WbI4BzO0Qo5miFDo3JkdpIVQNKbgC9Ra5O8OiI+O9HrW/Ukq5lZXvI6yUpE3AzcnOU+zMzs2Hwlq5lZQbnAm5kVlAu8mVlBucCbmRVUpl00x0vSduCRvHNM0yJgR94hmoS/iyP5+ziSv4/DpvNdnBIRfcf6QVMV+CKQtHa8lqV24+/iSP4+juTv47CsvgsP0ZiZFZQLvJlZQbnA19/qvAM0EX8XR/L3cSR/H4dl8l14DN7MrKB8BG9mVlAu8GZmBeUCXweSTpb0U0n3S7pX0oV5Z2oGkjolrZd0U95Z8iRpvqQbJD2Q/D/yqrwz5UnSh5O/J7+V9C1Js/PO1EiSrpa0TdJvx2w7QdKtkjYm9wvqsS8X+Po4BHw0Ip4HvBL4gKTn55ypGVwI3J93iCZwBfDDiPgD4CW08XciaQnwIWBVRLyQ2lTi78w3VcN9HXjjUdsuBn4cESuBHyfPp80Fvg4i4omI+HXyeJDaX+DGrh7QZCQtBc4Fvpp3ljxJmgu8BrgKICIORsTOfFPlbgbQLWkGMIeCrvQ2noi4HXjqqM1vBa5JHl8DnFePfbnA15mk5cAZwB35Jsndl4CPASN5B8nZqcB24GvJcNVXJfXkHSovEbEZ+B/A74EngGci4pZ8UzWFckQ8AbUDRmBxPT7UBb6OJPUC3wH+JiJ25Z0nL5LeDGyLiHV5Z2kCM4CXAf87Is4A9lCnf363omRs+a3ACuAkoEfSu/NNVVwu8HUiqYtacb82Im7MO0/OzgTeImkTcD1wtqRv5hspN48Bj0XE6L/obqBW8NvVnwAPR8T2iBgCbgRenXOmZrBV0okAyf22enyoC3wdSBK1Mdb7I+ILeefJW0RcEhFLI2I5tRNoP4mItjxKi4gtwKOSqsmm1wP35Rgpb78HXilpTvL35vW08UnnMb4PvDd5/F7ge/X40EzXZG0jZwLvAe6RdFey7RPJmrRmHwSulTQTeAh4X855chMRd0i6Afg1te6z9bTZlAWSvgW8Dlgk6THgUuAy4NuS3k/tl+Db67IvT1VgZlZMHqIxMysoF3gzs4JygTczKygXeDOzgnKBNzMrKBd4KzxJw5LuGnOr25WkkpaPnRXQrJm4D97awb6IeGneIcwazUfw1rYkbZL095J+ldxOT7afIunHkn6T3C9LtpclfVfS3clt9BL7Tkn/J5nj/BZJ3cnrPyTpvuRzrs/pj2ltzAXe2kH3UUM07xjzs10R8XLgH6jNgEny+BsR8WLgWuDKZPuVwG0R8RJq88ncm2xfCXw5Il4A7AT+PNl+MXBG8jn/Jas/nNl4fCWrFZ6k3RHRe4ztm4CzI+KhZLK4LRGxUNIO4MSIGEq2PxERiyRtB5ZGxIExn7EcuDVZqAFJHwe6IuIzkn4I7AbWAGsiYnfGf1SzI/gI3tpdjPN4vNccy4Exj4c5fG7rXODLwB8C65IFLswaxgXe2t07xtz/Inn8cw4vI/cXwL8kj38M/DU8u97s3PE+VFIHcHJE/JTawifzgef8K8IsSz6isHbQPWaWT6itjzraKjlL0h3UDnbelWz7EHC1pIuorcY0OvvjhcDqZMa/YWrF/olx9tkJfFPSPEDAF71UnzWax+CtbSVj8KsiYkfeWcyy4CEaM7OC8hG8mVlB+QjezKygXODNzArKBd7MrKBc4M3MCsoF3sysoP4/458v+2vAq1AAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# initialize perceptron\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "nn = Perceptron()\n",
    "\n",
    "# fit diabetes data\n",
    "nn.fit(X_scaled,y)\n",
    "plt.plot(range(1, len(nn.errors) + 1), nn.errors, marker='o')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Number of misclassifications')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6QR4oAW1xdyu"
   },
   "source": [
    "## Stretch Goals:\n",
    "\n",
    "- Research \"backpropagation\" to learn how weights get updated in neural networks (tomorrow's lecture). \n",
    "- Implement a multi-layer perceptron. (for non-linearly separable classes)\n",
    "- Try and implement your own backpropagation algorithm.\n",
    "- What are the pros and cons of the different activation functions? How should you decide between them for the different layers of a neural network?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_431_Intro_to_NN_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
