{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LS_DS_431_Intro_to_NN_Assignment.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/derek-shing/DS-Unit-4-Sprint-3-Neural-Networks/blob/master/module1-Intro-to-Neural-Networks/LS_DS_431_Intro_to_NN_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVfaLrjLvxvQ",
        "colab_type": "text"
      },
      "source": [
        "# Intro to Neural Networks Assignment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxtoY12mwmih",
        "colab_type": "text"
      },
      "source": [
        "## Define the Following:\n",
        "You can add image, diagrams, whatever you need to ensure that you understand the concepts below.\n",
        "\n",
        "### Input Layer:\n",
        "### Hidden Layer:\n",
        "### Output Layer:\n",
        "### Neuron:\n",
        "### Weight:\n",
        "### Activation Function:\n",
        "### Node Map:\n",
        "### Perceptron:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXuy9WcWzxa4",
        "colab_type": "text"
      },
      "source": [
        "## Inputs -> Outputs\n",
        "\n",
        "### Explain the flow of information through a neural network from inputs to outputs. Be sure to include: inputs, weights, bias, and activation functions. How does it all flow from beginning to end?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PlSwIJMC0A8F",
        "colab_type": "text"
      },
      "source": [
        "#### Your Answer Here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sWR43PTwhSk",
        "colab_type": "text"
      },
      "source": [
        "## Write your own perceptron code that can correctly classify a NAND gate. \n",
        "\n",
        "| x1 | x2 | y |\n",
        "|----|----|---|\n",
        "| 0  | 0  | 1 |\n",
        "| 1  | 0  | 1 |\n",
        "| 0  | 1  | 1 |\n",
        "| 1  | 1  | 0 |"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sgh7VFGwnXGH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##### Your Code Here #####\n",
        "import numpy as np\n",
        "np.random.seed(1)\n",
        "\n",
        "\n",
        "\n",
        "inputs = np.array([\n",
        "    [0, 0, 1],\n",
        "    [1, 1, 1],\n",
        "    [1, 0, 1],\n",
        "    [0, 1, 1]\n",
        "])\n",
        "\n",
        "correct_outputs = [[1], [0], [1], [1]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lk-tZKiM4v3F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoid(x):\n",
        "  return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "  return sigmoid(x) * (1 - sigmoid(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7qIRBn45CUP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "b3da00cb-f029-424b-af4b-9186ba32b7ef"
      },
      "source": [
        "weights = 2 * np.random.random((3, 1)) - 1\n",
        "weights"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.16595599],\n",
              "       [ 0.44064899],\n",
              "       [-0.99977125]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-ompd1T5JwI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "7be8d897-27e9-4434-c762-b0a6877c64fe"
      },
      "source": [
        "weighted_sum = np.dot(inputs, weights)\n",
        "weighted_sum"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.99977125],\n",
              "       [-0.72507825],\n",
              "       [-1.16572724],\n",
              "       [-0.55912226]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e02B-_u25Ux3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "4ef6cfa4-228a-4b5d-977e-c3fa2ef68d84"
      },
      "source": [
        "activated_output = sigmoid(weighted_sum)\n",
        "activated_output"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.2689864 ],\n",
              "       [0.3262757 ],\n",
              "       [0.23762817],\n",
              "       [0.36375058]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ELJ3Tk15cob",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "85c430c8-6a3e-4f8f-ca05-5b7941c01eb5"
      },
      "source": [
        "error = correct_outputs - activated_output\n",
        "error"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.7310136 ],\n",
              "       [-0.3262757 ],\n",
              "       [ 0.76237183],\n",
              "       [ 0.63624942]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgLYqqhY5k7J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "cfd40eeb-0f39-4592-8aff-98022dbb5316"
      },
      "source": [
        "adjustments = error * sigmoid_derivative(activated_output)\n",
        "adjustments"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.17948714],\n",
              "       [-0.079436  ],\n",
              "       [ 0.18792752],\n",
              "       [ 0.15391469]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sS4VKyA-5prR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "030a70f1-128b-4008-fc99-a6ebd99e7fa2"
      },
      "source": [
        "weights += np.dot(inputs.T, adjustments)\n",
        "weights"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.05746447],\n",
              "       [ 0.51512768],\n",
              "       [-0.55787791]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Q43mb6D5raj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "4e0c397d-3df7-45dd-c187-7e7a36c9d103"
      },
      "source": [
        "for iteration in range(10000):\n",
        "  # Weighted sum of inputs/weights\n",
        "  weighted_sum = np.dot(inputs, weights)\n",
        "  \n",
        "  # Activate!\n",
        "  activated_output = sigmoid(weighted_sum)\n",
        "  \n",
        "  # Calculate error\n",
        "  error = correct_outputs - activated_output\n",
        "  \n",
        "  # Calculate weight adjustments - watch linked videos for more intuition!\n",
        "  adjustments = error * sigmoid(activated_output)\n",
        "  \n",
        "  # Update weights\n",
        "  weights += np.dot(inputs.T, adjustments)\n",
        "  \n",
        "print('Weights after training')\n",
        "print(weights)\n",
        "\n",
        "print('Output after training')\n",
        "print(activated_output)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Weights after training\n",
            "[[-13.85204949]\n",
            " [-13.85204949]\n",
            " [ 21.13616677]]\n",
            "Output after training\n",
            "[[1.        ]\n",
            " [0.00140287]\n",
            " [0.99931405]\n",
            " [0.99931405]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xf7sdqVs0s4x",
        "colab_type": "text"
      },
      "source": [
        "## Implement your own Perceptron Class and use it to classify a binary dataset like: \n",
        "- [The Pima Indians Diabetes dataset](https://raw.githubusercontent.com/ryanleeallred/datasets/master/diabetes.csv) \n",
        "- [Titanic](https://raw.githubusercontent.com/ryanleeallred/datasets/master/titanic.csv)\n",
        "- [A two-class version of the Iris dataset](https://raw.githubusercontent.com/ryanleeallred/datasets/master/Iris.csv)\n",
        "\n",
        "You may need to search for other's implementations in order to get inspiration for your own. There are *lots* of perceptron implementations on the internet with varying levels of sophistication and complexity. Whatever your approach, make sure you understand **every** line of your implementation and what its purpose is."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-W0tiX1F1hh2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##### Your Code Here #####"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QR4oAW1xdyu",
        "colab_type": "text"
      },
      "source": [
        "## Stretch Goals:\n",
        "\n",
        "- Research \"backpropagation\" to learn how weights get updated in neural networks (tomorrow's lecture). \n",
        "- Implement a multi-layer perceptron. (for non-linearly separable classes)\n",
        "- Try and implement your own backpropagation algorithm.\n",
        "- What are the pros and cons of the different activation functions? How should you decide between them for the different layers of a neural network?"
      ]
    }
  ]
}