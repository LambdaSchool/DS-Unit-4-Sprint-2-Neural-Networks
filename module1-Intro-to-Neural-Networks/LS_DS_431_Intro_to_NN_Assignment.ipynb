{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LS_DS_431_Intro_to_NN_Assignment.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/donw385/DS-Unit-4-Sprint-3-Neural-Networks/blob/master/module1-Intro-to-Neural-Networks/LS_DS_431_Intro_to_NN_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVfaLrjLvxvQ",
        "colab_type": "text"
      },
      "source": [
        "# Intro to Neural Networks Assignment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxtoY12mwmih",
        "colab_type": "text"
      },
      "source": [
        "## Define the Following:\n",
        "You can add image, diagrams, whatever you need to ensure that you understand the concepts below.\n",
        "\n",
        "### Input Layer: what receives input from our dataset\n",
        "### Hidden Layer: Layers after the input layer are called Hidden Layers. This is because they cannot be accessed except through the input layer.\n",
        "### Output Layer: The final layer is called the Output Layer. The purpose of the output layer is to output a vector of values that is in a format that is suitable for the type of problem that we're trying to address. \n",
        "### Neuron:  neurons or \"nodes\" are similar in that they receive inputs and pass on their signal to the next layer of nodes if a certain threshold is reached\n",
        "### Weight: differentiates importance of input values\n",
        "### Activation Function: In Artificial Neural Networks activation functions decide how much signal to pass onto the next layer. This is why they are sometimes referred to as transfer functions because they determine how much signal is transferred to the next layer.\n",
        "### Node Map: visual diagram of the architecture or \"topology\" of our neural network. It's kind of like a flow chart in that it shows the path from inputs to outputs. They are usually color coded and help us understand at a very high level, some of the differences in architecture between kinds of neural networks.\n",
        "### Perceptron: A perceptron is just a single node or neuron of a neural network with nothing else. It can take any number of inputs and spit out an output.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXuy9WcWzxa4",
        "colab_type": "text"
      },
      "source": [
        "## Inputs -> Outputs\n",
        "\n",
        "### Explain the flow of information through a neural network from inputs to outputs. Be sure to include: inputs, weights, bias, and activation functions. How does it all flow from beginning to end?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PlSwIJMC0A8F",
        "colab_type": "text"
      },
      "source": [
        "Neural networks are a class of machine learning algorithms used to model complex patterns in datasets using multiple hidden layers and non-linear activation functions. A neural network takes an input, passes it through multiple layers of hidden neurons (mini-functions with unique coefficients that must be learned), and outputs a prediction representing the combined input of all the neurons.\n",
        "\n",
        "Each neuron’s coefficients (weights) are then adjusted relative to how much they contributed to the total error. Bias terms are additional constants attached to neurons and added to the weighted input before the activation function is applied. This process is repeated iteratively until the network error drops below an acceptable threshold.\n",
        "\n",
        "Activation functions live inside neural network layers and modify the data they receive before passing it to the next layer. Activation functions give neural networks their power — allowing them to model complex non-linear relationships. By modifying inputs with non-linear functions neural networks can model highly complex relationships between features. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sWR43PTwhSk",
        "colab_type": "text"
      },
      "source": [
        "## Write your own perceptron code that can correctly classify a NAND gate. \n",
        "\n",
        "| x1 | x2 | y |\n",
        "|----|----|---|\n",
        "| 0  | 0  | 1 |\n",
        "| 1  | 0  | 1 |\n",
        "| 0  | 1  | 1 |\n",
        "| 1  | 1  | 0 |"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QuwbFFuBmn62",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sgh7VFGwnXGH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  class PerceptronClassifier():\n",
        "    \"\"\"\n",
        "    Basic perceptron class for binary classification\n",
        "    \"\"\"\n",
        "    def __init__(self, learning_rate=0.1, n_iter=100, tolerance=0.000001):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.n_iter = n_iter\n",
        "        self.tolerance = tolerance\n",
        "    \n",
        "    def fit(self, X, y):\n",
        "        \"\"\"\n",
        "        Fit perceptron to a set of training data using gradient descent\n",
        "        \"\"\"\n",
        "        # initialize weights and cost list\n",
        "        self.weights_ = np.random.uniform(-0.01, 0.01, X.shape[1] + 1)\n",
        "        self.costs_ = []\n",
        "        # iterate until fit is adequate\n",
        "        for i in range(self.n_iter):\n",
        "            preds = self.predict_proba(X)\n",
        "            errors = preds - y\n",
        "            cost = np.sum(errors ** 2)\n",
        "            self.costs_.append(cost)\n",
        "            gradient = np.dot(X.T, errors)\n",
        "            self.weights_[1:] -= self.learning_rate * gradient\n",
        "            self.weights_[0] -= np.mean(errors)\n",
        "            \n",
        "            # break the loop if we are close enough\n",
        "            if cost < self.tolerance:\n",
        "                break\n",
        "            \n",
        "        return self\n",
        "    \n",
        "    def predict_proba(self, X):\n",
        "        \"\"\"\n",
        "        Computes sigmoid output value given X\n",
        "        \"\"\"\n",
        "        return 1. / (1. + np.exp(-(np.dot(X, self.weights_[1:]) + self.weights_[0])))\n",
        "    \n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Predicts the binary class of X values\n",
        "        \"\"\"\n",
        "        return np.where(self.predict_proba(X)>=0.5, 1, 0)\n",
        "    \n",
        "    def show_loss(self):\n",
        "        \"\"\"\n",
        "        Shows loss along epochs\n",
        "        \"\"\"\n",
        "        try:\n",
        "            iters = range(len(self.costs_))\n",
        "            fig, ax = plt.subplots()\n",
        "            ax.plot(iters, self.costs_)\n",
        "            ax.set_xlabel('Number of Iterations')\n",
        "            ax.set_ylabel('Training Loss (SSE)')\n",
        "            ax.set_title('Training Loss')\n",
        "            plt.show()\n",
        "        except:\n",
        "            print ('Please train me first :)')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwBBAHDcm0h4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = np.array([[0,0],\n",
        "            [1,0],\n",
        "            [0,1],\n",
        "            [1,1]])\n",
        "y = np.array([1,1,1,0])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28IZzva8m1rr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "55b1dfea-7163-4388-8861-7d29e42eff50"
      },
      "source": [
        "X"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0, 1],\n",
              "       [1, 1, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 1, 1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ymcPK9vnJo4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "18313644-5748-405d-b800-adc76e8da891"
      },
      "source": [
        "ppn = PerceptronClassifier(learning_rate = 1.0, n_iter=100)\n",
        "ppn.fit(X, y)\n",
        "ppn.predict(X)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RacyjWDqnMB3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "335d5a9a-0015-43ec-838c-b63c0bfc4137"
      },
      "source": [
        "ppn.show_loss()\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xf7sdqVs0s4x",
        "colab_type": "text"
      },
      "source": [
        "## Implement your own Perceptron Class and use it to classify a binary dataset like: \n",
        "- [The Pima Indians Diabetes dataset](https://raw.githubusercontent.com/ryanleeallred/datasets/master/diabetes.csv) \n",
        "- [Titanic](https://raw.githubusercontent.com/ryanleeallred/datasets/master/titanic.csv)\n",
        "- [A two-class version of the Iris dataset](https://raw.githubusercontent.com/ryanleeallred/datasets/master/Iris.csv)\n",
        "\n",
        "You may need to search for other's implementations in order to get inspiration for your own. There are *lots* of perceptron implementations on the internet with varying levels of sophistication and complexity. Whatever your approach, make sure you understand **every** line of your implementation and what its purpose is."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-W0tiX1F1hh2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Perceptron(object):\n",
        "\n",
        "    def __init__(self, no_of_inputs, threshold=100, learning_rate=0.01):\n",
        "        self.threshold = threshold\n",
        "        self.learning_rate = learning_rate\n",
        "        self.weights = np.zeros(no_of_inputs + 1)\n",
        "           \n",
        "    def predict(self, inputs):\n",
        "        summation = np.dot(inputs, self.weights[1:]) + self.weights[0]\n",
        "        if summation > 0:\n",
        "            activation = 1\n",
        "        else:\n",
        "            activation = 0            \n",
        "        return activation\n",
        "\n",
        "    def train(self, training_inputs, labels):\n",
        "        for _ in range(self.threshold):\n",
        "            for inputs, label in zip(training_inputs, labels):\n",
        "                prediction = self.predict(inputs)\n",
        "                self.weights[1:] += self.learning_rate * (label - prediction) * inputs\n",
        "                self.weights[0] += self.learning_rate * (label - prediction)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyL-_DNKoPZy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "bdb449fb-74b0-4986-a6e6-200f959cb0c6"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "url = 'https://raw.githubusercontent.com/ryanleeallred/datasets/master/diabetes.csv'\n",
        "df = pd.read_csv(url)\n",
        "df.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
              "0            6      148             72             35        0  33.6   \n",
              "1            1       85             66             29        0  26.6   \n",
              "2            8      183             64              0        0  23.3   \n",
              "3            1       89             66             23       94  28.1   \n",
              "4            0      137             40             35      168  43.1   \n",
              "\n",
              "   DiabetesPedigreeFunction  Age  Outcome  \n",
              "0                     0.627   50        1  \n",
              "1                     0.351   31        0  \n",
              "2                     0.672   32        1  \n",
              "3                     0.167   21        0  \n",
              "4                     2.288   33        1  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHcto0W3o52U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_altered = df.drop(columns='Outcome')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bko95bXDoSmd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "X = df.drop(columns='Outcome').values\n",
        "y = df.Outcome.values\n",
        "no_of_inputs = df_altered.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRLZakAvpAxT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f94b0cda-92e8-4942-bba6-6474d17b53f7"
      },
      "source": [
        "df_altered.shape[1]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "458N7qjKou2g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "5fe126da-d91b-4867-8249-bac0a80dbf60"
      },
      "source": [
        "pn = Perceptron(no_of_inputs=no_of_inputs, threshold=10, learning_rate=0.01)\n",
        "pn.train(X, y)\n",
        "y_pred = [pn.predict(row) for row in X]\n",
        "print(f'weights: {pn.weights}')\n",
        "print(f'Accuracy: {accuracy_score(y, y_pred)}')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "weights: [-2.9      8.97     1.14    -2.85    -1.9      1.63     0.635    0.56346\n",
            " -1.2    ]\n",
            "Accuracy: 0.5885416666666666\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdX9IW49pE1a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "ccc11636-885d-488d-bcd7-7feb642e3a45"
      },
      "source": [
        "# Accuracy after 100 iterations\n",
        "pn = Perceptron(no_of_inputs=no_of_inputs, threshold=100, learning_rate=0.01)\n",
        "pn.train(X, y)\n",
        "y_pred = [pn.predict(row) for row in X]\n",
        "print(f'weights: {pn.weights}')\n",
        "print(f'Accuracy: {accuracy_score(y, y_pred)}')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "weights: [-28.28     15.3       0.97     -3.48     -2.74      1.59     -0.127\n",
            "   6.89463  -2.25   ]\n",
            "Accuracy: 0.6536458333333334\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RU-fTAz_pHV2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "d281f625-6463-40f6-e644-afd394712612"
      },
      "source": [
        "# Accuracy after 1000 iterations\n",
        "pn = Perceptron(no_of_inputs=no_of_inputs, threshold=1000, learning_rate=0.01)\n",
        "pn.train(X, y)\n",
        "y_pred = [pn.predict(row) for row in X]\n",
        "print(f'weights: {pn.weights}')\n",
        "print(f'Accuracy: {accuracy_score(y, y_pred)}')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "weights: [-237.44      13.58       2.61      -3.4       -2.16       2.52\n",
            "    2.666     46.19301   -1.95   ]\n",
            "Accuracy: 0.6171875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-J0eDi-pMAC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "d493608c-8225-4243-da1a-baf0e3799d87"
      },
      "source": [
        "# Accuracy after 10000 iterations\n",
        "pn = Perceptron(no_of_inputs=no_of_inputs, threshold=10000, learning_rate=0.01)\n",
        "pn.train(X, y)\n",
        "y_pred = [pn.predict(row) for row in X]\n",
        "print(f'weights: {pn.weights}')\n",
        "print(f'Accuracy: {accuracy_score(y, y_pred)}')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "weights: [-847.85      12.63       5.72      -3.94      -1.88       1.59\n",
            "    8.516    124.50169    1.21   ]\n",
            "Accuracy: 0.6822916666666666\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QR4oAW1xdyu",
        "colab_type": "text"
      },
      "source": [
        "## Stretch Goals:\n",
        "\n",
        "- Research \"backpropagation\" to learn how weights get updated in neural networks (tomorrow's lecture). \n",
        "- Implement a multi-layer perceptron. (for non-linearly separable classes)\n",
        "- Try and implement your own backpropagation algorithm.\n",
        "- What are the pros and cons of the different activation functions? How should you decide between them for the different layers of a neural network?"
      ]
    }
  ]
}