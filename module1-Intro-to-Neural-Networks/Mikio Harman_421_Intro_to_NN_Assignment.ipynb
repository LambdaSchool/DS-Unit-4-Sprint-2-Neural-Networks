{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dVfaLrjLvxvQ"
   },
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "# Neural Networks\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2 Assignment 1*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wxtoY12mwmih"
   },
   "source": [
    "## Define the Following:\n",
    "You can add image, diagrams, whatever you need to ensure that you understand the concepts below.\n",
    "\n",
    "### Input Layer:\n",
    "The input Layer is where the feature data from the dataframe are input or where inputs from other neurons are recieved.\n",
    "### Hidden Layer:\n",
    "These are the layer that exist between the input layer and output layer. You cna have one hidden layer or many hidden layers\n",
    "### Output Layer:\n",
    "This is the answer/result of our neurons in our neural netoworks. These ouputs can then be used as inputs for the next layer of neurons or be the final output(s) of the neural network.\n",
    "### Neuron:\n",
    "The neuron recieves inputs, multiplies the inputs by their weights, sums everyhting up, and then applies the activation function to the sum. Usually involves a continuous activation function\n",
    "### Weight:\n",
    "This is the amount or positive or negative effect an input will be associated with the ending output. \n",
    "### Activation Function:\n",
    "The activation function is how the neural network normalizes the results after inputs, weights, and biases have been applied within the neuron. \n",
    "### Node Map:\n",
    "The node maps show how the features of the dataframe or the outputs of upper level neurons are further processed throughout the neural netowork. It shows inputs, outputs, and hidden layers visualized at a high level.\n",
    "### Perceptron:\n",
    "Simply, a perceptron consists of four distinct parts. Uses a binary activation function that is either activate or not, different from a neuron\n",
    "1. Inputs\n",
    "2. Weights\n",
    "3. Weighted Sum\n",
    "4. Activation Function (Output)\n",
    "\n",
    "Perceptrons classify data into two parts (0,1) most of the time. Perceptrons are also known as Linear Binary Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NXuy9WcWzxa4"
   },
   "source": [
    "## Inputs -> Outputs\n",
    "\n",
    "### Explain the flow of information through a neural network from inputs to outputs. Be sure to include: inputs, weights, bias, and activation functions. How does it all flow from beginning to end?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PlSwIJMC0A8F"
   },
   "source": [
    "#### Your Answer Here\n",
    "Depending on your network, Inputs and Outputs can range arbitraily. Each input can come from an upper level neuron or the intial inputted values from a dataframe. Each input can be weighted negatively or positvely depending on whether your desired answer needs the neuron to activate negatively or positively depending how your inputted bias as shifted the activation curve up or down.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6sWR43PTwhSk"
   },
   "source": [
    "## Write your own perceptron code that can correctly classify (99.0% accuracy) a NAND gate. \n",
    "\n",
    "| x1 | x2 | y |\n",
    "|----|----|---|\n",
    "| 0  | 0  | 1 |\n",
    "| 1  | 0  | 1 |\n",
    "| 0  | 1  | 1 |\n",
    "| 1  | 1  | 0 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "inputs = np.array([\n",
    "    [0,0,1],\n",
    "    [1,0,1],\n",
    "    [0,1,1],\n",
    "    [1,1,1]\n",
    "])\n",
    "\n",
    "\n",
    "outputs = [[1], [1], [1], [0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sgh7VFGwnXGH"
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    sx = sigmoid(x)\n",
    "    return sx * (1-sx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.25091976],\n",
       "       [ 0.90142861],\n",
       "       [ 0.46398788]])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize random weightss for our three inputs\n",
    "weights = 2 * np.random.random((3,1)) - 1\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.46398788],\n",
       "       [0.21306812],\n",
       "       [1.3654165 ],\n",
       "       [1.11449673]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate weighted sum of inputs aand weights\n",
    "weighted_sum = np.dot(inputs, weights)\n",
    "weighted_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.61395979],\n",
       "       [0.55306642],\n",
       "       [0.79663861],\n",
       "       [0.75296649]])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output the activated value for the end of 1 training epoch\n",
    "activated_output = sigmoid(weighted_sum)\n",
    "activated_output # True values are [1, 1, 1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.38604021],\n",
       "       [ 0.44693358],\n",
       "       [ 0.20336139],\n",
       "       [-0.75296649]])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take difference eof output and true values to calculate error\n",
    "error = outputs - activated_output\n",
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nThis helps the perceptron activate correctly toward the right classification\\n\\n'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gradient descent/backprop magic\n",
    "\"\"\"\n",
    "The adjusments to make to the weights, multiply the error of the sigmoid\n",
    "derivative of the activated output. This tells how much to inncrease or \n",
    "decrease our weights by\n",
    "\"\"\"\n",
    "adjusted = error * sigmoid_derivative(activated_output)\n",
    "adjusted\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "This helps the perceptron activate correctly toward the right classification\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.31120624],\n",
       "       [ 0.78109208],\n",
       "       [ 0.53521543]])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"the new weights will be equal to the dot product\n",
    "of your inputs and the adjusted.\"\"\"\n",
    "#also known as an epoch or a single iteration\n",
    "weights += np.dot(inputs.T, adjusted)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights after training\n",
      "[[-11.83951525]\n",
      " [-11.83951525]\n",
      " [ 17.80813756]]\n",
      "Output after train\n",
      "[[0.99999998]\n",
      " [0.99744851]\n",
      " [0.99744851]\n",
      " [0.0028127 ]]\n"
     ]
    }
   ],
   "source": [
    "# Steps we've already done: \n",
    "# 1. Randomly Initialized Weights already. Those are in memory as `weights`\n",
    "# 2. We've already got input data & correct_outputs\n",
    "\n",
    "\"\"\"\n",
    "1. \n",
    "2.\n",
    "3.\n",
    "4.\n",
    "\"\"\"\n",
    "\n",
    "# Update our weights 10,000 times - (fingers crossed that this process \n",
    "# reduces error)\n",
    "for iteration in range(10000):\n",
    "    \n",
    "    # Weighted sum of inputs / weights\n",
    "    weighted_sum = np.dot(inputs, weights)\n",
    "    \n",
    "    # Activate!\n",
    "    activated_output = sigmoid(weighted_sum)\n",
    "    \n",
    "    # Cac error\n",
    "    error = outputs - activated_output\n",
    "    \n",
    "    adjustments = error * sigmoid_derivative(activated_output)\n",
    "    \n",
    "    # Update the Weights\n",
    "    weights += np.dot(inputs.T, adjustments)\n",
    "    \n",
    "print(\"Weights after training\")\n",
    "print(weights)\n",
    "\n",
    "print(\"Output after train\")\n",
    "print(activated_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xf7sdqVs0s4x"
   },
   "source": [
    "## Implement your own Perceptron Class and use it to classify a binary dataset: \n",
    "- [The Pima Indians Diabetes dataset](https://raw.githubusercontent.com/ryanleeallred/datasets/master/diabetes.csv) \n",
    "\n",
    "You may need to search for other's implementations in order to get inspiration for your own. There are *lots* of perceptron implementations on the internet with varying levels of sophistication and complexity. Whatever your approach, make sure you understand **every** line of your implementation and what its purpose is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/ryanleeallred/datasets/master/diabetes.csv')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although neural networks can handle non-normalized data, scaling or normalizing your data will improve your neural network's learning speed. Try to apply the sklearn `MinMaxScaler` or `Normalizer` to your diabetes dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Explore\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, Normalizer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#features for X\n",
    "feats = list(diabetes)[:-1]\n",
    "\n",
    "#split teh data\n",
    "training, test = train_test_split(df, test_size=.2,)\n",
    "\n",
    "X = training[feats]\n",
    "y = training['Outcome']\n",
    "\n",
    "X_test = test[feats]\n",
    "y_test = test['Outcome']\n",
    "\n",
    "normalize = MinMaxScaler()\n",
    "X_norm = normalize.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-W0tiX1F1hh2"
   },
   "outputs": [],
   "source": [
    "##### Update this Class #####\n",
    "\n",
    "class Perceptron(object):\n",
    "    def __init__(self, rate = 0.01, niter = 10000):\n",
    "        self.rate = rate\n",
    "        self.niter = niter\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit training data\n",
    "        X : Training vectors, X.shape : [#samples, #features]\n",
    "        y : Target values, y.shape : [#samples]\n",
    "        \"\"\"\n",
    "\n",
    "        # weights\n",
    "        self.weight = np.zeros(1 + X.shape[1])\n",
    "\n",
    "        # Number of misclassifications\n",
    "        self.errors = []  # Number of misclassifications\n",
    "\n",
    "        for i in range(self.niter):\n",
    "            err = 0\n",
    "            for xi, target in zip(X, y):\n",
    "                delta_w = self.rate * (target - self.predict(xi))\n",
    "                self.weight[1:] += delta_w * xi\n",
    "                self.weight[0] += delta_w\n",
    "                err += int(delta_w != 0.0)\n",
    "            self.errors.append(err)\n",
    "        return self\n",
    "\n",
    "    def net_input(self, X):\n",
    "        \"\"\"Calculate net input\"\"\"\n",
    "        return np.dot(X, self.weight[1:]) + self.weight[0]\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Return class label after unit step\"\"\"\n",
    "        return np.where(self.net_input(X) >= 0.0, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pn = Perceptron()\n",
    "pn.fit(X_norm, y)\n",
    "plt.plot(range(1, len(pn.errors) + 1), pn.errors, marker='o')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Number of misclassifications')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3246753246753247"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = pn.predict(X_test)\n",
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6QR4oAW1xdyu"
   },
   "source": [
    "## Stretch Goals:\n",
    "\n",
    "- Research \"backpropagation\" to learn how weights get updated in neural networks (tomorrow's lecture). \n",
    "- Implement a multi-layer perceptron. (for non-linearly separable classes)\n",
    "- Try and implement your own backpropagation algorithm.\n",
    "- What are the pros and cons of the different activation functions? How should you decide between them for the different layers of a neural network?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_431_Intro_to_NN_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
