{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2*\n",
    "\n",
    "# Sprint Challenge - Neural Network Foundations\n",
    "\n",
    "Table of Problems\n",
    "\n",
    "1. [Defining Neural Networks](#Q1)\n",
    "2. [Chocolate Gummy Bears](#Q2)\n",
    "    - Perceptron\n",
    "    - Multilayer Perceptron\n",
    "4. [Keras MMP](#Q3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Q1\"></a>\n",
    "## 1. Define the following terms:\n",
    "\n",
    "- **Neuron:**\n",
    "Neuron takes one or more inputs that are multiplied by values called “weights” and added together. This value is then passed to a non-linear function, known as an activation function, to become the neuron's output.\n",
    "Its basic building bock of any Neural Network.\n",
    "- **Input Layer:**\n",
    "Its the first layer of neural Net, where the inputs of data are fed. \n",
    "- **Hidden Layer:**\n",
    "Hidden layers reside in-between input and output layers,where artificial neurons take in a set of weighted inputs and produce an output through an activation function.\n",
    "- **Output Layer:**\n",
    "The output layer in an artificial neural network is the last layer of neurons that produces given outputs for the program.\n",
    "- **Activation:**\n",
    "Activation functions are mathematical equations that determine the output of a neural network. The function is attached to each neuron in the network, and determines whether it should be activated (“fired”) or not, based on whether each neuron's input is relevant for the model's prediction.\n",
    "- **Backpropagation:**\n",
    "Backpropagation is used to update the weights by calculating a gradient. The gradient gives a direction in which to adjust the weight. The gradient and the error determine how much to move the weight. This is were the learning takes place and it happens after every epoch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Chocolate Gummy Bears <a id=\"Q2\"></a>\n",
    "\n",
    "Right now, you're probably thinking, \"yuck, who the hell would eat that?\". Great question. Your candy company wants to know too. And you thought I was kidding about the [Chocolate Gummy Bears](https://nuts.com/chocolatessweets/gummies/gummy-bears/milk-gummy-bears.html?utm_source=google&utm_medium=cpc&adpos=1o1&gclid=Cj0KCQjwrfvsBRD7ARIsAKuDvMOZrysDku3jGuWaDqf9TrV3x5JLXt1eqnVhN0KM6fMcbA1nod3h8AwaAvWwEALw_wcB). \n",
    "\n",
    "Let's assume that a candy company has gone out and collected information on the types of Halloween candy kids ate. Our candy company wants to predict the eating behavior of witches, warlocks, and ghosts -- aka costumed kids. They shared a sample dataset with us. Each row represents a piece of candy that a costumed child was presented with during \"trick\" or \"treat\". We know if the candy was `chocolate` (or not chocolate) or `gummy` (or not gummy). Your goal is to predict if the costumed kid `ate` the piece of candy. \n",
    "\n",
    "If both chocolate and gummy equal one, you've got a chocolate gummy bear on your hands!?!?!\n",
    "![Chocolate Gummy Bear](https://ed910ae2d60f0d25bcb8-80550f96b5feb12604f4f720bfefb46d.ssl.cf1.rackcdn.com/3fb630c04435b7b5-2leZuM7_-zoom.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "candy = pd.read_csv('chocolate_gummy_bears.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chocolate</th>\n",
       "      <th>gummy</th>\n",
       "      <th>ate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   chocolate  gummy  ate\n",
       "0          0      1    1\n",
       "1          1      0    1\n",
       "2          0      1    1\n",
       "3          0      0    0\n",
       "4          1      1    0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron\n",
    "\n",
    "To make predictions on the `candy` dataframe. Build and train a Perceptron using numpy. Your target column is `ate` and your features: `chocolate` and `gummy`. Do not do any feature engineering. :P\n",
    "\n",
    "Once you've trained your model, report your accuracy. You will not be able to achieve more than ~50% with the simple perceptron. Explain why you could not achieve a higher accuracy with the *simple perceptron* architecture, because it's possible to achieve ~95% accuracy on this dataset. Provide your answer in markdown (and *optional* data anlysis code) after your perceptron implementation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/karthikmahendra/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# Start your candy perceptron here\n",
    "\n",
    "X = candy[['chocolate', 'gummy']].values\n",
    "#y = candy['ate'].values\n",
    "y = candy.as_matrix(columns = ['ate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       ...,\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       ...,\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron():\n",
    "    def __init__(self):\n",
    "        # Set up Architecture of Neural Network\n",
    "        self.inputs = 2\n",
    "        self.outputNodes = 1\n",
    "        # Initial Weights\n",
    "        # 2x1 Matrix Array for the First Layer\n",
    "        self.weights1 = np.random.rand(self.inputs, self.outputNodes)\n",
    "    \n",
    "    def sigmoid(self, s):\n",
    "        return 1 / (1+np.exp(-s))\n",
    "    \n",
    "    def sigmoidPrime(self, s):\n",
    "        return s * (1 - s)\n",
    "    \n",
    "    def feed_forward(self, X):\n",
    "        # Weighted sum of inputs => output layer\n",
    "        self.output_sum = np.dot(X, self.weights1)\n",
    "        \n",
    "        # Final activation of output\n",
    "        self.activated_output = self.sigmoid(self.output_sum)\n",
    "        \n",
    "        return self.activated_output\n",
    "    \n",
    "    def backward(self, X,y,o):\n",
    "        # Error in Output\n",
    "        self.o_error = y - o\n",
    "        \n",
    "        self.adjustments = self.o_error * self.sigmoidPrime(o)\n",
    "        \n",
    "        # Adjustment to first set of weights (input => output)\n",
    "        self.weights1 += np.dot(X.T, self.adjustments)\n",
    "        \n",
    "    def train(self, X, y):\n",
    "        o = self.feed_forward(X)\n",
    "        self.backward(X, y, o)\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "per = Perceptron()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------EPOCH 1---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Predicted Output: \n",
      " [[1.51506346e-45]\n",
      " [3.43243876e-80]\n",
      " [1.51506346e-45]\n",
      " ...\n",
      " [1.51506346e-45]\n",
      " [1.51506346e-45]\n",
      " [3.43243876e-80]]\n",
      "Loss: \n",
      " 0.54885\n",
      "Accuracy: \n",
      " 0.45115000000000005\n",
      "+---------EPOCH 2---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Predicted Output: \n",
      " [[1.51506346e-45]\n",
      " [3.43243876e-80]\n",
      " [1.51506346e-45]\n",
      " ...\n",
      " [1.51506346e-45]\n",
      " [1.51506346e-45]\n",
      " [3.43243876e-80]]\n",
      "Loss: \n",
      " 0.54885\n",
      "Accuracy: \n",
      " 0.45115000000000005\n",
      "+---------EPOCH 3---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Predicted Output: \n",
      " [[1.51506346e-45]\n",
      " [3.43243876e-80]\n",
      " [1.51506346e-45]\n",
      " ...\n",
      " [1.51506346e-45]\n",
      " [1.51506346e-45]\n",
      " [3.43243876e-80]]\n",
      "Loss: \n",
      " 0.54885\n",
      "Accuracy: \n",
      " 0.45115000000000005\n",
      "+---------EPOCH 4---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Predicted Output: \n",
      " [[1.51506346e-45]\n",
      " [3.43243876e-80]\n",
      " [1.51506346e-45]\n",
      " ...\n",
      " [1.51506346e-45]\n",
      " [1.51506346e-45]\n",
      " [3.43243876e-80]]\n",
      "Loss: \n",
      " 0.54885\n",
      "Accuracy: \n",
      " 0.45115000000000005\n",
      "+---------EPOCH 5---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Predicted Output: \n",
      " [[1.51506346e-45]\n",
      " [3.43243876e-80]\n",
      " [1.51506346e-45]\n",
      " ...\n",
      " [1.51506346e-45]\n",
      " [1.51506346e-45]\n",
      " [3.43243876e-80]]\n",
      "Loss: \n",
      " 0.54885\n",
      "Accuracy: \n",
      " 0.45115000000000005\n",
      "+---------EPOCH 10---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Predicted Output: \n",
      " [[1.51506346e-45]\n",
      " [3.43243876e-80]\n",
      " [1.51506346e-45]\n",
      " ...\n",
      " [1.51506346e-45]\n",
      " [1.51506346e-45]\n",
      " [3.43243876e-80]]\n",
      "Loss: \n",
      " 0.54885\n",
      "Accuracy: \n",
      " 0.45115000000000005\n",
      "+---------EPOCH 20---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Predicted Output: \n",
      " [[1.51506346e-45]\n",
      " [3.43243876e-80]\n",
      " [1.51506346e-45]\n",
      " ...\n",
      " [1.51506346e-45]\n",
      " [1.51506346e-45]\n",
      " [3.43243876e-80]]\n",
      "Loss: \n",
      " 0.54885\n",
      "Accuracy: \n",
      " 0.45115000000000005\n",
      "+---------EPOCH 30---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Predicted Output: \n",
      " [[1.51506346e-45]\n",
      " [3.43243876e-80]\n",
      " [1.51506346e-45]\n",
      " ...\n",
      " [1.51506346e-45]\n",
      " [1.51506346e-45]\n",
      " [3.43243876e-80]]\n",
      "Loss: \n",
      " 0.54885\n",
      "Accuracy: \n",
      " 0.45115000000000005\n",
      "+---------EPOCH 40---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Predicted Output: \n",
      " [[1.51506346e-45]\n",
      " [3.43243876e-80]\n",
      " [1.51506346e-45]\n",
      " ...\n",
      " [1.51506346e-45]\n",
      " [1.51506346e-45]\n",
      " [3.43243876e-80]]\n",
      "Loss: \n",
      " 0.54885\n",
      "Accuracy: \n",
      " 0.45115000000000005\n",
      "+---------EPOCH 50---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Predicted Output: \n",
      " [[1.51506346e-45]\n",
      " [3.43243876e-80]\n",
      " [1.51506346e-45]\n",
      " ...\n",
      " [1.51506346e-45]\n",
      " [1.51506346e-45]\n",
      " [3.43243876e-80]]\n",
      "Loss: \n",
      " 0.54885\n",
      "Accuracy: \n",
      " 0.45115000000000005\n",
      "+---------EPOCH 60---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Predicted Output: \n",
      " [[1.51506346e-45]\n",
      " [3.43243876e-80]\n",
      " [1.51506346e-45]\n",
      " ...\n",
      " [1.51506346e-45]\n",
      " [1.51506346e-45]\n",
      " [3.43243876e-80]]\n",
      "Loss: \n",
      " 0.54885\n",
      "Accuracy: \n",
      " 0.45115000000000005\n",
      "+---------EPOCH 70---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Predicted Output: \n",
      " [[1.51506346e-45]\n",
      " [3.43243876e-80]\n",
      " [1.51506346e-45]\n",
      " ...\n",
      " [1.51506346e-45]\n",
      " [1.51506346e-45]\n",
      " [3.43243876e-80]]\n",
      "Loss: \n",
      " 0.54885\n",
      "Accuracy: \n",
      " 0.45115000000000005\n",
      "+---------EPOCH 80---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Predicted Output: \n",
      " [[1.51506346e-45]\n",
      " [3.43243876e-80]\n",
      " [1.51506346e-45]\n",
      " ...\n",
      " [1.51506346e-45]\n",
      " [1.51506346e-45]\n",
      " [3.43243876e-80]]\n",
      "Loss: \n",
      " 0.54885\n",
      "Accuracy: \n",
      " 0.45115000000000005\n",
      "+---------EPOCH 90---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Predicted Output: \n",
      " [[1.51506346e-45]\n",
      " [3.43243876e-80]\n",
      " [1.51506346e-45]\n",
      " ...\n",
      " [1.51506346e-45]\n",
      " [1.51506346e-45]\n",
      " [3.43243876e-80]]\n",
      "Loss: \n",
      " 0.54885\n",
      "Accuracy: \n",
      " 0.45115000000000005\n",
      "+---------EPOCH 100---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Predicted Output: \n",
      " [[1.51506346e-45]\n",
      " [3.43243876e-80]\n",
      " [1.51506346e-45]\n",
      " ...\n",
      " [1.51506346e-45]\n",
      " [1.51506346e-45]\n",
      " [3.43243876e-80]]\n",
      "Loss: \n",
      " 0.54885\n",
      "Accuracy: \n",
      " 0.45115000000000005\n"
     ]
    }
   ],
   "source": [
    "# Number of Epochs / Iterations\n",
    "for i in range(100):\n",
    "    if (i+1 in [1,2,3,4,5]) or ((i+1) % 10 ==0):\n",
    "        print('+' + '---' * 3 + f'EPOCH {i+1}' + '---'*3 + '+')\n",
    "        print('Input: \\n', X)\n",
    "        print('Actual Output: \\n', y)\n",
    "        print('Predicted Output: \\n', str(per.feed_forward(X)))\n",
    "        print(\"Loss: \\n\", str(np.mean(np.square(y - per.feed_forward(X)))))\n",
    "        print(\"Accuracy: \\n\",str(1-np.mean(np.square(y - per.feed_forward(X)))))\n",
    "    per.train(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer Perceptron <a id=\"Q3\"></a>\n",
    "\n",
    "Using the sample candy dataset, implement a Neural Network Multilayer Perceptron class that uses backpropagation to update the network's weights. Your Multilayer Perceptron should be implemented in Numpy. \n",
    "Your network must have one hidden layer.\n",
    "\n",
    "Once you've trained your model, report your accuracy. Explain why your MLP's performance is considerably better than your simple perceptron's on the candy dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self):\n",
    "        # Set up Architecture of Neural Network\n",
    "        self.inputs = 2\n",
    "        self.hiddenNodes = 25\n",
    "        self.outputNodes = 1\n",
    "        # Initial Weights\n",
    "        # 3x4 Matrix Array for the First Layer\n",
    "        self.weights1 = np.random.rand(self.inputs, self.hiddenNodes)\n",
    "        # 4x1 Matrix Array for the First Layer\n",
    "        self.weights2 = np.random.rand(self.hiddenNodes, self.outputNodes)\n",
    "    \n",
    "    def sigmoid(self, s):\n",
    "        return 1 / (1+np.exp(-s))\n",
    "    \n",
    "    def sigmoidPrime(self, s):\n",
    "        return s * (1 - s)\n",
    "    \n",
    "    def feed_forward(self, X):\n",
    "        # Weighted sum of inputs => hidden layer\n",
    "        self.hidden_sum = np.dot(X, self.weights1)\n",
    "        \n",
    "        # Activations of weighted sum\n",
    "        self.activated_hidden = self.sigmoid(self.hidden_sum)\n",
    "        \n",
    "        # Weight sum between hidden and output\n",
    "        self.output_sum = np.dot(self.activated_hidden, self.weights2)\n",
    "        \n",
    "        # Final activation of output\n",
    "        self.activated_output = self.sigmoid(self.output_sum)\n",
    "        \n",
    "        return self.activated_output\n",
    "    \n",
    "    def backward(self, X,y,o):\n",
    "        # Error in Output\n",
    "        self.o_error = y - o\n",
    "        \n",
    "        # Apply Derivative of Sigmoid to error\n",
    "        # How far off are we in relation to the Sigmoid f(x) of the output\n",
    "        # ^- aka hidden => output\n",
    "        self.o_delta = self.o_error * self.sigmoidPrime(o)\n",
    "        \n",
    "        # z2 error\n",
    "        self.z2_error = self.o_delta.dot(self.weights2.T)\n",
    "        \n",
    "        # How much of that \"far off\" can explained by the input => hidden\n",
    "        self.z2_delta = self.z2_error * self.sigmoidPrime(self.activated_hidden)\n",
    "        \n",
    "        # Adjustment to first set of weights (input => hidden)\n",
    "        self.weights1 += X.T.dot(self.z2_delta)\n",
    "        # Adjustment to second set of weights (hidden => output)\n",
    "        self.weights2 += self.activated_hidden.T.dot(self.o_delta)\n",
    "        \n",
    "    def train(self, X, y):\n",
    "        o = self.feed_forward(X)\n",
    "        self.backward(X, y, o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NeuralNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------EPOCH 1---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Predicted Output: \n",
      " [[0.99945737]\n",
      " [0.99936087]\n",
      " [0.99945737]\n",
      " ...\n",
      " [0.99945737]\n",
      " [0.99945737]\n",
      " [0.99936087]]\n",
      "Loss: \n",
      " 0.4986126356639787\n",
      "Accuracy: \n",
      " 0.5013873643360214\n",
      "+---------EPOCH 2---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Predicted Output: \n",
      " [[6.78547871e-22]\n",
      " [4.39647226e-21]\n",
      " [6.78547871e-22]\n",
      " ...\n",
      " [6.78547871e-22]\n",
      " [6.78547871e-22]\n",
      " [4.39647226e-21]]\n",
      "Loss: \n",
      " 0.5\n",
      "Accuracy: \n",
      " 0.5\n",
      "+---------EPOCH 3---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Predicted Output: \n",
      " [[6.78547871e-22]\n",
      " [4.39647226e-21]\n",
      " [6.78547871e-22]\n",
      " ...\n",
      " [6.78547871e-22]\n",
      " [6.78547871e-22]\n",
      " [4.39647226e-21]]\n",
      "Loss: \n",
      " 0.5\n",
      "Accuracy: \n",
      " 0.5\n",
      "+---------EPOCH 4---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Predicted Output: \n",
      " [[6.78547871e-22]\n",
      " [4.39647226e-21]\n",
      " [6.78547871e-22]\n",
      " ...\n",
      " [6.78547871e-22]\n",
      " [6.78547871e-22]\n",
      " [4.39647226e-21]]\n",
      "Loss: \n",
      " 0.5\n",
      "Accuracy: \n",
      " 0.5\n",
      "+---------EPOCH 5---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Predicted Output: \n",
      " [[6.78547871e-22]\n",
      " [4.39647226e-21]\n",
      " [6.78547871e-22]\n",
      " ...\n",
      " [6.78547871e-22]\n",
      " [6.78547871e-22]\n",
      " [4.39647226e-21]]\n",
      "Loss: \n",
      " 0.5\n",
      "Accuracy: \n",
      " 0.5\n"
     ]
    }
   ],
   "source": [
    "# Number of Epochs / Iterations\n",
    "for i in range(100):\n",
    "    if (i+1 in [1,2,3,4,5]) or ((i+1) % 1000 ==0):\n",
    "        print('+' + '---' * 3 + f'EPOCH {i+1}' + '---'*3 + '+')\n",
    "        print('Input: \\n', X)\n",
    "        print('Actual Output: \\n', y)\n",
    "        print('Predicted Output: \\n', str(nn.feed_forward(X)))\n",
    "        print(\"Loss: \\n\", str(np.mean(np.square(y - nn.feed_forward(X)))))\n",
    "        print(\"Accuracy: \\n\",str(1-np.mean(np.square(y - nn.feed_forward(X)))))\n",
    "    nn.train(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy of MLP is better than Simple Perceptron because we have an extra hidden layer. Hidden layer adds more complexity to model, hence its able to give more accurate predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P.S. Don't try candy gummy bears. They're disgusting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Keras MMP <a id=\"Q3\"></a>\n",
    "\n",
    "Implement a Multilayer Perceptron architecture of your choosing using the Keras library. Train your model and report its baseline accuracy. Then hyperparameter tune at least two parameters and report your model's accuracy.\n",
    "Use the Heart Disease Dataset (binary classification)\n",
    "Use an appropriate loss function for a binary classification task\n",
    "Use an appropriate activation function on the final layer of your network.\n",
    "Train your model using verbose output for ease of grading.\n",
    "Use GridSearchCV or RandomSearchCV to hyperparameter tune your model. (for at least two hyperparameters)\n",
    "When hyperparameter tuning, show you work by adding code cells for each new experiment.\n",
    "Report the accuracy for each combination of hyperparameters as you test them so that we can easily see which resulted in the highest accuracy.\n",
    "You must hyperparameter tune at least 3 parameters in order to get a 3 on this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(303, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>246</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>120</td>\n",
       "      <td>211</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>140</td>\n",
       "      <td>197</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>138</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>173</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>108</td>\n",
       "      <td>309</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "233   64    1   0       120   246    0        0       96      1      2.2   \n",
       "105   68    0   2       120   211    0        0      115      0      1.5   \n",
       "144   76    0   2       140   197    0        2      116      0      1.1   \n",
       "163   38    1   2       138   175    0        1      173      0      0.0   \n",
       "61    54    1   1       108   309    0        1      156      0      0.0   \n",
       "\n",
       "     slope  ca  thal  target  \n",
       "233      0   1     2       0  \n",
       "105      1   0     2       1  \n",
       "144      1   0     2       1  \n",
       "163      2   4     2       1  \n",
       "61       2   0     3       1  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/ryanleeallred/datasets/master/heart.csv')\n",
    "df = df.sample(frac=1)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((303, 13), (303, 1))"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split traget out of df\n",
    "X = df.drop('target', axis=1).values.astype('float32')\n",
    "y = df['target'].values.reshape(-1,1)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.544554\n",
       "0    0.455446\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline\n",
    "df['target'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "seed = 42\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_train.shape,X_test.shape\n",
    "num_inputs = X.shape[1]\n",
    "num_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model( hidden_1_nodes=13,optimizer='adam',init_mode = 'uniform'):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_1_nodes, input_dim=num_inputs, activation='relu'))\n",
    "    model.add(Dense(7, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 303 samples\n",
      "Epoch 1/20\n",
      "303/303 [==============================] - 0s 1ms/sample - loss: 4.9041 - accuracy: 0.5413\n",
      "Epoch 2/20\n",
      "303/303 [==============================] - 0s 227us/sample - loss: 1.3630 - accuracy: 0.4818\n",
      "Epoch 3/20\n",
      "303/303 [==============================] - 0s 161us/sample - loss: 1.0423 - accuracy: 0.5149\n",
      "Epoch 4/20\n",
      "303/303 [==============================] - 0s 140us/sample - loss: 0.7656 - accuracy: 0.5743\n",
      "Epoch 5/20\n",
      "303/303 [==============================] - 0s 138us/sample - loss: 0.7092 - accuracy: 0.6337\n",
      "Epoch 6/20\n",
      "303/303 [==============================] - 0s 145us/sample - loss: 0.6230 - accuracy: 0.6469\n",
      "Epoch 7/20\n",
      "303/303 [==============================] - 0s 137us/sample - loss: 0.5443 - accuracy: 0.7360\n",
      "Epoch 8/20\n",
      "303/303 [==============================] - 0s 131us/sample - loss: 0.5305 - accuracy: 0.7228\n",
      "Epoch 9/20\n",
      "303/303 [==============================] - 0s 140us/sample - loss: 0.5778 - accuracy: 0.7030\n",
      "Epoch 10/20\n",
      "303/303 [==============================] - 0s 136us/sample - loss: 0.5167 - accuracy: 0.7294\n",
      "Epoch 11/20\n",
      "303/303 [==============================] - 0s 156us/sample - loss: 0.5003 - accuracy: 0.7525\n",
      "Epoch 12/20\n",
      "303/303 [==============================] - 0s 166us/sample - loss: 0.5054 - accuracy: 0.7327\n",
      "Epoch 13/20\n",
      "303/303 [==============================] - 0s 217us/sample - loss: 0.5050 - accuracy: 0.7459\n",
      "Epoch 14/20\n",
      "303/303 [==============================] - 0s 193us/sample - loss: 0.4936 - accuracy: 0.7525\n",
      "Epoch 15/20\n",
      "303/303 [==============================] - 0s 144us/sample - loss: 0.4700 - accuracy: 0.7888\n",
      "Epoch 16/20\n",
      "303/303 [==============================] - 0s 143us/sample - loss: 0.4753 - accuracy: 0.7888\n",
      "Epoch 17/20\n",
      "303/303 [==============================] - 0s 136us/sample - loss: 0.4888 - accuracy: 0.7525\n",
      "Epoch 18/20\n",
      "303/303 [==============================] - 0s 132us/sample - loss: 0.5015 - accuracy: 0.7360\n",
      "Epoch 19/20\n",
      "303/303 [==============================] - 0s 134us/sample - loss: 0.5926 - accuracy: 0.7063\n",
      "Epoch 20/20\n",
      "303/303 [==============================] - 0s 137us/sample - loss: 0.4921 - accuracy: 0.7558\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15b2fd240>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y,  \n",
    "          epochs=20, \n",
    "          batch_size=10,\n",
    "          verbose=True,\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'batch_size': [5, 10, 100],\n",
    "             'epochs': [20, 50, 100],\n",
    "             'optimizer': ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.8052805264790853 using {'batch_size': 5, 'epochs': 50, 'optimizer': 'Adam'}\n",
      "Mean: 0.5445544719696045, Stdev: 0.029147716944745876 with: {'batch_size': 5, 'epochs': 20, 'optimizer': 'SGD'}\n",
      "Mean: 0.7656765580177307, Stdev: 0.05197366159998095 with: {'batch_size': 5, 'epochs': 20, 'optimizer': 'RMSprop'}\n",
      "Mean: 0.5346534649531046, Stdev: 0.12934597880363888 with: {'batch_size': 5, 'epochs': 20, 'optimizer': 'Adagrad'}\n",
      "Mean: 0.5016501744588217, Stdev: 0.06121201287978154 with: {'batch_size': 5, 'epochs': 20, 'optimizer': 'Adadelta'}\n",
      "Mean: 0.726072629292806, Stdev: 0.004667370101995413 with: {'batch_size': 5, 'epochs': 20, 'optimizer': 'Adam'}\n",
      "Mean: 0.6567656795183817, Stdev: 0.06584137467860096 with: {'batch_size': 5, 'epochs': 20, 'optimizer': 'Adamax'}\n",
      "Mean: 0.5940594176451365, Stdev: 0.10321119961528105 with: {'batch_size': 5, 'epochs': 20, 'optimizer': 'Nadam'}\n",
      "Mean: 0.5742574334144592, Stdev: 0.06617139168454245 with: {'batch_size': 5, 'epochs': 50, 'optimizer': 'SGD'}\n",
      "Mean: 0.7458745837211609, Stdev: 0.03820409826336089 with: {'batch_size': 5, 'epochs': 50, 'optimizer': 'RMSprop'}\n",
      "Mean: 0.48184818029403687, Stdev: 0.09473729380429237 with: {'batch_size': 5, 'epochs': 50, 'optimizer': 'Adagrad'}\n",
      "Mean: 0.5049504935741425, Stdev: 0.05301115817067107 with: {'batch_size': 5, 'epochs': 50, 'optimizer': 'Adadelta'}\n",
      "Mean: 0.8052805264790853, Stdev: 0.06067581132594036 with: {'batch_size': 5, 'epochs': 50, 'optimizer': 'Adam'}\n",
      "Mean: 0.6831683119138082, Stdev: 0.04042063510541671 with: {'batch_size': 5, 'epochs': 50, 'optimizer': 'Adamax'}\n",
      "Mean: 0.8052805264790853, Stdev: 0.07290665165289216 with: {'batch_size': 5, 'epochs': 50, 'optimizer': 'Nadam'}\n",
      "Mean: 0.5445544719696045, Stdev: 0.029147716944745876 with: {'batch_size': 5, 'epochs': 100, 'optimizer': 'SGD'}\n",
      "Mean: 0.7821782231330872, Stdev: 0.06313901243626734 with: {'batch_size': 5, 'epochs': 100, 'optimizer': 'RMSprop'}\n",
      "Mean: 0.5016501744588217, Stdev: 0.044523898114561394 with: {'batch_size': 5, 'epochs': 100, 'optimizer': 'Adagrad'}\n",
      "Mean: 0.5082508325576782, Stdev: 0.05259861345783228 with: {'batch_size': 5, 'epochs': 100, 'optimizer': 'Adadelta'}\n",
      "Mean: 0.8052805264790853, Stdev: 0.025986816922028384 with: {'batch_size': 5, 'epochs': 100, 'optimizer': 'Adam'}\n",
      "Mean: 0.6897689898808798, Stdev: 0.025986844677952755 with: {'batch_size': 5, 'epochs': 100, 'optimizer': 'Adamax'}\n",
      "Mean: 0.7524752418200175, Stdev: 0.04850475725980029 with: {'batch_size': 5, 'epochs': 100, 'optimizer': 'Nadam'}\n",
      "Mean: 0.5445544719696045, Stdev: 0.029147716944745876 with: {'batch_size': 10, 'epochs': 20, 'optimizer': 'SGD'}\n",
      "Mean: 0.6501650313536326, Stdev: 0.11035151723730562 with: {'batch_size': 10, 'epochs': 20, 'optimizer': 'RMSprop'}\n",
      "Mean: 0.4554455478986104, Stdev: 0.08517154886848485 with: {'batch_size': 10, 'epochs': 20, 'optimizer': 'Adagrad'}\n",
      "Mean: 0.4455445607503255, Stdev: 0.04277718116912489 with: {'batch_size': 10, 'epochs': 20, 'optimizer': 'Adadelta'}\n",
      "Mean: 0.6501650214195251, Stdev: 0.06969872531259208 with: {'batch_size': 10, 'epochs': 20, 'optimizer': 'Adam'}\n",
      "Mean: 0.5346534748872122, Stdev: 0.04917380333184564 with: {'batch_size': 10, 'epochs': 20, 'optimizer': 'Adamax'}\n",
      "Mean: 0.6468646923700968, Stdev: 0.04939482881633197 with: {'batch_size': 10, 'epochs': 20, 'optimizer': 'Nadam'}\n",
      "Mean: 0.5412541429201762, Stdev: 0.025986816922028384 with: {'batch_size': 10, 'epochs': 50, 'optimizer': 'SGD'}\n",
      "Mean: 0.6336633761723837, Stdev: 0.1012937855087298 with: {'batch_size': 10, 'epochs': 50, 'optimizer': 'RMSprop'}\n",
      "Mean: 0.554455449183782, Stdev: 0.042777167373330094 with: {'batch_size': 10, 'epochs': 50, 'optimizer': 'Adagrad'}\n",
      "Mean: 0.5808580915133158, Stdev: 0.06484117772000389 with: {'batch_size': 10, 'epochs': 50, 'optimizer': 'Adadelta'}\n",
      "Mean: 0.7095709641774496, Stdev: 0.020344620391104674 with: {'batch_size': 10, 'epochs': 50, 'optimizer': 'Adam'}\n",
      "Mean: 0.6897689898808798, Stdev: 0.04148451975481741 with: {'batch_size': 10, 'epochs': 50, 'optimizer': 'Adamax'}\n",
      "Mean: 0.6864686409632365, Stdev: 0.025986844677952755 with: {'batch_size': 10, 'epochs': 50, 'optimizer': 'Nadam'}\n",
      "Mean: 0.5412541429201762, Stdev: 0.025986816922028384 with: {'batch_size': 10, 'epochs': 100, 'optimizer': 'SGD'}\n",
      "Mean: 0.7062706351280212, Stdev: 0.05197366159998095 with: {'batch_size': 10, 'epochs': 100, 'optimizer': 'RMSprop'}\n",
      "Mean: 0.6138614018758138, Stdev: 0.08440074111595573 with: {'batch_size': 10, 'epochs': 100, 'optimizer': 'Adagrad'}\n",
      "Mean: 0.5379538138707479, Stdev: 0.02333685050997706 with: {'batch_size': 10, 'epochs': 100, 'optimizer': 'Adadelta'}\n",
      "Mean: 0.7722772161165873, Stdev: 0.0631390404765296 with: {'batch_size': 10, 'epochs': 100, 'optimizer': 'Adam'}\n",
      "Mean: 0.7425742745399475, Stdev: 0.0370461016997341 with: {'batch_size': 10, 'epochs': 100, 'optimizer': 'Adamax'}\n",
      "Mean: 0.7128712932268778, Stdev: 0.1283314883241956 with: {'batch_size': 10, 'epochs': 100, 'optimizer': 'Nadam'}\n",
      "Mean: 0.5577557881673177, Stdev: 0.040689189213402255 with: {'batch_size': 100, 'epochs': 20, 'optimizer': 'SGD'}\n",
      "Mean: 0.5973597367604574, Stdev: 0.110055010377282 with: {'batch_size': 100, 'epochs': 20, 'optimizer': 'RMSprop'}\n",
      "Mean: 0.5412541329860687, Stdev: 0.0336568980862956 with: {'batch_size': 100, 'epochs': 20, 'optimizer': 'Adagrad'}\n",
      "Mean: 0.5049505035082499, Stdev: 0.037046114974743874 with: {'batch_size': 100, 'epochs': 20, 'optimizer': 'Adadelta'}\n",
      "Mean: 0.5742574334144592, Stdev: 0.05048532667293615 with: {'batch_size': 100, 'epochs': 20, 'optimizer': 'Adam'}\n",
      "Mean: 0.5346534748872122, Stdev: 0.03233650078428388 with: {'batch_size': 100, 'epochs': 20, 'optimizer': 'Adamax'}\n",
      "Mean: 0.5214521388212839, Stdev: 0.1268804177061422 with: {'batch_size': 100, 'epochs': 20, 'optimizer': 'Nadam'}\n",
      "Mean: 0.5445544719696045, Stdev: 0.029147716944745876 with: {'batch_size': 100, 'epochs': 50, 'optimizer': 'SGD'}\n",
      "Mean: 0.5841584205627441, Stdev: 0.028004220611972473 with: {'batch_size': 100, 'epochs': 50, 'optimizer': 'RMSprop'}\n",
      "Mean: 0.6105610728263855, Stdev: 0.10042985989191526 with: {'batch_size': 100, 'epochs': 50, 'optimizer': 'Adagrad'}\n",
      "Mean: 0.5313531557718912, Stdev: 0.02034459460670113 with: {'batch_size': 100, 'epochs': 50, 'optimizer': 'Adadelta'}\n",
      "Mean: 0.5676567554473877, Stdev: 0.08644093203320917 with: {'batch_size': 100, 'epochs': 50, 'optimizer': 'Adam'}\n",
      "Mean: 0.6237623890240988, Stdev: 0.09002099632401238 with: {'batch_size': 100, 'epochs': 50, 'optimizer': 'Adamax'}\n",
      "Mean: 0.5346534649531046, Stdev: 0.09323067008817769 with: {'batch_size': 100, 'epochs': 50, 'optimizer': 'Nadam'}\n",
      "Mean: 0.5775577624638876, Stdev: 0.02034459460670113 with: {'batch_size': 100, 'epochs': 100, 'optimizer': 'SGD'}\n",
      "Mean: 0.5346534550189972, Stdev: 0.11317773275676378 with: {'batch_size': 100, 'epochs': 100, 'optimizer': 'RMSprop'}\n",
      "Mean: 0.4785478512446086, Stdev: 0.09014191684218391 with: {'batch_size': 100, 'epochs': 100, 'optimizer': 'Adagrad'}\n",
      "Mean: 0.4455445508162181, Stdev: 0.016168256475516667 with: {'batch_size': 100, 'epochs': 100, 'optimizer': 'Adadelta'}\n",
      "Mean: 0.7128712932268778, Stdev: 0.04501050908807029 with: {'batch_size': 100, 'epochs': 100, 'optimizer': 'Adam'}\n",
      "Mean: 0.5214521686236063, Stdev: 0.01682844222431205 with: {'batch_size': 100, 'epochs': 100, 'optimizer': 'Adamax'}\n",
      "Mean: 0.5973597367604574, Stdev: 0.05134107112194954 with: {'batch_size': 100, 'epochs': 100, 'optimizer': 'Nadam'}\n",
      "CPU times: user 8min 36s, sys: 48 s, total: 9min 24s\n",
      "Wall time: 6min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create Grid Search\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, n_jobs=1)\n",
    "grid_result = grid.fit(X, y,verbose=False)\n",
    "\n",
    "# Report Results\n",
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f\"Mean: {mean}, Stdev: {stdev} with: {param}\")\n",
    "                       \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'batch_size': [5, 10, 100],\n",
    "             'epochs': [20, 50, 100],\n",
    "             'optimizer': ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam'],\n",
    "             'init_mode': ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Create Grid Search\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, n_jobs=1)\n",
    "grid_result = grid.fit(X, y,verbose=False)\n",
    "\n",
    "# Report Results\n",
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f\"Mean: {mean}, Stdev: {stdev} with: {param}\")"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nteract": {
   "version": "0.15.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
