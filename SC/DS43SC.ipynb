{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y6SKlgYrpcym"
   },
   "source": [
    "# Neural Networks Sprint Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BrEbRrjVphPM"
   },
   "source": [
    "## 1) Define the following terms:\n",
    "\n",
    "A neural network is a function between two vector spaces $V^{m} \\rightarrow V^{c}$ where $m$ is the number of features and $c$ is the cardinality of target.\n",
    "- Neuron\n",
    "\n",
    "A neuron is a function from a vector space to a scalar, it sums its inputs and applies an activation function which clips or normalizes it. \n",
    "\n",
    "- Input Layer\n",
    "\n",
    "An input layer is where you send observations, it has as many neurons as the number of features. \n",
    "\n",
    "- Hidden Layer\n",
    "\n",
    "A hidden layer can be of arbitary dimension. for layer length $w$ it transforms the neural net into a composite function $V^{m} \\rightarrow \n",
    "V^{w} \\rightarrow V^{w} \\rightarrow V^{c}$\n",
    "\n",
    "- Output Layer\n",
    "\n",
    "The output layer is your prediction vector. In multiclass problems, it's a matrix beyond just being a column. \n",
    "\n",
    "- Activation\n",
    "\n",
    "Activation can normalize values to probabilities (as in logistic regression) or clip them to just positive\n",
    "\n",
    "- Backpropagation\n",
    "\n",
    "Backpropagation updates weights, or the values in the matrices that represent your layers. It does this by iteratively nudging them closer to the goal, which is an accurate score. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ri_gRA2Jp728"
   },
   "source": [
    "## 2) Create a perceptron class that can model the behavior of an AND gate. You can use the following table as your training data:\n",
    "\n",
    "| x1 | x2 | x3 | y |\n",
    "|----|----|----|---|\n",
    "| 1  | 1  | 1  | 1 |\n",
    "| 1  | 0  | 1  | 0 |\n",
    "| 0  | 1  | 1  | 0 |\n",
    "| 0  | 0  | 1  | 0 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New pandarallel memory created - Size: 2000 MB\n",
      "Pandarallel will run on 4 workers\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import category_encoders as ce\n",
    "import keras\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize()\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "def squish(x: np.number) -> np.number: \n",
    "    return np.divide(1, 1 + np.exp(-x))\n",
    "\n",
    "def del_squish(x: np.number) -> np.number: \n",
    "    s = squish(x)\n",
    "    return s * (1 - s)\n",
    "\n",
    "def relu(x): \n",
    "    if x < 0: \n",
    "        return 0\n",
    "    else: \n",
    "        return x\n",
    "\n",
    "\n",
    "def b(x: np.number) -> np.number: \n",
    "    ''' such that b after/composed sigmoid === derivative of sigmoid. '''\n",
    "    return x * (1 - x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ig6ZTH8tpQ19"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 0, 0]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([[1,1,1], [1,0,1], [0,1,1], [0,0,1]])\n",
    "y = np.array([[1],[0],[0],[0]])\n",
    "\n",
    "class Perceptron: \n",
    "    def __init__(self, X, y): \n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.inputs = X.shape[1]\n",
    "        self.weights = np.array([1,1,-1])\n",
    "        self.prediction = [self.relu(x) for x in self.X @ self.weights]\n",
    "    \n",
    "    def relu(self, x): \n",
    "        if x < 0: \n",
    "            return 0\n",
    "        else: \n",
    "            return x\n",
    "\n",
    "P = Perceptron(X, y)\n",
    "\n",
    "P.prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "86HyRi8Osr3U"
   },
   "source": [
    "## 3) Implement a Neural Network Multilayer Perceptron class that uses backpropagation to update the network's weights. \n",
    "- Your network must have one hidden layer. \n",
    "- You do not have to update weights via gradient descent. You can use something like the derivative of the sigmoid function to update weights.\n",
    "- Train your model on the Heart Disease dataset from UCI:\n",
    "\n",
    "[Github Dataset](https://github.com/ryanleeallred/datasets/blob/master/heart.csv)\n",
    "\n",
    "[Raw File on Github](https://raw.githubusercontent.com/ryanleeallred/datasets/master/heart.csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(303, 14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/quinn/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/quinn/anaconda3/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.952197</td>\n",
       "      <td>0.681005</td>\n",
       "      <td>1.973123</td>\n",
       "      <td>0.763956</td>\n",
       "      <td>-0.256334</td>\n",
       "      <td>2.394438</td>\n",
       "      <td>-1.005832</td>\n",
       "      <td>0.015443</td>\n",
       "      <td>-0.696631</td>\n",
       "      <td>1.087338</td>\n",
       "      <td>-2.274579</td>\n",
       "      <td>-0.714429</td>\n",
       "      <td>-2.148873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.915313</td>\n",
       "      <td>0.681005</td>\n",
       "      <td>1.002577</td>\n",
       "      <td>-0.092738</td>\n",
       "      <td>0.072199</td>\n",
       "      <td>-0.417635</td>\n",
       "      <td>0.898962</td>\n",
       "      <td>1.633471</td>\n",
       "      <td>-0.696631</td>\n",
       "      <td>2.122573</td>\n",
       "      <td>-2.274579</td>\n",
       "      <td>-0.714429</td>\n",
       "      <td>-0.512922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.474158</td>\n",
       "      <td>-1.468418</td>\n",
       "      <td>0.032031</td>\n",
       "      <td>-0.092738</td>\n",
       "      <td>-0.816773</td>\n",
       "      <td>-0.417635</td>\n",
       "      <td>-1.005832</td>\n",
       "      <td>0.977514</td>\n",
       "      <td>-0.696631</td>\n",
       "      <td>0.310912</td>\n",
       "      <td>0.976352</td>\n",
       "      <td>-0.714429</td>\n",
       "      <td>-0.512922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.180175</td>\n",
       "      <td>0.681005</td>\n",
       "      <td>0.032031</td>\n",
       "      <td>-0.663867</td>\n",
       "      <td>-0.198357</td>\n",
       "      <td>-0.417635</td>\n",
       "      <td>0.898962</td>\n",
       "      <td>1.239897</td>\n",
       "      <td>-0.696631</td>\n",
       "      <td>-0.206705</td>\n",
       "      <td>0.976352</td>\n",
       "      <td>-0.714429</td>\n",
       "      <td>-0.512922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.290464</td>\n",
       "      <td>-1.468418</td>\n",
       "      <td>-0.938515</td>\n",
       "      <td>-0.663867</td>\n",
       "      <td>2.082050</td>\n",
       "      <td>-0.417635</td>\n",
       "      <td>0.898962</td>\n",
       "      <td>0.583939</td>\n",
       "      <td>1.435481</td>\n",
       "      <td>-0.379244</td>\n",
       "      <td>0.976352</td>\n",
       "      <td>-0.714429</td>\n",
       "      <td>-0.512922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age       sex        cp  trestbps      chol       fbs   restecg  \\\n",
       "0  0.952197  0.681005  1.973123  0.763956 -0.256334  2.394438 -1.005832   \n",
       "1 -1.915313  0.681005  1.002577 -0.092738  0.072199 -0.417635  0.898962   \n",
       "2 -1.474158 -1.468418  0.032031 -0.092738 -0.816773 -0.417635 -1.005832   \n",
       "3  0.180175  0.681005  0.032031 -0.663867 -0.198357 -0.417635  0.898962   \n",
       "4  0.290464 -1.468418 -0.938515 -0.663867  2.082050 -0.417635  0.898962   \n",
       "\n",
       "    thalach     exang   oldpeak     slope        ca      thal  \n",
       "0  0.015443 -0.696631  1.087338 -2.274579 -0.714429 -2.148873  \n",
       "1  1.633471 -0.696631  2.122573 -2.274579 -0.714429 -0.512922  \n",
       "2  0.977514 -0.696631  0.310912  0.976352 -0.714429 -0.512922  \n",
       "3  1.239897 -0.696631 -0.206705  0.976352 -0.714429 -0.512922  \n",
       "4  0.583939  1.435481 -0.379244  0.976352 -0.714429 -0.512922  "
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean(dat): \n",
    "    assert dat.isna().sum().sum()==0\n",
    "    assert all([t.name in ['int64', 'float64'] for t in dat.dtypes])\n",
    "    print(dat.shape)\n",
    "    a = StandardScaler().fit_transform(dat.drop('target', axis=1))\n",
    "    return (pd.DataFrame(data=a, columns=dat.drop('target', axis=1).columns),\n",
    "           dat.target)\n",
    "\n",
    "X, y = clean(pd.read_csv(\"https://raw.githubusercontent.com/ryanleeallred/datasets/master/heart.csv\"))\n",
    "\n",
    "X.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CNfiajv3v4Ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tepoch 2 with MSSE loss 0.0\n",
      "\tepoch 3 with MSSE loss 0.0\n",
      "\tepoch 4 with MSSE loss 0.0\n",
      "\tepoch 5 with MSSE loss 0.0\n",
      "\tepoch 13 with MSSE loss 0.0\n",
      "\tepoch 24 with MSSE loss 0.0\n",
      "\tepoch 35 with MSSE loss 0.0\n",
      "\tepoch 46 with MSSE loss 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class NeuralNetwork: \n",
    "    def __init__(self, X, y): \n",
    "        self.X = X.values\n",
    "        self.y = y.values.reshape(-1,1)\n",
    "        self.inputs = X.shape[1]\n",
    "        self.hidden_1 = X.shape[1]\n",
    "        self.output_nodes = 1\n",
    "        # init weights: \n",
    "        self.L1_weights = np.random.randn(self.inputs, self.hidden_1)\n",
    "        self.L2_weights = np.random.randn(self.hidden_1, self.output_nodes)\n",
    "        self.predictions = self.refresh_ff()\n",
    "        \n",
    "    def feed_forward(self): \n",
    "        ''' matmul to produce predictions ''' \n",
    "        hidden_sum_1 = self.X @ self.L1_weights\n",
    "        self.activated_hidden_1 = np.clip(hidden_sum_1, a_min=0, a_max=None) # relu this layer\n",
    "        hidden_sum_2 = self.activated_hidden_1 @ self.L2_weights\n",
    "        self.activated_hidden_2 = squish(hidden_sum_2)\n",
    "        return self.activated_hidden_2\n",
    "\n",
    "    def refresh_ff(self): \n",
    "        ''' run this when weights are updated '''\n",
    "        prds = self.feed_forward()\n",
    "        self.predictions = prds\n",
    "        return prds\n",
    "    \n",
    "    def loss(self): \n",
    "        ''' mean squared error '''\n",
    "        self.refresh_ff()\n",
    "        n = len(self.y)\n",
    "        assert len(self.predictions)==n\n",
    "        #print(sum([Y for Y in (self.predictions - self.y)]))\n",
    "        return np.divide(sum([Y**2 for Y in (self.predictions - self.y)]), n)\n",
    "    \n",
    "    def back(self): \n",
    "        ''' will modify values of Lk_weights '''\n",
    "        predns = self.refresh_ff()\n",
    "        output_error = predns - self.y\n",
    "        del_output_error = output_error * b(predns)\n",
    "\n",
    "        s2_error = del_output_error @ self.L2_weights.T\n",
    "        del_s2_error = s2_error * b(self.activated_hidden_2)\n",
    "        \n",
    "        s1_error = del_s2_error @ self.L1_weights.T\n",
    "        del_s1_error = s1_error * b(self.activated_hidden_1)\n",
    "        \n",
    "        assert self.L1_weights.shape == (X.T @ del_s2_error).shape\n",
    "        assert self.L2_weights.shape == (self.activated_hidden_1.T @ del_output_error).shape\n",
    "        self.L1_weights = X.T @ del_s2_error\n",
    "        self.L2_weights = self.activated_hidden_1.T @ del_output_error\n",
    "        pass\n",
    "    \n",
    "def report(N: NeuralNetwork) -> str: \n",
    "    s = ''\n",
    "    ls = {}\n",
    "    for epoch in range(50): \n",
    "        N.back()\n",
    "        if epoch%11==0 or epoch in [1,2,3]: \n",
    "            ls[epoch+1] = N.loss()\n",
    "\n",
    "    for k,v in ls.items(): \n",
    "        s += f\"\\tepoch {k+1} with MSSE loss {v}\\n\"\n",
    "    return s\n",
    "\n",
    "print(report(NeuralNetwork(X,y)))\n",
    "\n",
    "#NN = NeuralNetwork(X,y)\n",
    "\n",
    "# NN = NeuralNetwork(X,y)\n",
    "# for _ in range(3): \n",
    "#     NN.back()\n",
    "\n",
    "# print(NN.predictions.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WARNING: Hypothesis: loss goes too low too quickly, it's numerically unstable! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GGT1oRzXw3H9"
   },
   "source": [
    "## 4) Implement a Multilayer Perceptron architecture of your choosing using the Keras library. Train your model and report its baseline accuracy. Then hyperparameter tune at least two parameters and report your model's accuracy. \n",
    "\n",
    "- Use the Heart Disease Dataset (binary classification)\n",
    "- Use an appropriate loss function for a binary classification task\n",
    "- Use an appropriate activation function on the final layer of your network. \n",
    "- Train your model using verbose output for ease of grading.\n",
    "- Use GridSearchCV to hyperparameter tune your model. (for at least two hyperparameters)\n",
    "- When hyperparameter tuning, show you work by adding code cells for each new experiment. \n",
    "- Report the accuracy for each combination of hyperparameters as you test them so that we can easily see which resulted in the highest accuracy.\n",
    "- You must hyperparameter tune at least 5 parameters in order to get a 3 on this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XWw4IYxLxKwH"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.952197</td>\n",
       "      <td>0.681005</td>\n",
       "      <td>1.973123</td>\n",
       "      <td>0.763956</td>\n",
       "      <td>-0.256334</td>\n",
       "      <td>2.394438</td>\n",
       "      <td>-1.005832</td>\n",
       "      <td>0.015443</td>\n",
       "      <td>-0.696631</td>\n",
       "      <td>1.087338</td>\n",
       "      <td>-2.274579</td>\n",
       "      <td>-0.714429</td>\n",
       "      <td>-2.148873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.915313</td>\n",
       "      <td>0.681005</td>\n",
       "      <td>1.002577</td>\n",
       "      <td>-0.092738</td>\n",
       "      <td>0.072199</td>\n",
       "      <td>-0.417635</td>\n",
       "      <td>0.898962</td>\n",
       "      <td>1.633471</td>\n",
       "      <td>-0.696631</td>\n",
       "      <td>2.122573</td>\n",
       "      <td>-2.274579</td>\n",
       "      <td>-0.714429</td>\n",
       "      <td>-0.512922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.474158</td>\n",
       "      <td>-1.468418</td>\n",
       "      <td>0.032031</td>\n",
       "      <td>-0.092738</td>\n",
       "      <td>-0.816773</td>\n",
       "      <td>-0.417635</td>\n",
       "      <td>-1.005832</td>\n",
       "      <td>0.977514</td>\n",
       "      <td>-0.696631</td>\n",
       "      <td>0.310912</td>\n",
       "      <td>0.976352</td>\n",
       "      <td>-0.714429</td>\n",
       "      <td>-0.512922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.180175</td>\n",
       "      <td>0.681005</td>\n",
       "      <td>0.032031</td>\n",
       "      <td>-0.663867</td>\n",
       "      <td>-0.198357</td>\n",
       "      <td>-0.417635</td>\n",
       "      <td>0.898962</td>\n",
       "      <td>1.239897</td>\n",
       "      <td>-0.696631</td>\n",
       "      <td>-0.206705</td>\n",
       "      <td>0.976352</td>\n",
       "      <td>-0.714429</td>\n",
       "      <td>-0.512922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.290464</td>\n",
       "      <td>-1.468418</td>\n",
       "      <td>-0.938515</td>\n",
       "      <td>-0.663867</td>\n",
       "      <td>2.082050</td>\n",
       "      <td>-0.417635</td>\n",
       "      <td>0.898962</td>\n",
       "      <td>0.583939</td>\n",
       "      <td>1.435481</td>\n",
       "      <td>-0.379244</td>\n",
       "      <td>0.976352</td>\n",
       "      <td>-0.714429</td>\n",
       "      <td>-0.512922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age       sex        cp  trestbps      chol       fbs   restecg  \\\n",
       "0  0.952197  0.681005  1.973123  0.763956 -0.256334  2.394438 -1.005832   \n",
       "1 -1.915313  0.681005  1.002577 -0.092738  0.072199 -0.417635  0.898962   \n",
       "2 -1.474158 -1.468418  0.032031 -0.092738 -0.816773 -0.417635 -1.005832   \n",
       "3  0.180175  0.681005  0.032031 -0.663867 -0.198357 -0.417635  0.898962   \n",
       "4  0.290464 -1.468418 -0.938515 -0.663867  2.082050 -0.417635  0.898962   \n",
       "\n",
       "    thalach     exang   oldpeak     slope        ca      thal  \n",
       "0  0.015443 -0.696631  1.087338 -2.274579 -0.714429 -2.148873  \n",
       "1  1.633471 -0.696631  2.122573 -2.274579 -0.714429 -0.512922  \n",
       "2  0.977514 -0.696631  0.310912  0.976352 -0.714429 -0.512922  \n",
       "3  1.239897 -0.696631 -0.206705  0.976352 -0.714429 -0.512922  \n",
       "4  0.583939  1.435481 -0.379244  0.976352 -0.714429 -0.512922  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 203 samples, validate on 100 samples\n",
      "Epoch 1/22\n",
      "203/203 [==============================] - 1s 4ms/step - loss: 0.1617 - mean_squared_error: 0.1617 - val_loss: 0.7468 - val_mean_squared_error: 0.7468\n",
      "Epoch 2/22\n",
      "203/203 [==============================] - 0s 122us/step - loss: 0.1188 - mean_squared_error: 0.1188 - val_loss: 0.4114 - val_mean_squared_error: 0.4114\n",
      "Epoch 3/22\n",
      "203/203 [==============================] - 0s 145us/step - loss: 0.0992 - mean_squared_error: 0.0992 - val_loss: 0.4060 - val_mean_squared_error: 0.4060\n",
      "Epoch 4/22\n",
      "203/203 [==============================] - 0s 117us/step - loss: 0.0892 - mean_squared_error: 0.0892 - val_loss: 0.2869 - val_mean_squared_error: 0.2869\n",
      "Epoch 5/22\n",
      "203/203 [==============================] - 0s 160us/step - loss: 0.0784 - mean_squared_error: 0.0784 - val_loss: 0.3524 - val_mean_squared_error: 0.3524\n",
      "Epoch 6/22\n",
      "203/203 [==============================] - 0s 158us/step - loss: 0.0721 - mean_squared_error: 0.0721 - val_loss: 0.3031 - val_mean_squared_error: 0.3031\n",
      "Epoch 7/22\n",
      "203/203 [==============================] - 0s 154us/step - loss: 0.0670 - mean_squared_error: 0.0670 - val_loss: 0.3227 - val_mean_squared_error: 0.3227\n",
      "Epoch 8/22\n",
      "203/203 [==============================] - 0s 129us/step - loss: 0.0619 - mean_squared_error: 0.0619 - val_loss: 0.3174 - val_mean_squared_error: 0.3174\n",
      "Epoch 9/22\n",
      "203/203 [==============================] - 0s 123us/step - loss: 0.0577 - mean_squared_error: 0.0577 - val_loss: 0.3211 - val_mean_squared_error: 0.3211\n",
      "Epoch 10/22\n",
      "203/203 [==============================] - 0s 149us/step - loss: 0.0546 - mean_squared_error: 0.0546 - val_loss: 0.2887 - val_mean_squared_error: 0.2887\n",
      "Epoch 11/22\n",
      "203/203 [==============================] - 0s 140us/step - loss: 0.0517 - mean_squared_error: 0.0517 - val_loss: 0.3372 - val_mean_squared_error: 0.3372\n",
      "Epoch 12/22\n",
      "203/203 [==============================] - 0s 141us/step - loss: 0.0482 - mean_squared_error: 0.0482 - val_loss: 0.2953 - val_mean_squared_error: 0.2953\n",
      "Epoch 13/22\n",
      "203/203 [==============================] - 0s 125us/step - loss: 0.0456 - mean_squared_error: 0.0456 - val_loss: 0.3127 - val_mean_squared_error: 0.3127\n",
      "Epoch 14/22\n",
      "203/203 [==============================] - 0s 123us/step - loss: 0.0424 - mean_squared_error: 0.0424 - val_loss: 0.3038 - val_mean_squared_error: 0.3038\n",
      "Epoch 15/22\n",
      "203/203 [==============================] - 0s 162us/step - loss: 0.0397 - mean_squared_error: 0.0397 - val_loss: 0.3215 - val_mean_squared_error: 0.3215\n",
      "Epoch 16/22\n",
      "203/203 [==============================] - 0s 131us/step - loss: 0.0365 - mean_squared_error: 0.0365 - val_loss: 0.3242 - val_mean_squared_error: 0.3242\n",
      "Epoch 17/22\n",
      "203/203 [==============================] - 0s 127us/step - loss: 0.0344 - mean_squared_error: 0.0344 - val_loss: 0.3065 - val_mean_squared_error: 0.3065\n",
      "Epoch 18/22\n",
      "203/203 [==============================] - 0s 150us/step - loss: 0.0335 - mean_squared_error: 0.0335 - val_loss: 0.3469 - val_mean_squared_error: 0.3469\n",
      "Epoch 19/22\n",
      "203/203 [==============================] - 0s 149us/step - loss: 0.0310 - mean_squared_error: 0.0310 - val_loss: 0.3201 - val_mean_squared_error: 0.3201\n",
      "Epoch 20/22\n",
      "203/203 [==============================] - 0s 147us/step - loss: 0.0290 - mean_squared_error: 0.0290 - val_loss: 0.3090 - val_mean_squared_error: 0.3090\n",
      "Epoch 21/22\n",
      "203/203 [==============================] - 0s 155us/step - loss: 0.0266 - mean_squared_error: 0.0266 - val_loss: 0.2854 - val_mean_squared_error: 0.2854\n",
      "Epoch 22/22\n",
      "203/203 [==============================] - 0s 168us/step - loss: 0.0256 - mean_squared_error: 0.0256 - val_loss: 0.2921 - val_mean_squared_error: 0.2921\n",
      "303/303 [==============================] - 0s 36us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.11190128532966764, 0.11190128532966764]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Important Hyperparameters\n",
    "inputs = X.shape[1]\n",
    "epochs = 22\n",
    "batch_size = 16\n",
    "\n",
    "# Create Model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(inputs,)))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(64, activation='sigmoid'))\n",
    "model.add(Dense(1))\n",
    "# Compile Model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "# Fit Model\n",
    "model.fit(X, y, validation_split=0.33, epochs=epochs, batch_size=batch_size, verbose=1)\n",
    "\n",
    "model.evaluate(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "DS43SC.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
