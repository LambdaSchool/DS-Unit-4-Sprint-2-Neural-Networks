{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New pandarallel memory created - Size: 2000 MB\n",
      "Pandarallel will run on 4 workers\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import category_encoders as ce\n",
    "import keras\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize()\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "def squish(x: np.number) -> np.number: \n",
    "    return np.divide(1, 1 + np.exp(-x))\n",
    "\n",
    "def del_squish(x: np.number) -> np.number: \n",
    "    s = squish(x)\n",
    "    return s * (1 - s)\n",
    "\n",
    "def relu(x): \n",
    "    if x < 0: \n",
    "        return 0\n",
    "    else: \n",
    "        return x\n",
    "\n",
    "def b(x: np.number) -> np.number: \n",
    "    ''' such that b after/composed sigmoid === derivative of sigmoid. '''\n",
    "    return x * (1 - x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y6SKlgYrpcym"
   },
   "source": [
    "# Neural Networks Sprint Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BrEbRrjVphPM"
   },
   "source": [
    "## 1) Define the following terms:\n",
    "\n",
    "A neural network is a function between two vector spaces $V^{m} \\rightarrow V^{c}$ where $m$ is the number of features and $c$ is the cardinality of target.\n",
    "- Neuron\n",
    "\n",
    "A neuron is a function from a vector space to a scalar, it sums its inputs and applies an _activation function_ which clips or normalizes it. For your selection of _activation function_ $f$, $neur = [x_1, ..., x_n] \\mapsto f(\\Sigma_{k=1}^{n}x_k) : V^{n} \\rightarrow \\mathbb{R}$, where the vector $x$ is output of a matrix multiplication fed to it by it's preceding edges \n",
    "\n",
    "- Input Layer\n",
    "\n",
    "An input layer is where you send observations, it has as many neurons as the number of features. \n",
    "\n",
    "- Hidden Layer\n",
    "\n",
    "A hidden layer can be of arbitary dimension. for layer length $w$ it transforms the neural net into a composite function $V^{m} \\rightarrow \n",
    "V^{w} \\rightarrow V^{w} \\rightarrow V^{c}$. In matrix terms, it's almost as if it \"decomposes\" the matrix $N$ a multiplication of more matrices. \n",
    "\n",
    "- Output Layer\n",
    "\n",
    "The output layer is your prediction vector. In multiclass problems, it's a matrix of arbitrary dimension. in 2-targeted problems (including regressions), it's equivalent to a column vector. \n",
    "\n",
    "- Activation\n",
    "\n",
    "Activation can normalize values to probabilities (as in logistic regression) or clip them to just positive. These are the two most common (sigmoid and relu, respectively), but you can play with tons of different ideas. \n",
    "\n",
    "- Backpropagation\n",
    "\n",
    "Backpropagation updates weights, or the values in the matrices that represent your layers. It does this by iteratively nudging them closer to the goal, which is an accurate score. It's based on the idea that the neural network is a composite function/matrix, and observing the behavior of the _chain rule_ on it--- you update from the end toward the beginning, sending information through each step of the way. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ri_gRA2Jp728"
   },
   "source": [
    "## 2) Create a perceptron class that can model the behavior of an AND gate. You can use the following table as your training data:\n",
    "\n",
    "| x1 | x2 | x3 | y |\n",
    "|----|----|----|---|\n",
    "| 1  | 1  | 1  | 1 |\n",
    "| 1  | 0  | 1  | 0 |\n",
    "| 0  | 1  | 1  | 0 |\n",
    "| 0  | 0  | 1  | 0 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ig6ZTH8tpQ19"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 0, 0]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([[1,1,1], [1,0,1], [0,1,1], [0,0,1]])\n",
    "y = np.array([[1],[0],[0],[0]])\n",
    "\n",
    "class Perceptron: \n",
    "    def __init__(self, X, y): \n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.inputs = X.shape[1]\n",
    "        self.weights = np.array([1,1,-1])\n",
    "        self.prediction = [self.relu(x) for x in self.X @ self.weights]\n",
    "    \n",
    "    def relu(self, x): \n",
    "        if x < 0: \n",
    "            return 0\n",
    "        else: \n",
    "            return x\n",
    "\n",
    "P = Perceptron(X, y)\n",
    "\n",
    "P.prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "86HyRi8Osr3U"
   },
   "source": [
    "## 3) Implement a Neural Network Multilayer Perceptron class that uses backpropagation to update the network's weights. \n",
    "- Your network must have one hidden layer. \n",
    "- You do not have to update weights via gradient descent. You can use something like the derivative of the sigmoid function to update weights.\n",
    "- Train your model on the Heart Disease dataset from UCI:\n",
    "\n",
    "[Github Dataset](https://github.com/ryanleeallred/datasets/blob/master/heart.csv)\n",
    "\n",
    "[Raw File on Github](https://raw.githubusercontent.com/ryanleeallred/datasets/master/heart.csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(303, 14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/quinn/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/quinn/anaconda3/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.952197</td>\n",
       "      <td>0.681005</td>\n",
       "      <td>1.973123</td>\n",
       "      <td>0.763956</td>\n",
       "      <td>-0.256334</td>\n",
       "      <td>2.394438</td>\n",
       "      <td>-1.005832</td>\n",
       "      <td>0.015443</td>\n",
       "      <td>-0.696631</td>\n",
       "      <td>1.087338</td>\n",
       "      <td>-2.274579</td>\n",
       "      <td>-0.714429</td>\n",
       "      <td>-2.148873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.915313</td>\n",
       "      <td>0.681005</td>\n",
       "      <td>1.002577</td>\n",
       "      <td>-0.092738</td>\n",
       "      <td>0.072199</td>\n",
       "      <td>-0.417635</td>\n",
       "      <td>0.898962</td>\n",
       "      <td>1.633471</td>\n",
       "      <td>-0.696631</td>\n",
       "      <td>2.122573</td>\n",
       "      <td>-2.274579</td>\n",
       "      <td>-0.714429</td>\n",
       "      <td>-0.512922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.474158</td>\n",
       "      <td>-1.468418</td>\n",
       "      <td>0.032031</td>\n",
       "      <td>-0.092738</td>\n",
       "      <td>-0.816773</td>\n",
       "      <td>-0.417635</td>\n",
       "      <td>-1.005832</td>\n",
       "      <td>0.977514</td>\n",
       "      <td>-0.696631</td>\n",
       "      <td>0.310912</td>\n",
       "      <td>0.976352</td>\n",
       "      <td>-0.714429</td>\n",
       "      <td>-0.512922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.180175</td>\n",
       "      <td>0.681005</td>\n",
       "      <td>0.032031</td>\n",
       "      <td>-0.663867</td>\n",
       "      <td>-0.198357</td>\n",
       "      <td>-0.417635</td>\n",
       "      <td>0.898962</td>\n",
       "      <td>1.239897</td>\n",
       "      <td>-0.696631</td>\n",
       "      <td>-0.206705</td>\n",
       "      <td>0.976352</td>\n",
       "      <td>-0.714429</td>\n",
       "      <td>-0.512922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.290464</td>\n",
       "      <td>-1.468418</td>\n",
       "      <td>-0.938515</td>\n",
       "      <td>-0.663867</td>\n",
       "      <td>2.082050</td>\n",
       "      <td>-0.417635</td>\n",
       "      <td>0.898962</td>\n",
       "      <td>0.583939</td>\n",
       "      <td>1.435481</td>\n",
       "      <td>-0.379244</td>\n",
       "      <td>0.976352</td>\n",
       "      <td>-0.714429</td>\n",
       "      <td>-0.512922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age       sex        cp  trestbps      chol       fbs   restecg  \\\n",
       "0  0.952197  0.681005  1.973123  0.763956 -0.256334  2.394438 -1.005832   \n",
       "1 -1.915313  0.681005  1.002577 -0.092738  0.072199 -0.417635  0.898962   \n",
       "2 -1.474158 -1.468418  0.032031 -0.092738 -0.816773 -0.417635 -1.005832   \n",
       "3  0.180175  0.681005  0.032031 -0.663867 -0.198357 -0.417635  0.898962   \n",
       "4  0.290464 -1.468418 -0.938515 -0.663867  2.082050 -0.417635  0.898962   \n",
       "\n",
       "    thalach     exang   oldpeak     slope        ca      thal  \n",
       "0  0.015443 -0.696631  1.087338 -2.274579 -0.714429 -2.148873  \n",
       "1  1.633471 -0.696631  2.122573 -2.274579 -0.714429 -0.512922  \n",
       "2  0.977514 -0.696631  0.310912  0.976352 -0.714429 -0.512922  \n",
       "3  1.239897 -0.696631 -0.206705  0.976352 -0.714429 -0.512922  \n",
       "4  0.583939  1.435481 -0.379244  0.976352 -0.714429 -0.512922  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean(dat): \n",
    "    assert dat.isna().sum().sum()==0\n",
    "    assert all([t.name in ['int64', 'float64'] for t in dat.dtypes])\n",
    "    print(dat.shape)\n",
    "    a = StandardScaler().fit_transform(dat.drop('target', axis=1))\n",
    "    return (pd.DataFrame(data=a, columns=dat.drop('target', axis=1).columns),\n",
    "           dat.target)\n",
    "\n",
    "X, y = clean(pd.read_csv(\"https://raw.githubusercontent.com/ryanleeallred/datasets/master/heart.csv\"))\n",
    "\n",
    "X.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CNfiajv3v4Ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tepoch 2 with MSSE loss 0.0\n",
      "\tepoch 3 with MSSE loss 0.0\n",
      "\tepoch 4 with MSSE loss 0.0\n",
      "\tepoch 5 with MSSE loss 0.0\n",
      "\tepoch 13 with MSSE loss 0.0\n",
      "\tepoch 24 with MSSE loss 0.0\n",
      "\tepoch 35 with MSSE loss 0.0\n",
      "\tepoch 46 with MSSE loss 0.0\n",
      "\n",
      "\n",
      "\n",
      "\t-----TESTING EARLY EPOCHS\n",
      "[[0.99924748]\n",
      " [0.12804186]\n",
      " [0.9696781 ]\n",
      " [0.65310602]\n",
      " [0.92010235]]\n",
      "              0\n",
      "0  5.355302e-08\n",
      "1  2.075819e-10\n",
      "2  6.454704e-12\n",
      "3  1.671034e-07\n",
      "4  1.033748e-01\n",
      "    0\n",
      "0 NaN\n",
      "1 NaN\n",
      "2 NaN\n",
      "3 NaN\n",
      "4 NaN\n"
     ]
    }
   ],
   "source": [
    "class NeuralNetwork: \n",
    "    def __init__(self, X, y): \n",
    "        self.X = X.values\n",
    "        self.y = y.values.reshape(-1,1)\n",
    "        self.inputs = X.shape[1]\n",
    "        self.hidden_1 = X.shape[1]\n",
    "        self.output_nodes = 1\n",
    "        # init weights: \n",
    "        self.L1_weights = np.random.randn(self.inputs, self.hidden_1)\n",
    "        self.L2_weights = np.random.randn(self.hidden_1, self.output_nodes)\n",
    "        self.predictions = self.refresh_ff()\n",
    "        \n",
    "    def feed_forward(self): \n",
    "        ''' matmul to produce predictions ''' \n",
    "        hidden_sum_1 = self.X @ self.L1_weights\n",
    "        self.activated_hidden_1 = np.clip(hidden_sum_1, a_min=0, a_max=None) # relu this layer\n",
    "        hidden_sum_2 = self.activated_hidden_1 @ self.L2_weights\n",
    "        self.activated_hidden_2 = squish(hidden_sum_2)\n",
    "        return self.activated_hidden_2\n",
    "\n",
    "    def refresh_ff(self): \n",
    "        ''' run this when weights are updated '''\n",
    "        prds = self.feed_forward()\n",
    "        self.predictions = prds\n",
    "        return prds\n",
    "    \n",
    "    def loss(self): \n",
    "        ''' mean squared error '''\n",
    "        self.refresh_ff()\n",
    "        n = len(self.y)\n",
    "        assert len(self.predictions)==n\n",
    "        #print(sum([Y for Y in (self.predictions - self.y)]))\n",
    "        return np.divide(sum([Y**2 for Y in (self.predictions - self.y)]), n)\n",
    "    \n",
    "    def back(self): \n",
    "        ''' will modify values of Lk_weights '''\n",
    "        predns = self.refresh_ff()\n",
    "        output_error = predns - self.y\n",
    "        del_output_error = output_error * b(predns)\n",
    "\n",
    "        s2_error = del_output_error @ self.L2_weights.T\n",
    "        del_s2_error = s2_error * b(self.activated_hidden_2)\n",
    "        \n",
    "        s1_error = del_s2_error @ self.L1_weights.T\n",
    "        del_s1_error = s1_error * b(self.activated_hidden_1)\n",
    "        \n",
    "        assert self.L1_weights.shape == (X.T @ del_s2_error).shape\n",
    "        assert self.L2_weights.shape == (self.activated_hidden_1.T @ del_output_error).shape\n",
    "        self.L1_weights = X.T @ del_s2_error\n",
    "        self.L2_weights = self.activated_hidden_1.T @ del_output_error\n",
    "        pass\n",
    "    \n",
    "def report(N: NeuralNetwork) -> str: \n",
    "    s = ''\n",
    "    ls = {}\n",
    "    for epoch in range(50): \n",
    "        N.back()\n",
    "        if epoch%11==0 or epoch in [1,2,3]: \n",
    "            ls[epoch+1] = N.loss()\n",
    "\n",
    "    for k,v in ls.items(): \n",
    "        s += f\"\\tepoch {k+1} with MSSE loss {v}\\n\"\n",
    "    return s\n",
    "\n",
    "print(report(NeuralNetwork(X,y)))\n",
    "\n",
    "print(\"\\n\\n\\t-----TESTING EARLY EPOCHS\")\n",
    "\n",
    "NN = NeuralNetwork(X,y)\n",
    "for _ in range(4): \n",
    "    NN.back()\n",
    "    print(NN.predictions[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WARNING: Hypothesis: loss goes too low too quickly, it's numerically unstable! \n",
    "\n",
    "You can see that at the second epoch, my predictions are unreasonably close to 0--- the next step, they go _quantum zero_ like the Mrs. Pym (a reference to Ant Man and Ant Man & the Wasp). \n",
    "\n",
    "The NaN's don't propagate, so the loss function just reports them as zero. \n",
    "\n",
    "But the predictions zeroing out might be a sign that i need higher decimal precision, or more careful scaling/standardzing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XWw4IYxLxKwH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S\n",
      "E\n",
      "E\n",
      " \n",
      "P\n",
      "A\n",
      "R\n",
      "t\n",
      "4\n",
      ".\n",
      "i\n",
      "p\n",
      "y\n",
      "n\n",
      "b\n",
      " \n",
      "F\n",
      "I\n",
      "L\n",
      "E\n",
      " \n",
      "I\n",
      "N\n",
      " \n",
      "D\n",
      "I\n",
      "R\n"
     ]
    }
   ],
   "source": [
    "# see part4.ipynb, in this dir\n",
    "\n",
    "for c in \"SEE PARt4.ipynb FILE IN DIR\": \n",
    "    print(c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GGT1oRzXw3H9"
   },
   "source": [
    "## 4) Implement a Multilayer Perceptron architecture of your choosing using the Keras library. Train your model and report its baseline accuracy. Then hyperparameter tune at least two parameters and report your model's accuracy. \n",
    "\n",
    "- Use the Heart Disease Dataset (binary classification)\n",
    "- Use an appropriate loss function for a binary classification task\n",
    "- Use an appropriate activation function on the final layer of your network. \n",
    "- Train your model using verbose output for ease of grading.\n",
    "- Use GridSearchCV to hyperparameter tune your model. (for at least two hyperparameters)\n",
    "- When hyperparameter tuning, show you work by adding code cells for each new experiment. \n",
    "- Report the accuracy for each combination of hyperparameters as you test them so that we can easily see which resulted in the highest accuracy.\n",
    "- You must hyperparameter tune at least 5 parameters in order to get a 3 on this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XWw4IYxLxKwH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEE PARt4.ipynb FILE IN DIR\n"
     ]
    }
   ],
   "source": [
    "print(\"SEE PARt4.ipynb FILE IN DIR\")\n",
    "\n",
    "# see part4.ipynb, in this dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "DS43SC.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
