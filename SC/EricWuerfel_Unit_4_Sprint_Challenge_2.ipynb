{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2*\n",
    "\n",
    "# Sprint Challenge - Neural Network Foundations\n",
    "\n",
    "Table of Problems\n",
    "\n",
    "1. [Defining Neural Networks](#Q1)\n",
    "2. [Perceptron on XOR Gates](#Q2)\n",
    "3. [Multilayer Perceptron](#Q3)\n",
    "4. [Keras MMP](#Q4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Q1\"></a>\n",
    "## 1. Define the following terms:\n",
    "\n",
    "- **Neuron:** An individual node in a layer of a Neural Network. Each neuron sends the weighted sum of its inputs through an activation function. The output of a neuron is the value of the activation function.\n",
    "\n",
    "- **Input Layer:** The first layer of a Neural Network which takes the values of features as inputs.\n",
    "\n",
    "- **Hidden Layer:** Any layer between the input and output layer. These layers add complexity.\n",
    "\n",
    "- **Output Layer:** The final layer of a Neural Network which returns the output we're looking for.\n",
    "\n",
    "- **Activation:** The function that determines the final output of a Neuron. This is analogous to \"how much a Neuron fires\" in the brain.\n",
    "\n",
    "- **Backpropagation:** The process by which weights in the Neural Network are adjusted.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Perceptron on XOR Gates <a id=\"Q3=2\"></a>\n",
    "\n",
    "Create a perceptron class that can model the behavior of an AND gate. You can use the following table as your training data:\n",
    "\n",
    "|x1\t|x2|x3|\ty|\n",
    "|---|---|---|---|\n",
    "1|\t1|\t1|\t1|\n",
    "1|\t0|\t1|\t0|\n",
    "0|\t1|\t1|\t0|\n",
    "0|\t0|\t1|\t0|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set the input and output\n",
    "inputs = np.array([\n",
    "    [1, 1, 1],\n",
    "    [1, 0, 1],\n",
    "    [0, 1, 1],\n",
    "    [0, 0, 1]\n",
    "])\n",
    "\n",
    "correct_outputs = [[1], [0], [0], [0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the activation function & derivative\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Derivative of sigmoid\n",
    "def sigmoid_derivative(x):\n",
    "    sx = sigmoid(x)\n",
    "    return sx * (1-sx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.25091976],\n",
       "       [ 0.90142861],\n",
       "       [ 0.46398788]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep weights bounded [-1, 1]\n",
    "weights = 2 * np.random.random((3, 1)) - 1\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output after Training:\n",
      "[[9.96429406e-01]\n",
      " [2.00908516e-03]\n",
      " [2.00908516e-03]\n",
      " [1.45223694e-08]]\n"
     ]
    }
   ],
   "source": [
    "# trian for 10,000 epochs\n",
    "for iteration in range(10000):\n",
    "    # weighted sum\n",
    "    weighted_sum = np.dot(inputs, weights)\n",
    "    \n",
    "    # Activate using Sigmoid\n",
    "    activated_output = sigmoid(weighted_sum)\n",
    "    \n",
    "    # Errors & Adjustments\n",
    "    error = correct_outputs - activated_output\n",
    "    adjustments = error * sigmoid_derivative(activated_output)\n",
    "    \n",
    "    # Update weights\n",
    "    weights += np.dot(inputs.T, adjustments)\n",
    "    \n",
    "print('Output after Training:')\n",
    "print(activated_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Multilayer Perceptron <a id=\"Q3\"></a>\n",
    "\n",
    "Implement a Neural Network Multilayer Perceptron class that uses backpropagation to update the network's weights.\n",
    "Your network must have one hidden layer.\n",
    "You do not have to update weights via gradient descent. You can use something like the derivative of the sigmoid function to update weights.\n",
    "Train your model on the Heart Disease dataset from UCI:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(303, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>112</td>\n",
       "      <td>230</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>165</td>\n",
       "      <td>0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>110</td>\n",
       "      <td>265</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>94</td>\n",
       "      <td>199</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>179</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>288</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>159</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>135</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "183   58    1   2       112   230    0        0      165      0      2.5   \n",
       "60    71    0   2       110   265    1        0      130      0      0.0   \n",
       "124   39    0   2        94   199    0        1      179      0      0.0   \n",
       "93    54    0   1       132   288    1        0      159      1      0.0   \n",
       "63    41    1   1       135   203    0        1      132      0      0.0   \n",
       "\n",
       "     slope  ca  thal  target  \n",
       "183      1   1     3       0  \n",
       "60       2   1     2       1  \n",
       "124      2   0     2       1  \n",
       "93       2   1     2       1  \n",
       "63       1   0     1       1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/ryanleeallred/datasets/master/heart.csv')\n",
    "df = df.sample(frac=1)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "# Select Features & train_test split\n",
    "features = df.columns.tolist()[0:13]\n",
    "target = df.columns.tolist()[13]\n",
    "\n",
    "# Split by features & target\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# Instantiate scaler\n",
    "scaler = StandardScaler()\n",
    "# Normalize X\n",
    "X = pd.DataFrame(scaler.fit_transform(X), columns = features)\n",
    "\n",
    "# Train/Test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(242, 13)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(61, 13)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP:\n",
    "    def __init__(self):\n",
    "        # Set up Architecture\n",
    "        self.inputs = 13\n",
    "        self.hiddenNodes = 4\n",
    "        self.output = 1\n",
    "        \n",
    "        # Initialize Weights\n",
    "        self.weights1 = np.random.rand(self.inputs, self.hiddenNodes)\n",
    "        self.weights2 = np.random.rand(self.hiddenNodes, self.output)\n",
    "        \n",
    "    # Define the activation function & derivative\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    # Derivative of sigmoid\n",
    "    def sigmoid_derivative(self, x):\n",
    "        sx = self.sigmoid(x)\n",
    "        return sx * (1-sx)\n",
    "    \n",
    "    # Forward Propogation\n",
    "    def feed_forward(self, X):\n",
    "        # Activation of Weighted Sum\n",
    "        self.hidden_sum = np.dot(X, self.weights1)\n",
    "        self.activated_hidden = self.sigmoid(self.hidden_sum)\n",
    "        \n",
    "        # Next Layer\n",
    "        self.output_sum = np.dot(self.activated_hidden, self.weights2)\n",
    "        self.activated_output = self.sigmoid(self.output_sum)\n",
    "        \n",
    "        return self.activated_output\n",
    "    \n",
    "    # Backward Propagation\n",
    "    def feed_backward(self, X, y, y_pred):\n",
    "        # Output --> Hidden\n",
    "        self.output_error = y.values - y_pred\n",
    "        self.output_delta = self.output_error.dot(self.sigmoid_derivative(y_pred))\n",
    "        \n",
    "        # Hidden --> Input\n",
    "        self.input_error = self.output_delta.dot(self.weights2.T)\n",
    "        self.input_delta = self.input_error*self.sigmoid_derivative(self.activated_hidden)\n",
    "        \n",
    "        # Update Weights\n",
    "        self.weights1 += X.T.dot(self.input_delta)\n",
    "        self.weights2 += self.activated_hidden.T.dot(self.output_delta)\n",
    "        \n",
    "    # Train MLP\n",
    "    def train(self, X, y):\n",
    "        y_pred = self.feed_forward(X)\n",
    "        self.feed_backward(X, y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate MLP\n",
    "mlp = MLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = mlp.feed_forward(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------EPOCH 1---------+\n",
      "Accuracy: \n",
      " 0.5445544554455446\n",
      "+---------EPOCH 2---------+\n",
      "Accuracy: \n",
      " 0.45544554455445546\n",
      "+---------EPOCH 3---------+\n",
      "Accuracy: \n",
      " 0.5436721889970403\n",
      "+---------EPOCH 4---------+\n",
      "Accuracy: \n",
      " 0.45544554455445546\n",
      "+---------EPOCH 5---------+\n",
      "Accuracy: \n",
      " 0.45544554455445546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:14: RuntimeWarning: overflow encountered in exp\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------EPOCH 1000---------+\n",
      "Accuracy: \n",
      " 0.5269091217242975\n",
      "+---------EPOCH 2000---------+\n",
      "Accuracy: \n",
      " 0.45544554455445546\n",
      "+---------EPOCH 3000---------+\n",
      "Accuracy: \n",
      " 0.5445544554455446\n",
      "+---------EPOCH 4000---------+\n",
      "Accuracy: \n",
      " 0.5442603666434658\n",
      "+---------EPOCH 5000---------+\n",
      "Accuracy: \n",
      " 0.45544554455445546\n",
      "+---------EPOCH 6000---------+\n",
      "Accuracy: \n",
      " 0.5330849916674836\n",
      "+---------EPOCH 7000---------+\n",
      "Accuracy: \n",
      " 0.45544554455445546\n",
      "+---------EPOCH 8000---------+\n",
      "Accuracy: \n",
      " 0.523085962982914\n",
      "+---------EPOCH 9000---------+\n",
      "Accuracy: \n",
      " 0.4555925889618665\n",
      "+---------EPOCH 10000---------+\n",
      "Accuracy: \n",
      " 0.45544554455445546\n"
     ]
    }
   ],
   "source": [
    "# Set number of Epochs\n",
    "for i in range(10000):\n",
    "    if (i+1 in [1,2,3,4,5]) or ((i+1) % 1000 ==0):\n",
    "        print('+' + '---' * 3 + f'EPOCH {i+1}' + '---'*3 + '+')\n",
    "        print(\"Accuracy: \\n\", str(((abs(y.values - mlp.feed_forward(X)).sum()) / (303 * 303))))\n",
    "    mlp.train(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Keras MMP <a id=\"Q4\"></a>\n",
    "\n",
    "Implement a Multilayer Perceptron architecture of your choosing using the Keras library. Train your model and report its baseline accuracy. Then hyperparameter tune at least two parameters and report your model's accuracy.\n",
    "Use the Heart Disease Dataset (binary classification)\n",
    "Use an appropriate loss function for a binary classification task\n",
    "Use an appropriate activation function on the final layer of your network.\n",
    "Train your model using verbose output for ease of grading.\n",
    "Use GridSearchCV to hyperparameter tune your model. (for at least two hyperparameters)\n",
    "When hyperparameter tuning, show you work by adding code cells for each new experiment.\n",
    "Report the accuracy for each combination of hyperparameters as you test them so that we can easily see which resulted in the highest accuracy.\n",
    "You must hyperparameter tune at least 5 parameters in order to get a 3 on this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(303, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>134</td>\n",
       "      <td>409</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>138</td>\n",
       "      <td>223</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>177</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>160</td>\n",
       "      <td>234</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "246   56    0   0       134   409    0        0      150      1      1.9   \n",
       "92    52    1   2       138   223    0        1      169      0      0.0   \n",
       "149   42    1   2       130   180    0        1      150      0      0.0   \n",
       "178   43    1   0       120   177    0        0      120      1      2.5   \n",
       "106   69    1   3       160   234    1        0      131      0      0.1   \n",
       "\n",
       "     slope  ca  thal  target  \n",
       "246      1   2     3       0  \n",
       "92       2   4     2       1  \n",
       "149      2   0     2       1  \n",
       "178      1   0     3       0  \n",
       "106      1   1     2       1  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/ryanleeallred/datasets/master/heart.csv')\n",
    "df = df.sample(frac=1)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "# Select Features & train_test split\n",
    "features = df.columns.tolist()[0:13]\n",
    "target = df.columns.tolist()[13]\n",
    "\n",
    "# Split by features & target\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# Instantiate scaler\n",
    "scaler = StandardScaler()\n",
    "# Normalize X\n",
    "X = pd.DataFrame(scaler.fit_transform(X), columns = features)\n",
    "\n",
    "# Train/Test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(812)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model function for Keras Classifier\n",
    "def create_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=13, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/10\n",
      "242/242 [==============================] - 0s 416us/sample - loss: 0.6525 - acc: 0.6116\n",
      "Epoch 2/10\n",
      "242/242 [==============================] - 0s 160us/sample - loss: 0.6297 - acc: 0.6322\n",
      "Epoch 3/10\n",
      "242/242 [==============================] - 0s 97us/sample - loss: 0.6089 - acc: 0.6529\n",
      "Epoch 4/10\n",
      "242/242 [==============================] - 0s 106us/sample - loss: 0.5904 - acc: 0.6860\n",
      "Epoch 5/10\n",
      "242/242 [==============================] - 0s 76us/sample - loss: 0.5737 - acc: 0.7066\n",
      "Epoch 6/10\n",
      "242/242 [==============================] - 0s 125us/sample - loss: 0.5579 - acc: 0.7231\n",
      "Epoch 7/10\n",
      "242/242 [==============================] - 0s 157us/sample - loss: 0.5444 - acc: 0.7521\n",
      "Epoch 8/10\n",
      "242/242 [==============================] - 0s 130us/sample - loss: 0.5311 - acc: 0.7645\n",
      "Epoch 9/10\n",
      "242/242 [==============================] - 0s 140us/sample - loss: 0.5191 - acc: 0.7686\n",
      "Epoch 10/10\n",
      "242/242 [==============================] - 0s 44us/sample - loss: 0.5074 - acc: 0.7769\n",
      "61/61 [==============================] - 0s 586us/sample - loss: 0.5582 - acc: 0.7377\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5581578719811361, 0.73770493]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check baseline model stats\n",
    "model = create_model()\n",
    "\n",
    "# Fit\n",
    "model.fit(X_train, y_train, epochs=10)\n",
    "\n",
    "# Evaluate\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Baseline Accuracy: 67.21%**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune Batch Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define search params\n",
    "param_grid = {'batch_size': [10, 20, 40, 60, 80, 100],\n",
    "              'epochs': [10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "202/202 [==============================] - 0s 677us/sample - loss: 0.8241 - acc: 0.3317\n",
      "Epoch 2/10\n",
      "202/202 [==============================] - 0s 261us/sample - loss: 0.7757 - acc: 0.3812\n",
      "Epoch 3/10\n",
      "202/202 [==============================] - 0s 152us/sample - loss: 0.7327 - acc: 0.4604\n",
      "Epoch 4/10\n",
      "202/202 [==============================] - 0s 280us/sample - loss: 0.6950 - acc: 0.5446\n",
      "Epoch 5/10\n",
      "202/202 [==============================] - 0s 280us/sample - loss: 0.6621 - acc: 0.6337\n",
      "Epoch 6/10\n",
      "202/202 [==============================] - 0s 221us/sample - loss: 0.6294 - acc: 0.6832\n",
      "Epoch 7/10\n",
      "202/202 [==============================] - 0s 244us/sample - loss: 0.6003 - acc: 0.7327\n",
      "Epoch 8/10\n",
      "202/202 [==============================] - 0s 285us/sample - loss: 0.5728 - acc: 0.7673\n",
      "Epoch 9/10\n",
      "202/202 [==============================] - 0s 205us/sample - loss: 0.5471 - acc: 0.8069\n",
      "Epoch 10/10\n",
      "202/202 [==============================] - 0s 157us/sample - loss: 0.5229 - acc: 0.8119\n",
      "101/101 [==============================] - 0s 331us/sample - loss: 0.5460 - acc: 0.7723\n",
      "202/202 [==============================] - 0s 102us/sample - loss: 0.5098 - acc: 0.8168\n",
      "Epoch 1/10\n",
      "202/202 [==============================] - 0s 636us/sample - loss: 0.8124 - acc: 0.5050\n",
      "Epoch 2/10\n",
      "202/202 [==============================] - 0s 219us/sample - loss: 0.7425 - acc: 0.5594\n",
      "Epoch 3/10\n",
      "202/202 [==============================] - 0s 261us/sample - loss: 0.6839 - acc: 0.6436\n",
      "Epoch 4/10\n",
      "202/202 [==============================] - 0s 167us/sample - loss: 0.6357 - acc: 0.6733\n",
      "Epoch 5/10\n",
      "202/202 [==============================] - 0s 271us/sample - loss: 0.5963 - acc: 0.7178\n",
      "Epoch 6/10\n",
      "202/202 [==============================] - 0s 415us/sample - loss: 0.5624 - acc: 0.7871\n",
      "Epoch 7/10\n",
      "202/202 [==============================] - 0s 253us/sample - loss: 0.5333 - acc: 0.7723\n",
      "Epoch 8/10\n",
      "202/202 [==============================] - 0s 257us/sample - loss: 0.5085 - acc: 0.7624\n",
      "Epoch 9/10\n",
      "202/202 [==============================] - 0s 200us/sample - loss: 0.4859 - acc: 0.7772\n",
      "Epoch 10/10\n",
      "202/202 [==============================] - 0s 185us/sample - loss: 0.4669 - acc: 0.7970\n",
      "101/101 [==============================] - 0s 369us/sample - loss: 0.4858 - acc: 0.8119\n",
      "202/202 [==============================] - 0s 112us/sample - loss: 0.4568 - acc: 0.8119\n",
      "Epoch 1/10\n",
      "202/202 [==============================] - 0s 787us/sample - loss: 0.8077 - acc: 0.5446\n",
      "Epoch 2/10\n",
      "202/202 [==============================] - 0s 229us/sample - loss: 0.7324 - acc: 0.5792\n",
      "Epoch 3/10\n",
      "202/202 [==============================] - 0s 219us/sample - loss: 0.6685 - acc: 0.6287\n",
      "Epoch 4/10\n",
      "202/202 [==============================] - 0s 246us/sample - loss: 0.6181 - acc: 0.6584\n",
      "Epoch 5/10\n",
      "202/202 [==============================] - 0s 311us/sample - loss: 0.5754 - acc: 0.6931\n",
      "Epoch 6/10\n",
      "202/202 [==============================] - 0s 291us/sample - loss: 0.5430 - acc: 0.7178\n",
      "Epoch 7/10\n",
      "202/202 [==============================] - 0s 252us/sample - loss: 0.5156 - acc: 0.7525\n",
      "Epoch 8/10\n",
      "202/202 [==============================] - 0s 268us/sample - loss: 0.4929 - acc: 0.7871\n",
      "Epoch 9/10\n",
      "202/202 [==============================] - 0s 415us/sample - loss: 0.4737 - acc: 0.7970\n",
      "Epoch 10/10\n",
      "202/202 [==============================] - 0s 372us/sample - loss: 0.4583 - acc: 0.8020\n",
      "101/101 [==============================] - 0s 427us/sample - loss: 0.5108 - acc: 0.7426\n",
      "202/202 [==============================] - 0s 128us/sample - loss: 0.4491 - acc: 0.8020\n",
      "Epoch 1/10\n",
      "202/202 [==============================] - 0s 1ms/sample - loss: 1.0073 - acc: 0.4208\n",
      "Epoch 2/10\n",
      "202/202 [==============================] - 0s 569us/sample - loss: 0.9440 - acc: 0.4307\n",
      "Epoch 3/10\n",
      "202/202 [==============================] - 0s 290us/sample - loss: 0.8905 - acc: 0.4455\n",
      "Epoch 4/10\n",
      "202/202 [==============================] - 0s 329us/sample - loss: 0.8438 - acc: 0.4653\n",
      "Epoch 5/10\n",
      "202/202 [==============================] - 0s 529us/sample - loss: 0.8015 - acc: 0.4752\n",
      "Epoch 6/10\n",
      "202/202 [==============================] - 0s 74us/sample - loss: 0.7618 - acc: 0.4752\n",
      "Epoch 7/10\n",
      "202/202 [==============================] - 0s 595us/sample - loss: 0.7279 - acc: 0.5050\n",
      "Epoch 8/10\n",
      "202/202 [==============================] - 0s 443us/sample - loss: 0.6954 - acc: 0.5198\n",
      "Epoch 9/10\n",
      "202/202 [==============================] - 0s 345us/sample - loss: 0.6693 - acc: 0.5545\n",
      "Epoch 10/10\n",
      "202/202 [==============================] - 0s 391us/sample - loss: 0.6461 - acc: 0.5941\n",
      "101/101 [==============================] - 0s 520us/sample - loss: 0.7385 - acc: 0.5446\n",
      "202/202 [==============================] - 0s 313us/sample - loss: 0.6331 - acc: 0.6238\n",
      "Epoch 1/10\n",
      "202/202 [==============================] - 0s 544us/sample - loss: 0.7448 - acc: 0.3762\n",
      "Epoch 2/10\n",
      "202/202 [==============================] - 0s 348us/sample - loss: 0.7232 - acc: 0.4356\n",
      "Epoch 3/10\n",
      "202/202 [==============================] - 0s 521us/sample - loss: 0.7030 - acc: 0.4703\n",
      "Epoch 4/10\n",
      "202/202 [==============================] - 0s 416us/sample - loss: 0.6849 - acc: 0.5248\n",
      "Epoch 5/10\n",
      "202/202 [==============================] - 0s 238us/sample - loss: 0.6683 - acc: 0.5644\n",
      "Epoch 6/10\n",
      "202/202 [==============================] - 0s 185us/sample - loss: 0.6519 - acc: 0.6188\n",
      "Epoch 7/10\n",
      "202/202 [==============================] - 0s 213us/sample - loss: 0.6369 - acc: 0.6584\n",
      "Epoch 8/10\n",
      "202/202 [==============================] - 0s 193us/sample - loss: 0.6219 - acc: 0.7030\n",
      "Epoch 9/10\n",
      "202/202 [==============================] - 0s 301us/sample - loss: 0.6086 - acc: 0.7277\n",
      "Epoch 10/10\n",
      "202/202 [==============================] - 0s 158us/sample - loss: 0.5967 - acc: 0.7426\n",
      "101/101 [==============================] - 0s 460us/sample - loss: 0.5850 - acc: 0.7723\n",
      "202/202 [==============================] - 0s 53us/sample - loss: 0.5897 - acc: 0.7426\n",
      "Epoch 1/10\n",
      "202/202 [==============================] - 0s 605us/sample - loss: 0.7448 - acc: 0.5347\n",
      "Epoch 2/10\n",
      "202/202 [==============================] - 0s 156us/sample - loss: 0.7031 - acc: 0.5990\n",
      "Epoch 3/10\n",
      "202/202 [==============================] - 0s 96us/sample - loss: 0.6654 - acc: 0.6287\n",
      "Epoch 4/10\n",
      "202/202 [==============================] - 0s 190us/sample - loss: 0.6344 - acc: 0.6584\n",
      "Epoch 5/10\n",
      "202/202 [==============================] - 0s 123us/sample - loss: 0.6075 - acc: 0.6832\n",
      "Epoch 6/10\n",
      "202/202 [==============================] - 0s 164us/sample - loss: 0.5835 - acc: 0.6931\n",
      "Epoch 7/10\n",
      "202/202 [==============================] - 0s 91us/sample - loss: 0.5612 - acc: 0.7079\n",
      "Epoch 8/10\n",
      "202/202 [==============================] - 0s 260us/sample - loss: 0.5419 - acc: 0.7178\n",
      "Epoch 9/10\n",
      "202/202 [==============================] - 0s 113us/sample - loss: 0.5236 - acc: 0.7426\n",
      "Epoch 10/10\n",
      "202/202 [==============================] - 0s 186us/sample - loss: 0.5075 - acc: 0.7426\n",
      "101/101 [==============================] - 0s 500us/sample - loss: 0.5562 - acc: 0.7525\n",
      "202/202 [==============================] - 0s 67us/sample - loss: 0.4987 - acc: 0.7475\n",
      "Epoch 1/10\n",
      "202/202 [==============================] - 0s 857us/sample - loss: 0.9909 - acc: 0.5000\n",
      "Epoch 2/10\n",
      "202/202 [==============================] - 0s 285us/sample - loss: 0.9565 - acc: 0.5099\n",
      "Epoch 3/10\n",
      "202/202 [==============================] - 0s 232us/sample - loss: 0.9255 - acc: 0.5149\n",
      "Epoch 4/10\n",
      "202/202 [==============================] - 0s 160us/sample - loss: 0.8978 - acc: 0.5248\n",
      "Epoch 5/10\n",
      "202/202 [==============================] - 0s 89us/sample - loss: 0.8711 - acc: 0.5297\n",
      "Epoch 6/10\n",
      "202/202 [==============================] - 0s 83us/sample - loss: 0.8474 - acc: 0.5396\n",
      "Epoch 7/10\n",
      "202/202 [==============================] - 0s 110us/sample - loss: 0.8239 - acc: 0.5396\n",
      "Epoch 8/10\n",
      "202/202 [==============================] - 0s 71us/sample - loss: 0.8006 - acc: 0.5545\n",
      "Epoch 9/10\n",
      "202/202 [==============================] - 0s 165us/sample - loss: 0.7799 - acc: 0.5545\n",
      "Epoch 10/10\n",
      "202/202 [==============================] - 0s 92us/sample - loss: 0.7595 - acc: 0.5545\n",
      "101/101 [==============================] - 0s 506us/sample - loss: 0.8191 - acc: 0.5347\n",
      "202/202 [==============================] - 0s 46us/sample - loss: 0.7470 - acc: 0.5545\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202/202 [==============================] - 0s 622us/sample - loss: 0.7004 - acc: 0.5248\n",
      "Epoch 2/10\n",
      "202/202 [==============================] - 0s 64us/sample - loss: 0.6813 - acc: 0.5495\n",
      "Epoch 3/10\n",
      "202/202 [==============================] - 0s 109us/sample - loss: 0.6667 - acc: 0.5743\n",
      "Epoch 4/10\n",
      "202/202 [==============================] - 0s 68us/sample - loss: 0.6533 - acc: 0.5891\n",
      "Epoch 5/10\n",
      "202/202 [==============================] - 0s 64us/sample - loss: 0.6401 - acc: 0.6040\n",
      "Epoch 6/10\n",
      "202/202 [==============================] - 0s 84us/sample - loss: 0.6265 - acc: 0.6436\n",
      "Epoch 7/10\n",
      "202/202 [==============================] - 0s 105us/sample - loss: 0.6138 - acc: 0.6634\n",
      "Epoch 8/10\n",
      "202/202 [==============================] - 0s 99us/sample - loss: 0.6021 - acc: 0.6733\n",
      "Epoch 9/10\n",
      "202/202 [==============================] - 0s 101us/sample - loss: 0.5911 - acc: 0.6980\n",
      "Epoch 10/10\n",
      "202/202 [==============================] - 0s 94us/sample - loss: 0.5804 - acc: 0.7079\n",
      "101/101 [==============================] - 0s 756us/sample - loss: 0.5736 - acc: 0.7426\n",
      "202/202 [==============================] - 0s 45us/sample - loss: 0.5735 - acc: 0.7079\n",
      "Epoch 1/10\n",
      "202/202 [==============================] - 0s 630us/sample - loss: 0.6896 - acc: 0.5693\n",
      "Epoch 2/10\n",
      "202/202 [==============================] - 0s 103us/sample - loss: 0.6729 - acc: 0.5842\n",
      "Epoch 3/10\n",
      "202/202 [==============================] - 0s 49us/sample - loss: 0.6584 - acc: 0.5891\n",
      "Epoch 4/10\n",
      "202/202 [==============================] - 0s 102us/sample - loss: 0.6465 - acc: 0.5990\n",
      "Epoch 5/10\n",
      "202/202 [==============================] - 0s 94us/sample - loss: 0.6330 - acc: 0.6040\n",
      "Epoch 6/10\n",
      "202/202 [==============================] - 0s 90us/sample - loss: 0.6212 - acc: 0.6040\n",
      "Epoch 7/10\n",
      "202/202 [==============================] - 0s 92us/sample - loss: 0.6100 - acc: 0.6139\n",
      "Epoch 8/10\n",
      "202/202 [==============================] - 0s 124us/sample - loss: 0.6000 - acc: 0.6386\n",
      "Epoch 9/10\n",
      "202/202 [==============================] - 0s 88us/sample - loss: 0.5899 - acc: 0.6584\n",
      "Epoch 10/10\n",
      "202/202 [==============================] - 0s 119us/sample - loss: 0.5806 - acc: 0.6832\n",
      "101/101 [==============================] - 0s 579us/sample - loss: 0.6548 - acc: 0.6436\n",
      "202/202 [==============================] - 0s 35us/sample - loss: 0.5748 - acc: 0.7030\n",
      "Epoch 1/10\n",
      "202/202 [==============================] - 0s 619us/sample - loss: 0.8509 - acc: 0.4208\n",
      "Epoch 2/10\n",
      "202/202 [==============================] - 0s 54us/sample - loss: 0.8283 - acc: 0.4356\n",
      "Epoch 3/10\n",
      "202/202 [==============================] - 0s 99us/sample - loss: 0.8068 - acc: 0.4505\n",
      "Epoch 4/10\n",
      "202/202 [==============================] - 0s 109us/sample - loss: 0.7856 - acc: 0.4851\n",
      "Epoch 5/10\n",
      "202/202 [==============================] - 0s 184us/sample - loss: 0.7656 - acc: 0.5050\n",
      "Epoch 6/10\n",
      "202/202 [==============================] - 0s 86us/sample - loss: 0.7461 - acc: 0.5099\n",
      "Epoch 7/10\n",
      "202/202 [==============================] - 0s 89us/sample - loss: 0.7283 - acc: 0.5198\n",
      "Epoch 8/10\n",
      "202/202 [==============================] - 0s 82us/sample - loss: 0.7105 - acc: 0.5446\n",
      "Epoch 9/10\n",
      "202/202 [==============================] - 0s 91us/sample - loss: 0.6933 - acc: 0.5693\n",
      "Epoch 10/10\n",
      "202/202 [==============================] - 0s 123us/sample - loss: 0.6772 - acc: 0.5941\n",
      "101/101 [==============================] - 0s 604us/sample - loss: 0.6610 - acc: 0.6337\n",
      "202/202 [==============================] - 0s 32us/sample - loss: 0.6668 - acc: 0.6040\n",
      "Epoch 1/10\n",
      "202/202 [==============================] - 0s 877us/sample - loss: 1.0282 - acc: 0.3069\n",
      "Epoch 2/10\n",
      "202/202 [==============================] - 0s 116us/sample - loss: 1.0056 - acc: 0.3218\n",
      "Epoch 3/10\n",
      "202/202 [==============================] - 0s 161us/sample - loss: 0.9859 - acc: 0.3366\n",
      "Epoch 4/10\n",
      "202/202 [==============================] - 0s 113us/sample - loss: 0.9657 - acc: 0.3416\n",
      "Epoch 5/10\n",
      "202/202 [==============================] - 0s 99us/sample - loss: 0.9456 - acc: 0.3663\n",
      "Epoch 6/10\n",
      "202/202 [==============================] - 0s 92us/sample - loss: 0.9282 - acc: 0.3812\n",
      "Epoch 7/10\n",
      "202/202 [==============================] - 0s 79us/sample - loss: 0.9091 - acc: 0.3911\n",
      "Epoch 8/10\n",
      "202/202 [==============================] - 0s 54us/sample - loss: 0.8923 - acc: 0.3960\n",
      "Epoch 9/10\n",
      "202/202 [==============================] - 0s 38us/sample - loss: 0.8752 - acc: 0.3960\n",
      "Epoch 10/10\n",
      "202/202 [==============================] - 0s 95us/sample - loss: 0.8588 - acc: 0.4158\n",
      "101/101 [==============================] - 0s 640us/sample - loss: 0.8537 - acc: 0.3861\n",
      "202/202 [==============================] - 0s 27us/sample - loss: 0.8485 - acc: 0.4257\n",
      "Epoch 1/10\n",
      "202/202 [==============================] - 0s 696us/sample - loss: 0.7885 - acc: 0.4851\n",
      "Epoch 2/10\n",
      "202/202 [==============================] - 0s 45us/sample - loss: 0.7650 - acc: 0.5000\n",
      "Epoch 3/10\n",
      "202/202 [==============================] - 0s 86us/sample - loss: 0.7422 - acc: 0.5198\n",
      "Epoch 4/10\n",
      "202/202 [==============================] - 0s 86us/sample - loss: 0.7216 - acc: 0.5495\n",
      "Epoch 5/10\n",
      "202/202 [==============================] - 0s 108us/sample - loss: 0.7009 - acc: 0.5792\n",
      "Epoch 6/10\n",
      "202/202 [==============================] - 0s 86us/sample - loss: 0.6827 - acc: 0.5941\n",
      "Epoch 7/10\n",
      "202/202 [==============================] - 0s 81us/sample - loss: 0.6655 - acc: 0.5990\n",
      "Epoch 8/10\n",
      "202/202 [==============================] - 0s 89us/sample - loss: 0.6498 - acc: 0.6139\n",
      "Epoch 9/10\n",
      "202/202 [==============================] - 0s 104us/sample - loss: 0.6337 - acc: 0.6386\n",
      "Epoch 10/10\n",
      "202/202 [==============================] - 0s 99us/sample - loss: 0.6201 - acc: 0.6436\n",
      "101/101 [==============================] - 0s 1ms/sample - loss: 0.6502 - acc: 0.6040\n",
      "202/202 [==============================] - 0s 64us/sample - loss: 0.6105 - acc: 0.6634\n",
      "Epoch 1/10\n",
      "202/202 [==============================] - 0s 1ms/sample - loss: 0.7613 - acc: 0.4505\n",
      "Epoch 2/10\n",
      "202/202 [==============================] - 0s 58us/sample - loss: 0.7479 - acc: 0.4851\n",
      "Epoch 3/10\n",
      "202/202 [==============================] - 0s 103us/sample - loss: 0.7355 - acc: 0.5050\n",
      "Epoch 4/10\n",
      "202/202 [==============================] - 0s 116us/sample - loss: 0.7237 - acc: 0.5297\n",
      "Epoch 5/10\n",
      "202/202 [==============================] - 0s 120us/sample - loss: 0.7123 - acc: 0.5347\n",
      "Epoch 6/10\n",
      "202/202 [==============================] - 0s 126us/sample - loss: 0.7009 - acc: 0.5396\n",
      "Epoch 7/10\n",
      "202/202 [==============================] - 0s 163us/sample - loss: 0.6898 - acc: 0.5545\n",
      "Epoch 8/10\n",
      "202/202 [==============================] - 0s 144us/sample - loss: 0.6791 - acc: 0.5743\n",
      "Epoch 9/10\n",
      "202/202 [==============================] - 0s 44us/sample - loss: 0.6695 - acc: 0.6089\n",
      "Epoch 10/10\n",
      "202/202 [==============================] - 0s 46us/sample - loss: 0.6594 - acc: 0.6188\n",
      "101/101 [==============================] - 0s 2ms/sample - loss: 0.6701 - acc: 0.6337\n",
      "202/202 [==============================] - 0s 33us/sample - loss: 0.6527 - acc: 0.6386\n",
      "Epoch 1/10\n",
      "202/202 [==============================] - 0s 695us/sample - loss: 0.9541 - acc: 0.3564\n",
      "Epoch 2/10\n",
      "202/202 [==============================] - 0s 28us/sample - loss: 0.9388 - acc: 0.3515\n",
      "Epoch 3/10\n",
      "202/202 [==============================] - 0s 34us/sample - loss: 0.9242 - acc: 0.3663\n",
      "Epoch 4/10\n",
      "202/202 [==============================] - 0s 38us/sample - loss: 0.9087 - acc: 0.3762\n",
      "Epoch 5/10\n",
      "202/202 [==============================] - 0s 55us/sample - loss: 0.8953 - acc: 0.3812\n",
      "Epoch 6/10\n",
      "202/202 [==============================] - 0s 77us/sample - loss: 0.8803 - acc: 0.3861\n",
      "Epoch 7/10\n",
      "202/202 [==============================] - 0s 83us/sample - loss: 0.8667 - acc: 0.3960\n",
      "Epoch 8/10\n",
      "202/202 [==============================] - 0s 57us/sample - loss: 0.8531 - acc: 0.4010\n",
      "Epoch 9/10\n",
      "202/202 [==============================] - 0s 41us/sample - loss: 0.8403 - acc: 0.4109\n",
      "Epoch 10/10\n",
      "202/202 [==============================] - 0s 71us/sample - loss: 0.8277 - acc: 0.4158\n",
      "101/101 [==============================] - 0s 756us/sample - loss: 0.8305 - acc: 0.4356\n",
      "202/202 [==============================] - 0s 18us/sample - loss: 0.8181 - acc: 0.4257\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202/202 [==============================] - 0s 695us/sample - loss: 0.7741 - acc: 0.4950\n",
      "Epoch 2/10\n",
      "202/202 [==============================] - 0s 36us/sample - loss: 0.7566 - acc: 0.5149\n",
      "Epoch 3/10\n",
      "202/202 [==============================] - 0s 56us/sample - loss: 0.7405 - acc: 0.5248\n",
      "Epoch 4/10\n",
      "202/202 [==============================] - 0s 75us/sample - loss: 0.7252 - acc: 0.5347\n",
      "Epoch 5/10\n",
      "202/202 [==============================] - 0s 73us/sample - loss: 0.7104 - acc: 0.5396\n",
      "Epoch 6/10\n",
      "202/202 [==============================] - 0s 74us/sample - loss: 0.6956 - acc: 0.5594\n",
      "Epoch 7/10\n",
      "202/202 [==============================] - 0s 50us/sample - loss: 0.6827 - acc: 0.5644\n",
      "Epoch 8/10\n",
      "202/202 [==============================] - 0s 48us/sample - loss: 0.6692 - acc: 0.5990\n",
      "Epoch 9/10\n",
      "202/202 [==============================] - 0s 56us/sample - loss: 0.6576 - acc: 0.6040\n",
      "Epoch 10/10\n",
      "202/202 [==============================] - 0s 66us/sample - loss: 0.6453 - acc: 0.6188\n",
      "101/101 [==============================] - 0s 813us/sample - loss: 0.6285 - acc: 0.6436\n",
      "202/202 [==============================] - 0s 28us/sample - loss: 0.6374 - acc: 0.6287\n",
      "Epoch 1/10\n",
      "202/202 [==============================] - 0s 728us/sample - loss: 0.7004 - acc: 0.5891\n",
      "Epoch 2/10\n",
      "202/202 [==============================] - 0s 33us/sample - loss: 0.6880 - acc: 0.5990\n",
      "Epoch 3/10\n",
      "202/202 [==============================] - 0s 46us/sample - loss: 0.6781 - acc: 0.6089\n",
      "Epoch 4/10\n",
      "202/202 [==============================] - 0s 84us/sample - loss: 0.6693 - acc: 0.6089\n",
      "Epoch 5/10\n",
      "202/202 [==============================] - 0s 64us/sample - loss: 0.6608 - acc: 0.6139\n",
      "Epoch 6/10\n",
      "202/202 [==============================] - 0s 63us/sample - loss: 0.6529 - acc: 0.6139\n",
      "Epoch 7/10\n",
      "202/202 [==============================] - 0s 72us/sample - loss: 0.6451 - acc: 0.6287\n",
      "Epoch 8/10\n",
      "202/202 [==============================] - 0s 77us/sample - loss: 0.6375 - acc: 0.6386\n",
      "Epoch 9/10\n",
      "202/202 [==============================] - 0s 68us/sample - loss: 0.6304 - acc: 0.6535\n",
      "Epoch 10/10\n",
      "202/202 [==============================] - 0s 42us/sample - loss: 0.6237 - acc: 0.6683\n",
      "101/101 [==============================] - 0s 864us/sample - loss: 0.6984 - acc: 0.5842\n",
      "202/202 [==============================] - 0s 21us/sample - loss: 0.6180 - acc: 0.6733\n",
      "Epoch 1/10\n",
      "202/202 [==============================] - 0s 731us/sample - loss: 0.6700 - acc: 0.5693\n",
      "Epoch 2/10\n",
      "202/202 [==============================] - 0s 33us/sample - loss: 0.6584 - acc: 0.5842\n",
      "Epoch 3/10\n",
      "202/202 [==============================] - 0s 30us/sample - loss: 0.6486 - acc: 0.5891\n",
      "Epoch 4/10\n",
      "202/202 [==============================] - 0s 40us/sample - loss: 0.6400 - acc: 0.6040\n",
      "Epoch 5/10\n",
      "202/202 [==============================] - 0s 42us/sample - loss: 0.6322 - acc: 0.6139\n",
      "Epoch 6/10\n",
      "202/202 [==============================] - 0s 39us/sample - loss: 0.6251 - acc: 0.6238\n",
      "Epoch 7/10\n",
      "202/202 [==============================] - 0s 70us/sample - loss: 0.6182 - acc: 0.6337\n",
      "Epoch 8/10\n",
      "202/202 [==============================] - 0s 60us/sample - loss: 0.6118 - acc: 0.6436\n",
      "Epoch 9/10\n",
      "202/202 [==============================] - 0s 66us/sample - loss: 0.6064 - acc: 0.6485\n",
      "Epoch 10/10\n",
      "202/202 [==============================] - 0s 62us/sample - loss: 0.6011 - acc: 0.6584\n",
      "101/101 [==============================] - 0s 881us/sample - loss: 0.5637 - acc: 0.6832\n",
      "202/202 [==============================] - 0s 22us/sample - loss: 0.5963 - acc: 0.6634\n",
      "Epoch 1/10\n",
      "202/202 [==============================] - 0s 765us/sample - loss: 0.7978 - acc: 0.5446\n",
      "Epoch 2/10\n",
      "202/202 [==============================] - 0s 30us/sample - loss: 0.7870 - acc: 0.5446\n",
      "Epoch 3/10\n",
      "202/202 [==============================] - 0s 86us/sample - loss: 0.7791 - acc: 0.5446\n",
      "Epoch 4/10\n",
      "202/202 [==============================] - 0s 32us/sample - loss: 0.7715 - acc: 0.5446\n",
      "Epoch 5/10\n",
      "202/202 [==============================] - 0s 79us/sample - loss: 0.7643 - acc: 0.5446\n",
      "Epoch 6/10\n",
      "202/202 [==============================] - 0s 62us/sample - loss: 0.7570 - acc: 0.5446\n",
      "Epoch 7/10\n",
      "202/202 [==============================] - 0s 59us/sample - loss: 0.7504 - acc: 0.5446\n",
      "Epoch 8/10\n",
      "202/202 [==============================] - 0s 65us/sample - loss: 0.7436 - acc: 0.5446\n",
      "Epoch 9/10\n",
      "202/202 [==============================] - 0s 74us/sample - loss: 0.7371 - acc: 0.5446\n",
      "Epoch 10/10\n",
      "202/202 [==============================] - 0s 73us/sample - loss: 0.7306 - acc: 0.5495\n",
      "101/101 [==============================] - 0s 928us/sample - loss: 0.8341 - acc: 0.5248\n",
      "202/202 [==============================] - 0s 22us/sample - loss: 0.7253 - acc: 0.5495\n",
      "Epoch 1/10\n",
      "303/303 [==============================] - 0s 729us/sample - loss: 0.6700 - acc: 0.6238\n",
      "Epoch 2/10\n",
      "303/303 [==============================] - 0s 191us/sample - loss: 0.5940 - acc: 0.7162\n",
      "Epoch 3/10\n",
      "303/303 [==============================] - 0s 196us/sample - loss: 0.5385 - acc: 0.7492\n",
      "Epoch 4/10\n",
      "303/303 [==============================] - 0s 156us/sample - loss: 0.4988 - acc: 0.7525\n",
      "Epoch 5/10\n",
      "303/303 [==============================] - 0s 159us/sample - loss: 0.4699 - acc: 0.7789\n",
      "Epoch 6/10\n",
      "303/303 [==============================] - 0s 161us/sample - loss: 0.4466 - acc: 0.7954\n",
      "Epoch 7/10\n",
      "303/303 [==============================] - 0s 196us/sample - loss: 0.4286 - acc: 0.8053\n",
      "Epoch 8/10\n",
      "303/303 [==============================] - 0s 162us/sample - loss: 0.4134 - acc: 0.8185\n",
      "Epoch 9/10\n",
      "303/303 [==============================] - 0s 160us/sample - loss: 0.4012 - acc: 0.8251\n",
      "Epoch 10/10\n",
      "303/303 [==============================] - 0s 162us/sample - loss: 0.3916 - acc: 0.8284\n"
     ]
    }
   ],
   "source": [
    "# New model\n",
    "model = KerasClassifier(build_fn=create_model, verbose=1)\n",
    "\n",
    "# Create Grid Search\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1, cv=3)\n",
    "grid_result = grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.7755775650342306 using {'batch_size': 10, 'epochs': 10}\n"
     ]
    }
   ],
   "source": [
    "# Report Results\n",
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define search params\n",
    "param_grid = {'batch_size': [10],\n",
    "              'epochs': [5, 10, 20, 50, 100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "202/202 [==============================] - 0s 971us/sample - loss: 0.7490 - acc: 0.5792\n",
      "Epoch 2/5\n",
      "202/202 [==============================] - 0s 203us/sample - loss: 0.6845 - acc: 0.6139\n",
      "Epoch 3/5\n",
      "202/202 [==============================] - 0s 279us/sample - loss: 0.6296 - acc: 0.6584\n",
      "Epoch 4/5\n",
      "202/202 [==============================] - 0s 209us/sample - loss: 0.5836 - acc: 0.6881\n",
      "Epoch 5/5\n",
      "202/202 [==============================] - 0s 152us/sample - loss: 0.5447 - acc: 0.7327\n",
      "101/101 [==============================] - 0s 1ms/sample - loss: 0.4697 - acc: 0.8317\n",
      "202/202 [==============================] - 0s 175us/sample - loss: 0.5238 - acc: 0.7525\n",
      "Epoch 1/5\n",
      "202/202 [==============================] - 0s 2ms/sample - loss: 0.8010 - acc: 0.4307\n",
      "Epoch 2/5\n",
      "202/202 [==============================] - 0s 371us/sample - loss: 0.7425 - acc: 0.4901\n",
      "Epoch 3/5\n",
      "202/202 [==============================] - 0s 403us/sample - loss: 0.6923 - acc: 0.5446\n",
      "Epoch 4/5\n",
      "202/202 [==============================] - 0s 346us/sample - loss: 0.6490 - acc: 0.6040\n",
      "Epoch 5/5\n",
      "202/202 [==============================] - 0s 303us/sample - loss: 0.6130 - acc: 0.6683\n",
      "101/101 [==============================] - 0s 1ms/sample - loss: 0.5028 - acc: 0.7723\n",
      "202/202 [==============================] - 0s 104us/sample - loss: 0.5937 - acc: 0.6980\n",
      "Epoch 1/5\n",
      "202/202 [==============================] - 0s 969us/sample - loss: 0.6316 - acc: 0.6881\n",
      "Epoch 2/5\n",
      "202/202 [==============================] - 0s 354us/sample - loss: 0.5945 - acc: 0.6881\n",
      "Epoch 3/5\n",
      "202/202 [==============================] - 0s 292us/sample - loss: 0.5625 - acc: 0.7376\n",
      "Epoch 4/5\n",
      "202/202 [==============================] - 0s 212us/sample - loss: 0.5356 - acc: 0.7525\n",
      "Epoch 5/5\n",
      "202/202 [==============================] - 0s 164us/sample - loss: 0.5118 - acc: 0.7624\n",
      "101/101 [==============================] - 0s 1ms/sample - loss: 0.5519 - acc: 0.7426\n",
      "202/202 [==============================] - 0s 193us/sample - loss: 0.4992 - acc: 0.7723\n",
      "Epoch 1/10\n",
      "202/202 [==============================] - 0s 1ms/sample - loss: 0.7497 - acc: 0.4158\n",
      "Epoch 2/10\n",
      "202/202 [==============================] - 0s 201us/sample - loss: 0.6845 - acc: 0.5495\n",
      "Epoch 3/10\n",
      "202/202 [==============================] - 0s 242us/sample - loss: 0.6366 - acc: 0.6188\n",
      "Epoch 4/10\n",
      "202/202 [==============================] - 0s 157us/sample - loss: 0.6000 - acc: 0.6634\n",
      "Epoch 5/10\n",
      "202/202 [==============================] - 0s 263us/sample - loss: 0.5703 - acc: 0.7129\n",
      "Epoch 6/10\n",
      "202/202 [==============================] - 0s 242us/sample - loss: 0.5424 - acc: 0.7426\n",
      "Epoch 7/10\n",
      "202/202 [==============================] - 0s 174us/sample - loss: 0.5188 - acc: 0.7624\n",
      "Epoch 8/10\n",
      "202/202 [==============================] - 0s 250us/sample - loss: 0.4978 - acc: 0.7624\n",
      "Epoch 9/10\n",
      "202/202 [==============================] - 0s 250us/sample - loss: 0.4787 - acc: 0.7822\n",
      "Epoch 10/10\n",
      "202/202 [==============================] - 0s 193us/sample - loss: 0.4619 - acc: 0.7921\n",
      "101/101 [==============================] - 0s 1ms/sample - loss: 0.4855 - acc: 0.7822\n",
      "202/202 [==============================] - 0s 96us/sample - loss: 0.4527 - acc: 0.7970\n",
      "Epoch 1/10\n",
      "202/202 [==============================] - 0s 2ms/sample - loss: 0.5726 - acc: 0.6881\n",
      "Epoch 2/10\n",
      "202/202 [==============================] - 0s 393us/sample - loss: 0.5449 - acc: 0.7129\n",
      "Epoch 3/10\n",
      "202/202 [==============================] - 0s 321us/sample - loss: 0.5225 - acc: 0.7574\n",
      "Epoch 4/10\n",
      "202/202 [==============================] - 0s 311us/sample - loss: 0.5026 - acc: 0.7822\n",
      "Epoch 5/10\n",
      "202/202 [==============================] - 0s 392us/sample - loss: 0.4854 - acc: 0.8119\n",
      "Epoch 6/10\n",
      "202/202 [==============================] - 0s 283us/sample - loss: 0.4710 - acc: 0.8119\n",
      "Epoch 7/10\n",
      "202/202 [==============================] - 0s 283us/sample - loss: 0.4574 - acc: 0.8218\n",
      "Epoch 8/10\n",
      "202/202 [==============================] - 0s 409us/sample - loss: 0.4464 - acc: 0.8366\n",
      "Epoch 9/10\n",
      "202/202 [==============================] - 0s 325us/sample - loss: 0.4369 - acc: 0.8416\n",
      "Epoch 10/10\n",
      "202/202 [==============================] - 0s 299us/sample - loss: 0.4292 - acc: 0.8416\n",
      "101/101 [==============================] - 0s 2ms/sample - loss: 0.3940 - acc: 0.8515\n",
      "202/202 [==============================] - 0s 303us/sample - loss: 0.4232 - acc: 0.8465\n",
      "Epoch 1/10\n",
      "202/202 [==============================] - 0s 1ms/sample - loss: 0.6577 - acc: 0.6733\n",
      "Epoch 2/10\n",
      "202/202 [==============================] - 0s 261us/sample - loss: 0.6084 - acc: 0.7129\n",
      "Epoch 3/10\n",
      "202/202 [==============================] - 0s 314us/sample - loss: 0.5723 - acc: 0.7376\n",
      "Epoch 4/10\n",
      "202/202 [==============================] - 0s 280us/sample - loss: 0.5413 - acc: 0.7673\n",
      "Epoch 5/10\n",
      "202/202 [==============================] - 0s 256us/sample - loss: 0.5155 - acc: 0.7921\n",
      "Epoch 6/10\n",
      "202/202 [==============================] - 0s 354us/sample - loss: 0.4928 - acc: 0.8020\n",
      "Epoch 7/10\n",
      "202/202 [==============================] - 0s 354us/sample - loss: 0.4733 - acc: 0.8218\n",
      "Epoch 8/10\n",
      "202/202 [==============================] - 0s 388us/sample - loss: 0.4580 - acc: 0.8416\n",
      "Epoch 9/10\n",
      "202/202 [==============================] - 0s 336us/sample - loss: 0.4435 - acc: 0.8416\n",
      "Epoch 10/10\n",
      "202/202 [==============================] - 0s 377us/sample - loss: 0.4324 - acc: 0.8317\n",
      "101/101 [==============================] - 0s 2ms/sample - loss: 0.4764 - acc: 0.8119\n",
      "202/202 [==============================] - 0s 262us/sample - loss: 0.4243 - acc: 0.8416\n",
      "Epoch 1/20\n",
      "202/202 [==============================] - 1s 3ms/sample - loss: 0.8219 - acc: 0.3713\n",
      "Epoch 2/20\n",
      "202/202 [==============================] - 0s 246us/sample - loss: 0.7474 - acc: 0.4653\n",
      "Epoch 3/20\n",
      "202/202 [==============================] - 0s 198us/sample - loss: 0.6871 - acc: 0.5842\n",
      "Epoch 4/20\n",
      "202/202 [==============================] - 0s 184us/sample - loss: 0.6384 - acc: 0.6634\n",
      "Epoch 5/20\n",
      "202/202 [==============================] - 0s 281us/sample - loss: 0.5993 - acc: 0.6931\n",
      "Epoch 6/20\n",
      "202/202 [==============================] - 0s 357us/sample - loss: 0.5639 - acc: 0.7376\n",
      "Epoch 7/20\n",
      "202/202 [==============================] - 0s 620us/sample - loss: 0.5347 - acc: 0.7475\n",
      "Epoch 8/20\n",
      "202/202 [==============================] - 0s 431us/sample - loss: 0.5101 - acc: 0.7673\n",
      "Epoch 9/20\n",
      "202/202 [==============================] - 0s 271us/sample - loss: 0.4885 - acc: 0.7871\n",
      "Epoch 10/20\n",
      "202/202 [==============================] - 0s 197us/sample - loss: 0.4682 - acc: 0.7970\n",
      "Epoch 11/20\n",
      "202/202 [==============================] - 0s 305us/sample - loss: 0.4523 - acc: 0.8119\n",
      "Epoch 12/20\n",
      "202/202 [==============================] - 0s 242us/sample - loss: 0.4369 - acc: 0.8119\n",
      "Epoch 13/20\n",
      "202/202 [==============================] - 0s 265us/sample - loss: 0.4232 - acc: 0.8168\n",
      "Epoch 14/20\n",
      "202/202 [==============================] - 0s 235us/sample - loss: 0.4115 - acc: 0.8168\n",
      "Epoch 15/20\n",
      "202/202 [==============================] - 0s 227us/sample - loss: 0.4006 - acc: 0.8218\n",
      "Epoch 16/20\n",
      "202/202 [==============================] - 0s 164us/sample - loss: 0.3908 - acc: 0.8267\n",
      "Epoch 17/20\n",
      "202/202 [==============================] - 0s 255us/sample - loss: 0.3825 - acc: 0.8317\n",
      "Epoch 18/20\n",
      "202/202 [==============================] - 0s 251us/sample - loss: 0.3745 - acc: 0.8366\n",
      "Epoch 19/20\n",
      "202/202 [==============================] - 0s 232us/sample - loss: 0.3662 - acc: 0.8465\n",
      "Epoch 20/20\n",
      "202/202 [==============================] - 0s 163us/sample - loss: 0.3595 - acc: 0.8465\n",
      "101/101 [==============================] - 0s 1ms/sample - loss: 0.4240 - acc: 0.7921\n",
      "202/202 [==============================] - 0s 103us/sample - loss: 0.3545 - acc: 0.8465\n",
      "Epoch 1/20\n",
      "202/202 [==============================] - 0s 1ms/sample - loss: 0.7373 - acc: 0.5297\n",
      "Epoch 2/20\n",
      "202/202 [==============================] - 0s 234us/sample - loss: 0.6760 - acc: 0.6188\n",
      "Epoch 3/20\n",
      "202/202 [==============================] - 0s 220us/sample - loss: 0.6304 - acc: 0.6485\n",
      "Epoch 4/20\n",
      "202/202 [==============================] - 0s 204us/sample - loss: 0.5923 - acc: 0.6931\n",
      "Epoch 5/20\n",
      "202/202 [==============================] - 0s 174us/sample - loss: 0.5601 - acc: 0.7327\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202/202 [==============================] - 0s 259us/sample - loss: 0.5328 - acc: 0.7475\n",
      "Epoch 7/20\n",
      "202/202 [==============================] - 0s 330us/sample - loss: 0.5100 - acc: 0.7624\n",
      "Epoch 8/20\n",
      "202/202 [==============================] - 0s 235us/sample - loss: 0.4910 - acc: 0.7822\n",
      "Epoch 9/20\n",
      "202/202 [==============================] - 0s 167us/sample - loss: 0.4737 - acc: 0.8069\n",
      "Epoch 10/20\n",
      "202/202 [==============================] - 0s 256us/sample - loss: 0.4578 - acc: 0.8020\n",
      "Epoch 11/20\n",
      "202/202 [==============================] - 0s 235us/sample - loss: 0.4447 - acc: 0.8069\n",
      "Epoch 12/20\n",
      "202/202 [==============================] - 0s 170us/sample - loss: 0.4339 - acc: 0.8119\n",
      "Epoch 13/20\n",
      "202/202 [==============================] - 0s 250us/sample - loss: 0.4238 - acc: 0.8267\n",
      "Epoch 14/20\n",
      "202/202 [==============================] - 0s 273us/sample - loss: 0.4146 - acc: 0.8317\n",
      "Epoch 15/20\n",
      "202/202 [==============================] - 0s 235us/sample - loss: 0.4059 - acc: 0.8317\n",
      "Epoch 16/20\n",
      "202/202 [==============================] - 0s 257us/sample - loss: 0.3985 - acc: 0.8366\n",
      "Epoch 17/20\n",
      "202/202 [==============================] - 0s 242us/sample - loss: 0.3921 - acc: 0.8416\n",
      "Epoch 18/20\n",
      "202/202 [==============================] - 0s 250us/sample - loss: 0.3868 - acc: 0.8465\n",
      "Epoch 19/20\n",
      "202/202 [==============================] - 0s 204us/sample - loss: 0.3808 - acc: 0.8465\n",
      "Epoch 20/20\n",
      "202/202 [==============================] - 0s 198us/sample - loss: 0.3758 - acc: 0.8465\n",
      "101/101 [==============================] - 0s 1ms/sample - loss: 0.3581 - acc: 0.8614\n",
      "202/202 [==============================] - 0s 120us/sample - loss: 0.3723 - acc: 0.8465\n",
      "Epoch 1/20\n",
      "202/202 [==============================] - 0s 2ms/sample - loss: 0.5921 - acc: 0.6535\n",
      "Epoch 2/20\n",
      "202/202 [==============================] - 0s 241us/sample - loss: 0.5557 - acc: 0.6980\n",
      "Epoch 3/20\n",
      "202/202 [==============================] - 0s 385us/sample - loss: 0.5248 - acc: 0.7178\n",
      "Epoch 4/20\n",
      "202/202 [==============================] - 0s 360us/sample - loss: 0.5014 - acc: 0.7426\n",
      "Epoch 5/20\n",
      "202/202 [==============================] - 0s 314us/sample - loss: 0.4789 - acc: 0.7574\n",
      "Epoch 6/20\n",
      "202/202 [==============================] - 0s 206us/sample - loss: 0.4596 - acc: 0.7624\n",
      "Epoch 7/20\n",
      "202/202 [==============================] - 0s 158us/sample - loss: 0.4431 - acc: 0.7723\n",
      "Epoch 8/20\n",
      "202/202 [==============================] - 0s 214us/sample - loss: 0.4287 - acc: 0.7871\n",
      "Epoch 9/20\n",
      "202/202 [==============================] - 0s 214us/sample - loss: 0.4169 - acc: 0.7921\n",
      "Epoch 10/20\n",
      "202/202 [==============================] - 0s 165us/sample - loss: 0.4054 - acc: 0.8069\n",
      "Epoch 11/20\n",
      "202/202 [==============================] - 0s 259us/sample - loss: 0.3960 - acc: 0.8119\n",
      "Epoch 12/20\n",
      "202/202 [==============================] - 0s 235us/sample - loss: 0.3881 - acc: 0.8168\n",
      "Epoch 13/20\n",
      "202/202 [==============================] - 0s 244us/sample - loss: 0.3801 - acc: 0.8168\n",
      "Epoch 14/20\n",
      "202/202 [==============================] - 0s 241us/sample - loss: 0.3734 - acc: 0.8218\n",
      "Epoch 15/20\n",
      "202/202 [==============================] - 0s 175us/sample - loss: 0.3678 - acc: 0.8317\n",
      "Epoch 16/20\n",
      "202/202 [==============================] - 0s 252us/sample - loss: 0.3624 - acc: 0.8366\n",
      "Epoch 17/20\n",
      "202/202 [==============================] - 0s 342us/sample - loss: 0.3577 - acc: 0.8366\n",
      "Epoch 18/20\n",
      "202/202 [==============================] - 0s 292us/sample - loss: 0.3532 - acc: 0.8564\n",
      "Epoch 19/20\n",
      "202/202 [==============================] - 0s 376us/sample - loss: 0.3489 - acc: 0.8614\n",
      "Epoch 20/20\n",
      "202/202 [==============================] - 0s 298us/sample - loss: 0.3453 - acc: 0.8614\n",
      "101/101 [==============================] - 0s 2ms/sample - loss: 0.4128 - acc: 0.7822\n",
      "202/202 [==============================] - 0s 241us/sample - loss: 0.3422 - acc: 0.8614\n",
      "Epoch 1/50\n",
      "202/202 [==============================] - 0s 1ms/sample - loss: 0.7272 - acc: 0.5743\n",
      "Epoch 2/50\n",
      "202/202 [==============================] - 0s 201us/sample - loss: 0.6803 - acc: 0.6188\n",
      "Epoch 3/50\n",
      "202/202 [==============================] - 0s 165us/sample - loss: 0.6413 - acc: 0.6584\n",
      "Epoch 4/50\n",
      "202/202 [==============================] - 0s 218us/sample - loss: 0.6087 - acc: 0.6782\n",
      "Epoch 5/50\n",
      "202/202 [==============================] - 0s 186us/sample - loss: 0.5810 - acc: 0.7129\n",
      "Epoch 6/50\n",
      "202/202 [==============================] - 0s 244us/sample - loss: 0.5563 - acc: 0.7475\n",
      "Epoch 7/50\n",
      "202/202 [==============================] - 0s 236us/sample - loss: 0.5344 - acc: 0.7574\n",
      "Epoch 8/50\n",
      "202/202 [==============================] - 0s 246us/sample - loss: 0.5136 - acc: 0.7673\n",
      "Epoch 9/50\n",
      "202/202 [==============================] - 0s 179us/sample - loss: 0.4964 - acc: 0.7822\n",
      "Epoch 10/50\n",
      "202/202 [==============================] - 0s 244us/sample - loss: 0.4817 - acc: 0.7871\n",
      "Epoch 11/50\n",
      "202/202 [==============================] - 0s 247us/sample - loss: 0.4670 - acc: 0.8119\n",
      "Epoch 12/50\n",
      "202/202 [==============================] - 0s 248us/sample - loss: 0.4546 - acc: 0.8218\n",
      "Epoch 13/50\n",
      "202/202 [==============================] - 0s 209us/sample - loss: 0.4422 - acc: 0.8267\n",
      "Epoch 14/50\n",
      "202/202 [==============================] - 0s 202us/sample - loss: 0.4317 - acc: 0.8317\n",
      "Epoch 15/50\n",
      "202/202 [==============================] - 0s 292us/sample - loss: 0.4208 - acc: 0.8366\n",
      "Epoch 16/50\n",
      "202/202 [==============================] - 0s 219us/sample - loss: 0.4125 - acc: 0.8366\n",
      "Epoch 17/50\n",
      "202/202 [==============================] - 0s 250us/sample - loss: 0.4040 - acc: 0.8317\n",
      "Epoch 18/50\n",
      "202/202 [==============================] - 0s 247us/sample - loss: 0.3967 - acc: 0.8366\n",
      "Epoch 19/50\n",
      "202/202 [==============================] - 0s 244us/sample - loss: 0.3901 - acc: 0.8317\n",
      "Epoch 20/50\n",
      "202/202 [==============================] - 0s 248us/sample - loss: 0.3831 - acc: 0.8366\n",
      "Epoch 21/50\n",
      "202/202 [==============================] - 0s 303us/sample - loss: 0.3768 - acc: 0.8366\n",
      "Epoch 22/50\n",
      "202/202 [==============================] - 0s 469us/sample - loss: 0.3709 - acc: 0.8317\n",
      "Epoch 23/50\n",
      "202/202 [==============================] - 0s 483us/sample - loss: 0.3658 - acc: 0.8317\n",
      "Epoch 24/50\n",
      "202/202 [==============================] - 0s 268us/sample - loss: 0.3599 - acc: 0.8416\n",
      "Epoch 25/50\n",
      "202/202 [==============================] - 0s 311us/sample - loss: 0.3554 - acc: 0.8416\n",
      "Epoch 26/50\n",
      "202/202 [==============================] - 0s 263us/sample - loss: 0.3506 - acc: 0.8416\n",
      "Epoch 27/50\n",
      "202/202 [==============================] - 0s 359us/sample - loss: 0.3460 - acc: 0.8416\n",
      "Epoch 28/50\n",
      "202/202 [==============================] - 0s 317us/sample - loss: 0.3420 - acc: 0.8366\n",
      "Epoch 29/50\n",
      "202/202 [==============================] - 0s 375us/sample - loss: 0.3383 - acc: 0.8366\n",
      "Epoch 30/50\n",
      "202/202 [==============================] - 0s 262us/sample - loss: 0.3345 - acc: 0.8416\n",
      "Epoch 31/50\n",
      "202/202 [==============================] - 0s 261us/sample - loss: 0.3309 - acc: 0.8416\n",
      "Epoch 32/50\n",
      "202/202 [==============================] - 0s 222us/sample - loss: 0.3271 - acc: 0.8416\n",
      "Epoch 33/50\n",
      "202/202 [==============================] - 0s 310us/sample - loss: 0.3240 - acc: 0.8416\n",
      "Epoch 34/50\n",
      "202/202 [==============================] - 0s 342us/sample - loss: 0.3203 - acc: 0.8416\n",
      "Epoch 35/50\n",
      "202/202 [==============================] - 0s 280us/sample - loss: 0.3173 - acc: 0.8515\n",
      "Epoch 36/50\n",
      "202/202 [==============================] - 0s 330us/sample - loss: 0.3138 - acc: 0.8614\n",
      "Epoch 37/50\n",
      "202/202 [==============================] - 0s 235us/sample - loss: 0.3111 - acc: 0.8614\n",
      "Epoch 38/50\n",
      "202/202 [==============================] - 0s 174us/sample - loss: 0.3080 - acc: 0.8564\n",
      "Epoch 39/50\n",
      "202/202 [==============================] - 0s 245us/sample - loss: 0.3055 - acc: 0.8614\n",
      "Epoch 40/50\n",
      "202/202 [==============================] - 0s 292us/sample - loss: 0.3029 - acc: 0.8614\n",
      "Epoch 41/50\n",
      "202/202 [==============================] - 0s 163us/sample - loss: 0.3000 - acc: 0.8614\n",
      "Epoch 42/50\n",
      "202/202 [==============================] - 0s 458us/sample - loss: 0.2974 - acc: 0.8614\n",
      "Epoch 43/50\n",
      "202/202 [==============================] - 0s 423us/sample - loss: 0.2950 - acc: 0.8614\n",
      "Epoch 44/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202/202 [==============================] - 0s 244us/sample - loss: 0.2925 - acc: 0.8614\n",
      "Epoch 45/50\n",
      "202/202 [==============================] - 0s 187us/sample - loss: 0.2903 - acc: 0.8614\n",
      "Epoch 46/50\n",
      "202/202 [==============================] - 0s 241us/sample - loss: 0.2881 - acc: 0.8614\n",
      "Epoch 47/50\n",
      "202/202 [==============================] - 0s 245us/sample - loss: 0.2861 - acc: 0.8614\n",
      "Epoch 48/50\n",
      "202/202 [==============================] - 0s 190us/sample - loss: 0.2838 - acc: 0.8614\n",
      "Epoch 49/50\n",
      "202/202 [==============================] - 0s 241us/sample - loss: 0.2824 - acc: 0.8663\n",
      "Epoch 50/50\n",
      "202/202 [==============================] - 0s 235us/sample - loss: 0.2791 - acc: 0.8663\n",
      "101/101 [==============================] - 0s 1ms/sample - loss: 0.4570 - acc: 0.8218\n",
      "202/202 [==============================] - 0s 127us/sample - loss: 0.2773 - acc: 0.8663\n",
      "Epoch 1/50\n",
      "202/202 [==============================] - 0s 2ms/sample - loss: 0.7337 - acc: 0.5297\n",
      "Epoch 2/50\n",
      "202/202 [==============================] - 0s 338us/sample - loss: 0.6701 - acc: 0.5891\n",
      "Epoch 3/50\n",
      "202/202 [==============================] - 0s 431us/sample - loss: 0.6197 - acc: 0.6980\n",
      "Epoch 4/50\n",
      "202/202 [==============================] - 0s 386us/sample - loss: 0.5783 - acc: 0.7178\n",
      "Epoch 5/50\n",
      "202/202 [==============================] - 0s 362us/sample - loss: 0.5455 - acc: 0.7277\n",
      "Epoch 6/50\n",
      "202/202 [==============================] - 0s 303us/sample - loss: 0.5167 - acc: 0.7475\n",
      "Epoch 7/50\n",
      "202/202 [==============================] - 0s 214us/sample - loss: 0.4949 - acc: 0.7723\n",
      "Epoch 8/50\n",
      "202/202 [==============================] - 0s 230us/sample - loss: 0.4740 - acc: 0.7970\n",
      "Epoch 9/50\n",
      "202/202 [==============================] - 0s 165us/sample - loss: 0.4578 - acc: 0.8168\n",
      "Epoch 10/50\n",
      "202/202 [==============================] - 0s 266us/sample - loss: 0.4444 - acc: 0.8168\n",
      "Epoch 11/50\n",
      "202/202 [==============================] - 0s 256us/sample - loss: 0.4314 - acc: 0.8218\n",
      "Epoch 12/50\n",
      "202/202 [==============================] - 0s 191us/sample - loss: 0.4208 - acc: 0.8267\n",
      "Epoch 13/50\n",
      "202/202 [==============================] - 0s 258us/sample - loss: 0.4128 - acc: 0.8267\n",
      "Epoch 14/50\n",
      "202/202 [==============================] - 0s 226us/sample - loss: 0.4052 - acc: 0.8267\n",
      "Epoch 15/50\n",
      "202/202 [==============================] - 0s 189us/sample - loss: 0.3996 - acc: 0.8267\n",
      "Epoch 16/50\n",
      "202/202 [==============================] - 0s 257us/sample - loss: 0.3938 - acc: 0.8366\n",
      "Epoch 17/50\n",
      "202/202 [==============================] - 0s 172us/sample - loss: 0.3881 - acc: 0.8366\n",
      "Epoch 18/50\n",
      "202/202 [==============================] - 0s 243us/sample - loss: 0.3831 - acc: 0.8366\n",
      "Epoch 19/50\n",
      "202/202 [==============================] - 0s 255us/sample - loss: 0.3786 - acc: 0.8366\n",
      "Epoch 20/50\n",
      "202/202 [==============================] - 0s 276us/sample - loss: 0.3745 - acc: 0.8465\n",
      "Epoch 21/50\n",
      "202/202 [==============================] - 0s 378us/sample - loss: 0.3713 - acc: 0.8614\n",
      "Epoch 22/50\n",
      "202/202 [==============================] - 0s 441us/sample - loss: 0.3668 - acc: 0.8614\n",
      "Epoch 23/50\n",
      "202/202 [==============================] - 0s 375us/sample - loss: 0.3633 - acc: 0.8663\n",
      "Epoch 24/50\n",
      "202/202 [==============================] - 0s 418us/sample - loss: 0.3606 - acc: 0.8663\n",
      "Epoch 25/50\n",
      "202/202 [==============================] - 0s 361us/sample - loss: 0.3569 - acc: 0.8663\n",
      "Epoch 26/50\n",
      "202/202 [==============================] - 0s 410us/sample - loss: 0.3543 - acc: 0.8663\n",
      "Epoch 27/50\n",
      "202/202 [==============================] - 0s 338us/sample - loss: 0.3515 - acc: 0.8663\n",
      "Epoch 28/50\n",
      "202/202 [==============================] - 0s 239us/sample - loss: 0.3491 - acc: 0.8663\n",
      "Epoch 29/50\n",
      "202/202 [==============================] - 0s 182us/sample - loss: 0.3467 - acc: 0.8762\n",
      "Epoch 30/50\n",
      "202/202 [==============================] - 0s 247us/sample - loss: 0.3446 - acc: 0.8762\n",
      "Epoch 31/50\n",
      "202/202 [==============================] - 0s 158us/sample - loss: 0.3423 - acc: 0.8762\n",
      "Epoch 32/50\n",
      "202/202 [==============================] - 0s 258us/sample - loss: 0.3405 - acc: 0.8762\n",
      "Epoch 33/50\n",
      "202/202 [==============================] - 0s 191us/sample - loss: 0.3382 - acc: 0.8762\n",
      "Epoch 34/50\n",
      "202/202 [==============================] - 0s 297us/sample - loss: 0.3370 - acc: 0.8762\n",
      "Epoch 35/50\n",
      "202/202 [==============================] - 0s 381us/sample - loss: 0.3350 - acc: 0.8812\n",
      "Epoch 36/50\n",
      "202/202 [==============================] - 0s 405us/sample - loss: 0.3331 - acc: 0.8762\n",
      "Epoch 37/50\n",
      "202/202 [==============================] - 0s 376us/sample - loss: 0.3313 - acc: 0.8861\n",
      "Epoch 38/50\n",
      "202/202 [==============================] - 0s 385us/sample - loss: 0.3298 - acc: 0.8861\n",
      "Epoch 39/50\n",
      "202/202 [==============================] - 0s 396us/sample - loss: 0.3282 - acc: 0.8861\n",
      "Epoch 40/50\n",
      "202/202 [==============================] - 0s 415us/sample - loss: 0.3266 - acc: 0.8861\n",
      "Epoch 41/50\n",
      "202/202 [==============================] - 0s 343us/sample - loss: 0.3252 - acc: 0.8861\n",
      "Epoch 42/50\n",
      "202/202 [==============================] - 0s 345us/sample - loss: 0.3235 - acc: 0.8861\n",
      "Epoch 43/50\n",
      "202/202 [==============================] - 0s 266us/sample - loss: 0.3221 - acc: 0.8960\n",
      "Epoch 44/50\n",
      "202/202 [==============================] - 0s 303us/sample - loss: 0.3210 - acc: 0.8911\n",
      "Epoch 45/50\n",
      "202/202 [==============================] - 0s 294us/sample - loss: 0.3194 - acc: 0.8960\n",
      "Epoch 46/50\n",
      "202/202 [==============================] - 0s 189us/sample - loss: 0.3181 - acc: 0.9010\n",
      "Epoch 47/50\n",
      "202/202 [==============================] - 0s 252us/sample - loss: 0.3167 - acc: 0.9010\n",
      "Epoch 48/50\n",
      "202/202 [==============================] - 0s 163us/sample - loss: 0.3148 - acc: 0.9010\n",
      "Epoch 49/50\n",
      "202/202 [==============================] - 0s 266us/sample - loss: 0.3135 - acc: 0.9010\n",
      "Epoch 50/50\n",
      "202/202 [==============================] - 0s 163us/sample - loss: 0.3121 - acc: 0.9059\n",
      "101/101 [==============================] - 0s 2ms/sample - loss: 0.3890 - acc: 0.8416\n",
      "202/202 [==============================] - 0s 246us/sample - loss: 0.3103 - acc: 0.9059\n",
      "Epoch 1/50\n",
      "202/202 [==============================] - 0s 1ms/sample - loss: 0.8171 - acc: 0.3663\n",
      "Epoch 2/50\n",
      "202/202 [==============================] - 0s 209us/sample - loss: 0.7560 - acc: 0.4406\n",
      "Epoch 3/50\n",
      "202/202 [==============================] - 0s 198us/sample - loss: 0.6994 - acc: 0.5347\n",
      "Epoch 4/50\n",
      "202/202 [==============================] - 0s 256us/sample - loss: 0.6550 - acc: 0.6287\n",
      "Epoch 5/50\n",
      "202/202 [==============================] - 0s 210us/sample - loss: 0.6179 - acc: 0.6584\n",
      "Epoch 6/50\n",
      "202/202 [==============================] - 0s 295us/sample - loss: 0.5865 - acc: 0.7178\n",
      "Epoch 7/50\n",
      "202/202 [==============================] - 0s 399us/sample - loss: 0.5590 - acc: 0.7525\n",
      "Epoch 8/50\n",
      "202/202 [==============================] - 0s 422us/sample - loss: 0.5347 - acc: 0.7871\n",
      "Epoch 9/50\n",
      "202/202 [==============================] - 0s 368us/sample - loss: 0.5140 - acc: 0.7871\n",
      "Epoch 10/50\n",
      "202/202 [==============================] - 0s 412us/sample - loss: 0.4946 - acc: 0.7871\n",
      "Epoch 11/50\n",
      "202/202 [==============================] - 0s 336us/sample - loss: 0.4787 - acc: 0.7871\n",
      "Epoch 12/50\n",
      "202/202 [==============================] - 0s 271us/sample - loss: 0.4639 - acc: 0.7970\n",
      "Epoch 13/50\n",
      "202/202 [==============================] - 0s 353us/sample - loss: 0.4505 - acc: 0.8020\n",
      "Epoch 14/50\n",
      "202/202 [==============================] - 0s 269us/sample - loss: 0.4390 - acc: 0.8119\n",
      "Epoch 15/50\n",
      "202/202 [==============================] - 0s 411us/sample - loss: 0.4283 - acc: 0.8218\n",
      "Epoch 16/50\n",
      "202/202 [==============================] - 0s 374us/sample - loss: 0.4203 - acc: 0.8317\n",
      "Epoch 17/50\n",
      "202/202 [==============================] - 0s 405us/sample - loss: 0.4132 - acc: 0.8366\n",
      "Epoch 18/50\n",
      "202/202 [==============================] - 0s 367us/sample - loss: 0.4052 - acc: 0.8366\n",
      "Epoch 19/50\n",
      "202/202 [==============================] - 0s 403us/sample - loss: 0.3981 - acc: 0.8366\n",
      "Epoch 20/50\n",
      "202/202 [==============================] - 0s 375us/sample - loss: 0.3923 - acc: 0.8465\n",
      "Epoch 21/50\n",
      "202/202 [==============================] - 0s 448us/sample - loss: 0.3860 - acc: 0.8515\n",
      "Epoch 22/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202/202 [==============================] - 0s 410us/sample - loss: 0.3810 - acc: 0.8515\n",
      "Epoch 23/50\n",
      "202/202 [==============================] - 0s 530us/sample - loss: 0.3762 - acc: 0.8564\n",
      "Epoch 24/50\n",
      "202/202 [==============================] - 0s 358us/sample - loss: 0.3720 - acc: 0.8663\n",
      "Epoch 25/50\n",
      "202/202 [==============================] - 0s 286us/sample - loss: 0.3678 - acc: 0.8663\n",
      "Epoch 26/50\n",
      "202/202 [==============================] - 0s 681us/sample - loss: 0.3642 - acc: 0.8713\n",
      "Epoch 27/50\n",
      "202/202 [==============================] - 0s 331us/sample - loss: 0.3614 - acc: 0.8713\n",
      "Epoch 28/50\n",
      "202/202 [==============================] - 0s 528us/sample - loss: 0.3580 - acc: 0.8713\n",
      "Epoch 29/50\n",
      "202/202 [==============================] - 0s 315us/sample - loss: 0.3550 - acc: 0.8762\n",
      "Epoch 30/50\n",
      "202/202 [==============================] - 0s 265us/sample - loss: 0.3516 - acc: 0.8762\n",
      "Epoch 31/50\n",
      "202/202 [==============================] - 0s 361us/sample - loss: 0.3493 - acc: 0.8762\n",
      "Epoch 32/50\n",
      "202/202 [==============================] - 0s 292us/sample - loss: 0.3468 - acc: 0.8762\n",
      "Epoch 33/50\n",
      "202/202 [==============================] - 0s 924us/sample - loss: 0.3446 - acc: 0.8762\n",
      "Epoch 34/50\n",
      "202/202 [==============================] - 0s 654us/sample - loss: 0.3424 - acc: 0.8812\n",
      "Epoch 35/50\n",
      "202/202 [==============================] - 0s 528us/sample - loss: 0.3400 - acc: 0.8861\n",
      "Epoch 36/50\n",
      "202/202 [==============================] - 0s 443us/sample - loss: 0.3378 - acc: 0.8861\n",
      "Epoch 37/50\n",
      "202/202 [==============================] - 0s 273us/sample - loss: 0.3359 - acc: 0.8911\n",
      "Epoch 38/50\n",
      "202/202 [==============================] - 0s 309us/sample - loss: 0.3336 - acc: 0.8911\n",
      "Epoch 39/50\n",
      "202/202 [==============================] - 0s 304us/sample - loss: 0.3318 - acc: 0.8911\n",
      "Epoch 40/50\n",
      "202/202 [==============================] - 0s 287us/sample - loss: 0.3302 - acc: 0.8861\n",
      "Epoch 41/50\n",
      "202/202 [==============================] - 0s 249us/sample - loss: 0.3282 - acc: 0.8861\n",
      "Epoch 42/50\n",
      "202/202 [==============================] - 0s 231us/sample - loss: 0.3264 - acc: 0.8861\n",
      "Epoch 43/50\n",
      "202/202 [==============================] - 0s 278us/sample - loss: 0.3247 - acc: 0.8861\n",
      "Epoch 44/50\n",
      "202/202 [==============================] - 0s 262us/sample - loss: 0.3230 - acc: 0.8861\n",
      "Epoch 45/50\n",
      "202/202 [==============================] - 0s 216us/sample - loss: 0.3228 - acc: 0.8861\n",
      "Epoch 46/50\n",
      "202/202 [==============================] - 0s 200us/sample - loss: 0.3206 - acc: 0.8861\n",
      "Epoch 47/50\n",
      "202/202 [==============================] - 0s 200us/sample - loss: 0.3183 - acc: 0.8861\n",
      "Epoch 48/50\n",
      "202/202 [==============================] - 0s 581us/sample - loss: 0.3176 - acc: 0.8861\n",
      "Epoch 49/50\n",
      "202/202 [==============================] - 0s 458us/sample - loss: 0.3159 - acc: 0.8861\n",
      "Epoch 50/50\n",
      "202/202 [==============================] - 0s 393us/sample - loss: 0.3146 - acc: 0.8861\n",
      "101/101 [==============================] - 0s 2ms/sample - loss: 0.3955 - acc: 0.8317\n",
      "202/202 [==============================] - 0s 184us/sample - loss: 0.3128 - acc: 0.8861\n",
      "Epoch 1/100\n",
      "202/202 [==============================] - 0s 2ms/sample - loss: 1.0177 - acc: 0.4455\n",
      "Epoch 2/100\n",
      "202/202 [==============================] - 0s 285us/sample - loss: 0.9330 - acc: 0.4505\n",
      "Epoch 3/100\n",
      "202/202 [==============================] - 0s 219us/sample - loss: 0.8684 - acc: 0.4653\n",
      "Epoch 4/100\n",
      "202/202 [==============================] - 0s 227us/sample - loss: 0.8080 - acc: 0.5099\n",
      "Epoch 5/100\n",
      "202/202 [==============================] - 0s 230us/sample - loss: 0.7568 - acc: 0.5446\n",
      "Epoch 6/100\n",
      "202/202 [==============================] - 0s 245us/sample - loss: 0.7093 - acc: 0.5792\n",
      "Epoch 7/100\n",
      "202/202 [==============================] - 0s 224us/sample - loss: 0.6664 - acc: 0.6238\n",
      "Epoch 8/100\n",
      "202/202 [==============================] - 0s 213us/sample - loss: 0.6262 - acc: 0.6535\n",
      "Epoch 9/100\n",
      "202/202 [==============================] - 0s 186us/sample - loss: 0.5888 - acc: 0.6832\n",
      "Epoch 10/100\n",
      "202/202 [==============================] - 0s 273us/sample - loss: 0.5540 - acc: 0.7327\n",
      "Epoch 11/100\n",
      "202/202 [==============================] - 0s 206us/sample - loss: 0.5244 - acc: 0.7426\n",
      "Epoch 12/100\n",
      "202/202 [==============================] - 0s 285us/sample - loss: 0.4967 - acc: 0.7475\n",
      "Epoch 13/100\n",
      "202/202 [==============================] - 0s 287us/sample - loss: 0.4733 - acc: 0.7673\n",
      "Epoch 14/100\n",
      "202/202 [==============================] - 0s 696us/sample - loss: 0.4516 - acc: 0.7723\n",
      "Epoch 15/100\n",
      "202/202 [==============================] - 0s 509us/sample - loss: 0.4326 - acc: 0.7871\n",
      "Epoch 16/100\n",
      "202/202 [==============================] - 0s 492us/sample - loss: 0.4143 - acc: 0.8119\n",
      "Epoch 17/100\n",
      "202/202 [==============================] - 0s 452us/sample - loss: 0.3989 - acc: 0.8218\n",
      "Epoch 18/100\n",
      "202/202 [==============================] - 0s 488us/sample - loss: 0.3856 - acc: 0.8317\n",
      "Epoch 19/100\n",
      "202/202 [==============================] - 0s 436us/sample - loss: 0.3736 - acc: 0.8465\n",
      "Epoch 20/100\n",
      "202/202 [==============================] - 0s 650us/sample - loss: 0.3635 - acc: 0.8416\n",
      "Epoch 21/100\n",
      "202/202 [==============================] - 0s 506us/sample - loss: 0.3548 - acc: 0.8465\n",
      "Epoch 22/100\n",
      "202/202 [==============================] - 0s 455us/sample - loss: 0.3468 - acc: 0.8515\n",
      "Epoch 23/100\n",
      "202/202 [==============================] - 0s 238us/sample - loss: 0.3403 - acc: 0.8515\n",
      "Epoch 24/100\n",
      "202/202 [==============================] - 0s 354us/sample - loss: 0.3341 - acc: 0.8515\n",
      "Epoch 25/100\n",
      "202/202 [==============================] - 0s 375us/sample - loss: 0.3288 - acc: 0.8564\n",
      "Epoch 26/100\n",
      "202/202 [==============================] - 0s 380us/sample - loss: 0.3234 - acc: 0.8564\n",
      "Epoch 27/100\n",
      "202/202 [==============================] - 0s 833us/sample - loss: 0.3188 - acc: 0.8564\n",
      "Epoch 28/100\n",
      "202/202 [==============================] - 0s 688us/sample - loss: 0.3148 - acc: 0.8515\n",
      "Epoch 29/100\n",
      "202/202 [==============================] - 0s 743us/sample - loss: 0.3103 - acc: 0.8515\n",
      "Epoch 30/100\n",
      "202/202 [==============================] - 0s 345us/sample - loss: 0.3066 - acc: 0.8515\n",
      "Epoch 31/100\n",
      "202/202 [==============================] - 0s 383us/sample - loss: 0.3027 - acc: 0.8515\n",
      "Epoch 32/100\n",
      "202/202 [==============================] - 0s 523us/sample - loss: 0.2995 - acc: 0.8515\n",
      "Epoch 33/100\n",
      "202/202 [==============================] - 0s 466us/sample - loss: 0.2961 - acc: 0.8515\n",
      "Epoch 34/100\n",
      "202/202 [==============================] - 0s 910us/sample - loss: 0.2938 - acc: 0.8564\n",
      "Epoch 35/100\n",
      "202/202 [==============================] - 0s 822us/sample - loss: 0.2907 - acc: 0.8564\n",
      "Epoch 36/100\n",
      "202/202 [==============================] - 0s 416us/sample - loss: 0.2878 - acc: 0.8614\n",
      "Epoch 37/100\n",
      "202/202 [==============================] - 0s 308us/sample - loss: 0.2856 - acc: 0.8614\n",
      "Epoch 38/100\n",
      "202/202 [==============================] - 0s 390us/sample - loss: 0.2833 - acc: 0.8614\n",
      "Epoch 39/100\n",
      "202/202 [==============================] - 0s 261us/sample - loss: 0.2810 - acc: 0.8614\n",
      "Epoch 40/100\n",
      "202/202 [==============================] - 0s 429us/sample - loss: 0.2790 - acc: 0.8614\n",
      "Epoch 41/100\n",
      "202/202 [==============================] - 0s 245us/sample - loss: 0.2768 - acc: 0.8663\n",
      "Epoch 42/100\n",
      "202/202 [==============================] - 0s 610us/sample - loss: 0.2749 - acc: 0.8663\n",
      "Epoch 43/100\n",
      "202/202 [==============================] - 0s 586us/sample - loss: 0.2728 - acc: 0.8663\n",
      "Epoch 44/100\n",
      "202/202 [==============================] - 0s 505us/sample - loss: 0.2711 - acc: 0.8663\n",
      "Epoch 45/100\n",
      "202/202 [==============================] - 0s 538us/sample - loss: 0.2691 - acc: 0.8614\n",
      "Epoch 46/100\n",
      "202/202 [==============================] - 0s 468us/sample - loss: 0.2673 - acc: 0.8663\n",
      "Epoch 47/100\n",
      "202/202 [==============================] - 0s 419us/sample - loss: 0.2656 - acc: 0.8663\n",
      "Epoch 48/100\n",
      "202/202 [==============================] - 0s 672us/sample - loss: 0.2637 - acc: 0.8663\n",
      "Epoch 49/100\n",
      "202/202 [==============================] - 0s 352us/sample - loss: 0.2621 - acc: 0.8663\n",
      "Epoch 50/100\n",
      "202/202 [==============================] - 0s 382us/sample - loss: 0.2608 - acc: 0.8713\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202/202 [==============================] - 0s 471us/sample - loss: 0.2592 - acc: 0.8713\n",
      "Epoch 52/100\n",
      "202/202 [==============================] - 0s 363us/sample - loss: 0.2578 - acc: 0.8713\n",
      "Epoch 53/100\n",
      "202/202 [==============================] - 0s 253us/sample - loss: 0.2562 - acc: 0.8713\n",
      "Epoch 54/100\n",
      "202/202 [==============================] - 0s 202us/sample - loss: 0.2546 - acc: 0.8713\n",
      "Epoch 55/100\n",
      "202/202 [==============================] - 0s 164us/sample - loss: 0.2529 - acc: 0.8713\n",
      "Epoch 56/100\n",
      "202/202 [==============================] - 0s 300us/sample - loss: 0.2513 - acc: 0.8762\n",
      "Epoch 57/100\n",
      "202/202 [==============================] - 0s 264us/sample - loss: 0.2495 - acc: 0.8812\n",
      "Epoch 58/100\n",
      "202/202 [==============================] - 0s 479us/sample - loss: 0.2485 - acc: 0.8812\n",
      "Epoch 59/100\n",
      "202/202 [==============================] - 0s 612us/sample - loss: 0.2468 - acc: 0.8812\n",
      "Epoch 60/100\n",
      "202/202 [==============================] - 0s 406us/sample - loss: 0.2460 - acc: 0.8812\n",
      "Epoch 61/100\n",
      "202/202 [==============================] - 0s 400us/sample - loss: 0.2444 - acc: 0.8861\n",
      "Epoch 62/100\n",
      "202/202 [==============================] - 0s 339us/sample - loss: 0.2429 - acc: 0.8861\n",
      "Epoch 63/100\n",
      "202/202 [==============================] - 0s 304us/sample - loss: 0.2415 - acc: 0.8861\n",
      "Epoch 64/100\n",
      "202/202 [==============================] - 0s 322us/sample - loss: 0.2406 - acc: 0.8911\n",
      "Epoch 65/100\n",
      "202/202 [==============================] - 0s 318us/sample - loss: 0.2385 - acc: 0.8911\n",
      "Epoch 66/100\n",
      "202/202 [==============================] - 0s 386us/sample - loss: 0.2377 - acc: 0.8960\n",
      "Epoch 67/100\n",
      "202/202 [==============================] - 0s 390us/sample - loss: 0.2362 - acc: 0.9010\n",
      "Epoch 68/100\n",
      "202/202 [==============================] - 0s 299us/sample - loss: 0.2351 - acc: 0.8960\n",
      "Epoch 69/100\n",
      "202/202 [==============================] - 0s 472us/sample - loss: 0.2336 - acc: 0.9010\n",
      "Epoch 70/100\n",
      "202/202 [==============================] - 0s 530us/sample - loss: 0.2329 - acc: 0.9010\n",
      "Epoch 71/100\n",
      "202/202 [==============================] - 0s 255us/sample - loss: 0.2319 - acc: 0.8960\n",
      "Epoch 72/100\n",
      "202/202 [==============================] - 0s 348us/sample - loss: 0.2306 - acc: 0.8960\n",
      "Epoch 73/100\n",
      "202/202 [==============================] - 0s 480us/sample - loss: 0.2297 - acc: 0.8960\n",
      "Epoch 74/100\n",
      "202/202 [==============================] - 0s 302us/sample - loss: 0.2283 - acc: 0.8960\n",
      "Epoch 75/100\n",
      "202/202 [==============================] - 0s 487us/sample - loss: 0.2272 - acc: 0.9010\n",
      "Epoch 76/100\n",
      "202/202 [==============================] - 0s 392us/sample - loss: 0.2262 - acc: 0.9059\n",
      "Epoch 77/100\n",
      "202/202 [==============================] - 0s 337us/sample - loss: 0.2249 - acc: 0.9010\n",
      "Epoch 78/100\n",
      "202/202 [==============================] - 0s 403us/sample - loss: 0.2243 - acc: 0.9059\n",
      "Epoch 79/100\n",
      "202/202 [==============================] - 0s 534us/sample - loss: 0.2231 - acc: 0.9059\n",
      "Epoch 80/100\n",
      "202/202 [==============================] - 0s 447us/sample - loss: 0.2224 - acc: 0.9059\n",
      "Epoch 81/100\n",
      "202/202 [==============================] - 0s 253us/sample - loss: 0.2216 - acc: 0.9010\n",
      "Epoch 82/100\n",
      "202/202 [==============================] - 0s 379us/sample - loss: 0.2212 - acc: 0.9010\n",
      "Epoch 83/100\n",
      "202/202 [==============================] - 0s 342us/sample - loss: 0.2194 - acc: 0.9059\n",
      "Epoch 84/100\n",
      "202/202 [==============================] - 0s 401us/sample - loss: 0.2186 - acc: 0.9059\n",
      "Epoch 85/100\n",
      "202/202 [==============================] - 0s 765us/sample - loss: 0.2179 - acc: 0.9059\n",
      "Epoch 86/100\n",
      "202/202 [==============================] - 0s 710us/sample - loss: 0.2169 - acc: 0.9059\n",
      "Epoch 87/100\n",
      "202/202 [==============================] - 0s 244us/sample - loss: 0.2161 - acc: 0.9059\n",
      "Epoch 88/100\n",
      "202/202 [==============================] - 0s 242us/sample - loss: 0.2153 - acc: 0.9059\n",
      "Epoch 89/100\n",
      "202/202 [==============================] - 0s 384us/sample - loss: 0.2143 - acc: 0.9059\n",
      "Epoch 90/100\n",
      "202/202 [==============================] - 0s 539us/sample - loss: 0.2137 - acc: 0.9059\n",
      "Epoch 91/100\n",
      "202/202 [==============================] - 0s 282us/sample - loss: 0.2129 - acc: 0.9059\n",
      "Epoch 92/100\n",
      "202/202 [==============================] - 0s 212us/sample - loss: 0.2121 - acc: 0.9059\n",
      "Epoch 93/100\n",
      "202/202 [==============================] - 0s 208us/sample - loss: 0.2105 - acc: 0.9109\n",
      "Epoch 94/100\n",
      "202/202 [==============================] - 0s 194us/sample - loss: 0.2099 - acc: 0.9109\n",
      "Epoch 95/100\n",
      "202/202 [==============================] - 0s 289us/sample - loss: 0.2090 - acc: 0.9158\n",
      "Epoch 96/100\n",
      "202/202 [==============================] - 0s 211us/sample - loss: 0.2080 - acc: 0.9109\n",
      "Epoch 97/100\n",
      "202/202 [==============================] - 0s 214us/sample - loss: 0.2069 - acc: 0.9158\n",
      "Epoch 98/100\n",
      "202/202 [==============================] - 0s 292us/sample - loss: 0.2057 - acc: 0.9257\n",
      "Epoch 99/100\n",
      "202/202 [==============================] - 0s 207us/sample - loss: 0.2051 - acc: 0.9208\n",
      "Epoch 100/100\n",
      "202/202 [==============================] - 0s 212us/sample - loss: 0.2040 - acc: 0.9257\n",
      "101/101 [==============================] - 0s 2ms/sample - loss: 0.5460 - acc: 0.8218\n",
      "202/202 [==============================] - 0s 200us/sample - loss: 0.2027 - acc: 0.9257\n",
      "Epoch 1/100\n",
      "202/202 [==============================] - 0s 1ms/sample - loss: 0.7642 - acc: 0.5594\n",
      "Epoch 2/100\n",
      "202/202 [==============================] - 0s 246us/sample - loss: 0.7021 - acc: 0.6139\n",
      "Epoch 3/100\n",
      "202/202 [==============================] - 0s 250us/sample - loss: 0.6503 - acc: 0.6634\n",
      "Epoch 4/100\n",
      "202/202 [==============================] - 0s 276us/sample - loss: 0.6113 - acc: 0.6782\n",
      "Epoch 5/100\n",
      "202/202 [==============================] - 0s 213us/sample - loss: 0.5780 - acc: 0.6980\n",
      "Epoch 6/100\n",
      "202/202 [==============================] - 0s 213us/sample - loss: 0.5470 - acc: 0.7426\n",
      "Epoch 7/100\n",
      "202/202 [==============================] - 0s 236us/sample - loss: 0.5218 - acc: 0.7921\n",
      "Epoch 8/100\n",
      "202/202 [==============================] - 0s 304us/sample - loss: 0.5008 - acc: 0.7871\n",
      "Epoch 9/100\n",
      "202/202 [==============================] - 0s 292us/sample - loss: 0.4820 - acc: 0.7921\n",
      "Epoch 10/100\n",
      "202/202 [==============================] - 0s 222us/sample - loss: 0.4678 - acc: 0.8020\n",
      "Epoch 11/100\n",
      "202/202 [==============================] - 0s 216us/sample - loss: 0.4549 - acc: 0.8069\n",
      "Epoch 12/100\n",
      "202/202 [==============================] - 0s 192us/sample - loss: 0.4421 - acc: 0.8119\n",
      "Epoch 13/100\n",
      "202/202 [==============================] - 0s 287us/sample - loss: 0.4311 - acc: 0.8119\n",
      "Epoch 14/100\n",
      "202/202 [==============================] - 0s 220us/sample - loss: 0.4208 - acc: 0.8168\n",
      "Epoch 15/100\n",
      "202/202 [==============================] - 0s 216us/sample - loss: 0.4114 - acc: 0.8168\n",
      "Epoch 16/100\n",
      "202/202 [==============================] - 0s 213us/sample - loss: 0.4030 - acc: 0.8168\n",
      "Epoch 17/100\n",
      "202/202 [==============================] - 0s 235us/sample - loss: 0.3954 - acc: 0.8267\n",
      "Epoch 18/100\n",
      "202/202 [==============================] - 0s 398us/sample - loss: 0.3888 - acc: 0.8267\n",
      "Epoch 19/100\n",
      "202/202 [==============================] - 0s 401us/sample - loss: 0.3825 - acc: 0.8267\n",
      "Epoch 20/100\n",
      "202/202 [==============================] - 0s 277us/sample - loss: 0.3775 - acc: 0.8267\n",
      "Epoch 21/100\n",
      "202/202 [==============================] - 0s 216us/sample - loss: 0.3721 - acc: 0.8317\n",
      "Epoch 22/100\n",
      "202/202 [==============================] - 0s 220us/sample - loss: 0.3677 - acc: 0.8317\n",
      "Epoch 23/100\n",
      "202/202 [==============================] - 0s 224us/sample - loss: 0.3634 - acc: 0.8416\n",
      "Epoch 24/100\n",
      "202/202 [==============================] - 0s 227us/sample - loss: 0.3589 - acc: 0.8416\n",
      "Epoch 25/100\n",
      "202/202 [==============================] - 0s 289us/sample - loss: 0.3554 - acc: 0.8465\n",
      "Epoch 26/100\n",
      "202/202 [==============================] - 0s 223us/sample - loss: 0.3519 - acc: 0.8465\n",
      "Epoch 27/100\n",
      "202/202 [==============================] - 0s 220us/sample - loss: 0.3491 - acc: 0.8465\n",
      "Epoch 28/100\n",
      "202/202 [==============================] - 0s 212us/sample - loss: 0.3458 - acc: 0.8465\n",
      "Epoch 29/100\n",
      "202/202 [==============================] - 0s 204us/sample - loss: 0.3429 - acc: 0.8465\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202/202 [==============================] - 0s 285us/sample - loss: 0.3399 - acc: 0.8564\n",
      "Epoch 31/100\n",
      "202/202 [==============================] - 0s 214us/sample - loss: 0.3371 - acc: 0.8564\n",
      "Epoch 32/100\n",
      "202/202 [==============================] - 0s 214us/sample - loss: 0.3343 - acc: 0.8614\n",
      "Epoch 33/100\n",
      "202/202 [==============================] - 0s 193us/sample - loss: 0.3321 - acc: 0.8614\n",
      "Epoch 34/100\n",
      "202/202 [==============================] - 0s 261us/sample - loss: 0.3302 - acc: 0.8663\n",
      "Epoch 35/100\n",
      "202/202 [==============================] - 0s 187us/sample - loss: 0.3271 - acc: 0.8713\n",
      "Epoch 36/100\n",
      "202/202 [==============================] - 0s 258us/sample - loss: 0.3253 - acc: 0.8663\n",
      "Epoch 37/100\n",
      "202/202 [==============================] - 0s 195us/sample - loss: 0.3226 - acc: 0.8762\n",
      "Epoch 38/100\n",
      "202/202 [==============================] - 0s 256us/sample - loss: 0.3205 - acc: 0.8762\n",
      "Epoch 39/100\n",
      "202/202 [==============================] - 0s 198us/sample - loss: 0.3184 - acc: 0.8762\n",
      "Epoch 40/100\n",
      "202/202 [==============================] - 0s 270us/sample - loss: 0.3165 - acc: 0.8812\n",
      "Epoch 41/100\n",
      "202/202 [==============================] - 0s 219us/sample - loss: 0.3142 - acc: 0.8812\n",
      "Epoch 42/100\n",
      "202/202 [==============================] - 0s 197us/sample - loss: 0.3128 - acc: 0.8812\n",
      "Epoch 43/100\n",
      "202/202 [==============================] - 0s 288us/sample - loss: 0.3107 - acc: 0.8812\n",
      "Epoch 44/100\n",
      "202/202 [==============================] - 0s 213us/sample - loss: 0.3086 - acc: 0.8812\n",
      "Epoch 45/100\n",
      "202/202 [==============================] - 0s 214us/sample - loss: 0.3073 - acc: 0.8812\n",
      "Epoch 46/100\n",
      "202/202 [==============================] - 0s 161us/sample - loss: 0.3055 - acc: 0.8812\n",
      "Epoch 47/100\n",
      "202/202 [==============================] - 0s 289us/sample - loss: 0.3031 - acc: 0.8812\n",
      "Epoch 48/100\n",
      "202/202 [==============================] - 0s 180us/sample - loss: 0.3016 - acc: 0.8911\n",
      "Epoch 49/100\n",
      "202/202 [==============================] - 0s 265us/sample - loss: 0.3001 - acc: 0.8911\n",
      "Epoch 50/100\n",
      "202/202 [==============================] - 0s 200us/sample - loss: 0.2976 - acc: 0.8911\n",
      "Epoch 51/100\n",
      "202/202 [==============================] - 0s 268us/sample - loss: 0.2965 - acc: 0.8911\n",
      "Epoch 52/100\n",
      "202/202 [==============================] - 0s 209us/sample - loss: 0.2955 - acc: 0.8911\n",
      "Epoch 53/100\n",
      "202/202 [==============================] - 0s 260us/sample - loss: 0.2943 - acc: 0.8861\n",
      "Epoch 54/100\n",
      "202/202 [==============================] - 0s 211us/sample - loss: 0.2927 - acc: 0.8861\n",
      "Epoch 55/100\n",
      "202/202 [==============================] - 0s 277us/sample - loss: 0.2917 - acc: 0.8861\n",
      "Epoch 56/100\n",
      "202/202 [==============================] - 0s 210us/sample - loss: 0.2908 - acc: 0.8861\n",
      "Epoch 57/100\n",
      "202/202 [==============================] - 0s 203us/sample - loss: 0.2890 - acc: 0.8861\n",
      "Epoch 58/100\n",
      "202/202 [==============================] - 0s 274us/sample - loss: 0.2878 - acc: 0.8861\n",
      "Epoch 59/100\n",
      "202/202 [==============================] - 0s 216us/sample - loss: 0.2863 - acc: 0.8861\n",
      "Epoch 60/100\n",
      "202/202 [==============================] - 0s 214us/sample - loss: 0.2854 - acc: 0.8861\n",
      "Epoch 61/100\n",
      "202/202 [==============================] - 0s 261us/sample - loss: 0.2838 - acc: 0.8861\n",
      "Epoch 62/100\n",
      "202/202 [==============================] - 0s 205us/sample - loss: 0.2825 - acc: 0.8861\n",
      "Epoch 63/100\n",
      "202/202 [==============================] - ETA: 0s - loss: 0.2841 - acc: 0.890 - 0s 275us/sample - loss: 0.2818 - acc: 0.8911\n",
      "Epoch 64/100\n",
      "202/202 [==============================] - 0s 210us/sample - loss: 0.2805 - acc: 0.8911\n",
      "Epoch 65/100\n",
      "202/202 [==============================] - 0s 197us/sample - loss: 0.2792 - acc: 0.8911\n",
      "Epoch 66/100\n",
      "202/202 [==============================] - 0s 265us/sample - loss: 0.2784 - acc: 0.8911\n",
      "Epoch 67/100\n",
      "202/202 [==============================] - 0s 209us/sample - loss: 0.2772 - acc: 0.8861\n",
      "Epoch 68/100\n",
      "202/202 [==============================] - 0s 258us/sample - loss: 0.2763 - acc: 0.8861\n",
      "Epoch 69/100\n",
      "202/202 [==============================] - 0s 213us/sample - loss: 0.2752 - acc: 0.8861\n",
      "Epoch 70/100\n",
      "202/202 [==============================] - 0s 260us/sample - loss: 0.2742 - acc: 0.8911\n",
      "Epoch 71/100\n",
      "202/202 [==============================] - 0s 213us/sample - loss: 0.2734 - acc: 0.8911\n",
      "Epoch 72/100\n",
      "202/202 [==============================] - 0s 162us/sample - loss: 0.2730 - acc: 0.8911\n",
      "Epoch 73/100\n",
      "202/202 [==============================] - 0s 271us/sample - loss: 0.2715 - acc: 0.8911\n",
      "Epoch 74/100\n",
      "202/202 [==============================] - 0s 209us/sample - loss: 0.2708 - acc: 0.8911\n",
      "Epoch 75/100\n",
      "202/202 [==============================] - 0s 164us/sample - loss: 0.2700 - acc: 0.8911\n",
      "Epoch 76/100\n",
      "202/202 [==============================] - 0s 276us/sample - loss: 0.2686 - acc: 0.8911\n",
      "Epoch 77/100\n",
      "202/202 [==============================] - 0s 257us/sample - loss: 0.2676 - acc: 0.8911\n",
      "Epoch 78/100\n",
      "202/202 [==============================] - 0s 213us/sample - loss: 0.2668 - acc: 0.8911\n",
      "Epoch 79/100\n",
      "202/202 [==============================] - 0s 262us/sample - loss: 0.2658 - acc: 0.8911\n",
      "Epoch 80/100\n",
      "202/202 [==============================] - 0s 186us/sample - loss: 0.2654 - acc: 0.8911\n",
      "Epoch 81/100\n",
      "202/202 [==============================] - 0s 256us/sample - loss: 0.2640 - acc: 0.8960\n",
      "Epoch 82/100\n",
      "202/202 [==============================] - 0s 186us/sample - loss: 0.2631 - acc: 0.8960\n",
      "Epoch 83/100\n",
      "202/202 [==============================] - 0s 277us/sample - loss: 0.2621 - acc: 0.8960\n",
      "Epoch 84/100\n",
      "202/202 [==============================] - 0s 228us/sample - loss: 0.2611 - acc: 0.8960\n",
      "Epoch 85/100\n",
      "202/202 [==============================] - 0s 208us/sample - loss: 0.2599 - acc: 0.8960\n",
      "Epoch 86/100\n",
      "202/202 [==============================] - 0s 206us/sample - loss: 0.2588 - acc: 0.8960\n",
      "Epoch 87/100\n",
      "202/202 [==============================] - 0s 273us/sample - loss: 0.2580 - acc: 0.8960\n",
      "Epoch 88/100\n",
      "202/202 [==============================] - 0s 218us/sample - loss: 0.2572 - acc: 0.8960\n",
      "Epoch 89/100\n",
      "202/202 [==============================] - 0s 207us/sample - loss: 0.2565 - acc: 0.8960\n",
      "Epoch 90/100\n",
      "202/202 [==============================] - 0s 251us/sample - loss: 0.2553 - acc: 0.8960\n",
      "Epoch 91/100\n",
      "202/202 [==============================] - 0s 187us/sample - loss: 0.2547 - acc: 0.8960\n",
      "Epoch 92/100\n",
      "202/202 [==============================] - 0s 262us/sample - loss: 0.2542 - acc: 0.8960\n",
      "Epoch 93/100\n",
      "202/202 [==============================] - 0s 197us/sample - loss: 0.2533 - acc: 0.8960\n",
      "Epoch 94/100\n",
      "202/202 [==============================] - 0s 261us/sample - loss: 0.2524 - acc: 0.8960\n",
      "Epoch 95/100\n",
      "202/202 [==============================] - 0s 204us/sample - loss: 0.2518 - acc: 0.8960\n",
      "Epoch 96/100\n",
      "202/202 [==============================] - 0s 257us/sample - loss: 0.2509 - acc: 0.8960\n",
      "Epoch 97/100\n",
      "202/202 [==============================] - 0s 180us/sample - loss: 0.2504 - acc: 0.8960\n",
      "Epoch 98/100\n",
      "202/202 [==============================] - 0s 272us/sample - loss: 0.2501 - acc: 0.8960\n",
      "Epoch 99/100\n",
      "202/202 [==============================] - 0s 214us/sample - loss: 0.2503 - acc: 0.8960\n",
      "Epoch 100/100\n",
      "202/202 [==============================] - 0s 165us/sample - loss: 0.2485 - acc: 0.8960\n",
      "101/101 [==============================] - 0s 2ms/sample - loss: 0.3866 - acc: 0.8416\n",
      "202/202 [==============================] - 0s 163us/sample - loss: 0.2466 - acc: 0.8960\n",
      "Epoch 1/100\n",
      "202/202 [==============================] - 0s 1ms/sample - loss: 0.7373 - acc: 0.6287\n",
      "Epoch 2/100\n",
      "202/202 [==============================] - 0s 170us/sample - loss: 0.6826 - acc: 0.6485\n",
      "Epoch 3/100\n",
      "202/202 [==============================] - 0s 283us/sample - loss: 0.6395 - acc: 0.6634\n",
      "Epoch 4/100\n",
      "202/202 [==============================] - 0s 192us/sample - loss: 0.6016 - acc: 0.6931\n",
      "Epoch 5/100\n",
      "202/202 [==============================] - 0s 261us/sample - loss: 0.5716 - acc: 0.7129\n",
      "Epoch 6/100\n",
      "202/202 [==============================] - 0s 188us/sample - loss: 0.5425 - acc: 0.7327\n",
      "Epoch 7/100\n",
      "202/202 [==============================] - 0s 272us/sample - loss: 0.5182 - acc: 0.7525\n",
      "Epoch 8/100\n",
      "202/202 [==============================] - 0s 191us/sample - loss: 0.4987 - acc: 0.7525\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202/202 [==============================] - 0s 265us/sample - loss: 0.4797 - acc: 0.7822\n",
      "Epoch 10/100\n",
      "202/202 [==============================] - 0s 197us/sample - loss: 0.4637 - acc: 0.7921\n",
      "Epoch 11/100\n",
      "202/202 [==============================] - 0s 255us/sample - loss: 0.4500 - acc: 0.8168\n",
      "Epoch 12/100\n",
      "202/202 [==============================] - 0s 198us/sample - loss: 0.4379 - acc: 0.8218\n",
      "Epoch 13/100\n",
      "202/202 [==============================] - 0s 259us/sample - loss: 0.4270 - acc: 0.8218\n",
      "Epoch 14/100\n",
      "202/202 [==============================] - 0s 185us/sample - loss: 0.4160 - acc: 0.8465\n",
      "Epoch 15/100\n",
      "202/202 [==============================] - 0s 271us/sample - loss: 0.4066 - acc: 0.8515\n",
      "Epoch 16/100\n",
      "202/202 [==============================] - 0s 198us/sample - loss: 0.3983 - acc: 0.8564\n",
      "Epoch 17/100\n",
      "202/202 [==============================] - 0s 251us/sample - loss: 0.3903 - acc: 0.8515\n",
      "Epoch 18/100\n",
      "202/202 [==============================] - 0s 191us/sample - loss: 0.3829 - acc: 0.8515\n",
      "Epoch 19/100\n",
      "202/202 [==============================] - 0s 265us/sample - loss: 0.3769 - acc: 0.8515\n",
      "Epoch 20/100\n",
      "202/202 [==============================] - 0s 211us/sample - loss: 0.3708 - acc: 0.8515\n",
      "Epoch 21/100\n",
      "202/202 [==============================] - 0s 269us/sample - loss: 0.3655 - acc: 0.8564\n",
      "Epoch 22/100\n",
      "202/202 [==============================] - 0s 203us/sample - loss: 0.3611 - acc: 0.8663\n",
      "Epoch 23/100\n",
      "202/202 [==============================] - 0s 183us/sample - loss: 0.3565 - acc: 0.8663\n",
      "Epoch 24/100\n",
      "202/202 [==============================] - 0s 253us/sample - loss: 0.3516 - acc: 0.8663\n",
      "Epoch 25/100\n",
      "202/202 [==============================] - 0s 248us/sample - loss: 0.3477 - acc: 0.8663\n",
      "Epoch 26/100\n",
      "202/202 [==============================] - 0s 188us/sample - loss: 0.3427 - acc: 0.8663\n",
      "Epoch 27/100\n",
      "202/202 [==============================] - 0s 253us/sample - loss: 0.3396 - acc: 0.8663\n",
      "Epoch 28/100\n",
      "202/202 [==============================] - 0s 164us/sample - loss: 0.3356 - acc: 0.8812\n",
      "Epoch 29/100\n",
      "202/202 [==============================] - 0s 256us/sample - loss: 0.3331 - acc: 0.8762\n",
      "Epoch 30/100\n",
      "202/202 [==============================] - 0s 256us/sample - loss: 0.3294 - acc: 0.8762\n",
      "Epoch 31/100\n",
      "202/202 [==============================] - 0s 163us/sample - loss: 0.3268 - acc: 0.8762\n",
      "Epoch 32/100\n",
      "202/202 [==============================] - 0s 217us/sample - loss: 0.3237 - acc: 0.8812\n",
      "Epoch 33/100\n",
      "202/202 [==============================] - 0s 187us/sample - loss: 0.3214 - acc: 0.8812\n",
      "Epoch 34/100\n",
      "202/202 [==============================] - 0s 243us/sample - loss: 0.3188 - acc: 0.8812\n",
      "Epoch 35/100\n",
      "202/202 [==============================] - 0s 249us/sample - loss: 0.3161 - acc: 0.8812\n",
      "Epoch 36/100\n",
      "202/202 [==============================] - 0s 185us/sample - loss: 0.3140 - acc: 0.8812\n",
      "Epoch 37/100\n",
      "202/202 [==============================] - 0s 251us/sample - loss: 0.3116 - acc: 0.8812\n",
      "Epoch 38/100\n",
      "202/202 [==============================] - 0s 242us/sample - loss: 0.3101 - acc: 0.8812\n",
      "Epoch 39/100\n",
      "202/202 [==============================] - 0s 159us/sample - loss: 0.3080 - acc: 0.8812\n",
      "Epoch 40/100\n",
      "202/202 [==============================] - 0s 221us/sample - loss: 0.3058 - acc: 0.8812\n",
      "Epoch 41/100\n",
      "202/202 [==============================] - 0s 214us/sample - loss: 0.3042 - acc: 0.8812\n",
      "Epoch 42/100\n",
      "202/202 [==============================] - 0s 177us/sample - loss: 0.3020 - acc: 0.8812\n",
      "Epoch 43/100\n",
      "202/202 [==============================] - 0s 263us/sample - loss: 0.3002 - acc: 0.8812\n",
      "Epoch 44/100\n",
      "202/202 [==============================] - 0s 166us/sample - loss: 0.2982 - acc: 0.8911\n",
      "Epoch 45/100\n",
      "202/202 [==============================] - 0s 221us/sample - loss: 0.2967 - acc: 0.8911\n",
      "Epoch 46/100\n",
      "202/202 [==============================] - 0s 163us/sample - loss: 0.2945 - acc: 0.8911\n",
      "Epoch 47/100\n",
      "202/202 [==============================] - 0s 217us/sample - loss: 0.2927 - acc: 0.8911\n",
      "Epoch 48/100\n",
      "202/202 [==============================] - 0s 202us/sample - loss: 0.2910 - acc: 0.8911\n",
      "Epoch 49/100\n",
      "202/202 [==============================] - 0s 254us/sample - loss: 0.2893 - acc: 0.8911\n",
      "Epoch 50/100\n",
      "202/202 [==============================] - 0s 188us/sample - loss: 0.2875 - acc: 0.8911\n",
      "Epoch 51/100\n",
      "202/202 [==============================] - 0s 254us/sample - loss: 0.2861 - acc: 0.8911\n",
      "Epoch 52/100\n",
      "202/202 [==============================] - 0s 192us/sample - loss: 0.2841 - acc: 0.8911\n",
      "Epoch 53/100\n",
      "202/202 [==============================] - 0s 294us/sample - loss: 0.2824 - acc: 0.8911\n",
      "Epoch 54/100\n",
      "202/202 [==============================] - 0s 206us/sample - loss: 0.2809 - acc: 0.8911\n",
      "Epoch 55/100\n",
      "202/202 [==============================] - 0s 182us/sample - loss: 0.2794 - acc: 0.8911\n",
      "Epoch 56/100\n",
      "202/202 [==============================] - 0s 267us/sample - loss: 0.2776 - acc: 0.8911\n",
      "Epoch 57/100\n",
      "202/202 [==============================] - 0s 194us/sample - loss: 0.2765 - acc: 0.8861\n",
      "Epoch 58/100\n",
      "202/202 [==============================] - 0s 253us/sample - loss: 0.2748 - acc: 0.8861\n",
      "Epoch 59/100\n",
      "202/202 [==============================] - 0s 184us/sample - loss: 0.2725 - acc: 0.8861\n",
      "Epoch 60/100\n",
      "202/202 [==============================] - 0s 259us/sample - loss: 0.2714 - acc: 0.8861\n",
      "Epoch 61/100\n",
      "202/202 [==============================] - 0s 182us/sample - loss: 0.2700 - acc: 0.8911\n",
      "Epoch 62/100\n",
      "202/202 [==============================] - 0s 255us/sample - loss: 0.2684 - acc: 0.8911\n",
      "Epoch 63/100\n",
      "202/202 [==============================] - 0s 259us/sample - loss: 0.2667 - acc: 0.8911\n",
      "Epoch 64/100\n",
      "202/202 [==============================] - 0s 182us/sample - loss: 0.2651 - acc: 0.8960\n",
      "Epoch 65/100\n",
      "202/202 [==============================] - 0s 261us/sample - loss: 0.2642 - acc: 0.8911\n",
      "Epoch 66/100\n",
      "202/202 [==============================] - 0s 160us/sample - loss: 0.2622 - acc: 0.8960\n",
      "Epoch 67/100\n",
      "202/202 [==============================] - 0s 251us/sample - loss: 0.2606 - acc: 0.8960\n",
      "Epoch 68/100\n",
      "202/202 [==============================] - 0s 176us/sample - loss: 0.2589 - acc: 0.9010\n",
      "Epoch 69/100\n",
      "202/202 [==============================] - 0s 257us/sample - loss: 0.2578 - acc: 0.9010\n",
      "Epoch 70/100\n",
      "202/202 [==============================] - 0s 166us/sample - loss: 0.2558 - acc: 0.9010\n",
      "Epoch 71/100\n",
      "202/202 [==============================] - 0s 212us/sample - loss: 0.2548 - acc: 0.9010\n",
      "Epoch 72/100\n",
      "202/202 [==============================] - 0s 203us/sample - loss: 0.2533 - acc: 0.9010\n",
      "Epoch 73/100\n",
      "202/202 [==============================] - 0s 161us/sample - loss: 0.2517 - acc: 0.9010\n",
      "Epoch 74/100\n",
      "202/202 [==============================] - 0s 278us/sample - loss: 0.2508 - acc: 0.9010\n",
      "Epoch 75/100\n",
      "202/202 [==============================] - 0s 244us/sample - loss: 0.2493 - acc: 0.9010\n",
      "Epoch 76/100\n",
      "202/202 [==============================] - 0s 161us/sample - loss: 0.2475 - acc: 0.9059\n",
      "Epoch 77/100\n",
      "202/202 [==============================] - 0s 239us/sample - loss: 0.2470 - acc: 0.9059\n",
      "Epoch 78/100\n",
      "202/202 [==============================] - 0s 186us/sample - loss: 0.2455 - acc: 0.9059\n",
      "Epoch 79/100\n",
      "202/202 [==============================] - 0s 258us/sample - loss: 0.2440 - acc: 0.9059\n",
      "Epoch 80/100\n",
      "202/202 [==============================] - 0s 163us/sample - loss: 0.2428 - acc: 0.9059\n",
      "Epoch 81/100\n",
      "202/202 [==============================] - 0s 264us/sample - loss: 0.2421 - acc: 0.9059\n",
      "Epoch 82/100\n",
      "202/202 [==============================] - 0s 248us/sample - loss: 0.2407 - acc: 0.9109\n",
      "Epoch 83/100\n",
      "202/202 [==============================] - 0s 162us/sample - loss: 0.2393 - acc: 0.9109\n",
      "Epoch 84/100\n",
      "202/202 [==============================] - 0s 251us/sample - loss: 0.2380 - acc: 0.9109\n",
      "Epoch 85/100\n",
      "202/202 [==============================] - 0s 249us/sample - loss: 0.2375 - acc: 0.9109\n",
      "Epoch 86/100\n",
      "202/202 [==============================] - 0s 159us/sample - loss: 0.2354 - acc: 0.9109\n",
      "Epoch 87/100\n",
      "202/202 [==============================] - 0s 236us/sample - loss: 0.2341 - acc: 0.9109\n",
      "Epoch 88/100\n",
      "202/202 [==============================] - 0s 183us/sample - loss: 0.2329 - acc: 0.9109\n",
      "Epoch 89/100\n",
      "202/202 [==============================] - 0s 264us/sample - loss: 0.2317 - acc: 0.9109\n",
      "Epoch 90/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202/202 [==============================] - 0s 161us/sample - loss: 0.2304 - acc: 0.9158\n",
      "Epoch 91/100\n",
      "202/202 [==============================] - 0s 224us/sample - loss: 0.2295 - acc: 0.9158\n",
      "Epoch 92/100\n",
      "202/202 [==============================] - 0s 191us/sample - loss: 0.2283 - acc: 0.9158\n",
      "Epoch 93/100\n",
      "202/202 [==============================] - 0s 249us/sample - loss: 0.2276 - acc: 0.9158\n",
      "Epoch 94/100\n",
      "202/202 [==============================] - 0s 163us/sample - loss: 0.2257 - acc: 0.9158\n",
      "Epoch 95/100\n",
      "202/202 [==============================] - 0s 219us/sample - loss: 0.2254 - acc: 0.9158\n",
      "Epoch 96/100\n",
      "202/202 [==============================] - 0s 187us/sample - loss: 0.2239 - acc: 0.9208\n",
      "Epoch 97/100\n",
      "202/202 [==============================] - 0s 258us/sample - loss: 0.2227 - acc: 0.9208\n",
      "Epoch 98/100\n",
      "202/202 [==============================] - 0s 185us/sample - loss: 0.2218 - acc: 0.9208\n",
      "Epoch 99/100\n",
      "202/202 [==============================] - 0s 250us/sample - loss: 0.2207 - acc: 0.9208\n",
      "Epoch 100/100\n",
      "202/202 [==============================] - 0s 248us/sample - loss: 0.2190 - acc: 0.9208\n",
      "101/101 [==============================] - 0s 2ms/sample - loss: 0.5162 - acc: 0.7822\n",
      "202/202 [==============================] - 0s 191us/sample - loss: 0.2174 - acc: 0.9208\n",
      "Epoch 1/50\n",
      "303/303 [==============================] - 0s 900us/sample - loss: 0.5308 - acc: 0.7393\n",
      "Epoch 2/50\n",
      "303/303 [==============================] - 0s 192us/sample - loss: 0.4895 - acc: 0.7624\n",
      "Epoch 3/50\n",
      "303/303 [==============================] - 0s 192us/sample - loss: 0.4600 - acc: 0.7690\n",
      "Epoch 4/50\n",
      "303/303 [==============================] - 0s 216us/sample - loss: 0.4381 - acc: 0.7822\n",
      "Epoch 5/50\n",
      "303/303 [==============================] - 0s 213us/sample - loss: 0.4209 - acc: 0.7987\n",
      "Epoch 6/50\n",
      "303/303 [==============================] - 0s 212us/sample - loss: 0.4071 - acc: 0.7987\n",
      "Epoch 7/50\n",
      "303/303 [==============================] - 0s 225us/sample - loss: 0.3953 - acc: 0.8020\n",
      "Epoch 8/50\n",
      "303/303 [==============================] - 0s 216us/sample - loss: 0.3852 - acc: 0.8185\n",
      "Epoch 9/50\n",
      "303/303 [==============================] - 0s 216us/sample - loss: 0.3769 - acc: 0.8251\n",
      "Epoch 10/50\n",
      "303/303 [==============================] - 0s 214us/sample - loss: 0.3684 - acc: 0.8251\n",
      "Epoch 11/50\n",
      "303/303 [==============================] - 0s 212us/sample - loss: 0.3622 - acc: 0.8284\n",
      "Epoch 12/50\n",
      "303/303 [==============================] - 0s 213us/sample - loss: 0.3563 - acc: 0.8317\n",
      "Epoch 13/50\n",
      "303/303 [==============================] - 0s 217us/sample - loss: 0.3509 - acc: 0.8317\n",
      "Epoch 14/50\n",
      "303/303 [==============================] - 0s 215us/sample - loss: 0.3465 - acc: 0.8284\n",
      "Epoch 15/50\n",
      "303/303 [==============================] - 0s 212us/sample - loss: 0.3421 - acc: 0.8317\n",
      "Epoch 16/50\n",
      "303/303 [==============================] - 0s 218us/sample - loss: 0.3379 - acc: 0.8383\n",
      "Epoch 17/50\n",
      "303/303 [==============================] - 0s 213us/sample - loss: 0.3340 - acc: 0.8449\n",
      "Epoch 18/50\n",
      "303/303 [==============================] - 0s 205us/sample - loss: 0.3302 - acc: 0.8548\n",
      "Epoch 19/50\n",
      "303/303 [==============================] - 0s 190us/sample - loss: 0.3269 - acc: 0.8614\n",
      "Epoch 20/50\n",
      "303/303 [==============================] - 0s 220us/sample - loss: 0.3241 - acc: 0.8548\n",
      "Epoch 21/50\n",
      "303/303 [==============================] - 0s 215us/sample - loss: 0.3211 - acc: 0.8581\n",
      "Epoch 22/50\n",
      "303/303 [==============================] - 0s 215us/sample - loss: 0.3187 - acc: 0.8614\n",
      "Epoch 23/50\n",
      "303/303 [==============================] - 0s 212us/sample - loss: 0.3163 - acc: 0.8647\n",
      "Epoch 24/50\n",
      "303/303 [==============================] - 0s 215us/sample - loss: 0.3150 - acc: 0.8647\n",
      "Epoch 25/50\n",
      "303/303 [==============================] - 0s 222us/sample - loss: 0.3123 - acc: 0.8647\n",
      "Epoch 26/50\n",
      "303/303 [==============================] - 0s 226us/sample - loss: 0.3096 - acc: 0.8614\n",
      "Epoch 27/50\n",
      "303/303 [==============================] - 0s 225us/sample - loss: 0.3073 - acc: 0.8647\n",
      "Epoch 28/50\n",
      "303/303 [==============================] - 0s 242us/sample - loss: 0.3054 - acc: 0.8614\n",
      "Epoch 29/50\n",
      "303/303 [==============================] - 0s 285us/sample - loss: 0.3035 - acc: 0.8647\n",
      "Epoch 30/50\n",
      "303/303 [==============================] - 0s 259us/sample - loss: 0.3013 - acc: 0.8581\n",
      "Epoch 31/50\n",
      "303/303 [==============================] - 0s 252us/sample - loss: 0.2988 - acc: 0.8647\n",
      "Epoch 32/50\n",
      "303/303 [==============================] - 0s 736us/sample - loss: 0.2972 - acc: 0.8614\n",
      "Epoch 33/50\n",
      "303/303 [==============================] - 0s 268us/sample - loss: 0.2958 - acc: 0.8614\n",
      "Epoch 34/50\n",
      "303/303 [==============================] - 0s 309us/sample - loss: 0.2934 - acc: 0.8680\n",
      "Epoch 35/50\n",
      "303/303 [==============================] - 0s 330us/sample - loss: 0.2920 - acc: 0.8647\n",
      "Epoch 36/50\n",
      "303/303 [==============================] - 0s 343us/sample - loss: 0.2902 - acc: 0.8713s - loss: 0.2999 - acc: 0.880\n",
      "Epoch 37/50\n",
      "303/303 [==============================] - 0s 218us/sample - loss: 0.2892 - acc: 0.8746\n",
      "Epoch 38/50\n",
      "303/303 [==============================] - 0s 327us/sample - loss: 0.2875 - acc: 0.8746\n",
      "Epoch 39/50\n",
      "303/303 [==============================] - 0s 297us/sample - loss: 0.2868 - acc: 0.8746\n",
      "Epoch 40/50\n",
      "303/303 [==============================] - 0s 312us/sample - loss: 0.2845 - acc: 0.8746\n",
      "Epoch 41/50\n",
      "303/303 [==============================] - 0s 181us/sample - loss: 0.2831 - acc: 0.8746\n",
      "Epoch 42/50\n",
      "303/303 [==============================] - 0s 189us/sample - loss: 0.2817 - acc: 0.8746\n",
      "Epoch 43/50\n",
      "303/303 [==============================] - 0s 215us/sample - loss: 0.2805 - acc: 0.8713\n",
      "Epoch 44/50\n",
      "303/303 [==============================] - 0s 209us/sample - loss: 0.2793 - acc: 0.8680\n",
      "Epoch 45/50\n",
      "303/303 [==============================] - 0s 246us/sample - loss: 0.2775 - acc: 0.8812\n",
      "Epoch 46/50\n",
      "303/303 [==============================] - 0s 267us/sample - loss: 0.2768 - acc: 0.8878\n",
      "Epoch 47/50\n",
      "303/303 [==============================] - 0s 244us/sample - loss: 0.2747 - acc: 0.8812\n",
      "Epoch 48/50\n",
      "303/303 [==============================] - 0s 212us/sample - loss: 0.2736 - acc: 0.8812\n",
      "Epoch 49/50\n",
      "303/303 [==============================] - 0s 212us/sample - loss: 0.2728 - acc: 0.8746\n",
      "Epoch 50/50\n",
      "303/303 [==============================] - 0s 213us/sample - loss: 0.2716 - acc: 0.8845\n"
     ]
    }
   ],
   "source": [
    "# New model\n",
    "model = KerasClassifier(build_fn=create_model, verbose=1)\n",
    "\n",
    "# Create Grid Search\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1, cv=3)\n",
    "grid_result = grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.8316831588745117 using {'batch_size': 10, 'epochs': 50}\n"
     ]
    }
   ],
   "source": [
    "# Report Results\n",
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 0.6642 - acc: 0.5661\n",
      "Epoch 2/50\n",
      "242/242 [==============================] - 0s 265us/sample - loss: 0.5998 - acc: 0.6777\n",
      "Epoch 3/50\n",
      "242/242 [==============================] - 0s 267us/sample - loss: 0.5522 - acc: 0.7397\n",
      "Epoch 4/50\n",
      "242/242 [==============================] - 0s 272us/sample - loss: 0.5178 - acc: 0.7686\n",
      "Epoch 5/50\n",
      "242/242 [==============================] - 0s 272us/sample - loss: 0.4881 - acc: 0.7934\n",
      "Epoch 6/50\n",
      "242/242 [==============================] - 0s 273us/sample - loss: 0.4633 - acc: 0.8099\n",
      "Epoch 7/50\n",
      "242/242 [==============================] - 0s 263us/sample - loss: 0.4438 - acc: 0.8140\n",
      "Epoch 8/50\n",
      "242/242 [==============================] - 0s 220us/sample - loss: 0.4278 - acc: 0.8182\n",
      "Epoch 9/50\n",
      "242/242 [==============================] - 0s 282us/sample - loss: 0.4130 - acc: 0.8306\n",
      "Epoch 10/50\n",
      "242/242 [==============================] - 0s 298us/sample - loss: 0.4001 - acc: 0.8306\n",
      "Epoch 11/50\n",
      "242/242 [==============================] - 0s 274us/sample - loss: 0.3898 - acc: 0.8264\n",
      "Epoch 12/50\n",
      "242/242 [==============================] - 0s 337us/sample - loss: 0.3803 - acc: 0.8306\n",
      "Epoch 13/50\n",
      "242/242 [==============================] - 0s 334us/sample - loss: 0.3724 - acc: 0.8347\n",
      "Epoch 14/50\n",
      "242/242 [==============================] - 0s 344us/sample - loss: 0.3645 - acc: 0.8471\n",
      "Epoch 15/50\n",
      "242/242 [==============================] - 0s 382us/sample - loss: 0.3573 - acc: 0.8512\n",
      "Epoch 16/50\n",
      "242/242 [==============================] - 0s 295us/sample - loss: 0.3511 - acc: 0.8554\n",
      "Epoch 17/50\n",
      "242/242 [==============================] - 0s 295us/sample - loss: 0.3458 - acc: 0.8636\n",
      "Epoch 18/50\n",
      "242/242 [==============================] - 0s 329us/sample - loss: 0.3409 - acc: 0.8636\n",
      "Epoch 19/50\n",
      "242/242 [==============================] - 0s 377us/sample - loss: 0.3361 - acc: 0.8678\n",
      "Epoch 20/50\n",
      "242/242 [==============================] - 0s 441us/sample - loss: 0.3321 - acc: 0.8678\n",
      "Epoch 21/50\n",
      "242/242 [==============================] - 0s 256us/sample - loss: 0.3284 - acc: 0.8719\n",
      "Epoch 22/50\n",
      "242/242 [==============================] - 0s 299us/sample - loss: 0.3245 - acc: 0.8719\n",
      "Epoch 23/50\n",
      "242/242 [==============================] - 0s 337us/sample - loss: 0.3212 - acc: 0.8678\n",
      "Epoch 24/50\n",
      "242/242 [==============================] - 0s 285us/sample - loss: 0.3185 - acc: 0.8719\n",
      "Epoch 25/50\n",
      "242/242 [==============================] - 0s 385us/sample - loss: 0.3151 - acc: 0.8719\n",
      "Epoch 26/50\n",
      "242/242 [==============================] - 0s 320us/sample - loss: 0.3121 - acc: 0.8719\n",
      "Epoch 27/50\n",
      "242/242 [==============================] - 0s 280us/sample - loss: 0.3096 - acc: 0.8802\n",
      "Epoch 28/50\n",
      "242/242 [==============================] - 0s 337us/sample - loss: 0.3070 - acc: 0.8802\n",
      "Epoch 29/50\n",
      "242/242 [==============================] - 0s 386us/sample - loss: 0.3046 - acc: 0.8802\n",
      "Epoch 30/50\n",
      "242/242 [==============================] - 0s 621us/sample - loss: 0.3023 - acc: 0.8802\n",
      "Epoch 31/50\n",
      "242/242 [==============================] - 0s 705us/sample - loss: 0.3001 - acc: 0.8843\n",
      "Epoch 32/50\n",
      "242/242 [==============================] - 0s 692us/sample - loss: 0.2978 - acc: 0.8884\n",
      "Epoch 33/50\n",
      "242/242 [==============================] - 0s 601us/sample - loss: 0.2965 - acc: 0.8843\n",
      "Epoch 34/50\n",
      "242/242 [==============================] - 0s 577us/sample - loss: 0.2942 - acc: 0.8843\n",
      "Epoch 35/50\n",
      "242/242 [==============================] - 0s 407us/sample - loss: 0.2923 - acc: 0.8843\n",
      "Epoch 36/50\n",
      "242/242 [==============================] - 0s 279us/sample - loss: 0.2903 - acc: 0.8843\n",
      "Epoch 37/50\n",
      "242/242 [==============================] - 0s 340us/sample - loss: 0.2885 - acc: 0.8884\n",
      "Epoch 38/50\n",
      "242/242 [==============================] - 0s 337us/sample - loss: 0.2870 - acc: 0.8843\n",
      "Epoch 39/50\n",
      "242/242 [==============================] - 0s 369us/sample - loss: 0.2852 - acc: 0.8884\n",
      "Epoch 40/50\n",
      "242/242 [==============================] - 0s 697us/sample - loss: 0.2844 - acc: 0.8884\n",
      "Epoch 41/50\n",
      "242/242 [==============================] - 0s 569us/sample - loss: 0.2825 - acc: 0.8884\n",
      "Epoch 42/50\n",
      "242/242 [==============================] - 0s 753us/sample - loss: 0.2815 - acc: 0.8884\n",
      "Epoch 43/50\n",
      "242/242 [==============================] - 0s 953us/sample - loss: 0.2795 - acc: 0.8884\n",
      "Epoch 44/50\n",
      "242/242 [==============================] - 0s 736us/sample - loss: 0.2781 - acc: 0.8884\n",
      "Epoch 45/50\n",
      "242/242 [==============================] - 0s 610us/sample - loss: 0.2766 - acc: 0.8884\n",
      "Epoch 46/50\n",
      "242/242 [==============================] - 0s 389us/sample - loss: 0.2754 - acc: 0.8884\n",
      "Epoch 47/50\n",
      "242/242 [==============================] - 0s 413us/sample - loss: 0.2738 - acc: 0.8884\n",
      "Epoch 48/50\n",
      "242/242 [==============================] - 0s 254us/sample - loss: 0.2726 - acc: 0.8884\n",
      "Epoch 49/50\n",
      "242/242 [==============================] - 0s 457us/sample - loss: 0.2710 - acc: 0.8884\n",
      "Epoch 50/50\n",
      "242/242 [==============================] - 0s 276us/sample - loss: 0.2703 - acc: 0.8843\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a411ed860>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# New model\n",
    "model = create_model()\n",
    "model.fit(X_train, y_train, batch_size=10, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61/61 [==============================] - 0s 3ms/sample - loss: 0.4583 - acc: 0.7869\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.45829280526911625, 0.78688526]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate model\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Final Accuracy: 78.69%**"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nteract": {
   "version": "0.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
