{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2*\n",
    "\n",
    "# Sprint Challenge - Neural Network Foundations\n",
    "\n",
    "Table of Problems\n",
    "\n",
    "1. [Defining Neural Networks](#Q1)\n",
    "2. [Perceptron on XOR Gates](#Q2)\n",
    "3. [Multilayer Perceptron](#Q3)\n",
    "4. [Keras MMP](#Q4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Q1\"></a>\n",
    "## 1. Define the following terms:\n",
    "\n",
    "- **Neuron:** An individual node in a layer of a Neural Network. Each neuron sends the weighted sum of its inputs through an activation function. The output of a neuron is the value of the activation function.\n",
    "\n",
    "- **Input Layer:** The first layer of a Neural Network which takes the values of features as inputs.\n",
    "\n",
    "- **Hidden Layer:** Any layer between the input and output layer. These layers add complexity.\n",
    "\n",
    "- **Output Layer:** The final layer of a Neural Network which returns the output we're looking for.\n",
    "\n",
    "- **Activation:** The function that determines the final output of a Neuron. This is analogous to \"how much a Neuron fires\" in the brain.\n",
    "\n",
    "- **Backpropagation:** The process by which weights in the Neural Network are adjusted.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Perceptron on XOR Gates <a id=\"Q3=2\"></a>\n",
    "\n",
    "Create a perceptron class that can model the behavior of an AND gate. You can use the following table as your training data:\n",
    "\n",
    "|x1\t|x2|x3|\ty|\n",
    "|---|---|---|---|\n",
    "1|\t1|\t1|\t1|\n",
    "1|\t0|\t1|\t0|\n",
    "0|\t1|\t1|\t0|\n",
    "0|\t0|\t1|\t0|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set the input and output\n",
    "inputs = np.array([\n",
    "    [1, 1, 1],\n",
    "    [1, 0, 1],\n",
    "    [0, 1, 1],\n",
    "    [0, 0, 1]\n",
    "])\n",
    "\n",
    "correct_outputs = [[1], [0], [0], [0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the activation function & derivative\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Derivative of sigmoid\n",
    "def sigmoid_derivative(x):\n",
    "    sx = sigmoid(x)\n",
    "    return sx * (1-sx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.25091976],\n",
       "       [ 0.90142861],\n",
       "       [ 0.46398788]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep weights bounded [-1, 1]\n",
    "weights = 2 * np.random.random((3, 1)) - 1\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output after Training:\n",
      "[[9.96429406e-01]\n",
      " [2.00908516e-03]\n",
      " [2.00908516e-03]\n",
      " [1.45223694e-08]]\n"
     ]
    }
   ],
   "source": [
    "# trian for 10,000 epochs\n",
    "for iteration in range(10000):\n",
    "    # weighted sum\n",
    "    weighted_sum = np.dot(inputs, weights)\n",
    "    \n",
    "    # Activate using Sigmoid\n",
    "    activated_output = sigmoid(weighted_sum)\n",
    "    \n",
    "    # Errors & Adjustments\n",
    "    error = correct_outputs - activated_output\n",
    "    adjustments = error * sigmoid_derivative(activated_output)\n",
    "    \n",
    "    # Update weights\n",
    "    weights += np.dot(inputs.T, adjustments)\n",
    "    \n",
    "print('Output after Training:')\n",
    "print(activated_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Multilayer Perceptron <a id=\"Q3\"></a>\n",
    "\n",
    "Implement a Neural Network Multilayer Perceptron class that uses backpropagation to update the network's weights.\n",
    "Your network must have one hidden layer.\n",
    "You do not have to update weights via gradient descent. You can use something like the derivative of the sigmoid function to update weights.\n",
    "Train your model on the Heart Disease dataset from UCI:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(303, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>112</td>\n",
       "      <td>230</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>165</td>\n",
       "      <td>0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>110</td>\n",
       "      <td>265</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>94</td>\n",
       "      <td>199</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>179</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>288</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>159</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>135</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "183   58    1   2       112   230    0        0      165      0      2.5   \n",
       "60    71    0   2       110   265    1        0      130      0      0.0   \n",
       "124   39    0   2        94   199    0        1      179      0      0.0   \n",
       "93    54    0   1       132   288    1        0      159      1      0.0   \n",
       "63    41    1   1       135   203    0        1      132      0      0.0   \n",
       "\n",
       "     slope  ca  thal  target  \n",
       "183      1   1     3       0  \n",
       "60       2   1     2       1  \n",
       "124      2   0     2       1  \n",
       "93       2   1     2       1  \n",
       "63       1   0     1       1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/ryanleeallred/datasets/master/heart.csv')\n",
    "df = df.sample(frac=1)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "# Select Features & train_test split\n",
    "features = df.columns.tolist()[0:13]\n",
    "target = df.columns.tolist()[13]\n",
    "\n",
    "# Split by features & target\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# Instantiate scaler\n",
    "scaler = StandardScaler()\n",
    "# Normalize X\n",
    "X = pd.DataFrame(scaler.fit_transform(X), columns = features)\n",
    "\n",
    "# Train/Test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(242, 13)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(61, 13)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP:\n",
    "    def __init__(self):\n",
    "        # Set up Architecture\n",
    "        self.inputs = 13\n",
    "        self.hiddenNodes = 4\n",
    "        self.output = 1\n",
    "        \n",
    "        # Initialize Weights\n",
    "        self.weights1 = np.random.rand(self.inputs, self.hiddenNodes)\n",
    "        self.weights2 = np.random.rand(self.hiddenNodes, self.output)\n",
    "        \n",
    "    # Define the activation function & derivative\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    # Derivative of sigmoid\n",
    "    def sigmoid_derivative(self, x):\n",
    "        sx = self.sigmoid(x)\n",
    "        return sx * (1-sx)\n",
    "    \n",
    "    # Forward Propogation\n",
    "    def feed_forward(self, X):\n",
    "        # Activation of Weighted Sum\n",
    "        self.hidden_sum = np.dot(X, self.weights1)\n",
    "        self.activated_hidden = self.sigmoid(self.hidden_sum)\n",
    "        \n",
    "        # Next Layer\n",
    "        self.output_sum = np.dot(self.activated_hidden, self.weights2)\n",
    "        self.activated_output = self.sigmoid(self.output_sum)\n",
    "        \n",
    "        return self.activated_output\n",
    "    \n",
    "    # Backward Propagation\n",
    "    def feed_backward(self, X, y, y_pred):\n",
    "        # Output --> Hidden\n",
    "        self.output_error = y.values - y_pred\n",
    "        self.output_delta = self.output_error.dot(self.sigmoid_derivative(y_pred))\n",
    "        \n",
    "        # Hidden --> Input\n",
    "        self.input_error = self.output_delta.dot(self.weights2.T)\n",
    "        self.input_delta = self.input_error*self.sigmoid_derivative(self.activated_hidden)\n",
    "        \n",
    "        # Update Weights\n",
    "        self.weights1 += X.T.dot(self.input_delta)\n",
    "        self.weights2 += self.activated_hidden.T.dot(self.output_delta)\n",
    "        \n",
    "    # Train MLP\n",
    "    def train(self, X, y):\n",
    "        y_pred = self.feed_forward(X)\n",
    "        self.feed_backward(X, y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate MLP\n",
    "mlp = MLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = mlp.feed_forward(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------EPOCH 1---------+\n",
      "Accuracy: \n",
      " 0.5445544554455446\n",
      "+---------EPOCH 2---------+\n",
      "Accuracy: \n",
      " 0.45544554455445546\n",
      "+---------EPOCH 3---------+\n",
      "Accuracy: \n",
      " 0.5436721889970403\n",
      "+---------EPOCH 4---------+\n",
      "Accuracy: \n",
      " 0.45544554455445546\n",
      "+---------EPOCH 5---------+\n",
      "Accuracy: \n",
      " 0.45544554455445546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:14: RuntimeWarning: overflow encountered in exp\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------EPOCH 1000---------+\n",
      "Accuracy: \n",
      " 0.5269091217242975\n",
      "+---------EPOCH 2000---------+\n",
      "Accuracy: \n",
      " 0.45544554455445546\n",
      "+---------EPOCH 3000---------+\n",
      "Accuracy: \n",
      " 0.5445544554455446\n",
      "+---------EPOCH 4000---------+\n",
      "Accuracy: \n",
      " 0.5442603666434658\n",
      "+---------EPOCH 5000---------+\n",
      "Accuracy: \n",
      " 0.45544554455445546\n",
      "+---------EPOCH 6000---------+\n",
      "Accuracy: \n",
      " 0.5330849916674836\n",
      "+---------EPOCH 7000---------+\n",
      "Accuracy: \n",
      " 0.45544554455445546\n",
      "+---------EPOCH 8000---------+\n",
      "Accuracy: \n",
      " 0.523085962982914\n",
      "+---------EPOCH 9000---------+\n",
      "Accuracy: \n",
      " 0.4555925889618665\n",
      "+---------EPOCH 10000---------+\n",
      "Accuracy: \n",
      " 0.45544554455445546\n"
     ]
    }
   ],
   "source": [
    "# Set number of Epochs\n",
    "for i in range(10000):\n",
    "    if (i+1 in [1,2,3,4,5]) or ((i+1) % 1000 ==0):\n",
    "        print('+' + '---' * 3 + f'EPOCH {i+1}' + '---'*3 + '+')\n",
    "        print(\"Accuracy: \\n\", str(((abs(y.values - mlp.feed_forward(X)).sum()) / (303 * 303))))\n",
    "    mlp.train(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Keras MMP <a id=\"Q4\"></a>\n",
    "\n",
    "Implement a Multilayer Perceptron architecture of your choosing using the Keras library. Train your model and report its baseline accuracy. Then hyperparameter tune at least two parameters and report your model's accuracy.\n",
    "Use the Heart Disease Dataset (binary classification)\n",
    "Use an appropriate loss function for a binary classification task\n",
    "Use an appropriate activation function on the final layer of your network.\n",
    "Train your model using verbose output for ease of grading.\n",
    "Use GridSearchCV to hyperparameter tune your model. (for at least two hyperparameters)\n",
    "When hyperparameter tuning, show you work by adding code cells for each new experiment.\n",
    "Report the accuracy for each combination of hyperparameters as you test them so that we can easily see which resulted in the highest accuracy.\n",
    "You must hyperparameter tune at least 5 parameters in order to get a 3 on this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(303, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>134</td>\n",
       "      <td>409</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>138</td>\n",
       "      <td>223</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>177</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>160</td>\n",
       "      <td>234</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "246   56    0   0       134   409    0        0      150      1      1.9   \n",
       "92    52    1   2       138   223    0        1      169      0      0.0   \n",
       "149   42    1   2       130   180    0        1      150      0      0.0   \n",
       "178   43    1   0       120   177    0        0      120      1      2.5   \n",
       "106   69    1   3       160   234    1        0      131      0      0.1   \n",
       "\n",
       "     slope  ca  thal  target  \n",
       "246      1   2     3       0  \n",
       "92       2   4     2       1  \n",
       "149      2   0     2       1  \n",
       "178      1   0     3       0  \n",
       "106      1   1     2       1  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/ryanleeallred/datasets/master/heart.csv')\n",
    "df = df.sample(frac=1)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "# Select Features & train_test split\n",
    "features = df.columns.tolist()[0:13]\n",
    "target = df.columns.tolist()[13]\n",
    "\n",
    "# Split by features & target\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# Instantiate scaler\n",
    "scaler = StandardScaler()\n",
    "# Normalize X\n",
    "X = pd.DataFrame(scaler.fit_transform(X), columns = features)\n",
    "\n",
    "# Train/Test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(812)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model function for Keras Classifier\n",
    "def create_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=13, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/10\n",
      "242/242 [==============================] - 0s 416us/sample - loss: 0.6525 - acc: 0.6116\n",
      "Epoch 2/10\n",
      "242/242 [==============================] - 0s 160us/sample - loss: 0.6297 - acc: 0.6322\n",
      "Epoch 3/10\n",
      "242/242 [==============================] - 0s 97us/sample - loss: 0.6089 - acc: 0.6529\n",
      "Epoch 4/10\n",
      "242/242 [==============================] - 0s 106us/sample - loss: 0.5904 - acc: 0.6860\n",
      "Epoch 5/10\n",
      "242/242 [==============================] - 0s 76us/sample - loss: 0.5737 - acc: 0.7066\n",
      "Epoch 6/10\n",
      "242/242 [==============================] - 0s 125us/sample - loss: 0.5579 - acc: 0.7231\n",
      "Epoch 7/10\n",
      "242/242 [==============================] - 0s 157us/sample - loss: 0.5444 - acc: 0.7521\n",
      "Epoch 8/10\n",
      "242/242 [==============================] - 0s 130us/sample - loss: 0.5311 - acc: 0.7645\n",
      "Epoch 9/10\n",
      "242/242 [==============================] - 0s 140us/sample - loss: 0.5191 - acc: 0.7686\n",
      "Epoch 10/10\n",
      "242/242 [==============================] - 0s 44us/sample - loss: 0.5074 - acc: 0.7769\n",
      "61/61 [==============================] - 0s 586us/sample - loss: 0.5582 - acc: 0.7377\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5581578719811361, 0.73770493]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check baseline model stats\n",
    "model = create_model()\n",
    "\n",
    "# Fit\n",
    "model.fit(X_train, y_train, epochs=10)\n",
    "\n",
    "# Evaluate\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Baseline Accuracy: 67.21%**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune Batch Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define search params\n",
    "param_grid = {'batch_size': [10, 20, 40, 60, 80, 100],\n",
    "              'epochs': [10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "202/202 [==============================] - 0s 677us/sample - loss: 0.8241 - acc: 0.3317\n",
      "Epoch 2/10\n",
      "202/202 [==============================] - 0s 261us/sample - loss: 0.7757 - acc: 0.3812\n",
      "Epoch 3/10\n",
      "202/202 [==============================] - 0s 152us/sample - loss: 0.7327 - acc: 0.4604\n",
      "Epoch 4/10\n",
      "202/202 [==============================] - 0s 280us/sample - loss: 0.6950 - acc: 0.5446\n",
      "Epoch 5/10\n",
      "202/202 [==============================] - 0s 280us/sample - loss: 0.6621 - acc: 0.6337\n",
      "Epoch 6/10\n",
      "202/202 [==============================] - 0s 221us/sample - loss: 0.6294 - acc: 0.6832\n",
      "Epoch 7/10\n",
      "202/202 [==============================] - 0s 244us/sample - loss: 0.6003 - acc: 0.7327\n",
      "Epoch 8/10\n",
      "202/202 [==============================] - 0s 285us/sample - loss: 0.5728 - acc: 0.7673\n",
      "Epoch 9/10\n",
      "202/202 [==============================] - 0s 205us/sample - loss: 0.5471 - acc: 0.8069\n",
      "Epoch 10/10\n",
      "202/202 [==============================] - 0s 157us/sample - loss: 0.5229 - acc: 0.8119\n",
      "101/101 [==============================] - 0s 331us/sample - loss: 0.5460 - acc: 0.7723\n",
      "202/202 [==============================] - 0s 102us/sample - loss: 0.5098 - acc: 0.8168\n",
      "Epoch 1/10\n",
      "202/202 [==============================] - 0s 636us/sample - loss: 0.8124 - acc: 0.5050\n",
      "Epoch 2/10\n",
      "202/202 [==============================] - 0s 219us/sample - loss: 0.7425 - acc: 0.5594\n",
      "Epoch 3/10\n",
      "202/202 [==============================] - 0s 261us/sample - loss: 0.6839 - acc: 0.6436\n",
      "Epoch 4/10\n",
      "202/202 [==============================] - 0s 167us/sample - loss: 0.6357 - acc: 0.6733\n",
      "Epoch 5/10\n",
      "202/202 [==============================] - 0s 271us/sample - loss: 0.5963 - acc: 0.7178\n",
      "Epoch 6/10\n",
      "202/202 [==============================] - 0s 415us/sample - loss: 0.5624 - acc: 0.7871\n",
      "Epoch 7/10\n",
      "202/202 [==============================] - 0s 253us/sample - loss: 0.5333 - acc: 0.7723\n",
      "Epoch 8/10\n",
      "202/202 [==============================] - 0s 257us/sample - loss: 0.5085 - acc: 0.7624\n",
      "Epoch 9/10\n",
      "202/202 [==============================] - 0s 200us/sample - loss: 0.4859 - acc: 0.7772\n",
      "Epoch 10/10\n",
      "202/202 [==============================] - 0s 185us/sample - loss: 0.4669 - acc: 0.7970\n",
      "101/101 [==============================] - 0s 369us/sample - loss: 0.4858 - acc: 0.8119\n",
      "202/202 [==============================] - 0s 112us/sample - loss: 0.4568 - acc: 0.8119\n",
      "Epoch 1/10\n",
      "202/202 [==============================] - 0s 787us/sample - loss: 0.8077 - acc: 0.5446\n",
      "Epoch 2/10\n",
      "202/202 [==============================] - 0s 229us/sample - loss: 0.7324 - acc: 0.5792\n",
      "Epoch 3/10\n",
      "202/202 [==============================] - 0s 219us/sample - loss: 0.6685 - acc: 0.6287\n",
      "Epoch 4/10\n",
      "202/202 [==============================] - 0s 246us/sample - loss: 0.6181 - acc: 0.6584\n",
      "Epoch 5/10\n",
      "202/202 [==============================] - 0s 311us/sample - loss: 0.5754 - acc: 0.6931\n",
      "Epoch 6/10\n",
      "202/202 [==============================] - 0s 291us/sample - loss: 0.5430 - acc: 0.7178\n",
      "Epoch 7/10\n",
      "202/202 [==============================] - 0s 252us/sample - loss: 0.5156 - acc: 0.7525\n",
      "Epoch 8/10\n",
      "202/202 [==============================] - 0s 268us/sample - loss: 0.4929 - acc: 0.7871\n",
      "Epoch 9/10\n",
      "202/202 [==============================] - 0s 415us/sample - loss: 0.4737 - acc: 0.7970\n",
      "Epoch 10/10\n",
      "202/202 [==============================] - 0s 372us/sample - loss: 0.4583 - acc: 0.8020\n",
      "101/101 [==============================] - 0s 427us/sample - loss: 0.5108 - acc: 0.7426\n",
      "202/202 [==============================] - 0s 128us/sample - loss: 0.4491 - acc: 0.8020\n",
      "Epoch 1/10\n",
      "202/202 [==============================] - 0s 1ms/sample - loss: 1.0073 - acc: 0.4208\n",
      "Epoch 2/10\n",
      "202/202 [==============================] - 0s 569us/sample - loss: 0.9440 - acc: 0.4307\n",
      "Epoch 3/10\n",
      "202/202 [==============================] - 0s 290us/sample - loss: 0.8905 - acc: 0.4455\n",
      "Epoch 4/10\n",
      "202/202 [==============================] - 0s 329us/sample - loss: 0.8438 - acc: 0.4653\n",
      "Epoch 5/10\n",
      "202/202 [==============================] - 0s 529us/sample - loss: 0.8015 - acc: 0.4752\n",
      "Epoch 6/10\n",
      "202/202 [==============================] - 0s 74us/sample - loss: 0.7618 - acc: 0.4752\n",
      "Epoch 7/10\n",
      "202/202 [==============================] - 0s 595us/sample - loss: 0.7279 - acc: 0.5050\n",
      "Epoch 8/10\n",
      "202/202 [==============================] - 0s 443us/sample - loss: 0.6954 - acc: 0.5198\n",
      "Epoch 9/10\n",
      "202/202 [==============================] - 0s 345us/sample - loss: 0.6693 - acc: 0.5545\n",
      "Epoch 10/10\n",
      "202/202 [==============================] - 0s 391us/sample - loss: 0.6461 - acc: 0.5941\n",
      "101/101 [==============================] - 0s 520us/sample - loss: 0.7385 - acc: 0.5446\n",
      "202/202 [==============================] - 0s 313us/sample - loss: 0.6331 - acc: 0.6238\n",
      "Epoch 1/10\n",
      "202/202 [==============================] - 0s 544us/sample - loss: 0.7448 - acc: 0.3762\n",
      "Epoch 2/10\n",
      "202/202 [==============================] - 0s 348us/sample - loss: 0.7232 - acc: 0.4356\n",
      "Epoch 3/10\n",
      "202/202 [==============================] - 0s 521us/sample - loss: 0.7030 - acc: 0.4703\n",
      "Epoch 4/10\n",
      "202/202 [==============================] - 0s 416us/sample - loss: 0.6849 - acc: 0.5248\n",
      "Epoch 5/10\n",
      "202/202 [==============================] - 0s 238us/sample - loss: 0.6683 - acc: 0.5644\n",
      "Epoch 6/10\n",
      "202/202 [==============================] - 0s 185us/sample - loss: 0.6519 - acc: 0.6188\n",
      "Epoch 7/10\n",
      "202/202 [==============================] - 0s 213us/sample - loss: 0.6369 - acc: 0.6584\n",
      "Epoch 8/10\n",
      "202/202 [==============================] - 0s 193us/sample - loss: 0.6219 - acc: 0.7030\n",
      "Epoch 9/10\n",
      "202/202 [==============================] - 0s 301us/sample - loss: 0.6086 - acc: 0.7277\n",
      "Epoch 10/10\n",
      "202/202 [==============================] - 0s 158us/sample - loss: 0.5967 - acc: 0.7426\n",
      "101/101 [==============================] - 0s 460us/sample - loss: 0.5850 - acc: 0.7723\n",
      "202/202 [==============================] - 0s 53us/sample - loss: 0.5897 - acc: 0.7426\n",
      "Epoch 1/10\n",
      "202/202 [==============================] - 0s 605us/sample - loss: 0.7448 - acc: 0.5347\n",
      "Epoch 2/10\n",
      "202/202 [==============================] - 0s 156us/sample - loss: 0.7031 - acc: 0.5990\n",
      "Epoch 3/10\n",
      "202/202 [==============================] - 0s 96us/sample - loss: 0.6654 - acc: 0.6287\n",
      "Epoch 4/10\n",
      "202/202 [==============================] - 0s 190us/sample - loss: 0.6344 - acc: 0.6584\n",
      "Epoch 5/10\n",
      "202/202 [==============================] - 0s 123us/sample - loss: 0.6075 - acc: 0.6832\n",
      "Epoch 6/10\n",
      "202/202 [==============================] - 0s 164us/sample - loss: 0.5835 - acc: 0.6931\n",
      "Epoch 7/10\n",
      "202/202 [==============================] - 0s 91us/sample - loss: 0.5612 - acc: 0.7079\n",
      "Epoch 8/10\n",
      "202/202 [==============================] - 0s 260us/sample - loss: 0.5419 - acc: 0.7178\n",
      "Epoch 9/10\n",
      "202/202 [==============================] - 0s 113us/sample - loss: 0.5236 - acc: 0.7426\n",
      "Epoch 10/10\n",
      "202/202 [==============================] - 0s 186us/sample - loss: 0.5075 - acc: 0.7426\n",
      "101/101 [==============================] - 0s 500us/sample - loss: 0.5562 - acc: 0.7525\n",
      "202/202 [==============================] - 0s 67us/sample - loss: 0.4987 - acc: 0.7475\n",
      "Epoch 1/10\n",
      "202/202 [==============================] - 0s 857us/sample - loss: 0.9909 - acc: 0.5000\n",
      "Epoch 2/10\n",
      "202/202 [==============================] - 0s 285us/sample - loss: 0.9565 - acc: 0.5099\n",
      "Epoch 3/10\n",
      "202/202 [==============================] - 0s 232us/sample - loss: 0.9255 - acc: 0.5149\n",
      "Epoch 4/10\n",
      "202/202 [==============================] - 0s 160us/sample - loss: 0.8978 - acc: 0.5248\n",
      "Epoch 5/10\n",
      "202/202 [==============================] - 0s 89us/sample - loss: 0.8711 - acc: 0.5297\n",
      "Epoch 6/10\n",
      "202/202 [==============================] - 0s 83us/sample - loss: 0.8474 - acc: 0.5396\n",
      "Epoch 7/10\n",
      "202/202 [==============================] - 0s 110us/sample - loss: 0.8239 - acc: 0.5396\n",
      "Epoch 8/10\n",
      "202/202 [==============================] - 0s 71us/sample - loss: 0.8006 - acc: 0.5545\n",
      "Epoch 9/10\n",
      "202/202 [==============================] - 0s 165us/sample - loss: 0.7799 - acc: 0.5545\n",
      "Epoch 10/10\n",
      "202/202 [==============================] - 0s 92us/sample - loss: 0.7595 - acc: 0.5545\n",
      "101/101 [==============================] - 0s 506us/sample - loss: 0.8191 - acc: 0.5347\n",
      "202/202 [==============================] - 0s 46us/sample - loss: 0.7470 - acc: 0.5545\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202/202 [==============================] - 0s 622us/sample - loss: 0.7004 - acc: 0.5248\n",
      "Epoch 2/10\n",
      "202/202 [==============================] - 0s 64us/sample - loss: 0.6813 - acc: 0.5495\n",
      "Epoch 3/10\n",
      "202/202 [==============================] - 0s 109us/sample - loss: 0.6667 - acc: 0.5743\n",
      "Epoch 4/10\n",
      "202/202 [==============================] - 0s 68us/sample - loss: 0.6533 - acc: 0.5891\n",
      "Epoch 5/10\n",
      "202/202 [==============================] - 0s 64us/sample - loss: 0.6401 - acc: 0.6040\n",
      "Epoch 6/10\n",
      "202/202 [==============================] - 0s 84us/sample - loss: 0.6265 - acc: 0.6436\n",
      "Epoch 7/10\n",
      "202/202 [==============================] - 0s 105us/sample - loss: 0.6138 - acc: 0.6634\n",
      "Epoch 8/10\n",
      "202/202 [==============================] - 0s 99us/sample - loss: 0.6021 - acc: 0.6733\n",
      "Epoch 9/10\n",
      "202/202 [==============================] - 0s 101us/sample - loss: 0.5911 - acc: 0.6980\n",
      "Epoch 10/10\n",
      "202/202 [==============================] - 0s 94us/sample - loss: 0.5804 - acc: 0.7079\n",
      "101/101 [==============================] - 0s 756us/sample - loss: 0.5736 - acc: 0.7426\n",
      "202/202 [==============================] - 0s 45us/sample - loss: 0.5735 - acc: 0.7079\n",
      "Epoch 1/10\n",
      "202/202 [==============================] - 0s 630us/sample - loss: 0.6896 - acc: 0.5693\n",
      "Epoch 2/10\n",
      "202/202 [==============================] - 0s 103us/sample - loss: 0.6729 - acc: 0.5842\n",
      "Epoch 3/10\n",
      "202/202 [==============================] - 0s 49us/sample - loss: 0.6584 - acc: 0.5891\n",
      "Epoch 4/10\n",
      "202/202 [==============================] - 0s 102us/sample - loss: 0.6465 - acc: 0.5990\n",
      "Epoch 5/10\n",
      "202/202 [==============================] - 0s 94us/sample - loss: 0.6330 - acc: 0.6040\n",
      "Epoch 6/10\n",
      "202/202 [==============================] - 0s 90us/sample - loss: 0.6212 - acc: 0.6040\n",
      "Epoch 7/10\n",
      "202/202 [==============================] - 0s 92us/sample - loss: 0.6100 - acc: 0.6139\n",
      "Epoch 8/10\n",
      "202/202 [==============================] - 0s 124us/sample - loss: 0.6000 - acc: 0.6386\n",
      "Epoch 9/10\n",
      "202/202 [==============================] - 0s 88us/sample - loss: 0.5899 - acc: 0.6584\n",
      "Epoch 10/10\n",
      "202/202 [==============================] - 0s 119us/sample - loss: 0.5806 - acc: 0.6832\n",
      "101/101 [==============================] - 0s 579us/sample - loss: 0.6548 - acc: 0.6436\n",
      "202/202 [==============================] - 0s 35us/sample - loss: 0.5748 - acc: 0.7030\n",
      "Epoch 1/10\n",
      "202/202 [==============================] - 0s 619us/sample - loss: 0.8509 - acc: 0.4208\n",
      "Epoch 2/10\n",
      "202/202 [==============================] - 0s 54us/sample - loss: 0.8283 - acc: 0.4356\n",
      "Epoch 3/10\n",
      "202/202 [==============================] - 0s 99us/sample - loss: 0.8068 - acc: 0.4505\n",
      "Epoch 4/10\n",
      "202/202 [==============================] - 0s 109us/sample - loss: 0.7856 - acc: 0.4851\n",
      "Epoch 5/10\n",
      "202/202 [==============================] - 0s 184us/sample - loss: 0.7656 - acc: 0.5050\n",
      "Epoch 6/10\n",
      "202/202 [==============================] - 0s 86us/sample - loss: 0.7461 - acc: 0.5099\n",
      "Epoch 7/10\n",
      "202/202 [==============================] - 0s 89us/sample - loss: 0.7283 - acc: 0.5198\n",
      "Epoch 8/10\n",
      "202/202 [==============================] - 0s 82us/sample - loss: 0.7105 - acc: 0.5446\n",
      "Epoch 9/10\n",
      "202/202 [==============================] - 0s 91us/sample - loss: 0.6933 - acc: 0.5693\n",
      "Epoch 10/10\n",
      "202/202 [==============================] - 0s 123us/sample - loss: 0.6772 - acc: 0.5941\n",
      "101/101 [==============================] - 0s 604us/sample - loss: 0.6610 - acc: 0.6337\n",
      "202/202 [==============================] - 0s 32us/sample - loss: 0.6668 - acc: 0.6040\n",
      "Epoch 1/10\n",
      "202/202 [==============================] - 0s 877us/sample - loss: 1.0282 - acc: 0.3069\n",
      "Epoch 2/10\n",
      "202/202 [==============================] - 0s 116us/sample - loss: 1.0056 - acc: 0.3218\n",
      "Epoch 3/10\n",
      "202/202 [==============================] - 0s 161us/sample - loss: 0.9859 - acc: 0.3366\n",
      "Epoch 4/10\n",
      "202/202 [==============================] - 0s 113us/sample - loss: 0.9657 - acc: 0.3416\n",
      "Epoch 5/10\n",
      "202/202 [==============================] - 0s 99us/sample - loss: 0.9456 - acc: 0.3663\n",
      "Epoch 6/10\n",
      "202/202 [==============================] - 0s 92us/sample - loss: 0.9282 - acc: 0.3812\n",
      "Epoch 7/10\n",
      "202/202 [==============================] - 0s 79us/sample - loss: 0.9091 - acc: 0.3911\n",
      "Epoch 8/10\n",
      "202/202 [==============================] - 0s 54us/sample - loss: 0.8923 - acc: 0.3960\n",
      "Epoch 9/10\n",
      "202/202 [==============================] - 0s 38us/sample - loss: 0.8752 - acc: 0.3960\n",
      "Epoch 10/10\n",
      "202/202 [==============================] - 0s 95us/sample - loss: 0.8588 - acc: 0.4158\n",
      "101/101 [==============================] - 0s 640us/sample - loss: 0.8537 - acc: 0.3861\n",
      "202/202 [==============================] - 0s 27us/sample - loss: 0.8485 - acc: 0.4257\n",
      "Epoch 1/10\n",
      "202/202 [==============================] - 0s 696us/sample - loss: 0.7885 - acc: 0.4851\n",
      "Epoch 2/10\n",
      "202/202 [==============================] - 0s 45us/sample - loss: 0.7650 - acc: 0.5000\n",
      "Epoch 3/10\n",
      "202/202 [==============================] - 0s 86us/sample - loss: 0.7422 - acc: 0.5198\n",
      "Epoch 4/10\n",
      "202/202 [==============================] - 0s 86us/sample - loss: 0.7216 - acc: 0.5495\n",
      "Epoch 5/10\n",
      "202/202 [==============================] - 0s 108us/sample - loss: 0.7009 - acc: 0.5792\n",
      "Epoch 6/10\n",
      "202/202 [==============================] - 0s 86us/sample - loss: 0.6827 - acc: 0.5941\n",
      "Epoch 7/10\n",
      "202/202 [==============================] - 0s 81us/sample - loss: 0.6655 - acc: 0.5990\n",
      "Epoch 8/10\n",
      "202/202 [==============================] - 0s 89us/sample - loss: 0.6498 - acc: 0.6139\n",
      "Epoch 9/10\n",
      "202/202 [==============================] - 0s 104us/sample - loss: 0.6337 - acc: 0.6386\n",
      "Epoch 10/10\n",
      "202/202 [==============================] - 0s 99us/sample - loss: 0.6201 - acc: 0.6436\n",
      "101/101 [==============================] - 0s 1ms/sample - loss: 0.6502 - acc: 0.6040\n",
      "202/202 [==============================] - 0s 64us/sample - loss: 0.6105 - acc: 0.6634\n",
      "Epoch 1/10\n",
      "202/202 [==============================] - 0s 1ms/sample - loss: 0.7613 - acc: 0.4505\n",
      "Epoch 2/10\n",
      "202/202 [==============================] - 0s 58us/sample - loss: 0.7479 - acc: 0.4851\n",
      "Epoch 3/10\n",
      "202/202 [==============================] - 0s 103us/sample - loss: 0.7355 - acc: 0.5050\n",
      "Epoch 4/10\n",
      "202/202 [==============================] - 0s 116us/sample - loss: 0.7237 - acc: 0.5297\n",
      "Epoch 5/10\n",
      "202/202 [==============================] - 0s 120us/sample - loss: 0.7123 - acc: 0.5347\n",
      "Epoch 6/10\n",
      "202/202 [==============================] - 0s 126us/sample - loss: 0.7009 - acc: 0.5396\n",
      "Epoch 7/10\n",
      "202/202 [==============================] - 0s 163us/sample - loss: 0.6898 - acc: 0.5545\n",
      "Epoch 8/10\n",
      "202/202 [==============================] - 0s 144us/sample - loss: 0.6791 - acc: 0.5743\n",
      "Epoch 9/10\n",
      "202/202 [==============================] - 0s 44us/sample - loss: 0.6695 - acc: 0.6089\n",
      "Epoch 10/10\n",
      "202/202 [==============================] - 0s 46us/sample - loss: 0.6594 - acc: 0.6188\n",
      "101/101 [==============================] - 0s 2ms/sample - loss: 0.6701 - acc: 0.6337\n",
      "202/202 [==============================] - 0s 33us/sample - loss: 0.6527 - acc: 0.6386\n",
      "Epoch 1/10\n",
      "202/202 [==============================] - 0s 695us/sample - loss: 0.9541 - acc: 0.3564\n",
      "Epoch 2/10\n",
      "202/202 [==============================] - 0s 28us/sample - loss: 0.9388 - acc: 0.3515\n",
      "Epoch 3/10\n",
      "202/202 [==============================] - 0s 34us/sample - loss: 0.9242 - acc: 0.3663\n",
      "Epoch 4/10\n",
      "202/202 [==============================] - 0s 38us/sample - loss: 0.9087 - acc: 0.3762\n",
      "Epoch 5/10\n",
      "202/202 [==============================] - 0s 55us/sample - loss: 0.8953 - acc: 0.3812\n",
      "Epoch 6/10\n",
      "202/202 [==============================] - 0s 77us/sample - loss: 0.8803 - acc: 0.3861\n",
      "Epoch 7/10\n",
      "202/202 [==============================] - 0s 83us/sample - loss: 0.8667 - acc: 0.3960\n",
      "Epoch 8/10\n",
      "202/202 [==============================] - 0s 57us/sample - loss: 0.8531 - acc: 0.4010\n",
      "Epoch 9/10\n",
      "202/202 [==============================] - 0s 41us/sample - loss: 0.8403 - acc: 0.4109\n",
      "Epoch 10/10\n",
      "202/202 [==============================] - 0s 71us/sample - loss: 0.8277 - acc: 0.4158\n",
      "101/101 [==============================] - 0s 756us/sample - loss: 0.8305 - acc: 0.4356\n",
      "202/202 [==============================] - 0s 18us/sample - loss: 0.8181 - acc: 0.4257\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202/202 [==============================] - 0s 695us/sample - loss: 0.7741 - acc: 0.4950\n",
      "Epoch 2/10\n",
      "202/202 [==============================] - 0s 36us/sample - loss: 0.7566 - acc: 0.5149\n",
      "Epoch 3/10\n",
      "202/202 [==============================] - 0s 56us/sample - loss: 0.7405 - acc: 0.5248\n",
      "Epoch 4/10\n",
      "202/202 [==============================] - 0s 75us/sample - loss: 0.7252 - acc: 0.5347\n",
      "Epoch 5/10\n",
      "202/202 [==============================] - 0s 73us/sample - loss: 0.7104 - acc: 0.5396\n",
      "Epoch 6/10\n",
      "202/202 [==============================] - 0s 74us/sample - loss: 0.6956 - acc: 0.5594\n",
      "Epoch 7/10\n",
      "202/202 [==============================] - 0s 50us/sample - loss: 0.6827 - acc: 0.5644\n",
      "Epoch 8/10\n",
      "202/202 [==============================] - 0s 48us/sample - loss: 0.6692 - acc: 0.5990\n",
      "Epoch 9/10\n",
      "202/202 [==============================] - 0s 56us/sample - loss: 0.6576 - acc: 0.6040\n",
      "Epoch 10/10\n",
      "202/202 [==============================] - 0s 66us/sample - loss: 0.6453 - acc: 0.6188\n",
      "101/101 [==============================] - 0s 813us/sample - loss: 0.6285 - acc: 0.6436\n",
      "202/202 [==============================] - 0s 28us/sample - loss: 0.6374 - acc: 0.6287\n",
      "Epoch 1/10\n",
      "202/202 [==============================] - 0s 728us/sample - loss: 0.7004 - acc: 0.5891\n",
      "Epoch 2/10\n",
      "202/202 [==============================] - 0s 33us/sample - loss: 0.6880 - acc: 0.5990\n",
      "Epoch 3/10\n",
      "202/202 [==============================] - 0s 46us/sample - loss: 0.6781 - acc: 0.6089\n",
      "Epoch 4/10\n",
      "202/202 [==============================] - 0s 84us/sample - loss: 0.6693 - acc: 0.6089\n",
      "Epoch 5/10\n",
      "202/202 [==============================] - 0s 64us/sample - loss: 0.6608 - acc: 0.6139\n",
      "Epoch 6/10\n",
      "202/202 [==============================] - 0s 63us/sample - loss: 0.6529 - acc: 0.6139\n",
      "Epoch 7/10\n",
      "202/202 [==============================] - 0s 72us/sample - loss: 0.6451 - acc: 0.6287\n",
      "Epoch 8/10\n",
      "202/202 [==============================] - 0s 77us/sample - loss: 0.6375 - acc: 0.6386\n",
      "Epoch 9/10\n",
      "202/202 [==============================] - 0s 68us/sample - loss: 0.6304 - acc: 0.6535\n",
      "Epoch 10/10\n",
      "202/202 [==============================] - 0s 42us/sample - loss: 0.6237 - acc: 0.6683\n",
      "101/101 [==============================] - 0s 864us/sample - loss: 0.6984 - acc: 0.5842\n",
      "202/202 [==============================] - 0s 21us/sample - loss: 0.6180 - acc: 0.6733\n",
      "Epoch 1/10\n",
      "202/202 [==============================] - 0s 731us/sample - loss: 0.6700 - acc: 0.5693\n",
      "Epoch 2/10\n",
      "202/202 [==============================] - 0s 33us/sample - loss: 0.6584 - acc: 0.5842\n",
      "Epoch 3/10\n",
      "202/202 [==============================] - 0s 30us/sample - loss: 0.6486 - acc: 0.5891\n",
      "Epoch 4/10\n",
      "202/202 [==============================] - 0s 40us/sample - loss: 0.6400 - acc: 0.6040\n",
      "Epoch 5/10\n",
      "202/202 [==============================] - 0s 42us/sample - loss: 0.6322 - acc: 0.6139\n",
      "Epoch 6/10\n",
      "202/202 [==============================] - 0s 39us/sample - loss: 0.6251 - acc: 0.6238\n",
      "Epoch 7/10\n",
      "202/202 [==============================] - 0s 70us/sample - loss: 0.6182 - acc: 0.6337\n",
      "Epoch 8/10\n",
      "202/202 [==============================] - 0s 60us/sample - loss: 0.6118 - acc: 0.6436\n",
      "Epoch 9/10\n",
      "202/202 [==============================] - 0s 66us/sample - loss: 0.6064 - acc: 0.6485\n",
      "Epoch 10/10\n",
      "202/202 [==============================] - 0s 62us/sample - loss: 0.6011 - acc: 0.6584\n",
      "101/101 [==============================] - 0s 881us/sample - loss: 0.5637 - acc: 0.6832\n",
      "202/202 [==============================] - 0s 22us/sample - loss: 0.5963 - acc: 0.6634\n",
      "Epoch 1/10\n",
      "202/202 [==============================] - 0s 765us/sample - loss: 0.7978 - acc: 0.5446\n",
      "Epoch 2/10\n",
      "202/202 [==============================] - 0s 30us/sample - loss: 0.7870 - acc: 0.5446\n",
      "Epoch 3/10\n",
      "202/202 [==============================] - 0s 86us/sample - loss: 0.7791 - acc: 0.5446\n",
      "Epoch 4/10\n",
      "202/202 [==============================] - 0s 32us/sample - loss: 0.7715 - acc: 0.5446\n",
      "Epoch 5/10\n",
      "202/202 [==============================] - 0s 79us/sample - loss: 0.7643 - acc: 0.5446\n",
      "Epoch 6/10\n",
      "202/202 [==============================] - 0s 62us/sample - loss: 0.7570 - acc: 0.5446\n",
      "Epoch 7/10\n",
      "202/202 [==============================] - 0s 59us/sample - loss: 0.7504 - acc: 0.5446\n",
      "Epoch 8/10\n",
      "202/202 [==============================] - 0s 65us/sample - loss: 0.7436 - acc: 0.5446\n",
      "Epoch 9/10\n",
      "202/202 [==============================] - 0s 74us/sample - loss: 0.7371 - acc: 0.5446\n",
      "Epoch 10/10\n",
      "202/202 [==============================] - 0s 73us/sample - loss: 0.7306 - acc: 0.5495\n",
      "101/101 [==============================] - 0s 928us/sample - loss: 0.8341 - acc: 0.5248\n",
      "202/202 [==============================] - 0s 22us/sample - loss: 0.7253 - acc: 0.5495\n",
      "Epoch 1/10\n",
      "303/303 [==============================] - 0s 729us/sample - loss: 0.6700 - acc: 0.6238\n",
      "Epoch 2/10\n",
      "303/303 [==============================] - 0s 191us/sample - loss: 0.5940 - acc: 0.7162\n",
      "Epoch 3/10\n",
      "303/303 [==============================] - 0s 196us/sample - loss: 0.5385 - acc: 0.7492\n",
      "Epoch 4/10\n",
      "303/303 [==============================] - 0s 156us/sample - loss: 0.4988 - acc: 0.7525\n",
      "Epoch 5/10\n",
      "303/303 [==============================] - 0s 159us/sample - loss: 0.4699 - acc: 0.7789\n",
      "Epoch 6/10\n",
      "303/303 [==============================] - 0s 161us/sample - loss: 0.4466 - acc: 0.7954\n",
      "Epoch 7/10\n",
      "303/303 [==============================] - 0s 196us/sample - loss: 0.4286 - acc: 0.8053\n",
      "Epoch 8/10\n",
      "303/303 [==============================] - 0s 162us/sample - loss: 0.4134 - acc: 0.8185\n",
      "Epoch 9/10\n",
      "303/303 [==============================] - 0s 160us/sample - loss: 0.4012 - acc: 0.8251\n",
      "Epoch 10/10\n",
      "303/303 [==============================] - 0s 162us/sample - loss: 0.3916 - acc: 0.8284\n"
     ]
    }
   ],
   "source": [
    "# New model\n",
    "model = KerasClassifier(build_fn=create_model, verbose=1)\n",
    "\n",
    "# Create Grid Search\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1, cv=3)\n",
    "grid_result = grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.7755775650342306 using {'batch_size': 10, 'epochs': 10}\n"
     ]
    }
   ],
   "source": [
    "# Report Results\n",
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model function for Keras Classifier\n",
    "def create_dense_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=13, activation='relu'))\n",
    "    model.add(Dense(12, activation='relu'))\n",
    "    model.add(Dense(12, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 0.6848 - acc: 0.6446\n",
      "Epoch 2/50\n",
      "242/242 [==============================] - 0s 304us/sample - loss: 0.6644 - acc: 0.7521\n",
      "Epoch 3/50\n",
      "242/242 [==============================] - 0s 383us/sample - loss: 0.6391 - acc: 0.8017\n",
      "Epoch 4/50\n",
      "242/242 [==============================] - 0s 282us/sample - loss: 0.6013 - acc: 0.8182\n",
      "Epoch 5/50\n",
      "242/242 [==============================] - 0s 314us/sample - loss: 0.5467 - acc: 0.8347\n",
      "Epoch 6/50\n",
      "242/242 [==============================] - 0s 334us/sample - loss: 0.4823 - acc: 0.8471\n",
      "Epoch 7/50\n",
      "242/242 [==============================] - 0s 429us/sample - loss: 0.4194 - acc: 0.8512\n",
      "Epoch 8/50\n",
      "242/242 [==============================] - 0s 306us/sample - loss: 0.3704 - acc: 0.8512\n",
      "Epoch 9/50\n",
      "242/242 [==============================] - 0s 379us/sample - loss: 0.3415 - acc: 0.8678\n",
      "Epoch 10/50\n",
      "242/242 [==============================] - 0s 287us/sample - loss: 0.3229 - acc: 0.8760\n",
      "Epoch 11/50\n",
      "242/242 [==============================] - 0s 316us/sample - loss: 0.3092 - acc: 0.8926\n",
      "Epoch 12/50\n",
      "242/242 [==============================] - 0s 421us/sample - loss: 0.3000 - acc: 0.8967\n",
      "Epoch 13/50\n",
      "242/242 [==============================] - 0s 261us/sample - loss: 0.2929 - acc: 0.9008\n",
      "Epoch 14/50\n",
      "242/242 [==============================] - 0s 333us/sample - loss: 0.2856 - acc: 0.9008\n",
      "Epoch 15/50\n",
      "242/242 [==============================] - 0s 407us/sample - loss: 0.2815 - acc: 0.9008\n",
      "Epoch 16/50\n",
      "242/242 [==============================] - 0s 368us/sample - loss: 0.2768 - acc: 0.9008\n",
      "Epoch 17/50\n",
      "242/242 [==============================] - 0s 431us/sample - loss: 0.2710 - acc: 0.9008\n",
      "Epoch 18/50\n",
      "242/242 [==============================] - 0s 250us/sample - loss: 0.2681 - acc: 0.9008\n",
      "Epoch 19/50\n",
      "242/242 [==============================] - 0s 377us/sample - loss: 0.2633 - acc: 0.9050\n",
      "Epoch 20/50\n",
      "242/242 [==============================] - 0s 457us/sample - loss: 0.2598 - acc: 0.9050\n",
      "Epoch 21/50\n",
      "242/242 [==============================] - 0s 591us/sample - loss: 0.2564 - acc: 0.9091\n",
      "Epoch 22/50\n",
      "242/242 [==============================] - 0s 690us/sample - loss: 0.2504 - acc: 0.9174\n",
      "Epoch 23/50\n",
      "242/242 [==============================] - 0s 615us/sample - loss: 0.2470 - acc: 0.9174\n",
      "Epoch 24/50\n",
      "242/242 [==============================] - 0s 624us/sample - loss: 0.2453 - acc: 0.9132\n",
      "Epoch 25/50\n",
      "242/242 [==============================] - 0s 504us/sample - loss: 0.2409 - acc: 0.9174\n",
      "Epoch 26/50\n",
      "242/242 [==============================] - 0s 585us/sample - loss: 0.2349 - acc: 0.9174\n",
      "Epoch 27/50\n",
      "242/242 [==============================] - 0s 568us/sample - loss: 0.2315 - acc: 0.9174\n",
      "Epoch 28/50\n",
      "242/242 [==============================] - 0s 527us/sample - loss: 0.2276 - acc: 0.9174\n",
      "Epoch 29/50\n",
      "242/242 [==============================] - 0s 432us/sample - loss: 0.2227 - acc: 0.9174\n",
      "Epoch 30/50\n",
      "242/242 [==============================] - 0s 339us/sample - loss: 0.2199 - acc: 0.9174\n",
      "Epoch 31/50\n",
      "242/242 [==============================] - 0s 696us/sample - loss: 0.2149 - acc: 0.9298\n",
      "Epoch 32/50\n",
      "242/242 [==============================] - 0s 757us/sample - loss: 0.2116 - acc: 0.9298\n",
      "Epoch 33/50\n",
      "242/242 [==============================] - 0s 639us/sample - loss: 0.2082 - acc: 0.9298\n",
      "Epoch 34/50\n",
      "242/242 [==============================] - 0s 652us/sample - loss: 0.2050 - acc: 0.9339\n",
      "Epoch 35/50\n",
      "242/242 [==============================] - 0s 464us/sample - loss: 0.2011 - acc: 0.9298\n",
      "Epoch 36/50\n",
      "242/242 [==============================] - 0s 360us/sample - loss: 0.1974 - acc: 0.9298\n",
      "Epoch 37/50\n",
      "242/242 [==============================] - 0s 384us/sample - loss: 0.1948 - acc: 0.9339\n",
      "Epoch 38/50\n",
      "242/242 [==============================] - 0s 476us/sample - loss: 0.1934 - acc: 0.9339\n",
      "Epoch 39/50\n",
      "242/242 [==============================] - 0s 396us/sample - loss: 0.1885 - acc: 0.9339\n",
      "Epoch 40/50\n",
      "242/242 [==============================] - 0s 790us/sample - loss: 0.1859 - acc: 0.9339\n",
      "Epoch 41/50\n",
      "242/242 [==============================] - 0s 625us/sample - loss: 0.1824 - acc: 0.9339\n",
      "Epoch 42/50\n",
      "242/242 [==============================] - 0s 982us/sample - loss: 0.1778 - acc: 0.9380\n",
      "Epoch 43/50\n",
      "242/242 [==============================] - 0s 884us/sample - loss: 0.1737 - acc: 0.9380\n",
      "Epoch 44/50\n",
      "242/242 [==============================] - 0s 786us/sample - loss: 0.1711 - acc: 0.9421\n",
      "Epoch 45/50\n",
      "242/242 [==============================] - 0s 731us/sample - loss: 0.1678 - acc: 0.9421\n",
      "Epoch 46/50\n",
      "242/242 [==============================] - 0s 768us/sample - loss: 0.1650 - acc: 0.9421\n",
      "Epoch 47/50\n",
      "242/242 [==============================] - 0s 776us/sample - loss: 0.1614 - acc: 0.9421\n",
      "Epoch 48/50\n",
      "242/242 [==============================] - 0s 865us/sample - loss: 0.1566 - acc: 0.9421\n",
      "Epoch 49/50\n",
      "242/242 [==============================] - 0s 785us/sample - loss: 0.1545 - acc: 0.9421\n",
      "Epoch 50/50\n",
      "242/242 [==============================] - 0s 607us/sample - loss: 0.1504 - acc: 0.9463\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a40fe8518>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# New model\n",
    "model = create_dense_model()\n",
    "model.fit(X_train, y_train, batch_size=10, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61/61 [==============================] - 0s 5ms/sample - loss: 0.5108 - acc: 0.8197\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5107712921549062, 0.8196721]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate model\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define search params\n",
    "param_grid = {'batch_size': [10],\n",
    "              'epochs': [5, 10, 20, 50, 100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "202/202 [==============================] - 0s 2ms/sample - loss: 0.7123 - acc: 0.4604\n",
      "Epoch 2/5\n",
      "202/202 [==============================] - 0s 341us/sample - loss: 0.6723 - acc: 0.5990\n",
      "Epoch 3/5\n",
      "202/202 [==============================] - 0s 337us/sample - loss: 0.6397 - acc: 0.7228\n",
      "Epoch 4/5\n",
      "202/202 [==============================] - 0s 289us/sample - loss: 0.6025 - acc: 0.7624\n",
      "Epoch 5/5\n",
      "202/202 [==============================] - 0s 280us/sample - loss: 0.5594 - acc: 0.8168\n",
      "101/101 [==============================] - 0s 2ms/sample - loss: 0.5741 - acc: 0.7030\n",
      "202/202 [==============================] - 0s 338us/sample - loss: 0.5326 - acc: 0.8168\n",
      "Epoch 1/5\n",
      "202/202 [==============================] - 1s 3ms/sample - loss: 0.6792 - acc: 0.5891\n",
      "Epoch 2/5\n",
      "202/202 [==============================] - 0s 700us/sample - loss: 0.6481 - acc: 0.7030\n",
      "Epoch 3/5\n",
      "202/202 [==============================] - 0s 731us/sample - loss: 0.6191 - acc: 0.7723\n",
      "Epoch 4/5\n",
      "202/202 [==============================] - 0s 657us/sample - loss: 0.5863 - acc: 0.7822\n",
      "Epoch 5/5\n",
      "202/202 [==============================] - 0s 795us/sample - loss: 0.5492 - acc: 0.7871\n",
      "101/101 [==============================] - 0s 3ms/sample - loss: 0.5480 - acc: 0.7624\n",
      "202/202 [==============================] - 0s 518us/sample - loss: 0.5273 - acc: 0.7970\n",
      "Epoch 1/5\n",
      "202/202 [==============================] - 0s 2ms/sample - loss: 0.6484 - acc: 0.6584\n",
      "Epoch 2/5\n",
      "202/202 [==============================] - 0s 426us/sample - loss: 0.6174 - acc: 0.7030\n",
      "Epoch 3/5\n",
      "202/202 [==============================] - 0s 381us/sample - loss: 0.5876 - acc: 0.7574\n",
      "Epoch 4/5\n",
      "202/202 [==============================] - 0s 379us/sample - loss: 0.5535 - acc: 0.7723\n",
      "Epoch 5/5\n",
      "202/202 [==============================] - 0s 421us/sample - loss: 0.5205 - acc: 0.7772\n",
      "101/101 [==============================] - 0s 2ms/sample - loss: 0.5281 - acc: 0.7624\n",
      "202/202 [==============================] - 0s 462us/sample - loss: 0.5000 - acc: 0.7970\n",
      "Epoch 1/10\n",
      "202/202 [==============================] - 0s 2ms/sample - loss: 0.7371 - acc: 0.4752\n",
      "Epoch 2/10\n",
      "202/202 [==============================] - 0s 357us/sample - loss: 0.6777 - acc: 0.5495\n",
      "Epoch 3/10\n",
      "202/202 [==============================] - 0s 437us/sample - loss: 0.6339 - acc: 0.6386\n",
      "Epoch 4/10\n",
      "202/202 [==============================] - 0s 425us/sample - loss: 0.5916 - acc: 0.7426\n",
      "Epoch 5/10\n",
      "202/202 [==============================] - 0s 466us/sample - loss: 0.5470 - acc: 0.8069\n",
      "Epoch 6/10\n",
      "202/202 [==============================] - 0s 407us/sample - loss: 0.5021 - acc: 0.8168\n",
      "Epoch 7/10\n",
      "202/202 [==============================] - 0s 432us/sample - loss: 0.4594 - acc: 0.8069\n",
      "Epoch 8/10\n",
      "202/202 [==============================] - 0s 491us/sample - loss: 0.4237 - acc: 0.7970\n",
      "Epoch 9/10\n",
      "202/202 [==============================] - 0s 302us/sample - loss: 0.3950 - acc: 0.8267\n",
      "Epoch 10/10\n",
      "202/202 [==============================] - 0s 450us/sample - loss: 0.3703 - acc: 0.8267\n",
      "101/101 [==============================] - 0s 3ms/sample - loss: 0.5801 - acc: 0.6931\n",
      "202/202 [==============================] - 0s 391us/sample - loss: 0.3551 - acc: 0.8366\n",
      "Epoch 1/10\n",
      "202/202 [==============================] - 0s 2ms/sample - loss: 0.6785 - acc: 0.6188\n",
      "Epoch 2/10\n",
      "202/202 [==============================] - 0s 566us/sample - loss: 0.6584 - acc: 0.6782\n",
      "Epoch 3/10\n",
      "202/202 [==============================] - 0s 753us/sample - loss: 0.6364 - acc: 0.6980\n",
      "Epoch 4/10\n",
      "202/202 [==============================] - 0s 540us/sample - loss: 0.6150 - acc: 0.7475\n",
      "Epoch 5/10\n",
      "202/202 [==============================] - 0s 342us/sample - loss: 0.5878 - acc: 0.7624\n",
      "Epoch 6/10\n",
      "202/202 [==============================] - 0s 606us/sample - loss: 0.5548 - acc: 0.7871\n",
      "Epoch 7/10\n",
      "202/202 [==============================] - 0s 436us/sample - loss: 0.5186 - acc: 0.7921\n",
      "Epoch 8/10\n",
      "202/202 [==============================] - 0s 508us/sample - loss: 0.4827 - acc: 0.8168\n",
      "Epoch 9/10\n",
      "202/202 [==============================] - 0s 416us/sample - loss: 0.4501 - acc: 0.8218\n",
      "Epoch 10/10\n",
      "202/202 [==============================] - 0s 579us/sample - loss: 0.4232 - acc: 0.8218\n",
      "101/101 [==============================] - 0s 2ms/sample - loss: 0.4271 - acc: 0.8416\n",
      "202/202 [==============================] - 0s 424us/sample - loss: 0.4092 - acc: 0.8267\n",
      "Epoch 1/10\n",
      "202/202 [==============================] - 0s 2ms/sample - loss: 0.7328 - acc: 0.4455\n",
      "Epoch 2/10\n",
      "202/202 [==============================] - 0s 562us/sample - loss: 0.6857 - acc: 0.4505\n",
      "Epoch 3/10\n",
      "202/202 [==============================] - 0s 1ms/sample - loss: 0.6583 - acc: 0.5000\n",
      "Epoch 4/10\n",
      "202/202 [==============================] - 0s 1ms/sample - loss: 0.6368 - acc: 0.6188\n",
      "Epoch 5/10\n",
      "202/202 [==============================] - 0s 607us/sample - loss: 0.6172 - acc: 0.6881\n",
      "Epoch 6/10\n",
      "202/202 [==============================] - 0s 375us/sample - loss: 0.5987 - acc: 0.7228\n",
      "Epoch 7/10\n",
      "202/202 [==============================] - 0s 707us/sample - loss: 0.5816 - acc: 0.7376\n",
      "Epoch 8/10\n",
      "202/202 [==============================] - 0s 538us/sample - loss: 0.5650 - acc: 0.7673\n",
      "Epoch 9/10\n",
      "202/202 [==============================] - 0s 569us/sample - loss: 0.5487 - acc: 0.7871\n",
      "Epoch 10/10\n",
      "202/202 [==============================] - 0s 539us/sample - loss: 0.5325 - acc: 0.8168\n",
      "101/101 [==============================] - 0s 3ms/sample - loss: 0.5379 - acc: 0.7624\n",
      "202/202 [==============================] - 0s 427us/sample - loss: 0.5231 - acc: 0.8218\n",
      "Epoch 1/20\n",
      "202/202 [==============================] - 0s 2ms/sample - loss: 0.6376 - acc: 0.6980\n",
      "Epoch 2/20\n",
      "202/202 [==============================] - 0s 407us/sample - loss: 0.5905 - acc: 0.7228\n",
      "Epoch 3/20\n",
      "202/202 [==============================] - 0s 286us/sample - loss: 0.5527 - acc: 0.7574\n",
      "Epoch 4/20\n",
      "202/202 [==============================] - 0s 237us/sample - loss: 0.5172 - acc: 0.7624\n",
      "Epoch 5/20\n",
      "202/202 [==============================] - 0s 295us/sample - loss: 0.4856 - acc: 0.8119\n",
      "Epoch 6/20\n",
      "202/202 [==============================] - 0s 244us/sample - loss: 0.4568 - acc: 0.8069\n",
      "Epoch 7/20\n",
      "202/202 [==============================] - 0s 233us/sample - loss: 0.4303 - acc: 0.8119\n",
      "Epoch 8/20\n",
      "202/202 [==============================] - 0s 239us/sample - loss: 0.4057 - acc: 0.8267\n",
      "Epoch 9/20\n",
      "202/202 [==============================] - 0s 237us/sample - loss: 0.3834 - acc: 0.8366\n",
      "Epoch 10/20\n",
      "202/202 [==============================] - 0s 298us/sample - loss: 0.3612 - acc: 0.8366\n",
      "Epoch 11/20\n",
      "202/202 [==============================] - 0s 361us/sample - loss: 0.3444 - acc: 0.8614\n",
      "Epoch 12/20\n",
      "202/202 [==============================] - 0s 401us/sample - loss: 0.3265 - acc: 0.8614\n",
      "Epoch 13/20\n",
      "202/202 [==============================] - 0s 320us/sample - loss: 0.3124 - acc: 0.8663\n",
      "Epoch 14/20\n",
      "202/202 [==============================] - 0s 280us/sample - loss: 0.3004 - acc: 0.8713\n",
      "Epoch 15/20\n",
      "202/202 [==============================] - 0s 237us/sample - loss: 0.2898 - acc: 0.8812\n",
      "Epoch 16/20\n",
      "202/202 [==============================] - 0s 237us/sample - loss: 0.2796 - acc: 0.8812\n",
      "Epoch 17/20\n",
      "202/202 [==============================] - 0s 245us/sample - loss: 0.2705 - acc: 0.8812\n",
      "Epoch 18/20\n",
      "202/202 [==============================] - 0s 238us/sample - loss: 0.2621 - acc: 0.8861\n",
      "Epoch 19/20\n",
      "202/202 [==============================] - 0s 236us/sample - loss: 0.2521 - acc: 0.8960\n",
      "Epoch 20/20\n",
      "202/202 [==============================] - 0s 238us/sample - loss: 0.2438 - acc: 0.9010\n",
      "101/101 [==============================] - 0s 2ms/sample - loss: 0.5138 - acc: 0.8119\n",
      "202/202 [==============================] - 0s 239us/sample - loss: 0.2361 - acc: 0.9010\n",
      "Epoch 1/20\n",
      "202/202 [==============================] - 0s 2ms/sample - loss: 0.7205 - acc: 0.4653\n",
      "Epoch 2/20\n",
      "202/202 [==============================] - 0s 293us/sample - loss: 0.6924 - acc: 0.5149\n",
      "Epoch 3/20\n",
      "202/202 [==============================] - 0s 242us/sample - loss: 0.6715 - acc: 0.5792\n",
      "Epoch 4/20\n",
      "202/202 [==============================] - 0s 240us/sample - loss: 0.6504 - acc: 0.6683\n",
      "Epoch 5/20\n",
      "202/202 [==============================] - 0s 242us/sample - loss: 0.6280 - acc: 0.7129\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202/202 [==============================] - 0s 238us/sample - loss: 0.6017 - acc: 0.7376\n",
      "Epoch 7/20\n",
      "202/202 [==============================] - 0s 244us/sample - loss: 0.5690 - acc: 0.7772\n",
      "Epoch 8/20\n",
      "202/202 [==============================] - 0s 298us/sample - loss: 0.5342 - acc: 0.8168\n",
      "Epoch 9/20\n",
      "202/202 [==============================] - 0s 295us/sample - loss: 0.4959 - acc: 0.8168\n",
      "Epoch 10/20\n",
      "202/202 [==============================] - 0s 232us/sample - loss: 0.4655 - acc: 0.8317\n",
      "Epoch 11/20\n",
      "202/202 [==============================] - 0s 234us/sample - loss: 0.4391 - acc: 0.8168\n",
      "Epoch 12/20\n",
      "202/202 [==============================] - 0s 230us/sample - loss: 0.4192 - acc: 0.8317\n",
      "Epoch 13/20\n",
      "202/202 [==============================] - 0s 232us/sample - loss: 0.4059 - acc: 0.8366\n",
      "Epoch 14/20\n",
      "202/202 [==============================] - 0s 236us/sample - loss: 0.3946 - acc: 0.8416\n",
      "Epoch 15/20\n",
      "202/202 [==============================] - 0s 237us/sample - loss: 0.3853 - acc: 0.8515\n",
      "Epoch 16/20\n",
      "202/202 [==============================] - 0s 248us/sample - loss: 0.3777 - acc: 0.8515\n",
      "Epoch 17/20\n",
      "202/202 [==============================] - 0s 253us/sample - loss: 0.3711 - acc: 0.8663\n",
      "Epoch 18/20\n",
      "202/202 [==============================] - 0s 306us/sample - loss: 0.3647 - acc: 0.8614\n",
      "Epoch 19/20\n",
      "202/202 [==============================] - 0s 395us/sample - loss: 0.3601 - acc: 0.8564\n",
      "Epoch 20/20\n",
      "202/202 [==============================] - 0s 402us/sample - loss: 0.3544 - acc: 0.8564\n",
      "101/101 [==============================] - 0s 2ms/sample - loss: 0.4239 - acc: 0.8218\n",
      "202/202 [==============================] - 0s 210us/sample - loss: 0.3488 - acc: 0.8614\n",
      "Epoch 1/20\n",
      "202/202 [==============================] - 0s 2ms/sample - loss: 0.6614 - acc: 0.5644\n",
      "Epoch 2/20\n",
      "202/202 [==============================] - 0s 245us/sample - loss: 0.6286 - acc: 0.7327\n",
      "Epoch 3/20\n",
      "202/202 [==============================] - 0s 244us/sample - loss: 0.5830 - acc: 0.7574\n",
      "Epoch 4/20\n",
      "202/202 [==============================] - 0s 246us/sample - loss: 0.5251 - acc: 0.7921\n",
      "Epoch 5/20\n",
      "202/202 [==============================] - 0s 241us/sample - loss: 0.4715 - acc: 0.7970\n",
      "Epoch 6/20\n",
      "202/202 [==============================] - 0s 238us/sample - loss: 0.4364 - acc: 0.8020\n",
      "Epoch 7/20\n",
      "202/202 [==============================] - 0s 239us/sample - loss: 0.4132 - acc: 0.8020\n",
      "Epoch 8/20\n",
      "202/202 [==============================] - 0s 236us/sample - loss: 0.3976 - acc: 0.8119\n",
      "Epoch 9/20\n",
      "202/202 [==============================] - 0s 284us/sample - loss: 0.3845 - acc: 0.8168\n",
      "Epoch 10/20\n",
      "202/202 [==============================] - 0s 235us/sample - loss: 0.3738 - acc: 0.8267\n",
      "Epoch 11/20\n",
      "202/202 [==============================] - 0s 238us/sample - loss: 0.3646 - acc: 0.8317\n",
      "Epoch 12/20\n",
      "202/202 [==============================] - 0s 231us/sample - loss: 0.3580 - acc: 0.8465\n",
      "Epoch 13/20\n",
      "202/202 [==============================] - 0s 234us/sample - loss: 0.3493 - acc: 0.8465\n",
      "Epoch 14/20\n",
      "202/202 [==============================] - 0s 233us/sample - loss: 0.3413 - acc: 0.8416\n",
      "Epoch 15/20\n",
      "202/202 [==============================] - 0s 243us/sample - loss: 0.3349 - acc: 0.8515\n",
      "Epoch 16/20\n",
      "202/202 [==============================] - 0s 238us/sample - loss: 0.3310 - acc: 0.8515\n",
      "Epoch 17/20\n",
      "202/202 [==============================] - 0s 240us/sample - loss: 0.3250 - acc: 0.8663\n",
      "Epoch 18/20\n",
      "202/202 [==============================] - 0s 231us/sample - loss: 0.3204 - acc: 0.8713\n",
      "Epoch 19/20\n",
      "202/202 [==============================] - 0s 233us/sample - loss: 0.3161 - acc: 0.8713\n",
      "Epoch 20/20\n",
      "202/202 [==============================] - 0s 235us/sample - loss: 0.3117 - acc: 0.8762\n",
      "101/101 [==============================] - 0s 4ms/sample - loss: 0.3764 - acc: 0.8119\n",
      "202/202 [==============================] - 0s 272us/sample - loss: 0.3051 - acc: 0.8762\n",
      "Epoch 1/50\n",
      "202/202 [==============================] - 0s 2ms/sample - loss: 0.7512 - acc: 0.4455\n",
      "Epoch 2/50\n",
      "202/202 [==============================] - 0s 298us/sample - loss: 0.6849 - acc: 0.5297\n",
      "Epoch 3/50\n",
      "202/202 [==============================] - 0s 290us/sample - loss: 0.6499 - acc: 0.6782\n",
      "Epoch 4/50\n",
      "202/202 [==============================] - 0s 293us/sample - loss: 0.6248 - acc: 0.7178\n",
      "Epoch 5/50\n",
      "202/202 [==============================] - 0s 306us/sample - loss: 0.6015 - acc: 0.7673\n",
      "Epoch 6/50\n",
      "202/202 [==============================] - 0s 310us/sample - loss: 0.5774 - acc: 0.7822\n",
      "Epoch 7/50\n",
      "202/202 [==============================] - 0s 263us/sample - loss: 0.5518 - acc: 0.7822\n",
      "Epoch 8/50\n",
      "202/202 [==============================] - 0s 387us/sample - loss: 0.5248 - acc: 0.7970\n",
      "Epoch 9/50\n",
      "202/202 [==============================] - 0s 546us/sample - loss: 0.4975 - acc: 0.8069\n",
      "Epoch 10/50\n",
      "202/202 [==============================] - 0s 551us/sample - loss: 0.4722 - acc: 0.8119\n",
      "Epoch 11/50\n",
      "202/202 [==============================] - 0s 425us/sample - loss: 0.4451 - acc: 0.8416\n",
      "Epoch 12/50\n",
      "202/202 [==============================] - 0s 273us/sample - loss: 0.4205 - acc: 0.8366\n",
      "Epoch 13/50\n",
      "202/202 [==============================] - 0s 293us/sample - loss: 0.3969 - acc: 0.8366\n",
      "Epoch 14/50\n",
      "202/202 [==============================] - 0s 246us/sample - loss: 0.3770 - acc: 0.8366\n",
      "Epoch 15/50\n",
      "202/202 [==============================] - 0s 352us/sample - loss: 0.3593 - acc: 0.8416\n",
      "Epoch 16/50\n",
      "202/202 [==============================] - 0s 536us/sample - loss: 0.3448 - acc: 0.8465\n",
      "Epoch 17/50\n",
      "202/202 [==============================] - 0s 506us/sample - loss: 0.3287 - acc: 0.8515\n",
      "Epoch 18/50\n",
      "202/202 [==============================] - 0s 495us/sample - loss: 0.3195 - acc: 0.8564\n",
      "Epoch 19/50\n",
      "202/202 [==============================] - 0s 518us/sample - loss: 0.3096 - acc: 0.8663\n",
      "Epoch 20/50\n",
      "202/202 [==============================] - 0s 539us/sample - loss: 0.2976 - acc: 0.8713\n",
      "Epoch 21/50\n",
      "202/202 [==============================] - 0s 542us/sample - loss: 0.2883 - acc: 0.8812\n",
      "Epoch 22/50\n",
      "202/202 [==============================] - 0s 484us/sample - loss: 0.2843 - acc: 0.8762\n",
      "Epoch 23/50\n",
      "202/202 [==============================] - 0s 493us/sample - loss: 0.2762 - acc: 0.8861\n",
      "Epoch 24/50\n",
      "202/202 [==============================] - 0s 520us/sample - loss: 0.2727 - acc: 0.8911\n",
      "Epoch 25/50\n",
      "202/202 [==============================] - 0s 501us/sample - loss: 0.2676 - acc: 0.8960\n",
      "Epoch 26/50\n",
      "202/202 [==============================] - 0s 366us/sample - loss: 0.2641 - acc: 0.8911\n",
      "Epoch 27/50\n",
      "202/202 [==============================] - 0s 498us/sample - loss: 0.2565 - acc: 0.8911\n",
      "Epoch 28/50\n",
      "202/202 [==============================] - 0s 386us/sample - loss: 0.2529 - acc: 0.8911\n",
      "Epoch 29/50\n",
      "202/202 [==============================] - 0s 543us/sample - loss: 0.2495 - acc: 0.8960\n",
      "Epoch 30/50\n",
      "202/202 [==============================] - 0s 512us/sample - loss: 0.2425 - acc: 0.9010\n",
      "Epoch 31/50\n",
      "202/202 [==============================] - 0s 500us/sample - loss: 0.2405 - acc: 0.9158\n",
      "Epoch 32/50\n",
      "202/202 [==============================] - 0s 348us/sample - loss: 0.2349 - acc: 0.9109\n",
      "Epoch 33/50\n",
      "202/202 [==============================] - 0s 298us/sample - loss: 0.2317 - acc: 0.9109\n",
      "Epoch 34/50\n",
      "202/202 [==============================] - 0s 302us/sample - loss: 0.2284 - acc: 0.9158\n",
      "Epoch 35/50\n",
      "202/202 [==============================] - 0s 321us/sample - loss: 0.2236 - acc: 0.9158\n",
      "Epoch 36/50\n",
      "202/202 [==============================] - 0s 526us/sample - loss: 0.2205 - acc: 0.9109\n",
      "Epoch 37/50\n",
      "202/202 [==============================] - 0s 459us/sample - loss: 0.2163 - acc: 0.9158\n",
      "Epoch 38/50\n",
      "202/202 [==============================] - 0s 264us/sample - loss: 0.2118 - acc: 0.9158\n",
      "Epoch 39/50\n",
      "202/202 [==============================] - 0s 301us/sample - loss: 0.2108 - acc: 0.9257\n",
      "Epoch 40/50\n",
      "202/202 [==============================] - 0s 247us/sample - loss: 0.2068 - acc: 0.9257\n",
      "Epoch 41/50\n",
      "202/202 [==============================] - 0s 302us/sample - loss: 0.2031 - acc: 0.9307\n",
      "Epoch 42/50\n",
      "202/202 [==============================] - 0s 342us/sample - loss: 0.2004 - acc: 0.9158\n",
      "Epoch 43/50\n",
      "202/202 [==============================] - 0s 357us/sample - loss: 0.1971 - acc: 0.9257\n",
      "Epoch 44/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202/202 [==============================] - 0s 302us/sample - loss: 0.1962 - acc: 0.9307\n",
      "Epoch 45/50\n",
      "202/202 [==============================] - 0s 297us/sample - loss: 0.1914 - acc: 0.9257\n",
      "Epoch 46/50\n",
      "202/202 [==============================] - 0s 344us/sample - loss: 0.1887 - acc: 0.9257\n",
      "Epoch 47/50\n",
      "202/202 [==============================] - 0s 350us/sample - loss: 0.1860 - acc: 0.9406\n",
      "Epoch 48/50\n",
      "202/202 [==============================] - 0s 376us/sample - loss: 0.1830 - acc: 0.9406\n",
      "Epoch 49/50\n",
      "202/202 [==============================] - 0s 1ms/sample - loss: 0.1795 - acc: 0.9406\n",
      "Epoch 50/50\n",
      "202/202 [==============================] - 0s 487us/sample - loss: 0.1752 - acc: 0.9406\n",
      "101/101 [==============================] - 0s 3ms/sample - loss: 0.7903 - acc: 0.7921\n",
      "202/202 [==============================] - 0s 211us/sample - loss: 0.1715 - acc: 0.9406\n",
      "Epoch 1/50\n",
      "202/202 [==============================] - 0s 2ms/sample - loss: 0.7610 - acc: 0.5248\n",
      "Epoch 2/50\n",
      "202/202 [==============================] - 0s 305us/sample - loss: 0.7116 - acc: 0.5248\n",
      "Epoch 3/50\n",
      "202/202 [==============================] - 0s 293us/sample - loss: 0.6753 - acc: 0.5347\n",
      "Epoch 4/50\n",
      "202/202 [==============================] - 0s 252us/sample - loss: 0.6469 - acc: 0.5446\n",
      "Epoch 5/50\n",
      "202/202 [==============================] - 0s 304us/sample - loss: 0.6226 - acc: 0.5644\n",
      "Epoch 6/50\n",
      "202/202 [==============================] - 0s 248us/sample - loss: 0.5969 - acc: 0.6188\n",
      "Epoch 7/50\n",
      "202/202 [==============================] - 0s 246us/sample - loss: 0.5713 - acc: 0.6980\n",
      "Epoch 8/50\n",
      "202/202 [==============================] - 0s 300us/sample - loss: 0.5443 - acc: 0.7525\n",
      "Epoch 9/50\n",
      "202/202 [==============================] - 0s 248us/sample - loss: 0.5117 - acc: 0.7970\n",
      "Epoch 10/50\n",
      "202/202 [==============================] - 0s 299us/sample - loss: 0.4770 - acc: 0.8366\n",
      "Epoch 11/50\n",
      "202/202 [==============================] - 0s 244us/sample - loss: 0.4422 - acc: 0.8366\n",
      "Epoch 12/50\n",
      "202/202 [==============================] - 0s 244us/sample - loss: 0.4137 - acc: 0.8416\n",
      "Epoch 13/50\n",
      "202/202 [==============================] - 0s 301us/sample - loss: 0.3890 - acc: 0.8366\n",
      "Epoch 14/50\n",
      "202/202 [==============================] - 0s 245us/sample - loss: 0.3737 - acc: 0.8416\n",
      "Epoch 15/50\n",
      "202/202 [==============================] - 0s 292us/sample - loss: 0.3616 - acc: 0.8515\n",
      "Epoch 16/50\n",
      "202/202 [==============================] - 0s 244us/sample - loss: 0.3530 - acc: 0.8515\n",
      "Epoch 17/50\n",
      "202/202 [==============================] - 0s 288us/sample - loss: 0.3456 - acc: 0.8515\n",
      "Epoch 18/50\n",
      "202/202 [==============================] - 0s 295us/sample - loss: 0.3383 - acc: 0.8564\n",
      "Epoch 19/50\n",
      "202/202 [==============================] - 0s 288us/sample - loss: 0.3335 - acc: 0.8614\n",
      "Epoch 20/50\n",
      "202/202 [==============================] - 0s 244us/sample - loss: 0.3287 - acc: 0.8614\n",
      "Epoch 21/50\n",
      "202/202 [==============================] - 0s 243us/sample - loss: 0.3231 - acc: 0.8663\n",
      "Epoch 22/50\n",
      "202/202 [==============================] - 0s 299us/sample - loss: 0.3175 - acc: 0.8663\n",
      "Epoch 23/50\n",
      "202/202 [==============================] - 0s 238us/sample - loss: 0.3117 - acc: 0.8812\n",
      "Epoch 24/50\n",
      "202/202 [==============================] - 0s 238us/sample - loss: 0.3072 - acc: 0.8861\n",
      "Epoch 25/50\n",
      "202/202 [==============================] - 0s 292us/sample - loss: 0.3048 - acc: 0.8812\n",
      "Epoch 26/50\n",
      "202/202 [==============================] - 0s 241us/sample - loss: 0.2995 - acc: 0.8861\n",
      "Epoch 27/50\n",
      "202/202 [==============================] - 0s 286us/sample - loss: 0.2951 - acc: 0.8861\n",
      "Epoch 28/50\n",
      "202/202 [==============================] - 0s 328us/sample - loss: 0.2909 - acc: 0.8911\n",
      "Epoch 29/50\n",
      "202/202 [==============================] - 0s 279us/sample - loss: 0.2913 - acc: 0.8861\n",
      "Epoch 30/50\n",
      "202/202 [==============================] - 0s 294us/sample - loss: 0.2842 - acc: 0.8911\n",
      "Epoch 31/50\n",
      "202/202 [==============================] - 0s 241us/sample - loss: 0.2814 - acc: 0.8911\n",
      "Epoch 32/50\n",
      "202/202 [==============================] - 0s 293us/sample - loss: 0.2778 - acc: 0.8911\n",
      "Epoch 33/50\n",
      "202/202 [==============================] - 0s 243us/sample - loss: 0.2744 - acc: 0.9010\n",
      "Epoch 34/50\n",
      "202/202 [==============================] - 0s 245us/sample - loss: 0.2701 - acc: 0.8960\n",
      "Epoch 35/50\n",
      "202/202 [==============================] - 0s 298us/sample - loss: 0.2676 - acc: 0.9010\n",
      "Epoch 36/50\n",
      "202/202 [==============================] - 0s 280us/sample - loss: 0.2652 - acc: 0.9010\n",
      "Epoch 37/50\n",
      "202/202 [==============================] - 0s 292us/sample - loss: 0.2609 - acc: 0.9010\n",
      "Epoch 38/50\n",
      "202/202 [==============================] - 0s 299us/sample - loss: 0.2572 - acc: 0.9010\n",
      "Epoch 39/50\n",
      "202/202 [==============================] - 0s 247us/sample - loss: 0.2551 - acc: 0.9010\n",
      "Epoch 40/50\n",
      "202/202 [==============================] - 0s 296us/sample - loss: 0.2512 - acc: 0.9059\n",
      "Epoch 41/50\n",
      "202/202 [==============================] - 0s 244us/sample - loss: 0.2467 - acc: 0.9059\n",
      "Epoch 42/50\n",
      "202/202 [==============================] - 0s 294us/sample - loss: 0.2440 - acc: 0.9109\n",
      "Epoch 43/50\n",
      "202/202 [==============================] - 0s 251us/sample - loss: 0.2416 - acc: 0.9109\n",
      "Epoch 44/50\n",
      "202/202 [==============================] - 0s 239us/sample - loss: 0.2401 - acc: 0.9109\n",
      "Epoch 45/50\n",
      "202/202 [==============================] - 0s 294us/sample - loss: 0.2355 - acc: 0.9109\n",
      "Epoch 46/50\n",
      "202/202 [==============================] - 0s 239us/sample - loss: 0.2346 - acc: 0.9158\n",
      "Epoch 47/50\n",
      "202/202 [==============================] - 0s 237us/sample - loss: 0.2298 - acc: 0.9158\n",
      "Epoch 48/50\n",
      "202/202 [==============================] - 0s 248us/sample - loss: 0.2261 - acc: 0.9109\n",
      "Epoch 49/50\n",
      "202/202 [==============================] - 0s 295us/sample - loss: 0.2244 - acc: 0.9109\n",
      "Epoch 50/50\n",
      "202/202 [==============================] - 0s 239us/sample - loss: 0.2216 - acc: 0.9208\n",
      "101/101 [==============================] - 0s 3ms/sample - loss: 0.4406 - acc: 0.8614\n",
      "202/202 [==============================] - 0s 223us/sample - loss: 0.2147 - acc: 0.9208\n",
      "Epoch 1/50\n",
      "202/202 [==============================] - 0s 2ms/sample - loss: 0.7209 - acc: 0.4653\n",
      "Epoch 2/50\n",
      "202/202 [==============================] - 0s 314us/sample - loss: 0.6713 - acc: 0.4901\n",
      "Epoch 3/50\n",
      "202/202 [==============================] - 0s 339us/sample - loss: 0.6382 - acc: 0.5743\n",
      "Epoch 4/50\n",
      "202/202 [==============================] - 0s 297us/sample - loss: 0.6098 - acc: 0.6386\n",
      "Epoch 5/50\n",
      "202/202 [==============================] - 0s 322us/sample - loss: 0.5849 - acc: 0.7624\n",
      "Epoch 6/50\n",
      "202/202 [==============================] - 0s 322us/sample - loss: 0.5629 - acc: 0.8218\n",
      "Epoch 7/50\n",
      "202/202 [==============================] - 0s 389us/sample - loss: 0.5431 - acc: 0.8267\n",
      "Epoch 8/50\n",
      "202/202 [==============================] - 0s 398us/sample - loss: 0.5241 - acc: 0.8317\n",
      "Epoch 9/50\n",
      "202/202 [==============================] - 0s 321us/sample - loss: 0.5044 - acc: 0.8416\n",
      "Epoch 10/50\n",
      "202/202 [==============================] - 0s 330us/sample - loss: 0.4865 - acc: 0.8564\n",
      "Epoch 11/50\n",
      "202/202 [==============================] - 0s 300us/sample - loss: 0.4660 - acc: 0.8564\n",
      "Epoch 12/50\n",
      "202/202 [==============================] - 0s 348us/sample - loss: 0.4470 - acc: 0.8515\n",
      "Epoch 13/50\n",
      "202/202 [==============================] - 0s 863us/sample - loss: 0.4255 - acc: 0.8564\n",
      "Epoch 14/50\n",
      "202/202 [==============================] - 0s 464us/sample - loss: 0.4017 - acc: 0.8614\n",
      "Epoch 15/50\n",
      "202/202 [==============================] - 0s 503us/sample - loss: 0.3825 - acc: 0.8564\n",
      "Epoch 16/50\n",
      "202/202 [==============================] - 0s 459us/sample - loss: 0.3687 - acc: 0.8515\n",
      "Epoch 17/50\n",
      "202/202 [==============================] - 0s 596us/sample - loss: 0.3537 - acc: 0.8663\n",
      "Epoch 18/50\n",
      "202/202 [==============================] - 0s 392us/sample - loss: 0.3377 - acc: 0.8713\n",
      "Epoch 19/50\n",
      "202/202 [==============================] - 0s 649us/sample - loss: 0.3270 - acc: 0.8762\n",
      "Epoch 20/50\n",
      "202/202 [==============================] - 0s 424us/sample - loss: 0.3167 - acc: 0.8713\n",
      "Epoch 21/50\n",
      "202/202 [==============================] - 0s 413us/sample - loss: 0.3059 - acc: 0.8861\n",
      "Epoch 22/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202/202 [==============================] - 0s 374us/sample - loss: 0.2973 - acc: 0.8911\n",
      "Epoch 23/50\n",
      "202/202 [==============================] - 0s 956us/sample - loss: 0.2906 - acc: 0.8911\n",
      "Epoch 24/50\n",
      "202/202 [==============================] - 0s 554us/sample - loss: 0.2847 - acc: 0.8960\n",
      "Epoch 25/50\n",
      "202/202 [==============================] - 0s 441us/sample - loss: 0.2784 - acc: 0.8960\n",
      "Epoch 26/50\n",
      "202/202 [==============================] - 0s 339us/sample - loss: 0.2738 - acc: 0.9059\n",
      "Epoch 27/50\n",
      "202/202 [==============================] - 0s 961us/sample - loss: 0.2680 - acc: 0.8960\n",
      "Epoch 28/50\n",
      "202/202 [==============================] - 0s 739us/sample - loss: 0.2611 - acc: 0.9059\n",
      "Epoch 29/50\n",
      "202/202 [==============================] - 0s 679us/sample - loss: 0.2560 - acc: 0.9109\n",
      "Epoch 30/50\n",
      "202/202 [==============================] - 0s 663us/sample - loss: 0.2517 - acc: 0.9158\n",
      "Epoch 31/50\n",
      "202/202 [==============================] - 0s 483us/sample - loss: 0.2468 - acc: 0.9158\n",
      "Epoch 32/50\n",
      "202/202 [==============================] - 0s 514us/sample - loss: 0.2415 - acc: 0.9257\n",
      "Epoch 33/50\n",
      "202/202 [==============================] - 0s 592us/sample - loss: 0.2374 - acc: 0.9307\n",
      "Epoch 34/50\n",
      "202/202 [==============================] - 0s 380us/sample - loss: 0.2337 - acc: 0.9257\n",
      "Epoch 35/50\n",
      "202/202 [==============================] - 0s 289us/sample - loss: 0.2284 - acc: 0.9257\n",
      "Epoch 36/50\n",
      "202/202 [==============================] - 0s 236us/sample - loss: 0.2247 - acc: 0.9356\n",
      "Epoch 37/50\n",
      "202/202 [==============================] - 0s 250us/sample - loss: 0.2194 - acc: 0.9356\n",
      "Epoch 38/50\n",
      "202/202 [==============================] - 0s 466us/sample - loss: 0.2160 - acc: 0.9356\n",
      "Epoch 39/50\n",
      "202/202 [==============================] - 0s 571us/sample - loss: 0.2130 - acc: 0.9356\n",
      "Epoch 40/50\n",
      "202/202 [==============================] - 0s 422us/sample - loss: 0.2096 - acc: 0.9356\n",
      "Epoch 41/50\n",
      "202/202 [==============================] - 0s 295us/sample - loss: 0.2072 - acc: 0.9257\n",
      "Epoch 42/50\n",
      "202/202 [==============================] - 0s 241us/sample - loss: 0.2022 - acc: 0.9356\n",
      "Epoch 43/50\n",
      "202/202 [==============================] - 0s 287us/sample - loss: 0.1965 - acc: 0.9406s - loss: 0.1984 - acc: 0.940\n",
      "Epoch 44/50\n",
      "202/202 [==============================] - 0s 265us/sample - loss: 0.1928 - acc: 0.9406\n",
      "Epoch 45/50\n",
      "202/202 [==============================] - 0s 480us/sample - loss: 0.1892 - acc: 0.9406\n",
      "Epoch 46/50\n",
      "202/202 [==============================] - 0s 490us/sample - loss: 0.1848 - acc: 0.9406\n",
      "Epoch 47/50\n",
      "202/202 [==============================] - 0s 369us/sample - loss: 0.1822 - acc: 0.9406\n",
      "Epoch 48/50\n",
      "202/202 [==============================] - 0s 423us/sample - loss: 0.1786 - acc: 0.9406\n",
      "Epoch 49/50\n",
      "202/202 [==============================] - 0s 422us/sample - loss: 0.1757 - acc: 0.9406\n",
      "Epoch 50/50\n",
      "202/202 [==============================] - 0s 444us/sample - loss: 0.1706 - acc: 0.9356\n",
      "101/101 [==============================] - 0s 4ms/sample - loss: 0.6171 - acc: 0.7525\n",
      "202/202 [==============================] - 0s 222us/sample - loss: 0.1661 - acc: 0.9356\n",
      "Epoch 1/100\n",
      "202/202 [==============================] - 0s 2ms/sample - loss: 0.6552 - acc: 0.6188\n",
      "Epoch 2/100\n",
      "202/202 [==============================] - 0s 324us/sample - loss: 0.5947 - acc: 0.7525\n",
      "Epoch 3/100\n",
      "202/202 [==============================] - 0s 316us/sample - loss: 0.5499 - acc: 0.8168\n",
      "Epoch 4/100\n",
      "202/202 [==============================] - 0s 318us/sample - loss: 0.5083 - acc: 0.8317\n",
      "Epoch 5/100\n",
      "202/202 [==============================] - 0s 307us/sample - loss: 0.4693 - acc: 0.8317\n",
      "Epoch 6/100\n",
      "202/202 [==============================] - 0s 313us/sample - loss: 0.4359 - acc: 0.8218\n",
      "Epoch 7/100\n",
      "202/202 [==============================] - 0s 313us/sample - loss: 0.4045 - acc: 0.8317\n",
      "Epoch 8/100\n",
      "202/202 [==============================] - 0s 323us/sample - loss: 0.3782 - acc: 0.8267\n",
      "Epoch 9/100\n",
      "202/202 [==============================] - 0s 316us/sample - loss: 0.3543 - acc: 0.8267\n",
      "Epoch 10/100\n",
      "202/202 [==============================] - 0s 312us/sample - loss: 0.3376 - acc: 0.8465\n",
      "Epoch 11/100\n",
      "202/202 [==============================] - 0s 307us/sample - loss: 0.3237 - acc: 0.8416\n",
      "Epoch 12/100\n",
      "202/202 [==============================] - 0s 303us/sample - loss: 0.3130 - acc: 0.8416\n",
      "Epoch 13/100\n",
      "202/202 [==============================] - ETA: 0s - loss: 0.3007 - acc: 0.855 - 0s 288us/sample - loss: 0.3031 - acc: 0.8515\n",
      "Epoch 14/100\n",
      "202/202 [==============================] - 0s 379us/sample - loss: 0.2934 - acc: 0.8564\n",
      "Epoch 15/100\n",
      "202/202 [==============================] - 0s 302us/sample - loss: 0.2861 - acc: 0.8564\n",
      "Epoch 16/100\n",
      "202/202 [==============================] - 0s 295us/sample - loss: 0.2747 - acc: 0.8663\n",
      "Epoch 17/100\n",
      "202/202 [==============================] - 0s 309us/sample - loss: 0.2702 - acc: 0.8614\n",
      "Epoch 18/100\n",
      "202/202 [==============================] - 0s 308us/sample - loss: 0.2599 - acc: 0.8663\n",
      "Epoch 19/100\n",
      "202/202 [==============================] - 0s 300us/sample - loss: 0.2537 - acc: 0.8614\n",
      "Epoch 20/100\n",
      "202/202 [==============================] - 0s 249us/sample - loss: 0.2474 - acc: 0.8663\n",
      "Epoch 21/100\n",
      "202/202 [==============================] - 0s 309us/sample - loss: 0.2426 - acc: 0.8812\n",
      "Epoch 22/100\n",
      "202/202 [==============================] - 0s 425us/sample - loss: 0.2367 - acc: 0.8861\n",
      "Epoch 23/100\n",
      "202/202 [==============================] - 0s 408us/sample - loss: 0.2312 - acc: 0.8861\n",
      "Epoch 24/100\n",
      "202/202 [==============================] - 0s 346us/sample - loss: 0.2268 - acc: 0.8812\n",
      "Epoch 25/100\n",
      "202/202 [==============================] - 0s 307us/sample - loss: 0.2220 - acc: 0.8911\n",
      "Epoch 26/100\n",
      "202/202 [==============================] - 0s 297us/sample - loss: 0.2176 - acc: 0.9010\n",
      "Epoch 27/100\n",
      "202/202 [==============================] - 0s 297us/sample - loss: 0.2145 - acc: 0.8960\n",
      "Epoch 28/100\n",
      "202/202 [==============================] - 0s 309us/sample - loss: 0.2104 - acc: 0.9059\n",
      "Epoch 29/100\n",
      "202/202 [==============================] - 0s 254us/sample - loss: 0.2060 - acc: 0.9109\n",
      "Epoch 30/100\n",
      "202/202 [==============================] - 0s 306us/sample - loss: 0.2023 - acc: 0.9059\n",
      "Epoch 31/100\n",
      "202/202 [==============================] - 0s 294us/sample - loss: 0.1997 - acc: 0.9109\n",
      "Epoch 32/100\n",
      "202/202 [==============================] - 0s 300us/sample - loss: 0.1963 - acc: 0.9158\n",
      "Epoch 33/100\n",
      "202/202 [==============================] - 0s 252us/sample - loss: 0.1926 - acc: 0.9158\n",
      "Epoch 34/100\n",
      "202/202 [==============================] - 0s 258us/sample - loss: 0.1901 - acc: 0.9109\n",
      "Epoch 35/100\n",
      "202/202 [==============================] - 0s 310us/sample - loss: 0.1861 - acc: 0.9208\n",
      "Epoch 36/100\n",
      "202/202 [==============================] - 0s 312us/sample - loss: 0.1811 - acc: 0.9158\n",
      "Epoch 37/100\n",
      "202/202 [==============================] - 0s 315us/sample - loss: 0.1825 - acc: 0.9208\n",
      "Epoch 38/100\n",
      "202/202 [==============================] - 0s 306us/sample - loss: 0.1757 - acc: 0.9356\n",
      "Epoch 39/100\n",
      "202/202 [==============================] - 0s 307us/sample - loss: 0.1732 - acc: 0.9307\n",
      "Epoch 40/100\n",
      "202/202 [==============================] - 0s 296us/sample - loss: 0.1705 - acc: 0.9356\n",
      "Epoch 41/100\n",
      "202/202 [==============================] - 0s 255us/sample - loss: 0.1659 - acc: 0.9455\n",
      "Epoch 42/100\n",
      "202/202 [==============================] - 0s 303us/sample - loss: 0.1631 - acc: 0.9406\n",
      "Epoch 43/100\n",
      "202/202 [==============================] - 0s 305us/sample - loss: 0.1609 - acc: 0.9505\n",
      "Epoch 44/100\n",
      "202/202 [==============================] - 0s 262us/sample - loss: 0.1571 - acc: 0.9505\n",
      "Epoch 45/100\n",
      "202/202 [==============================] - 0s 311us/sample - loss: 0.1555 - acc: 0.9455\n",
      "Epoch 46/100\n",
      "202/202 [==============================] - 0s 306us/sample - loss: 0.1554 - acc: 0.9554\n",
      "Epoch 47/100\n",
      "202/202 [==============================] - 0s 332us/sample - loss: 0.1470 - acc: 0.9604\n",
      "Epoch 48/100\n",
      "202/202 [==============================] - 0s 411us/sample - loss: 0.1452 - acc: 0.9554\n",
      "Epoch 49/100\n",
      "202/202 [==============================] - 0s 272us/sample - loss: 0.1428 - acc: 0.9554\n",
      "Epoch 50/100\n",
      "202/202 [==============================] - 0s 304us/sample - loss: 0.1397 - acc: 0.9604\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202/202 [==============================] - 0s 355us/sample - loss: 0.1359 - acc: 0.9653\n",
      "Epoch 52/100\n",
      "202/202 [==============================] - 0s 355us/sample - loss: 0.1332 - acc: 0.9604\n",
      "Epoch 53/100\n",
      "202/202 [==============================] - 0s 410us/sample - loss: 0.1309 - acc: 0.9653\n",
      "Epoch 54/100\n",
      "202/202 [==============================] - 0s 390us/sample - loss: 0.1319 - acc: 0.9653\n",
      "Epoch 55/100\n",
      "202/202 [==============================] - 0s 472us/sample - loss: 0.1290 - acc: 0.9604\n",
      "Epoch 56/100\n",
      "202/202 [==============================] - 0s 311us/sample - loss: 0.1245 - acc: 0.9653\n",
      "Epoch 57/100\n",
      "202/202 [==============================] - 0s 1ms/sample - loss: 0.1215 - acc: 0.9604\n",
      "Epoch 58/100\n",
      "202/202 [==============================] - 0s 394us/sample - loss: 0.1225 - acc: 0.9703\n",
      "Epoch 59/100\n",
      "202/202 [==============================] - 0s 511us/sample - loss: 0.1191 - acc: 0.9604\n",
      "Epoch 60/100\n",
      "202/202 [==============================] - 0s 499us/sample - loss: 0.1151 - acc: 0.9703\n",
      "Epoch 61/100\n",
      "202/202 [==============================] - 0s 340us/sample - loss: 0.1123 - acc: 0.9653\n",
      "Epoch 62/100\n",
      "202/202 [==============================] - 0s 504us/sample - loss: 0.1105 - acc: 0.9703\n",
      "Epoch 63/100\n",
      "202/202 [==============================] - 0s 358us/sample - loss: 0.1088 - acc: 0.9653\n",
      "Epoch 64/100\n",
      "202/202 [==============================] - 0s 345us/sample - loss: 0.1095 - acc: 0.9703\n",
      "Epoch 65/100\n",
      "202/202 [==============================] - 0s 406us/sample - loss: 0.1044 - acc: 0.9703\n",
      "Epoch 66/100\n",
      "202/202 [==============================] - 0s 367us/sample - loss: 0.1040 - acc: 0.9703\n",
      "Epoch 67/100\n",
      "202/202 [==============================] - 0s 319us/sample - loss: 0.1017 - acc: 0.9703\n",
      "Epoch 68/100\n",
      "202/202 [==============================] - 0s 279us/sample - loss: 0.1018 - acc: 0.9703\n",
      "Epoch 69/100\n",
      "202/202 [==============================] - 0s 283us/sample - loss: 0.0986 - acc: 0.9752\n",
      "Epoch 70/100\n",
      "202/202 [==============================] - 0s 242us/sample - loss: 0.0961 - acc: 0.9752\n",
      "Epoch 71/100\n",
      "202/202 [==============================] - 0s 244us/sample - loss: 0.0944 - acc: 0.9703\n",
      "Epoch 72/100\n",
      "202/202 [==============================] - 0s 252us/sample - loss: 0.0930 - acc: 0.9703\n",
      "Epoch 73/100\n",
      "202/202 [==============================] - 0s 396us/sample - loss: 0.0913 - acc: 0.9703\n",
      "Epoch 74/100\n",
      "202/202 [==============================] - 0s 349us/sample - loss: 0.0890 - acc: 0.9802\n",
      "Epoch 75/100\n",
      "202/202 [==============================] - 0s 301us/sample - loss: 0.0897 - acc: 0.9703\n",
      "Epoch 76/100\n",
      "202/202 [==============================] - 0s 283us/sample - loss: 0.0865 - acc: 0.9703\n",
      "Epoch 77/100\n",
      "202/202 [==============================] - 0s 297us/sample - loss: 0.0855 - acc: 0.9851\n",
      "Epoch 78/100\n",
      "202/202 [==============================] - 0s 246us/sample - loss: 0.0830 - acc: 0.9802\n",
      "Epoch 79/100\n",
      "202/202 [==============================] - 0s 291us/sample - loss: 0.0830 - acc: 0.9703\n",
      "Epoch 80/100\n",
      "202/202 [==============================] - 0s 240us/sample - loss: 0.0815 - acc: 0.9752\n",
      "Epoch 81/100\n",
      "202/202 [==============================] - 0s 239us/sample - loss: 0.0798 - acc: 0.9802\n",
      "Epoch 82/100\n",
      "202/202 [==============================] - 0s 353us/sample - loss: 0.0789 - acc: 0.9802\n",
      "Epoch 83/100\n",
      "202/202 [==============================] - 0s 374us/sample - loss: 0.0784 - acc: 0.9752\n",
      "Epoch 84/100\n",
      "202/202 [==============================] - 0s 430us/sample - loss: 0.0756 - acc: 0.9802\n",
      "Epoch 85/100\n",
      "202/202 [==============================] - 0s 297us/sample - loss: 0.0751 - acc: 0.9802\n",
      "Epoch 86/100\n",
      "202/202 [==============================] - 0s 256us/sample - loss: 0.0746 - acc: 0.9802\n",
      "Epoch 87/100\n",
      "202/202 [==============================] - 0s 312us/sample - loss: 0.0742 - acc: 0.9752\n",
      "Epoch 88/100\n",
      "202/202 [==============================] - 0s 239us/sample - loss: 0.0717 - acc: 0.9802\n",
      "Epoch 89/100\n",
      "202/202 [==============================] - 0s 297us/sample - loss: 0.0709 - acc: 0.9802\n",
      "Epoch 90/100\n",
      "202/202 [==============================] - 0s 255us/sample - loss: 0.0684 - acc: 0.9802\n",
      "Epoch 91/100\n",
      "202/202 [==============================] - 0s 342us/sample - loss: 0.0680 - acc: 0.9802\n",
      "Epoch 92/100\n",
      "202/202 [==============================] - 0s 298us/sample - loss: 0.0679 - acc: 0.9802\n",
      "Epoch 93/100\n",
      "202/202 [==============================] - 0s 312us/sample - loss: 0.0654 - acc: 0.9802\n",
      "Epoch 94/100\n",
      "202/202 [==============================] - 0s 298us/sample - loss: 0.0660 - acc: 0.9851\n",
      "Epoch 95/100\n",
      "202/202 [==============================] - 0s 289us/sample - loss: 0.0643 - acc: 0.9851\n",
      "Epoch 96/100\n",
      "202/202 [==============================] - 0s 260us/sample - loss: 0.0622 - acc: 0.9802\n",
      "Epoch 97/100\n",
      "202/202 [==============================] - 0s 341us/sample - loss: 0.0623 - acc: 0.9851\n",
      "Epoch 98/100\n",
      "202/202 [==============================] - 0s 329us/sample - loss: 0.0607 - acc: 0.9851\n",
      "Epoch 99/100\n",
      "202/202 [==============================] - 0s 363us/sample - loss: 0.0584 - acc: 0.9851\n",
      "Epoch 100/100\n",
      "202/202 [==============================] - 0s 362us/sample - loss: 0.0599 - acc: 0.9851\n",
      "101/101 [==============================] - 0s 4ms/sample - loss: 0.9483 - acc: 0.7624\n",
      "202/202 [==============================] - 0s 322us/sample - loss: 0.0559 - acc: 0.9851\n",
      "Epoch 1/100\n",
      "202/202 [==============================] - 1s 3ms/sample - loss: 0.6681 - acc: 0.5594\n",
      "Epoch 2/100\n",
      "202/202 [==============================] - 0s 378us/sample - loss: 0.6279 - acc: 0.7030\n",
      "Epoch 3/100\n",
      "202/202 [==============================] - 0s 336us/sample - loss: 0.5881 - acc: 0.7475\n",
      "Epoch 4/100\n",
      "202/202 [==============================] - 0s 424us/sample - loss: 0.5425 - acc: 0.8119\n",
      "Epoch 5/100\n",
      "202/202 [==============================] - 0s 480us/sample - loss: 0.4974 - acc: 0.8168\n",
      "Epoch 6/100\n",
      "202/202 [==============================] - 0s 428us/sample - loss: 0.4567 - acc: 0.8168\n",
      "Epoch 7/100\n",
      "202/202 [==============================] - 0s 635us/sample - loss: 0.4252 - acc: 0.8416\n",
      "Epoch 8/100\n",
      "202/202 [==============================] - 0s 565us/sample - loss: 0.4049 - acc: 0.8515s - loss: 0.3785 - acc: 0.872\n",
      "Epoch 9/100\n",
      "202/202 [==============================] - 0s 694us/sample - loss: 0.3895 - acc: 0.8515\n",
      "Epoch 10/100\n",
      "202/202 [==============================] - 0s 547us/sample - loss: 0.3764 - acc: 0.8614\n",
      "Epoch 11/100\n",
      "202/202 [==============================] - 0s 533us/sample - loss: 0.3663 - acc: 0.8713\n",
      "Epoch 12/100\n",
      "202/202 [==============================] - 0s 330us/sample - loss: 0.3585 - acc: 0.8861\n",
      "Epoch 13/100\n",
      "202/202 [==============================] - 0s 318us/sample - loss: 0.3505 - acc: 0.8911\n",
      "Epoch 14/100\n",
      "202/202 [==============================] - 0s 318us/sample - loss: 0.3446 - acc: 0.8911\n",
      "Epoch 15/100\n",
      "202/202 [==============================] - 0s 390us/sample - loss: 0.3411 - acc: 0.8911\n",
      "Epoch 16/100\n",
      "202/202 [==============================] - 0s 347us/sample - loss: 0.3367 - acc: 0.8911\n",
      "Epoch 17/100\n",
      "202/202 [==============================] - 0s 326us/sample - loss: 0.3326 - acc: 0.8911\n",
      "Epoch 18/100\n",
      "202/202 [==============================] - 0s 301us/sample - loss: 0.3279 - acc: 0.8911\n",
      "Epoch 19/100\n",
      "202/202 [==============================] - 0s 299us/sample - loss: 0.3241 - acc: 0.8911\n",
      "Epoch 20/100\n",
      "202/202 [==============================] - 0s 319us/sample - loss: 0.3216 - acc: 0.8911\n",
      "Epoch 21/100\n",
      "202/202 [==============================] - 0s 319us/sample - loss: 0.3194 - acc: 0.8911\n",
      "Epoch 22/100\n",
      "202/202 [==============================] - 0s 460us/sample - loss: 0.3150 - acc: 0.8911\n",
      "Epoch 23/100\n",
      "202/202 [==============================] - 0s 501us/sample - loss: 0.3114 - acc: 0.8911\n",
      "Epoch 24/100\n",
      "202/202 [==============================] - 0s 526us/sample - loss: 0.3078 - acc: 0.8911\n",
      "Epoch 25/100\n",
      "202/202 [==============================] - 0s 503us/sample - loss: 0.3046 - acc: 0.8911\n",
      "Epoch 26/100\n",
      "202/202 [==============================] - 0s 411us/sample - loss: 0.3028 - acc: 0.8911\n",
      "Epoch 27/100\n",
      "202/202 [==============================] - 0s 445us/sample - loss: 0.3003 - acc: 0.8911\n",
      "Epoch 28/100\n",
      "202/202 [==============================] - 0s 362us/sample - loss: 0.2960 - acc: 0.8911\n",
      "Epoch 29/100\n",
      "202/202 [==============================] - 0s 308us/sample - loss: 0.2941 - acc: 0.8911\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202/202 [==============================] - 0s 304us/sample - loss: 0.2913 - acc: 0.8911\n",
      "Epoch 31/100\n",
      "202/202 [==============================] - 0s 306us/sample - loss: 0.2877 - acc: 0.8911\n",
      "Epoch 32/100\n",
      "202/202 [==============================] - 0s 306us/sample - loss: 0.2843 - acc: 0.8960\n",
      "Epoch 33/100\n",
      "202/202 [==============================] - 0s 309us/sample - loss: 0.2812 - acc: 0.8960\n",
      "Epoch 34/100\n",
      "202/202 [==============================] - 0s 304us/sample - loss: 0.2788 - acc: 0.9010\n",
      "Epoch 35/100\n",
      "202/202 [==============================] - 0s 302us/sample - loss: 0.2754 - acc: 0.8960\n",
      "Epoch 36/100\n",
      "202/202 [==============================] - 0s 320us/sample - loss: 0.2723 - acc: 0.9010\n",
      "Epoch 37/100\n",
      "202/202 [==============================] - 0s 355us/sample - loss: 0.2704 - acc: 0.9109\n",
      "Epoch 38/100\n",
      "202/202 [==============================] - 0s 308us/sample - loss: 0.2664 - acc: 0.9010\n",
      "Epoch 39/100\n",
      "202/202 [==============================] - ETA: 0s - loss: 0.2636 - acc: 0.911 - 0s 308us/sample - loss: 0.2625 - acc: 0.9109\n",
      "Epoch 40/100\n",
      "202/202 [==============================] - 0s 321us/sample - loss: 0.2602 - acc: 0.9158\n",
      "Epoch 41/100\n",
      "202/202 [==============================] - 0s 303us/sample - loss: 0.2555 - acc: 0.9109\n",
      "Epoch 42/100\n",
      "202/202 [==============================] - 0s 315us/sample - loss: 0.2545 - acc: 0.9158\n",
      "Epoch 43/100\n",
      "202/202 [==============================] - 0s 665us/sample - loss: 0.2491 - acc: 0.9109\n",
      "Epoch 44/100\n",
      "202/202 [==============================] - 0s 684us/sample - loss: 0.2469 - acc: 0.9109\n",
      "Epoch 45/100\n",
      "202/202 [==============================] - 0s 615us/sample - loss: 0.2462 - acc: 0.9158\n",
      "Epoch 46/100\n",
      "202/202 [==============================] - 0s 703us/sample - loss: 0.2408 - acc: 0.9109s - loss: 0.2258 - acc: 0.91\n",
      "Epoch 47/100\n",
      "202/202 [==============================] - 0s 621us/sample - loss: 0.2370 - acc: 0.9158\n",
      "Epoch 48/100\n",
      "202/202 [==============================] - 0s 2ms/sample - loss: 0.2354 - acc: 0.9208\n",
      "Epoch 49/100\n",
      "202/202 [==============================] - 0s 707us/sample - loss: 0.2318 - acc: 0.9208\n",
      "Epoch 50/100\n",
      "202/202 [==============================] - 0s 1ms/sample - loss: 0.2280 - acc: 0.9257\n",
      "Epoch 51/100\n",
      "202/202 [==============================] - 0s 629us/sample - loss: 0.2246 - acc: 0.9257\n",
      "Epoch 52/100\n",
      "202/202 [==============================] - 0s 709us/sample - loss: 0.2227 - acc: 0.9307\n",
      "Epoch 53/100\n",
      "202/202 [==============================] - 0s 405us/sample - loss: 0.2178 - acc: 0.9257\n",
      "Epoch 54/100\n",
      "202/202 [==============================] - 0s 501us/sample - loss: 0.2156 - acc: 0.9257\n",
      "Epoch 55/100\n",
      "202/202 [==============================] - 0s 465us/sample - loss: 0.2126 - acc: 0.9307\n",
      "Epoch 56/100\n",
      "202/202 [==============================] - 0s 442us/sample - loss: 0.2083 - acc: 0.9307\n",
      "Epoch 57/100\n",
      "202/202 [==============================] - 0s 366us/sample - loss: 0.2078 - acc: 0.9307\n",
      "Epoch 58/100\n",
      "202/202 [==============================] - 0s 302us/sample - loss: 0.2030 - acc: 0.9307\n",
      "Epoch 59/100\n",
      "202/202 [==============================] - 0s 301us/sample - loss: 0.1986 - acc: 0.9307\n",
      "Epoch 60/100\n",
      "202/202 [==============================] - 0s 254us/sample - loss: 0.1970 - acc: 0.9307\n",
      "Epoch 61/100\n",
      "202/202 [==============================] - 0s 313us/sample - loss: 0.1926 - acc: 0.9307\n",
      "Epoch 62/100\n",
      "202/202 [==============================] - 0s 306us/sample - loss: 0.1871 - acc: 0.9307\n",
      "Epoch 63/100\n",
      "202/202 [==============================] - 0s 309us/sample - loss: 0.1848 - acc: 0.9307\n",
      "Epoch 64/100\n",
      "202/202 [==============================] - 0s 311us/sample - loss: 0.1831 - acc: 0.9307\n",
      "Epoch 65/100\n",
      "202/202 [==============================] - 0s 351us/sample - loss: 0.1778 - acc: 0.9307\n",
      "Epoch 66/100\n",
      "202/202 [==============================] - 0s 422us/sample - loss: 0.1755 - acc: 0.9307\n",
      "Epoch 67/100\n",
      "202/202 [==============================] - 0s 525us/sample - loss: 0.1733 - acc: 0.9257\n",
      "Epoch 68/100\n",
      "202/202 [==============================] - 0s 413us/sample - loss: 0.1703 - acc: 0.9406\n",
      "Epoch 69/100\n",
      "202/202 [==============================] - 0s 341us/sample - loss: 0.1676 - acc: 0.9406\n",
      "Epoch 70/100\n",
      "202/202 [==============================] - 0s 301us/sample - loss: 0.1647 - acc: 0.9406\n",
      "Epoch 71/100\n",
      "202/202 [==============================] - 0s 322us/sample - loss: 0.1607 - acc: 0.9406\n",
      "Epoch 72/100\n",
      "202/202 [==============================] - 0s 294us/sample - loss: 0.1584 - acc: 0.9406\n",
      "Epoch 73/100\n",
      "202/202 [==============================] - 0s 308us/sample - loss: 0.1565 - acc: 0.9505\n",
      "Epoch 74/100\n",
      "202/202 [==============================] - 0s 318us/sample - loss: 0.1537 - acc: 0.9505\n",
      "Epoch 75/100\n",
      "202/202 [==============================] - 0s 299us/sample - loss: 0.1525 - acc: 0.9455\n",
      "Epoch 76/100\n",
      "202/202 [==============================] - 0s 302us/sample - loss: 0.1517 - acc: 0.9554\n",
      "Epoch 77/100\n",
      "202/202 [==============================] - 0s 252us/sample - loss: 0.1466 - acc: 0.9554\n",
      "Epoch 78/100\n",
      "202/202 [==============================] - 0s 315us/sample - loss: 0.1436 - acc: 0.9505\n",
      "Epoch 79/100\n",
      "202/202 [==============================] - 0s 307us/sample - loss: 0.1424 - acc: 0.9554\n",
      "Epoch 80/100\n",
      "202/202 [==============================] - 0s 248us/sample - loss: 0.1396 - acc: 0.9554\n",
      "Epoch 81/100\n",
      "202/202 [==============================] - 0s 378us/sample - loss: 0.1364 - acc: 0.9554\n",
      "Epoch 82/100\n",
      "202/202 [==============================] - 0s 468us/sample - loss: 0.1331 - acc: 0.9653\n",
      "Epoch 83/100\n",
      "202/202 [==============================] - 0s 520us/sample - loss: 0.1300 - acc: 0.9604\n",
      "Epoch 84/100\n",
      "202/202 [==============================] - 0s 530us/sample - loss: 0.1271 - acc: 0.9653\n",
      "Epoch 85/100\n",
      "202/202 [==============================] - 0s 436us/sample - loss: 0.1243 - acc: 0.9653\n",
      "Epoch 86/100\n",
      "202/202 [==============================] - 0s 486us/sample - loss: 0.1240 - acc: 0.9653\n",
      "Epoch 87/100\n",
      "202/202 [==============================] - 0s 438us/sample - loss: 0.1212 - acc: 0.9703\n",
      "Epoch 88/100\n",
      "202/202 [==============================] - 0s 396us/sample - loss: 0.1170 - acc: 0.9752\n",
      "Epoch 89/100\n",
      "202/202 [==============================] - 0s 359us/sample - loss: 0.1150 - acc: 0.9752\n",
      "Epoch 90/100\n",
      "202/202 [==============================] - 0s 335us/sample - loss: 0.1122 - acc: 0.9752\n",
      "Epoch 91/100\n",
      "202/202 [==============================] - 0s 325us/sample - loss: 0.1084 - acc: 0.9752\n",
      "Epoch 92/100\n",
      "202/202 [==============================] - 0s 380us/sample - loss: 0.1076 - acc: 0.9703\n",
      "Epoch 93/100\n",
      "202/202 [==============================] - 0s 346us/sample - loss: 0.1062 - acc: 0.9752\n",
      "Epoch 94/100\n",
      "202/202 [==============================] - 0s 302us/sample - loss: 0.1028 - acc: 0.9752\n",
      "Epoch 95/100\n",
      "202/202 [==============================] - 0s 301us/sample - loss: 0.1010 - acc: 0.9752\n",
      "Epoch 96/100\n",
      "202/202 [==============================] - 0s 356us/sample - loss: 0.0990 - acc: 0.9802\n",
      "Epoch 97/100\n",
      "202/202 [==============================] - 0s 349us/sample - loss: 0.0963 - acc: 0.9752\n",
      "Epoch 98/100\n",
      "202/202 [==============================] - 0s 371us/sample - loss: 0.0942 - acc: 0.9752\n",
      "Epoch 99/100\n",
      "202/202 [==============================] - 0s 303us/sample - loss: 0.0929 - acc: 0.9802\n",
      "Epoch 100/100\n",
      "202/202 [==============================] - 0s 308us/sample - loss: 0.0901 - acc: 0.9802\n",
      "101/101 [==============================] - 0s 3ms/sample - loss: 0.7139 - acc: 0.8416\n",
      "202/202 [==============================] - 0s 234us/sample - loss: 0.0874 - acc: 0.9802\n",
      "Epoch 1/100\n",
      "202/202 [==============================] - 0s 2ms/sample - loss: 0.7921 - acc: 0.4752\n",
      "Epoch 2/100\n",
      "202/202 [==============================] - 0s 316us/sample - loss: 0.6950 - acc: 0.6287\n",
      "Epoch 3/100\n",
      "202/202 [==============================] - 0s 338us/sample - loss: 0.6499 - acc: 0.6683\n",
      "Epoch 4/100\n",
      "202/202 [==============================] - 0s 329us/sample - loss: 0.6119 - acc: 0.7327\n",
      "Epoch 5/100\n",
      "202/202 [==============================] - 0s 333us/sample - loss: 0.5795 - acc: 0.7772\n",
      "Epoch 6/100\n",
      "202/202 [==============================] - 0s 316us/sample - loss: 0.5459 - acc: 0.8168\n",
      "Epoch 7/100\n",
      "202/202 [==============================] - 0s 315us/sample - loss: 0.5129 - acc: 0.8069\n",
      "Epoch 8/100\n",
      "202/202 [==============================] - 0s 314us/sample - loss: 0.4789 - acc: 0.8119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100\n",
      "202/202 [==============================] - 0s 316us/sample - loss: 0.4502 - acc: 0.8218\n",
      "Epoch 10/100\n",
      "202/202 [==============================] - 0s 310us/sample - loss: 0.4233 - acc: 0.8267\n",
      "Epoch 11/100\n",
      "202/202 [==============================] - 0s 311us/sample - loss: 0.4022 - acc: 0.8267\n",
      "Epoch 12/100\n",
      "202/202 [==============================] - 0s 316us/sample - loss: 0.3858 - acc: 0.8416\n",
      "Epoch 13/100\n",
      "202/202 [==============================] - 0s 316us/sample - loss: 0.3728 - acc: 0.8465\n",
      "Epoch 14/100\n",
      "202/202 [==============================] - 0s 312us/sample - loss: 0.3564 - acc: 0.8515\n",
      "Epoch 15/100\n",
      "202/202 [==============================] - 0s 333us/sample - loss: 0.3476 - acc: 0.8713\n",
      "Epoch 16/100\n",
      "202/202 [==============================] - 0s 451us/sample - loss: 0.3371 - acc: 0.8762\n",
      "Epoch 17/100\n",
      "202/202 [==============================] - 0s 271us/sample - loss: 0.3299 - acc: 0.8762\n",
      "Epoch 18/100\n",
      "202/202 [==============================] - 0s 316us/sample - loss: 0.3226 - acc: 0.8713\n",
      "Epoch 19/100\n",
      "202/202 [==============================] - 0s 315us/sample - loss: 0.3159 - acc: 0.8713\n",
      "Epoch 20/100\n",
      "202/202 [==============================] - 0s 331us/sample - loss: 0.3097 - acc: 0.8713\n",
      "Epoch 21/100\n",
      "202/202 [==============================] - 0s 302us/sample - loss: 0.3024 - acc: 0.8713\n",
      "Epoch 22/100\n",
      "202/202 [==============================] - 0s 328us/sample - loss: 0.2983 - acc: 0.8812\n",
      "Epoch 23/100\n",
      "202/202 [==============================] - 0s 355us/sample - loss: 0.2919 - acc: 0.8861\n",
      "Epoch 24/100\n",
      "202/202 [==============================] - 0s 472us/sample - loss: 0.2872 - acc: 0.8911\n",
      "Epoch 25/100\n",
      "202/202 [==============================] - 0s 366us/sample - loss: 0.2820 - acc: 0.8861\n",
      "Epoch 26/100\n",
      "202/202 [==============================] - 0s 356us/sample - loss: 0.2790 - acc: 0.8861\n",
      "Epoch 27/100\n",
      "202/202 [==============================] - 0s 1ms/sample - loss: 0.2740 - acc: 0.8911\n",
      "Epoch 28/100\n",
      "202/202 [==============================] - 0s 386us/sample - loss: 0.2702 - acc: 0.8960\n",
      "Epoch 29/100\n",
      "202/202 [==============================] - 0s 549us/sample - loss: 0.2633 - acc: 0.8960\n",
      "Epoch 30/100\n",
      "202/202 [==============================] - 0s 351us/sample - loss: 0.2621 - acc: 0.9010\n",
      "Epoch 31/100\n",
      "202/202 [==============================] - 0s 357us/sample - loss: 0.2566 - acc: 0.9010\n",
      "Epoch 32/100\n",
      "202/202 [==============================] - 0s 434us/sample - loss: 0.2521 - acc: 0.8960\n",
      "Epoch 33/100\n",
      "202/202 [==============================] - 0s 491us/sample - loss: 0.2489 - acc: 0.9010\n",
      "Epoch 34/100\n",
      "202/202 [==============================] - 0s 385us/sample - loss: 0.2468 - acc: 0.9010\n",
      "Epoch 35/100\n",
      "202/202 [==============================] - 0s 456us/sample - loss: 0.2437 - acc: 0.9059\n",
      "Epoch 36/100\n",
      "202/202 [==============================] - 0s 413us/sample - loss: 0.2385 - acc: 0.9010\n",
      "Epoch 37/100\n",
      "202/202 [==============================] - 0s 306us/sample - loss: 0.2336 - acc: 0.9010\n",
      "Epoch 38/100\n",
      "202/202 [==============================] - 0s 310us/sample - loss: 0.2293 - acc: 0.9059\n",
      "Epoch 39/100\n",
      "202/202 [==============================] - 0s 310us/sample - loss: 0.2258 - acc: 0.9109\n",
      "Epoch 40/100\n",
      "202/202 [==============================] - 0s 316us/sample - loss: 0.2217 - acc: 0.9059\n",
      "Epoch 41/100\n",
      "202/202 [==============================] - 0s 367us/sample - loss: 0.2197 - acc: 0.9109\n",
      "Epoch 42/100\n",
      "202/202 [==============================] - 0s 308us/sample - loss: 0.2149 - acc: 0.9109\n",
      "Epoch 43/100\n",
      "202/202 [==============================] - 0s 311us/sample - loss: 0.2110 - acc: 0.9109\n",
      "Epoch 44/100\n",
      "202/202 [==============================] - 0s 304us/sample - loss: 0.2075 - acc: 0.9109\n",
      "Epoch 45/100\n",
      "202/202 [==============================] - 0s 313us/sample - loss: 0.2032 - acc: 0.9208\n",
      "Epoch 46/100\n",
      "202/202 [==============================] - 0s 311us/sample - loss: 0.2037 - acc: 0.9109\n",
      "Epoch 47/100\n",
      "202/202 [==============================] - 0s 316us/sample - loss: 0.1982 - acc: 0.9257\n",
      "Epoch 48/100\n",
      "202/202 [==============================] - 0s 320us/sample - loss: 0.1964 - acc: 0.9257\n",
      "Epoch 49/100\n",
      "202/202 [==============================] - 0s 310us/sample - loss: 0.1910 - acc: 0.9307\n",
      "Epoch 50/100\n",
      "202/202 [==============================] - 0s 315us/sample - loss: 0.1874 - acc: 0.9307\n",
      "Epoch 51/100\n",
      "202/202 [==============================] - 0s 344us/sample - loss: 0.1833 - acc: 0.9307\n",
      "Epoch 52/100\n",
      "202/202 [==============================] - 0s 300us/sample - loss: 0.1801 - acc: 0.9307\n",
      "Epoch 53/100\n",
      "202/202 [==============================] - 0s 315us/sample - loss: 0.1774 - acc: 0.9307\n",
      "Epoch 54/100\n",
      "202/202 [==============================] - 0s 304us/sample - loss: 0.1728 - acc: 0.9356\n",
      "Epoch 55/100\n",
      "202/202 [==============================] - 0s 317us/sample - loss: 0.1726 - acc: 0.9356\n",
      "Epoch 56/100\n",
      "202/202 [==============================] - 0s 315us/sample - loss: 0.1687 - acc: 0.9406\n",
      "Epoch 57/100\n",
      "202/202 [==============================] - 0s 306us/sample - loss: 0.1630 - acc: 0.9406\n",
      "Epoch 58/100\n",
      "202/202 [==============================] - 0s 303us/sample - loss: 0.1618 - acc: 0.9406\n",
      "Epoch 59/100\n",
      "202/202 [==============================] - 0s 315us/sample - loss: 0.1583 - acc: 0.9455\n",
      "Epoch 60/100\n",
      "202/202 [==============================] - 0s 320us/sample - loss: 0.1561 - acc: 0.9505\n",
      "Epoch 61/100\n",
      "202/202 [==============================] - 0s 313us/sample - loss: 0.1519 - acc: 0.9455\n",
      "Epoch 62/100\n",
      "202/202 [==============================] - 0s 308us/sample - loss: 0.1493 - acc: 0.9554\n",
      "Epoch 63/100\n",
      "202/202 [==============================] - 0s 313us/sample - loss: 0.1463 - acc: 0.9604\n",
      "Epoch 64/100\n",
      "202/202 [==============================] - 0s 312us/sample - loss: 0.1433 - acc: 0.9604\n",
      "Epoch 65/100\n",
      "202/202 [==============================] - 0s 321us/sample - loss: 0.1419 - acc: 0.9554\n",
      "Epoch 66/100\n",
      "202/202 [==============================] - 0s 318us/sample - loss: 0.1376 - acc: 0.9703\n",
      "Epoch 67/100\n",
      "202/202 [==============================] - 0s 309us/sample - loss: 0.1352 - acc: 0.9703\n",
      "Epoch 68/100\n",
      "202/202 [==============================] - 0s 317us/sample - loss: 0.1327 - acc: 0.9703\n",
      "Epoch 69/100\n",
      "202/202 [==============================] - 0s 334us/sample - loss: 0.1328 - acc: 0.9554\n",
      "Epoch 70/100\n",
      "202/202 [==============================] - 0s 304us/sample - loss: 0.1307 - acc: 0.9604\n",
      "Epoch 71/100\n",
      "202/202 [==============================] - 0s 299us/sample - loss: 0.1265 - acc: 0.9653\n",
      "Epoch 72/100\n",
      "202/202 [==============================] - 0s 311us/sample - loss: 0.1243 - acc: 0.9653\n",
      "Epoch 73/100\n",
      "202/202 [==============================] - 0s 311us/sample - loss: 0.1223 - acc: 0.9703\n",
      "Epoch 74/100\n",
      "202/202 [==============================] - 0s 316us/sample - loss: 0.1179 - acc: 0.9703\n",
      "Epoch 75/100\n",
      "202/202 [==============================] - 0s 314us/sample - loss: 0.1153 - acc: 0.9703\n",
      "Epoch 76/100\n",
      "202/202 [==============================] - 0s 311us/sample - loss: 0.1130 - acc: 0.9703\n",
      "Epoch 77/100\n",
      "202/202 [==============================] - 0s 311us/sample - loss: 0.1099 - acc: 0.9703\n",
      "Epoch 78/100\n",
      "202/202 [==============================] - 0s 314us/sample - loss: 0.1099 - acc: 0.9703\n",
      "Epoch 79/100\n",
      "202/202 [==============================] - 0s 312us/sample - loss: 0.1059 - acc: 0.9752\n",
      "Epoch 80/100\n",
      "202/202 [==============================] - 0s 304us/sample - loss: 0.1009 - acc: 0.9752\n",
      "Epoch 81/100\n",
      "202/202 [==============================] - 0s 304us/sample - loss: 0.0980 - acc: 0.9752\n",
      "Epoch 82/100\n",
      "202/202 [==============================] - 0s 318us/sample - loss: 0.1027 - acc: 0.9752\n",
      "Epoch 83/100\n",
      "202/202 [==============================] - 0s 317us/sample - loss: 0.0960 - acc: 0.9802\n",
      "Epoch 84/100\n",
      "202/202 [==============================] - 0s 306us/sample - loss: 0.0917 - acc: 0.9752\n",
      "Epoch 85/100\n",
      "202/202 [==============================] - 0s 310us/sample - loss: 0.0891 - acc: 0.9752\n",
      "Epoch 86/100\n",
      "202/202 [==============================] - 0s 353us/sample - loss: 0.0871 - acc: 0.9851\n",
      "Epoch 87/100\n",
      "202/202 [==============================] - 0s 461us/sample - loss: 0.0838 - acc: 0.9851\n",
      "Epoch 88/100\n",
      "202/202 [==============================] - 0s 626us/sample - loss: 0.0834 - acc: 0.9752\n",
      "Epoch 89/100\n",
      "202/202 [==============================] - 0s 546us/sample - loss: 0.0804 - acc: 0.9851\n",
      "Epoch 90/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202/202 [==============================] - 0s 586us/sample - loss: 0.0781 - acc: 0.9851\n",
      "Epoch 91/100\n",
      "202/202 [==============================] - 0s 307us/sample - loss: 0.0758 - acc: 0.9851\n",
      "Epoch 92/100\n",
      "202/202 [==============================] - 0s 310us/sample - loss: 0.0743 - acc: 0.9851\n",
      "Epoch 93/100\n",
      "202/202 [==============================] - 0s 301us/sample - loss: 0.0719 - acc: 0.9851\n",
      "Epoch 94/100\n",
      "202/202 [==============================] - 0s 321us/sample - loss: 0.0705 - acc: 0.9851\n",
      "Epoch 95/100\n",
      "202/202 [==============================] - 0s 315us/sample - loss: 0.0678 - acc: 0.9851\n",
      "Epoch 96/100\n",
      "202/202 [==============================] - 0s 471us/sample - loss: 0.0672 - acc: 0.9851\n",
      "Epoch 97/100\n",
      "202/202 [==============================] - 0s 541us/sample - loss: 0.0655 - acc: 0.9901\n",
      "Epoch 98/100\n",
      "202/202 [==============================] - 0s 497us/sample - loss: 0.0635 - acc: 0.9901\n",
      "Epoch 99/100\n",
      "202/202 [==============================] - 0s 402us/sample - loss: 0.0614 - acc: 0.9901\n",
      "Epoch 100/100\n",
      "202/202 [==============================] - 0s 470us/sample - loss: 0.0594 - acc: 0.9901\n",
      "101/101 [==============================] - 0s 4ms/sample - loss: 0.6028 - acc: 0.8416\n",
      "202/202 [==============================] - 0s 231us/sample - loss: 0.0573 - acc: 0.9901\n",
      "Epoch 1/20\n",
      "303/303 [==============================] - 0s 2ms/sample - loss: 0.6588 - acc: 0.6172\n",
      "Epoch 2/20\n",
      "303/303 [==============================] - 0s 336us/sample - loss: 0.5776 - acc: 0.7525\n",
      "Epoch 3/20\n",
      "303/303 [==============================] - 0s 791us/sample - loss: 0.5139 - acc: 0.7558\n",
      "Epoch 4/20\n",
      "303/303 [==============================] - 0s 752us/sample - loss: 0.4662 - acc: 0.7723s - loss: 0.4850 - acc: 0.\n",
      "Epoch 5/20\n",
      "303/303 [==============================] - 0s 680us/sample - loss: 0.4341 - acc: 0.7954\n",
      "Epoch 6/20\n",
      "303/303 [==============================] - 0s 1ms/sample - loss: 0.4137 - acc: 0.7954\n",
      "Epoch 7/20\n",
      "303/303 [==============================] - 0s 1ms/sample - loss: 0.3972 - acc: 0.7987\n",
      "Epoch 8/20\n",
      "303/303 [==============================] - 0s 742us/sample - loss: 0.3862 - acc: 0.8053\n",
      "Epoch 9/20\n",
      "303/303 [==============================] - 0s 1ms/sample - loss: 0.3760 - acc: 0.8185\n",
      "Epoch 10/20\n",
      "303/303 [==============================] - 0s 947us/sample - loss: 0.3662 - acc: 0.8218\n",
      "Epoch 11/20\n",
      "303/303 [==============================] - 0s 502us/sample - loss: 0.3576 - acc: 0.8218\n",
      "Epoch 12/20\n",
      "303/303 [==============================] - 0s 624us/sample - loss: 0.3509 - acc: 0.8317\n",
      "Epoch 13/20\n",
      "303/303 [==============================] - 0s 444us/sample - loss: 0.3456 - acc: 0.8350\n",
      "Epoch 14/20\n",
      "303/303 [==============================] - 0s 397us/sample - loss: 0.3390 - acc: 0.8350\n",
      "Epoch 15/20\n",
      "303/303 [==============================] - 0s 389us/sample - loss: 0.3359 - acc: 0.8416\n",
      "Epoch 16/20\n",
      "303/303 [==============================] - 0s 455us/sample - loss: 0.3295 - acc: 0.8449\n",
      "Epoch 17/20\n",
      "303/303 [==============================] - 0s 1ms/sample - loss: 0.3254 - acc: 0.8515\n",
      "Epoch 18/20\n",
      "303/303 [==============================] - 0s 1ms/sample - loss: 0.3212 - acc: 0.8449\n",
      "Epoch 19/20\n",
      "303/303 [==============================] - 0s 466us/sample - loss: 0.3187 - acc: 0.8449\n",
      "Epoch 20/20\n",
      "303/303 [==============================] - 0s 536us/sample - loss: 0.3148 - acc: 0.8515\n"
     ]
    }
   ],
   "source": [
    "# New model\n",
    "model = KerasClassifier(build_fn=create_dense_model, verbose=1)\n",
    "\n",
    "# Create Grid Search\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1, cv=3)\n",
    "grid_result = grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.8151815136273702 using {'batch_size': 10, 'epochs': 20}\n"
     ]
    }
   ],
   "source": [
    "# Report Results\n",
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "242/242 [==============================] - 0s 2ms/sample - loss: 0.7025 - acc: 0.4917\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 357us/sample - loss: 0.6658 - acc: 0.5868\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 356us/sample - loss: 0.6320 - acc: 0.6488\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 495us/sample - loss: 0.6001 - acc: 0.6901\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 318us/sample - loss: 0.5679 - acc: 0.7190\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 495us/sample - loss: 0.5363 - acc: 0.7314\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 324us/sample - loss: 0.5075 - acc: 0.7438\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 395us/sample - loss: 0.4846 - acc: 0.7645\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 453us/sample - loss: 0.4623 - acc: 0.7851\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 297us/sample - loss: 0.4443 - acc: 0.7810\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 362us/sample - loss: 0.4230 - acc: 0.8140\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 351us/sample - loss: 0.4092 - acc: 0.8223\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 459us/sample - loss: 0.3919 - acc: 0.8306\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 365us/sample - loss: 0.3807 - acc: 0.8140\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 320us/sample - loss: 0.3683 - acc: 0.8264\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 464us/sample - loss: 0.3597 - acc: 0.8306\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 356us/sample - loss: 0.3481 - acc: 0.8430\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 358us/sample - loss: 0.3382 - acc: 0.8595\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 528us/sample - loss: 0.3289 - acc: 0.8636\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 727us/sample - loss: 0.3228 - acc: 0.8719\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a4603cef0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# New model\n",
    "model = create_dense_model()\n",
    "model.fit(X_train, y_train, batch_size=10, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61/61 [==============================] - 0s 5ms/sample - loss: 0.4848 - acc: 0.8361\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4847899015809669, 0.8360656]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate model\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Final Accuracy: 83.61%**"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nteract": {
   "version": "0.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
