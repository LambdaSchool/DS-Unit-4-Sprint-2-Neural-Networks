{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2*\n",
    "\n",
    "# Sprint Challenge - Neural Network Foundations\n",
    "\n",
    "Table of Problems\n",
    "\n",
    "1. [Defining Neural Networks](#Q1)\n",
    "2. [Perceptron on XOR Gates](#Q2)\n",
    "3. [Multilayer Perceptron](#Q3)\n",
    "4. [Keras MMP](#Q4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Q1\"></a>\n",
    "## 1. Define the following terms:\n",
    "\n",
    "- **Neuron:** A function that receives an input and pass it to the next layer of nodes through activation function\n",
    "- **Input Layer:** A layer that receives input from dataset to be passed to network\n",
    "- **Hidden Layer:** The layer in between input and output which they perform their functions, but we don't directly interact with them\n",
    "- **Output Layer:** Output a vector of values that is in a format that is suitable for the type of problem that we're trying to address through activation function\n",
    "- **Activation:** A function that transform the signal to pass onto the next layer\n",
    "- **Backpropagation:** An algorithm for how weights in a neural network are updated in reverse order at the end of each training epoch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Perceptron <a id=\"Q3=2\"></a>\n",
    "\n",
    "Create a perceptron class that can model the behavior of an AND gate. You can use the following table as your training data:\n",
    "\n",
    "|x1\t|x2|x3|\ty|\n",
    "|---|---|---|---|\n",
    "1|\t1|\t1|\t1|\n",
    "1|\t0|\t1|\t0|\n",
    "0|\t1|\t1|\t0|\n",
    "0|\t0|\t1|\t0|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 inputs \n",
      " [[1. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [0. 0. 1.]]\n",
      "1 output \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(12)\n",
    "# 3 input nodes\n",
    "X = np.array(([1,1,1], [1,0,1], [0,1,1], [0,0,1]), dtype=float)\n",
    "# 1 output node\n",
    "y = np.array(([1], [0], [0], [0]), dtype=float)\n",
    "\n",
    "print(\"3 inputs \\n\", X)\n",
    "print(\"1 output \\n\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self):\n",
    "        # Set up Architecture of Neural Network\n",
    "        self.inputs = X.shape[1]\n",
    "        self.hiddenNodes = 4\n",
    "        self.outputNodes = 1\n",
    "        \n",
    "        # Initial Weights\n",
    "        # 3x4 Matrix Array for the First Layer\n",
    "        self.weights1 = 2 * np.random.randn(self.inputs, self.hiddenNodes) - 1\n",
    "        # 4x1 Matrix Array for Hidden to Output\n",
    "        self.weights2 = 2 * np.random.rand(self.hiddenNodes, self.outputNodes) - 1\n",
    "        \n",
    "    def sigmoid(self, s):\n",
    "        return 1 / (1 + np.exp(-s))\n",
    "    \n",
    "    def sigmoidPrime(self, s):\n",
    "        return s * (1 - s)\n",
    "    \n",
    "    def feed_forward(self, X):\n",
    "        \"\"\"\n",
    "        Calculate the NN inference using feed forward.\n",
    "        aka \"predict\"\n",
    "        \"\"\"\n",
    "        \n",
    "        # Weighted sum of inputs => hidden layer\n",
    "        self.hidden_sum = np.dot(X, self.weights1)\n",
    "        \n",
    "        # Activations of weighted sum\n",
    "        self.activated_hidden = self.sigmoid(self.hidden_sum)\n",
    "        \n",
    "        # Weight sum between hidden and output\n",
    "        self.output_sum = np.dot(self.activated_hidden, self.weights2)\n",
    "        \n",
    "        # Final activation of output\n",
    "        self.activated_output = self.sigmoid(self.output_sum)\n",
    "        \n",
    "        return self.activated_output\n",
    "    def backward(self, X, y, o):\n",
    "        \"\"\"\n",
    "        Backward propagate through the network\n",
    "        \"\"\"\n",
    "        \n",
    "        # Error in output\n",
    "        self.o_error = y - o\n",
    "        \n",
    "        # Apply derivative of sigmoid to error\n",
    "        # How far off are we in relation to the Sigmoid f(x) of the output\n",
    "        # ^- hidden => output\n",
    "        self.o_delta = self.o_error * self.sigmoidPrime(o) # apply derivative of sigmoid to error\n",
    "        \n",
    "        # z2 error\n",
    "        self.z2_error = self.o_delta.dot(self.weights2.T) # how much the hidden layer weights were off\n",
    "        # How much of that \"far off\" can be explained by the inputs => hidden layer\n",
    "        self.z2_delta = self.z2_error * self.sigmoidPrime(self.activated_hidden)\n",
    "        \n",
    "        # Adjustment to first set of weights (input => hidden)\n",
    "        self.weights1 += X.T.dot(self.z2_delta)\n",
    "        \n",
    "        # Adjustment to second set of weights (hidden => output)\n",
    "        self.weights2 += self.activated_hidden.T.dot(self.o_delta)\n",
    "        \n",
    "    def train(self, X, y):\n",
    "        # Output\n",
    "        o = self.feed_forward(X)\n",
    "        self.backward(X, y, o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------EPOCH 1---------+\n",
      "Loss: \n",
      " 0.2633356696845635\n",
      "+---------EPOCH 2---------+\n",
      "Loss: \n",
      " 0.37966202034086133\n",
      "+---------EPOCH 3---------+\n",
      "Loss: \n",
      " 0.41440460359441916\n",
      "+---------EPOCH 50---------+\n",
      "Loss: \n",
      " 0.0997924972764671\n",
      "+---------EPOCH 100---------+\n",
      "Loss: \n",
      " 0.07639776303537395\n",
      "+---------EPOCH 150---------+\n",
      "Loss: \n",
      " 0.07442462837890616\n",
      "+---------EPOCH 200---------+\n",
      "Loss: \n",
      " 0.09189831084695625\n",
      "+---------EPOCH 250---------+\n",
      "Loss: \n",
      " 0.06587368742008175\n",
      "+---------EPOCH 300---------+\n",
      "Loss: \n",
      " 0.06125323181180962\n",
      "+---------EPOCH 350---------+\n",
      "Loss: \n",
      " 0.06250213686947978\n",
      "+---------EPOCH 400---------+\n",
      "Loss: \n",
      " 0.05974213583991388\n",
      "+---------EPOCH 450---------+\n",
      "Loss: \n",
      " 0.05884994054877512\n",
      "+---------EPOCH 500---------+\n",
      "Loss: \n",
      " 0.058638556021806794\n",
      "+---------EPOCH 550---------+\n",
      "Loss: \n",
      " 0.05852033650005535\n",
      "+---------EPOCH 600---------+\n",
      "Loss: \n",
      " 0.05827280779848982\n",
      "+---------EPOCH 650---------+\n",
      "Loss: \n",
      " 0.05815970647427748\n",
      "+---------EPOCH 700---------+\n",
      "Loss: \n",
      " 0.05807205364193028\n",
      "+---------EPOCH 750---------+\n",
      "Loss: \n",
      " 0.05800367477200341\n",
      "+---------EPOCH 800---------+\n",
      "Loss: \n",
      " 0.0579483913305312\n",
      "+---------EPOCH 850---------+\n",
      "Loss: \n",
      " 0.05790650739843235\n",
      "+---------EPOCH 900---------+\n",
      "Loss: \n",
      " 0.05789941502202095\n",
      "+---------EPOCH 950---------+\n",
      "Loss: \n",
      " 0.05790534419043956\n",
      "+---------EPOCH 1000---------+\n",
      "Loss: \n",
      " 0.057823265421809704\n"
     ]
    }
   ],
   "source": [
    "nn = Perceptron()\n",
    "np.random.seed(12)\n",
    "loss_lst = []\n",
    "# number of epochs / iterations\n",
    "for i in range(1000):\n",
    "    if (i+1 in [1,2,3]) or ((i+1) % 50 ==0):\n",
    "        print('+' + '---' * 3 + f'EPOCH {i+1}' + '---'*3 + '+')\n",
    "#         print('Input: \\n', X)\n",
    "#         print('Actual Output: \\n', y)\n",
    "#         print('Predicted Output: \\n', str(nn.feed_forward(X)))\n",
    "        loss = np.mean(np.square(y - nn.feed_forward(X)))\n",
    "        if loss < .01:\n",
    "            print('Input: \\n', X)\n",
    "            print('Actual Output: \\n', y)\n",
    "            print('Predicted Output: \\n', str(nn.feed_forward(X)))\n",
    "            print(\"Loss: \\n\", str(loss))\n",
    "            break\n",
    "        print(\"Loss: \\n\", str(loss))\n",
    "    loss_lst.append(loss)\n",
    "    nn.train(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0xa2a260cf60>]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(loss_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Multilayer Perceptron <a id=\"Q3\"></a>\n",
    "\n",
    "Implement a Neural Network Multilayer Perceptron class that uses backpropagation to update the network's weights.\n",
    "Your network must have one hidden layer.\n",
    "You do not have to update weights via gradient descent. You can use something like the derivative of the sigmoid function to update weights.\n",
    "Train your model on the Heart Disease dataset from UCI:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(303, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>253</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>144</td>\n",
       "      <td>1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>150</td>\n",
       "      <td>240</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>171</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>201</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>249</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>143</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "186   60    1   0       130   253    0        1      144      1      1.4   \n",
       "244   56    1   0       132   184    0        0      105      1      2.1   \n",
       "147   60    0   3       150   240    0        1      171      0      0.9   \n",
       "138   57    1   0       110   201    0        1      126      1      1.5   \n",
       "241   59    0   0       174   249    0        1      143      1      0.0   \n",
       "\n",
       "     slope  ca  thal  target  \n",
       "186      2   1     3       0  \n",
       "244      1   1     1       0  \n",
       "147      2   0     2       1  \n",
       "138      1   0     1       1  \n",
       "241      1   0     2       0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/ryanleeallred/datasets/master/heart.csv')\n",
    "df = df.sample(frac=1)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(303, 13)\n",
      "(303, 1)\n"
     ]
    }
   ],
   "source": [
    "sc = StandardScaler()\n",
    "dataset = df.values\n",
    "# split into input (X) and output (y) variables\n",
    "X = dataset[:,:-1]\n",
    "X = sc.fit_transform(X)\n",
    "y = dataset[:,-1]\n",
    "y = y.reshape(y.shape[0], 1)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self):\n",
    "        # Set up Architecture of Neural Network\n",
    "        self.inputs = X.shape[1]\n",
    "        self.hiddenNodes = 13\n",
    "        self.outputNodes = 1\n",
    "        \n",
    "        # Initial Weights\n",
    "        # 13x26 Matrix Array for the First Layer\n",
    "        self.weights1 = 2 * np.random.randn(self.inputs, self.hiddenNodes) - 1\n",
    "        # 26x1 Matrix Array for Hidden to Output\n",
    "        self.weights2 = 2 * np.random.rand(self.hiddenNodes, self.outputNodes) - 1\n",
    "        \n",
    "    def sigmoid(self, s):\n",
    "        return 1 / (1 + np.exp(-s))\n",
    "    \n",
    "    def sigmoidPrime(self, s):\n",
    "        return s * (1 - s)\n",
    "    \n",
    "    def feed_forward(self, X):\n",
    "        \"\"\"\n",
    "        Calculate the NN inference using feed forward.\n",
    "        aka \"predict\"\n",
    "        \"\"\"\n",
    "        \n",
    "        # Weighted sum of inputs => hidden layer\n",
    "        self.hidden_sum = np.dot(X, self.weights1)\n",
    "        \n",
    "        # Activations of weighted sum\n",
    "        self.activated_hidden = self.sigmoid(self.hidden_sum)\n",
    "        \n",
    "        # Weight sum between hidden and output\n",
    "        self.output_sum = np.dot(self.activated_hidden, self.weights2)\n",
    "        \n",
    "        # Final activation of output\n",
    "        self.activated_output = self.sigmoid(self.output_sum)\n",
    "        \n",
    "        return self.activated_output\n",
    "    def backward(self, X, y, o):\n",
    "        \"\"\"\n",
    "        Backward propagate through the network\n",
    "        \"\"\"\n",
    "        \n",
    "        # Error in output\n",
    "        self.o_error = y - o\n",
    "        \n",
    "        # Apply derivative of sigmoid to error\n",
    "        # How far off are we in relation to the Sigmoid f(x) of the output\n",
    "        # ^- hidden => output\n",
    "        self.o_delta = self.o_error * self.sigmoidPrime(o) # apply derivative of sigmoid to error\n",
    "        \n",
    "        # z2 error\n",
    "        self.z2_error = self.o_delta.dot(self.weights2.T) # how much the hidden layer weights were off\n",
    "        # How much of that \"far off\" can be explained by the inputs => hidden layer\n",
    "        self.z2_delta = self.z2_error * self.sigmoidPrime(self.activated_hidden)\n",
    "        \n",
    "        # Adjustment to first set of weights (input => hidden)\n",
    "        self.weights1 += X.T.dot(self.z2_delta)\n",
    "        \n",
    "        # Adjustment to second set of weights (hidden => output)\n",
    "        self.weights2 += self.activated_hidden.T.dot(self.o_delta)\n",
    "        \n",
    "    def train(self, X, y):\n",
    "        # Output\n",
    "        o = self.feed_forward(X)\n",
    "        self.backward(X, y, o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------EPOCH 1---------+\n",
      "Loss: \n",
      " 0.2978637787646219\n",
      "+---------EPOCH 2---------+\n",
      "Loss: \n",
      " 0.5405486976197587\n",
      "+---------EPOCH 3---------+\n",
      "Loss: \n",
      " 0.5287508850082298\n",
      "+---------EPOCH 4---------+\n",
      "Loss: \n",
      " 0.4962166761337012\n",
      "+---------EPOCH 5---------+\n",
      "Loss: \n",
      " 0.4450027480995814\n",
      "+---------EPOCH 50---------+\n",
      "Loss: \n",
      " 0.08933022163068424\n",
      "+---------EPOCH 100---------+\n",
      "Loss: \n",
      " 0.08919254714574228\n",
      "+---------EPOCH 150---------+\n",
      "Loss: \n",
      " 0.08589660132360263\n",
      "+---------EPOCH 200---------+\n",
      "Loss: \n",
      " 0.06294560232083063\n",
      "+---------EPOCH 250---------+\n",
      "Loss: \n",
      " 0.05963039822035064\n",
      "+---------EPOCH 300---------+\n",
      "Loss: \n",
      " 0.05953714306383379\n",
      "+---------EPOCH 350---------+\n",
      "Loss: \n",
      " 0.05950389650207643\n",
      "+---------EPOCH 400---------+\n",
      "Loss: \n",
      " 0.059484709633549286\n",
      "+---------EPOCH 450---------+\n",
      "Loss: \n",
      " 0.05947208235514174\n",
      "+---------EPOCH 500---------+\n",
      "Loss: \n",
      " 0.059463135403712876\n",
      "+---------EPOCH 550---------+\n",
      "Loss: \n",
      " 0.059456444547792524\n",
      "+---------EPOCH 600---------+\n",
      "Loss: \n",
      " 0.059451233896399946\n",
      "+---------EPOCH 650---------+\n",
      "Loss: \n",
      " 0.059447048765361374\n",
      "+---------EPOCH 700---------+\n",
      "Loss: \n",
      " 0.05944360542410568\n",
      "+---------EPOCH 750---------+\n",
      "Loss: \n",
      " 0.059440717319944575\n",
      "+---------EPOCH 800---------+\n",
      "Loss: \n",
      " 0.059438256434383364\n",
      "+---------EPOCH 850---------+\n",
      "Loss: \n",
      " 0.05943613177794947\n",
      "+---------EPOCH 900---------+\n",
      "Loss: \n",
      " 0.059434276766241564\n",
      "+---------EPOCH 950---------+\n",
      "Loss: \n",
      " 0.05943264146147903\n",
      "+---------EPOCH 1000---------+\n",
      "Loss: \n",
      " 0.05943118761356575\n"
     ]
    }
   ],
   "source": [
    "nn = NeuralNetwork()\n",
    "# number of epochs / iterations\n",
    "loss_lst = []\n",
    "for i in range(1000):\n",
    "    if (i+1 in [1,2,3,4,5]) or ((i+1) % 50 ==0):\n",
    "        print('+' + '---' * 3 + f'EPOCH {i+1}' + '---'*3 + '+')\n",
    "        loss = np.mean(np.square(y - nn.feed_forward(X)))\n",
    "#         if loss < .1:\n",
    "#             print('Input: \\n', X)\n",
    "#             print('First 5 Actual Output: \\n', y[:5])\n",
    "#             print('First 5 Predicted Output: \\n', str(nn.feed_forward(X)[:5]))\n",
    "#             print(\"Total Loss: \\n\", str(loss))\n",
    "#             break\n",
    "        print(\"Loss: \\n\", str(loss))\n",
    "    loss_lst.append(loss)\n",
    "    nn.train(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0xa2a255ee48>]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAVyUlEQVR4nO3dfYwcd33H8c939+5sHDsPji808kNsUhNkCiXhYsKDIKAQHJBs2oJqykN4qluEBRXQYgRNUSKkNqhAq7qA06ZJEMWEQNVr5DRNUEhLA4kvwXlwXCcX48QXh/gcO4kf725vv/1jZ53Zvbm7vdu9m/nNvl+S5Z3Z2dnv/jzz8W9/M7Nj7i4AQPgKaRcAAGgNAh0AcoJAB4CcINABICcIdADIiY603njRokW+fPnytN4eAIJ0//33H3T37qTnUgv05cuXq6+vL623B4AgmdmT4z3HkAsA5ASBDgA5QaADQE4Q6ACQEwQ6AOQEgQ4AOUGgA0BOBBfoh44N67aHn0m7DADInOAC/U++16dPff8BHThyMu1SACBTggv0gcMnJEkjo9yYAwDiggt0S7sAAMio4AK9ilvnAUCt4ALdrNJHJ88BoFZwgQ4ASEagA0BOBBfo0YgLQy4AUCfYQAcA1Aou0KtcdNEBIC64QDdxlgsAJAkv0BlyAYBEwQV6FR10AKgVXKBXO+hcKQoAtRoKdDNbY2a7zazfzDYlPP9RMxs0sx3Rn0+2vtRT7zVTqwaAoHVMtoCZFSVtlvROSQOStptZr7s/WrfoD9194wzUmIj+OQDUaqSHvlpSv7vvcfdhSVslrZvZssb30pBLWhUAQDY1EuiLJe2LTQ9E8+r9gZk9ZGa3mNnSpBWZ2QYz6zOzvsHBwWmUK34/FwDG0UigJ0Voff/4PyQtd/fXSrpT0o1JK3L3Le7e4+493d3dU6t00hIAoL01EugDkuI97iWS9scXcPfn3H0omrxO0utbU95YDLkAQLJGAn27pJVmtsLMuiStl9QbX8DMzo1NrpW0q3Ul1uIsFwBINulZLu5eMrONkm6XVJR0vbvvNLOrJfW5e6+kz5jZWkklSYckfXQGa67UNdNvAACBmTTQJcndt0naVjfvqtjjL0n6UmtLS8aQCwAkC+9KUUZcACBRcIFexc/nAkCt4ALdOBEdABIFF+gAgGTBBjoHRQGgVnCBzk2iASBZcIEOAEgWbKBzlgsA1Aou0KuX/jPkAgC1wgv0tAsAgIwKLtABAMmCC3TOcgGAZMEGOgCgVnCBXsVZLgBQK7hAr/6WC0MuAFArvECPhlz6njycbiEAkDHBBfqyhfMkST95YCDlSgAgW4IL9N9dcqYkqaPA0VEAiAsu0AEAyQh0AMgJAh0AciLYQOesRQCoFWygAwBqEegAkBMEOgDkRLCBzqX/AFAr2EAHANQKLtD5lUWkqVx2lUbLaZcBJAou0Kv4XXSkYe3mn+uCv/xPDR4ZSrsUYIxgAx1IwyNPv6jRsuu5YwQ6sifYQOegKADUaijQzWyNme02s34z2zTBcu8zMzezntaVCABoxKSBbmZFSZslXSFplaQPmNmqhOUWSPqMpHtbXWSr3PHos3rqueNplwEAM6KRHvpqSf3uvsfdhyVtlbQuYblrJF0r6WQL62upP76pT5d98+60y0AOMOSHLGok0BdL2hebHojmnWJmF0pa6u63trC2GTFc4pQzAPnUSKAnnSB4qn9iZgVJ35T0+UlXZLbBzPrMrG9wcLDxKhMLoIsEAHGNBPqApKWx6SWS9semF0j6HUk/M7O9ki6R1Jt0YNTdt7h7j7v3dHd3T79qAMAYjQT6dkkrzWyFmXVJWi+pt/qku7/g7ovcfbm7L5f0S0lr3b1vRioGMoAxdGTRpIHu7iVJGyXdLmmXpJvdfaeZXW1ma2e6QABAYzoaWcjdt0naVjfvqnGWvbT5sgAAU8WVogCQE8EGOpAmzrJCFhHoAJATBDoA5ASBDgA5EWygc1AUaWL7QxYFG+gAgFoEOgDkBIEOADkRbKAzhAkAtYINdABALQIdAHIiuEDndDEASBZcoFcl3UYJANpZsIFORx1p4psisijYQAcA1CLQASAnCHQAyAkCHZgGbnCBLAo20J2jUgBQI9hABwDUItABICcIdGAaGPFDFhHoAJATBDoA5ASBDgA5QaADQE4Q6MA0cEwUWUSgA0BOBBvonDYGALWCDXQAQC0CHZgGfksIWdRQoJvZGjPbbWb9ZrYp4fk/NbOHzWyHmf3czFa1vlQAwEQmDXQzK0raLOkKSaskfSAhsP/V3V/j7q+TdK2kb7S8UgDAhBrpoa+W1O/ue9x9WNJWSeviC7j7i7HJ0zQLZ3Xxe9QAUKujgWUWS9oXmx6Q9Ib6hczs05I+J6lL0juSVmRmGyRtkKRly5ZNtVYgM+hOIIsa6aFbwrwx27O7b3b38yV9UdJXklbk7lvcvcfde7q7u6dWKQBgQo0E+oCkpbHpJZL2T7D8VknvbaaoiXz8LSv0hhUL9bLO4ky9BQAEqZFA3y5ppZmtMLMuSesl9cYXMLOVscn3SHq8dSXW6iwWNLfJMD94dKhF1QBAdkw6hu7uJTPbKOl2SUVJ17v7TjO7WlKfu/dK2mhml0kakXRY0pUzWXSzfn3wmBbNn5N2GQDQUo0cFJW7b5O0rW7eVbHHn21xXROypFF9YBZxXRGyqC2vFGVnBJBHbRnoAJBHwQZ6M51sfocDQB4FGegMoSN9dAqQPUEGOgBgrLYMdPpWAPKoLQMdAPIo2EBv5rgmx0TRLLYhZFGQgW5cWQQAYwQZ6ACAsdoy0Lk5BoA8astAB5pFlwBZFGygN9XLZm8EkENBBjqHRAFgrCADvVl00AHkUVsGOgDkEYEOTAMXFiGLgg10rhQFgFpBBjoXigLAWEEGerO4sAhAHrVloAPN4q5XyKJgA539CQBqBRvozeA/AwB5FGigc1QUAOoFGujNoYOOZrENIYvaMtABII+CDXR6SABQK9hAbwannAHIoyADnStFAWCsIAO9WfTP0Sy+5CGL2jLQASCPgg10xsEBoFZDgW5ma8xst5n1m9mmhOc/Z2aPmtlDZvZTMzuv9aW2EP8XAMihSQPdzIqSNku6QtIqSR8ws1V1i/1KUo+7v1bSLZKubXWhNTXN5MqBBvCLnciiRnroqyX1u/sedx+WtFXSuvgC7n6Xux+PJn8paUlry2wtdkYAedRIoC+WtC82PRDNG88nJN2W9ISZbTCzPjPrGxwcbLxKAMCkGgn0pBGOxC6umX1IUo+kryc97+5b3L3H3Xu6u7sbr7LFOJ4KII86GlhmQNLS2PQSSfvrFzKzyyR9WdLb3H2oNeUl48IipI5OATKokR76dkkrzWyFmXVJWi+pN76AmV0o6buS1rr7gdaXCQCYzKSB7u4lSRsl3S5pl6Sb3X2nmV1tZmujxb4uab6kH5nZDjPrHWd1mcCQC6aDax+QdY0Mucjdt0naVjfvqtjjy1pcFwBgigK+UrSJ17auDLQptiFkUZCBblxahBQw4oKsCzLQAQBjtWWgc3ALQB4FG+hcvg8AtYIN9GbwXwGmI77d8CUPWRRkoHOlKACMFWSgAwDGastA5+sygDwKNtAJZcy2+NlRHJRHFgUb6M1hZwSQP0EGOgdFAWCsIAO9WQzXAMijtgx0YDo4Dx1ZF2ygsz8BQK1gA70Z/GcAII+CDHR+PhcAxgoy0JvF+CemI77dsAkhi9oy0AEgj4INdH7THABqBRvozeCybUwH2w2yLsxA55goAIwRZqA3idEaNIshP2RRWwY6AORRsIFO/wizjU45si7IQG92CJ39EkAeBRnozRo8MpR2CQgcnQJkUVsG+jW3Ppp2CQDQcm0V6F3Ftvq4ANpMuAnX5Hfe0mi5NXUAQEYEGeg2zXvQuVyF6KWHj4+0sCK0HQbRkUFBBnozzpzXJUm6+Gt36qu9O9V/4KiOnBzRaJk9FEDYOhpZyMzWSPo7SUVJ/+Tuf133/FslfUvSayWtd/dbWl1oq/z+hYtlJl33P7/WDffs1Q337JVUufF0Z7GgrmJBHUVTR6GgrqKpWDSZTAWrfDMwkwpW+UX2QjRt1emCxl3WLOF33BO+aCR990j6QlK/rsRlGnjdeMuNXSbhdYnLNbLM9NaVtFTyZ2ykrgbXFZvHf/rIukkD3cyKkjZLeqekAUnbzazX3eOnijwl6aOSvjATRSaZ7q7V1VHQX6x5lb645lV64Knn1X/gqI4Pl/TCiRENl8oaGXWVymWNjFYel93lXrnUu+yqTCuaLleGccqu2DKV58vRtFdfU1dw0g89JV244knzfWwL1K9vvHWNfc+EOhqsK2FlDb5n/TINtkUDdTR6SX7yuiZvQyDLGumhr5bU7+57JMnMtkpaJ+lUoLv73ui5YI40dhQLWr1ioVavWJh2KQjIjn3P672b/1c/uO8pvf1V56RdDlCjkTH0xZL2xaYHonlTZmYbzKzPzPoGBwens4rKeqb9SqA5yxbOkyT1PXk45UqAsRoJ9KT8nNaXUXff4u497t7T3d09nVUAqVp4Wpc++IZldCqQSY0E+oCkpbHpJZL2z0w5QPZ1FEyj7rpr9wHd+eizaZcDnNJIoG+XtNLMVphZl6T1knpntqzJHR0q6Z4nDvK71Jh1hYLp+PCoPvYv2/XJm/r04kmuaUA2TBro7l6StFHS7ZJ2SbrZ3Xea2dVmtlaSzOxiMxuQ9H5J3zWznTNZ9NnzuzR4ZEh/dN29euzZozP5VsAYRTMNl146/h9/DKSpoQuL3H2bu7/S3c93969F865y997o8XZ3X+Lup7n72e7+6pks+ivvWaV//OBFkqRP3Lh9Jt8KGKNYqB1BL3N+OjIiyCtFiwXT5ateroJJL57g6y5mV6Eu0EcZ9kNGBBnoUuU88o+8cXnaZaANFesuKeUKUmRFsIEuVS6rZ1/CbKvvoZcZQkdGBB3oHUWjd4RZN7ezdrcpM+SCjAg60AtGoGP2rb94Wc00Y+jIiqADvVhgZ8LsW3halx686nJ96tLzJXGWC7Ij7ECnh46UnDGvU69ZfIYkOhXIjqADvXpwih4S0lCIznbZcveelCsBKoIO9OrpY/ftPZRyJWhHFy07U5L0k189rR/fPzCl+9TueuZF3frQfo1wb1u0UEN3LMqq1yypfOX91p2P6fOXX3DqTkEFq9w1qBC/a5CJUxzRUuecPld/2LNUP+zbp8//6EEdHSrpyjctn/A1/QeOasNNfdpz8Jgk6YaPXaxLL+B31dEaQQf6pReco7e9slt3Pzao93/nFw29Zm5ncYarQjv50CXn6dDxYd3x6LP6q96duuGevfqt0+fq7PldmttZVGfR1FksqKNQ0JzOgr79syckSfPndOjoUEl3PzaokyOjUSfEVCxUOh/FgqloJovmFQtSsVCI5unUstVOTPVxtfNSLFRunTjpLQEnuTXfZK9v5HaCk97+r35yiu85nVsOxp/vKJiODpXkXjkecmJ4VHM6CioUTEOlsopm6iiaSqOuUXfN6Sio7K6hkbJe1lWUu3RyZFRzOgsqmOnkyKg6iwUVC6aR0bLcK3dKK5ddJ0fKOjEyqsVnvUzz57Q+fi2tXyvs6enxvr6+ptfz3NEh/d9vjpy61Vv1dm/l+C3joseS9JaVi3T63M6m3xeIu+eJg7r1oWd0+NiwBo8MafDokEZKZY2UXaXodoZHh0qSpA9fcp7+fM0F6rnmTg0z5NKWrln3an14mle6m9n97t6T9FzQPXRJOnv+HL35t+ekXQba3JvOX6Q3nb9owmWqHYvqj3v9fNPbdejYsMrllzojo+WXOiLlcqVHWC5LpXI5mvfSstXlRssvdWKqj0cbuI/t2OfHFDzh88n3fZ3aa6Z6T9jp3I92ohpcrhdPlPT88WE9/fwJFcz0mxdOam5nQeecPld7Dx5TsWA67+x5evK54yqVXcsWztPgkSEdGy7p5QvmqlQu67mjw1owt0NnzOvSvkPH1Vk0LVs4T3sGj8klvWLRaRo4fEInS6N63dIzZ2yYLfhAB0JhZirGvuqfs2CuzlkwN72CkDtBn+UCAHgJgQ4AOUGgA0BOEOgAkBMEOgDkBIEOADlBoANAThDoAJATqV36b2aDkp6c5ssXSTrYwnLyiDaaGO0zOdpoYmm1z3nu3p30RGqB3gwz6xvvtwxQQRtNjPaZHG00sSy2D0MuAJATBDoA5ESogb4l7QICQBtNjPaZHG00scy1T5Bj6ACAsULtoQMA6hDoAJATwQW6ma0xs91m1m9mm9KuZzaZ2V4ze9jMdphZXzRvoZndYWaPR3+fFc03M/v7qJ0eMrOLYuu5Mlr+cTO7Mq3P0wpmdr2ZHTCzR2LzWtYmZvb6qM37o9cm3cIys8Zpn6+a2dPRdrTDzN4de+5L0WfdbWbvis1P3O/MbIWZ3Ru12w/NrGv2Pl3zzGypmd1lZrvMbKeZfTaaH+Y25NE9N0P4I6ko6QlJr5DUJelBSavSrmsWP/9eSYvq5l0raVP0eJOkv4kev1vSbarcQ/cSSfdG8xdK2hP9fVb0+Ky0P1sTbfJWSRdJemQm2kTSfZLeGL3mNklXpP2ZW9A+X5X0hYRlV0X71BxJK6J9rTjRfifpZknro8ffkfSptD/zFNvnXEkXRY8XSHosaocgt6HQeuirJfW7+x53H5a0VdK6lGtK2zpJN0aPb5T03tj8m7zil5LONLNzJb1L0h3ufsjdD0u6Q9Ka2S66Vdz9vyUdqpvdkjaJnjvd3X/hlT3zpti6gjBO+4xnnaSt7j7k7r+W1K/KPpe430U9zXdIuiV6fbytg+Duz7j7A9HjI5J2SVqsQLeh0AJ9saR9semBaF67cEn/ZWb3m9mGaN7L3f0ZqbJxSqrefXa8tmqHNmxVmyyOHtfPz4ON0ZDB9dXhBE29fc6W9Ly7l+rmB8nMlku6UNK9CnQbCi3Qk8ae2um8yze7+0WSrpD0aTN76wTLjtdW7dyGU22TvLbVtyWdL+l1kp6R9LfR/LZtHzObL+nHkv7M3V+caNGEeZlpo9ACfUDS0tj0Ekn7U6pl1rn7/ujvA5L+TZWvws9GX+sU/X0gWny8tmqHNmxVmwxEj+vnB83dn3X3UXcvS7pOle1Imnr7HFRlyKGjbn5QzKxTlTD/vrv/JJod5DYUWqBvl7QyOrLeJWm9pN6Ua5oVZnaamS2oPpZ0uaRHVPn81SPqV0r69+hxr6SPREflL5H0QvTV8XZJl5vZWdFX7cujeXnSkjaJnjtiZpdE48Ufia0rWNWgivyeKtuRVGmf9WY2x8xWSFqpygG9xP0uGhO+S9L7otfH2zoI0b/rP0va5e7fiD0V5jaU9lHmqf5R5SjzY6ocdf9y2vXM4ud+hSpnFzwoaWf1s6syjvlTSY9Hfy+M5pukzVE7PSypJ7auj6tywKtf0sfS/mxNtssPVBk2GFGlN/SJVraJpB5VAu8JSf+g6OrqUP6M0z7fiz7/Q6oE1Lmx5b8cfdbdip2NMd5+F22X90Xt9iNJc9L+zFNsn7eoMgTykKQd0Z93h7oNcek/AOREaEMuAIBxEOgAkBMEOgDkBIEOADlBoANAThDoAJATBDoA5MT/AyoKzY8fsAhbAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(loss_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Keras MMP <a id=\"Q4\"></a>\n",
    "\n",
    "Implement a Multilayer Perceptron architecture of your choosing using the Keras library. Train your model and report its baseline accuracy. Then hyperparameter tune at least two parameters and report your model's accuracy.\n",
    "Use the Heart Disease Dataset (binary classification)\n",
    "Use an appropriate loss function for a binary classification task\n",
    "Use an appropriate activation function on the final layer of your network.\n",
    "Train your model using verbose output for ease of grading.\n",
    "Use GridSearchCV to hyperparameter tune your model. (for at least two hyperparameters)\n",
    "When hyperparameter tuning, show you work by adding code cells for each new experiment.\n",
    "Report the accuracy for each combination of hyperparameters as you test them so that we can easily see which resulted in the highest accuracy.\n",
    "You must hyperparameter tune at least 5 parameters in order to get a 3 on this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(303, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112</td>\n",
       "      <td>160</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>179</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>269</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>121</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>129</td>\n",
       "      <td>196</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>102</td>\n",
       "      <td>318</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "94    45    0   1       112   160    0        1      138      0      0.0   \n",
       "102   63    0   1       140   195    0        1      179      0      0.0   \n",
       "129   74    0   1       120   269    0        0      121      1      0.2   \n",
       "104   50    1   2       129   196    0        1      163      0      0.0   \n",
       "82    60    0   2       102   318    0        1      160      0      0.0   \n",
       "\n",
       "     slope  ca  thal  target  \n",
       "94       1   0     2       1  \n",
       "102      2   2     2       1  \n",
       "129      2   1     2       1  \n",
       "104      2   0     2       1  \n",
       "82       2   1     2       1  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/ryanleeallred/datasets/master/heart.csv')\n",
    "df = df.sample(frac=1)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(303, 13)\n",
      "(303,)\n"
     ]
    }
   ],
   "source": [
    "sc = StandardScaler()\n",
    "df = sc.fit_transform(df)\n",
    "# split into input (X) and output (y) variables\n",
    "X = df[:,:-1]\n",
    "y = df[:,-1]\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    # Input layer\n",
    "    model.add(Dense(num_neurons, input_dim=(X.shape[1]), activation='relu', kernel_initializer=init_mode))\n",
    "#     model.add(Dropout(0.05))\n",
    "    # Hidden Layers\n",
    "    model.add(Dense(num_neurons, activation='sigmoid', kernel_initializer=init_mode))\n",
    "#     model.add(Dropout(0.05))\n",
    "    model.add(Dense(num_neurons, activation='relu', kernel_initializer=init_mode))\n",
    "#     model.add(Dropout(0.05))\n",
    "    # Output Layer\n",
    "    model.add(Dense(1, activation='sigmoid', kernel_initializer=init_mode)) # sigmoid for binary output\n",
    "    # Compile model\n",
    "    adam = Adam(lr=learning_rate)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 272 samples, validate on 31 samples\n",
      "Epoch 1/10\n",
      "272/272 [==============================] - 4s 14ms/sample - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6919 - val_acc: 0.6452\n",
      "Epoch 2/10\n",
      "272/272 [==============================] - 0s 497us/sample - loss: 0.6926 - acc: 0.5331 - val_loss: 0.6892 - val_acc: 0.6452\n",
      "Epoch 3/10\n",
      "272/272 [==============================] - 0s 438us/sample - loss: 0.6916 - acc: 0.5331 - val_loss: 0.6865 - val_acc: 0.6452\n",
      "Epoch 4/10\n",
      "272/272 [==============================] - 0s 456us/sample - loss: 0.6899 - acc: 0.5331 - val_loss: 0.6819 - val_acc: 0.6452\n",
      "Epoch 5/10\n",
      "272/272 [==============================] - 0s 557us/sample - loss: 0.6851 - acc: 0.5331 - val_loss: 0.6691 - val_acc: 0.6452\n",
      "Epoch 6/10\n",
      "272/272 [==============================] - 0s 510us/sample - loss: 0.6715 - acc: 0.5331 - val_loss: 0.6442 - val_acc: 0.6452\n",
      "Epoch 7/10\n",
      "272/272 [==============================] - 0s 453us/sample - loss: 0.6409 - acc: 0.5625 - val_loss: 0.5952 - val_acc: 0.7097\n",
      "Epoch 8/10\n",
      "272/272 [==============================] - 0s 530us/sample - loss: 0.5944 - acc: 0.7279 - val_loss: 0.5415 - val_acc: 0.8065\n",
      "Epoch 9/10\n",
      "272/272 [==============================] - 0s 453us/sample - loss: 0.5504 - acc: 0.7941 - val_loss: 0.5071 - val_acc: 0.8387\n",
      "Epoch 10/10\n",
      "272/272 [==============================] - 0s 515us/sample - loss: 0.5170 - acc: 0.8162 - val_loss: 0.4891 - val_acc: 0.8710\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x37096f1eb8>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hyperparameters 83.9%\n",
    "num_neurons = 13\n",
    "epochs = 10\n",
    "batch_size = 13\n",
    "init_mode = 'normal'\n",
    "learning_rate = .5\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=epochs, batch_size=batch_size, verbose=1)\n",
    "model.fit(X, y, validation_split=.1)\n",
    "# validation_split - reserve some data from dataset\n",
    "# verbose shows the print statements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearchCV to hyperparameter tune your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\George\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.8085808555285136 using {'batch_size': 10, 'epochs': 20}\n",
      "\n",
      "Means: 0.7095709641774496, Stdev: 0.1289242458579567 with: {'batch_size': 10, 'epochs': 10}\n",
      "Means: 0.8085808555285136, Stdev: 0.03820407080172275 with: {'batch_size': 10, 'epochs': 20}\n",
      "Means: 0.5445544719696045, Stdev: 0.021388576788767738 with: {'batch_size': 30, 'epochs': 10}\n",
      "Means: 0.5445544719696045, Stdev: 0.021388576788767738 with: {'batch_size': 30, 'epochs': 20}\n",
      "Means: 0.5445544719696045, Stdev: 0.021388576788767738 with: {'batch_size': 50, 'epochs': 10}\n",
      "Means: 0.5445544719696045, Stdev: 0.021388576788767738 with: {'batch_size': 50, 'epochs': 20}\n",
      "Means: 0.495049516359965, Stdev: 0.04917382333385347 with: {'batch_size': 100, 'epochs': 10}\n",
      "Means: 0.5445544719696045, Stdev: 0.021388576788767738 with: {'batch_size': 100, 'epochs': 20}\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "num_neurons = 13\n",
    "init_mode = 'normal'\n",
    "learning_rate = .5\n",
    "# Grid Search parameters\n",
    "param_grid = {'batch_size': [10, 30, 50, 100],\n",
    "              'epochs': [10, 20]}\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "# Create Grid Search\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1)\n",
    "grid_result = grid.fit(X, y)\n",
    "\n",
    "# Report Results\n",
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\\n\")\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.8349835077921549 using {'batch_size': 10, 'epochs': 10}\n",
      "\n",
      "Means: 0.8349835077921549, Stdev: 0.07335350495647412 with: {'batch_size': 10, 'epochs': 10}\n",
      "Means: 0.8118811845779419, Stdev: 0.04917379533104063 with: {'batch_size': 10, 'epochs': 20}\n",
      "Means: 0.5445544719696045, Stdev: 0.021388576788767738 with: {'batch_size': 30, 'epochs': 10}\n",
      "Means: 0.8151815136273702, Stdev: 0.05502748195212182 with: {'batch_size': 30, 'epochs': 20}\n",
      "Means: 0.5445544719696045, Stdev: 0.021388576788767738 with: {'batch_size': 50, 'epochs': 10}\n",
      "Means: 0.5445544719696045, Stdev: 0.021388576788767738 with: {'batch_size': 50, 'epochs': 20}\n",
      "Means: 0.5445544719696045, Stdev: 0.021388576788767738 with: {'batch_size': 100, 'epochs': 10}\n",
      "Means: 0.5445544719696045, Stdev: 0.021388576788767738 with: {'batch_size': 100, 'epochs': 20}\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "num_neurons = 26\n",
    "init_mode = 'normal'\n",
    "learning_rate = .5\n",
    "# Grid Search parameters\n",
    "param_grid = {'batch_size': [10, 30, 50, 100],\n",
    "              'epochs': [10, 20]}\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "# Create Grid Search\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1)\n",
    "grid_result = grid.fit(X, y)\n",
    "\n",
    "# Report Results\n",
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\\n\")\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.8250825007756551 using {'batch_size': 10, 'epochs': 20}\n",
      "\n",
      "Means: 0.7788779139518738, Stdev: 0.08719369697853102 with: {'batch_size': 10, 'epochs': 10}\n",
      "Means: 0.8250825007756551, Stdev: 0.032671590713967885 with: {'batch_size': 10, 'epochs': 20}\n",
      "Means: 0.5445544719696045, Stdev: 0.021388576788767738 with: {'batch_size': 30, 'epochs': 10}\n",
      "Means: 0.5445544719696045, Stdev: 0.021388576788767738 with: {'batch_size': 30, 'epochs': 20}\n",
      "Means: 0.5445544719696045, Stdev: 0.021388576788767738 with: {'batch_size': 50, 'epochs': 10}\n",
      "Means: 0.5445544719696045, Stdev: 0.021388576788767738 with: {'batch_size': 50, 'epochs': 20}\n",
      "Means: 0.5445544719696045, Stdev: 0.021388576788767738 with: {'batch_size': 100, 'epochs': 10}\n",
      "Means: 0.5445544719696045, Stdev: 0.021388576788767738 with: {'batch_size': 100, 'epochs': 20}\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "num_neurons = 13\n",
    "init_mode = 'uniform'\n",
    "learning_rate = .5\n",
    "# Grid Search parameters\n",
    "param_grid = {'batch_size': [10, 30, 50, 100],\n",
    "              'epochs': [10, 20]}\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "# Create Grid Search\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1)\n",
    "grid_result = grid.fit(X, y)\n",
    "\n",
    "# Report Results\n",
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\\n\")\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.8250825007756551 using {'batch_size': 10, 'epochs': 20}\n",
      "\n",
      "Means: 0.6336633761723837, Stdev: 0.120721715539791 with: {'batch_size': 10, 'epochs': 10}\n",
      "Means: 0.8250825007756551, Stdev: 0.033656884448624094 with: {'batch_size': 10, 'epochs': 20}\n",
      "Means: 0.5445544719696045, Stdev: 0.021388576788767738 with: {'batch_size': 30, 'epochs': 10}\n",
      "Means: 0.7524752418200175, Stdev: 0.0889253680317193 with: {'batch_size': 30, 'epochs': 20}\n",
      "Means: 0.5445544719696045, Stdev: 0.021388576788767738 with: {'batch_size': 50, 'epochs': 10}\n",
      "Means: 0.5445544719696045, Stdev: 0.021388576788767738 with: {'batch_size': 50, 'epochs': 20}\n",
      "Means: 0.5445544719696045, Stdev: 0.021388576788767738 with: {'batch_size': 100, 'epochs': 10}\n",
      "Means: 0.5445544719696045, Stdev: 0.021388576788767738 with: {'batch_size': 100, 'epochs': 20}\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "num_neurons = 13\n",
    "init_mode = 'normal'\n",
    "learning_rate = .1\n",
    "# Grid Search parameters\n",
    "param_grid = {'batch_size': [10, 30, 50, 100],\n",
    "              'epochs': [10, 20]}\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "# Create Grid Search\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1)\n",
    "grid_result = grid.fit(X, y)\n",
    "\n",
    "# Report Results\n",
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\\n\")\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nteract": {
   "version": "0.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
