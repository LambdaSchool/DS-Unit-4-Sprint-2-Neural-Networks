{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "U4-S2-NNF-DS10",
      "language": "python",
      "name": "u4-s2-nnf-ds10"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "LS_DS_Unit_4_Sprint_Challenge_2_ALEX_KAISER.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lord-Kanzler/DS-Unit-4-Sprint-2-Neural-Networks/blob/master/LS_DS_Unit_4_Sprint_Challenge_2_ALEX_KAISER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9O7XSvM2u68",
        "colab_type": "text"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "## *Data Science Unit 4 Sprint 2*\n",
        "\n",
        "# Sprint Challenge - Neural Network Foundations\n",
        "\n",
        "Table of Problems\n",
        "\n",
        "1. [Defining Neural Networks](#Q1)\n",
        "2. [Simple Perceptron](#Q2)\n",
        "    - Perceptron\n",
        "    - Multilayer Perceptron\n",
        "    - Analyze and Compare\n",
        "4. [Keras MMP](#Q3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIhPfAyz2u68",
        "colab_type": "text"
      },
      "source": [
        "<a id=\"Q1\"></a>\n",
        "## 1. Defining Neural Networks \n",
        "\n",
        "Write *your own* definitions for the following terms:\n",
        "\n",
        "- **Neuron:** Node - similar to a biological neuron - Most basic unit in a Neural Network.\n",
        "- **Input Layer:** The first layer on a Neural Network.\n",
        "- **Hidden Layer:** Layer(s) between Input/output layer - not directly interacted with.\n",
        "- **Output Layer:**  Layer returning model results\n",
        "- **Activation Function:**  A function that decides how much a neuron contributes to the network based on its weighted sum. Examples: Sigmoid, Elu, RElu, Softmax, Tanh, Swish"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VE8mnwTJ2u69",
        "colab_type": "text"
      },
      "source": [
        "Explain how back propagation works as if you were explaining it to a five year-old. Use your own words, but feel free to reference external materials for this question. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gzm_ijqT31RH",
        "colab_type": "text"
      },
      "source": [
        "**When a neural network learns, it calculates an error based on the weighted sums and the activation function. This error of course factors in the results output, but that would not really be learning, since without backpropagation there would not be any updates to the previously determined inputs, and the results wouldn't change with repetition. Now with backpropagation, the error is fed back in order to make adjustements to the weights for every cycle (epoch), which results in a slight refinement of the results in the output layer. As this is repeated many times, the network eventually settles on a best result, and this iterative process of small optimizations is what we call backward propagation of errors used in gradient descent. This a basic form of learning, you use previous outcomes to update future actions.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVxHFoVS2u7A",
        "colab_type": "text"
      },
      "source": [
        "Remember our Simple Perceptron Class from Monday. In a simple prediction describe the process of making a prediction. How do you go from inputs to predicted output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjUMCHkx6nJQ",
        "colab_type": "text"
      },
      "source": [
        "**I kind of described it above already, but here's the calcuation proicess in a bit more detail. An input is received by the network, and multiplied by a weight. A bias of 1 is introduced as another input to offset a case where all other inputs would be zero (input stimulus). A neuron will continue to fire if it fits a given activation function (eg Sigmoid). These steps then lead to an output. Without backpropagation this will form the prediction, however, with backpropagation, the determined error is fed back to adjust the weights, with every epoch. This enables the neural network to further refine it's predictions with every cycle until it convergest at a \"best\" value** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLYJv_ym2u7C",
        "colab_type": "text"
      },
      "source": [
        "<a id=\"Q2\"></a>\n",
        "## 2. Simple Perceptron\n",
        "\n",
        "In this question, you will build two neural networks using Tensorflow Keras. After you build these two models, compare the results of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMss8Bi02u7C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Our Dataset\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "\n",
        "xx, yy = np.meshgrid(np.linspace(-3, 3, 50),\n",
        "                     np.linspace(-3, 3, 50))\n",
        "rng = np.random.RandomState(0)\n",
        "\n",
        "\"Use this X & y in the following 2 models\"\n",
        "X = rng.randn(300, 2)\n",
        "y = np.array(np.logical_xor(X[:, 0] > 0, X[:, 1] > 0), \n",
        "             dtype=int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ff1U5sWO2u7E",
        "colab_type": "text"
      },
      "source": [
        "### Simple Perceptron\n",
        "Construct a simple perceptron using Keras. You model should have 1 dense layer with a single neuron and a sigmoid activation function. Your model should be called `model1` and make sure to save the results of your fit statement to a variable called `h1`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWz_Sl2E-Zfn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8717cec8-102b-4072-e93e-4ac54771bfcc"
      },
      "source": [
        "X.shape, y.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((300, 2), (300,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_9AI7rq_w4v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dd267f14-3e97-4895-a221-5312989974b6"
      },
      "source": [
        "X"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.76405235,  0.40015721],\n",
              "       [ 0.97873798,  2.2408932 ],\n",
              "       [ 1.86755799, -0.97727788],\n",
              "       [ 0.95008842, -0.15135721],\n",
              "       [-0.10321885,  0.4105985 ],\n",
              "       [ 0.14404357,  1.45427351],\n",
              "       [ 0.76103773,  0.12167502],\n",
              "       [ 0.44386323,  0.33367433],\n",
              "       [ 1.49407907, -0.20515826],\n",
              "       [ 0.3130677 , -0.85409574],\n",
              "       [-2.55298982,  0.6536186 ],\n",
              "       [ 0.8644362 , -0.74216502],\n",
              "       [ 2.26975462, -1.45436567],\n",
              "       [ 0.04575852, -0.18718385],\n",
              "       [ 1.53277921,  1.46935877],\n",
              "       [ 0.15494743,  0.37816252],\n",
              "       [-0.88778575, -1.98079647],\n",
              "       [-0.34791215,  0.15634897],\n",
              "       [ 1.23029068,  1.20237985],\n",
              "       [-0.38732682, -0.30230275],\n",
              "       [-1.04855297, -1.42001794],\n",
              "       [-1.70627019,  1.9507754 ],\n",
              "       [-0.50965218, -0.4380743 ],\n",
              "       [-1.25279536,  0.77749036],\n",
              "       [-1.61389785, -0.21274028],\n",
              "       [-0.89546656,  0.3869025 ],\n",
              "       [-0.51080514, -1.18063218],\n",
              "       [-0.02818223,  0.42833187],\n",
              "       [ 0.06651722,  0.3024719 ],\n",
              "       [-0.63432209, -0.36274117],\n",
              "       [-0.67246045, -0.35955316],\n",
              "       [-0.81314628, -1.7262826 ],\n",
              "       [ 0.17742614, -0.40178094],\n",
              "       [-1.63019835,  0.46278226],\n",
              "       [-0.90729836,  0.0519454 ],\n",
              "       [ 0.72909056,  0.12898291],\n",
              "       [ 1.13940068, -1.23482582],\n",
              "       [ 0.40234164, -0.68481009],\n",
              "       [-0.87079715, -0.57884966],\n",
              "       [-0.31155253,  0.05616534],\n",
              "       [-1.16514984,  0.90082649],\n",
              "       [ 0.46566244, -1.53624369],\n",
              "       [ 1.48825219,  1.89588918],\n",
              "       [ 1.17877957, -0.17992484],\n",
              "       [-1.07075262,  1.05445173],\n",
              "       [-0.40317695,  1.22244507],\n",
              "       [ 0.20827498,  0.97663904],\n",
              "       [ 0.3563664 ,  0.70657317],\n",
              "       [ 0.01050002,  1.78587049],\n",
              "       [ 0.12691209,  0.40198936],\n",
              "       [ 1.8831507 , -1.34775906],\n",
              "       [-1.270485  ,  0.96939671],\n",
              "       [-1.17312341,  1.94362119],\n",
              "       [-0.41361898, -0.74745481],\n",
              "       [ 1.92294203,  1.48051479],\n",
              "       [ 1.86755896,  0.90604466],\n",
              "       [-0.86122569,  1.91006495],\n",
              "       [-0.26800337,  0.8024564 ],\n",
              "       [ 0.94725197, -0.15501009],\n",
              "       [ 0.61407937,  0.92220667],\n",
              "       [ 0.37642553, -1.09940079],\n",
              "       [ 0.29823817,  1.3263859 ],\n",
              "       [-0.69456786, -0.14963454],\n",
              "       [-0.43515355,  1.84926373],\n",
              "       [ 0.67229476,  0.40746184],\n",
              "       [-0.76991607,  0.53924919],\n",
              "       [-0.67433266,  0.03183056],\n",
              "       [-0.63584608,  0.67643329],\n",
              "       [ 0.57659082, -0.20829876],\n",
              "       [ 0.39600671, -1.09306151],\n",
              "       [-1.49125759,  0.4393917 ],\n",
              "       [ 0.1666735 ,  0.63503144],\n",
              "       [ 2.38314477,  0.94447949],\n",
              "       [-0.91282223,  1.11701629],\n",
              "       [-1.31590741, -0.4615846 ],\n",
              "       [-0.06824161,  1.71334272],\n",
              "       [-0.74475482, -0.82643854],\n",
              "       [-0.09845252, -0.66347829],\n",
              "       [ 1.12663592, -1.07993151],\n",
              "       [-1.14746865, -0.43782004],\n",
              "       [-0.49803245,  1.92953205],\n",
              "       [ 0.94942081,  0.08755124],\n",
              "       [-1.22543552,  0.84436298],\n",
              "       [-1.00021535, -1.5447711 ],\n",
              "       [ 1.18802979,  0.31694261],\n",
              "       [ 0.92085882,  0.31872765],\n",
              "       [ 0.85683061, -0.65102559],\n",
              "       [-1.03424284,  0.68159452],\n",
              "       [-0.80340966, -0.68954978],\n",
              "       [-0.4555325 ,  0.01747916],\n",
              "       [-0.35399391, -1.37495129],\n",
              "       [-0.6436184 , -2.22340315],\n",
              "       [ 0.62523145, -1.60205766],\n",
              "       [-1.10438334,  0.05216508],\n",
              "       [-0.739563  ,  1.5430146 ],\n",
              "       [-1.29285691,  0.26705087],\n",
              "       [-0.03928282, -1.1680935 ],\n",
              "       [ 0.52327666, -0.17154633],\n",
              "       [ 0.77179055,  0.82350415],\n",
              "       [ 2.16323595,  1.33652795],\n",
              "       [-0.36918184, -0.23937918],\n",
              "       [ 1.0996596 ,  0.65526373],\n",
              "       [ 0.64013153, -1.61695604],\n",
              "       [-0.02432612, -0.73803091],\n",
              "       [ 0.2799246 , -0.09815039],\n",
              "       [ 0.91017891,  0.31721822],\n",
              "       [ 0.78632796, -0.4664191 ],\n",
              "       [-0.94444626, -0.41004969],\n",
              "       [-0.01702041,  0.37915174],\n",
              "       [ 2.25930895, -0.04225715],\n",
              "       [-0.955945  , -0.34598178],\n",
              "       [-0.46359597,  0.48148147],\n",
              "       [-1.54079701,  0.06326199],\n",
              "       [ 0.15650654,  0.23218104],\n",
              "       [-0.59731607, -0.23792173],\n",
              "       [-1.42406091, -0.49331988],\n",
              "       [-0.54286148,  0.41605005],\n",
              "       [-1.15618243,  0.7811981 ],\n",
              "       [ 1.49448454, -2.06998503],\n",
              "       [ 0.42625873,  0.67690804],\n",
              "       [-0.63743703, -0.39727181],\n",
              "       [-0.13288058, -0.29779088],\n",
              "       [-0.30901297, -1.67600381],\n",
              "       [ 1.15233156,  1.07961859],\n",
              "       [-0.81336426, -1.46642433],\n",
              "       [ 0.52106488, -0.57578797],\n",
              "       [ 0.14195316, -0.31932842],\n",
              "       [ 0.69153875,  0.69474914],\n",
              "       [-0.72559738, -1.38336396],\n",
              "       [-1.5829384 ,  0.61037938],\n",
              "       [-1.18885926, -0.50681635],\n",
              "       [-0.59631404, -0.0525673 ],\n",
              "       [-1.93627981,  0.1887786 ],\n",
              "       [ 0.52389102,  0.08842209],\n",
              "       [-0.31088617,  0.09740017],\n",
              "       [ 0.39904635, -2.77259276],\n",
              "       [ 1.95591231,  0.39009332],\n",
              "       [-0.65240858, -0.39095338],\n",
              "       [ 0.49374178, -0.11610394],\n",
              "       [-2.03068447,  2.06449286],\n",
              "       [-0.11054066,  1.02017271],\n",
              "       [-0.69204985,  1.53637705],\n",
              "       [ 0.28634369,  0.60884383],\n",
              "       [-1.04525337,  1.21114529],\n",
              "       [ 0.68981816,  1.30184623],\n",
              "       [-0.62808756, -0.48102712],\n",
              "       [ 2.3039167 , -1.06001582],\n",
              "       [-0.1359497 ,  1.13689136],\n",
              "       [ 0.09772497,  0.58295368],\n",
              "       [-0.39944903,  0.37005589],\n",
              "       [-1.30652685,  1.65813068],\n",
              "       [-0.11816405, -0.6801782 ],\n",
              "       [ 0.66638308, -0.46071979],\n",
              "       [-1.33425847, -1.34671751],\n",
              "       [ 0.69377315, -0.15957344],\n",
              "       [-0.13370156,  1.07774381],\n",
              "       [-1.12682581, -0.73067775],\n",
              "       [-0.38487981,  0.09435159],\n",
              "       [-0.04217145, -0.28688719],\n",
              "       [-0.0616264 , -0.10730528],\n",
              "       [-0.71960439, -0.81299299],\n",
              "       [ 0.27451636, -0.89091508],\n",
              "       [-1.15735526, -0.31229225],\n",
              "       [-0.15766702,  2.2567235 ],\n",
              "       [-0.70470028,  0.94326072],\n",
              "       [ 0.74718833, -1.18894496],\n",
              "       [ 0.77325298, -1.18388064],\n",
              "       [-2.65917224,  0.60631952],\n",
              "       [-1.75589058,  0.45093446],\n",
              "       [-0.6840109 ,  1.6595508 ],\n",
              "       [ 1.0685094 , -0.4533858 ],\n",
              "       [-0.68783761, -1.2140774 ],\n",
              "       [-0.44092263, -0.2803555 ],\n",
              "       [-0.36469354,  0.15670386],\n",
              "       [ 0.5785215 ,  0.34965446],\n",
              "       [-0.76414392, -1.43779147],\n",
              "       [ 1.36453185, -0.68944918],\n",
              "       [-0.6522936 , -0.52118931],\n",
              "       [-1.84306955, -0.477974  ],\n",
              "       [-0.47965581,  0.6203583 ],\n",
              "       [ 0.69845715,  0.00377089],\n",
              "       [ 0.93184837,  0.33996498],\n",
              "       [-0.01568211,  0.16092817],\n",
              "       [-0.19065349, -0.39484951],\n",
              "       [-0.26773354, -1.12801133],\n",
              "       [ 0.28044171, -0.99312361],\n",
              "       [ 0.84163126, -0.24945858],\n",
              "       [ 0.04949498,  0.49383678],\n",
              "       [ 0.64331447, -1.57062341],\n",
              "       [-0.20690368,  0.88017891],\n",
              "       [-1.69810582,  0.38728048],\n",
              "       [-2.25556423, -1.02250684],\n",
              "       [ 0.03863055, -1.6567151 ],\n",
              "       [-0.98551074, -1.47183501],\n",
              "       [ 1.64813493,  0.16422776],\n",
              "       [ 0.56729028, -0.2226751 ],\n",
              "       [-0.35343175, -1.61647419],\n",
              "       [-0.29183736, -0.76149221],\n",
              "       [ 0.85792392,  1.14110187],\n",
              "       [ 1.46657872,  0.85255194],\n",
              "       [-0.59865394, -1.11589699],\n",
              "       [ 0.76666318,  0.35629282],\n",
              "       [-1.76853845,  0.35548179],\n",
              "       [ 0.81451982,  0.05892559],\n",
              "       [-0.18505367, -0.80764849],\n",
              "       [-1.4465347 ,  0.80029795],\n",
              "       [-0.30911444, -0.23346666],\n",
              "       [ 1.73272119,  0.68450111],\n",
              "       [ 0.370825  ,  0.14206181],\n",
              "       [ 1.51999486,  1.71958931],\n",
              "       [ 0.92950511,  0.58222459],\n",
              "       [-2.09460307,  0.12372191],\n",
              "       [-0.13010695,  0.09395323],\n",
              "       [ 0.94304609, -2.73967717],\n",
              "       [-0.56931205,  0.26990435],\n",
              "       [-0.46684555, -1.41690611],\n",
              "       [ 0.86896349,  0.27687191],\n",
              "       [-0.97110457,  0.3148172 ],\n",
              "       [ 0.82158571,  0.00529265],\n",
              "       [ 0.8005648 ,  0.07826018],\n",
              "       [-0.39522898, -1.15942052],\n",
              "       [-0.08593077,  0.19429294],\n",
              "       [ 0.87583276, -0.11510747],\n",
              "       [ 0.45741561, -0.96461201],\n",
              "       [-0.78262916, -0.1103893 ],\n",
              "       [-1.05462846,  0.82024784],\n",
              "       [ 0.46313033,  0.27909576],\n",
              "       [ 0.33890413,  2.02104356],\n",
              "       [-0.46886419, -2.20144129],\n",
              "       [ 0.1993002 , -0.05060354],\n",
              "       [-0.51751904, -0.97882986],\n",
              "       [-0.43918952,  0.18133843],\n",
              "       [-0.5028167 ,  2.41245368],\n",
              "       [-0.96050438, -0.79311736],\n",
              "       [-2.28862004,  0.25148442],\n",
              "       [-2.01640663, -0.53945463],\n",
              "       [-0.27567053, -0.70972797],\n",
              "       [ 1.73887268,  0.99439439],\n",
              "       [ 1.31913688, -0.88241882],\n",
              "       [ 1.12859406,  0.49600095],\n",
              "       [ 0.77140595,  1.02943883],\n",
              "       [-0.90876325, -0.42431762],\n",
              "       [ 0.86259601, -2.65561909],\n",
              "       [ 1.51332808,  0.55313206],\n",
              "       [-0.04570396,  0.22050766],\n",
              "       [-1.02993528, -0.34994336],\n",
              "       [ 1.10028434,  1.29802197],\n",
              "       [ 2.69622405, -0.07392467],\n",
              "       [-0.65855297, -0.51423397],\n",
              "       [-1.01804188, -0.07785476],\n",
              "       [ 0.38273243, -0.03424228],\n",
              "       [ 1.09634685, -0.2342158 ],\n",
              "       [-0.34745065, -0.58126848],\n",
              "       [-1.63263453, -1.56776772],\n",
              "       [-1.17915793,  1.30142807],\n",
              "       [ 0.89526027,  1.37496407],\n",
              "       [-1.33221165, -1.96862469],\n",
              "       [-0.66005632,  0.17581895],\n",
              "       [ 0.49869027,  1.04797216],\n",
              "       [ 0.28427967,  1.74266878],\n",
              "       [-0.22260568, -0.91307922],\n",
              "       [-1.68121822, -0.88897136],\n",
              "       [ 0.24211796, -0.88872026],\n",
              "       [ 0.93674246,  1.41232771],\n",
              "       [-2.36958691,  0.8640523 ],\n",
              "       [-2.23960406,  0.40149906],\n",
              "       [ 1.22487056,  0.06485611],\n",
              "       [-1.27968917, -0.5854312 ],\n",
              "       [-0.26164545, -0.18224478],\n",
              "       [-0.20289684, -0.10988278],\n",
              "       [ 0.21348005, -1.20857365],\n",
              "       [-0.24201983,  1.51826117],\n",
              "       [-0.38464542, -0.44383609],\n",
              "       [ 1.0781973 , -2.55918467],\n",
              "       [ 1.1813786 , -0.63190376],\n",
              "       [ 0.16392857,  0.09632136],\n",
              "       [ 0.94246812, -0.26759475],\n",
              "       [-0.67802578,  1.29784579],\n",
              "       [-2.36417382,  0.02033418],\n",
              "       [-1.34792542, -0.76157339],\n",
              "       [ 2.01125668, -0.04459543],\n",
              "       [ 0.1950697 , -1.78156286],\n",
              "       [-0.72904466,  0.1965574 ],\n",
              "       [ 0.35475769,  0.61688655],\n",
              "       [ 0.0086279 ,  0.52700421],\n",
              "       [ 0.45378191, -1.82974041],\n",
              "       [ 0.03700572,  0.76790241],\n",
              "       [ 0.58987982, -0.36385881],\n",
              "       [-0.80562651, -1.11831192],\n",
              "       [-0.13105401,  1.13307988],\n",
              "       [-1.9518041 , -0.65989173],\n",
              "       [-1.13980246,  0.78495752],\n",
              "       [-0.55430963, -0.47063766],\n",
              "       [-0.21694957,  0.44539325],\n",
              "       [-0.392389  , -3.04614305],\n",
              "       [ 0.54331189,  0.43904296],\n",
              "       [-0.21954103, -1.08403662],\n",
              "       [ 0.35178011,  0.37923553],\n",
              "       [-0.47003288, -0.21673147],\n",
              "       [-0.9301565 , -0.17858909]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCaJ8a1J2u7F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model1 = ...\n",
        "\n",
        "h1 = model1.fit(...)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YUpzRth-Pzv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "56a9e654-d68e-478b-d81f-571d12d0971e"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# This is our perceptron from Monday: \n",
        "model1 = Sequential()\n",
        "model1.add(Dense(1,input_dim=2, activation='sigmoid'))\n",
        "model1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "h1 = model1.fit(X,y, epochs=100)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9720 - accuracy: 0.4633\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9681 - accuracy: 0.4667\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9642 - accuracy: 0.4700\n",
            "Epoch 4/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9603 - accuracy: 0.4700\n",
            "Epoch 5/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9567 - accuracy: 0.4700\n",
            "Epoch 6/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9529 - accuracy: 0.4700\n",
            "Epoch 7/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9493 - accuracy: 0.4733\n",
            "Epoch 8/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9459 - accuracy: 0.4733\n",
            "Epoch 9/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9422 - accuracy: 0.4733\n",
            "Epoch 10/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9385 - accuracy: 0.4733\n",
            "Epoch 11/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9351 - accuracy: 0.4733\n",
            "Epoch 12/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9316 - accuracy: 0.4767\n",
            "Epoch 13/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9280 - accuracy: 0.4767\n",
            "Epoch 14/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9246 - accuracy: 0.4800\n",
            "Epoch 15/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9212 - accuracy: 0.4800\n",
            "Epoch 16/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9178 - accuracy: 0.4767\n",
            "Epoch 17/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9144 - accuracy: 0.4767\n",
            "Epoch 18/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9111 - accuracy: 0.4767\n",
            "Epoch 19/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9081 - accuracy: 0.4767\n",
            "Epoch 20/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9045 - accuracy: 0.4767\n",
            "Epoch 21/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9012 - accuracy: 0.4767\n",
            "Epoch 22/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8982 - accuracy: 0.4800\n",
            "Epoch 23/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8950 - accuracy: 0.4767\n",
            "Epoch 24/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8917 - accuracy: 0.4800\n",
            "Epoch 25/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8885 - accuracy: 0.4800\n",
            "Epoch 26/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8856 - accuracy: 0.4800\n",
            "Epoch 27/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8825 - accuracy: 0.4800\n",
            "Epoch 28/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8796 - accuracy: 0.4800\n",
            "Epoch 29/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8766 - accuracy: 0.4800\n",
            "Epoch 30/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8734 - accuracy: 0.4833\n",
            "Epoch 31/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8708 - accuracy: 0.4833\n",
            "Epoch 32/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8676 - accuracy: 0.4867\n",
            "Epoch 33/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8649 - accuracy: 0.4833\n",
            "Epoch 34/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8619 - accuracy: 0.4833\n",
            "Epoch 35/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8590 - accuracy: 0.4800\n",
            "Epoch 36/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8563 - accuracy: 0.4800\n",
            "Epoch 37/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8534 - accuracy: 0.4800\n",
            "Epoch 38/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8507 - accuracy: 0.4800\n",
            "Epoch 39/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8478 - accuracy: 0.4800\n",
            "Epoch 40/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8453 - accuracy: 0.4800\n",
            "Epoch 41/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8426 - accuracy: 0.4800\n",
            "Epoch 42/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8399 - accuracy: 0.4800\n",
            "Epoch 43/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8373 - accuracy: 0.4800\n",
            "Epoch 44/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8348 - accuracy: 0.4833\n",
            "Epoch 45/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8323 - accuracy: 0.4833\n",
            "Epoch 46/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8298 - accuracy: 0.4833\n",
            "Epoch 47/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8273 - accuracy: 0.4833\n",
            "Epoch 48/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8249 - accuracy: 0.4867\n",
            "Epoch 49/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8223 - accuracy: 0.4867\n",
            "Epoch 50/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8201 - accuracy: 0.4867\n",
            "Epoch 51/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8174 - accuracy: 0.4867\n",
            "Epoch 52/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8151 - accuracy: 0.4867\n",
            "Epoch 53/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8127 - accuracy: 0.4867\n",
            "Epoch 54/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8104 - accuracy: 0.4867\n",
            "Epoch 55/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8082 - accuracy: 0.4867\n",
            "Epoch 56/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8060 - accuracy: 0.4900\n",
            "Epoch 57/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8038 - accuracy: 0.4900\n",
            "Epoch 58/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8018 - accuracy: 0.4900\n",
            "Epoch 59/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7997 - accuracy: 0.4933\n",
            "Epoch 60/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7977 - accuracy: 0.4967\n",
            "Epoch 61/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7956 - accuracy: 0.5033\n",
            "Epoch 62/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7936 - accuracy: 0.5033\n",
            "Epoch 63/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7917 - accuracy: 0.5067\n",
            "Epoch 64/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7895 - accuracy: 0.5067\n",
            "Epoch 65/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7878 - accuracy: 0.5067\n",
            "Epoch 66/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7858 - accuracy: 0.5100\n",
            "Epoch 67/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7839 - accuracy: 0.5100\n",
            "Epoch 68/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7820 - accuracy: 0.5133\n",
            "Epoch 69/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7801 - accuracy: 0.5167\n",
            "Epoch 70/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7783 - accuracy: 0.5200\n",
            "Epoch 71/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7766 - accuracy: 0.5200\n",
            "Epoch 72/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7747 - accuracy: 0.5233\n",
            "Epoch 73/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7730 - accuracy: 0.5233\n",
            "Epoch 74/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7711 - accuracy: 0.5233\n",
            "Epoch 75/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7693 - accuracy: 0.5267\n",
            "Epoch 76/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7677 - accuracy: 0.5267\n",
            "Epoch 77/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7659 - accuracy: 0.5267\n",
            "Epoch 78/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7643 - accuracy: 0.5267\n",
            "Epoch 79/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7627 - accuracy: 0.5233\n",
            "Epoch 80/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7610 - accuracy: 0.5233\n",
            "Epoch 81/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7595 - accuracy: 0.5233\n",
            "Epoch 82/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7579 - accuracy: 0.5200\n",
            "Epoch 83/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7563 - accuracy: 0.5200\n",
            "Epoch 84/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7547 - accuracy: 0.5200\n",
            "Epoch 85/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7534 - accuracy: 0.5200\n",
            "Epoch 86/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7519 - accuracy: 0.5200\n",
            "Epoch 87/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7505 - accuracy: 0.5167\n",
            "Epoch 88/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7493 - accuracy: 0.5233\n",
            "Epoch 89/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7479 - accuracy: 0.5233\n",
            "Epoch 90/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7467 - accuracy: 0.5233\n",
            "Epoch 91/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7452 - accuracy: 0.5233\n",
            "Epoch 92/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7439 - accuracy: 0.5233\n",
            "Epoch 93/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7426 - accuracy: 0.5233\n",
            "Epoch 94/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7413 - accuracy: 0.5233\n",
            "Epoch 95/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7400 - accuracy: 0.5233\n",
            "Epoch 96/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7387 - accuracy: 0.5233\n",
            "Epoch 97/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7376 - accuracy: 0.5167\n",
            "Epoch 98/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7365 - accuracy: 0.5167\n",
            "Epoch 99/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7353 - accuracy: 0.5133\n",
            "Epoch 100/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7341 - accuracy: 0.5133\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoF31E3S-115",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "outputId": "66db3535-b2d6-4792-87fb-826e625a563a"
      },
      "source": [
        "model1.summary()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_21\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_43 (Dense)             (None, 1)                 3         \n",
            "=================================================================\n",
            "Total params: 3\n",
            "Trainable params: 3\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRk1ahct-4Cm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "b5b45751-470f-4f9d-f515-c62a30b3a6f0"
      },
      "source": [
        "# evaluate the model\n",
        "scores = model1.evaluate(X, y)\n",
        "print(f\"{model1.metrics_names[1]}: {scores[1]*100}\")"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7335 - accuracy: 0.5133\n",
            "accuracy: 51.33333206176758\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNRv9iN32u7G",
        "colab_type": "text"
      },
      "source": [
        "### Multi-Layer Perceptron\n",
        "Now construct a multi-layer perceptron using. Here are some architecture suggestions: \n",
        "- 2 Hidden Layers\n",
        "- 5-32 Neurons in the Hidden Layers\n",
        "- Your pick of activation function and optimizer\n",
        "- Incorporate the Callback function below into your model\n",
        "\n",
        "Your model should be called `model2` and make sure to save the results of your fit statement to a variable called `h2`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwQ4P9JC2u7H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class myCallback(tf.keras.callbacks.Callback): \n",
        "    def on_epoch_end(self, epoch, logs={}): \n",
        "        if(logs.get('accuracy') > .99999):   \n",
        "            self.model.stop_training = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guhgSRIF2u7J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model2 = ...\n",
        "\n",
        "h2 = model1.fit(...)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAEkO0PlBPTe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a53ab8ba-9def-4bf9-91b0-6ebe43ee2f49"
      },
      "source": [
        "model2 = Sequential([\n",
        "    Dense(1, input_dim=2, activation='sigmoid'),\n",
        "    Dense(32,activation='relu'),\n",
        "    Dense(10, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model2.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "h2 = model2.fit(X,y,\n",
        "                epochs=100)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.2041 - accuracy: 0.4733\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.1326 - accuracy: 0.4733\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0615 - accuracy: 0.4733\n",
            "Epoch 4/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.9907 - accuracy: 0.4733\n",
            "Epoch 5/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.9190 - accuracy: 0.4733\n",
            "Epoch 6/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.8464 - accuracy: 0.4733\n",
            "Epoch 7/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.7721 - accuracy: 0.4733\n",
            "Epoch 8/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.6977 - accuracy: 0.4733\n",
            "Epoch 9/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.6228 - accuracy: 0.4733\n",
            "Epoch 10/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.5498 - accuracy: 0.4733\n",
            "Epoch 11/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.4797 - accuracy: 0.4733\n",
            "Epoch 12/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.4126 - accuracy: 0.4733\n",
            "Epoch 13/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3487 - accuracy: 0.4733\n",
            "Epoch 14/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.2879 - accuracy: 0.4733\n",
            "Epoch 15/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2303 - accuracy: 0.4733\n",
            "Epoch 16/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1758 - accuracy: 0.4733\n",
            "Epoch 17/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.1242 - accuracy: 0.4733\n",
            "Epoch 18/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0751 - accuracy: 0.4733\n",
            "Epoch 19/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0301 - accuracy: 0.4733\n",
            "Epoch 20/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.9887 - accuracy: 0.4733\n",
            "Epoch 21/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.9507 - accuracy: 0.4733\n",
            "Epoch 22/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.9177 - accuracy: 0.4733\n",
            "Epoch 23/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8872 - accuracy: 0.4733\n",
            "Epoch 24/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8616 - accuracy: 0.4733\n",
            "Epoch 25/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8405 - accuracy: 0.4733\n",
            "Epoch 26/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8214 - accuracy: 0.4733\n",
            "Epoch 27/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8053 - accuracy: 0.4733\n",
            "Epoch 28/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7917 - accuracy: 0.4567\n",
            "Epoch 29/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7798 - accuracy: 0.4667\n",
            "Epoch 30/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7721 - accuracy: 0.4700\n",
            "Epoch 31/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7618 - accuracy: 0.5467\n",
            "Epoch 32/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7549 - accuracy: 0.5467\n",
            "Epoch 33/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7487 - accuracy: 0.5733\n",
            "Epoch 34/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7433 - accuracy: 0.5900\n",
            "Epoch 35/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7390 - accuracy: 0.5700\n",
            "Epoch 36/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.5667\n",
            "Epoch 37/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7312 - accuracy: 0.5767\n",
            "Epoch 38/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7281 - accuracy: 0.5833\n",
            "Epoch 39/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7254 - accuracy: 0.5867\n",
            "Epoch 40/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7227 - accuracy: 0.6033\n",
            "Epoch 41/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7206 - accuracy: 0.5967\n",
            "Epoch 42/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7193 - accuracy: 0.5733\n",
            "Epoch 43/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7165 - accuracy: 0.5567\n",
            "Epoch 44/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7146 - accuracy: 0.5500\n",
            "Epoch 45/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7133 - accuracy: 0.5300\n",
            "Epoch 46/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7119 - accuracy: 0.5300\n",
            "Epoch 47/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7105 - accuracy: 0.5400\n",
            "Epoch 48/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7094 - accuracy: 0.5567\n",
            "Epoch 49/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7082 - accuracy: 0.5567\n",
            "Epoch 50/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7071 - accuracy: 0.5567\n",
            "Epoch 51/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7067 - accuracy: 0.5700\n",
            "Epoch 52/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7053 - accuracy: 0.5667\n",
            "Epoch 53/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7046 - accuracy: 0.5600\n",
            "Epoch 54/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7037 - accuracy: 0.5833\n",
            "Epoch 55/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7029 - accuracy: 0.6000\n",
            "Epoch 56/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7020 - accuracy: 0.5600\n",
            "Epoch 57/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7022 - accuracy: 0.5267\n",
            "Epoch 58/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7013 - accuracy: 0.5433\n",
            "Epoch 59/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7012 - accuracy: 0.5967\n",
            "Epoch 60/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6997 - accuracy: 0.5633\n",
            "Epoch 61/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6992 - accuracy: 0.5400\n",
            "Epoch 62/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6988 - accuracy: 0.5267\n",
            "Epoch 63/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6987 - accuracy: 0.5300\n",
            "Epoch 64/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6978 - accuracy: 0.5300\n",
            "Epoch 65/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6973 - accuracy: 0.5433\n",
            "Epoch 66/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6970 - accuracy: 0.5733\n",
            "Epoch 67/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6968 - accuracy: 0.6233\n",
            "Epoch 68/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6962 - accuracy: 0.5733\n",
            "Epoch 69/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6959 - accuracy: 0.5833\n",
            "Epoch 70/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6955 - accuracy: 0.6167\n",
            "Epoch 71/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6950 - accuracy: 0.6000\n",
            "Epoch 72/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6946 - accuracy: 0.5633\n",
            "Epoch 73/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6940 - accuracy: 0.5500\n",
            "Epoch 74/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6939 - accuracy: 0.5433\n",
            "Epoch 75/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6937 - accuracy: 0.5367\n",
            "Epoch 76/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5333\n",
            "Epoch 77/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5433\n",
            "Epoch 78/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6923 - accuracy: 0.5567\n",
            "Epoch 79/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6922 - accuracy: 0.5967\n",
            "Epoch 80/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6919 - accuracy: 0.5967\n",
            "Epoch 81/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6914 - accuracy: 0.5567\n",
            "Epoch 82/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6913 - accuracy: 0.5700\n",
            "Epoch 83/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6907 - accuracy: 0.5633\n",
            "Epoch 84/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6905 - accuracy: 0.5433\n",
            "Epoch 85/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6900 - accuracy: 0.5600\n",
            "Epoch 86/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6897 - accuracy: 0.5633\n",
            "Epoch 87/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6894 - accuracy: 0.6067\n",
            "Epoch 88/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6890 - accuracy: 0.6467\n",
            "Epoch 89/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6887 - accuracy: 0.6500\n",
            "Epoch 90/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6883 - accuracy: 0.6400\n",
            "Epoch 91/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6889 - accuracy: 0.5567\n",
            "Epoch 92/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6877 - accuracy: 0.5767\n",
            "Epoch 93/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6874 - accuracy: 0.6533\n",
            "Epoch 94/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6871 - accuracy: 0.6500\n",
            "Epoch 95/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6869 - accuracy: 0.6600\n",
            "Epoch 96/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6867 - accuracy: 0.6633\n",
            "Epoch 97/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6861 - accuracy: 0.6633\n",
            "Epoch 98/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6861 - accuracy: 0.6600\n",
            "Epoch 99/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6855 - accuracy: 0.6600\n",
            "Epoch 100/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6853 - accuracy: 0.6600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mICyU6lBFWMu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "b428539a-baaf-47bf-b01e-2c968c0dbc5b"
      },
      "source": [
        "# evaluate the model\n",
        "scores = model2.evaluate(X, y)\n",
        "print(f\"{model2.metrics_names[1]}: {scores[1]*100}\")"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6847 - accuracy: 0.6600\n",
            "accuracy: 66.00000262260437\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAU1mkxS2u7L",
        "colab_type": "text"
      },
      "source": [
        "### Analyze and Compare\n",
        "\n",
        "**Before you Start**: You will need to install an additional library for this next segment. Install the package `mlxtend` into the environment you are using for the sprint challenge.\n",
        "\n",
        "\n",
        "The cells below generate decision boundary plots of your models (`model1` & `model2`). Review the plots."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-8sxpqrFltQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "483bb1c3-6859-49af-cfa7-1058e6b348cb"
      },
      "source": [
        "!pip install mlxtend"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mlxtend in /usr/local/lib/python3.6/dist-packages (0.14.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from mlxtend) (1.18.4)\n",
            "Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.6/dist-packages (from mlxtend) (1.4.1)\n",
            "Requirement already satisfied: pandas>=0.17.1 in /usr/local/lib/python3.6/dist-packages (from mlxtend) (1.0.3)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.6/dist-packages (from mlxtend) (0.22.2.post1)\n",
            "Requirement already satisfied: matplotlib>=1.5.1 in /usr/local/lib/python3.6/dist-packages (from mlxtend) (3.2.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from mlxtend) (46.1.3)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.17.1->mlxtend) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.17.1->mlxtend) (2.8.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18->mlxtend) (0.14.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.5.1->mlxtend) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.5.1->mlxtend) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.5.1->mlxtend) (1.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas>=0.17.1->mlxtend) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vK2r2AD2u7L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 792
        },
        "outputId": "b79396be-7137-462f-da1f-da5014648087"
      },
      "source": [
        "# Do Not change anything in this cell\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from mlxtend.plotting import plot_decision_regions\n",
        "\n",
        "h = .02  # step size in the mesh\n",
        "\n",
        "# create a mesh to plot in\n",
        "x_min, x_max = X[:, 0].min() - .2, X[:, 0].max() + .2\n",
        "y_min, y_max = X[:, 1].min() - .2, X[:, 1].max() + .2\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
        "                     np.arange(y_min, y_max, h))\n",
        "\n",
        "fig = plt.figure(figsize=(12,6))\n",
        "\n",
        "\n",
        "for clf, hist, name, grd in zip([model1,model2], [h1, h2],['Perceptron', 'Multi-Layer Perceptron'],[1,2]):\n",
        "\n",
        "    ax = plt.subplot(1,2, grd)\n",
        "    fig = plot_decision_regions(X=X, y=y, clf=clf, legend=2)\n",
        "    title = f\"{name} with {hist.history['accuracy'][-1]:,.2f} Accuracy\"\n",
        "    plt.title(title)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/mlxtend/plotting/decision_regions.py:244: MatplotlibDeprecationWarning: Passing unsupported keyword arguments to axis() will raise a TypeError in 3.3.\n",
            "  ax.axis(xmin=xx.min(), xmax=xx.max(), y_min=yy.min(), y_max=yy.max())\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-c2f9b7afbd9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplot_decision_regions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlegend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mtitle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{name} with {hist.history['accuracy'][-1]:,.2f} Accuracy\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/mlxtend/plotting/decision_regions.py\u001b[0m in \u001b[0;36mplot_decision_regions\u001b[0;34m(X, y, clf, feature_index, filler_feature_values, filler_feature_ranges, ax, X_highlight, res, legend, hide_spines, markers, colors, scatter_kwargs, contourf_kwargs, scatter_highlight_kwargs)\u001b[0m\n\u001b[1;32m    224\u001b[0m                 \u001b[0mX_predict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiller_feature_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[0mZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_predict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m     \u001b[0mZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m     \u001b[0;31m# Plot decisoin region\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;31m# Make sure contourf_kwargs has backwards compatible defaults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 3732480 into shape (432,864)"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FOGtCoj2u7N",
        "colab_type": "text"
      },
      "source": [
        "Why does the Perceptron (`model1`) only achieve ~70% accuracy? What is the architectural property of the Multi-Layer Perceptron that allows it more accurately learn the relationship between X and y? \n",
        "\n",
        "Why might this property be useful in more complex data such as images?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3T7IGh4KHMLj",
        "colab_type": "text"
      },
      "source": [
        "**As this part isn't working properly, and I don't have the time to debug it, I can only provide an answer of of assumptions. The higher accracy is achieved through the addition of extra layers representing additional neurons. As such there are more units for optimizations along the way, for every single cycle. Images are relatively complex inputs for any ML scenario. In order to effectively process these complex inputs, the network needs to be able to differentiate and refine it's parameters. A simple perceptron might processes the image data in a binary fashin, while a multi-layer perceptron can achieve higher granularity, and as such is able to tune more parameters, and device better feed-back loops**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27Ok8mrc2u7P",
        "colab_type": "text"
      },
      "source": [
        "## 3. Keras MMP <a id=\"Q3\"></a>\n",
        "\n",
        "Implement a Multilayer Perceptron architecture of your choosing using the Keras library. Train your model and report its baseline accuracy. Then hyperparameter tune at least two parameters and report your model's accuracy.\n",
        "Use the Heart Disease Dataset (binary classification)\n",
        "Use an appropriate loss function for a binary classification task\n",
        "Use an appropriate activation function on the final layer of your network.\n",
        "Train your model using verbose output for ease of grading.\n",
        "Use GridSearchCV or RandomSearchCV to hyperparameter tune your model. (for at least two hyperparameters)\n",
        "When hyperparameter tuning, show you work by adding code cells for each new experiment.\n",
        "Report the accuracy for each combination of hyperparameters as you test them so that we can easily see which resulted in the highest accuracy.\n",
        "You must hyperparameter tune at least 3 parameters in order to get a 3 on this section."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "inputHidden": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "outputHidden": false,
        "id": "nVkSlJ272u7P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "dafdf9cc-5f8e-44b6-c9db-54bf56b9d526"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/ryanleeallred/datasets/master/heart.csv')\n",
        "df = df.sample(frac=1)\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(303, 14)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>138</td>\n",
              "      <td>183</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>182</td>\n",
              "      <td>0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>276</th>\n",
              "      <td>58</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>146</td>\n",
              "      <td>218</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>105</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>48</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>130</td>\n",
              "      <td>275</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>139</td>\n",
              "      <td>0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159</th>\n",
              "      <td>56</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>130</td>\n",
              "      <td>221</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>163</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>245</th>\n",
              "      <td>48</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>124</td>\n",
              "      <td>274</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>166</td>\n",
              "      <td>0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     age  sex  cp  trestbps  chol  fbs  ...  exang  oldpeak  slope  ca  thal  target\n",
              "65    35    0   0       138   183    0  ...      0      1.4      2   0     2       1\n",
              "276   58    1   0       146   218    0  ...      0      2.0      1   1     3       0\n",
              "11    48    0   2       130   275    0  ...      0      0.2      2   0     2       1\n",
              "159   56    1   1       130   221    0  ...      0      0.0      2   0     3       1\n",
              "245   48    1   0       124   274    0  ...      0      0.5      1   0     3       0\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkupNf2Q2u7S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Your Code Here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8UCwSDhJ2Qt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "\n",
        "X = df[['age','sex','cp','trestbps','chol','fbs','restecg','thalach','exang','oldpeak','slope','ca','thal']].values\n",
        "y = df['target'].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2kLEwC4J2TW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3c071f87-1a8a-43ad-9b07-dda9f8a30250"
      },
      "source": [
        "# create model\n",
        "model = Sequential()\n",
        "model.add(Dense(2,input_dim = 13,activation = 'relu'))\n",
        "model.add(Dense(4,activation = 'relu'))\n",
        "model.add(Dense(1,activation = 'sigmoid'))\n",
        "model.compile(loss = 'binary_crossentropy',optimizer = 'adam', metrics = ['accuracy'])\n",
        "model.fit(X,y,epochs = 100, verbose = True)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 26.5512 - accuracy: 0.5446\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 22.6756 - accuracy: 0.5446\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 19.1005 - accuracy: 0.5446\n",
            "Epoch 4/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 15.2747 - accuracy: 0.5446\n",
            "Epoch 5/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 11.6312 - accuracy: 0.5446\n",
            "Epoch 6/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 7.9624 - accuracy: 0.5413\n",
            "Epoch 7/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 4.7637 - accuracy: 0.5050\n",
            "Epoch 8/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 3.3406 - accuracy: 0.3795\n",
            "Epoch 9/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 3.1462 - accuracy: 0.3894\n",
            "Epoch 10/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.5787 - accuracy: 0.4059\n",
            "Epoch 11/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.8551 - accuracy: 0.5215\n",
            "Epoch 12/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.6410 - accuracy: 0.5215\n",
            "Epoch 13/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.4473 - accuracy: 0.5248\n",
            "Epoch 14/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.4102 - accuracy: 0.5413\n",
            "Epoch 15/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3438 - accuracy: 0.5380\n",
            "Epoch 16/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3049 - accuracy: 0.5446\n",
            "Epoch 17/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2715 - accuracy: 0.5545\n",
            "Epoch 18/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.2348 - accuracy: 0.5578\n",
            "Epoch 19/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1908 - accuracy: 0.5743\n",
            "Epoch 20/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1493 - accuracy: 0.5776\n",
            "Epoch 21/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1019 - accuracy: 0.5875\n",
            "Epoch 22/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.0571 - accuracy: 0.6007\n",
            "Epoch 23/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0310 - accuracy: 0.5974\n",
            "Epoch 24/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9847 - accuracy: 0.6106\n",
            "Epoch 25/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9618 - accuracy: 0.6139\n",
            "Epoch 26/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9212 - accuracy: 0.6139\n",
            "Epoch 27/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8984 - accuracy: 0.6073\n",
            "Epoch 28/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8718 - accuracy: 0.6073\n",
            "Epoch 29/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8491 - accuracy: 0.6172\n",
            "Epoch 30/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8238 - accuracy: 0.6205\n",
            "Epoch 31/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8017 - accuracy: 0.6205\n",
            "Epoch 32/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7878 - accuracy: 0.5974\n",
            "Epoch 33/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7538 - accuracy: 0.6139\n",
            "Epoch 34/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7474 - accuracy: 0.5974\n",
            "Epoch 35/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7227 - accuracy: 0.6040\n",
            "Epoch 36/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7037 - accuracy: 0.6139\n",
            "Epoch 37/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7070 - accuracy: 0.6007\n",
            "Epoch 38/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6821 - accuracy: 0.6172\n",
            "Epoch 39/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6791 - accuracy: 0.6238\n",
            "Epoch 40/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6672 - accuracy: 0.6337\n",
            "Epoch 41/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6603 - accuracy: 0.6205\n",
            "Epoch 42/100\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6543 - accuracy: 0.6271\n",
            "Epoch 43/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6541 - accuracy: 0.6205\n",
            "Epoch 44/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6474 - accuracy: 0.6205\n",
            "Epoch 45/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6462 - accuracy: 0.6271\n",
            "Epoch 46/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6417 - accuracy: 0.6205\n",
            "Epoch 47/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6410 - accuracy: 0.6238\n",
            "Epoch 48/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6398 - accuracy: 0.6205\n",
            "Epoch 49/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6377 - accuracy: 0.6337\n",
            "Epoch 50/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6407 - accuracy: 0.6304\n",
            "Epoch 51/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6447 - accuracy: 0.6271\n",
            "Epoch 52/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6397 - accuracy: 0.6205\n",
            "Epoch 53/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6363 - accuracy: 0.6172\n",
            "Epoch 54/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6372 - accuracy: 0.6205\n",
            "Epoch 55/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6366 - accuracy: 0.6271\n",
            "Epoch 56/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6349 - accuracy: 0.6370\n",
            "Epoch 57/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6354 - accuracy: 0.6337\n",
            "Epoch 58/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6442 - accuracy: 0.6271\n",
            "Epoch 59/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6321 - accuracy: 0.6238\n",
            "Epoch 60/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6326 - accuracy: 0.6238\n",
            "Epoch 61/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6320 - accuracy: 0.6436\n",
            "Epoch 62/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6396 - accuracy: 0.6304\n",
            "Epoch 63/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6415 - accuracy: 0.6337\n",
            "Epoch 64/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6309 - accuracy: 0.6304\n",
            "Epoch 65/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6345 - accuracy: 0.6238\n",
            "Epoch 66/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6584 - accuracy: 0.6370\n",
            "Epoch 67/100\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6439 - accuracy: 0.6238\n",
            "Epoch 68/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6383 - accuracy: 0.6271\n",
            "Epoch 69/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6301 - accuracy: 0.6271\n",
            "Epoch 70/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6338 - accuracy: 0.6304\n",
            "Epoch 71/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6299 - accuracy: 0.6469\n",
            "Epoch 72/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6336 - accuracy: 0.6172\n",
            "Epoch 73/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6367 - accuracy: 0.6172\n",
            "Epoch 74/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6339 - accuracy: 0.6370\n",
            "Epoch 75/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6293 - accuracy: 0.6172\n",
            "Epoch 76/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6304 - accuracy: 0.6403\n",
            "Epoch 77/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6304 - accuracy: 0.6337\n",
            "Epoch 78/100\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6289 - accuracy: 0.6304\n",
            "Epoch 79/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6334 - accuracy: 0.6337\n",
            "Epoch 80/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6334 - accuracy: 0.6304\n",
            "Epoch 81/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6286 - accuracy: 0.6271\n",
            "Epoch 82/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6360 - accuracy: 0.6370\n",
            "Epoch 83/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6342 - accuracy: 0.6337\n",
            "Epoch 84/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6335 - accuracy: 0.6337\n",
            "Epoch 85/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6281 - accuracy: 0.6370\n",
            "Epoch 86/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6311 - accuracy: 0.6403\n",
            "Epoch 87/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6275 - accuracy: 0.6271\n",
            "Epoch 88/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6349 - accuracy: 0.6271\n",
            "Epoch 89/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6309 - accuracy: 0.6172\n",
            "Epoch 90/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6267 - accuracy: 0.6271\n",
            "Epoch 91/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6271 - accuracy: 0.6370\n",
            "Epoch 92/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6286 - accuracy: 0.6469\n",
            "Epoch 93/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6406 - accuracy: 0.6172\n",
            "Epoch 94/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6286 - accuracy: 0.6403\n",
            "Epoch 95/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6354 - accuracy: 0.6403\n",
            "Epoch 96/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6326 - accuracy: 0.6436\n",
            "Epoch 97/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6376 - accuracy: 0.6337\n",
            "Epoch 98/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6421 - accuracy: 0.6469\n",
            "Epoch 99/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6261 - accuracy: 0.6304\n",
            "Epoch 100/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6318 - accuracy: 0.6304\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1aa9a0c8d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnihA4KvJ2V3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f4344358-5b7d-4eb5-8a89-0887ae45fea2"
      },
      "source": [
        "score = model.evaluate(X,y,verbose = False)\n",
        "print(f\"{model.metrics_names[1]}: {score[1]*100}\")"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 64.02640342712402\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijHua4yDMb33",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rs8R5xxHN9O7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 890
        },
        "outputId": "5c49ed4b-6c07-4599-f72e-f7bd2bc878b4"
      },
      "source": [
        "# batch_size\n",
        "\n",
        "def create():\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    model.add(Dense(2,input_dim = 13,activation = 'relu'))\n",
        "    model.add(Dense(4,activation = 'relu'))\n",
        "    model.add(Dense(1,activation = 'sigmoid'))\n",
        "    model.compile(loss = 'binary_crossentropy',optimizer = 'adam', metrics = ['accuracy'])\n",
        "    return model\n",
        "    \n",
        "model2 = KerasClassifier(build_fn = create)\n",
        "\n",
        "parameters = {'batch_size': [10,20,50,80,100],\n",
        "             'epochs':[20]}\n",
        "\n",
        "grid = GridSearchCV(estimator = model2, param_grid = parameters, n_jobs = -1)\n",
        "grid_result = grid.fit(X,y)\n",
        "\n",
        "# Report Results\n",
        "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\")\n"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 1.0452 - accuracy: 0.4818\n",
            "Epoch 2/20\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.9039 - accuracy: 0.4719\n",
            "Epoch 3/20\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.8315 - accuracy: 0.4554\n",
            "Epoch 4/20\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.7849 - accuracy: 0.4653\n",
            "Epoch 5/20\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.7457 - accuracy: 0.4884\n",
            "Epoch 6/20\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.7233 - accuracy: 0.5017\n",
            "Epoch 7/20\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.7079 - accuracy: 0.5182\n",
            "Epoch 8/20\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.7003 - accuracy: 0.5380\n",
            "Epoch 9/20\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.6968 - accuracy: 0.5380\n",
            "Epoch 10/20\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6961 - accuracy: 0.5347\n",
            "Epoch 11/20\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6950 - accuracy: 0.5347\n",
            "Epoch 12/20\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6927 - accuracy: 0.5380\n",
            "Epoch 13/20\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6925 - accuracy: 0.5380\n",
            "Epoch 14/20\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6913 - accuracy: 0.5446\n",
            "Epoch 15/20\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5347\n",
            "Epoch 16/20\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6899 - accuracy: 0.5413\n",
            "Epoch 17/20\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6892 - accuracy: 0.5545\n",
            "Epoch 18/20\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6892 - accuracy: 0.5479\n",
            "Epoch 19/20\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.6896 - accuracy: 0.5545\n",
            "Epoch 20/20\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6919 - accuracy: 0.5314\n",
            "Best: 0.5969945311546325 using {'batch_size': 10, 'epochs': 20}\n",
            "Means: 0.5969945311546325, Stdev: 0.05034264976605319 with: {'batch_size': 10, 'epochs': 20}\n",
            "Means: 0.5278142094612122, Stdev: 0.05688164866137129 with: {'batch_size': 20, 'epochs': 20}\n",
            "Means: 0.5575409770011902, Stdev: 0.06705779915455844 with: {'batch_size': 50, 'epochs': 20}\n",
            "Means: 0.47836064696311953, Stdev: 0.08119074141061675 with: {'batch_size': 80, 'epochs': 20}\n",
            "Means: 0.5518032670021057, Stdev: 0.1185195985439908 with: {'batch_size': 100, 'epochs': 20}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlLgP6KjOpHu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        },
        "outputId": "1b6466a3-3295-437a-ffb5-5662b0395557"
      },
      "source": [
        "# optimizer\n",
        "\n",
        "def create(opt='adam'):\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    model.add(Dense(2,input_dim = 13,activation = 'relu'))\n",
        "    model.add(Dense(4,activation = 'relu'))\n",
        "    model.add(Dense(1,activation = 'sigmoid'))\n",
        "    model.compile(loss = 'binary_crossentropy',optimizer = opt, metrics = ['accuracy'])\n",
        "    return model\n",
        "    \n",
        "model2 = KerasClassifier(build_fn = create)\n",
        "\n",
        "parameters = {'batch_size': [10],\n",
        "              'opt': ['sgd', 'adam', 'nadam', 'rmsprop'],\n",
        "             'epochs':[20]}\n",
        "\n",
        "grid = GridSearchCV(estimator = model2, param_grid = parameters, n_jobs = -1)\n",
        "grid_result = grid.fit(X,y)\n",
        "\n",
        "# Report Results\n",
        "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\")\n"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 32.9003 - accuracy: 0.4554\n",
            "Epoch 2/20\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 18.3985 - accuracy: 0.4554\n",
            "Epoch 3/20\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 9.8283 - accuracy: 0.4554\n",
            "Epoch 4/20\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 4.1620 - accuracy: 0.4554\n",
            "Epoch 5/20\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 1.0304 - accuracy: 0.4488\n",
            "Epoch 6/20\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.7447 - accuracy: 0.5116\n",
            "Epoch 7/20\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.7307 - accuracy: 0.5380\n",
            "Epoch 8/20\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.7301 - accuracy: 0.5281\n",
            "Epoch 9/20\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.7212 - accuracy: 0.5017\n",
            "Epoch 10/20\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.7168 - accuracy: 0.5314\n",
            "Epoch 11/20\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.7146 - accuracy: 0.5215\n",
            "Epoch 12/20\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.7092 - accuracy: 0.5314\n",
            "Epoch 13/20\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.7058 - accuracy: 0.5281\n",
            "Epoch 14/20\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.7137 - accuracy: 0.5314\n",
            "Epoch 15/20\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.7092 - accuracy: 0.5017\n",
            "Epoch 16/20\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.7023 - accuracy: 0.5182\n",
            "Epoch 17/20\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.7037 - accuracy: 0.5050\n",
            "Epoch 18/20\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.7045 - accuracy: 0.4983\n",
            "Epoch 19/20\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.7008 - accuracy: 0.5248\n",
            "Epoch 20/20\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.7036 - accuracy: 0.4884\n",
            "Best: 0.6469398856163024 using {'batch_size': 10, 'epochs': 20, 'opt': 'adam'}\n",
            "Means: 0.5442076444625854, Stdev: 0.0688642466162586 with: {'batch_size': 10, 'epochs': 20, 'opt': 'sgd'}\n",
            "Means: 0.6469398856163024, Stdev: 0.07438729787247701 with: {'batch_size': 10, 'epochs': 20, 'opt': 'adam'}\n",
            "Means: 0.4720218539237976, Stdev: 0.07595286950126712 with: {'batch_size': 10, 'epochs': 20, 'opt': 'nadam'}\n",
            "Means: 0.5738797783851624, Stdev: 0.07068123317750034 with: {'batch_size': 10, 'epochs': 20, 'opt': 'rmsprop'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Wy-7EdHPIND",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        },
        "outputId": "51b96eff-1a7a-41b5-cada-5b6cfdb3f191"
      },
      "source": [
        "# learning_rate\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "\n",
        "def create(lr=0.1):\n",
        "    # create model\n",
        "    opt = Adam(learning_rate=lr)\n",
        "    model = Sequential()\n",
        "    model.add(Dense(2,input_dim = 13,activation = 'relu'))\n",
        "    model.add(Dense(4,activation = 'relu'))\n",
        "    model.add(Dense(1,activation = 'sigmoid'))\n",
        "    model.compile(loss = 'binary_crossentropy',optimizer = opt, metrics = ['accuracy'])\n",
        "    return model\n",
        "    \n",
        "model2 = KerasClassifier(build_fn = create)\n",
        "\n",
        "parameters = {'batch_size': [10],\n",
        "              'lr': [0.001, 0.01, 0.1, 0.2],\n",
        "             'epochs':[20]}\n",
        "\n",
        "grid = GridSearchCV(estimator = model2, param_grid = parameters, n_jobs = -1)\n",
        "grid_result = grid.fit(X,y)\n",
        "\n",
        "# Report Results\n",
        "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\")\n"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 7.4571 - accuracy: 0.4059\n",
            "Epoch 2/20\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.8362 - accuracy: 0.4752\n",
            "Epoch 3/20\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.6955 - accuracy: 0.5413\n",
            "Epoch 4/20\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.7016 - accuracy: 0.5116\n",
            "Epoch 5/20\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6995 - accuracy: 0.5050\n",
            "Epoch 6/20\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.6870 - accuracy: 0.5479\n",
            "Epoch 7/20\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5215\n",
            "Epoch 8/20\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6838 - accuracy: 0.5413\n",
            "Epoch 9/20\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6959 - accuracy: 0.5149\n",
            "Epoch 10/20\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6925 - accuracy: 0.5446\n",
            "Epoch 11/20\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6950 - accuracy: 0.5050\n",
            "Epoch 12/20\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6913 - accuracy: 0.5446\n",
            "Epoch 13/20\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6919 - accuracy: 0.5446\n",
            "Epoch 14/20\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6894 - accuracy: 0.5413\n",
            "Epoch 15/20\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6901 - accuracy: 0.5314\n",
            "Epoch 16/20\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.6871 - accuracy: 0.5446\n",
            "Epoch 17/20\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6889 - accuracy: 0.5446\n",
            "Epoch 18/20\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.6862 - accuracy: 0.5380\n",
            "Epoch 19/20\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5446\n",
            "Epoch 20/20\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6859 - accuracy: 0.5446\n",
            "Best: 0.6402185678482055 using {'batch_size': 10, 'epochs': 20, 'lr': 0.01}\n",
            "Means: 0.5408743143081665, Stdev: 0.06890655321135701 with: {'batch_size': 10, 'epochs': 20, 'lr': 0.001}\n",
            "Means: 0.6402185678482055, Stdev: 0.06261144905304364 with: {'batch_size': 10, 'epochs': 20, 'lr': 0.01}\n",
            "Means: 0.5442076444625854, Stdev: 0.0688642466162586 with: {'batch_size': 10, 'epochs': 20, 'lr': 0.1}\n",
            "Means: 0.4491256892681122, Stdev: 0.06409685065741068 with: {'batch_size': 10, 'epochs': 20, 'lr': 0.2}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_La9CiUyQSx9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 852
        },
        "outputId": "30ece2aa-3777-4ad7-aef5-77beb9b84550"
      },
      "source": [
        "# activation_function\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "\n",
        "def create(act='relu'):\n",
        "    # create model\n",
        "    opt = Adam(learning_rate=0.01)\n",
        "    model = Sequential()\n",
        "    model.add(Dense(2,input_dim = 13,activation = act))\n",
        "    model.add(Dense(4,activation = 'relu'))\n",
        "    model.add(Dense(1,activation = 'sigmoid'))\n",
        "    model.compile(loss = 'binary_crossentropy',optimizer = opt, metrics = ['accuracy'])\n",
        "    return model\n",
        "    \n",
        "model2 = KerasClassifier(build_fn = create)\n",
        "\n",
        "parameters = {'batch_size': [10],\n",
        "              'act': ['sigmoid', 'elu', 'relu', 'selu', 'softplus', 'tanh'],\n",
        "             'epochs':[20]}\n",
        "\n",
        "grid = GridSearchCV(estimator = model2, param_grid = parameters, n_jobs = -1)\n",
        "grid_result = grid.fit(X,y)\n",
        "\n",
        "# Report Results\n",
        "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\")"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 5.1065 - accuracy: 0.4587\n",
            "Epoch 2/20\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.7037 - accuracy: 0.4554\n",
            "Epoch 3/20\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.6946 - accuracy: 0.4719\n",
            "Epoch 4/20\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6913 - accuracy: 0.5446\n",
            "Epoch 5/20\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6905 - accuracy: 0.5446\n",
            "Epoch 6/20\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6902 - accuracy: 0.5446\n",
            "Epoch 7/20\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6898 - accuracy: 0.5446\n",
            "Epoch 8/20\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6896 - accuracy: 0.5446\n",
            "Epoch 9/20\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6897 - accuracy: 0.5446\n",
            "Epoch 10/20\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6895 - accuracy: 0.5446\n",
            "Epoch 11/20\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6897 - accuracy: 0.5446\n",
            "Epoch 12/20\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.6893 - accuracy: 0.5446\n",
            "Epoch 13/20\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6898 - accuracy: 0.5446\n",
            "Epoch 14/20\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6894 - accuracy: 0.5446\n",
            "Epoch 15/20\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6895 - accuracy: 0.5446\n",
            "Epoch 16/20\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 0.6893 - accuracy: 0.5446\n",
            "Epoch 17/20\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6894 - accuracy: 0.5446\n",
            "Epoch 18/20\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6896 - accuracy: 0.5446\n",
            "Epoch 19/20\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6899 - accuracy: 0.5446\n",
            "Epoch 20/20\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6897 - accuracy: 0.5446\n",
            "Best: 0.6272677540779114 using {'act': 'elu', 'batch_size': 10, 'epochs': 20}\n",
            "Means: 0.5442076444625854, Stdev: 0.0688642466162586 with: {'act': 'sigmoid', 'batch_size': 10, 'epochs': 20}\n",
            "Means: 0.6272677540779114, Stdev: 0.09595702627963917 with: {'act': 'elu', 'batch_size': 10, 'epochs': 20}\n",
            "Means: 0.5933879733085632, Stdev: 0.10428348094149137 with: {'act': 'relu', 'batch_size': 10, 'epochs': 20}\n",
            "Means: 0.5475409746170044, Stdev: 0.06362049574558594 with: {'act': 'selu', 'batch_size': 10, 'epochs': 20}\n",
            "Means: 0.5375409722328186, Stdev: 0.0695904512554932 with: {'act': 'softplus', 'batch_size': 10, 'epochs': 20}\n",
            "Means: 0.5442076444625854, Stdev: 0.0688642466162586 with: {'act': 'tanh', 'batch_size': 10, 'epochs': 20}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}