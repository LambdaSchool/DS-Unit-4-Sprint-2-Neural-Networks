{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2*\n",
    "\n",
    "# Sprint Challenge - Neural Network Foundations\n",
    "\n",
    "Table of Problems\n",
    "\n",
    "1. [Defining Neural Networks](#Q1)\n",
    "2. [Perceptron on XOR Gates](#Q2)\n",
    "3. [Multilayer Perceptron](#Q3)\n",
    "4. [Keras MMP](#Q4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Q1\"></a>\n",
    "## 1. Define the following terms:\n",
    "\n",
    "- **Neuron:**\n",
    "A Neuron is the basic unit of a neural network. It takes N inputs, weighs them and optionally applies a bias. It then applies an activation function to the sum of all inputs, weights, and bias. Depending on the actiation function, the neuron might activate, not activate, or send a weak signal to the next layer. \n",
    "- **Input Layer:**\n",
    "The input layer is the first layer of the neural network, it will have number of nodes equal to the number of features in the data and apply no activation function, but pass the inputs to the first hidden layer.\n",
    "- **Hidden Layer:**\n",
    "The hidden layers do not produce inputs or outputs, they are made up of neurons and behave due to the above description of neurons: they apply weights to the inputs they receive, may add bias, and then apply an activation function, possibly activating and sending a signal to the next layer.\n",
    "\n",
    "- **Output Layer:**\n",
    "The output layer will determine the shape of the output from the neural network, for a regression function, it will be a single neuron applying a linear function to the input.\n",
    "\n",
    "For a binary classification function, it will use a binary activation function, for a multi-classificaiton function, it will use a softmax function.\n",
    "\n",
    "The number of neurons in the output layer will correspond to the number of output features.\n",
    "\n",
    "- **Activation:**\n",
    "\n",
    "Neurons activate according to their activation functions. Sigmoid, Relu, and step are some possible functions, based on the inputs and weights (and bias) applied to the inputs, the function will (or will not) produce an output.\n",
    "\n",
    "Choosing the activation function depends on the nature of the problem. Relu functions produce a linearly increasing output once the input signal is above zero, and nothing when the input signal is below zero. \n",
    "\n",
    "Step functions produce a signal of 1 if the input signal is above zero, and zero below it.\n",
    "\n",
    "Sigmoid (or tanh which is a transformed sigmoid function) provide a signal of 1 at high inputs and zero at low inputs, with an inbetween output signal between 6 and -6.\n",
    "\n",
    "- **Backpropagation:**\n",
    "\n",
    "The process by which neural networks learn. During training, the outputs of the neural network are compared to the true y values to generate an error term, this error term is multiplied by the derivative of the activation function of the output of each layer of the neural network (except the input layer that has no activation function) to create a delta term. The weights of the inputs to each layer are then multiplied by delta term.\n",
    "\n",
    "Intuitively, we are updating the weights of inputs to our layers by the derivative of our activation functions so as to reduce the error or loss function of our model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Perceptron on AND Gates <a id=\"Q3=2\"></a>\n",
    "\n",
    "Create a perceptron class that can model the behavior of an AND gate. You can use the following table as your training data:\n",
    "\n",
    "|x1\t|x2|x3|\ty|\n",
    "|---|---|---|---|\n",
    "1|\t1|\t1|\t1|\n",
    "1|\t0|\t1|\t0|\n",
    "0|\t1|\t1|\t0|\n",
    "0|\t0|\t1|\t0|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# first we format our inputs and outputs\n",
    "\n",
    "inputs = np.array(([1,1,1, 0],\n",
    "                   [1,0,1, 0],\n",
    "                   [0,1,1, 0],\n",
    "                   [0,0,1, 0]), dtype=float)\n",
    "\n",
    "correct_outputs = np.array(([1], [0], [0], [0]), dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a single perceptron neural network\n",
    "class Perceptron():\n",
    "    def __init__(self, input_size = 4, outputNodes = 1):\n",
    "  # Set up Architecture of neural network\n",
    "        self.input = input_size \n",
    "        self.outputNodes = outputNodes\n",
    "        # Initial Weights\n",
    "        # 3x4 matrix for first layer\n",
    "        self.weights1 = np.random.randn(self.input, self.outputNodes)\n",
    "        \n",
    "        \n",
    "    def sigmoid(self, s):\n",
    "        return 1 / (1 + np.exp(-s))\n",
    "    \n",
    "    def sigmoidPrime(self, s):\n",
    "        return s * (1 - s)\n",
    "    \n",
    "    def feed_forward(self, X):\n",
    "        \"\"\"\n",
    "        Calculate the NN inference using feed forawrd\n",
    "\n",
    "        \"\"\"\n",
    "        #weighted sum of inputs and hidden layer\n",
    "        self.hidden_sum = np.dot(X, self.weights1)\n",
    "        #Activations of weighted sums\n",
    "        self.activated_output = self.sigmoid(self.hidden_sum)\n",
    "        \n",
    "\n",
    "\n",
    "        return self.activated_output\n",
    "    \n",
    "    def get_attributes(self):\n",
    "        \n",
    "        attributes = ['weights1', 'hidden_sum', 'activated_hidden', 'weights2', 'output']\n",
    "\n",
    "        [print(i + '\\n', getattr(nn,i), '\\n' + '---'*3) for i in dir(nn) if i in attributes]\n",
    "\n",
    "    def backward(self, X, y, o):\n",
    "        \"\"\"\n",
    "        Backward propagate through the network\n",
    "        \"\"\"\n",
    "        self.o_error = y - o #error in output\n",
    "        self.o_delta = self.o_error * self.sigmoidPrime(o) \n",
    "        # apply derivative of sigmoid to error\n",
    "\n",
    "        self.weights1 += X.T.dot(self.o_delta) #Adjust first set (input => hidden) weights\n",
    "\n",
    "    def train(self, X, y):\n",
    "        o = self.feed_forward(X)\n",
    "        self.backward(X, y, o)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------EPOCH 1---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 2---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 3---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 4---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 5---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 50---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 100---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 150---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 200---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 250---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 300---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 350---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 400---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 450---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 500---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 550---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 600---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 650---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 700---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 750---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 800---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 850---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 900---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 950---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 1000---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 1050---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 1100---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 1150---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 1200---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 1250---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 1300---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 1350---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 1400---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 1450---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 1500---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 1550---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 1600---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 1650---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 1700---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 1750---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 1800---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 1850---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 1900---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 1950---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 2000---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 2050---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 2100---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 2150---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 2200---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 2250---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 2300---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 2350---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 2400---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 2450---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 2500---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 2550---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 2600---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 2650---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 2700---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 2750---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 2800---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 2850---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 2900---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 2950---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 3000---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 3050---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 3100---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 3150---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 3200---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 3250---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 3300---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 3350---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 3400---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 3450---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 3500---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 3550---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 3600---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 3650---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 3700---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 3750---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 3800---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 3850---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 3900---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 3950---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 4000---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 4050---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 4100---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 4150---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 4200---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 4250---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 4300---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 4350---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 4400---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 4450---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 4500---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 4550---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 4600---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 4650---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 4700---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 4750---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 4800---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 4850---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 4900---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 4950---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 5000---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 5050---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 5100---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 5150---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 5200---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 5250---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 5300---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 5350---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 5400---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 5450---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 5500---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 5550---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 5600---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 5650---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 5700---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 5750---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 5800---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 5850---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 5900---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 5950---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 6000---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 6050---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 6100---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 6150---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 6200---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 6250---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 6300---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 6350---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 6400---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 6450---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 6500---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 6550---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 6600---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 6650---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 6700---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 6750---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 6800---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 6850---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 6900---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 6950---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 7000---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 7050---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 7100---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 7150---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 7200---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 7250---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 7300---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 7350---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 7400---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 7450---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 7500---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 7550---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 7600---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 7650---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 7700---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 7750---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 7800---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 7850---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 7900---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 7950---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 8000---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 8050---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 8100---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 8150---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 8200---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 8250---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 8300---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 8350---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 8400---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 8450---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 8500---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 8550---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 8600---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 8650---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 8700---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 8750---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 8800---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 8850---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 8900---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 8950---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 9000---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 9050---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 9100---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 9150---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 9200---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 9250---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 9300---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 9350---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 9400---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 9450---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 9500---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 9550---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 9600---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 9650---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 9700---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 9750---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 9800---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 9850---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 9900---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 9950---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n",
      "+---------EPOCH 10000---------+\n",
      "Input: \n",
      " [[1. 1. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Actual Output: \n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      " [[0.68491864]\n",
      " [0.30493931]\n",
      " [0.68013858]\n",
      " [0.3002838 ]]\n",
      "Loss: \n",
      " 0.18625577549629527\n"
     ]
    }
   ],
   "source": [
    "p = Perceptron()\n",
    "\n",
    "X = inputs\n",
    "y = correct_outputs\n",
    "\n",
    "for i in range(10000):\n",
    "    if (i+1 in [1,2,3,4,5]) or ((i+1) % 50 ==0):\n",
    "        print('+' + '---' * 3 + f'EPOCH {i+1}' + '---'*3 + '+')\n",
    "        print('Input: \\n', X)\n",
    "        print('Actual Output: \\n', y)\n",
    "        print('Predicted Output: \\n', str(p.feed_forward(X)))\n",
    "        print(\"Loss: \\n\", str(np.mean(np.square(y - p.feed_forward(X)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my loss function is not reducing, not sure why"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Multilayer Perceptron <a id=\"Q3\"></a>\n",
    "\n",
    "Implement a Neural Network Multilayer Perceptron class that uses backpropagation to update the network's weights.\n",
    "Your network must have one hidden layer.\n",
    "You do not have to update weights via gradient descent. You can use something like the derivative of the sigmoid function to update weights.\n",
    "Train your model on the Heart Disease dataset from UCI:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "# download data and seperate columns into categorical vs continuous values\n",
    "\n",
    "colnames = ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', \n",
    "            'restecg', 'thalach', 'exang', 'oldspeak', 'slope', 'ca', 'thal', 'target']\n",
    "\n",
    "onehot = ['sex', 'cp', 'fbs', 'restecg','exang', 'slope', 'ca', 'thal']\n",
    "\n",
    "scale = ['age', 'trestbps', 'chol', 'thalach', 'oldspeak' ]\n",
    "\n",
    "df = pd.read_csv('processed.cleveland.data', names=colnames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean out some nans, cast object columns to numeric and encode the target as a \n",
    "# binary variable\n",
    "df.replace('?', np.nan, inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "df['ca'] = pd.to_numeric(df['ca']) \n",
    "df['thal'] = pd.to_numeric(df['thal'])\n",
    "df['target'] = df['target'].map({0:0, 1:1, 2:1, 3:1, 4:1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode data using a column transformer\n",
    "cleaning_trans = ColumnTransformer(\n",
    "    [\n",
    "    ('scaler', StandardScaler(), scale),\n",
    "    ('hot', OneHotEncoder(), onehot)],\n",
    "    n_jobs=-1, remainder='passthrough', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((297, 13), (297,))"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaning_trans.fit_transform(df)\n",
    "X = df.drop(columns='target').values\n",
    "y = df['target'].values\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "class NueralNetwork():\n",
    "    def __init__(self, input_size = 13, hiddenNodes = 13, outputNodes = 1):\n",
    "#     def __init__(self, input_size, hiddenNodes, outputNodes):\n",
    "        # Set up Architecture of neural network\n",
    "        self.input = input_size \n",
    "        self.hiddenNodes = hiddenNodes\n",
    "        self.outputNodes = outputNodes\n",
    "        \n",
    "        # Initial Weights\n",
    "        # 3x4 matrix for first layer\n",
    "        self.weights1 = np.random.randn(self.input, self.hiddenNodes)\n",
    "        #4x1 matrix for hidden to output layer\n",
    "        self.weights2 = np.random.randn(self.hiddenNodes, self.outputNodes)\n",
    "        \n",
    "    def sigmoid(self, s):\n",
    "        return 1 / (1 + np.exp(-s))\n",
    "    \n",
    "    def sigmoidPrime(self, s):\n",
    "        return s * (1 - s)\n",
    "    \n",
    "    def feed_forward(self, X):\n",
    "        \"\"\"\n",
    "        Calculate the NN inference using feed forawrd\n",
    "\n",
    "        \"\"\"\n",
    "        #weighted sum of inputs and hidden layer\n",
    "        self.hidden_sum = np.dot(X, self.weights1)\n",
    "        \n",
    "        #Activations of weighted sums\n",
    "        self.activated_hidden = self.sigmoid(self.hidden_sum)\n",
    "        \n",
    "\n",
    "        #Weighted sum between hidden and output\n",
    "        self.output_sum = np.dot(self.activated_hidden, self.weights2)\n",
    "\n",
    "        # Final Activation of output\n",
    "        self.activated_output = self.sigmoid(self.output_sum)\n",
    "\n",
    "\n",
    "        return self.activated_output\n",
    "    \n",
    "    def get_attributes(self):\n",
    "        \n",
    "        attributes = ['weights1', 'hidden_sum', 'activated_hidden', 'weights2', 'output']\n",
    "\n",
    "        [print(i + '\\n', getattr(nn,i), '\\n' + '---'*3) for i in dir(nn) if i in attributes]\n",
    "\n",
    "    def backward(self, X, y, o):\n",
    "        \"\"\"\n",
    "        Backward propagate through the network\n",
    "        \"\"\"\n",
    "        self.o_error = y - o #error in output\n",
    "        self.o_delta = self.o_error * self.sigmoidPrime(o) # apply derivative of sigmoid to error\n",
    "\n",
    "        self.z2_error = self.o_delta.dot(self.weights2.T) # z2 error: how much our hidden layer weights were off\n",
    "        self.z2_delta = self.z2_error*self.sigmoidPrime(self.activated_hidden)\n",
    "\n",
    "        self.weights2 += self.activated_hidden.T.dot(self.o_delta) #adjust second set (hidden => output) weights\n",
    "        self.weights1 += X.T.dot(self.z2_delta) #Adjust first set (input => hidden) weights\n",
    "\n",
    "    def train(self, X, y):\n",
    "        o = self.feed_forward(X)\n",
    "        self.backward(X, y, o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((297, 1), (297, 13))"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshape y for network compatibility\n",
    "y = y.reshape(-1,1)\n",
    "y.shape, X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------EPOCH 1---------+\n",
      "Input: \n",
      " [[63.  1.  1. ...  3.  0.  6.]\n",
      " [67.  1.  4. ...  2.  3.  3.]\n",
      " [67.  1.  4. ...  2.  2.  7.]\n",
      " ...\n",
      " [68.  1.  4. ...  2.  2.  7.]\n",
      " [57.  1.  4. ...  2.  1.  7.]\n",
      " [57.  0.  2. ...  2.  1.  3.]]\n",
      "Loss: \n",
      " 0.42392537888364434\n",
      "+---------EPOCH 2---------+\n",
      "Input: \n",
      " [[63.  1.  1. ...  3.  0.  6.]\n",
      " [67.  1.  4. ...  2.  3.  3.]\n",
      " [67.  1.  4. ...  2.  2.  7.]\n",
      " ...\n",
      " [68.  1.  4. ...  2.  2.  7.]\n",
      " [57.  1.  4. ...  2.  1.  7.]\n",
      " [57.  0.  2. ...  2.  1.  3.]]\n",
      "Loss: \n",
      " 0.5387205387205387\n",
      "+---------EPOCH 3---------+\n",
      "Input: \n",
      " [[63.  1.  1. ...  3.  0.  6.]\n",
      " [67.  1.  4. ...  2.  3.  3.]\n",
      " [67.  1.  4. ...  2.  2.  7.]\n",
      " ...\n",
      " [68.  1.  4. ...  2.  2.  7.]\n",
      " [57.  1.  4. ...  2.  1.  7.]\n",
      " [57.  0.  2. ...  2.  1.  3.]]\n",
      "Loss: \n",
      " 0.5387205387205387\n",
      "+---------EPOCH 4---------+\n",
      "Input: \n",
      " [[63.  1.  1. ...  3.  0.  6.]\n",
      " [67.  1.  4. ...  2.  3.  3.]\n",
      " [67.  1.  4. ...  2.  2.  7.]\n",
      " ...\n",
      " [68.  1.  4. ...  2.  2.  7.]\n",
      " [57.  1.  4. ...  2.  1.  7.]\n",
      " [57.  0.  2. ...  2.  1.  3.]]\n",
      "Loss: \n",
      " 0.5387205387205387\n",
      "+---------EPOCH 5---------+\n",
      "Input: \n",
      " [[63.  1.  1. ...  3.  0.  6.]\n",
      " [67.  1.  4. ...  2.  3.  3.]\n",
      " [67.  1.  4. ...  2.  2.  7.]\n",
      " ...\n",
      " [68.  1.  4. ...  2.  2.  7.]\n",
      " [57.  1.  4. ...  2.  1.  7.]\n",
      " [57.  0.  2. ...  2.  1.  3.]]\n",
      "Loss: \n",
      " 0.5387205387205387\n",
      "+---------EPOCH 1000---------+\n",
      "Input: \n",
      " [[63.  1.  1. ...  3.  0.  6.]\n",
      " [67.  1.  4. ...  2.  3.  3.]\n",
      " [67.  1.  4. ...  2.  2.  7.]\n",
      " ...\n",
      " [68.  1.  4. ...  2.  2.  7.]\n",
      " [57.  1.  4. ...  2.  1.  7.]\n",
      " [57.  0.  2. ...  2.  1.  3.]]\n",
      "Loss: \n",
      " 0.5387205387205387\n"
     ]
    }
   ],
   "source": [
    "new_nn = NueralNetwork()\n",
    "\n",
    "for i in range(1000):\n",
    "    if (i+1 in [1,2,3,4,5]) or ((i+1) % 1000 ==0):\n",
    "        print('+' + '---' * 3 + f'EPOCH {i+1}' + '---'*3 + '+')\n",
    "        print('Input: \\n', X)\n",
    "#         print('Actual Output: \\n', y)\n",
    "#         print('Predicted Output: \\n', str(new_nn.feed_forward(X)))\n",
    "        print(\"Loss: \\n\", str(np.mean(np.square(y - new_nn.feed_forward(X)))))\n",
    "    new_nn.train(X, y)\n",
    "# print(\"Loss: \\n\", str(np.mean(np.square(y - new_nn.feed_forward(X)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss increases, again not sure why"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Keras MMP <a id=\"Q4\"></a>\n",
    "\n",
    "Implement a Multilayer Perceptron architecture of your choosing using the Keras library. Train your model and report its baseline accuracy. Then hyperparameter tune at least two parameters and report your model's accuracy.\n",
    "Use the Heart Disease Dataset (binary classification)\n",
    "Use an appropriate loss function for a binary classification task\n",
    "Use an appropriate activation function on the final layer of your network.\n",
    "Train your model using verbose output for ease of grading.\n",
    "Use GridSearchCV to hyperparameter tune your model. (for at least two hyperparameters)\n",
    "When hyperparameter tuning, show you work by adding code cells for each new experiment.\n",
    "Report the accuracy for each combination of hyperparameters as you test them so that we can easily see which resulted in the highest accuracy.\n",
    "You must hyperparameter tune at least 5 parameters in order to get a 3 on this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "# create a baseline model\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Random Seed\n",
    "seed = 2001\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Important Hyperparameters\n",
    "inputs = X.shape[1]\n",
    "epochs = 150\n",
    "batch_size = 20\n",
    "\n",
    "# Create our model\n",
    "model = Sequential()\n",
    "\n",
    "# input and hidden\n",
    "model.add(Dense(16, input_dim = inputs, activation='relu'))\n",
    "# model.add(Dropout(0.3))\n",
    "# model.add(Dense(64, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "\n",
    "#compile\n",
    "model.compile(loss='binary_crossentropy',\n",
    "               optimizer = 'adam',\n",
    "               metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Manual Validation Dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, \n",
    "                                                    random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 18us/sample - loss: 7.6666 - acc: 0.5000\n",
      "acc: 50.0\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=batch_size, epochs = epochs, validation_split=.1, verbose =0)\n",
    "scores = model.evaluate(X_test, y_test)\n",
    "print(f'{model.metrics_names[1]}: {scores[1]*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now to hyper paramater tune\n",
    "# I'm going to optimize batch size \n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "# Random Seed\n",
    "seed = 2001\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Important Hyperparameters\n",
    "inputs = X.shape[1]\n",
    "# epochs = 50\n",
    "# batch_size = 32\n",
    "\n",
    "# Create our model function for the kerasclassifier wrapper\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    # input and hidden\n",
    "    model.add(Dense(32, input_dim = inputs, activation='relu'))\n",
    "#     model.add(Dropout(0.3))\n",
    "#     model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "\n",
    "    #compile\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                   optimizer = 'adam',\n",
    "                   metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "\n",
    "# create hyper paramaters to optomize\n",
    "param_grid = {'batch_size': [10, 20, 40, 60, 80, 100],\n",
    "              'epochs': [20]}\n",
    "\n",
    "# create a grid search\n",
    "grid = GridSearchCV(estimator=model, cv=3, param_grid=param_grid, n_jobs=-1, verbose=0)\n",
    "grid_results = grid.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.5420875350634257 using {'batch_size': 60, 'epochs': 20}\n",
      "Means: 0.49494948983192444, Stdev: 0.042854957712725565 with: {'batch_size': 10, 'epochs': 20}\n",
      "Means: 0.5050505002339681, Stdev: 0.04285494366377606 with: {'batch_size': 20, 'epochs': 20}\n",
      "Means: 0.5252525210380554, Stdev: 0.03298974560640662 with: {'batch_size': 40, 'epochs': 20}\n",
      "Means: 0.5420875350634257, Stdev: 0.04832558313939803 with: {'batch_size': 60, 'epochs': 20}\n",
      "Means: 0.5420875350634257, Stdev: 0.09523322062967969 with: {'batch_size': 80, 'epochs': 20}\n",
      "Means: 0.5353535215059916, Stdev: 0.021820670271058235 with: {'batch_size': 100, 'epochs': 20}\n"
     ]
    }
   ],
   "source": [
    "# Report Results\n",
    "print(f\"Best: {grid_results.best_score_} using {grid_results.best_params_}\")\n",
    "means = grid_results.cv_results_['mean_test_score']\n",
    "stds = grid_results.cv_results_['std_test_score']\n",
    "params = grid_results.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0719 10:13:08.547494 140187306571584 deprecation.py:506] From /home/nedderlander/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/optimizer_v2/adagrad.py:105: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 86us/sample - loss: 8.1777 - acc: 0.4667\n",
      "acc: 46.666666865348816\n"
     ]
    }
   ],
   "source": [
    "# batch size looks good at 60\n",
    "# now I will try different optimizer functions\n",
    "optimizers = ['Adam', 'Adagrad', 'Adadelta', 'Adamax']\n",
    "init_mode = ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']\n",
    "\n",
    "model = Sequential()\n",
    "# input and hidden\n",
    "model.add(Dense(32, input_dim = inputs, activation='relu'))\n",
    "#     model.add(Dropout(0.3))\n",
    "#     model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "\n",
    "#compile\n",
    "model.compile(loss='binary_crossentropy',\n",
    "               optimizer = 'adagrad',\n",
    "               metrics=['accuracy'])\n",
    "\n",
    "batch_size= 60\n",
    "epochs= 20\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size=batch_size, epochs = epochs, \n",
    "                    validation_split=.1, verbose =0)\n",
    "scores = model.evaluate(X_test, y_test)\n",
    "print(f'{model.metrics_names[1]}: {scores[1]*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 54us/sample - loss: 7.1983 - acc: 0.5333\n",
      "acc: 53.33333611488342\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# input and hidden\n",
    "model.add(Dense(32, input_dim = inputs, activation='relu'))\n",
    "#     model.add(Dropout(0.3))\n",
    "#     model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "\n",
    "#compile\n",
    "model.compile(loss='binary_crossentropy',\n",
    "               optimizer = 'adamax',\n",
    "               metrics=['accuracy'])\n",
    "\n",
    "batch_size= 60\n",
    "epochs= 20\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size=batch_size, epochs = epochs, \n",
    "                    validation_split=.1, verbose =0)\n",
    "scores = model.evaluate(X_test, y_test)\n",
    "print(f'{model.metrics_names[1]}: {scores[1]*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adamax seems to have a slight improvement\n",
    "# so I will tune epochs with the adamax optimizer\n",
    "\n",
    "# Random Seed\n",
    "seed = 2001\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Important Hyperparameters\n",
    "inputs = X.shape[1]\n",
    "# epochs = 50\n",
    "# batch_size = 32\n",
    "\n",
    "# Create our model function for the kerasclassifier wrapper\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    # input and hidden\n",
    "    model.add(Dense(32, input_dim = inputs, activation='relu'))\n",
    "#     model.add(Dropout(0.3))\n",
    "#     model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "\n",
    "    #compile\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                   optimizer = 'adamax',\n",
    "                   metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "\n",
    "# create hyper paramaters to optomize\n",
    "param_grid = {'batch_size': [60],\n",
    "              'epochs': [100, 150, 250],\n",
    "              'shuffle': [True, False],\n",
    "             'validation_data': [(X_test,y_test)],\n",
    "             'class_weight': [{0:1, 1:10}, {0:0.5, 1:100}]}\n",
    "\n",
    "# create a grid search\n",
    "grid = GridSearchCV(estimator=model, cv=3, param_grid=param_grid, n_jobs=-1, verbose=0)\n",
    "grid_results = grid.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.5280898809432983 using {'batch_size': 60, 'class_weight': {0: 0.5, 1: 100}, 'epochs': 100, 'shuffle': True, 'validation_data': (array([[6.50e+01, 1.00e+00, 4.00e+00, 1.20e+02, 1.77e+02, 0.00e+00,\n",
      "        0.00e+00, 1.40e+02, 0.00e+00, 4.00e-01, 1.00e+00, 0.00e+00,\n",
      "        7.00e+00],\n",
      "       [5.80e+01, 1.00e+00, 4.00e+00, 1.46e+02, 2.18e+02, 0.00e+00,\n",
      "        0.00e+00, 1.05e+02, 0.00e+00, 2.00e+00, 2.00e+00, 1.00e+00,\n",
      "        7.00e+00],\n",
      "       [4.70e+01, 1.00e+00, 4.00e+00, 1.10e+02, 2.75e+02, 0.00e+00,\n",
      "        2.00e+00, 1.18e+02, 1.00e+00, 1.00e+00, 2.00e+00, 1.00e+00,\n",
      "        3.00e+00],\n",
      "       [5.70e+01, 1.00e+00, 4.00e+00, 1.10e+02, 2.01e+02, 0.00e+00,\n",
      "        0.00e+00, 1.26e+02, 1.00e+00, 1.50e+00, 2.00e+00, 0.00e+00,\n",
      "        6.00e+00],\n",
      "       [3.40e+01, 1.00e+00, 1.00e+00, 1.18e+02, 1.82e+02, 0.00e+00,\n",
      "        2.00e+00, 1.74e+02, 0.00e+00, 0.00e+00, 1.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.60e+01, 0.00e+00, 1.00e+00, 1.50e+02, 2.26e+02, 0.00e+00,\n",
      "        0.00e+00, 1.14e+02, 0.00e+00, 2.60e+00, 3.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [4.70e+01, 1.00e+00, 3.00e+00, 1.30e+02, 2.53e+02, 0.00e+00,\n",
      "        0.00e+00, 1.79e+02, 0.00e+00, 0.00e+00, 1.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.00e+01, 1.00e+00, 3.00e+00, 1.40e+02, 1.85e+02, 0.00e+00,\n",
      "        2.00e+00, 1.55e+02, 0.00e+00, 3.00e+00, 2.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [5.40e+01, 0.00e+00, 2.00e+00, 1.32e+02, 2.88e+02, 1.00e+00,\n",
      "        2.00e+00, 1.59e+02, 1.00e+00, 0.00e+00, 1.00e+00, 1.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.40e+01, 1.00e+00, 4.00e+00, 1.20e+02, 2.46e+02, 0.00e+00,\n",
      "        2.00e+00, 9.60e+01, 1.00e+00, 2.20e+00, 3.00e+00, 1.00e+00,\n",
      "        3.00e+00],\n",
      "       [4.00e+01, 1.00e+00, 1.00e+00, 1.40e+02, 1.99e+02, 0.00e+00,\n",
      "        0.00e+00, 1.78e+02, 1.00e+00, 1.40e+00, 1.00e+00, 0.00e+00,\n",
      "        7.00e+00],\n",
      "       [4.20e+01, 1.00e+00, 1.00e+00, 1.48e+02, 2.44e+02, 0.00e+00,\n",
      "        2.00e+00, 1.78e+02, 0.00e+00, 8.00e-01, 1.00e+00, 2.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.90e+01, 1.00e+00, 1.00e+00, 1.60e+02, 2.34e+02, 1.00e+00,\n",
      "        2.00e+00, 1.31e+02, 0.00e+00, 1.00e-01, 2.00e+00, 1.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.90e+01, 0.00e+00, 1.00e+00, 1.40e+02, 2.39e+02, 0.00e+00,\n",
      "        0.00e+00, 1.51e+02, 0.00e+00, 1.80e+00, 1.00e+00, 2.00e+00,\n",
      "        3.00e+00],\n",
      "       [4.80e+01, 1.00e+00, 4.00e+00, 1.24e+02, 2.74e+02, 0.00e+00,\n",
      "        2.00e+00, 1.66e+02, 0.00e+00, 5.00e-01, 2.00e+00, 0.00e+00,\n",
      "        7.00e+00],\n",
      "       [5.80e+01, 1.00e+00, 4.00e+00, 1.25e+02, 3.00e+02, 0.00e+00,\n",
      "        2.00e+00, 1.71e+02, 0.00e+00, 0.00e+00, 1.00e+00, 2.00e+00,\n",
      "        7.00e+00],\n",
      "       [5.80e+01, 1.00e+00, 4.00e+00, 1.14e+02, 3.18e+02, 0.00e+00,\n",
      "        1.00e+00, 1.40e+02, 0.00e+00, 4.40e+00, 3.00e+00, 3.00e+00,\n",
      "        6.00e+00],\n",
      "       [5.30e+01, 1.00e+00, 4.00e+00, 1.40e+02, 2.03e+02, 1.00e+00,\n",
      "        2.00e+00, 1.55e+02, 1.00e+00, 3.10e+00, 3.00e+00, 0.00e+00,\n",
      "        7.00e+00],\n",
      "       [5.80e+01, 0.00e+00, 4.00e+00, 1.30e+02, 1.97e+02, 0.00e+00,\n",
      "        0.00e+00, 1.31e+02, 0.00e+00, 6.00e-01, 2.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.10e+01, 1.00e+00, 4.00e+00, 1.40e+02, 2.07e+02, 0.00e+00,\n",
      "        2.00e+00, 1.38e+02, 1.00e+00, 1.90e+00, 1.00e+00, 1.00e+00,\n",
      "        7.00e+00],\n",
      "       [4.40e+01, 1.00e+00, 3.00e+00, 1.40e+02, 2.35e+02, 0.00e+00,\n",
      "        2.00e+00, 1.80e+02, 0.00e+00, 0.00e+00, 1.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [4.90e+01, 1.00e+00, 3.00e+00, 1.18e+02, 1.49e+02, 0.00e+00,\n",
      "        2.00e+00, 1.26e+02, 0.00e+00, 8.00e-01, 1.00e+00, 3.00e+00,\n",
      "        3.00e+00],\n",
      "       [4.70e+01, 1.00e+00, 3.00e+00, 1.08e+02, 2.43e+02, 0.00e+00,\n",
      "        0.00e+00, 1.52e+02, 0.00e+00, 0.00e+00, 1.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [4.30e+01, 0.00e+00, 4.00e+00, 1.32e+02, 3.41e+02, 1.00e+00,\n",
      "        2.00e+00, 1.36e+02, 1.00e+00, 3.00e+00, 2.00e+00, 0.00e+00,\n",
      "        7.00e+00],\n",
      "       [5.60e+01, 0.00e+00, 2.00e+00, 1.40e+02, 2.94e+02, 0.00e+00,\n",
      "        2.00e+00, 1.53e+02, 0.00e+00, 1.30e+00, 2.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.80e+01, 0.00e+00, 3.00e+00, 1.20e+02, 2.11e+02, 0.00e+00,\n",
      "        2.00e+00, 1.15e+02, 0.00e+00, 1.50e+00, 2.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [5.20e+01, 0.00e+00, 3.00e+00, 1.36e+02, 1.96e+02, 0.00e+00,\n",
      "        2.00e+00, 1.69e+02, 0.00e+00, 1.00e-01, 2.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.20e+01, 0.00e+00, 4.00e+00, 1.40e+02, 3.94e+02, 0.00e+00,\n",
      "        2.00e+00, 1.57e+02, 0.00e+00, 1.20e+00, 2.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.30e+01, 1.00e+00, 4.00e+00, 1.30e+02, 2.54e+02, 0.00e+00,\n",
      "        2.00e+00, 1.47e+02, 0.00e+00, 1.40e+00, 2.00e+00, 1.00e+00,\n",
      "        7.00e+00],\n",
      "       [6.40e+01, 1.00e+00, 3.00e+00, 1.40e+02, 3.35e+02, 0.00e+00,\n",
      "        0.00e+00, 1.58e+02, 0.00e+00, 0.00e+00, 1.00e+00, 0.00e+00,\n",
      "        3.00e+00]]), array([[0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1]]))}\n",
      "Means: 0.4569288492202759, Stdev: 0.005296678746061075 with: {'batch_size': 60, 'class_weight': {0: 1, 1: 10}, 'epochs': 100, 'shuffle': True, 'validation_data': (array([[6.50e+01, 1.00e+00, 4.00e+00, 1.20e+02, 1.77e+02, 0.00e+00,\n",
      "        0.00e+00, 1.40e+02, 0.00e+00, 4.00e-01, 1.00e+00, 0.00e+00,\n",
      "        7.00e+00],\n",
      "       [5.80e+01, 1.00e+00, 4.00e+00, 1.46e+02, 2.18e+02, 0.00e+00,\n",
      "        0.00e+00, 1.05e+02, 0.00e+00, 2.00e+00, 2.00e+00, 1.00e+00,\n",
      "        7.00e+00],\n",
      "       [4.70e+01, 1.00e+00, 4.00e+00, 1.10e+02, 2.75e+02, 0.00e+00,\n",
      "        2.00e+00, 1.18e+02, 1.00e+00, 1.00e+00, 2.00e+00, 1.00e+00,\n",
      "        3.00e+00],\n",
      "       [5.70e+01, 1.00e+00, 4.00e+00, 1.10e+02, 2.01e+02, 0.00e+00,\n",
      "        0.00e+00, 1.26e+02, 1.00e+00, 1.50e+00, 2.00e+00, 0.00e+00,\n",
      "        6.00e+00],\n",
      "       [3.40e+01, 1.00e+00, 1.00e+00, 1.18e+02, 1.82e+02, 0.00e+00,\n",
      "        2.00e+00, 1.74e+02, 0.00e+00, 0.00e+00, 1.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.60e+01, 0.00e+00, 1.00e+00, 1.50e+02, 2.26e+02, 0.00e+00,\n",
      "        0.00e+00, 1.14e+02, 0.00e+00, 2.60e+00, 3.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [4.70e+01, 1.00e+00, 3.00e+00, 1.30e+02, 2.53e+02, 0.00e+00,\n",
      "        0.00e+00, 1.79e+02, 0.00e+00, 0.00e+00, 1.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.00e+01, 1.00e+00, 3.00e+00, 1.40e+02, 1.85e+02, 0.00e+00,\n",
      "        2.00e+00, 1.55e+02, 0.00e+00, 3.00e+00, 2.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [5.40e+01, 0.00e+00, 2.00e+00, 1.32e+02, 2.88e+02, 1.00e+00,\n",
      "        2.00e+00, 1.59e+02, 1.00e+00, 0.00e+00, 1.00e+00, 1.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.40e+01, 1.00e+00, 4.00e+00, 1.20e+02, 2.46e+02, 0.00e+00,\n",
      "        2.00e+00, 9.60e+01, 1.00e+00, 2.20e+00, 3.00e+00, 1.00e+00,\n",
      "        3.00e+00],\n",
      "       [4.00e+01, 1.00e+00, 1.00e+00, 1.40e+02, 1.99e+02, 0.00e+00,\n",
      "        0.00e+00, 1.78e+02, 1.00e+00, 1.40e+00, 1.00e+00, 0.00e+00,\n",
      "        7.00e+00],\n",
      "       [4.20e+01, 1.00e+00, 1.00e+00, 1.48e+02, 2.44e+02, 0.00e+00,\n",
      "        2.00e+00, 1.78e+02, 0.00e+00, 8.00e-01, 1.00e+00, 2.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.90e+01, 1.00e+00, 1.00e+00, 1.60e+02, 2.34e+02, 1.00e+00,\n",
      "        2.00e+00, 1.31e+02, 0.00e+00, 1.00e-01, 2.00e+00, 1.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.90e+01, 0.00e+00, 1.00e+00, 1.40e+02, 2.39e+02, 0.00e+00,\n",
      "        0.00e+00, 1.51e+02, 0.00e+00, 1.80e+00, 1.00e+00, 2.00e+00,\n",
      "        3.00e+00],\n",
      "       [4.80e+01, 1.00e+00, 4.00e+00, 1.24e+02, 2.74e+02, 0.00e+00,\n",
      "        2.00e+00, 1.66e+02, 0.00e+00, 5.00e-01, 2.00e+00, 0.00e+00,\n",
      "        7.00e+00],\n",
      "       [5.80e+01, 1.00e+00, 4.00e+00, 1.25e+02, 3.00e+02, 0.00e+00,\n",
      "        2.00e+00, 1.71e+02, 0.00e+00, 0.00e+00, 1.00e+00, 2.00e+00,\n",
      "        7.00e+00],\n",
      "       [5.80e+01, 1.00e+00, 4.00e+00, 1.14e+02, 3.18e+02, 0.00e+00,\n",
      "        1.00e+00, 1.40e+02, 0.00e+00, 4.40e+00, 3.00e+00, 3.00e+00,\n",
      "        6.00e+00],\n",
      "       [5.30e+01, 1.00e+00, 4.00e+00, 1.40e+02, 2.03e+02, 1.00e+00,\n",
      "        2.00e+00, 1.55e+02, 1.00e+00, 3.10e+00, 3.00e+00, 0.00e+00,\n",
      "        7.00e+00],\n",
      "       [5.80e+01, 0.00e+00, 4.00e+00, 1.30e+02, 1.97e+02, 0.00e+00,\n",
      "        0.00e+00, 1.31e+02, 0.00e+00, 6.00e-01, 2.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.10e+01, 1.00e+00, 4.00e+00, 1.40e+02, 2.07e+02, 0.00e+00,\n",
      "        2.00e+00, 1.38e+02, 1.00e+00, 1.90e+00, 1.00e+00, 1.00e+00,\n",
      "        7.00e+00],\n",
      "       [4.40e+01, 1.00e+00, 3.00e+00, 1.40e+02, 2.35e+02, 0.00e+00,\n",
      "        2.00e+00, 1.80e+02, 0.00e+00, 0.00e+00, 1.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [4.90e+01, 1.00e+00, 3.00e+00, 1.18e+02, 1.49e+02, 0.00e+00,\n",
      "        2.00e+00, 1.26e+02, 0.00e+00, 8.00e-01, 1.00e+00, 3.00e+00,\n",
      "        3.00e+00],\n",
      "       [4.70e+01, 1.00e+00, 3.00e+00, 1.08e+02, 2.43e+02, 0.00e+00,\n",
      "        0.00e+00, 1.52e+02, 0.00e+00, 0.00e+00, 1.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [4.30e+01, 0.00e+00, 4.00e+00, 1.32e+02, 3.41e+02, 1.00e+00,\n",
      "        2.00e+00, 1.36e+02, 1.00e+00, 3.00e+00, 2.00e+00, 0.00e+00,\n",
      "        7.00e+00],\n",
      "       [5.60e+01, 0.00e+00, 2.00e+00, 1.40e+02, 2.94e+02, 0.00e+00,\n",
      "        2.00e+00, 1.53e+02, 0.00e+00, 1.30e+00, 2.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.80e+01, 0.00e+00, 3.00e+00, 1.20e+02, 2.11e+02, 0.00e+00,\n",
      "        2.00e+00, 1.15e+02, 0.00e+00, 1.50e+00, 2.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [5.20e+01, 0.00e+00, 3.00e+00, 1.36e+02, 1.96e+02, 0.00e+00,\n",
      "        2.00e+00, 1.69e+02, 0.00e+00, 1.00e-01, 2.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.20e+01, 0.00e+00, 4.00e+00, 1.40e+02, 3.94e+02, 0.00e+00,\n",
      "        2.00e+00, 1.57e+02, 0.00e+00, 1.20e+00, 2.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.30e+01, 1.00e+00, 4.00e+00, 1.30e+02, 2.54e+02, 0.00e+00,\n",
      "        2.00e+00, 1.47e+02, 0.00e+00, 1.40e+00, 2.00e+00, 1.00e+00,\n",
      "        7.00e+00],\n",
      "       [6.40e+01, 1.00e+00, 3.00e+00, 1.40e+02, 3.35e+02, 0.00e+00,\n",
      "        0.00e+00, 1.58e+02, 0.00e+00, 0.00e+00, 1.00e+00, 0.00e+00,\n",
      "        3.00e+00]]), array([[0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1]]))}\n",
      "Means: 0.4606741666793823, Stdev: 0.009174116699547994 with: {'batch_size': 60, 'class_weight': {0: 1, 1: 10}, 'epochs': 100, 'shuffle': False, 'validation_data': (array([[6.50e+01, 1.00e+00, 4.00e+00, 1.20e+02, 1.77e+02, 0.00e+00,\n",
      "        0.00e+00, 1.40e+02, 0.00e+00, 4.00e-01, 1.00e+00, 0.00e+00,\n",
      "        7.00e+00],\n",
      "       [5.80e+01, 1.00e+00, 4.00e+00, 1.46e+02, 2.18e+02, 0.00e+00,\n",
      "        0.00e+00, 1.05e+02, 0.00e+00, 2.00e+00, 2.00e+00, 1.00e+00,\n",
      "        7.00e+00],\n",
      "       [4.70e+01, 1.00e+00, 4.00e+00, 1.10e+02, 2.75e+02, 0.00e+00,\n",
      "        2.00e+00, 1.18e+02, 1.00e+00, 1.00e+00, 2.00e+00, 1.00e+00,\n",
      "        3.00e+00],\n",
      "       [5.70e+01, 1.00e+00, 4.00e+00, 1.10e+02, 2.01e+02, 0.00e+00,\n",
      "        0.00e+00, 1.26e+02, 1.00e+00, 1.50e+00, 2.00e+00, 0.00e+00,\n",
      "        6.00e+00],\n",
      "       [3.40e+01, 1.00e+00, 1.00e+00, 1.18e+02, 1.82e+02, 0.00e+00,\n",
      "        2.00e+00, 1.74e+02, 0.00e+00, 0.00e+00, 1.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.60e+01, 0.00e+00, 1.00e+00, 1.50e+02, 2.26e+02, 0.00e+00,\n",
      "        0.00e+00, 1.14e+02, 0.00e+00, 2.60e+00, 3.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [4.70e+01, 1.00e+00, 3.00e+00, 1.30e+02, 2.53e+02, 0.00e+00,\n",
      "        0.00e+00, 1.79e+02, 0.00e+00, 0.00e+00, 1.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.00e+01, 1.00e+00, 3.00e+00, 1.40e+02, 1.85e+02, 0.00e+00,\n",
      "        2.00e+00, 1.55e+02, 0.00e+00, 3.00e+00, 2.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [5.40e+01, 0.00e+00, 2.00e+00, 1.32e+02, 2.88e+02, 1.00e+00,\n",
      "        2.00e+00, 1.59e+02, 1.00e+00, 0.00e+00, 1.00e+00, 1.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.40e+01, 1.00e+00, 4.00e+00, 1.20e+02, 2.46e+02, 0.00e+00,\n",
      "        2.00e+00, 9.60e+01, 1.00e+00, 2.20e+00, 3.00e+00, 1.00e+00,\n",
      "        3.00e+00],\n",
      "       [4.00e+01, 1.00e+00, 1.00e+00, 1.40e+02, 1.99e+02, 0.00e+00,\n",
      "        0.00e+00, 1.78e+02, 1.00e+00, 1.40e+00, 1.00e+00, 0.00e+00,\n",
      "        7.00e+00],\n",
      "       [4.20e+01, 1.00e+00, 1.00e+00, 1.48e+02, 2.44e+02, 0.00e+00,\n",
      "        2.00e+00, 1.78e+02, 0.00e+00, 8.00e-01, 1.00e+00, 2.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.90e+01, 1.00e+00, 1.00e+00, 1.60e+02, 2.34e+02, 1.00e+00,\n",
      "        2.00e+00, 1.31e+02, 0.00e+00, 1.00e-01, 2.00e+00, 1.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.90e+01, 0.00e+00, 1.00e+00, 1.40e+02, 2.39e+02, 0.00e+00,\n",
      "        0.00e+00, 1.51e+02, 0.00e+00, 1.80e+00, 1.00e+00, 2.00e+00,\n",
      "        3.00e+00],\n",
      "       [4.80e+01, 1.00e+00, 4.00e+00, 1.24e+02, 2.74e+02, 0.00e+00,\n",
      "        2.00e+00, 1.66e+02, 0.00e+00, 5.00e-01, 2.00e+00, 0.00e+00,\n",
      "        7.00e+00],\n",
      "       [5.80e+01, 1.00e+00, 4.00e+00, 1.25e+02, 3.00e+02, 0.00e+00,\n",
      "        2.00e+00, 1.71e+02, 0.00e+00, 0.00e+00, 1.00e+00, 2.00e+00,\n",
      "        7.00e+00],\n",
      "       [5.80e+01, 1.00e+00, 4.00e+00, 1.14e+02, 3.18e+02, 0.00e+00,\n",
      "        1.00e+00, 1.40e+02, 0.00e+00, 4.40e+00, 3.00e+00, 3.00e+00,\n",
      "        6.00e+00],\n",
      "       [5.30e+01, 1.00e+00, 4.00e+00, 1.40e+02, 2.03e+02, 1.00e+00,\n",
      "        2.00e+00, 1.55e+02, 1.00e+00, 3.10e+00, 3.00e+00, 0.00e+00,\n",
      "        7.00e+00],\n",
      "       [5.80e+01, 0.00e+00, 4.00e+00, 1.30e+02, 1.97e+02, 0.00e+00,\n",
      "        0.00e+00, 1.31e+02, 0.00e+00, 6.00e-01, 2.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.10e+01, 1.00e+00, 4.00e+00, 1.40e+02, 2.07e+02, 0.00e+00,\n",
      "        2.00e+00, 1.38e+02, 1.00e+00, 1.90e+00, 1.00e+00, 1.00e+00,\n",
      "        7.00e+00],\n",
      "       [4.40e+01, 1.00e+00, 3.00e+00, 1.40e+02, 2.35e+02, 0.00e+00,\n",
      "        2.00e+00, 1.80e+02, 0.00e+00, 0.00e+00, 1.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [4.90e+01, 1.00e+00, 3.00e+00, 1.18e+02, 1.49e+02, 0.00e+00,\n",
      "        2.00e+00, 1.26e+02, 0.00e+00, 8.00e-01, 1.00e+00, 3.00e+00,\n",
      "        3.00e+00],\n",
      "       [4.70e+01, 1.00e+00, 3.00e+00, 1.08e+02, 2.43e+02, 0.00e+00,\n",
      "        0.00e+00, 1.52e+02, 0.00e+00, 0.00e+00, 1.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [4.30e+01, 0.00e+00, 4.00e+00, 1.32e+02, 3.41e+02, 1.00e+00,\n",
      "        2.00e+00, 1.36e+02, 1.00e+00, 3.00e+00, 2.00e+00, 0.00e+00,\n",
      "        7.00e+00],\n",
      "       [5.60e+01, 0.00e+00, 2.00e+00, 1.40e+02, 2.94e+02, 0.00e+00,\n",
      "        2.00e+00, 1.53e+02, 0.00e+00, 1.30e+00, 2.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.80e+01, 0.00e+00, 3.00e+00, 1.20e+02, 2.11e+02, 0.00e+00,\n",
      "        2.00e+00, 1.15e+02, 0.00e+00, 1.50e+00, 2.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [5.20e+01, 0.00e+00, 3.00e+00, 1.36e+02, 1.96e+02, 0.00e+00,\n",
      "        2.00e+00, 1.69e+02, 0.00e+00, 1.00e-01, 2.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.20e+01, 0.00e+00, 4.00e+00, 1.40e+02, 3.94e+02, 0.00e+00,\n",
      "        2.00e+00, 1.57e+02, 0.00e+00, 1.20e+00, 2.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.30e+01, 1.00e+00, 4.00e+00, 1.30e+02, 2.54e+02, 0.00e+00,\n",
      "        2.00e+00, 1.47e+02, 0.00e+00, 1.40e+00, 2.00e+00, 1.00e+00,\n",
      "        7.00e+00],\n",
      "       [6.40e+01, 1.00e+00, 3.00e+00, 1.40e+02, 3.35e+02, 0.00e+00,\n",
      "        0.00e+00, 1.58e+02, 0.00e+00, 0.00e+00, 1.00e+00, 0.00e+00,\n",
      "        3.00e+00]]), array([[0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1]]))}\n",
      "Means: 0.49438202381134033, Stdev: 0.039989047589578594 with: {'batch_size': 60, 'class_weight': {0: 1, 1: 10}, 'epochs': 150, 'shuffle': True, 'validation_data': (array([[6.50e+01, 1.00e+00, 4.00e+00, 1.20e+02, 1.77e+02, 0.00e+00,\n",
      "        0.00e+00, 1.40e+02, 0.00e+00, 4.00e-01, 1.00e+00, 0.00e+00,\n",
      "        7.00e+00],\n",
      "       [5.80e+01, 1.00e+00, 4.00e+00, 1.46e+02, 2.18e+02, 0.00e+00,\n",
      "        0.00e+00, 1.05e+02, 0.00e+00, 2.00e+00, 2.00e+00, 1.00e+00,\n",
      "        7.00e+00],\n",
      "       [4.70e+01, 1.00e+00, 4.00e+00, 1.10e+02, 2.75e+02, 0.00e+00,\n",
      "        2.00e+00, 1.18e+02, 1.00e+00, 1.00e+00, 2.00e+00, 1.00e+00,\n",
      "        3.00e+00],\n",
      "       [5.70e+01, 1.00e+00, 4.00e+00, 1.10e+02, 2.01e+02, 0.00e+00,\n",
      "        0.00e+00, 1.26e+02, 1.00e+00, 1.50e+00, 2.00e+00, 0.00e+00,\n",
      "        6.00e+00],\n",
      "       [3.40e+01, 1.00e+00, 1.00e+00, 1.18e+02, 1.82e+02, 0.00e+00,\n",
      "        2.00e+00, 1.74e+02, 0.00e+00, 0.00e+00, 1.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.60e+01, 0.00e+00, 1.00e+00, 1.50e+02, 2.26e+02, 0.00e+00,\n",
      "        0.00e+00, 1.14e+02, 0.00e+00, 2.60e+00, 3.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [4.70e+01, 1.00e+00, 3.00e+00, 1.30e+02, 2.53e+02, 0.00e+00,\n",
      "        0.00e+00, 1.79e+02, 0.00e+00, 0.00e+00, 1.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.00e+01, 1.00e+00, 3.00e+00, 1.40e+02, 1.85e+02, 0.00e+00,\n",
      "        2.00e+00, 1.55e+02, 0.00e+00, 3.00e+00, 2.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [5.40e+01, 0.00e+00, 2.00e+00, 1.32e+02, 2.88e+02, 1.00e+00,\n",
      "        2.00e+00, 1.59e+02, 1.00e+00, 0.00e+00, 1.00e+00, 1.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.40e+01, 1.00e+00, 4.00e+00, 1.20e+02, 2.46e+02, 0.00e+00,\n",
      "        2.00e+00, 9.60e+01, 1.00e+00, 2.20e+00, 3.00e+00, 1.00e+00,\n",
      "        3.00e+00],\n",
      "       [4.00e+01, 1.00e+00, 1.00e+00, 1.40e+02, 1.99e+02, 0.00e+00,\n",
      "        0.00e+00, 1.78e+02, 1.00e+00, 1.40e+00, 1.00e+00, 0.00e+00,\n",
      "        7.00e+00],\n",
      "       [4.20e+01, 1.00e+00, 1.00e+00, 1.48e+02, 2.44e+02, 0.00e+00,\n",
      "        2.00e+00, 1.78e+02, 0.00e+00, 8.00e-01, 1.00e+00, 2.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.90e+01, 1.00e+00, 1.00e+00, 1.60e+02, 2.34e+02, 1.00e+00,\n",
      "        2.00e+00, 1.31e+02, 0.00e+00, 1.00e-01, 2.00e+00, 1.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.90e+01, 0.00e+00, 1.00e+00, 1.40e+02, 2.39e+02, 0.00e+00,\n",
      "        0.00e+00, 1.51e+02, 0.00e+00, 1.80e+00, 1.00e+00, 2.00e+00,\n",
      "        3.00e+00],\n",
      "       [4.80e+01, 1.00e+00, 4.00e+00, 1.24e+02, 2.74e+02, 0.00e+00,\n",
      "        2.00e+00, 1.66e+02, 0.00e+00, 5.00e-01, 2.00e+00, 0.00e+00,\n",
      "        7.00e+00],\n",
      "       [5.80e+01, 1.00e+00, 4.00e+00, 1.25e+02, 3.00e+02, 0.00e+00,\n",
      "        2.00e+00, 1.71e+02, 0.00e+00, 0.00e+00, 1.00e+00, 2.00e+00,\n",
      "        7.00e+00],\n",
      "       [5.80e+01, 1.00e+00, 4.00e+00, 1.14e+02, 3.18e+02, 0.00e+00,\n",
      "        1.00e+00, 1.40e+02, 0.00e+00, 4.40e+00, 3.00e+00, 3.00e+00,\n",
      "        6.00e+00],\n",
      "       [5.30e+01, 1.00e+00, 4.00e+00, 1.40e+02, 2.03e+02, 1.00e+00,\n",
      "        2.00e+00, 1.55e+02, 1.00e+00, 3.10e+00, 3.00e+00, 0.00e+00,\n",
      "        7.00e+00],\n",
      "       [5.80e+01, 0.00e+00, 4.00e+00, 1.30e+02, 1.97e+02, 0.00e+00,\n",
      "        0.00e+00, 1.31e+02, 0.00e+00, 6.00e-01, 2.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.10e+01, 1.00e+00, 4.00e+00, 1.40e+02, 2.07e+02, 0.00e+00,\n",
      "        2.00e+00, 1.38e+02, 1.00e+00, 1.90e+00, 1.00e+00, 1.00e+00,\n",
      "        7.00e+00],\n",
      "       [4.40e+01, 1.00e+00, 3.00e+00, 1.40e+02, 2.35e+02, 0.00e+00,\n",
      "        2.00e+00, 1.80e+02, 0.00e+00, 0.00e+00, 1.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [4.90e+01, 1.00e+00, 3.00e+00, 1.18e+02, 1.49e+02, 0.00e+00,\n",
      "        2.00e+00, 1.26e+02, 0.00e+00, 8.00e-01, 1.00e+00, 3.00e+00,\n",
      "        3.00e+00],\n",
      "       [4.70e+01, 1.00e+00, 3.00e+00, 1.08e+02, 2.43e+02, 0.00e+00,\n",
      "        0.00e+00, 1.52e+02, 0.00e+00, 0.00e+00, 1.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [4.30e+01, 0.00e+00, 4.00e+00, 1.32e+02, 3.41e+02, 1.00e+00,\n",
      "        2.00e+00, 1.36e+02, 1.00e+00, 3.00e+00, 2.00e+00, 0.00e+00,\n",
      "        7.00e+00],\n",
      "       [5.60e+01, 0.00e+00, 2.00e+00, 1.40e+02, 2.94e+02, 0.00e+00,\n",
      "        2.00e+00, 1.53e+02, 0.00e+00, 1.30e+00, 2.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.80e+01, 0.00e+00, 3.00e+00, 1.20e+02, 2.11e+02, 0.00e+00,\n",
      "        2.00e+00, 1.15e+02, 0.00e+00, 1.50e+00, 2.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [5.20e+01, 0.00e+00, 3.00e+00, 1.36e+02, 1.96e+02, 0.00e+00,\n",
      "        2.00e+00, 1.69e+02, 0.00e+00, 1.00e-01, 2.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.20e+01, 0.00e+00, 4.00e+00, 1.40e+02, 3.94e+02, 0.00e+00,\n",
      "        2.00e+00, 1.57e+02, 0.00e+00, 1.20e+00, 2.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.30e+01, 1.00e+00, 4.00e+00, 1.30e+02, 2.54e+02, 0.00e+00,\n",
      "        2.00e+00, 1.47e+02, 0.00e+00, 1.40e+00, 2.00e+00, 1.00e+00,\n",
      "        7.00e+00],\n",
      "       [6.40e+01, 1.00e+00, 3.00e+00, 1.40e+02, 3.35e+02, 0.00e+00,\n",
      "        0.00e+00, 1.58e+02, 0.00e+00, 0.00e+00, 1.00e+00, 0.00e+00,\n",
      "        3.00e+00]]), array([[0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1]]))}\n",
      "Means: 0.5056179761886597, Stdev: 0.039989047589578594 with: {'batch_size': 60, 'class_weight': {0: 1, 1: 10}, 'epochs': 150, 'shuffle': False, 'validation_data': (array([[6.50e+01, 1.00e+00, 4.00e+00, 1.20e+02, 1.77e+02, 0.00e+00,\n",
      "        0.00e+00, 1.40e+02, 0.00e+00, 4.00e-01, 1.00e+00, 0.00e+00,\n",
      "        7.00e+00],\n",
      "       [5.80e+01, 1.00e+00, 4.00e+00, 1.46e+02, 2.18e+02, 0.00e+00,\n",
      "        0.00e+00, 1.05e+02, 0.00e+00, 2.00e+00, 2.00e+00, 1.00e+00,\n",
      "        7.00e+00],\n",
      "       [4.70e+01, 1.00e+00, 4.00e+00, 1.10e+02, 2.75e+02, 0.00e+00,\n",
      "        2.00e+00, 1.18e+02, 1.00e+00, 1.00e+00, 2.00e+00, 1.00e+00,\n",
      "        3.00e+00],\n",
      "       [5.70e+01, 1.00e+00, 4.00e+00, 1.10e+02, 2.01e+02, 0.00e+00,\n",
      "        0.00e+00, 1.26e+02, 1.00e+00, 1.50e+00, 2.00e+00, 0.00e+00,\n",
      "        6.00e+00],\n",
      "       [3.40e+01, 1.00e+00, 1.00e+00, 1.18e+02, 1.82e+02, 0.00e+00,\n",
      "        2.00e+00, 1.74e+02, 0.00e+00, 0.00e+00, 1.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.60e+01, 0.00e+00, 1.00e+00, 1.50e+02, 2.26e+02, 0.00e+00,\n",
      "        0.00e+00, 1.14e+02, 0.00e+00, 2.60e+00, 3.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [4.70e+01, 1.00e+00, 3.00e+00, 1.30e+02, 2.53e+02, 0.00e+00,\n",
      "        0.00e+00, 1.79e+02, 0.00e+00, 0.00e+00, 1.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.00e+01, 1.00e+00, 3.00e+00, 1.40e+02, 1.85e+02, 0.00e+00,\n",
      "        2.00e+00, 1.55e+02, 0.00e+00, 3.00e+00, 2.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [5.40e+01, 0.00e+00, 2.00e+00, 1.32e+02, 2.88e+02, 1.00e+00,\n",
      "        2.00e+00, 1.59e+02, 1.00e+00, 0.00e+00, 1.00e+00, 1.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.40e+01, 1.00e+00, 4.00e+00, 1.20e+02, 2.46e+02, 0.00e+00,\n",
      "        2.00e+00, 9.60e+01, 1.00e+00, 2.20e+00, 3.00e+00, 1.00e+00,\n",
      "        3.00e+00],\n",
      "       [4.00e+01, 1.00e+00, 1.00e+00, 1.40e+02, 1.99e+02, 0.00e+00,\n",
      "        0.00e+00, 1.78e+02, 1.00e+00, 1.40e+00, 1.00e+00, 0.00e+00,\n",
      "        7.00e+00],\n",
      "       [4.20e+01, 1.00e+00, 1.00e+00, 1.48e+02, 2.44e+02, 0.00e+00,\n",
      "        2.00e+00, 1.78e+02, 0.00e+00, 8.00e-01, 1.00e+00, 2.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.90e+01, 1.00e+00, 1.00e+00, 1.60e+02, 2.34e+02, 1.00e+00,\n",
      "        2.00e+00, 1.31e+02, 0.00e+00, 1.00e-01, 2.00e+00, 1.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.90e+01, 0.00e+00, 1.00e+00, 1.40e+02, 2.39e+02, 0.00e+00,\n",
      "        0.00e+00, 1.51e+02, 0.00e+00, 1.80e+00, 1.00e+00, 2.00e+00,\n",
      "        3.00e+00],\n",
      "       [4.80e+01, 1.00e+00, 4.00e+00, 1.24e+02, 2.74e+02, 0.00e+00,\n",
      "        2.00e+00, 1.66e+02, 0.00e+00, 5.00e-01, 2.00e+00, 0.00e+00,\n",
      "        7.00e+00],\n",
      "       [5.80e+01, 1.00e+00, 4.00e+00, 1.25e+02, 3.00e+02, 0.00e+00,\n",
      "        2.00e+00, 1.71e+02, 0.00e+00, 0.00e+00, 1.00e+00, 2.00e+00,\n",
      "        7.00e+00],\n",
      "       [5.80e+01, 1.00e+00, 4.00e+00, 1.14e+02, 3.18e+02, 0.00e+00,\n",
      "        1.00e+00, 1.40e+02, 0.00e+00, 4.40e+00, 3.00e+00, 3.00e+00,\n",
      "        6.00e+00],\n",
      "       [5.30e+01, 1.00e+00, 4.00e+00, 1.40e+02, 2.03e+02, 1.00e+00,\n",
      "        2.00e+00, 1.55e+02, 1.00e+00, 3.10e+00, 3.00e+00, 0.00e+00,\n",
      "        7.00e+00],\n",
      "       [5.80e+01, 0.00e+00, 4.00e+00, 1.30e+02, 1.97e+02, 0.00e+00,\n",
      "        0.00e+00, 1.31e+02, 0.00e+00, 6.00e-01, 2.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.10e+01, 1.00e+00, 4.00e+00, 1.40e+02, 2.07e+02, 0.00e+00,\n",
      "        2.00e+00, 1.38e+02, 1.00e+00, 1.90e+00, 1.00e+00, 1.00e+00,\n",
      "        7.00e+00],\n",
      "       [4.40e+01, 1.00e+00, 3.00e+00, 1.40e+02, 2.35e+02, 0.00e+00,\n",
      "        2.00e+00, 1.80e+02, 0.00e+00, 0.00e+00, 1.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [4.90e+01, 1.00e+00, 3.00e+00, 1.18e+02, 1.49e+02, 0.00e+00,\n",
      "        2.00e+00, 1.26e+02, 0.00e+00, 8.00e-01, 1.00e+00, 3.00e+00,\n",
      "        3.00e+00],\n",
      "       [4.70e+01, 1.00e+00, 3.00e+00, 1.08e+02, 2.43e+02, 0.00e+00,\n",
      "        0.00e+00, 1.52e+02, 0.00e+00, 0.00e+00, 1.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [4.30e+01, 0.00e+00, 4.00e+00, 1.32e+02, 3.41e+02, 1.00e+00,\n",
      "        2.00e+00, 1.36e+02, 1.00e+00, 3.00e+00, 2.00e+00, 0.00e+00,\n",
      "        7.00e+00],\n",
      "       [5.60e+01, 0.00e+00, 2.00e+00, 1.40e+02, 2.94e+02, 0.00e+00,\n",
      "        2.00e+00, 1.53e+02, 0.00e+00, 1.30e+00, 2.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.80e+01, 0.00e+00, 3.00e+00, 1.20e+02, 2.11e+02, 0.00e+00,\n",
      "        2.00e+00, 1.15e+02, 0.00e+00, 1.50e+00, 2.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [5.20e+01, 0.00e+00, 3.00e+00, 1.36e+02, 1.96e+02, 0.00e+00,\n",
      "        2.00e+00, 1.69e+02, 0.00e+00, 1.00e-01, 2.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.20e+01, 0.00e+00, 4.00e+00, 1.40e+02, 3.94e+02, 0.00e+00,\n",
      "        2.00e+00, 1.57e+02, 0.00e+00, 1.20e+00, 2.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.30e+01, 1.00e+00, 4.00e+00, 1.30e+02, 2.54e+02, 0.00e+00,\n",
      "        2.00e+00, 1.47e+02, 0.00e+00, 1.40e+00, 2.00e+00, 1.00e+00,\n",
      "        7.00e+00],\n",
      "       [6.40e+01, 1.00e+00, 3.00e+00, 1.40e+02, 3.35e+02, 0.00e+00,\n",
      "        0.00e+00, 1.58e+02, 0.00e+00, 0.00e+00, 1.00e+00, 0.00e+00,\n",
      "        3.00e+00]]), array([[0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1]]))}\n",
      "Means: 0.4719101091225942, Stdev: 0.045870595664487666 with: {'batch_size': 60, 'class_weight': {0: 1, 1: 10}, 'epochs': 250, 'shuffle': True, 'validation_data': (array([[6.50e+01, 1.00e+00, 4.00e+00, 1.20e+02, 1.77e+02, 0.00e+00,\n",
      "        0.00e+00, 1.40e+02, 0.00e+00, 4.00e-01, 1.00e+00, 0.00e+00,\n",
      "        7.00e+00],\n",
      "       [5.80e+01, 1.00e+00, 4.00e+00, 1.46e+02, 2.18e+02, 0.00e+00,\n",
      "        0.00e+00, 1.05e+02, 0.00e+00, 2.00e+00, 2.00e+00, 1.00e+00,\n",
      "        7.00e+00],\n",
      "       [4.70e+01, 1.00e+00, 4.00e+00, 1.10e+02, 2.75e+02, 0.00e+00,\n",
      "        2.00e+00, 1.18e+02, 1.00e+00, 1.00e+00, 2.00e+00, 1.00e+00,\n",
      "        3.00e+00],\n",
      "       [5.70e+01, 1.00e+00, 4.00e+00, 1.10e+02, 2.01e+02, 0.00e+00,\n",
      "        0.00e+00, 1.26e+02, 1.00e+00, 1.50e+00, 2.00e+00, 0.00e+00,\n",
      "        6.00e+00],\n",
      "       [3.40e+01, 1.00e+00, 1.00e+00, 1.18e+02, 1.82e+02, 0.00e+00,\n",
      "        2.00e+00, 1.74e+02, 0.00e+00, 0.00e+00, 1.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.60e+01, 0.00e+00, 1.00e+00, 1.50e+02, 2.26e+02, 0.00e+00,\n",
      "        0.00e+00, 1.14e+02, 0.00e+00, 2.60e+00, 3.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [4.70e+01, 1.00e+00, 3.00e+00, 1.30e+02, 2.53e+02, 0.00e+00,\n",
      "        0.00e+00, 1.79e+02, 0.00e+00, 0.00e+00, 1.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.00e+01, 1.00e+00, 3.00e+00, 1.40e+02, 1.85e+02, 0.00e+00,\n",
      "        2.00e+00, 1.55e+02, 0.00e+00, 3.00e+00, 2.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [5.40e+01, 0.00e+00, 2.00e+00, 1.32e+02, 2.88e+02, 1.00e+00,\n",
      "        2.00e+00, 1.59e+02, 1.00e+00, 0.00e+00, 1.00e+00, 1.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.40e+01, 1.00e+00, 4.00e+00, 1.20e+02, 2.46e+02, 0.00e+00,\n",
      "        2.00e+00, 9.60e+01, 1.00e+00, 2.20e+00, 3.00e+00, 1.00e+00,\n",
      "        3.00e+00],\n",
      "       [4.00e+01, 1.00e+00, 1.00e+00, 1.40e+02, 1.99e+02, 0.00e+00,\n",
      "        0.00e+00, 1.78e+02, 1.00e+00, 1.40e+00, 1.00e+00, 0.00e+00,\n",
      "        7.00e+00],\n",
      "       [4.20e+01, 1.00e+00, 1.00e+00, 1.48e+02, 2.44e+02, 0.00e+00,\n",
      "        2.00e+00, 1.78e+02, 0.00e+00, 8.00e-01, 1.00e+00, 2.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.90e+01, 1.00e+00, 1.00e+00, 1.60e+02, 2.34e+02, 1.00e+00,\n",
      "        2.00e+00, 1.31e+02, 0.00e+00, 1.00e-01, 2.00e+00, 1.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.90e+01, 0.00e+00, 1.00e+00, 1.40e+02, 2.39e+02, 0.00e+00,\n",
      "        0.00e+00, 1.51e+02, 0.00e+00, 1.80e+00, 1.00e+00, 2.00e+00,\n",
      "        3.00e+00],\n",
      "       [4.80e+01, 1.00e+00, 4.00e+00, 1.24e+02, 2.74e+02, 0.00e+00,\n",
      "        2.00e+00, 1.66e+02, 0.00e+00, 5.00e-01, 2.00e+00, 0.00e+00,\n",
      "        7.00e+00],\n",
      "       [5.80e+01, 1.00e+00, 4.00e+00, 1.25e+02, 3.00e+02, 0.00e+00,\n",
      "        2.00e+00, 1.71e+02, 0.00e+00, 0.00e+00, 1.00e+00, 2.00e+00,\n",
      "        7.00e+00],\n",
      "       [5.80e+01, 1.00e+00, 4.00e+00, 1.14e+02, 3.18e+02, 0.00e+00,\n",
      "        1.00e+00, 1.40e+02, 0.00e+00, 4.40e+00, 3.00e+00, 3.00e+00,\n",
      "        6.00e+00],\n",
      "       [5.30e+01, 1.00e+00, 4.00e+00, 1.40e+02, 2.03e+02, 1.00e+00,\n",
      "        2.00e+00, 1.55e+02, 1.00e+00, 3.10e+00, 3.00e+00, 0.00e+00,\n",
      "        7.00e+00],\n",
      "       [5.80e+01, 0.00e+00, 4.00e+00, 1.30e+02, 1.97e+02, 0.00e+00,\n",
      "        0.00e+00, 1.31e+02, 0.00e+00, 6.00e-01, 2.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.10e+01, 1.00e+00, 4.00e+00, 1.40e+02, 2.07e+02, 0.00e+00,\n",
      "        2.00e+00, 1.38e+02, 1.00e+00, 1.90e+00, 1.00e+00, 1.00e+00,\n",
      "        7.00e+00],\n",
      "       [4.40e+01, 1.00e+00, 3.00e+00, 1.40e+02, 2.35e+02, 0.00e+00,\n",
      "        2.00e+00, 1.80e+02, 0.00e+00, 0.00e+00, 1.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [4.90e+01, 1.00e+00, 3.00e+00, 1.18e+02, 1.49e+02, 0.00e+00,\n",
      "        2.00e+00, 1.26e+02, 0.00e+00, 8.00e-01, 1.00e+00, 3.00e+00,\n",
      "        3.00e+00],\n",
      "       [4.70e+01, 1.00e+00, 3.00e+00, 1.08e+02, 2.43e+02, 0.00e+00,\n",
      "        0.00e+00, 1.52e+02, 0.00e+00, 0.00e+00, 1.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [4.30e+01, 0.00e+00, 4.00e+00, 1.32e+02, 3.41e+02, 1.00e+00,\n",
      "        2.00e+00, 1.36e+02, 1.00e+00, 3.00e+00, 2.00e+00, 0.00e+00,\n",
      "        7.00e+00],\n",
      "       [5.60e+01, 0.00e+00, 2.00e+00, 1.40e+02, 2.94e+02, 0.00e+00,\n",
      "        2.00e+00, 1.53e+02, 0.00e+00, 1.30e+00, 2.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.80e+01, 0.00e+00, 3.00e+00, 1.20e+02, 2.11e+02, 0.00e+00,\n",
      "        2.00e+00, 1.15e+02, 0.00e+00, 1.50e+00, 2.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [5.20e+01, 0.00e+00, 3.00e+00, 1.36e+02, 1.96e+02, 0.00e+00,\n",
      "        2.00e+00, 1.69e+02, 0.00e+00, 1.00e-01, 2.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.20e+01, 0.00e+00, 4.00e+00, 1.40e+02, 3.94e+02, 0.00e+00,\n",
      "        2.00e+00, 1.57e+02, 0.00e+00, 1.20e+00, 2.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.30e+01, 1.00e+00, 4.00e+00, 1.30e+02, 2.54e+02, 0.00e+00,\n",
      "        2.00e+00, 1.47e+02, 0.00e+00, 1.40e+00, 2.00e+00, 1.00e+00,\n",
      "        7.00e+00],\n",
      "       [6.40e+01, 1.00e+00, 3.00e+00, 1.40e+02, 3.35e+02, 0.00e+00,\n",
      "        0.00e+00, 1.58e+02, 0.00e+00, 0.00e+00, 1.00e+00, 0.00e+00,\n",
      "        3.00e+00]]), array([[0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1]]))}\n",
      "Means: 0.47940075397491455, Stdev: 0.034732645260272504 with: {'batch_size': 60, 'class_weight': {0: 1, 1: 10}, 'epochs': 250, 'shuffle': False, 'validation_data': (array([[6.50e+01, 1.00e+00, 4.00e+00, 1.20e+02, 1.77e+02, 0.00e+00,\n",
      "        0.00e+00, 1.40e+02, 0.00e+00, 4.00e-01, 1.00e+00, 0.00e+00,\n",
      "        7.00e+00],\n",
      "       [5.80e+01, 1.00e+00, 4.00e+00, 1.46e+02, 2.18e+02, 0.00e+00,\n",
      "        0.00e+00, 1.05e+02, 0.00e+00, 2.00e+00, 2.00e+00, 1.00e+00,\n",
      "        7.00e+00],\n",
      "       [4.70e+01, 1.00e+00, 4.00e+00, 1.10e+02, 2.75e+02, 0.00e+00,\n",
      "        2.00e+00, 1.18e+02, 1.00e+00, 1.00e+00, 2.00e+00, 1.00e+00,\n",
      "        3.00e+00],\n",
      "       [5.70e+01, 1.00e+00, 4.00e+00, 1.10e+02, 2.01e+02, 0.00e+00,\n",
      "        0.00e+00, 1.26e+02, 1.00e+00, 1.50e+00, 2.00e+00, 0.00e+00,\n",
      "        6.00e+00],\n",
      "       [3.40e+01, 1.00e+00, 1.00e+00, 1.18e+02, 1.82e+02, 0.00e+00,\n",
      "        2.00e+00, 1.74e+02, 0.00e+00, 0.00e+00, 1.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.60e+01, 0.00e+00, 1.00e+00, 1.50e+02, 2.26e+02, 0.00e+00,\n",
      "        0.00e+00, 1.14e+02, 0.00e+00, 2.60e+00, 3.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [4.70e+01, 1.00e+00, 3.00e+00, 1.30e+02, 2.53e+02, 0.00e+00,\n",
      "        0.00e+00, 1.79e+02, 0.00e+00, 0.00e+00, 1.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.00e+01, 1.00e+00, 3.00e+00, 1.40e+02, 1.85e+02, 0.00e+00,\n",
      "        2.00e+00, 1.55e+02, 0.00e+00, 3.00e+00, 2.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [5.40e+01, 0.00e+00, 2.00e+00, 1.32e+02, 2.88e+02, 1.00e+00,\n",
      "        2.00e+00, 1.59e+02, 1.00e+00, 0.00e+00, 1.00e+00, 1.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.40e+01, 1.00e+00, 4.00e+00, 1.20e+02, 2.46e+02, 0.00e+00,\n",
      "        2.00e+00, 9.60e+01, 1.00e+00, 2.20e+00, 3.00e+00, 1.00e+00,\n",
      "        3.00e+00],\n",
      "       [4.00e+01, 1.00e+00, 1.00e+00, 1.40e+02, 1.99e+02, 0.00e+00,\n",
      "        0.00e+00, 1.78e+02, 1.00e+00, 1.40e+00, 1.00e+00, 0.00e+00,\n",
      "        7.00e+00],\n",
      "       [4.20e+01, 1.00e+00, 1.00e+00, 1.48e+02, 2.44e+02, 0.00e+00,\n",
      "        2.00e+00, 1.78e+02, 0.00e+00, 8.00e-01, 1.00e+00, 2.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.90e+01, 1.00e+00, 1.00e+00, 1.60e+02, 2.34e+02, 1.00e+00,\n",
      "        2.00e+00, 1.31e+02, 0.00e+00, 1.00e-01, 2.00e+00, 1.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.90e+01, 0.00e+00, 1.00e+00, 1.40e+02, 2.39e+02, 0.00e+00,\n",
      "        0.00e+00, 1.51e+02, 0.00e+00, 1.80e+00, 1.00e+00, 2.00e+00,\n",
      "        3.00e+00],\n",
      "       [4.80e+01, 1.00e+00, 4.00e+00, 1.24e+02, 2.74e+02, 0.00e+00,\n",
      "        2.00e+00, 1.66e+02, 0.00e+00, 5.00e-01, 2.00e+00, 0.00e+00,\n",
      "        7.00e+00],\n",
      "       [5.80e+01, 1.00e+00, 4.00e+00, 1.25e+02, 3.00e+02, 0.00e+00,\n",
      "        2.00e+00, 1.71e+02, 0.00e+00, 0.00e+00, 1.00e+00, 2.00e+00,\n",
      "        7.00e+00],\n",
      "       [5.80e+01, 1.00e+00, 4.00e+00, 1.14e+02, 3.18e+02, 0.00e+00,\n",
      "        1.00e+00, 1.40e+02, 0.00e+00, 4.40e+00, 3.00e+00, 3.00e+00,\n",
      "        6.00e+00],\n",
      "       [5.30e+01, 1.00e+00, 4.00e+00, 1.40e+02, 2.03e+02, 1.00e+00,\n",
      "        2.00e+00, 1.55e+02, 1.00e+00, 3.10e+00, 3.00e+00, 0.00e+00,\n",
      "        7.00e+00],\n",
      "       [5.80e+01, 0.00e+00, 4.00e+00, 1.30e+02, 1.97e+02, 0.00e+00,\n",
      "        0.00e+00, 1.31e+02, 0.00e+00, 6.00e-01, 2.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.10e+01, 1.00e+00, 4.00e+00, 1.40e+02, 2.07e+02, 0.00e+00,\n",
      "        2.00e+00, 1.38e+02, 1.00e+00, 1.90e+00, 1.00e+00, 1.00e+00,\n",
      "        7.00e+00],\n",
      "       [4.40e+01, 1.00e+00, 3.00e+00, 1.40e+02, 2.35e+02, 0.00e+00,\n",
      "        2.00e+00, 1.80e+02, 0.00e+00, 0.00e+00, 1.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [4.90e+01, 1.00e+00, 3.00e+00, 1.18e+02, 1.49e+02, 0.00e+00,\n",
      "        2.00e+00, 1.26e+02, 0.00e+00, 8.00e-01, 1.00e+00, 3.00e+00,\n",
      "        3.00e+00],\n",
      "       [4.70e+01, 1.00e+00, 3.00e+00, 1.08e+02, 2.43e+02, 0.00e+00,\n",
      "        0.00e+00, 1.52e+02, 0.00e+00, 0.00e+00, 1.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [4.30e+01, 0.00e+00, 4.00e+00, 1.32e+02, 3.41e+02, 1.00e+00,\n",
      "        2.00e+00, 1.36e+02, 1.00e+00, 3.00e+00, 2.00e+00, 0.00e+00,\n",
      "        7.00e+00],\n",
      "       [5.60e+01, 0.00e+00, 2.00e+00, 1.40e+02, 2.94e+02, 0.00e+00,\n",
      "        2.00e+00, 1.53e+02, 0.00e+00, 1.30e+00, 2.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.80e+01, 0.00e+00, 3.00e+00, 1.20e+02, 2.11e+02, 0.00e+00,\n",
      "        2.00e+00, 1.15e+02, 0.00e+00, 1.50e+00, 2.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [5.20e+01, 0.00e+00, 3.00e+00, 1.36e+02, 1.96e+02, 0.00e+00,\n",
      "        2.00e+00, 1.69e+02, 0.00e+00, 1.00e-01, 2.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.20e+01, 0.00e+00, 4.00e+00, 1.40e+02, 3.94e+02, 0.00e+00,\n",
      "        2.00e+00, 1.57e+02, 0.00e+00, 1.20e+00, 2.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.30e+01, 1.00e+00, 4.00e+00, 1.30e+02, 2.54e+02, 0.00e+00,\n",
      "        2.00e+00, 1.47e+02, 0.00e+00, 1.40e+00, 2.00e+00, 1.00e+00,\n",
      "        7.00e+00],\n",
      "       [6.40e+01, 1.00e+00, 3.00e+00, 1.40e+02, 3.35e+02, 0.00e+00,\n",
      "        0.00e+00, 1.58e+02, 0.00e+00, 0.00e+00, 1.00e+00, 0.00e+00,\n",
      "        3.00e+00]]), array([[0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1]]))}\n",
      "Means: 0.5280898809432983, Stdev: 0.04587058349773997 with: {'batch_size': 60, 'class_weight': {0: 0.5, 1: 100}, 'epochs': 100, 'shuffle': True, 'validation_data': (array([[6.50e+01, 1.00e+00, 4.00e+00, 1.20e+02, 1.77e+02, 0.00e+00,\n",
      "        0.00e+00, 1.40e+02, 0.00e+00, 4.00e-01, 1.00e+00, 0.00e+00,\n",
      "        7.00e+00],\n",
      "       [5.80e+01, 1.00e+00, 4.00e+00, 1.46e+02, 2.18e+02, 0.00e+00,\n",
      "        0.00e+00, 1.05e+02, 0.00e+00, 2.00e+00, 2.00e+00, 1.00e+00,\n",
      "        7.00e+00],\n",
      "       [4.70e+01, 1.00e+00, 4.00e+00, 1.10e+02, 2.75e+02, 0.00e+00,\n",
      "        2.00e+00, 1.18e+02, 1.00e+00, 1.00e+00, 2.00e+00, 1.00e+00,\n",
      "        3.00e+00],\n",
      "       [5.70e+01, 1.00e+00, 4.00e+00, 1.10e+02, 2.01e+02, 0.00e+00,\n",
      "        0.00e+00, 1.26e+02, 1.00e+00, 1.50e+00, 2.00e+00, 0.00e+00,\n",
      "        6.00e+00],\n",
      "       [3.40e+01, 1.00e+00, 1.00e+00, 1.18e+02, 1.82e+02, 0.00e+00,\n",
      "        2.00e+00, 1.74e+02, 0.00e+00, 0.00e+00, 1.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.60e+01, 0.00e+00, 1.00e+00, 1.50e+02, 2.26e+02, 0.00e+00,\n",
      "        0.00e+00, 1.14e+02, 0.00e+00, 2.60e+00, 3.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [4.70e+01, 1.00e+00, 3.00e+00, 1.30e+02, 2.53e+02, 0.00e+00,\n",
      "        0.00e+00, 1.79e+02, 0.00e+00, 0.00e+00, 1.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.00e+01, 1.00e+00, 3.00e+00, 1.40e+02, 1.85e+02, 0.00e+00,\n",
      "        2.00e+00, 1.55e+02, 0.00e+00, 3.00e+00, 2.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [5.40e+01, 0.00e+00, 2.00e+00, 1.32e+02, 2.88e+02, 1.00e+00,\n",
      "        2.00e+00, 1.59e+02, 1.00e+00, 0.00e+00, 1.00e+00, 1.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.40e+01, 1.00e+00, 4.00e+00, 1.20e+02, 2.46e+02, 0.00e+00,\n",
      "        2.00e+00, 9.60e+01, 1.00e+00, 2.20e+00, 3.00e+00, 1.00e+00,\n",
      "        3.00e+00],\n",
      "       [4.00e+01, 1.00e+00, 1.00e+00, 1.40e+02, 1.99e+02, 0.00e+00,\n",
      "        0.00e+00, 1.78e+02, 1.00e+00, 1.40e+00, 1.00e+00, 0.00e+00,\n",
      "        7.00e+00],\n",
      "       [4.20e+01, 1.00e+00, 1.00e+00, 1.48e+02, 2.44e+02, 0.00e+00,\n",
      "        2.00e+00, 1.78e+02, 0.00e+00, 8.00e-01, 1.00e+00, 2.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.90e+01, 1.00e+00, 1.00e+00, 1.60e+02, 2.34e+02, 1.00e+00,\n",
      "        2.00e+00, 1.31e+02, 0.00e+00, 1.00e-01, 2.00e+00, 1.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.90e+01, 0.00e+00, 1.00e+00, 1.40e+02, 2.39e+02, 0.00e+00,\n",
      "        0.00e+00, 1.51e+02, 0.00e+00, 1.80e+00, 1.00e+00, 2.00e+00,\n",
      "        3.00e+00],\n",
      "       [4.80e+01, 1.00e+00, 4.00e+00, 1.24e+02, 2.74e+02, 0.00e+00,\n",
      "        2.00e+00, 1.66e+02, 0.00e+00, 5.00e-01, 2.00e+00, 0.00e+00,\n",
      "        7.00e+00],\n",
      "       [5.80e+01, 1.00e+00, 4.00e+00, 1.25e+02, 3.00e+02, 0.00e+00,\n",
      "        2.00e+00, 1.71e+02, 0.00e+00, 0.00e+00, 1.00e+00, 2.00e+00,\n",
      "        7.00e+00],\n",
      "       [5.80e+01, 1.00e+00, 4.00e+00, 1.14e+02, 3.18e+02, 0.00e+00,\n",
      "        1.00e+00, 1.40e+02, 0.00e+00, 4.40e+00, 3.00e+00, 3.00e+00,\n",
      "        6.00e+00],\n",
      "       [5.30e+01, 1.00e+00, 4.00e+00, 1.40e+02, 2.03e+02, 1.00e+00,\n",
      "        2.00e+00, 1.55e+02, 1.00e+00, 3.10e+00, 3.00e+00, 0.00e+00,\n",
      "        7.00e+00],\n",
      "       [5.80e+01, 0.00e+00, 4.00e+00, 1.30e+02, 1.97e+02, 0.00e+00,\n",
      "        0.00e+00, 1.31e+02, 0.00e+00, 6.00e-01, 2.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.10e+01, 1.00e+00, 4.00e+00, 1.40e+02, 2.07e+02, 0.00e+00,\n",
      "        2.00e+00, 1.38e+02, 1.00e+00, 1.90e+00, 1.00e+00, 1.00e+00,\n",
      "        7.00e+00],\n",
      "       [4.40e+01, 1.00e+00, 3.00e+00, 1.40e+02, 2.35e+02, 0.00e+00,\n",
      "        2.00e+00, 1.80e+02, 0.00e+00, 0.00e+00, 1.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [4.90e+01, 1.00e+00, 3.00e+00, 1.18e+02, 1.49e+02, 0.00e+00,\n",
      "        2.00e+00, 1.26e+02, 0.00e+00, 8.00e-01, 1.00e+00, 3.00e+00,\n",
      "        3.00e+00],\n",
      "       [4.70e+01, 1.00e+00, 3.00e+00, 1.08e+02, 2.43e+02, 0.00e+00,\n",
      "        0.00e+00, 1.52e+02, 0.00e+00, 0.00e+00, 1.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [4.30e+01, 0.00e+00, 4.00e+00, 1.32e+02, 3.41e+02, 1.00e+00,\n",
      "        2.00e+00, 1.36e+02, 1.00e+00, 3.00e+00, 2.00e+00, 0.00e+00,\n",
      "        7.00e+00],\n",
      "       [5.60e+01, 0.00e+00, 2.00e+00, 1.40e+02, 2.94e+02, 0.00e+00,\n",
      "        2.00e+00, 1.53e+02, 0.00e+00, 1.30e+00, 2.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.80e+01, 0.00e+00, 3.00e+00, 1.20e+02, 2.11e+02, 0.00e+00,\n",
      "        2.00e+00, 1.15e+02, 0.00e+00, 1.50e+00, 2.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [5.20e+01, 0.00e+00, 3.00e+00, 1.36e+02, 1.96e+02, 0.00e+00,\n",
      "        2.00e+00, 1.69e+02, 0.00e+00, 1.00e-01, 2.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.20e+01, 0.00e+00, 4.00e+00, 1.40e+02, 3.94e+02, 0.00e+00,\n",
      "        2.00e+00, 1.57e+02, 0.00e+00, 1.20e+00, 2.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.30e+01, 1.00e+00, 4.00e+00, 1.30e+02, 2.54e+02, 0.00e+00,\n",
      "        2.00e+00, 1.47e+02, 0.00e+00, 1.40e+00, 2.00e+00, 1.00e+00,\n",
      "        7.00e+00],\n",
      "       [6.40e+01, 1.00e+00, 3.00e+00, 1.40e+02, 3.35e+02, 0.00e+00,\n",
      "        0.00e+00, 1.58e+02, 0.00e+00, 0.00e+00, 1.00e+00, 0.00e+00,\n",
      "        3.00e+00]]), array([[0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1]]))}\n",
      "Means: 0.47940075397491455, Stdev: 0.034732645260272504 with: {'batch_size': 60, 'class_weight': {0: 0.5, 1: 100}, 'epochs': 100, 'shuffle': False, 'validation_data': (array([[6.50e+01, 1.00e+00, 4.00e+00, 1.20e+02, 1.77e+02, 0.00e+00,\n",
      "        0.00e+00, 1.40e+02, 0.00e+00, 4.00e-01, 1.00e+00, 0.00e+00,\n",
      "        7.00e+00],\n",
      "       [5.80e+01, 1.00e+00, 4.00e+00, 1.46e+02, 2.18e+02, 0.00e+00,\n",
      "        0.00e+00, 1.05e+02, 0.00e+00, 2.00e+00, 2.00e+00, 1.00e+00,\n",
      "        7.00e+00],\n",
      "       [4.70e+01, 1.00e+00, 4.00e+00, 1.10e+02, 2.75e+02, 0.00e+00,\n",
      "        2.00e+00, 1.18e+02, 1.00e+00, 1.00e+00, 2.00e+00, 1.00e+00,\n",
      "        3.00e+00],\n",
      "       [5.70e+01, 1.00e+00, 4.00e+00, 1.10e+02, 2.01e+02, 0.00e+00,\n",
      "        0.00e+00, 1.26e+02, 1.00e+00, 1.50e+00, 2.00e+00, 0.00e+00,\n",
      "        6.00e+00],\n",
      "       [3.40e+01, 1.00e+00, 1.00e+00, 1.18e+02, 1.82e+02, 0.00e+00,\n",
      "        2.00e+00, 1.74e+02, 0.00e+00, 0.00e+00, 1.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.60e+01, 0.00e+00, 1.00e+00, 1.50e+02, 2.26e+02, 0.00e+00,\n",
      "        0.00e+00, 1.14e+02, 0.00e+00, 2.60e+00, 3.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [4.70e+01, 1.00e+00, 3.00e+00, 1.30e+02, 2.53e+02, 0.00e+00,\n",
      "        0.00e+00, 1.79e+02, 0.00e+00, 0.00e+00, 1.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.00e+01, 1.00e+00, 3.00e+00, 1.40e+02, 1.85e+02, 0.00e+00,\n",
      "        2.00e+00, 1.55e+02, 0.00e+00, 3.00e+00, 2.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [5.40e+01, 0.00e+00, 2.00e+00, 1.32e+02, 2.88e+02, 1.00e+00,\n",
      "        2.00e+00, 1.59e+02, 1.00e+00, 0.00e+00, 1.00e+00, 1.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.40e+01, 1.00e+00, 4.00e+00, 1.20e+02, 2.46e+02, 0.00e+00,\n",
      "        2.00e+00, 9.60e+01, 1.00e+00, 2.20e+00, 3.00e+00, 1.00e+00,\n",
      "        3.00e+00],\n",
      "       [4.00e+01, 1.00e+00, 1.00e+00, 1.40e+02, 1.99e+02, 0.00e+00,\n",
      "        0.00e+00, 1.78e+02, 1.00e+00, 1.40e+00, 1.00e+00, 0.00e+00,\n",
      "        7.00e+00],\n",
      "       [4.20e+01, 1.00e+00, 1.00e+00, 1.48e+02, 2.44e+02, 0.00e+00,\n",
      "        2.00e+00, 1.78e+02, 0.00e+00, 8.00e-01, 1.00e+00, 2.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.90e+01, 1.00e+00, 1.00e+00, 1.60e+02, 2.34e+02, 1.00e+00,\n",
      "        2.00e+00, 1.31e+02, 0.00e+00, 1.00e-01, 2.00e+00, 1.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.90e+01, 0.00e+00, 1.00e+00, 1.40e+02, 2.39e+02, 0.00e+00,\n",
      "        0.00e+00, 1.51e+02, 0.00e+00, 1.80e+00, 1.00e+00, 2.00e+00,\n",
      "        3.00e+00],\n",
      "       [4.80e+01, 1.00e+00, 4.00e+00, 1.24e+02, 2.74e+02, 0.00e+00,\n",
      "        2.00e+00, 1.66e+02, 0.00e+00, 5.00e-01, 2.00e+00, 0.00e+00,\n",
      "        7.00e+00],\n",
      "       [5.80e+01, 1.00e+00, 4.00e+00, 1.25e+02, 3.00e+02, 0.00e+00,\n",
      "        2.00e+00, 1.71e+02, 0.00e+00, 0.00e+00, 1.00e+00, 2.00e+00,\n",
      "        7.00e+00],\n",
      "       [5.80e+01, 1.00e+00, 4.00e+00, 1.14e+02, 3.18e+02, 0.00e+00,\n",
      "        1.00e+00, 1.40e+02, 0.00e+00, 4.40e+00, 3.00e+00, 3.00e+00,\n",
      "        6.00e+00],\n",
      "       [5.30e+01, 1.00e+00, 4.00e+00, 1.40e+02, 2.03e+02, 1.00e+00,\n",
      "        2.00e+00, 1.55e+02, 1.00e+00, 3.10e+00, 3.00e+00, 0.00e+00,\n",
      "        7.00e+00],\n",
      "       [5.80e+01, 0.00e+00, 4.00e+00, 1.30e+02, 1.97e+02, 0.00e+00,\n",
      "        0.00e+00, 1.31e+02, 0.00e+00, 6.00e-01, 2.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.10e+01, 1.00e+00, 4.00e+00, 1.40e+02, 2.07e+02, 0.00e+00,\n",
      "        2.00e+00, 1.38e+02, 1.00e+00, 1.90e+00, 1.00e+00, 1.00e+00,\n",
      "        7.00e+00],\n",
      "       [4.40e+01, 1.00e+00, 3.00e+00, 1.40e+02, 2.35e+02, 0.00e+00,\n",
      "        2.00e+00, 1.80e+02, 0.00e+00, 0.00e+00, 1.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [4.90e+01, 1.00e+00, 3.00e+00, 1.18e+02, 1.49e+02, 0.00e+00,\n",
      "        2.00e+00, 1.26e+02, 0.00e+00, 8.00e-01, 1.00e+00, 3.00e+00,\n",
      "        3.00e+00],\n",
      "       [4.70e+01, 1.00e+00, 3.00e+00, 1.08e+02, 2.43e+02, 0.00e+00,\n",
      "        0.00e+00, 1.52e+02, 0.00e+00, 0.00e+00, 1.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [4.30e+01, 0.00e+00, 4.00e+00, 1.32e+02, 3.41e+02, 1.00e+00,\n",
      "        2.00e+00, 1.36e+02, 1.00e+00, 3.00e+00, 2.00e+00, 0.00e+00,\n",
      "        7.00e+00],\n",
      "       [5.60e+01, 0.00e+00, 2.00e+00, 1.40e+02, 2.94e+02, 0.00e+00,\n",
      "        2.00e+00, 1.53e+02, 0.00e+00, 1.30e+00, 2.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.80e+01, 0.00e+00, 3.00e+00, 1.20e+02, 2.11e+02, 0.00e+00,\n",
      "        2.00e+00, 1.15e+02, 0.00e+00, 1.50e+00, 2.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [5.20e+01, 0.00e+00, 3.00e+00, 1.36e+02, 1.96e+02, 0.00e+00,\n",
      "        2.00e+00, 1.69e+02, 0.00e+00, 1.00e-01, 2.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.20e+01, 0.00e+00, 4.00e+00, 1.40e+02, 3.94e+02, 0.00e+00,\n",
      "        2.00e+00, 1.57e+02, 0.00e+00, 1.20e+00, 2.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.30e+01, 1.00e+00, 4.00e+00, 1.30e+02, 2.54e+02, 0.00e+00,\n",
      "        2.00e+00, 1.47e+02, 0.00e+00, 1.40e+00, 2.00e+00, 1.00e+00,\n",
      "        7.00e+00],\n",
      "       [6.40e+01, 1.00e+00, 3.00e+00, 1.40e+02, 3.35e+02, 0.00e+00,\n",
      "        0.00e+00, 1.58e+02, 0.00e+00, 0.00e+00, 1.00e+00, 0.00e+00,\n",
      "        3.00e+00]]), array([[0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1]]))}\n",
      "Means: 0.4606741666793823, Stdev: 0.009174116699547994 with: {'batch_size': 60, 'class_weight': {0: 0.5, 1: 100}, 'epochs': 150, 'shuffle': True, 'validation_data': (array([[6.50e+01, 1.00e+00, 4.00e+00, 1.20e+02, 1.77e+02, 0.00e+00,\n",
      "        0.00e+00, 1.40e+02, 0.00e+00, 4.00e-01, 1.00e+00, 0.00e+00,\n",
      "        7.00e+00],\n",
      "       [5.80e+01, 1.00e+00, 4.00e+00, 1.46e+02, 2.18e+02, 0.00e+00,\n",
      "        0.00e+00, 1.05e+02, 0.00e+00, 2.00e+00, 2.00e+00, 1.00e+00,\n",
      "        7.00e+00],\n",
      "       [4.70e+01, 1.00e+00, 4.00e+00, 1.10e+02, 2.75e+02, 0.00e+00,\n",
      "        2.00e+00, 1.18e+02, 1.00e+00, 1.00e+00, 2.00e+00, 1.00e+00,\n",
      "        3.00e+00],\n",
      "       [5.70e+01, 1.00e+00, 4.00e+00, 1.10e+02, 2.01e+02, 0.00e+00,\n",
      "        0.00e+00, 1.26e+02, 1.00e+00, 1.50e+00, 2.00e+00, 0.00e+00,\n",
      "        6.00e+00],\n",
      "       [3.40e+01, 1.00e+00, 1.00e+00, 1.18e+02, 1.82e+02, 0.00e+00,\n",
      "        2.00e+00, 1.74e+02, 0.00e+00, 0.00e+00, 1.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.60e+01, 0.00e+00, 1.00e+00, 1.50e+02, 2.26e+02, 0.00e+00,\n",
      "        0.00e+00, 1.14e+02, 0.00e+00, 2.60e+00, 3.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [4.70e+01, 1.00e+00, 3.00e+00, 1.30e+02, 2.53e+02, 0.00e+00,\n",
      "        0.00e+00, 1.79e+02, 0.00e+00, 0.00e+00, 1.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.00e+01, 1.00e+00, 3.00e+00, 1.40e+02, 1.85e+02, 0.00e+00,\n",
      "        2.00e+00, 1.55e+02, 0.00e+00, 3.00e+00, 2.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [5.40e+01, 0.00e+00, 2.00e+00, 1.32e+02, 2.88e+02, 1.00e+00,\n",
      "        2.00e+00, 1.59e+02, 1.00e+00, 0.00e+00, 1.00e+00, 1.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.40e+01, 1.00e+00, 4.00e+00, 1.20e+02, 2.46e+02, 0.00e+00,\n",
      "        2.00e+00, 9.60e+01, 1.00e+00, 2.20e+00, 3.00e+00, 1.00e+00,\n",
      "        3.00e+00],\n",
      "       [4.00e+01, 1.00e+00, 1.00e+00, 1.40e+02, 1.99e+02, 0.00e+00,\n",
      "        0.00e+00, 1.78e+02, 1.00e+00, 1.40e+00, 1.00e+00, 0.00e+00,\n",
      "        7.00e+00],\n",
      "       [4.20e+01, 1.00e+00, 1.00e+00, 1.48e+02, 2.44e+02, 0.00e+00,\n",
      "        2.00e+00, 1.78e+02, 0.00e+00, 8.00e-01, 1.00e+00, 2.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.90e+01, 1.00e+00, 1.00e+00, 1.60e+02, 2.34e+02, 1.00e+00,\n",
      "        2.00e+00, 1.31e+02, 0.00e+00, 1.00e-01, 2.00e+00, 1.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.90e+01, 0.00e+00, 1.00e+00, 1.40e+02, 2.39e+02, 0.00e+00,\n",
      "        0.00e+00, 1.51e+02, 0.00e+00, 1.80e+00, 1.00e+00, 2.00e+00,\n",
      "        3.00e+00],\n",
      "       [4.80e+01, 1.00e+00, 4.00e+00, 1.24e+02, 2.74e+02, 0.00e+00,\n",
      "        2.00e+00, 1.66e+02, 0.00e+00, 5.00e-01, 2.00e+00, 0.00e+00,\n",
      "        7.00e+00],\n",
      "       [5.80e+01, 1.00e+00, 4.00e+00, 1.25e+02, 3.00e+02, 0.00e+00,\n",
      "        2.00e+00, 1.71e+02, 0.00e+00, 0.00e+00, 1.00e+00, 2.00e+00,\n",
      "        7.00e+00],\n",
      "       [5.80e+01, 1.00e+00, 4.00e+00, 1.14e+02, 3.18e+02, 0.00e+00,\n",
      "        1.00e+00, 1.40e+02, 0.00e+00, 4.40e+00, 3.00e+00, 3.00e+00,\n",
      "        6.00e+00],\n",
      "       [5.30e+01, 1.00e+00, 4.00e+00, 1.40e+02, 2.03e+02, 1.00e+00,\n",
      "        2.00e+00, 1.55e+02, 1.00e+00, 3.10e+00, 3.00e+00, 0.00e+00,\n",
      "        7.00e+00],\n",
      "       [5.80e+01, 0.00e+00, 4.00e+00, 1.30e+02, 1.97e+02, 0.00e+00,\n",
      "        0.00e+00, 1.31e+02, 0.00e+00, 6.00e-01, 2.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.10e+01, 1.00e+00, 4.00e+00, 1.40e+02, 2.07e+02, 0.00e+00,\n",
      "        2.00e+00, 1.38e+02, 1.00e+00, 1.90e+00, 1.00e+00, 1.00e+00,\n",
      "        7.00e+00],\n",
      "       [4.40e+01, 1.00e+00, 3.00e+00, 1.40e+02, 2.35e+02, 0.00e+00,\n",
      "        2.00e+00, 1.80e+02, 0.00e+00, 0.00e+00, 1.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [4.90e+01, 1.00e+00, 3.00e+00, 1.18e+02, 1.49e+02, 0.00e+00,\n",
      "        2.00e+00, 1.26e+02, 0.00e+00, 8.00e-01, 1.00e+00, 3.00e+00,\n",
      "        3.00e+00],\n",
      "       [4.70e+01, 1.00e+00, 3.00e+00, 1.08e+02, 2.43e+02, 0.00e+00,\n",
      "        0.00e+00, 1.52e+02, 0.00e+00, 0.00e+00, 1.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [4.30e+01, 0.00e+00, 4.00e+00, 1.32e+02, 3.41e+02, 1.00e+00,\n",
      "        2.00e+00, 1.36e+02, 1.00e+00, 3.00e+00, 2.00e+00, 0.00e+00,\n",
      "        7.00e+00],\n",
      "       [5.60e+01, 0.00e+00, 2.00e+00, 1.40e+02, 2.94e+02, 0.00e+00,\n",
      "        2.00e+00, 1.53e+02, 0.00e+00, 1.30e+00, 2.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.80e+01, 0.00e+00, 3.00e+00, 1.20e+02, 2.11e+02, 0.00e+00,\n",
      "        2.00e+00, 1.15e+02, 0.00e+00, 1.50e+00, 2.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [5.20e+01, 0.00e+00, 3.00e+00, 1.36e+02, 1.96e+02, 0.00e+00,\n",
      "        2.00e+00, 1.69e+02, 0.00e+00, 1.00e-01, 2.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.20e+01, 0.00e+00, 4.00e+00, 1.40e+02, 3.94e+02, 0.00e+00,\n",
      "        2.00e+00, 1.57e+02, 0.00e+00, 1.20e+00, 2.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.30e+01, 1.00e+00, 4.00e+00, 1.30e+02, 2.54e+02, 0.00e+00,\n",
      "        2.00e+00, 1.47e+02, 0.00e+00, 1.40e+00, 2.00e+00, 1.00e+00,\n",
      "        7.00e+00],\n",
      "       [6.40e+01, 1.00e+00, 3.00e+00, 1.40e+02, 3.35e+02, 0.00e+00,\n",
      "        0.00e+00, 1.58e+02, 0.00e+00, 0.00e+00, 1.00e+00, 0.00e+00,\n",
      "        3.00e+00]]), array([[0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1]]))}\n",
      "Means: 0.5056179761886597, Stdev: 0.039989047589578594 with: {'batch_size': 60, 'class_weight': {0: 0.5, 1: 100}, 'epochs': 150, 'shuffle': False, 'validation_data': (array([[6.50e+01, 1.00e+00, 4.00e+00, 1.20e+02, 1.77e+02, 0.00e+00,\n",
      "        0.00e+00, 1.40e+02, 0.00e+00, 4.00e-01, 1.00e+00, 0.00e+00,\n",
      "        7.00e+00],\n",
      "       [5.80e+01, 1.00e+00, 4.00e+00, 1.46e+02, 2.18e+02, 0.00e+00,\n",
      "        0.00e+00, 1.05e+02, 0.00e+00, 2.00e+00, 2.00e+00, 1.00e+00,\n",
      "        7.00e+00],\n",
      "       [4.70e+01, 1.00e+00, 4.00e+00, 1.10e+02, 2.75e+02, 0.00e+00,\n",
      "        2.00e+00, 1.18e+02, 1.00e+00, 1.00e+00, 2.00e+00, 1.00e+00,\n",
      "        3.00e+00],\n",
      "       [5.70e+01, 1.00e+00, 4.00e+00, 1.10e+02, 2.01e+02, 0.00e+00,\n",
      "        0.00e+00, 1.26e+02, 1.00e+00, 1.50e+00, 2.00e+00, 0.00e+00,\n",
      "        6.00e+00],\n",
      "       [3.40e+01, 1.00e+00, 1.00e+00, 1.18e+02, 1.82e+02, 0.00e+00,\n",
      "        2.00e+00, 1.74e+02, 0.00e+00, 0.00e+00, 1.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.60e+01, 0.00e+00, 1.00e+00, 1.50e+02, 2.26e+02, 0.00e+00,\n",
      "        0.00e+00, 1.14e+02, 0.00e+00, 2.60e+00, 3.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [4.70e+01, 1.00e+00, 3.00e+00, 1.30e+02, 2.53e+02, 0.00e+00,\n",
      "        0.00e+00, 1.79e+02, 0.00e+00, 0.00e+00, 1.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.00e+01, 1.00e+00, 3.00e+00, 1.40e+02, 1.85e+02, 0.00e+00,\n",
      "        2.00e+00, 1.55e+02, 0.00e+00, 3.00e+00, 2.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [5.40e+01, 0.00e+00, 2.00e+00, 1.32e+02, 2.88e+02, 1.00e+00,\n",
      "        2.00e+00, 1.59e+02, 1.00e+00, 0.00e+00, 1.00e+00, 1.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.40e+01, 1.00e+00, 4.00e+00, 1.20e+02, 2.46e+02, 0.00e+00,\n",
      "        2.00e+00, 9.60e+01, 1.00e+00, 2.20e+00, 3.00e+00, 1.00e+00,\n",
      "        3.00e+00],\n",
      "       [4.00e+01, 1.00e+00, 1.00e+00, 1.40e+02, 1.99e+02, 0.00e+00,\n",
      "        0.00e+00, 1.78e+02, 1.00e+00, 1.40e+00, 1.00e+00, 0.00e+00,\n",
      "        7.00e+00],\n",
      "       [4.20e+01, 1.00e+00, 1.00e+00, 1.48e+02, 2.44e+02, 0.00e+00,\n",
      "        2.00e+00, 1.78e+02, 0.00e+00, 8.00e-01, 1.00e+00, 2.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.90e+01, 1.00e+00, 1.00e+00, 1.60e+02, 2.34e+02, 1.00e+00,\n",
      "        2.00e+00, 1.31e+02, 0.00e+00, 1.00e-01, 2.00e+00, 1.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.90e+01, 0.00e+00, 1.00e+00, 1.40e+02, 2.39e+02, 0.00e+00,\n",
      "        0.00e+00, 1.51e+02, 0.00e+00, 1.80e+00, 1.00e+00, 2.00e+00,\n",
      "        3.00e+00],\n",
      "       [4.80e+01, 1.00e+00, 4.00e+00, 1.24e+02, 2.74e+02, 0.00e+00,\n",
      "        2.00e+00, 1.66e+02, 0.00e+00, 5.00e-01, 2.00e+00, 0.00e+00,\n",
      "        7.00e+00],\n",
      "       [5.80e+01, 1.00e+00, 4.00e+00, 1.25e+02, 3.00e+02, 0.00e+00,\n",
      "        2.00e+00, 1.71e+02, 0.00e+00, 0.00e+00, 1.00e+00, 2.00e+00,\n",
      "        7.00e+00],\n",
      "       [5.80e+01, 1.00e+00, 4.00e+00, 1.14e+02, 3.18e+02, 0.00e+00,\n",
      "        1.00e+00, 1.40e+02, 0.00e+00, 4.40e+00, 3.00e+00, 3.00e+00,\n",
      "        6.00e+00],\n",
      "       [5.30e+01, 1.00e+00, 4.00e+00, 1.40e+02, 2.03e+02, 1.00e+00,\n",
      "        2.00e+00, 1.55e+02, 1.00e+00, 3.10e+00, 3.00e+00, 0.00e+00,\n",
      "        7.00e+00],\n",
      "       [5.80e+01, 0.00e+00, 4.00e+00, 1.30e+02, 1.97e+02, 0.00e+00,\n",
      "        0.00e+00, 1.31e+02, 0.00e+00, 6.00e-01, 2.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.10e+01, 1.00e+00, 4.00e+00, 1.40e+02, 2.07e+02, 0.00e+00,\n",
      "        2.00e+00, 1.38e+02, 1.00e+00, 1.90e+00, 1.00e+00, 1.00e+00,\n",
      "        7.00e+00],\n",
      "       [4.40e+01, 1.00e+00, 3.00e+00, 1.40e+02, 2.35e+02, 0.00e+00,\n",
      "        2.00e+00, 1.80e+02, 0.00e+00, 0.00e+00, 1.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [4.90e+01, 1.00e+00, 3.00e+00, 1.18e+02, 1.49e+02, 0.00e+00,\n",
      "        2.00e+00, 1.26e+02, 0.00e+00, 8.00e-01, 1.00e+00, 3.00e+00,\n",
      "        3.00e+00],\n",
      "       [4.70e+01, 1.00e+00, 3.00e+00, 1.08e+02, 2.43e+02, 0.00e+00,\n",
      "        0.00e+00, 1.52e+02, 0.00e+00, 0.00e+00, 1.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [4.30e+01, 0.00e+00, 4.00e+00, 1.32e+02, 3.41e+02, 1.00e+00,\n",
      "        2.00e+00, 1.36e+02, 1.00e+00, 3.00e+00, 2.00e+00, 0.00e+00,\n",
      "        7.00e+00],\n",
      "       [5.60e+01, 0.00e+00, 2.00e+00, 1.40e+02, 2.94e+02, 0.00e+00,\n",
      "        2.00e+00, 1.53e+02, 0.00e+00, 1.30e+00, 2.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.80e+01, 0.00e+00, 3.00e+00, 1.20e+02, 2.11e+02, 0.00e+00,\n",
      "        2.00e+00, 1.15e+02, 0.00e+00, 1.50e+00, 2.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [5.20e+01, 0.00e+00, 3.00e+00, 1.36e+02, 1.96e+02, 0.00e+00,\n",
      "        2.00e+00, 1.69e+02, 0.00e+00, 1.00e-01, 2.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.20e+01, 0.00e+00, 4.00e+00, 1.40e+02, 3.94e+02, 0.00e+00,\n",
      "        2.00e+00, 1.57e+02, 0.00e+00, 1.20e+00, 2.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.30e+01, 1.00e+00, 4.00e+00, 1.30e+02, 2.54e+02, 0.00e+00,\n",
      "        2.00e+00, 1.47e+02, 0.00e+00, 1.40e+00, 2.00e+00, 1.00e+00,\n",
      "        7.00e+00],\n",
      "       [6.40e+01, 1.00e+00, 3.00e+00, 1.40e+02, 3.35e+02, 0.00e+00,\n",
      "        0.00e+00, 1.58e+02, 0.00e+00, 0.00e+00, 1.00e+00, 0.00e+00,\n",
      "        3.00e+00]]), array([[0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1]]))}\n",
      "Means: 0.5056179761886597, Stdev: 0.039989047589578594 with: {'batch_size': 60, 'class_weight': {0: 0.5, 1: 100}, 'epochs': 250, 'shuffle': True, 'validation_data': (array([[6.50e+01, 1.00e+00, 4.00e+00, 1.20e+02, 1.77e+02, 0.00e+00,\n",
      "        0.00e+00, 1.40e+02, 0.00e+00, 4.00e-01, 1.00e+00, 0.00e+00,\n",
      "        7.00e+00],\n",
      "       [5.80e+01, 1.00e+00, 4.00e+00, 1.46e+02, 2.18e+02, 0.00e+00,\n",
      "        0.00e+00, 1.05e+02, 0.00e+00, 2.00e+00, 2.00e+00, 1.00e+00,\n",
      "        7.00e+00],\n",
      "       [4.70e+01, 1.00e+00, 4.00e+00, 1.10e+02, 2.75e+02, 0.00e+00,\n",
      "        2.00e+00, 1.18e+02, 1.00e+00, 1.00e+00, 2.00e+00, 1.00e+00,\n",
      "        3.00e+00],\n",
      "       [5.70e+01, 1.00e+00, 4.00e+00, 1.10e+02, 2.01e+02, 0.00e+00,\n",
      "        0.00e+00, 1.26e+02, 1.00e+00, 1.50e+00, 2.00e+00, 0.00e+00,\n",
      "        6.00e+00],\n",
      "       [3.40e+01, 1.00e+00, 1.00e+00, 1.18e+02, 1.82e+02, 0.00e+00,\n",
      "        2.00e+00, 1.74e+02, 0.00e+00, 0.00e+00, 1.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.60e+01, 0.00e+00, 1.00e+00, 1.50e+02, 2.26e+02, 0.00e+00,\n",
      "        0.00e+00, 1.14e+02, 0.00e+00, 2.60e+00, 3.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [4.70e+01, 1.00e+00, 3.00e+00, 1.30e+02, 2.53e+02, 0.00e+00,\n",
      "        0.00e+00, 1.79e+02, 0.00e+00, 0.00e+00, 1.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.00e+01, 1.00e+00, 3.00e+00, 1.40e+02, 1.85e+02, 0.00e+00,\n",
      "        2.00e+00, 1.55e+02, 0.00e+00, 3.00e+00, 2.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [5.40e+01, 0.00e+00, 2.00e+00, 1.32e+02, 2.88e+02, 1.00e+00,\n",
      "        2.00e+00, 1.59e+02, 1.00e+00, 0.00e+00, 1.00e+00, 1.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.40e+01, 1.00e+00, 4.00e+00, 1.20e+02, 2.46e+02, 0.00e+00,\n",
      "        2.00e+00, 9.60e+01, 1.00e+00, 2.20e+00, 3.00e+00, 1.00e+00,\n",
      "        3.00e+00],\n",
      "       [4.00e+01, 1.00e+00, 1.00e+00, 1.40e+02, 1.99e+02, 0.00e+00,\n",
      "        0.00e+00, 1.78e+02, 1.00e+00, 1.40e+00, 1.00e+00, 0.00e+00,\n",
      "        7.00e+00],\n",
      "       [4.20e+01, 1.00e+00, 1.00e+00, 1.48e+02, 2.44e+02, 0.00e+00,\n",
      "        2.00e+00, 1.78e+02, 0.00e+00, 8.00e-01, 1.00e+00, 2.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.90e+01, 1.00e+00, 1.00e+00, 1.60e+02, 2.34e+02, 1.00e+00,\n",
      "        2.00e+00, 1.31e+02, 0.00e+00, 1.00e-01, 2.00e+00, 1.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.90e+01, 0.00e+00, 1.00e+00, 1.40e+02, 2.39e+02, 0.00e+00,\n",
      "        0.00e+00, 1.51e+02, 0.00e+00, 1.80e+00, 1.00e+00, 2.00e+00,\n",
      "        3.00e+00],\n",
      "       [4.80e+01, 1.00e+00, 4.00e+00, 1.24e+02, 2.74e+02, 0.00e+00,\n",
      "        2.00e+00, 1.66e+02, 0.00e+00, 5.00e-01, 2.00e+00, 0.00e+00,\n",
      "        7.00e+00],\n",
      "       [5.80e+01, 1.00e+00, 4.00e+00, 1.25e+02, 3.00e+02, 0.00e+00,\n",
      "        2.00e+00, 1.71e+02, 0.00e+00, 0.00e+00, 1.00e+00, 2.00e+00,\n",
      "        7.00e+00],\n",
      "       [5.80e+01, 1.00e+00, 4.00e+00, 1.14e+02, 3.18e+02, 0.00e+00,\n",
      "        1.00e+00, 1.40e+02, 0.00e+00, 4.40e+00, 3.00e+00, 3.00e+00,\n",
      "        6.00e+00],\n",
      "       [5.30e+01, 1.00e+00, 4.00e+00, 1.40e+02, 2.03e+02, 1.00e+00,\n",
      "        2.00e+00, 1.55e+02, 1.00e+00, 3.10e+00, 3.00e+00, 0.00e+00,\n",
      "        7.00e+00],\n",
      "       [5.80e+01, 0.00e+00, 4.00e+00, 1.30e+02, 1.97e+02, 0.00e+00,\n",
      "        0.00e+00, 1.31e+02, 0.00e+00, 6.00e-01, 2.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.10e+01, 1.00e+00, 4.00e+00, 1.40e+02, 2.07e+02, 0.00e+00,\n",
      "        2.00e+00, 1.38e+02, 1.00e+00, 1.90e+00, 1.00e+00, 1.00e+00,\n",
      "        7.00e+00],\n",
      "       [4.40e+01, 1.00e+00, 3.00e+00, 1.40e+02, 2.35e+02, 0.00e+00,\n",
      "        2.00e+00, 1.80e+02, 0.00e+00, 0.00e+00, 1.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [4.90e+01, 1.00e+00, 3.00e+00, 1.18e+02, 1.49e+02, 0.00e+00,\n",
      "        2.00e+00, 1.26e+02, 0.00e+00, 8.00e-01, 1.00e+00, 3.00e+00,\n",
      "        3.00e+00],\n",
      "       [4.70e+01, 1.00e+00, 3.00e+00, 1.08e+02, 2.43e+02, 0.00e+00,\n",
      "        0.00e+00, 1.52e+02, 0.00e+00, 0.00e+00, 1.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [4.30e+01, 0.00e+00, 4.00e+00, 1.32e+02, 3.41e+02, 1.00e+00,\n",
      "        2.00e+00, 1.36e+02, 1.00e+00, 3.00e+00, 2.00e+00, 0.00e+00,\n",
      "        7.00e+00],\n",
      "       [5.60e+01, 0.00e+00, 2.00e+00, 1.40e+02, 2.94e+02, 0.00e+00,\n",
      "        2.00e+00, 1.53e+02, 0.00e+00, 1.30e+00, 2.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.80e+01, 0.00e+00, 3.00e+00, 1.20e+02, 2.11e+02, 0.00e+00,\n",
      "        2.00e+00, 1.15e+02, 0.00e+00, 1.50e+00, 2.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [5.20e+01, 0.00e+00, 3.00e+00, 1.36e+02, 1.96e+02, 0.00e+00,\n",
      "        2.00e+00, 1.69e+02, 0.00e+00, 1.00e-01, 2.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.20e+01, 0.00e+00, 4.00e+00, 1.40e+02, 3.94e+02, 0.00e+00,\n",
      "        2.00e+00, 1.57e+02, 0.00e+00, 1.20e+00, 2.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.30e+01, 1.00e+00, 4.00e+00, 1.30e+02, 2.54e+02, 0.00e+00,\n",
      "        2.00e+00, 1.47e+02, 0.00e+00, 1.40e+00, 2.00e+00, 1.00e+00,\n",
      "        7.00e+00],\n",
      "       [6.40e+01, 1.00e+00, 3.00e+00, 1.40e+02, 3.35e+02, 0.00e+00,\n",
      "        0.00e+00, 1.58e+02, 0.00e+00, 0.00e+00, 1.00e+00, 0.00e+00,\n",
      "        3.00e+00]]), array([[0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1]]))}\n",
      "Means: 0.47940075397491455, Stdev: 0.034732645260272504 with: {'batch_size': 60, 'class_weight': {0: 0.5, 1: 100}, 'epochs': 250, 'shuffle': False, 'validation_data': (array([[6.50e+01, 1.00e+00, 4.00e+00, 1.20e+02, 1.77e+02, 0.00e+00,\n",
      "        0.00e+00, 1.40e+02, 0.00e+00, 4.00e-01, 1.00e+00, 0.00e+00,\n",
      "        7.00e+00],\n",
      "       [5.80e+01, 1.00e+00, 4.00e+00, 1.46e+02, 2.18e+02, 0.00e+00,\n",
      "        0.00e+00, 1.05e+02, 0.00e+00, 2.00e+00, 2.00e+00, 1.00e+00,\n",
      "        7.00e+00],\n",
      "       [4.70e+01, 1.00e+00, 4.00e+00, 1.10e+02, 2.75e+02, 0.00e+00,\n",
      "        2.00e+00, 1.18e+02, 1.00e+00, 1.00e+00, 2.00e+00, 1.00e+00,\n",
      "        3.00e+00],\n",
      "       [5.70e+01, 1.00e+00, 4.00e+00, 1.10e+02, 2.01e+02, 0.00e+00,\n",
      "        0.00e+00, 1.26e+02, 1.00e+00, 1.50e+00, 2.00e+00, 0.00e+00,\n",
      "        6.00e+00],\n",
      "       [3.40e+01, 1.00e+00, 1.00e+00, 1.18e+02, 1.82e+02, 0.00e+00,\n",
      "        2.00e+00, 1.74e+02, 0.00e+00, 0.00e+00, 1.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.60e+01, 0.00e+00, 1.00e+00, 1.50e+02, 2.26e+02, 0.00e+00,\n",
      "        0.00e+00, 1.14e+02, 0.00e+00, 2.60e+00, 3.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [4.70e+01, 1.00e+00, 3.00e+00, 1.30e+02, 2.53e+02, 0.00e+00,\n",
      "        0.00e+00, 1.79e+02, 0.00e+00, 0.00e+00, 1.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.00e+01, 1.00e+00, 3.00e+00, 1.40e+02, 1.85e+02, 0.00e+00,\n",
      "        2.00e+00, 1.55e+02, 0.00e+00, 3.00e+00, 2.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [5.40e+01, 0.00e+00, 2.00e+00, 1.32e+02, 2.88e+02, 1.00e+00,\n",
      "        2.00e+00, 1.59e+02, 1.00e+00, 0.00e+00, 1.00e+00, 1.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.40e+01, 1.00e+00, 4.00e+00, 1.20e+02, 2.46e+02, 0.00e+00,\n",
      "        2.00e+00, 9.60e+01, 1.00e+00, 2.20e+00, 3.00e+00, 1.00e+00,\n",
      "        3.00e+00],\n",
      "       [4.00e+01, 1.00e+00, 1.00e+00, 1.40e+02, 1.99e+02, 0.00e+00,\n",
      "        0.00e+00, 1.78e+02, 1.00e+00, 1.40e+00, 1.00e+00, 0.00e+00,\n",
      "        7.00e+00],\n",
      "       [4.20e+01, 1.00e+00, 1.00e+00, 1.48e+02, 2.44e+02, 0.00e+00,\n",
      "        2.00e+00, 1.78e+02, 0.00e+00, 8.00e-01, 1.00e+00, 2.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.90e+01, 1.00e+00, 1.00e+00, 1.60e+02, 2.34e+02, 1.00e+00,\n",
      "        2.00e+00, 1.31e+02, 0.00e+00, 1.00e-01, 2.00e+00, 1.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.90e+01, 0.00e+00, 1.00e+00, 1.40e+02, 2.39e+02, 0.00e+00,\n",
      "        0.00e+00, 1.51e+02, 0.00e+00, 1.80e+00, 1.00e+00, 2.00e+00,\n",
      "        3.00e+00],\n",
      "       [4.80e+01, 1.00e+00, 4.00e+00, 1.24e+02, 2.74e+02, 0.00e+00,\n",
      "        2.00e+00, 1.66e+02, 0.00e+00, 5.00e-01, 2.00e+00, 0.00e+00,\n",
      "        7.00e+00],\n",
      "       [5.80e+01, 1.00e+00, 4.00e+00, 1.25e+02, 3.00e+02, 0.00e+00,\n",
      "        2.00e+00, 1.71e+02, 0.00e+00, 0.00e+00, 1.00e+00, 2.00e+00,\n",
      "        7.00e+00],\n",
      "       [5.80e+01, 1.00e+00, 4.00e+00, 1.14e+02, 3.18e+02, 0.00e+00,\n",
      "        1.00e+00, 1.40e+02, 0.00e+00, 4.40e+00, 3.00e+00, 3.00e+00,\n",
      "        6.00e+00],\n",
      "       [5.30e+01, 1.00e+00, 4.00e+00, 1.40e+02, 2.03e+02, 1.00e+00,\n",
      "        2.00e+00, 1.55e+02, 1.00e+00, 3.10e+00, 3.00e+00, 0.00e+00,\n",
      "        7.00e+00],\n",
      "       [5.80e+01, 0.00e+00, 4.00e+00, 1.30e+02, 1.97e+02, 0.00e+00,\n",
      "        0.00e+00, 1.31e+02, 0.00e+00, 6.00e-01, 2.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.10e+01, 1.00e+00, 4.00e+00, 1.40e+02, 2.07e+02, 0.00e+00,\n",
      "        2.00e+00, 1.38e+02, 1.00e+00, 1.90e+00, 1.00e+00, 1.00e+00,\n",
      "        7.00e+00],\n",
      "       [4.40e+01, 1.00e+00, 3.00e+00, 1.40e+02, 2.35e+02, 0.00e+00,\n",
      "        2.00e+00, 1.80e+02, 0.00e+00, 0.00e+00, 1.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [4.90e+01, 1.00e+00, 3.00e+00, 1.18e+02, 1.49e+02, 0.00e+00,\n",
      "        2.00e+00, 1.26e+02, 0.00e+00, 8.00e-01, 1.00e+00, 3.00e+00,\n",
      "        3.00e+00],\n",
      "       [4.70e+01, 1.00e+00, 3.00e+00, 1.08e+02, 2.43e+02, 0.00e+00,\n",
      "        0.00e+00, 1.52e+02, 0.00e+00, 0.00e+00, 1.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [4.30e+01, 0.00e+00, 4.00e+00, 1.32e+02, 3.41e+02, 1.00e+00,\n",
      "        2.00e+00, 1.36e+02, 1.00e+00, 3.00e+00, 2.00e+00, 0.00e+00,\n",
      "        7.00e+00],\n",
      "       [5.60e+01, 0.00e+00, 2.00e+00, 1.40e+02, 2.94e+02, 0.00e+00,\n",
      "        2.00e+00, 1.53e+02, 0.00e+00, 1.30e+00, 2.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.80e+01, 0.00e+00, 3.00e+00, 1.20e+02, 2.11e+02, 0.00e+00,\n",
      "        2.00e+00, 1.15e+02, 0.00e+00, 1.50e+00, 2.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [5.20e+01, 0.00e+00, 3.00e+00, 1.36e+02, 1.96e+02, 0.00e+00,\n",
      "        2.00e+00, 1.69e+02, 0.00e+00, 1.00e-01, 2.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.20e+01, 0.00e+00, 4.00e+00, 1.40e+02, 3.94e+02, 0.00e+00,\n",
      "        2.00e+00, 1.57e+02, 0.00e+00, 1.20e+00, 2.00e+00, 0.00e+00,\n",
      "        3.00e+00],\n",
      "       [6.30e+01, 1.00e+00, 4.00e+00, 1.30e+02, 2.54e+02, 0.00e+00,\n",
      "        2.00e+00, 1.47e+02, 0.00e+00, 1.40e+00, 2.00e+00, 1.00e+00,\n",
      "        7.00e+00],\n",
      "       [6.40e+01, 1.00e+00, 3.00e+00, 1.40e+02, 3.35e+02, 0.00e+00,\n",
      "        0.00e+00, 1.58e+02, 0.00e+00, 0.00e+00, 1.00e+00, 0.00e+00,\n",
      "        3.00e+00]]), array([[0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1],\n",
      "       [1]]))}\n"
     ]
    }
   ],
   "source": [
    "# Report Results\n",
    "print(f\"Best: {grid_results.best_score_} using {grid_results.best_params_}\")\n",
    "means = grid_results.cv_results_['mean_test_score']\n",
    "stds = grid_results.cv_results_['std_test_score']\n",
    "params = grid_results.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = grid_results.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verbose': 0,\n",
       " 'batch_size': 60,\n",
       " 'class_weight': {0: 0.5, 1: 100},\n",
       " 'epochs': 100,\n",
       " 'shuffle': True,\n",
       " 'validation_data': (array([[6.50e+01, 1.00e+00, 4.00e+00, 1.20e+02, 1.77e+02, 0.00e+00,\n",
       "          0.00e+00, 1.40e+02, 0.00e+00, 4.00e-01, 1.00e+00, 0.00e+00,\n",
       "          7.00e+00],\n",
       "         [5.80e+01, 1.00e+00, 4.00e+00, 1.46e+02, 2.18e+02, 0.00e+00,\n",
       "          0.00e+00, 1.05e+02, 0.00e+00, 2.00e+00, 2.00e+00, 1.00e+00,\n",
       "          7.00e+00],\n",
       "         [4.70e+01, 1.00e+00, 4.00e+00, 1.10e+02, 2.75e+02, 0.00e+00,\n",
       "          2.00e+00, 1.18e+02, 1.00e+00, 1.00e+00, 2.00e+00, 1.00e+00,\n",
       "          3.00e+00],\n",
       "         [5.70e+01, 1.00e+00, 4.00e+00, 1.10e+02, 2.01e+02, 0.00e+00,\n",
       "          0.00e+00, 1.26e+02, 1.00e+00, 1.50e+00, 2.00e+00, 0.00e+00,\n",
       "          6.00e+00],\n",
       "         [3.40e+01, 1.00e+00, 1.00e+00, 1.18e+02, 1.82e+02, 0.00e+00,\n",
       "          2.00e+00, 1.74e+02, 0.00e+00, 0.00e+00, 1.00e+00, 0.00e+00,\n",
       "          3.00e+00],\n",
       "         [6.60e+01, 0.00e+00, 1.00e+00, 1.50e+02, 2.26e+02, 0.00e+00,\n",
       "          0.00e+00, 1.14e+02, 0.00e+00, 2.60e+00, 3.00e+00, 0.00e+00,\n",
       "          3.00e+00],\n",
       "         [4.70e+01, 1.00e+00, 3.00e+00, 1.30e+02, 2.53e+02, 0.00e+00,\n",
       "          0.00e+00, 1.79e+02, 0.00e+00, 0.00e+00, 1.00e+00, 0.00e+00,\n",
       "          3.00e+00],\n",
       "         [6.00e+01, 1.00e+00, 3.00e+00, 1.40e+02, 1.85e+02, 0.00e+00,\n",
       "          2.00e+00, 1.55e+02, 0.00e+00, 3.00e+00, 2.00e+00, 0.00e+00,\n",
       "          3.00e+00],\n",
       "         [5.40e+01, 0.00e+00, 2.00e+00, 1.32e+02, 2.88e+02, 1.00e+00,\n",
       "          2.00e+00, 1.59e+02, 1.00e+00, 0.00e+00, 1.00e+00, 1.00e+00,\n",
       "          3.00e+00],\n",
       "         [6.40e+01, 1.00e+00, 4.00e+00, 1.20e+02, 2.46e+02, 0.00e+00,\n",
       "          2.00e+00, 9.60e+01, 1.00e+00, 2.20e+00, 3.00e+00, 1.00e+00,\n",
       "          3.00e+00],\n",
       "         [4.00e+01, 1.00e+00, 1.00e+00, 1.40e+02, 1.99e+02, 0.00e+00,\n",
       "          0.00e+00, 1.78e+02, 1.00e+00, 1.40e+00, 1.00e+00, 0.00e+00,\n",
       "          7.00e+00],\n",
       "         [4.20e+01, 1.00e+00, 1.00e+00, 1.48e+02, 2.44e+02, 0.00e+00,\n",
       "          2.00e+00, 1.78e+02, 0.00e+00, 8.00e-01, 1.00e+00, 2.00e+00,\n",
       "          3.00e+00],\n",
       "         [6.90e+01, 1.00e+00, 1.00e+00, 1.60e+02, 2.34e+02, 1.00e+00,\n",
       "          2.00e+00, 1.31e+02, 0.00e+00, 1.00e-01, 2.00e+00, 1.00e+00,\n",
       "          3.00e+00],\n",
       "         [6.90e+01, 0.00e+00, 1.00e+00, 1.40e+02, 2.39e+02, 0.00e+00,\n",
       "          0.00e+00, 1.51e+02, 0.00e+00, 1.80e+00, 1.00e+00, 2.00e+00,\n",
       "          3.00e+00],\n",
       "         [4.80e+01, 1.00e+00, 4.00e+00, 1.24e+02, 2.74e+02, 0.00e+00,\n",
       "          2.00e+00, 1.66e+02, 0.00e+00, 5.00e-01, 2.00e+00, 0.00e+00,\n",
       "          7.00e+00],\n",
       "         [5.80e+01, 1.00e+00, 4.00e+00, 1.25e+02, 3.00e+02, 0.00e+00,\n",
       "          2.00e+00, 1.71e+02, 0.00e+00, 0.00e+00, 1.00e+00, 2.00e+00,\n",
       "          7.00e+00],\n",
       "         [5.80e+01, 1.00e+00, 4.00e+00, 1.14e+02, 3.18e+02, 0.00e+00,\n",
       "          1.00e+00, 1.40e+02, 0.00e+00, 4.40e+00, 3.00e+00, 3.00e+00,\n",
       "          6.00e+00],\n",
       "         [5.30e+01, 1.00e+00, 4.00e+00, 1.40e+02, 2.03e+02, 1.00e+00,\n",
       "          2.00e+00, 1.55e+02, 1.00e+00, 3.10e+00, 3.00e+00, 0.00e+00,\n",
       "          7.00e+00],\n",
       "         [5.80e+01, 0.00e+00, 4.00e+00, 1.30e+02, 1.97e+02, 0.00e+00,\n",
       "          0.00e+00, 1.31e+02, 0.00e+00, 6.00e-01, 2.00e+00, 0.00e+00,\n",
       "          3.00e+00],\n",
       "         [6.10e+01, 1.00e+00, 4.00e+00, 1.40e+02, 2.07e+02, 0.00e+00,\n",
       "          2.00e+00, 1.38e+02, 1.00e+00, 1.90e+00, 1.00e+00, 1.00e+00,\n",
       "          7.00e+00],\n",
       "         [4.40e+01, 1.00e+00, 3.00e+00, 1.40e+02, 2.35e+02, 0.00e+00,\n",
       "          2.00e+00, 1.80e+02, 0.00e+00, 0.00e+00, 1.00e+00, 0.00e+00,\n",
       "          3.00e+00],\n",
       "         [4.90e+01, 1.00e+00, 3.00e+00, 1.18e+02, 1.49e+02, 0.00e+00,\n",
       "          2.00e+00, 1.26e+02, 0.00e+00, 8.00e-01, 1.00e+00, 3.00e+00,\n",
       "          3.00e+00],\n",
       "         [4.70e+01, 1.00e+00, 3.00e+00, 1.08e+02, 2.43e+02, 0.00e+00,\n",
       "          0.00e+00, 1.52e+02, 0.00e+00, 0.00e+00, 1.00e+00, 0.00e+00,\n",
       "          3.00e+00],\n",
       "         [4.30e+01, 0.00e+00, 4.00e+00, 1.32e+02, 3.41e+02, 1.00e+00,\n",
       "          2.00e+00, 1.36e+02, 1.00e+00, 3.00e+00, 2.00e+00, 0.00e+00,\n",
       "          7.00e+00],\n",
       "         [5.60e+01, 0.00e+00, 2.00e+00, 1.40e+02, 2.94e+02, 0.00e+00,\n",
       "          2.00e+00, 1.53e+02, 0.00e+00, 1.30e+00, 2.00e+00, 0.00e+00,\n",
       "          3.00e+00],\n",
       "         [6.80e+01, 0.00e+00, 3.00e+00, 1.20e+02, 2.11e+02, 0.00e+00,\n",
       "          2.00e+00, 1.15e+02, 0.00e+00, 1.50e+00, 2.00e+00, 0.00e+00,\n",
       "          3.00e+00],\n",
       "         [5.20e+01, 0.00e+00, 3.00e+00, 1.36e+02, 1.96e+02, 0.00e+00,\n",
       "          2.00e+00, 1.69e+02, 0.00e+00, 1.00e-01, 2.00e+00, 0.00e+00,\n",
       "          3.00e+00],\n",
       "         [6.20e+01, 0.00e+00, 4.00e+00, 1.40e+02, 3.94e+02, 0.00e+00,\n",
       "          2.00e+00, 1.57e+02, 0.00e+00, 1.20e+00, 2.00e+00, 0.00e+00,\n",
       "          3.00e+00],\n",
       "         [6.30e+01, 1.00e+00, 4.00e+00, 1.30e+02, 2.54e+02, 0.00e+00,\n",
       "          2.00e+00, 1.47e+02, 0.00e+00, 1.40e+00, 2.00e+00, 1.00e+00,\n",
       "          7.00e+00],\n",
       "         [6.40e+01, 1.00e+00, 3.00e+00, 1.40e+02, 3.35e+02, 0.00e+00,\n",
       "          0.00e+00, 1.58e+02, 0.00e+00, 0.00e+00, 1.00e+00, 0.00e+00,\n",
       "          3.00e+00]]), array([[0],\n",
       "         [1],\n",
       "         [1],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [1],\n",
       "         [0],\n",
       "         [1],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [0],\n",
       "         [1],\n",
       "         [0],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [1],\n",
       "         [1]])),\n",
       " 'build_fn': <function __main__.create_model()>}"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# our best estimator is thus\n",
    "model.get_params()"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nteract": {
   "version": "0.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
