{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2*\n",
    "\n",
    "# Sprint Challenge - Neural Network Foundations\n",
    "\n",
    "Table of Problems\n",
    "\n",
    "1. [Defining Neural Networks](#Q1)\n",
    "2. [Chocolate Gummy Bears](#Q2)\n",
    "    - Perceptron\n",
    "    - Multilayer Perceptron\n",
    "4. [Keras MMP](#Q3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Q1\"></a>\n",
    "## 1. Define the following terms:\n",
    "\n",
    "- **Neuron:**\n",
    "- **Input Layer:**\n",
    "- **Hidden Layer:**\n",
    "- **Output Layer:**\n",
    "- **Activation:**\n",
    "- **Backpropagation:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Chocolate Gummy Bears <a id=\"Q2\"></a>\n",
    "\n",
    "Right now, you're probably thinking, \"yuck, who the hell would eat that?\". Great question. Your candy company wants to know too. And you thought I was kidding about the [Chocolate Gummy Bears](https://nuts.com/chocolatessweets/gummies/gummy-bears/milk-gummy-bears.html?utm_source=google&utm_medium=cpc&adpos=1o1&gclid=Cj0KCQjwrfvsBRD7ARIsAKuDvMOZrysDku3jGuWaDqf9TrV3x5JLXt1eqnVhN0KM6fMcbA1nod3h8AwaAvWwEALw_wcB). \n",
    "\n",
    "Let's assume that a candy company has gone out and collected information on the types of Halloween candy kids ate. Our candy company wants to predict the eating behavior of witches, warlocks, and ghosts -- aka costumed kids. They shared a sample dataset with us. Each row represents a piece of candy that a costumed child was presented with during \"trick\" or \"treat\". We know if the candy was `chocolate` (or not chocolate) or `gummy` (or not gummy). Your goal is to predict if the costumed kid `ate` the piece of candy. \n",
    "\n",
    "If both chocolate and gummy equal one, you've got a chocolate gummy bear on your hands!?!?!\n",
    "![Chocolate Gummy Bear](https://ed910ae2d60f0d25bcb8-80550f96b5feb12604f4f720bfefb46d.ssl.cf1.rackcdn.com/3fb630c04435b7b5-2leZuM7_-zoom.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "candy = pd.read_csv('chocolate_gummy_bears.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chocolate</th>\n",
       "      <th>gummy</th>\n",
       "      <th>ate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   chocolate  gummy  ate\n",
       "0          0      1    1\n",
       "1          1      0    1\n",
       "2          0      1    1\n",
       "3          0      0    0\n",
       "4          1      1    0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron\n",
    "\n",
    "To make predictions on the `candy` dataframe. Build and train a Perceptron using numpy. Your target column is `ate` and your features: `chocolate` and `gummy`. Do not do any feature engineering. :P\n",
    "\n",
    "Once you've trained your model, report your accuracy. You will not be able to achieve more than ~50% with the simple perceptron. Explain why you could not achieve a higher accuracy with the *simple perceptron* architecture, because it's possible to achieve ~95% accuracy on this dataset. Provide your answer in markdown (and *optional* data anlysis code) after your perceptron implementation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "# Start your candy perceptron here\n",
    "\n",
    "X = candy[['chocolate', 'gummy']].values\n",
    "y = candy['ate'].values\n",
    "X_train = X[0:7500]\n",
    "y_train = y[0:7500]\n",
    "X_test = X[7500:10000]\n",
    "y_test = y[7500:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron(object):\n",
    "  def __init__(self, rate = 0.01, niter = 10):\n",
    "    self.rate = rate\n",
    "    self.niter = niter\n",
    "\n",
    "  def fit(self, X, y):\n",
    "    \"\"\"Fit training data\n",
    "    X : Training vectors, X.shape : [#samples, #features]\n",
    "    y : Target values, y.shape : [#samples]\n",
    "    \"\"\"\n",
    "\n",
    "    # weights\n",
    "    self.weight = np.zeros(1 + X.shape[1])\n",
    "\n",
    "    # Number of misclassifications\n",
    "    self.errors = []  # Number of misclassifications\n",
    "\n",
    "    for i in range(self.niter):\n",
    "      err = 0\n",
    "      for xi, target in zip(X, y):\n",
    "        delta_w = self.rate * (target - self.predict(xi))\n",
    "        self.weight[1:] += delta_w * xi\n",
    "        self.weight[0] += delta_w\n",
    "        err += int(delta_w != 0.0)\n",
    "      self.errors.append(err)\n",
    "    return self\n",
    "\n",
    "  def net_input(self, X):\n",
    "    \"\"\"Calculate net input\"\"\"\n",
    "    return np.dot(X, self.weight[1:]) + self.weight[0]\n",
    "\n",
    "  def predict(self, X):\n",
    "    \"\"\"Return class label after unit step\"\"\"\n",
    "    return np.where(self.net_input(X) >= 0.0, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Perceptron at 0x11f887f90>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pn = Perceptron(0.05, 5)\n",
    "pn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5048"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "pred = pn.predict(X_test)\n",
    "accuracy_score(pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1, len(pn.errors) + 1), pn.errors, marker='o')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Number of misclassifications')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer Perceptron <a id=\"Q3\"></a>\n",
    "\n",
    "Using the sample candy dataset, implement a Neural Network Multilayer Perceptron class that uses backpropagation to update the network's weights. Your Multilayer Perceptron should be implemented in Numpy. \n",
    "Your network must have one hidden layer.\n",
    "\n",
    "Once you've trained your model, report your accuracy. Explain why your MLP's performance is considerably better than your simple perceptron's on the candy dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self):\n",
    "        # Set up Architecture of Neural Network\n",
    "        self.inputs = 2\n",
    "        self.hiddenNodes = 10\n",
    "        self.outputNodes = 7500\n",
    "\n",
    "        # Initial Weights\n",
    "       \n",
    "        self.weights1 = np.random.rand(self.inputs, self.hiddenNodes)\n",
    "       \n",
    "        # Hidden to Output\n",
    "        \n",
    "        self.weights2 = np.random.rand(self.hiddenNodes, self.outputNodes)\n",
    "    \n",
    "    def sigmoid(self, s):\n",
    "        return 1 / (1+np.exp(-s))\n",
    "    \n",
    "    def sigmoidPrime(self, s):\n",
    "       \n",
    "        return s * (1 - s)\n",
    "    \n",
    "    def feed_forward(self, X):\n",
    "        \"\"\"\n",
    "        Calculate the NN inference using feed forward.\n",
    "        aka \"predict\"\n",
    "        \"\"\"\n",
    "        \n",
    "        # Weighted sum of inputs => hidden layer\n",
    "        self.hidden_sum = np.dot(X, self.weights1)\n",
    "        \n",
    "        # Activations of weighted sum\n",
    "        self.activated_hidden = self.sigmoid(self.hidden_sum)\n",
    "        \n",
    "        # Weight sum between hidden and output\n",
    "        self.output_sum = np.dot(self.activated_hidden, self.weights2)\n",
    "        \n",
    "        # Final activation of output\n",
    "        self.activated_output = self.sigmoid(self.output_sum)\n",
    "        \n",
    "        \n",
    "        return self.activated_output\n",
    "    \n",
    "    def backward(self, X,y,o):\n",
    "        \"\"\"\n",
    "        Backward propagate through the network\n",
    "        \"\"\"\n",
    "        \n",
    "        # Error in Output\n",
    "        \n",
    "        self.o_error = y - o\n",
    "        \n",
    "        # Apply Derivative of Sigmoid to error\n",
    "        self.o_delta = self.o_error * self.sigmoidPrime(o)\n",
    "        \n",
    "        # z2 error\n",
    "        self.z2_error = self.o_delta.dot(self.weights2.T)\n",
    "        # How much of that \"far off\" can explained by the input => hidden\n",
    "        self.z2_delta = self.z2_error * self.sigmoidPrime(self.activated_hidden)\n",
    "        \n",
    "        # Adjustment to first set of weights (input => hidden)\n",
    "        self.weights1 += X.T.dot(self.z2_delta)\n",
    "        # Adjustment to second set of weights (hidden => output)\n",
    "        self.weights2 += self.activated_hidden.T.dot(self.o_delta)\n",
    "        \n",
    "# Output\n",
    "    def train(self, X, y):\n",
    "        o = self.feed_forward(X)\n",
    "        self.backward(X,y,o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NeuralNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "L1|Wgt: \n",
      "[[0.63488144 0.96048945 0.89066323 0.62509437 0.63154018 0.91893622\n",
      "  0.86966194 0.18911396 0.65174836 0.18879818]\n",
      " [0.42134171 0.35505333 0.74413269 0.71336015 0.55820764 0.6112615\n",
      "  0.82637853 0.89272078 0.67221697 0.2620719 ]]\n",
      "L2|Wgt: \n",
      "[[0.93357745 0.18248358 0.49407112 ... 0.80410661 0.77379211 0.14159058]\n",
      " [0.16874105 0.92034235 0.97332326 ... 0.99998149 0.47292182 0.77976645]\n",
      " [0.96851517 0.31504691 0.2884559  ... 0.84941404 0.52464953 0.94305007]\n",
      " ...\n",
      " [0.77091032 0.03063851 0.60772247 ... 0.73940857 0.65717272 0.81166601]\n",
      " [0.82216281 0.07262991 0.38101653 ... 0.20267276 0.01460617 0.2292294 ]\n",
      " [0.54007813 0.59591015 0.90584373 ... 0.69152625 0.04165884 0.81063841]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'''\n",
    "L1|Wgt: \\n{nn.weights1}\n",
    "L2|Wgt: \\n{nn.weights2}\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7500, 2), (7500,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "IN: \n",
      "[[0 1 1]\n",
      " [1 0 1]\n",
      " [0 1 1]\n",
      " ...\n",
      " [0 1 1]\n",
      " [0 1 1]\n",
      " [1 0 1]]\n",
      "OT: \n",
      "[[0.98460684 0.93870218 0.97838246 ... 0.98585614 0.94918971 0.97961992]\n",
      " [0.98461137 0.94784903 0.97982949 ... 0.98704034 0.95081801 0.98085934]\n",
      " [0.98460684 0.93870218 0.97838246 ... 0.98585614 0.94918971 0.97961992]\n",
      " ...\n",
      " [0.99296025 0.96602543 0.9895761  ... 0.99391229 0.97115404 0.99044004]\n",
      " [0.98461137 0.94784903 0.97982949 ... 0.98704034 0.95081801 0.98085934]\n",
      " [0.98461137 0.94784903 0.97982949 ... 0.98704034 0.95081801 0.98085934]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output = nn.feed_forward(X_train)\n",
    "print(f'''\n",
    "IN: \\n{candy.values}\n",
    "OT: \\n{output}\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------EPOCH 1---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [1 1 1 ... 0 1 1]\n",
      "Predicted Output: \n",
      " [[0.98460684 0.93870218 0.97838246 ... 0.98585614 0.94918971 0.97961992]\n",
      " [0.98461137 0.94784903 0.97982949 ... 0.98704034 0.95081801 0.98085934]\n",
      " [0.98460684 0.93870218 0.97838246 ... 0.98585614 0.94918971 0.97961992]\n",
      " ...\n",
      " [0.99296025 0.96602543 0.9895761  ... 0.99391229 0.97115404 0.99044004]\n",
      " [0.98461137 0.94784903 0.97982949 ... 0.98704034 0.95081801 0.98085934]\n",
      " [0.98461137 0.94784903 0.97982949 ... 0.98704034 0.95081801 0.98085934]]\n",
      "Loss: \n",
      " 0.45583716225320114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximevacher-materno/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------EPOCH 2---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [1 1 1 ... 0 1 1]\n",
      "Predicted Output: \n",
      " [[0.5 0.5 0.5 ... 0.5 0.5 0.5]\n",
      " [0.5 0.5 0.5 ... 0.5 0.5 0.5]\n",
      " [0.5 0.5 0.5 ... 0.5 0.5 0.5]\n",
      " ...\n",
      " [0.5 0.5 0.5 ... 0.5 0.5 0.5]\n",
      " [0.5 0.5 0.5 ... 0.5 0.5 0.5]\n",
      " [0.5 0.5 0.5 ... 0.5 0.5 0.5]]\n",
      "Loss: \n",
      " 0.1866666672212677\n",
      "+---------EPOCH 3---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [1 1 1 ... 0 1 1]\n",
      "Predicted Output: \n",
      " [[0.5 0.5 0.5 ... 0.5 0.5 0.5]\n",
      " [0.5 0.5 0.5 ... 0.5 0.5 0.5]\n",
      " [0.5 0.5 0.5 ... 0.5 0.5 0.5]\n",
      " ...\n",
      " [0.5 0.5 0.5 ... 0.5 0.5 0.5]\n",
      " [0.5 0.5 0.5 ... 0.5 0.5 0.5]\n",
      " [0.5 0.5 0.5 ... 0.5 0.5 0.5]]\n",
      "Loss: \n",
      " 0.1866666672157802\n",
      "+---------EPOCH 4---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [1 1 1 ... 0 1 1]\n",
      "Predicted Output: \n",
      " [[0.5 0.5 0.5 ... 0.5 0.5 0.5]\n",
      " [0.5 0.5 0.5 ... 0.5 0.5 0.5]\n",
      " [0.5 0.5 0.5 ... 0.5 0.5 0.5]\n",
      " ...\n",
      " [0.5 0.5 0.5 ... 0.5 0.5 0.5]\n",
      " [0.5 0.5 0.5 ... 0.5 0.5 0.5]\n",
      " [0.5 0.5 0.5 ... 0.5 0.5 0.5]]\n",
      "Loss: \n",
      " 0.1866666672104702\n",
      "+---------EPOCH 5---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [1 1 1 ... 0 1 1]\n",
      "Predicted Output: \n",
      " [[0.5 0.5 0.5 ... 0.5 0.5 0.5]\n",
      " [0.5 0.5 0.5 ... 0.5 0.5 0.5]\n",
      " [0.5 0.5 0.5 ... 0.5 0.5 0.5]\n",
      " ...\n",
      " [0.5 0.5 0.5 ... 0.5 0.5 0.5]\n",
      " [0.5 0.5 0.5 ... 0.5 0.5 0.5]\n",
      " [0.5 0.5 0.5 ... 0.5 0.5 0.5]]\n",
      "Loss: \n",
      " 0.18666666720533104\n"
     ]
    }
   ],
   "source": [
    "for i in range(10000):\n",
    "    if (i+1 in [1,2,3,4,5]) or ((i+1) % 1000 ==0):\n",
    "        nice = nn.feed_forward(X_train)\n",
    "        print('+' + '---' * 3 + f'EPOCH {i+1}' + '---'*3 + '+')\n",
    "        print('Input: \\n', X_train)\n",
    "        print('Actual Output: \\n', y_train)\n",
    "        print('Predicted Output: \\n', str(nice))\n",
    "        print(\"Loss: \\n\", str(np.mean(np.square(y_train - nn.feed_forward(X_train)))))\n",
    "    nn.train(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P.S. Don't try candy gummy bears. They're disgusting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Keras MMP <a id=\"Q3\"></a>\n",
    "\n",
    "Implement a Multilayer Perceptron architecture of your choosing using the Keras library. Train your model and report its baseline accuracy. Then hyperparameter tune at least two parameters and report your model's accuracy.\n",
    "Use the Heart Disease Dataset (binary classification)\n",
    "Use an appropriate loss function for a binary classification task\n",
    "Use an appropriate activation function on the final layer of your network.\n",
    "Train your model using verbose output for ease of grading.\n",
    "Use GridSearchCV or RandomSearchCV to hyperparameter tune your model. (for at least two hyperparameters)\n",
    "When hyperparameter tuning, show you work by adding code cells for each new experiment.\n",
    "Report the accuracy for each combination of hyperparameters as you test them so that we can easily see which resulted in the highest accuracy.\n",
    "You must hyperparameter tune at least 3 parameters in order to get a 3 on this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(303, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>298</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>122</td>\n",
       "      <td>1</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>239</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>290</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>153</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>240</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "250   51    1   0       140   298    0        1      122      1      4.2   \n",
       "206   59    1   0       110   239    0        0      142      1      1.2   \n",
       "53    44    0   2       108   141    0        1      175      0      0.6   \n",
       "185   44    1   0       112   290    0        0      153      0      0.0   \n",
       "160   56    1   1       120   240    0        1      169      0      0.0   \n",
       "\n",
       "     slope  ca  thal  target  \n",
       "250      1   3     3       0  \n",
       "206      1   1     3       0  \n",
       "53       1   0     2       1  \n",
       "185      2   1     2       0  \n",
       "160      0   0     2       1  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/ryanleeallred/datasets/master/heart.csv')\n",
    "df = df.sample(frac=1)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(303, 13)\n",
      "(303,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximevacher-materno/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/maximevacher-materno/anaconda3/lib/python3.7/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "sc = StandardScaler()\n",
    "df = sc.fit_transform(df)\n",
    "# split \n",
    "X = df[:,:-1]\n",
    "y = df[:,-1]\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximevacher-materno/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Hyperparams\n",
    "inputs = X.shape[1]\n",
    "epochs = 25\n",
    "b_size = 250\n",
    "\n",
    "# Create model\n",
    "def create_model():\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(96, input_shape=(inputs,), activation='relu'))\n",
    "    model.add(Dropout(0.05))\n",
    "    model.add(Dense(48, activation='relu'))\n",
    "    model.add(Dropout(0.05))\n",
    "    model.add(Dense(48, activation='relu'))\n",
    "    model.add(Dropout(0.05))\n",
    "    model.add(Dense(48, activation='relu'))\n",
    "    model.add(Dropout(0.05))\n",
    "    model.add(Dense(48, activation='relu'))\n",
    "    model.add(Dropout(0.15))\n",
    "    model.add(Dense(96, activation='relu'))\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "\n",
    "param_grid = {'batch_size': [10, 30, 50, 100],\n",
    "              'epochs':[5,10, 20]}\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1, verbose=0)\n",
    "grid_result = grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.8217821717262268 using {'batch_size': 10, 'epochs': 20}\n",
      "Means: 0.6798679927984873, Stdev: 0.16375756603332123 with: {'batch_size': 10, 'epochs': 5}\n",
      "Means: 0.6963696380456289, Stdev: 0.17040699654348213 with: {'batch_size': 10, 'epochs': 10}\n",
      "Means: 0.8217821717262268, Stdev: 0.05301113405032084 with: {'batch_size': 10, 'epochs': 20}\n",
      "Means: 0.7557755907376608, Stdev: 0.04667370101995413 with: {'batch_size': 30, 'epochs': 5}\n",
      "Means: 0.8184818426767985, Stdev: 0.025986816922028384 with: {'batch_size': 30, 'epochs': 10}\n",
      "Means: 0.8217821717262268, Stdev: 0.03523787151819811 with: {'batch_size': 30, 'epochs': 20}\n",
      "Means: 0.5643564462661743, Stdev: 0.14025431949143605 with: {'batch_size': 50, 'epochs': 5}\n",
      "Means: 0.7953795393308004, Stdev: 0.05678100794290375 with: {'batch_size': 50, 'epochs': 10}\n",
      "Means: 0.8052805264790853, Stdev: 0.0336568844486241 with: {'batch_size': 50, 'epochs': 20}\n",
      "Means: 0.5511551300684611, Stdev: 0.04068918921340226 with: {'batch_size': 100, 'epochs': 5}\n",
      "Means: 0.6567656894524893, Stdev: 0.14378231512079218 with: {'batch_size': 100, 'epochs': 10}\n",
      "Means: 0.7722772161165873, Stdev: 0.10097068062121517 with: {'batch_size': 100, 'epochs': 20}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\")"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "nteract": {
   "version": "0.15.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
