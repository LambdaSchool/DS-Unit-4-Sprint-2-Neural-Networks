{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ira_431_Intro_to_NN_Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pragmatizt/DS-Unit-4-Sprint-2-Neural-Networks/blob/master/ira_431_Intro_to_NN_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dVfaLrjLvxvQ"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "# Neural Networks\n",
        "\n",
        "## *Data Science Unit 4 Sprint 2 Assignment 1*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wxtoY12mwmih"
      },
      "source": [
        "## Define the Following:\n",
        "You can add image, diagrams, whatever you need to ensure that you understand the concepts below.\n",
        "\n",
        "### Input Layer:\n",
        "### Hidden Layer:\n",
        "### Output Layer:\n",
        "### Neuron:\n",
        "### Weight:\n",
        "### Activation Function:\n",
        "### Node Map:\n",
        "### Perceptron:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NXuy9WcWzxa4"
      },
      "source": [
        "## Inputs -> Outputs\n",
        "\n",
        "### Explain the flow of information through a neural network from inputs to outputs. Be sure to include: inputs, weights, bias, and activation functions. How does it all flow from beginning to end?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PlSwIJMC0A8F"
      },
      "source": [
        "#### Your Answer Here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6sWR43PTwhSk"
      },
      "source": [
        "## Write your own perceptron code that can correctly classify (99.0% accuracy) a NAND gate. \n",
        "\n",
        "| x1 | x2 | y |\n",
        "|----|----|---|\n",
        "| 0  | 0  | 1 |\n",
        "| 1  | 0  | 1 |\n",
        "| 0  | 1  | 1 |\n",
        "| 1  | 1  | 0 |"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bj1l43eWhET7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "data = { 'x1': [0,1,0,1],\n",
        "         'x2': [0,0,1,1],\n",
        "         'y':  [1,1,1,0]\n",
        "       }\n",
        "\n",
        "df = pd.DataFrame.from_dict(data).astype('int')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Sgh7VFGwnXGH",
        "outputId": "76266463-8fb1-4b6a-eed3-9fd555f054fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        }
      },
      "source": [
        "##### Your Code Here #####\n",
        "\n",
        "df"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x1</th>\n",
              "      <th>x2</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   x1  x2  y\n",
              "0   0   0  1\n",
              "1   1   0  1\n",
              "2   0   1  1\n",
              "3   1   1  0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvIzOib3hEUE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASfA1BwnhXZN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs = np.array((df['x1'], df['x2']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyoRcz0XhXWZ",
        "colab_type": "code",
        "outputId": "bb9d8608-d912-4d49-99a0-2233dbb1f868",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "inputs"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 1, 0, 1],\n",
              "       [0, 0, 1, 1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lat4fYu6hjWR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = [df['y']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u84mhcLWhnSc",
        "colab_type": "code",
        "outputId": "fa50fd9f-1000-4cac-df9b-d57c5f85c490",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0    1\n",
              " 1    1\n",
              " 2    1\n",
              " 3    0\n",
              " Name: y, dtype: int64]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0rm9d1qhpA9",
        "colab_type": "code",
        "outputId": "0cba026e-6b44-44aa-8550-7e4e985e1610",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "inputs.shape[1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHddXGtlhrc4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weights = 2 * np.random.random((inputs.shape[1],1))-1\n",
        "# weights 4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0zedeD_hyql",
        "colab_type": "code",
        "outputId": "46129551-587c-4cf9-a283-8e8bee934b19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "weights"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.36321031],\n",
              "       [-0.66841877],\n",
              "       [-0.86386445],\n",
              "       [ 0.59460497]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpTqqdCfh1Em",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoid(x):\n",
        "  return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "  sx = sigmoid(x)\n",
        "  return sx * (1-sx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3suFO8R9iHSW",
        "colab_type": "code",
        "outputId": "24321b61-9fdd-41a3-8f25-6ded8759d95b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "weighted_sum = np.dot(inputs, weights) # because they are a matrix\n",
        "weighted_sum"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.0738138 ],\n",
              "       [-0.26925948]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ck79HgtiAtj",
        "colab_type": "code",
        "outputId": "07b45a5f-1a8c-4966-9a35-731b5a1ed75a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "activated_output = sigmoid(weighted_sum)\n",
        "activated_output"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.48155492],\n",
              "       [0.4330889 ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UU24D106iQZA",
        "colab_type": "code",
        "outputId": "c9a14d57-e6df-46ab-a453-e49a5a51d5c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "error = y - activated_output\n",
        "error"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.51844508,  0.51844508,  0.51844508, -0.48155492],\n",
              "       [ 0.5669111 ,  0.5669111 ,  0.5669111 , -0.4330889 ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bvu_PjWiQcD",
        "colab_type": "code",
        "outputId": "590c432a-a3db-40e1-e554-5559b8724b2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "adjusted = error * sigmoid_derivative(activated_output)\n",
        "adjusted # increase by positive values, decrease by negative values"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.12237836,  0.12237836,  0.12237836, -0.11367049],\n",
              "       [ 0.13528431,  0.13528431,  0.13528431, -0.10334978]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuoaHDBCiQfa",
        "colab_type": "code",
        "outputId": "2c9b5456-878c-4240-8bef-9142f4abba6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "weights = np.dot(inputs.T, adjusted)\n",
        "weights\n",
        "# after"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.        ,  0.        ,  0.        ,  0.        ],\n",
              "       [ 0.12237836,  0.12237836,  0.12237836, -0.11367049],\n",
              "       [ 0.13528431,  0.13528431,  0.13528431, -0.10334978],\n",
              "       [ 0.25766268,  0.25766268,  0.25766268, -0.21702026]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBxgmWJSitaV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Update our weights 10,000 times - (fingers crossed that this process reduces error)\n",
        "def perceptron_ira(inputs, weights, correct_outputs):\n",
        "  for iteration in range(10000):\n",
        "    # Weighted sum of inputs / weights\n",
        "    bias = 2*np.random.random()-1\n",
        "    weighted_sum = np.dot(inputs, weights) + bias\n",
        "\n",
        "    # Activate!\n",
        "    activated_output = sigmoid(weighted_sum)\n",
        "\n",
        "    # Cac error\n",
        "    error = correct_outputs - activated_output\n",
        "\n",
        "    adjusted = error * sigmoid_derivative(activated_output)\n",
        "\n",
        "    # update the weights\n",
        "    weights += np.dot(inputs.T, adjusted)\n",
        "    bias += np.mean(error)\n",
        "\n",
        "  print(\"Weights after training\")\n",
        "  print(weights)\n",
        "\n",
        "  print(\"Output after training\")\n",
        "  print(activated_output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0a654Z8itc8",
        "colab_type": "code",
        "outputId": "69bc1b15-0bc7-45b8-ff91-1b7a80877087",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        }
      },
      "source": [
        "perceptron_ira(inputs, weights, y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Weights after training\n",
            "[[ 0.          0.          0.          0.        ]\n",
            " [ 3.17604532  3.17604532  3.17604532 -3.26055021]\n",
            " [ 3.17677193  3.17677193  3.17677193 -3.25999085]\n",
            " [ 6.35281725  6.35281725  6.35281725 -6.52054105]]\n",
            "Output after training\n",
            "[[9.99948771e-01 9.99948771e-01 9.99948771e-01 8.02153111e-05]\n",
            " [9.99948808e-01 9.99948808e-01 9.99948808e-01 8.02601899e-05]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Xf7sdqVs0s4x"
      },
      "source": [
        "## Implement your own Perceptron Class and use it to classify a binary dataset: \n",
        "- [The Pima Indians Diabetes dataset](https://raw.githubusercontent.com/ryanleeallred/datasets/master/diabetes.csv) \n",
        "\n",
        "You may need to search for other's implementations in order to get inspiration for your own. There are *lots* of perceptron implementations on the internet with varying levels of sophistication and complexity. Whatever your approach, make sure you understand **every** line of your implementation and what its purpose is."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zt8Bju5VhEUM",
        "colab_type": "code",
        "outputId": "62f5be61-7d9c-44c9-f772-323c4e48e665",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        }
      },
      "source": [
        "diabetes = pd.read_csv('https://raw.githubusercontent.com/ryanleeallred/datasets/master/diabetes.csv')\n",
        "diabetes.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Pregnancies  Glucose  BloodPressure  ...  DiabetesPedigreeFunction  Age  Outcome\n",
              "0            6      148             72  ...                     0.627   50        1\n",
              "1            1       85             66  ...                     0.351   31        0\n",
              "2            8      183             64  ...                     0.672   32        1\n",
              "3            1       89             66  ...                     0.167   21        0\n",
              "4            0      137             40  ...                     2.288   33        1\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1kiQXbNhEUT",
        "colab_type": "text"
      },
      "source": [
        "Although neural networks can handle non-normalized data, scaling or normalizing your data will improve your neural network's learning speed. Try to apply the sklearn `MinMaxScaler` or `Normalizer` to your diabetes dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0imYV3HnjuOE",
        "colab_type": "code",
        "outputId": "bdff22b0-114b-4dba-ea7d-a09e48e07315",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "source": [
        "diabetes.dtypes"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pregnancies                   int64\n",
              "Glucose                       int64\n",
              "BloodPressure                 int64\n",
              "SkinThickness                 int64\n",
              "Insulin                       int64\n",
              "BMI                         float64\n",
              "DiabetesPedigreeFunction    float64\n",
              "Age                           int64\n",
              "Outcome                       int64\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iX9rSZIhEUT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler, Normalizer\n",
        "\n",
        "features = list(diabetes)[:-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6KMluMWj1JR",
        "colab_type": "code",
        "outputId": "d84e071a-7da3-4df1-aa26-f317450c95f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        }
      },
      "source": [
        "features"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Pregnancies',\n",
              " 'Glucose',\n",
              " 'BloodPressure',\n",
              " 'SkinThickness',\n",
              " 'Insulin',\n",
              " 'BMI',\n",
              " 'DiabetesPedigreeFunction',\n",
              " 'Age']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6Xfxatkj6dv",
        "colab_type": "code",
        "outputId": "9ab60555-444a-410b-8466-e9e89bdbe2bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        }
      },
      "source": [
        "y = diabetes['Outcome'].to_numpy() # Target value to numpy array\n",
        "y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0,\n",
              "       1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1,\n",
              "       0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "       1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
              "       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "       1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1,\n",
              "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "       1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1,\n",
              "       0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1,\n",
              "       1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1,\n",
              "       1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n",
              "       1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0,\n",
              "       1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0,\n",
              "       0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
              "       1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "       0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "       0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
              "       0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0,\n",
              "       0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1,\n",
              "       0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
              "       1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
              "       1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
              "       1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "       0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
              "       0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n",
              "       0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
              "       1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
              "       0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1,\n",
              "       0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0,\n",
              "       0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
              "       0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0,\n",
              "       1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aa2hDrNxkCdH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# MinMaxScaler: Transforms features by scaling each feature to a given range\n",
        "# fit_transform(self, X[, y]) fit to data, then transform it.\n",
        "# Normalizer: Normalize samples individually to unit norm\n",
        "scaler = MinMaxScaler()\n",
        "X = scaler.fit_transform(diabetes[feats])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ernK3gGBkQP3",
        "colab_type": "code",
        "outputId": "b7e63558-78aa-44e9-e83f-f707ba595ee7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "source": [
        "X"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.35294118, 0.74371859, 0.59016393, ..., 0.50074516, 0.23441503,\n",
              "        0.48333333],\n",
              "       [0.05882353, 0.42713568, 0.54098361, ..., 0.39642325, 0.11656704,\n",
              "        0.16666667],\n",
              "       [0.47058824, 0.91959799, 0.52459016, ..., 0.34724292, 0.25362938,\n",
              "        0.18333333],\n",
              "       ...,\n",
              "       [0.29411765, 0.6080402 , 0.59016393, ..., 0.390462  , 0.07130658,\n",
              "        0.15      ],\n",
              "       [0.05882353, 0.63316583, 0.49180328, ..., 0.4485842 , 0.11571307,\n",
              "        0.43333333],\n",
              "       [0.05882353, 0.46733668, 0.57377049, ..., 0.45305514, 0.10119556,\n",
              "        0.03333333]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-W0tiX1F1hh2",
        "colab": {}
      },
      "source": [
        "\n",
        "##### Update this Class #####\n",
        "\n",
        "class Perceptron(object):\n",
        "    def __init__(self, rate=0.1, niter=10000):\n",
        "        self.rate = rate\n",
        "        self.niter = niter\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"Fit training data\n",
        "        X : Training vectors, X.shape : [#samples, #features]\n",
        "        y : Target values, y.shape : [#samples]\n",
        "        \"\"\"\n",
        "\n",
        "        # Initialize Weights\n",
        "        self.weight = np.zeros(1 + X.shape[1])\n",
        "\n",
        "        # Number of misclassifications\n",
        "        self.errors = []  # Number of misclassifications\n",
        "\n",
        "        for i in range(self.niter):\n",
        "            err = 0\n",
        "            for xi, target in zip(X, y):\n",
        "                delta_w = self.rate * (target - self.predict(xi))\n",
        "                self.weight[1:] += delta_w * xi\n",
        "                self.weight[0] += delta_w\n",
        "                err += int(delta_w != 0.0)\n",
        "            self.errors.append(err)\n",
        "        return self\n",
        "    \n",
        "    def net_input(self, X):\n",
        "        return np.dot(X, self.weight[1:]) + self.weight[0]\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"Return class label after unit step\"\"\"\n",
        "        return np.where(self.net_input(X) >= 0.0, 1, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-2hGtnGlLgr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sh0tLHiLlLss",
        "colab_type": "code",
        "outputId": "b754e870-946b-47fc-94df-f0fc165f3c0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# train/test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((614, 8), (614,), (154, 8), (154,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXji60tsl91U",
        "colab_type": "code",
        "outputId": "bf39d7cc-5885-44cb-89df-38510c9db7cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "pn = Perceptron() \n",
        "pn.fit(X_train, y_train)\n",
        "plt.plot(range(1, len(pn.errors) + 1), pn.errors, marker='o')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Number of misclassifications')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEGCAYAAACKB4k+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ndQqGYRhGDusUDMMwjBz/Hx6W9QLpglINAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjG88Rw2l99S",
        "colab_type": "code",
        "outputId": "3af39f99-bb96-483d-ea8a-9b6fcbbf9141",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "predictions = [pn.predict(X_test[i]) for i in range(len(X_test))]\n",
        "print(\"accuracy:\", accuracy_score(y_test, predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 0.7662337662337663\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6QR4oAW1xdyu"
      },
      "source": [
        "## Stretch Goals:\n",
        "\n",
        "- Research \"backpropagation\" to learn how weights get updated in neural networks (tomorrow's lecture). \n",
        "- Implement a multi-layer perceptron. (for non-linearly separable classes)\n",
        "- Try and implement your own backpropagation algorithm.\n",
        "- What are the pros and cons of the different activation functions? How should you decide between them for the different layers of a neural network?"
      ]
    }
  ]
}