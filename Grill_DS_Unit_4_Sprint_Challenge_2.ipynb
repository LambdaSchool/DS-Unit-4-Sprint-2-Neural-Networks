{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2*\n",
    "\n",
    "# Sprint Challenge - Neural Network Foundations\n",
    "\n",
    "Table of Problems\n",
    "\n",
    "1. [Defining Neural Networks](#Q1)\n",
    "2. [Chocolate Gummy Bears](#Q2)\n",
    "    - Perceptron\n",
    "    - Multilayer Perceptron\n",
    "4. [Keras MMP](#Q3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Q1\"></a>\n",
    "## 1. Define the following terms:\n",
    "\n",
    "- **Neuron:** Neurons receive inputs, passing their signal (if activated) to the next layer if a certain threshold is reached and \n",
    "- **Input Layer:** The input layer is made of your data. This is how your data begins to go through the network.\n",
    "- **Hidden Layer:** The hidden layer can be made up of multiple layers and is where most of the variation in architecture of an NN occurs. \n",
    "- **Output Layer:** The output is the prediction or classification that is given by your neural network.\n",
    "- **Activation:** A neuron is activated according to one of many activation functions, such as tanh, relu, sigmoid, or linear. This would cause the neuron to send a signal on to the next neuron.\n",
    "- **Backpropagation:** The neural network operates according to a loss function and it wants to minimize the loss, therefore it will keep iterating through the layers, according to a gradient. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Chocolate Gummy Bears <a id=\"Q2\"></a>\n",
    "\n",
    "Right now, you're probably thinking, \"yuck, who the hell would eat that?\". Great question. Your candy company wants to know too. And you thought I was kidding about the [Chocolate Gummy Bears](https://nuts.com/chocolatessweets/gummies/gummy-bears/milk-gummy-bears.html?utm_source=google&utm_medium=cpc&adpos=1o1&gclid=Cj0KCQjwrfvsBRD7ARIsAKuDvMOZrysDku3jGuWaDqf9TrV3x5JLXt1eqnVhN0KM6fMcbA1nod3h8AwaAvWwEALw_wcB). \n",
    "\n",
    "Let's assume that a candy company has gone out and collected information on the types of Halloween candy kids ate. Our candy company wants to predict the eating behavior of witches, warlocks, and ghosts -- aka costumed kids. They shared a sample dataset with us. Each row represents a piece of candy that a costumed child was presented with during \"trick\" or \"treat\". We know if the candy was `chocolate` (or not chocolate) or `gummy` (or not gummy). Your goal is to predict if the costumed kid `ate` the piece of candy. \n",
    "\n",
    "If both chocolate and gummy equal one, you've got a chocolate gummy bear on your hands!?!?!\n",
    "![Chocolate Gummy Bear](https://ed910ae2d60f0d25bcb8-80550f96b5feb12604f4f720bfefb46d.ssl.cf1.rackcdn.com/3fb630c04435b7b5-2leZuM7_-zoom.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "candy = pd.read_csv('chocolate_gummy_bears.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chocolate</th>\n",
       "      <th>gummy</th>\n",
       "      <th>ate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   chocolate  gummy  ate\n",
       "0          0      1    1\n",
       "1          1      0    1\n",
       "2          0      1    1\n",
       "3          0      0    0\n",
       "4          1      1    0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron\n",
    "\n",
    "To make predictions on the `candy` dataframe. Build and train a Perceptron using numpy. Your target column is `ate` and your features: `chocolate` and `gummy`. Do not do any feature engineering. :P\n",
    "\n",
    "Once you've trained your model, report your accuracy. You will not be able to achieve more than ~50% with the simple perceptron. Explain why you could not achieve a higher accuracy with the *simple perceptron* architecture, because it's possible to achieve ~95% accuracy on this dataset. Provide your answer in markdown (and *optional* data anlysis code) after your perceptron implementation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "# Start your candy perceptron here\n",
    "\n",
    "X = candy[['chocolate', 'gummy']].values\n",
    "y = candy['ate'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    5000\n",
       "0    5000\n",
       "Name: ate, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candy.ate.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron(object):\n",
    "  def __init__(self, rate = 0.01, niter = 10):\n",
    "    self.rate = rate\n",
    "    self.niter = niter\n",
    "\n",
    "  def fit(self, X, y):\n",
    "\n",
    "    # weights\n",
    "    self.weight = np.zeros(1 + X.shape[1])\n",
    "\n",
    "    # Number of misclassifications\n",
    "    self.errors = []  # Number of misclassifications\n",
    "\n",
    "    for i in range(self.niter):\n",
    "      err = 0\n",
    "      for xi, target in zip(X, y):\n",
    "        delta_w = self.rate * (target - self.predict(xi))\n",
    "        self.weight[1:] += delta_w * xi\n",
    "        self.weight[0] += delta_w\n",
    "        err += int(delta_w != 0.0)\n",
    "      self.errors.append(err)\n",
    "    return self\n",
    "    \n",
    "    for i in range(self.niter):\n",
    "        weighted_sum = np.dot(X, self.weight)\n",
    "        activated_output = sigmoid(weighted_sum)\n",
    "        error = correct_outputs - activated_output\n",
    "        adjustments = error*sigmoid_derivative(activated_output)\n",
    "        weights =+ np.dot(X.T, adjustments)\n",
    "        return weights\n",
    "  def net_input(self, X):\n",
    "    \"\"\"Calculate net input\"\"\"\n",
    "    return np.dot(X, self.weight[1:]) + self.weight[0]\n",
    "\n",
    "  def predict(self, X):\n",
    "    \"\"\"Return class label after unit step\"\"\"\n",
    "    return np.where(self.net_input(X) >= 0.0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "per = Perceptron(niter=10)\n",
    "per.fit(X,y)\n",
    "y_pred = per.predict(X)\n",
    "\n",
    "accuracy_score(y_pred, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer Perceptron <a id=\"Q3\"></a>\n",
    "\n",
    "Using the sample candy dataset, implement a Neural Network Multilayer Perceptron class that uses backpropagation to update the network's weights. Your Multilayer Perceptron should be implemented in Numpy. \n",
    "Your network must have one hidden layer.\n",
    "\n",
    "Once you've trained your model, report your accuracy. Explain why your MLP's performance is considerably better than your simple perceptron's on the candy dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 2), (10000, 1))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y.reshape(-1,1)\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork():\n",
    "    def __init__(self, input_size = 2, hiddenNodes = 4, outputNodes = 1):\n",
    "#     def __init__(self, input_size, hiddenNodes, outputNodes):\n",
    "        # Set up Architecture of neural network\n",
    "        self.input = input_size \n",
    "        self.hiddenNodes = hiddenNodes\n",
    "        self.outputNodes = outputNodes\n",
    "        \n",
    "        # Initial Weights\n",
    "        # 2x3 matrix for first layer\n",
    "        self.weights1 = np.random.randn(self.input, self.hiddenNodes)\n",
    "        #3x1 matrix for hidden to output layer\n",
    "        self.weights2 = np.random.randn(self.hiddenNodes, self.outputNodes)\n",
    "        \n",
    "    def sigmoid(self, s):\n",
    "        return 1 / (1 + np.exp(-s))\n",
    "    \n",
    "    def sigmoidPrime(self, s):\n",
    "        return s * (1 - s)\n",
    "    \n",
    "    def feed_forward(self, X):\n",
    "\n",
    "        #weighted sum of inputs and hidden layer\n",
    "        self.hidden_sum = np.dot(X, self.weights1)\n",
    "        \n",
    "        #add bias\n",
    "#         self.hidden_sum + bias\n",
    "\n",
    "        #Activations of weighted sums\n",
    "        self.activated_hidden = self.sigmoid(self.hidden_sum)\n",
    "\n",
    "        #Weighted sum between hidden and output\n",
    "        self.output_sum = np.dot(self.activated_hidden, self.weights2)\n",
    "\n",
    "        # Final Activation of output\n",
    "        self.activated_output = self.sigmoid(self.output_sum)\n",
    "\n",
    "\n",
    "        return self.activated_output\n",
    "    \n",
    "    def get_attributes(self):\n",
    "        \n",
    "        attributes = ['weights1', 'hidden_sum', 'activated_hidden', 'weights2', 'output']\n",
    "\n",
    "        [print(i + '\\n', getattr(nn,i), '\\n' + '---'*3) for i in dir(nn) if i in attributes]\n",
    "\n",
    "    def backward(self, X, y, o):\n",
    "        \"\"\"\n",
    "        Backward propagate through the network\n",
    "        \"\"\"\n",
    "        self.o_error = y - o #error in output\n",
    "        self.o_delta = self.o_error * self.sigmoidPrime(o) # apply derivative of sigmoid to error\n",
    "\n",
    "        self.z2_error = self.o_delta.dot(self.weights2.T) # z2 error: how much our hidden layer weights were off\n",
    "        self.z2_delta = self.z2_error*self.sigmoidPrime(self.activated_hidden)\n",
    "\n",
    "        self.weights2 += self.activated_hidden.T.dot(self.o_delta) #adjust second set (hidden => output) weights\n",
    "        self.weights1 += X.T.dot(self.z2_delta) #Adjust first set (input => hidden) weights\n",
    "\n",
    "    def train(self, X, y):\n",
    "        o = self.feed_forward(X)\n",
    "        self.backward(X, y, o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------EPOCH 1---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Predicted Output: \n",
      " [[0.21828036]\n",
      " [0.26820486]\n",
      " [0.21828036]\n",
      " ...\n",
      " [0.21828036]\n",
      " [0.21828036]\n",
      " [0.26820486]]\n",
      "Loss: \n",
      " 0.3157467070147821\n",
      "+---------EPOCH 2---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Predicted Output: \n",
      " [[0.50037399]\n",
      " [0.50011314]\n",
      " [0.50037399]\n",
      " ...\n",
      " [0.50037399]\n",
      " [0.50037399]\n",
      " [0.50011314]]\n",
      "Loss: \n",
      " 0.42464145539295123\n",
      "+---------EPOCH 3---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Predicted Output: \n",
      " [[0.5005672 ]\n",
      " [0.50012835]\n",
      " [0.5005672 ]\n",
      " ...\n",
      " [0.5005672 ]\n",
      " [0.5005672 ]\n",
      " [0.50012835]]\n",
      "Loss: \n",
      " 0.4245950477112503\n",
      "+---------EPOCH 4---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Predicted Output: \n",
      " [[0.5010664 ]\n",
      " [0.50014808]\n",
      " [0.5010664 ]\n",
      " ...\n",
      " [0.5010664 ]\n",
      " [0.5010664 ]\n",
      " [0.50014808]]\n",
      "Loss: \n",
      " 0.4244795815026175\n",
      "+---------EPOCH 5---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Predicted Output: \n",
      " [[0.50349   ]\n",
      " [0.50017464]\n",
      " [0.50349   ]\n",
      " ...\n",
      " [0.50349   ]\n",
      " [0.50349   ]\n",
      " [0.50017464]]\n",
      "Loss: \n",
      " 0.423936194162634\n",
      "+---------EPOCH 1000---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Predicted Output: \n",
      " [[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " ...\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "Loss: \n",
      " 0.5\n",
      "+---------EPOCH 2000---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Predicted Output: \n",
      " [[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " ...\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "Loss: \n",
      " 0.5\n",
      "+---------EPOCH 3000---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Predicted Output: \n",
      " [[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " ...\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "Loss: \n",
      " 0.5\n",
      "+---------EPOCH 4000---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Predicted Output: \n",
      " [[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " ...\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "Loss: \n",
      " 0.5\n",
      "+---------EPOCH 5000---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Predicted Output: \n",
      " [[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " ...\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "Loss: \n",
      " 0.5\n",
      "+---------EPOCH 6000---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Predicted Output: \n",
      " [[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " ...\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "Loss: \n",
      " 0.5\n",
      "+---------EPOCH 7000---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Predicted Output: \n",
      " [[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " ...\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "Loss: \n",
      " 0.5\n",
      "+---------EPOCH 8000---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Predicted Output: \n",
      " [[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " ...\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "Loss: \n",
      " 0.5\n",
      "+---------EPOCH 9000---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Predicted Output: \n",
      " [[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " ...\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "Loss: \n",
      " 0.5\n",
      "+---------EPOCH 10000---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Predicted Output: \n",
      " [[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " ...\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "Loss: \n",
      " 0.5\n"
     ]
    }
   ],
   "source": [
    "nn = NeuralNetwork()\n",
    "\n",
    "# Number of Epochs / Iterations\n",
    "for i in range(10000):\n",
    "    if (i+1 in [1,2,3,4,5]) or ((i+1) % 1000 ==0):\n",
    "        print('+' + '---' * 3 + f'EPOCH {i+1}' + '---'*3 + '+')\n",
    "        print('Input: \\n', X)\n",
    "        print('Actual Output: \\n', y)\n",
    "        print('Predicted Output: \\n', str(nn.feed_forward(X)))\n",
    "        print(\"Loss: \\n\", str(np.mean(np.square(y - nn.feed_forward(X)))))\n",
    "    nn.train(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P.S. Don't try candy gummy bears. They're disgusting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Keras MMP <a id=\"Q3\"></a>\n",
    "\n",
    "Implement a Multilayer Perceptron architecture of your choosing using the Keras library. Train your model and report its baseline accuracy. Then hyperparameter tune at least two parameters and report your model's accuracy.\n",
    "Use the Heart Disease Dataset (binary classification)\n",
    "Use an appropriate loss function for a binary classification task\n",
    "Use an appropriate activation function on the final layer of your network.\n",
    "Train your model using verbose output for ease of grading.\n",
    "Use GridSearchCV or RandomSearchCV to hyperparameter tune your model. (for at least two hyperparameters)\n",
    "When hyperparameter tuning, show you work by adding code cells for each new experiment.\n",
    "Report the accuracy for each combination of hyperparameters as you test them so that we can easily see which resulted in the highest accuracy.\n",
    "You must hyperparameter tune at least 3 parameters in order to get a 3 on this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(303, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>268</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>160</td>\n",
       "      <td>0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>120</td>\n",
       "      <td>340</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "167   62    0   0       140   268    0        0      160      0      3.6   \n",
       "301   57    1   0       130   131    0        1      115      1      1.2   \n",
       "9     57    1   2       150   168    0        1      174      0      1.6   \n",
       "0     63    1   3       145   233    1        0      150      0      2.3   \n",
       "16    58    0   2       120   340    0        1      172      0      0.0   \n",
       "\n",
       "     slope  ca  thal  target  \n",
       "167      0   2     2       0  \n",
       "301      1   1     3       0  \n",
       "9        2   0     2       1  \n",
       "0        0   0     1       1  \n",
       "16       2   0     2       1  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.optimizers import SGD\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, Dropout\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/ryanleeallred/datasets/master/heart.csv')\n",
    "df = df.sample(frac=1)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'target'\n",
    "features = ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach',\n",
    "       'exang', 'oldpeak', 'slope', 'ca', 'thal']\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled = pd.DataFrame(X_scaled, columns=X.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy: 0.5445544554455446\n"
     ]
    }
   ],
   "source": [
    "## BASELINE ACCURACY\n",
    "\n",
    "#Identify target in our df and set the predicted value to the mode\n",
    "y_true = df['target']\n",
    "majority = df['target'].mode()[0]\n",
    "\n",
    "#Create a list of predictions for the length of our df\n",
    "y_pred = [majority] * len(y_true)\n",
    "\n",
    "#Use accuracy_score to check our baseline accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Baseline Accuracy:\", accuracy_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((212, 13), (91, 13), (212,), (91,))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, \n",
    "    y,\n",
    "    test_size=0.3,\n",
    "    random_state=5\n",
    "    )\n",
    "\n",
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 212 samples, validate on 91 samples\n",
      "Epoch 1/10\n",
      "212/212 [==============================] - 3s 14ms/step - loss: 0.5932 - accuracy: 0.7028 - val_loss: 0.4257 - val_accuracy: 0.8681\n",
      "Epoch 2/10\n",
      "212/212 [==============================] - 0s 785us/step - loss: 0.4477 - accuracy: 0.8113 - val_loss: 0.3474 - val_accuracy: 0.8791\n",
      "Epoch 3/10\n",
      "212/212 [==============================] - 0s 911us/step - loss: 0.4299 - accuracy: 0.8302 - val_loss: 0.3532 - val_accuracy: 0.8681\n",
      "Epoch 4/10\n",
      "212/212 [==============================] - 0s 527us/step - loss: 0.4035 - accuracy: 0.8538 - val_loss: 0.3533 - val_accuracy: 0.8681\n",
      "Epoch 5/10\n",
      "212/212 [==============================] - 0s 516us/step - loss: 0.3620 - accuracy: 0.8302 - val_loss: 0.3539 - val_accuracy: 0.8681\n",
      "Epoch 6/10\n",
      "212/212 [==============================] - 0s 510us/step - loss: 0.3330 - accuracy: 0.8396 - val_loss: 0.3590 - val_accuracy: 0.8681\n",
      "Epoch 7/10\n",
      "212/212 [==============================] - 0s 481us/step - loss: 0.3243 - accuracy: 0.8585 - val_loss: 0.3556 - val_accuracy: 0.8462\n",
      "Epoch 8/10\n",
      "212/212 [==============================] - 0s 505us/step - loss: 0.3135 - accuracy: 0.8538 - val_loss: 0.3658 - val_accuracy: 0.8242\n",
      "Epoch 9/10\n",
      "212/212 [==============================] - 0s 489us/step - loss: 0.2987 - accuracy: 0.8679 - val_loss: 0.3895 - val_accuracy: 0.8462\n",
      "Epoch 10/10\n",
      "212/212 [==============================] - 0s 496us/step - loss: 0.2874 - accuracy: 0.8915 - val_loss: 0.3621 - val_accuracy: 0.8462\n"
     ]
    }
   ],
   "source": [
    "batch_size = 20\n",
    "num_classes = 2\n",
    "epochs = 10\n",
    "\n",
    "opt = SGD(lr=0.1, momentum=0.9)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(5, activation='relu', input_shape=(13,)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(\n",
    "    loss='binary_crossentropy', \n",
    "    optimizer=opt, \n",
    "    metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "history = model.fit(\n",
    "    x_train, \n",
    "    y_train, \n",
    "    validation_data=(x_test, y_test), \n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    verbose=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(momentum=0, lr=0, dropout_rate=0, kernel_initializer='normal'):\n",
    "    opt = SGD(lr=lr, momentum=momentum)\n",
    "    model = Sequential()\n",
    "    model.add(Dense(30, \n",
    "                    input_shape=(13,),\n",
    "                    kernel_initializer=kernel_initializer,\n",
    "                    activation='sigmoid'\n",
    "                    ))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(20, activation='relu'))\n",
    "    model.add(Dense(3, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer=kernel_initializer, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "\n",
    "# define the grid search parameters\n",
    "momentum = [0.3, 0.4]\n",
    "lr = [0.001, 0.01, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "dropout_rate = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "batch_size = [5, 10, 50, 100]\n",
    "epochs = [10]\n",
    "\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.5571428656578064 using {'batch_size': 5, 'epochs': 10}\n",
      "Means: 0.5571428656578064, Stdev: 0.06179203482097474 with: {'batch_size': 5, 'epochs': 10}\n",
      "Means: 0.44772979617118835, Stdev: 0.06596504404181693 with: {'batch_size': 10, 'epochs': 10}\n",
      "Means: 0.4810631275177002, Stdev: 0.06052877453845564 with: {'batch_size': 50, 'epochs': 10}\n",
      "Means: 0.495348846912384, Stdev: 0.08403528686128361 with: {'batch_size': 100, 'epochs': 10}\n"
     ]
    }
   ],
   "source": [
    "# Create Grid Search\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1)\n",
    "grid_result = grid.fit(x_train, y_train)\n",
    "\n",
    "# Report Results\n",
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = dict(lr=lr, epochs=[10], batch_size=[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.7919158339500427 using {'batch_size': 10, 'epochs': 10, 'lr': 0.4}\n",
      "Means: 0.495348846912384, Stdev: 0.08403528686128361 with: {'batch_size': 10, 'epochs': 10, 'lr': 0.001}\n",
      "Means: 0.5524917006492615, Stdev: 0.06578893543637097 with: {'batch_size': 10, 'epochs': 10, 'lr': 0.01}\n",
      "Means: 0.5810631275177002, Stdev: 0.07716547119620129 with: {'batch_size': 10, 'epochs': 10, 'lr': 0.1}\n",
      "Means: 0.7347729802131653, Stdev: 0.13190664894583184 with: {'batch_size': 10, 'epochs': 10, 'lr': 0.2}\n",
      "Means: 0.7408637881278992, Stdev: 0.1428807570360425 with: {'batch_size': 10, 'epochs': 10, 'lr': 0.3}\n",
      "Means: 0.7919158339500427, Stdev: 0.06406055429385626 with: {'batch_size': 10, 'epochs': 10, 'lr': 0.4}\n",
      "Means: 0.7822812795639038, Stdev: 0.08145326126683324 with: {'batch_size': 10, 'epochs': 10, 'lr': 0.5}\n"
     ]
    }
   ],
   "source": [
    "# Create Grid Search\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1)\n",
    "grid_result = grid.fit(x_train, y_train)\n",
    "\n",
    "# Report Results\n",
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = dict(dropout_rate=dropout_rate, lr=[0.2], epochs=[10], batch_size=[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.7965669870376587 using {'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 10, 'lr': 0.2}\n",
      "Means: 0.7637873649597168, Stdev: 0.044172860457633925 with: {'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 10, 'lr': 0.2}\n",
      "Means: 0.7965669870376587, Stdev: 0.06440253004626151 with: {'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 10, 'lr': 0.2}\n",
      "Means: 0.7306755304336547, Stdev: 0.0729323220852061 with: {'batch_size': 10, 'dropout_rate': 0.2, 'epochs': 10, 'lr': 0.2}\n",
      "Means: 0.6796234846115112, Stdev: 0.11204745853411106 with: {'batch_size': 10, 'dropout_rate': 0.3, 'epochs': 10, 'lr': 0.2}\n",
      "Means: 0.6648947954177856, Stdev: 0.15101867102983685 with: {'batch_size': 10, 'dropout_rate': 0.4, 'epochs': 10, 'lr': 0.2}\n",
      "Means: 0.6239202737808227, Stdev: 0.126003933885156 with: {'batch_size': 10, 'dropout_rate': 0.5, 'epochs': 10, 'lr': 0.2}\n"
     ]
    }
   ],
   "source": [
    "# Create Grid Search\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1)\n",
    "grid_result = grid.fit(x_train, y_train)\n",
    "\n",
    "# Report Results\n",
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = dict(momentum=momentum, dropout_rate=[0.1], lr=[0.2], epochs=[10], batch_size=[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.8106312274932861 using {'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 10, 'lr': 0.2, 'momentum': 0.4}\n",
      "Means: 0.7772979021072388, Stdev: 0.09479823377517681 with: {'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 10, 'lr': 0.2, 'momentum': 0.3}\n",
      "Means: 0.8106312274932861, Stdev: 0.06154803689407415 with: {'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 10, 'lr': 0.2, 'momentum': 0.4}\n"
     ]
    }
   ],
   "source": [
    "# Create Grid Search\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1)\n",
    "grid_result = grid.fit(x_train, y_train)\n",
    "\n",
    "# Report Results\n",
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = SGD(lr=0.2, momentum=0.4)\n",
    "model = Sequential()\n",
    "model.add(Dense(30, input_shape=(13,), kernel_initializer='normal', activation='sigmoid'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(3, activation='relu'))\n",
    "model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 212 samples, validate on 91 samples\n",
      "Epoch 1/10\n",
      "212/212 [==============================] - 6s 27ms/step - loss: 0.6945 - accuracy: 0.5283 - val_loss: 0.6934 - val_accuracy: 0.5275\n",
      "Epoch 2/10\n",
      "212/212 [==============================] - 0s 1ms/step - loss: 0.6810 - accuracy: 0.5566 - val_loss: 0.6451 - val_accuracy: 0.7363\n",
      "Epoch 3/10\n",
      "212/212 [==============================] - 0s 2ms/step - loss: 0.5823 - accuracy: 0.7311 - val_loss: 0.7198 - val_accuracy: 0.5824\n",
      "Epoch 4/10\n",
      "212/212 [==============================] - 0s 1ms/step - loss: 0.5503 - accuracy: 0.7594 - val_loss: 0.4047 - val_accuracy: 0.8791\n",
      "Epoch 5/10\n",
      "212/212 [==============================] - 0s 1ms/step - loss: 0.4810 - accuracy: 0.7736 - val_loss: 0.4327 - val_accuracy: 0.7912\n",
      "Epoch 6/10\n",
      "212/212 [==============================] - 0s 1ms/step - loss: 0.4854 - accuracy: 0.7783 - val_loss: 0.4346 - val_accuracy: 0.8681\n",
      "Epoch 7/10\n",
      "212/212 [==============================] - 0s 1ms/step - loss: 0.4597 - accuracy: 0.7925 - val_loss: 0.3779 - val_accuracy: 0.8571\n",
      "Epoch 8/10\n",
      "212/212 [==============================] - 0s 1ms/step - loss: 0.4249 - accuracy: 0.8255 - val_loss: 0.3740 - val_accuracy: 0.8571\n",
      "Epoch 9/10\n",
      "212/212 [==============================] - 0s 1ms/step - loss: 0.4450 - accuracy: 0.8113 - val_loss: 0.3512 - val_accuracy: 0.8791\n",
      "Epoch 10/10\n",
      "212/212 [==============================] - 0s 1ms/step - loss: 0.4313 - accuracy: 0.8019 - val_loss: 0.3877 - val_accuracy: 0.8132\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1951b5d90>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), verbose=True, epochs=10, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_308\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1209 (Dense)           (None, 30)                420       \n",
      "_________________________________________________________________\n",
      "dropout_291 (Dropout)        (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense_1210 (Dense)           (None, 20)                620       \n",
      "_________________________________________________________________\n",
      "dense_1211 (Dense)           (None, 3)                 63        \n",
      "_________________________________________________________________\n",
      "dense_1212 (Dense)           (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 1,107\n",
      "Trainable params: 1,107\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy =  0.8131868243217468\n"
     ]
    }
   ],
   "source": [
    "print('Model Accuracy = ',score[1])"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "nteract": {
   "version": "0.15.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
