{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y6SKlgYrpcym"
   },
   "source": [
    "# Neural Networks Sprint Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BrEbRrjVphPM"
   },
   "source": [
    "## 1) Define the following terms:\n",
    "\n",
    "- Neuron\n",
    "- Input Layer\n",
    "- Hidden Layer\n",
    "- Output Layer\n",
    "- Activation\n",
    "- Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q5EksLqnp4oB"
   },
   "source": [
    "- Neuron: Receives one or more inputs, weights their values, sums them, and usually applies an activation function. The neural network is made up of layers of neurons, with one layer being an input, another being the output, and all others being hidden layers.\n",
    "- Input Layer: Layer of neurons which correspond to a row of the independent variables (x) in the data set. The input layer has no inputs going into it in a standard neural network.\n",
    "- Hidden Layer: Layer of neurons which has inputs going into it and outputs coming out of it. The values of the neurons in these layers are generally difficult to describe functions for.\n",
    "- Output Layer. Layer of neurons that correspond to a row of dependent variables (y) in the data set. The output layer has no outputs coming from it.\n",
    "- Activation: a function that is applied to the sum of weighted values coming into a neuron and defines the value of the neuron. Common activations include 'relu' and 'sigmoid' functions.\n",
    "- Backpropagation: Method of determining the correct weights of the neural network during the fitting of the neural network model. It works throught a generalization of the chain rule for differentials, and uses the calculation of the differential error layer by layer in reverse, from output to input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ri_gRA2Jp728"
   },
   "source": [
    "## 2) Create a perceptron class that can model the behavior of an AND gate. You can use the following table as your training data:\n",
    "\n",
    "| x1 | x2 | x3 | y |\n",
    "|----|----|----|---|\n",
    "| 1  | 1  | 1  | 1 |\n",
    "| 1  | 0  | 1  | 0 |\n",
    "| 0  | 1  | 1  | 0 |\n",
    "| 0  | 0  | 1  | 0 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ig6ZTH8tpQ19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.33895452e-01]\n",
      " [5.55409572e-02]\n",
      " [5.55409561e-02]\n",
      " [2.44730015e-04]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class NeuralNetwork(object):\n",
    "    \"\"\"Simple peceptron class.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.syn0 = 2 * np.random.random((3,1)) - 1\n",
    "        \n",
    "    def _calc_losses(self, X, y):\n",
    "        \"\"\"Run of one epoch in fitting of neural network for training.\"\"\"\n",
    "        self.l1 = 1 / (1 + np.exp(-(np.dot(X,self.syn0))))\n",
    "        self.l1_delta = (y - self.l1) * (1 - self.l1) * self.l1\n",
    "        self.syn0 += np.dot(X.T, self.l1_delta)\n",
    "        \n",
    "    def run(self, X, y, runs=1000):\n",
    "        \"\"\"Fits training data for neural network.\"\"\"\n",
    "        for i in range(runs):\n",
    "            self._calc_losses(X, y)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Calculate predicted values based on input using fitted model.\"\"\"\n",
    "        return 1 / (1 + np.exp(-(np.dot(X,self.syn0))))\n",
    "            \n",
    "X = np.array([[1,1,1],[1,0,1],[0,1,1],[0,0,1]])\n",
    "y = np.array([[1],[0],[0],[0]])\n",
    "\n",
    "model = NeuralNetwork()\n",
    "model.run(X,y)\n",
    "print(model.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "86HyRi8Osr3U"
   },
   "source": [
    "## 3) Implement a Neural Network Multilayer Perceptron class that uses backpropagation to update the network's weights. \n",
    "- Your network must have one hidden layer. \n",
    "- You do not have to update weights via gradient descent. You can use something like the derivative of the sigmoid function to update weights.\n",
    "- Train your model on the Heart Disease dataset from UCI:\n",
    "\n",
    "[Github Dataset](https://github.com/ryanleeallred/datasets/blob/master/heart.csv)\n",
    "\n",
    "[Raw File on Github](https://raw.githubusercontent.com/ryanleeallred/datasets/master/heart.csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CNfiajv3v4Ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9801980198019802\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "class MLPNeuralNetwork(object):\n",
    "    \"\"\"Multilayer neural network model with configurable layer sizes.\"\"\"\n",
    "    def __init__(self, layer_sizes):\n",
    "        self.layers = []\n",
    "        for i in range(len(layer_sizes)-1):\n",
    "            self.layers.append(2 * np.random.random((layer_sizes[i],layer_sizes[i+1])) - 1)\n",
    "        \n",
    "    def _calc_losses(self, X, y):\n",
    "        \"\"\"Run of one epoch in fitting of neural network for training.\"\"\"\n",
    "        self.losses = []\n",
    "        self.losses.append(1 / (1 + np.exp(-(np.dot(X, self.layers[0])))))\n",
    "        for layer in self.layers[1:]:\n",
    "            self.losses.append(1 / (1 + np.exp(-(np.dot(self.losses[-1], layer)))))\n",
    "        self.loss_delta = [(y - self.losses[-1]) * (1 - self.losses[-1]) * self.losses[-1]]\n",
    "        for i in range(-2, -len(self.losses) - 1, -1):\n",
    "            self.loss_delta = [self.loss_delta[0].dot(self.layers[i+1].T) * (1 - self.losses[i]) * self.losses[i]] + self.loss_delta\n",
    "        self.layers[0] += np.dot(X.T, self.loss_delta[0])\n",
    "        for i in range(1, len(self.layers)):\n",
    "            self.layers[i] += np.dot(self.losses[i-1].T, self.loss_delta[i])\n",
    "        \n",
    "    def run(self, X, y, runs=1000):\n",
    "        \"\"\"Fits training data for neural network.\"\"\"\n",
    "        for i in range(runs):\n",
    "            self._calc_losses(X, y)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Calculate predicted values based on input using fitted model.\"\"\"\n",
    "        self.losses = []\n",
    "        self.losses.append(1 / (1 + np.exp(-(np.dot(X, self.layers[0])))))\n",
    "        for layer in self.layers[1:]:\n",
    "            self.losses.append(1 / (1 + np.exp(-(np.dot(self.losses[-1], layer)))))\n",
    "        return self.losses[-1]\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/ryanleeallred/datasets/master/heart.csv\")\n",
    "X = df.drop(columns=[\"target\"]).values\n",
    "X = (X - X.mean(axis=0)) / X.std(axis=0)\n",
    "y = df[[\"target\"]].values\n",
    "\n",
    "model = MLPNeuralNetwork([X.shape[1], 8, y.shape[1]])\n",
    "model.run(X, y, 1000)\n",
    "pred = y.copy()\n",
    "p = model.predict(X)\n",
    "pred[p>0.5] = 1\n",
    "pred[p<=0.5] = 0\n",
    "print(accuracy_score(y, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GGT1oRzXw3H9"
   },
   "source": [
    "## 4) Implement a Multilayer Perceptron architecture of your choosing using the Keras library. Train your model and report its baseline accuracy. Then hyperparameter tune at least two parameters and report your model's accuracy. \n",
    "\n",
    "- Use the Heart Disease Dataset (binary classification)\n",
    "- Use an appropriate loss function for a binary classification task\n",
    "- Use an appropriate activation function on the final layer of your network. \n",
    "- Train your model using verbose output for ease of grading.\n",
    "- Use GridSearchCV to hyperparameter tune your model. (for at least two hyperparameters)\n",
    "- When hyperparameter tuning, show you work by adding code cells for each new experiment. \n",
    "- Report the accuracy for each combination of hyperparameters as you test them so that we can easily see which resulted in the highest accuracy.\n",
    "- You must hyperparameter tune at least 5 parameters in order to get a 3 on this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brit2\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   51.9s\n",
      "C:\\Users\\brit2\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\externals\\loky\\process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done 108 out of 108 | elapsed:  2.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "303/303 [==============================] - 1s 4ms/step - loss: 0.6912 - acc: 0.5578\n",
      "Epoch 2/10\n",
      "303/303 [==============================] - 0s 23us/step - loss: 0.6872 - acc: 0.5611\n",
      "Epoch 3/10\n",
      "303/303 [==============================] - 0s 30us/step - loss: 0.6837 - acc: 0.5710\n",
      "Epoch 4/10\n",
      "303/303 [==============================] - 0s 26us/step - loss: 0.6804 - acc: 0.5809\n",
      "Epoch 5/10\n",
      "303/303 [==============================] - 0s 30us/step - loss: 0.6770 - acc: 0.5941\n",
      "Epoch 6/10\n",
      "303/303 [==============================] - 0s 23us/step - loss: 0.6740 - acc: 0.5908\n",
      "Epoch 7/10\n",
      "303/303 [==============================] - 0s 30us/step - loss: 0.6708 - acc: 0.5908\n",
      "Epoch 8/10\n",
      "303/303 [==============================] - 0s 30us/step - loss: 0.6678 - acc: 0.6040\n",
      "Epoch 9/10\n",
      "303/303 [==============================] - 0s 26us/step - loss: 0.6651 - acc: 0.6073\n",
      "Epoch 10/10\n",
      "303/303 [==============================] - 0s 26us/step - loss: 0.6626 - acc: 0.6139\n",
      "0.7986798632656387 {'batch_size': 100, 'epochs': 10, 'layers': [8]}\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def create_model(layers=[16]):\n",
    "    model = Sequential()\n",
    "    for layer in layers:\n",
    "        model.add(Dense(layer, activation='sigmoid', input_dim=13))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "batch_size = [10, 40, 100]\n",
    "epochs = [10, 50, 100]\n",
    "layers = [[8], [12], [8,4], [12,4]]\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs, layers=layers)\n",
    "model = KerasClassifier(build_fn=create_model, verbose=1)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, verbose=1)\n",
    "grid_result = grid.fit(X, y)\n",
    "\n",
    "print(grid_result.best_score_, grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 10, 'epochs': 10, 'layers': [8]} 0.5709570984635809\n",
      "{'batch_size': 10, 'epochs': 10, 'layers': [12]} 0.4653465395221616\n",
      "{'batch_size': 10, 'epochs': 10, 'layers': [8, 4]} 0.15181518151815182\n",
      "{'batch_size': 10, 'epochs': 10, 'layers': [12, 4]} 0.6534653473706922\n",
      "{'batch_size': 10, 'epochs': 50, 'layers': [8]} 0.5676567654798527\n",
      "{'batch_size': 10, 'epochs': 50, 'layers': [12]} 0.6402640255174228\n",
      "{'batch_size': 10, 'epochs': 50, 'layers': [8, 4]} 0.557755775921809\n",
      "{'batch_size': 10, 'epochs': 50, 'layers': [12, 4]} 0.6138613863353288\n",
      "{'batch_size': 10, 'epochs': 100, 'layers': [8]} 0.6633663402728909\n",
      "{'batch_size': 10, 'epochs': 100, 'layers': [12]} 0.640264026255104\n",
      "{'batch_size': 10, 'epochs': 100, 'layers': [8, 4]} 0.6897689799467722\n",
      "{'batch_size': 10, 'epochs': 100, 'layers': [12, 4]} 0.6963696401111363\n",
      "{'batch_size': 40, 'epochs': 10, 'layers': [8]} 0.6666666716337204\n",
      "{'batch_size': 40, 'epochs': 10, 'layers': [12]} 0.3894389534350669\n",
      "{'batch_size': 40, 'epochs': 10, 'layers': [8, 4]} 0.7623762370336173\n",
      "{'batch_size': 40, 'epochs': 10, 'layers': [12, 4]} 0.2112211252596512\n",
      "{'batch_size': 40, 'epochs': 50, 'layers': [8]} 0.6699670054043086\n",
      "{'batch_size': 40, 'epochs': 50, 'layers': [12]} 0.46204620491553455\n",
      "{'batch_size': 40, 'epochs': 50, 'layers': [8, 4]} 0.2277227746378077\n",
      "{'batch_size': 40, 'epochs': 50, 'layers': [12, 4]} 0.23432343381859683\n",
      "{'batch_size': 40, 'epochs': 100, 'layers': [8]} 0.6369637000580431\n",
      "{'batch_size': 40, 'epochs': 100, 'layers': [12]} 0.6039603997280102\n",
      "{'batch_size': 40, 'epochs': 100, 'layers': [8, 4]} 0.3069306975937519\n",
      "{'batch_size': 40, 'epochs': 100, 'layers': [12, 4]} 0.5016501661599075\n",
      "{'batch_size': 100, 'epochs': 10, 'layers': [8]} 0.7986798632656387\n",
      "{'batch_size': 100, 'epochs': 10, 'layers': [12]} 0.49174917452406175\n",
      "{'batch_size': 100, 'epochs': 10, 'layers': [8, 4]} 0.17821782886391818\n",
      "{'batch_size': 100, 'epochs': 10, 'layers': [12, 4]} 0.5445544507243846\n",
      "{'batch_size': 100, 'epochs': 50, 'layers': [8]} 0.23762375529449764\n",
      "{'batch_size': 100, 'epochs': 50, 'layers': [12]} 0.2640264054188634\n",
      "{'batch_size': 100, 'epochs': 50, 'layers': [8, 4]} 0.6567656860099768\n",
      "{'batch_size': 100, 'epochs': 50, 'layers': [12, 4]} 0.43894389517629895\n",
      "{'batch_size': 100, 'epochs': 100, 'layers': [8]} 0.3828382778777541\n",
      "{'batch_size': 100, 'epochs': 100, 'layers': [12]} 0.5049504985903749\n",
      "{'batch_size': 100, 'epochs': 100, 'layers': [8, 4]} 0.18151815889692152\n",
      "{'batch_size': 100, 'epochs': 100, 'layers': [12, 4]} 0.2904290432485417\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(grid.cv_results_[\"mean_test_score\"])):\n",
    "    print(grid.cv_results_[\"params\"][i], grid.cv_results_[\"mean_test_score\"][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "DS43SC.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
