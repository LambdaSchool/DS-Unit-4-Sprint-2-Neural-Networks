{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "My Keras Notebook.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wel51x/DS-Unit-4-Sprint-3-Neural-Networks/blob/master/My_Keras_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CCQY7jpBfMur"
      },
      "source": [
        "##### Copyright 2018 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab_type": "code",
        "id": "z6X9omPnfO_h",
        "colab": {}
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "F1xIRPtY0E1w"
      },
      "source": [
        "# Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VyOjQZHhZxaA"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/guide/keras\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/guide/keras.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/guide/keras.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ViAXWoKlZ8s6"
      },
      "source": [
        "Keras is a high-level API to build and train deep learning models. It's used for\n",
        "fast prototyping, advanced research, and production, with three key advantages:\n",
        "\n",
        "- *User friendly*<br>\n",
        "  Keras has a simple, consistent interface optimized for common use cases. It\n",
        "  provides clear and actionable feedback for user errors.\n",
        "- *Modular and composable*<br>\n",
        "  Keras models are made by connecting configurable building blocks together,\n",
        "  with few restrictions.\n",
        "- *Easy to extend*<br> Write custom building blocks to express new ideas for\n",
        "  research. Create new layers, loss functions, and develop state-of-the-art\n",
        "  models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IsK5aF2xZ-40"
      },
      "source": [
        "## Import tf.keras\n",
        "\n",
        "`tf.keras` is TensorFlow's implementation of the\n",
        "[Keras API specification](https://keras.io). This is a high-level\n",
        "API to build and train models that includes first-class support for\n",
        "TensorFlow-specific functionality, such as [eager execution](#eager_execution),\n",
        "`tf.data` pipelines, and [Estimators](./estimators.md).\n",
        "`tf.keras` makes TensorFlow easier to use without sacrificing flexibility and\n",
        "performance.\n",
        "\n",
        "To get started, import `tf.keras` as part of your TensorFlow program setup:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Qoc055N3wiUG",
        "colab": {}
      },
      "source": [
        "\n",
        "!pip install -q pyyaml  # Required to save models in YAML format"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TgPcBFru0E1z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4847fefc-9304-4704-f55f-8c4584469b28"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "print(tf.VERSION)\n",
        "print(tf.keras.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.13.1\n",
            "2.2.4-tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lj03RamP0E13"
      },
      "source": [
        "`tf.keras` can run any Keras-compatible code, but keep in mind:\n",
        "\n",
        "* The `tf.keras` version in the latest TensorFlow release might not be the same\n",
        "  as the latest `keras` version from PyPI. Check `tf.keras.__version__`.\n",
        "* When [saving a model's weights](#weights_only), `tf.keras` defaults to the\n",
        "  [checkpoint format](./checkpoints.md). Pass `save_format='h5'` to\n",
        "  use HDF5."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7e1LPcXx0gR6"
      },
      "source": [
        "## Build a simple model\n",
        "\n",
        "### Sequential model\n",
        "\n",
        "In Keras, you assemble *layers* to build *models*. A model is (usually) a graph\n",
        "of layers. The most common type of model is a stack of layers: the\n",
        "`tf.keras.Sequential` model.\n",
        "\n",
        "To build a simple, fully-connected network (i.e. multi-layer perceptron):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WM-DUVQB0E14",
        "colab": {}
      },
      "source": [
        "model = tf.keras.Sequential()\n",
        "# Adds a densely-connected layer with 64 units to the model:\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "# Add another:\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "# Add a softmax layer with 10 output units:\n",
        "model.add(layers.Dense(10, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-ztyTipu0E18"
      },
      "source": [
        "### Configure the layers\n",
        "\n",
        "There are many `tf.keras.layers` available with some common constructor\n",
        "parameters:\n",
        "\n",
        "* `activation`: Set the activation function for the layer. This parameter is\n",
        "  specified by the name of a built-in function or as a callable object. By\n",
        "  default, no activation is applied.\n",
        "* `kernel_initializer` and `bias_initializer`: The initialization schemes\n",
        "  that create the layer's weights (kernel and bias). This parameter is a name or\n",
        "  a callable object. This defaults to the `\"Glorot uniform\"` initializer.\n",
        "* `kernel_regularizer` and `bias_regularizer`: The regularization schemes\n",
        "  that apply the layer's weights (kernel and bias), such as L1 or L2\n",
        "  regularization. By default, no regularization is applied.\n",
        "\n",
        "The following instantiates `tf.keras.layers.Dense` layers using constructor\n",
        "arguments:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MlL7PBtp0E19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "46c1602b-a66d-4e52-e5f9-0786b8ba6c93"
      },
      "source": [
        "# Create a sigmoid layer:\n",
        "layers.Dense(64, activation='sigmoid')\n",
        "# Or:\n",
        "layers.Dense(64, activation=tf.sigmoid)\n",
        "\n",
        "# A linear layer with L1 regularization of factor 0.01 applied to the kernel matrix:\n",
        "layers.Dense(64, kernel_regularizer=tf.keras.regularizers.l1(0.01))\n",
        "\n",
        "# A linear layer with L2 regularization of factor 0.01 applied to the bias vector:\n",
        "layers.Dense(64, bias_regularizer=tf.keras.regularizers.l2(0.01))\n",
        "\n",
        "# A linear layer with a kernel initialized to a random orthogonal matrix:\n",
        "layers.Dense(64, kernel_initializer='orthogonal')\n",
        "\n",
        "# A linear layer with a bias vector initialized to 2.0s:\n",
        "layers.Dense(64, bias_initializer=tf.keras.initializers.constant(2.0))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.layers.core.Dense at 0x7f6104f40eb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9NR6reyk0E2A"
      },
      "source": [
        "## Train and evaluate\n",
        "\n",
        "### Set up training\n",
        "\n",
        "After the model is constructed, configure its learning process by calling the\n",
        "`compile` method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sJ4AOn090E2A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "394dd63f-15e9-42f1-87d2-684622a2c7e0"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "# Adds a densely-connected layer with 64 units to the model:\n",
        "layers.Dense(64, activation='relu', input_shape=(32,)),\n",
        "# Add another:\n",
        "layers.Dense(64, activation='relu'),\n",
        "# Add a softmax layer with 10 output units:\n",
        "layers.Dense(10, activation='softmax')])\n",
        "\n",
        "model.compile(optimizer=tf.train.AdamOptimizer(0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HG-RAa9F0E2D"
      },
      "source": [
        "`tf.keras.Model.compile` takes three important arguments:\n",
        "\n",
        "* `optimizer`: This object specifies the training procedure. Pass it optimizer\n",
        "  instances from the `tf.train` module, such as\n",
        "  `tf.train.AdamOptimizer`, `tf.train.RMSPropOptimizer`, or\n",
        "  `tf.train.GradientDescentOptimizer`.\n",
        "* `loss`: The function to minimize during optimization. Common choices include\n",
        "  mean square error (`mse`), `categorical_crossentropy`, and\n",
        "  `binary_crossentropy`. Loss functions are specified by name or by\n",
        "  passing a callable object from the `tf.keras.losses` module.\n",
        "* `metrics`: Used to monitor training. These are string names or callables from\n",
        "  the `tf.keras.metrics` module.\n",
        "\n",
        "The following shows a few examples of configuring a model for training:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "St4Mgdar0E2E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "3048afc5-ed02-4e43-924e-62679d692b0d"
      },
      "source": [
        "# Configure a model for mean-squared error regression.\n",
        "model.compile(optimizer=tf.train.AdamOptimizer(0.01),\n",
        "              loss='mse',       # mean squared error\n",
        "              metrics=['mae'])  # mean absolute error\n",
        "\n",
        "# Configure a model for categorical classification.\n",
        "model.compile(optimizer=tf.train.RMSPropOptimizer(0.01),\n",
        "              loss=tf.keras.losses.categorical_crossentropy,\n",
        "              metrics=[tf.keras.metrics.categorical_accuracy])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yjI5rbi80E2G"
      },
      "source": [
        "### Input NumPy data\n",
        "\n",
        "For small datasets, use in-memory [NumPy](https://www.numpy.org/)\n",
        "arrays to train and evaluate a model. The model is \"fit\" to the training data\n",
        "using the `fit` method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3CvP6L-m0E2I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "outputId": "279d4f32-0aeb-45b8-b3bb-cdae5ca1c45a"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def random_one_hot_labels(shape):\n",
        "  n, n_class = shape\n",
        "  classes = np.random.randint(0, n_class, n)\n",
        "  labels = np.zeros((n, n_class))\n",
        "  labels[np.arange(n), classes] = 1\n",
        "  return labels\n",
        "\n",
        "data = np.random.random((1000, 32))\n",
        "labels = random_one_hot_labels((1000, 10))\n",
        "\n",
        "model.fit(data, labels, epochs=10, batch_size=32)\n",
        "data"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/10\n",
            "1000/1000 [==============================] - 1s 915us/sample - loss: 2.3357 - categorical_accuracy: 0.1160\n",
            "Epoch 2/10\n",
            "1000/1000 [==============================] - 0s 80us/sample - loss: 2.3141 - categorical_accuracy: 0.1050\n",
            "Epoch 3/10\n",
            "1000/1000 [==============================] - 0s 81us/sample - loss: 2.3092 - categorical_accuracy: 0.1170\n",
            "Epoch 4/10\n",
            "1000/1000 [==============================] - 0s 79us/sample - loss: 2.3086 - categorical_accuracy: 0.0990\n",
            "Epoch 5/10\n",
            "1000/1000 [==============================] - 0s 81us/sample - loss: 2.3111 - categorical_accuracy: 0.1120\n",
            "Epoch 6/10\n",
            "1000/1000 [==============================] - 0s 86us/sample - loss: 2.3027 - categorical_accuracy: 0.1200\n",
            "Epoch 7/10\n",
            "1000/1000 [==============================] - 0s 83us/sample - loss: 2.2957 - categorical_accuracy: 0.1220\n",
            "Epoch 8/10\n",
            "1000/1000 [==============================] - 0s 86us/sample - loss: 2.2778 - categorical_accuracy: 0.1380\n",
            "Epoch 9/10\n",
            "1000/1000 [==============================] - 0s 80us/sample - loss: 2.2706 - categorical_accuracy: 0.1420\n",
            "Epoch 10/10\n",
            "1000/1000 [==============================] - 0s 79us/sample - loss: 2.2264 - categorical_accuracy: 0.1700\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.85040005, 0.53873325, 0.68422184, ..., 0.11837261, 0.50529092,\n",
              "        0.88907163],\n",
              "       [0.59293983, 0.16691415, 0.97474638, ..., 0.58522118, 0.24905869,\n",
              "        0.24467203],\n",
              "       [0.97729476, 0.54150302, 0.35788059, ..., 0.25147901, 0.06191175,\n",
              "        0.00298405],\n",
              "       ...,\n",
              "       [0.66641895, 0.45901941, 0.89716368, ..., 0.49530704, 0.08017441,\n",
              "        0.02797396],\n",
              "       [0.32553351, 0.14017345, 0.76619284, ..., 0.61041985, 0.79469481,\n",
              "        0.7785337 ],\n",
              "       [0.7718266 , 0.91634012, 0.9048159 , ..., 0.00486609, 0.00518908,\n",
              "        0.69823313]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "N-pnVaFe0E2N"
      },
      "source": [
        "`tf.keras.Model.fit` takes three important arguments:\n",
        "\n",
        "* `epochs`: Training is structured into *epochs*. An epoch is one iteration over\n",
        "  the entire input data (this is done in smaller batches).\n",
        "* `batch_size`: When passed NumPy data, the model slices the data into smaller\n",
        "  batches and iterates over these batches during training. This integer\n",
        "  specifies the size of each batch. Be aware that the last batch may be smaller\n",
        "  if the total number of samples is not divisible by the batch size.\n",
        "* `validation_data`: When prototyping a model, you want to easily monitor its\n",
        "  performance on some validation data. Passing this argument—a tuple of inputs\n",
        "  and labels—allows the model to display the loss and metrics in inference mode\n",
        "  for the passed data, at the end of each epoch.\n",
        "\n",
        "Here's an example using `validation_data`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gFcXzVQa0E2N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "48a8c4af-4c98-4fb2-bb2c-b84f57f15a0e"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "data = np.random.random((1000, 32))\n",
        "labels = random_one_hot_labels((1000, 10))\n",
        "\n",
        "val_data = np.random.random((100, 32))\n",
        "val_labels = random_one_hot_labels((100, 10))\n",
        "\n",
        "model.fit(data, labels, epochs=10, batch_size=32,\n",
        "          validation_data=(val_data, val_labels))\n",
        "labels"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1000 samples, validate on 100 samples\n",
            "Epoch 1/10\n",
            "1000/1000 [==============================] - 0s 124us/sample - loss: 2.3243 - categorical_accuracy: 0.0900 - val_loss: 2.3194 - val_categorical_accuracy: 0.1300\n",
            "Epoch 2/10\n",
            "1000/1000 [==============================] - 0s 93us/sample - loss: 2.2999 - categorical_accuracy: 0.1140 - val_loss: 2.3039 - val_categorical_accuracy: 0.1400\n",
            "Epoch 3/10\n",
            "1000/1000 [==============================] - 0s 85us/sample - loss: 2.2984 - categorical_accuracy: 0.1250 - val_loss: 2.3080 - val_categorical_accuracy: 0.0900\n",
            "Epoch 4/10\n",
            "1000/1000 [==============================] - 0s 85us/sample - loss: 2.2815 - categorical_accuracy: 0.1260 - val_loss: 2.4075 - val_categorical_accuracy: 0.1300\n",
            "Epoch 5/10\n",
            "1000/1000 [==============================] - 0s 86us/sample - loss: 2.2760 - categorical_accuracy: 0.1530 - val_loss: 2.3250 - val_categorical_accuracy: 0.1100\n",
            "Epoch 6/10\n",
            "1000/1000 [==============================] - 0s 94us/sample - loss: 2.2553 - categorical_accuracy: 0.1480 - val_loss: 2.3075 - val_categorical_accuracy: 0.1300\n",
            "Epoch 7/10\n",
            "1000/1000 [==============================] - 0s 85us/sample - loss: 2.2208 - categorical_accuracy: 0.1750 - val_loss: 2.3242 - val_categorical_accuracy: 0.1500\n",
            "Epoch 8/10\n",
            "1000/1000 [==============================] - 0s 87us/sample - loss: 2.1981 - categorical_accuracy: 0.1890 - val_loss: 2.3773 - val_categorical_accuracy: 0.0700\n",
            "Epoch 9/10\n",
            "1000/1000 [==============================] - 0s 84us/sample - loss: 2.1557 - categorical_accuracy: 0.2100 - val_loss: 2.4033 - val_categorical_accuracy: 0.0800\n",
            "Epoch 10/10\n",
            "1000/1000 [==============================] - 0s 86us/sample - loss: 2.1320 - categorical_accuracy: 0.2180 - val_loss: 2.4122 - val_categorical_accuracy: 0.1400\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 1., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 1., ..., 0., 0., 0.],\n",
              "       [0., 0., 1., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-6ImyXzz0E2Q"
      },
      "source": [
        "### Input tf.data datasets\n",
        "\n",
        "Use the [Datasets API](./datasets.md) to scale to large datasets\n",
        "or multi-device training. Pass a `tf.data.Dataset` instance to the `fit`\n",
        "method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OziqhpIj0E2R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "79afaf84-92b7-4b58-ad5e-3c9ea32e2a90"
      },
      "source": [
        "# Instantiates a toy dataset instance:\n",
        "dataset = tf.data.Dataset.from_tensor_slices((data, labels))\n",
        "dataset = dataset.batch(32)\n",
        "dataset = dataset.repeat()\n",
        "\n",
        "# Don't forget to specify `steps_per_epoch` when calling `fit` on a dataset.\n",
        "model.fit(dataset, epochs=10, steps_per_epoch=30)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 2.0828 - categorical_accuracy: 0.2344\n",
            "Epoch 2/10\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 2.0183 - categorical_accuracy: 0.2628\n",
            "Epoch 3/10\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 1.9702 - categorical_accuracy: 0.2853\n",
            "Epoch 4/10\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 1.9141 - categorical_accuracy: 0.3013\n",
            "Epoch 5/10\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 1.8416 - categorical_accuracy: 0.3429\n",
            "Epoch 6/10\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 1.8005 - categorical_accuracy: 0.3504\n",
            "Epoch 7/10\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 1.7254 - categorical_accuracy: 0.3878\n",
            "Epoch 8/10\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 1.6965 - categorical_accuracy: 0.4103\n",
            "Epoch 9/10\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 1.6428 - categorical_accuracy: 0.4252\n",
            "Epoch 10/10\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 1.5983 - categorical_accuracy: 0.4338\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6105286c18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "I7BcMHkB0E2U"
      },
      "source": [
        "Here, the `fit` method uses the `steps_per_epoch` argument—this is the number of\n",
        "training steps the model runs before it moves to the next epoch. Since the\n",
        "`Dataset` yields batches of data, this snippet does not require a `batch_size`.\n",
        "\n",
        "Datasets can also be used for validation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YPMb3A0N0E2V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "outputId": "4713f77c-3586-4796-984f-0d4b7fe7cf4a"
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((data, labels))\n",
        "dataset = dataset.batch(32).repeat()\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_data, val_labels))\n",
        "val_dataset = val_dataset.batch(32).repeat()\n",
        "\n",
        "model.fit(dataset, epochs=10, steps_per_epoch=30,\n",
        "          validation_data=val_dataset,\n",
        "          validation_steps=3)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 1.5391 - categorical_accuracy: 0.4583 - val_loss: 3.1169 - val_categorical_accuracy: 0.0729\n",
            "Epoch 2/10\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 1.4680 - categorical_accuracy: 0.4861 - val_loss: 3.2739 - val_categorical_accuracy: 0.1029\n",
            "Epoch 3/10\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 1.4566 - categorical_accuracy: 0.4818 - val_loss: 3.1545 - val_categorical_accuracy: 0.0735\n",
            "Epoch 4/10\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 1.4004 - categorical_accuracy: 0.4989 - val_loss: 2.9845 - val_categorical_accuracy: 0.1029\n",
            "Epoch 5/10\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 1.3663 - categorical_accuracy: 0.5150 - val_loss: 3.5787 - val_categorical_accuracy: 0.1250\n",
            "Epoch 6/10\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 1.3159 - categorical_accuracy: 0.5545 - val_loss: 3.2451 - val_categorical_accuracy: 0.1471\n",
            "Epoch 7/10\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 1.2511 - categorical_accuracy: 0.5684 - val_loss: 3.2724 - val_categorical_accuracy: 0.0882\n",
            "Epoch 8/10\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 1.2462 - categorical_accuracy: 0.5673 - val_loss: 3.6049 - val_categorical_accuracy: 0.0882\n",
            "Epoch 9/10\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 1.1827 - categorical_accuracy: 0.6026 - val_loss: 4.0221 - val_categorical_accuracy: 0.1354\n",
            "Epoch 10/10\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 1.1503 - categorical_accuracy: 0.5972 - val_loss: 3.5834 - val_categorical_accuracy: 0.1029\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f60f80351d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IgGdlXso0E2X"
      },
      "source": [
        "### Evaluate and predict\n",
        "\n",
        "The `tf.keras.Model.evaluate` and `tf.keras.Model.predict` methods can use NumPy\n",
        "data and a `tf.data.Dataset`.\n",
        "\n",
        "To *evaluate* the inference-mode loss and metrics for the data provided:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mhDbOHEK0E2Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "cff224a5-e1d9-4b33-af63-4bbbfc5d86ba"
      },
      "source": [
        "data = np.random.random((1000, 32))\n",
        "labels = random_one_hot_labels((1000, 10))\n",
        "\n",
        "model.evaluate(data, labels, batch_size=32)\n",
        "\n",
        "model.evaluate(dataset, steps=30)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 0s 85us/sample - loss: 3.8409 - categorical_accuracy: 0.1240\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 1.4310 - categorical_accuracy: 0.5146\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.4309559285640716, 0.51458335]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UXUTmDfb0E2b"
      },
      "source": [
        "And to *predict* the output of the last layer in inference for the data provided,\n",
        "as a NumPy array:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9e3JsSoQ0E2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "46e59fa7-5141-42e2-bce7-6844de525f51"
      },
      "source": [
        "result = model.predict(data, batch_size=32)\n",
        "print(result.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fzEOW4Cn0E2h"
      },
      "source": [
        "## Build advanced models\n",
        "\n",
        "### Functional API\n",
        "\n",
        " The `tf.keras.Sequential` model is a simple stack of layers that cannot\n",
        "represent arbitrary models. Use the\n",
        "[Keras functional API](https://keras.io/getting-started/functional-api-guide/)\n",
        "to build complex model topologies such as:\n",
        "\n",
        "* Multi-input models,\n",
        "* Multi-output models,\n",
        "* Models with shared layers (the same layer called several times),\n",
        "* Models with non-sequential data flows (e.g. residual connections).\n",
        "\n",
        "Building a model with the functional API works like this:\n",
        "\n",
        "1. A layer instance is callable and returns a tensor.\n",
        "2. Input tensors and output tensors are used to define a `tf.keras.Model`\n",
        "   instance.\n",
        "3. This model is trained just like the `Sequential` model.\n",
        "\n",
        "The following example uses the functional API to build a simple, fully-connected\n",
        "network:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mROj832r0E2i",
        "colab": {}
      },
      "source": [
        "inputs = tf.keras.Input(shape=(32,))  # Returns a placeholder tensor\n",
        "\n",
        "# A layer instance is callable on a tensor, and returns a tensor.\n",
        "x = layers.Dense(64, activation='relu')(inputs)\n",
        "x = layers.Dense(64, activation='relu')(x)\n",
        "predictions = layers.Dense(10, activation='softmax')(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AFmspHeG1_W7"
      },
      "source": [
        "Instantiate the model given inputs and outputs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5k5uzlyu16HM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "bce8d997-4595-4184-860c-e3b0e8fb2bbc"
      },
      "source": [
        "model = tf.keras.Model(inputs=inputs, outputs=predictions)\n",
        "\n",
        "# The compile step specifies the training configuration.\n",
        "model.compile(optimizer=tf.train.RMSPropOptimizer(0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Trains for 5 epochs\n",
        "model.fit(data, labels, batch_size=32, epochs=5)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1000/1000 [==============================] - 0s 172us/sample - loss: 2.3961 - acc: 0.0890\n",
            "Epoch 2/5\n",
            "1000/1000 [==============================] - 0s 91us/sample - loss: 2.3566 - acc: 0.0940\n",
            "Epoch 3/5\n",
            "1000/1000 [==============================] - 0s 88us/sample - loss: 2.3168 - acc: 0.1220\n",
            "Epoch 4/5\n",
            "1000/1000 [==============================] - 0s 86us/sample - loss: 2.3036 - acc: 0.1180\n",
            "Epoch 5/5\n",
            "1000/1000 [==============================] - 0s 88us/sample - loss: 2.2943 - acc: 0.1330\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f60f0792e48>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EcKSLH3i0E2k"
      },
      "source": [
        "### Model subclassing\n",
        "\n",
        "Build a fully-customizable model by subclassing `tf.keras.Model` and defining\n",
        "your own forward pass. Create layers in the `__init__` method and set them as\n",
        "attributes of the class instance. Define the forward pass in the `call` method.\n",
        "\n",
        "Model subclassing is particularly useful when\n",
        "[eager execution](./eager.md) is enabled since the forward pass\n",
        "can be written imperatively.\n",
        "\n",
        "Key Point: Use the right API for the job. While model subclassing offers\n",
        "flexibility, it comes at a cost of greater complexity and more opportunities for\n",
        "user errors. If possible, prefer the functional API.\n",
        "\n",
        "The following example shows a subclassed `tf.keras.Model` using a custom forward\n",
        "pass:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KLiHWzcn2Fzk",
        "colab": {}
      },
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "\n",
        "  def __init__(self, num_classes=10):\n",
        "    super(MyModel, self).__init__(name='my_model')\n",
        "    self.num_classes = num_classes\n",
        "    # Define your layers here.\n",
        "    self.dense_1 = layers.Dense(32, activation='relu')\n",
        "    self.dense_2 = layers.Dense(num_classes, activation='sigmoid')\n",
        "\n",
        "  def call(self, inputs):\n",
        "    # Define your forward pass here,\n",
        "    # using layers you previously defined (in `__init__`).\n",
        "    x = self.dense_1(inputs)\n",
        "    return self.dense_2(x)\n",
        "\n",
        "  def compute_output_shape(self, input_shape):\n",
        "    # You need to override this function if you want to use the subclassed model\n",
        "    # as part of a functional-style model.\n",
        "    # Otherwise, this method is optional.\n",
        "    shape = tf.TensorShape(input_shape).as_list()\n",
        "    shape[-1] = self.num_classes\n",
        "    return tf.TensorShape(shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ShDD4fv72KGc"
      },
      "source": [
        "Instantiate the new model class:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "42C-qQHm0E2l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "aca9270f-e207-45a1-afd9-c618128ee877"
      },
      "source": [
        "model = MyModel(num_classes=10)\n",
        "\n",
        "# The compile step specifies the training configuration.\n",
        "model.compile(optimizer=tf.train.RMSPropOptimizer(0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Trains for 5 epochs.\n",
        "model.fit(data, labels, batch_size=32, epochs=5)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1000/1000 [==============================] - 0s 141us/sample - loss: 2.3218 - acc: 0.1180\n",
            "Epoch 2/5\n",
            "1000/1000 [==============================] - 0s 71us/sample - loss: 2.3194 - acc: 0.1190\n",
            "Epoch 3/5\n",
            "1000/1000 [==============================] - 0s 72us/sample - loss: 2.3139 - acc: 0.1280\n",
            "Epoch 4/5\n",
            "1000/1000 [==============================] - 0s 73us/sample - loss: 2.3075 - acc: 0.1210\n",
            "Epoch 5/5\n",
            "1000/1000 [==============================] - 0s 71us/sample - loss: 2.3028 - acc: 0.1330\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f60f029a4e0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yqRQiKj20E2o"
      },
      "source": [
        "### Custom layers\n",
        "\n",
        "Create a custom layer by subclassing `tf.keras.layers.Layer` and implementing\n",
        "the following methods:\n",
        "\n",
        "* `build`: Create the weights of the layer. Add weights with the `add_weight`\n",
        "  method.\n",
        "* `call`: Define the forward pass.\n",
        "* `compute_output_shape`: Specify how to compute the output shape of the layer\n",
        "  given the input shape.\n",
        "* Optionally, a layer can be serialized by implementing the `get_config` method\n",
        "  and the `from_config` class method.\n",
        "\n",
        "Here's an example of a custom layer that implements a `matmul` of an input with\n",
        "a kernel matrix:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "l7BFnIHr2WNc",
        "colab": {}
      },
      "source": [
        "class MyLayer(layers.Layer):\n",
        "\n",
        "  def __init__(self, output_dim, **kwargs):\n",
        "    self.output_dim = output_dim\n",
        "    super(MyLayer, self).__init__(**kwargs)\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    shape = tf.TensorShape((input_shape[1], self.output_dim))\n",
        "    # Create a trainable weight variable for this layer.\n",
        "    self.kernel = self.add_weight(name='kernel',\n",
        "                                  shape=shape,\n",
        "                                  initializer='uniform',\n",
        "                                  trainable=True)\n",
        "    # Make sure to call the `build` method at the end\n",
        "    super(MyLayer, self).build(input_shape)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return tf.matmul(inputs, self.kernel)\n",
        "\n",
        "  def compute_output_shape(self, input_shape):\n",
        "    shape = tf.TensorShape(input_shape).as_list()\n",
        "    shape[-1] = self.output_dim\n",
        "    return tf.TensorShape(shape)\n",
        "\n",
        "  def get_config(self):\n",
        "    base_config = super(MyLayer, self).get_config()\n",
        "    base_config['output_dim'] = self.output_dim\n",
        "    return base_config\n",
        "\n",
        "  @classmethod\n",
        "  def from_config(cls, config):\n",
        "    return cls(**config)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8wXDRgXV2ZrF"
      },
      "source": [
        "Create a model using your custom layer:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uqH-cY0h0E2p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "b498a033-a65b-4643-bef9-98c1fc398c80"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    MyLayer(10),\n",
        "    layers.Activation('softmax')])\n",
        "\n",
        "# The compile step specifies the training configuration\n",
        "model.compile(optimizer=tf.train.RMSPropOptimizer(0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Trains for 5 epochs.\n",
        "model.fit(data, labels, batch_size=32, epochs=5)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1000/1000 [==============================] - 0s 134us/sample - loss: 2.3015 - acc: 0.1290\n",
            "Epoch 2/5\n",
            "1000/1000 [==============================] - 0s 75us/sample - loss: 2.3005 - acc: 0.1230\n",
            "Epoch 3/5\n",
            "1000/1000 [==============================] - 0s 92us/sample - loss: 2.2982 - acc: 0.1220\n",
            "Epoch 4/5\n",
            "1000/1000 [==============================] - 0s 72us/sample - loss: 2.2947 - acc: 0.1260\n",
            "Epoch 5/5\n",
            "1000/1000 [==============================] - 0s 72us/sample - loss: 2.2922 - acc: 0.1310\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f60d6723b00>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Lu8cc3AJ0E2v"
      },
      "source": [
        "## Callbacks\n",
        "\n",
        "A callback is an object passed to a model to customize and extend its behavior\n",
        "during training. You can write your own custom callback, or use the built-in\n",
        "`tf.keras.callbacks` that include:\n",
        "\n",
        "* `tf.keras.callbacks.ModelCheckpoint`: Save checkpoints of your model at\n",
        "  regular intervals.\n",
        "* `tf.keras.callbacks.LearningRateScheduler`: Dynamically change the learning\n",
        "  rate.\n",
        "* `tf.keras.callbacks.EarlyStopping`: Interrupt training when validation\n",
        "  performance has stopped improving.\n",
        "* `tf.keras.callbacks.TensorBoard`: Monitor the model's behavior using\n",
        "  [TensorBoard](./summaries_and_tensorboard.md).\n",
        "\n",
        "To use a `tf.keras.callbacks.Callback`, pass it to the model's `fit` method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rdYwzSYV0E2v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "c429902b-ae13-4367-ff9e-de4ffb8eb8a1"
      },
      "source": [
        "callbacks = [\n",
        "  # Interrupt training if `val_loss` stops improving for over 2 epochs\n",
        "  tf.keras.callbacks.EarlyStopping(patience=2, monitor='val_loss'),\n",
        "  # Write TensorBoard logs to `./logs` directory\n",
        "  tf.keras.callbacks.TensorBoard(log_dir='./logs')\n",
        "]\n",
        "model.fit(data, labels, batch_size=32, epochs=5, callbacks=callbacks,\n",
        "          validation_data=(val_data, val_labels))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1000 samples, validate on 100 samples\n",
            "Epoch 1/5\n",
            "1000/1000 [==============================] - 0s 117us/sample - loss: 2.2894 - acc: 0.1300 - val_loss: 2.3111 - val_acc: 0.0800\n",
            "Epoch 2/5\n",
            "1000/1000 [==============================] - 0s 78us/sample - loss: 2.2868 - acc: 0.1280 - val_loss: 2.3108 - val_acc: 0.0800\n",
            "Epoch 3/5\n",
            "1000/1000 [==============================] - 0s 82us/sample - loss: 2.2840 - acc: 0.1310 - val_loss: 2.3106 - val_acc: 0.0800\n",
            "Epoch 4/5\n",
            "1000/1000 [==============================] - 0s 76us/sample - loss: 2.2816 - acc: 0.1360 - val_loss: 2.3079 - val_acc: 0.0900\n",
            "Epoch 5/5\n",
            "1000/1000 [==============================] - 0s 76us/sample - loss: 2.2786 - acc: 0.1280 - val_loss: 2.3046 - val_acc: 0.0900\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f60d658a518>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ghhaGfX62abv"
      },
      "source": [
        "<a id='weights_only'></a>\n",
        "## Save and restore"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qnl7K-aI0E2z"
      },
      "source": [
        "### Weights only\n",
        "\n",
        "Save and load the weights of a model using `tf.keras.Model.save_weights`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uQIANjB94fLB",
        "colab": {}
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "layers.Dense(64, activation='relu', input_shape=(32,)),\n",
        "layers.Dense(10, activation='softmax')])\n",
        "\n",
        "model.compile(optimizer=tf.train.AdamOptimizer(0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4eoHJ-ny0E21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "f4351bf7-7d78-44fe-df23-5636a11a4006"
      },
      "source": [
        "# Save weights to a TensorFlow Checkpoint file\n",
        "model.save_weights('./weights/my_model')\n",
        "\n",
        "# Restore the model's state,\n",
        "# this requires a model with the same architecture.\n",
        "model.load_weights('./weights/my_model')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py:1436: update_checkpoint_state (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.train.CheckpointManager to manage checkpoints rather than manually editing the Checkpoint proto.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.checkpointable.util.CheckpointLoadStatus at 0x7f60d6327240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "u25Id3xe0E25"
      },
      "source": [
        "By default, this saves the model's weights in the\n",
        "[TensorFlow checkpoint](./checkpoints.md) file format. Weights can\n",
        "also be saved to the Keras HDF5 format (the default for the multi-backend\n",
        "implementation of Keras):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JSAYoFEd0E26",
        "colab": {}
      },
      "source": [
        "# Save weights to a HDF5 file\n",
        "model.save_weights('my_model.h5', save_format='h5')\n",
        "\n",
        "# Restore the model's state\n",
        "model.load_weights('my_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mje_yKL10E29"
      },
      "source": [
        "### Configuration only\n",
        "\n",
        "A model's configuration can be saved—this serializes the model architecture\n",
        "without any weights. A saved configuration can recreate and initialize the same\n",
        "model, even without the code that defined the original model. Keras supports\n",
        "JSON and YAML serialization formats:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EbET0oJTzGkq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "ce6bf51b-9484-4aad-c76d-c90a63d15d5c"
      },
      "source": [
        "# Serialize a model to JSON format\n",
        "json_string = model.to_json()\n",
        "json_string"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\"class_name\": \"Sequential\", \"config\": {\"name\": \"sequential_3\", \"layers\": [{\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_17\", \"trainable\": true, \"batch_input_shape\": [null, 32], \"dtype\": \"float32\", \"units\": 64, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null, \"dtype\": \"float32\"}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {\"dtype\": \"float32\"}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_18\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 10, \"activation\": \"softmax\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null, \"dtype\": \"float32\"}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {\"dtype\": \"float32\"}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}]}, \"keras_version\": \"2.2.4-tf\", \"backend\": \"tensorflow\"}'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pX_badhH3yWV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "outputId": "f23fa20e-5efd-4d66-f99b-5e053977b118"
      },
      "source": [
        "import json\n",
        "import pprint\n",
        "pprint.pprint(json.loads(json_string))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'backend': 'tensorflow',\n",
            " 'class_name': 'Sequential',\n",
            " 'config': {'layers': [{'class_name': 'Dense',\n",
            "                        'config': {'activation': 'relu',\n",
            "                                   'activity_regularizer': None,\n",
            "                                   'batch_input_shape': [None, 32],\n",
            "                                   'bias_constraint': None,\n",
            "                                   'bias_initializer': {'class_name': 'Zeros',\n",
            "                                                        'config': {'dtype': 'float32'}},\n",
            "                                   'bias_regularizer': None,\n",
            "                                   'dtype': 'float32',\n",
            "                                   'kernel_constraint': None,\n",
            "                                   'kernel_initializer': {'class_name': 'GlorotUniform',\n",
            "                                                          'config': {'dtype': 'float32',\n",
            "                                                                     'seed': None}},\n",
            "                                   'kernel_regularizer': None,\n",
            "                                   'name': 'dense_17',\n",
            "                                   'trainable': True,\n",
            "                                   'units': 64,\n",
            "                                   'use_bias': True}},\n",
            "                       {'class_name': 'Dense',\n",
            "                        'config': {'activation': 'softmax',\n",
            "                                   'activity_regularizer': None,\n",
            "                                   'bias_constraint': None,\n",
            "                                   'bias_initializer': {'class_name': 'Zeros',\n",
            "                                                        'config': {'dtype': 'float32'}},\n",
            "                                   'bias_regularizer': None,\n",
            "                                   'dtype': 'float32',\n",
            "                                   'kernel_constraint': None,\n",
            "                                   'kernel_initializer': {'class_name': 'GlorotUniform',\n",
            "                                                          'config': {'dtype': 'float32',\n",
            "                                                                     'seed': None}},\n",
            "                                   'kernel_regularizer': None,\n",
            "                                   'name': 'dense_18',\n",
            "                                   'trainable': True,\n",
            "                                   'units': 10,\n",
            "                                   'use_bias': True}}],\n",
            "            'name': 'sequential_3'},\n",
            " 'keras_version': '2.2.4-tf'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Q7CIa05r4yTb"
      },
      "source": [
        "Recreate the model (newly initialized) from the JSON:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "J9UFv9k00E2_",
        "colab": {}
      },
      "source": [
        "fresh_model = tf.keras.models.model_from_json(json_string)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "t5NHtICh4uHK"
      },
      "source": [
        "Serializing a model to YAML format requires that you install `pyyaml` *before you import TensorFlow*:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aj24KB3Z36S4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        },
        "outputId": "b431e120-ef09-4642-e217-4ee7d7e0f408"
      },
      "source": [
        "yaml_string = model.to_yaml()\n",
        "print(yaml_string)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "backend: tensorflow\n",
            "class_name: Sequential\n",
            "config:\n",
            "  layers:\n",
            "  - class_name: Dense\n",
            "    config:\n",
            "      activation: relu\n",
            "      activity_regularizer: null\n",
            "      batch_input_shape: !!python/tuple [null, 32]\n",
            "      bias_constraint: null\n",
            "      bias_initializer:\n",
            "        class_name: Zeros\n",
            "        config: {dtype: float32}\n",
            "      bias_regularizer: null\n",
            "      dtype: float32\n",
            "      kernel_constraint: null\n",
            "      kernel_initializer:\n",
            "        class_name: GlorotUniform\n",
            "        config: {dtype: float32, seed: null}\n",
            "      kernel_regularizer: null\n",
            "      name: dense_17\n",
            "      trainable: true\n",
            "      units: 64\n",
            "      use_bias: true\n",
            "  - class_name: Dense\n",
            "    config:\n",
            "      activation: softmax\n",
            "      activity_regularizer: null\n",
            "      bias_constraint: null\n",
            "      bias_initializer:\n",
            "        class_name: Zeros\n",
            "        config: {dtype: float32}\n",
            "      bias_regularizer: null\n",
            "      dtype: float32\n",
            "      kernel_constraint: null\n",
            "      kernel_initializer:\n",
            "        class_name: GlorotUniform\n",
            "        config: {dtype: float32, seed: null}\n",
            "      kernel_regularizer: null\n",
            "      name: dense_18\n",
            "      trainable: true\n",
            "      units: 10\n",
            "      use_bias: true\n",
            "  name: sequential_3\n",
            "keras_version: 2.2.4-tf\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "O53Kerfl43v7"
      },
      "source": [
        "Recreate the model from the YAML:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "77yRuwg03_MG",
        "colab": {}
      },
      "source": [
        "fresh_model = tf.keras.models.model_from_yaml(yaml_string)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xPvOSSzM0E3B"
      },
      "source": [
        "Caution: Subclassed models are not serializable because their architecture is\n",
        "defined by the Python code in the body of the `call` method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iu8qMwld4-71"
      },
      "source": [
        "\n",
        "### Entire model\n",
        "\n",
        "The entire model can be saved to a file that contains the weight values, the\n",
        "model's configuration, and even the optimizer's configuration. This allows you\n",
        "to checkpoint a model and resume training later—from the exact same\n",
        "state—without access to the original code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "45oNY34Z0E3C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "2ab8427c-283b-413c-ccf6-4cdda98ae390"
      },
      "source": [
        "# Create a trivial model\n",
        "model = tf.keras.Sequential([\n",
        "  layers.Dense(64, activation='relu', input_shape=(32,)),\n",
        "  layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(data, labels, batch_size=32, epochs=5)\n",
        "\n",
        "\n",
        "# Save entire model to a HDF5 file\n",
        "model.save('my_model.h5')\n",
        "\n",
        "# Recreate the exact same model, including weights and optimizer.\n",
        "model = tf.keras.models.load_model('my_model.h5')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1000/1000 [==============================] - 0s 183us/sample - loss: 2.3247 - acc: 0.1040\n",
            "Epoch 2/5\n",
            "1000/1000 [==============================] - 0s 89us/sample - loss: 2.3002 - acc: 0.1270\n",
            "Epoch 3/5\n",
            "1000/1000 [==============================] - 0s 89us/sample - loss: 2.2888 - acc: 0.1270\n",
            "Epoch 4/5\n",
            "1000/1000 [==============================] - 0s 87us/sample - loss: 2.2812 - acc: 0.1410\n",
            "Epoch 5/5\n",
            "1000/1000 [==============================] - 0s 92us/sample - loss: 2.2720 - acc: 0.1540\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PMOWhDOB0E3E"
      },
      "source": [
        "## Eager execution\n",
        "\n",
        "[Eager execution](./eager.md) is an imperative programming\n",
        "environment that evaluates operations immediately. This is not required for\n",
        "Keras, but is supported by `tf.keras` and useful for inspecting your program and\n",
        "debugging.\n",
        "\n",
        "All of the `tf.keras` model-building APIs are compatible with eager execution.\n",
        "And while the `Sequential` and functional APIs can be used, eager execution\n",
        "especially benefits *model subclassing* and building *custom layers*—the APIs\n",
        "that require you to write the forward pass as code (instead of the APIs that\n",
        "create models by assembling existing layers).\n",
        "\n",
        "See the [eager execution guide](./eager.md#build_a_model) for\n",
        "examples of using Keras models with custom training loops and `tf.GradientTape`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2wG3NVco5B5V"
      },
      "source": [
        "## Distribution\n",
        "\n",
        "### Estimators\n",
        "\n",
        "The [Estimators](./estimators.md) API is used for training models\n",
        "for distributed environments. This targets industry use cases such as\n",
        "distributed training on large datasets that can export a model for production.\n",
        "\n",
        "A `tf.keras.Model` can be trained with the `tf.estimator` API by converting the\n",
        "model to an `tf.estimator.Estimator` object with\n",
        "`tf.keras.estimator.model_to_estimator`. See\n",
        "[Creating Estimators from Keras models](./estimators.md#creating_estimators_from_keras_models)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cVg0vfTO0E3E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "005f35be-d5b1-4968-b240-66feac986a8b"
      },
      "source": [
        "model = tf.keras.Sequential([layers.Dense(64, activation='relu', input_shape=(32,)),\n",
        "                          layers.Dense(10,activation='softmax')])\n",
        "\n",
        "model.compile(optimizer=tf.train.RMSPropOptimizer(0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "estimator = tf.keras.estimator.model_to_estimator(model)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpx4efgw36\n",
            "INFO:tensorflow:Using the Keras model provided.\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpx4efgw36', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f60d62766d8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "S7FKvikO0E3H"
      },
      "source": [
        "Note: Enable [eager execution](./eager.md) for debugging\n",
        "[Estimator input functions](./premade_estimators.md#create_input_functions)\n",
        "and inspecting data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6PJZ6e9J5JHF"
      },
      "source": [
        "### Multiple GPUs\n",
        "\n",
        "`tf.keras` models can run on multiple GPUs using\n",
        "`tf.contrib.distribute.DistributionStrategy`. This API provides distributed\n",
        "training on multiple GPUs with almost no changes to existing code.\n",
        "\n",
        "Currently, `tf.contrib.distribute.MirroredStrategy` is the only supported\n",
        "distribution strategy. `MirroredStrategy` does in-graph replication with\n",
        "synchronous training using all-reduce on a single machine. To use\n",
        "`DistributionStrategy` with Keras, convert the `tf.keras.Model` to a\n",
        "`tf.estimator.Estimator` with `tf.keras.estimator.model_to_estimator`, then\n",
        "train the estimator\n",
        "\n",
        "The following example distributes a `tf.keras.Model` across multiple GPUs on a\n",
        "single machine.\n",
        "\n",
        "First, define a simple model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sbaRr7g-0E3I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "910f034f-c2c9-4177-c67f-170e21791759"
      },
      "source": [
        "model = tf.keras.Sequential()\n",
        "model.add(layers.Dense(16, activation='relu', input_shape=(10,)))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "optimizer = tf.train.GradientDescentOptimizer(0.2)\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "model.summary()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_23 (Dense)             (None, 16)                176       \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 193\n",
            "Trainable params: 193\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yw4hSJme0E3L"
      },
      "source": [
        "Define an *input pipeline*. The `input_fn` returns a `tf.data.Dataset` object\n",
        "used to distribute the data across multiple devices—with each device processing\n",
        "a slice of the input batch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CxJW1QMH0E3L",
        "colab": {}
      },
      "source": [
        "def input_fn():\n",
        "  x = np.random.random((1024, 10))\n",
        "  y = np.random.randint(2, size=(1024, 1))\n",
        "  x = tf.cast(x, tf.float32)\n",
        "  dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
        "  dataset = dataset.repeat(10)\n",
        "  dataset = dataset.batch(32)\n",
        "  return dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rO9MiL6X0E3O"
      },
      "source": [
        "Next, create a `tf.estimator.RunConfig` and set the `train_distribute` argument\n",
        "to the `tf.contrib.distribute.MirroredStrategy` instance. When creating\n",
        "`MirroredStrategy`, you can specify a list of devices or set the `num_gpus`\n",
        "argument. The default uses all available GPUs, like the following:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BEwFq4PM0E3P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "88e7dfd8-9273-4883-bc41-1eaef3a18899"
      },
      "source": [
        "strategy = tf.contrib.distribute.MirroredStrategy()\n",
        "config = tf.estimator.RunConfig(train_distribute=strategy)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "INFO:tensorflow:Device is available but not used by distribute strategy: /device:CPU:0\n",
            "INFO:tensorflow:Device is available but not used by distribute strategy: /device:XLA_CPU:0\n",
            "INFO:tensorflow:Device is available but not used by distribute strategy: /device:XLA_GPU:0\n",
            "INFO:tensorflow:Configured nccl all-reduce.\n",
            "INFO:tensorflow:Initializing RunConfig with distribution strategies.\n",
            "INFO:tensorflow:Not using Distribute Coordinator.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TcnwYVun0E3R"
      },
      "source": [
        "Convert the Keras model to a `tf.estimator.Estimator` instance:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VSvbuIID0E3S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "cba488e2-a2d3-4ae6-98d6-f2b613357524"
      },
      "source": [
        "keras_estimator = tf.keras.estimator.model_to_estimator(\n",
        "  keras_model=model,\n",
        "  config=config,\n",
        "  model_dir='/tmp/model_dir')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using the Keras model provided.\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/model_dir', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': <tensorflow.contrib.distribute.python.mirrored_strategy.MirroredStrategy object at 0x7f60bf2aa7b8>, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f60bf2aa9b0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_distribute_coordinator_mode': None}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "N6BXU5F90E3U"
      },
      "source": [
        "Finally, train the `Estimator` instance by providing the `input_fn` and `steps`\n",
        "arguments:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XKoJ2wUH0E3U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2350
        },
        "outputId": "33ecf86c-2c47-48bb-a185-6b5c90c2425f"
      },
      "source": [
        "keras_estimator.train(input_fn=input_fn, steps=10)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:batch_all_reduce invoked for batches size = 4 with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from='/tmp/model_dir/keras/keras_model.ckpt', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})\n",
            "INFO:tensorflow:Warm-starting from: ('/tmp/model_dir/keras/keras_model.ckpt',)\n",
            "INFO:tensorflow:Warm-starting variable: dense_23/kernel; prev_var_name: Unchanged\n",
            "INFO:tensorflow:Warm-starting variable: dense_23/bias; prev_var_name: Unchanged\n",
            "INFO:tensorflow:Warm-starting variable: dense_24/kernel; prev_var_name: Unchanged\n",
            "INFO:tensorflow:Warm-starting variable: dense_24/bias; prev_var_name: Unchanged\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1316\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1317\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1351\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session_run_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1352\u001b[0;31m       \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExtendSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: No OpKernel was registered to support Op 'NcclAllReduce' used by {{node training/TFOptimizer/NcclAllReduce}}with these attrs: [num_devices=1, reduction=\"sum\", shared_name=\"c0\", T=DT_FLOAT]\nRegistered devices: [CPU, GPU, XLA_CPU, XLA_GPU]\nRegistered kernels:\n  <no registered kernels>\n\n\t [[{{node training/TFOptimizer/NcclAllReduce}}]]",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-843363108fab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mkeras_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1120\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_distribution\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model_distributed\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1183\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_distribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m       return self._actual_train_model_distributed(\n\u001b[0;32m-> 1185\u001b[0;31m           self._config._train_distribute, input_fn, hooks, saving_listeners)\n\u001b[0m\u001b[1;32m   1186\u001b[0m     \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_actual_train_model_distributed\u001b[0;34m(self, strategy, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1285\u001b[0m         return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n\u001b[1;32m   1286\u001b[0m                                                \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1287\u001b[0;31m                                                saving_listeners)\n\u001b[0m\u001b[1;32m   1288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1289\u001b[0m   def _train_with_estimator_spec(self, estimator_spec, worker_hooks, hooks,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_with_estimator_spec\u001b[0;34m(self, estimator_spec, worker_hooks, hooks, global_step_tensor, saving_listeners)\u001b[0m\n\u001b[1;32m   1401\u001b[0m         \u001b[0msave_summaries_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_summary_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1402\u001b[0m         \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1403\u001b[0;31m         log_step_count_steps=log_step_count_steps) as mon_sess:\n\u001b[0m\u001b[1;32m   1404\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1405\u001b[0m       \u001b[0many_step_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mMonitoredTrainingSession\u001b[0;34m(master, is_chief, checkpoint_dir, scaffold, hooks, chief_only_hooks, save_checkpoint_secs, save_summaries_steps, save_summaries_secs, config, stop_grace_period_secs, log_step_count_steps, max_wait_secs, save_checkpoint_steps, summary_dir)\u001b[0m\n\u001b[1;32m    506\u001b[0m       \u001b[0msession_creator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession_creator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m       \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_hooks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m       stop_grace_period_secs=stop_grace_period_secs)\n\u001b[0m\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, session_creator, hooks, stop_grace_period_secs)\u001b[0m\n\u001b[1;32m    932\u001b[0m     super(MonitoredSession, self).__init__(\n\u001b[1;32m    933\u001b[0m         \u001b[0msession_creator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshould_recover\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m         stop_grace_period_secs=stop_grace_period_secs)\n\u001b[0m\u001b[1;32m    935\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, session_creator, hooks, should_recover, stop_grace_period_secs)\u001b[0m\n\u001b[1;32m    646\u001b[0m         stop_grace_period_secs=stop_grace_period_secs)\n\u001b[1;32m    647\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshould_recover\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_RecoverableSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_coordinated_creator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_coordinated_creator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sess_creator)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \"\"\"\n\u001b[1;32m   1121\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess_creator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess_creator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m     \u001b[0m_WrappedSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_create_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36m_create_session\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1125\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1127\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess_creator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1128\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1129\u001b[0m         logging.info('An error was raised while a session was being created. '\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mcreate_session\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    803\u001b[0m       \u001b[0;34m\"\"\"Creates a coordinated session.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m       \u001b[0;31m# Keep the tf_sess for unit testing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 805\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_sess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session_creator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    806\u001b[0m       \u001b[0;31m# We don't want coordinator to suppress any exception.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoord\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoordinator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCoordinator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_stop_exception_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mcreate_session\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0minit_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scaffold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0minit_feed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scaffold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_feed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m         init_fn=self._scaffold.init_fn)\n\u001b[0m\u001b[1;32m    572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/session_manager.py\u001b[0m in \u001b[0;36mprepare_session\u001b[0;34m(self, master, init_op, saver, checkpoint_dir, checkpoint_filename_with_path, wait_for_checkpoint, max_wait_secs, config, init_feed_dict, init_fn)\u001b[0m\n\u001b[1;32m    285\u001b[0m                            \"init_fn or local_init_op was given\")\n\u001b[1;32m    286\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0minit_op\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit_feed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0minit_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0minit_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: No OpKernel was registered to support Op 'NcclAllReduce' used by node training/TFOptimizer/NcclAllReduce (defined at /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py:1254) with these attrs: [num_devices=1, reduction=\"sum\", shared_name=\"c0\", T=DT_FLOAT]\nRegistered devices: [CPU, GPU, XLA_CPU, XLA_GPU]\nRegistered kernels:\n  <no registered kernels>\n\n\t [[node training/TFOptimizer/NcclAllReduce (defined at /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py:1254) ]]\n\nCaused by op 'training/TFOptimizer/NcclAllReduce', defined at:\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2828, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-34-843363108fab>\", line 1, in <module>\n    keras_estimator.train(input_fn=input_fn, steps=10)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 358, in train\n    loss = self._train_model(input_fn, hooks, saving_listeners)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1122, in _train_model\n    return self._train_model_distributed(input_fn, hooks, saving_listeners)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1185, in _train_model_distributed\n    self._config._train_distribute, input_fn, hooks, saving_listeners)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1254, in _actual_train_model_distributed\n    self.config))\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py\", line 1199, in call_for_each_replica\n    return self._call_for_each_replica(fn, args, kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/mirrored_strategy.py\", line 641, in _call_for_each_replica\n    return _call_for_each_replica(self._container_strategy(), fn, args, kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/mirrored_strategy.py\", line 183, in _call_for_each_replica\n    **merge_kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/optimizer.py\", line 663, in _distributed_apply\n    ds_reduce_util.ReduceOp.SUM, grads_and_vars)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py\", line 1268, in batch_reduce_to\n    return self._batch_reduce_to(reduce_op, value_destination_pairs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/mirrored_strategy.py\", line 686, in _batch_reduce_to\n    value_destination_pairs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/cross_device_ops.py\", line 271, in batch_reduce\n    return self._batch_reduce(reduce_op, value_destination_pairs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/cross_device_ops.py\", line 626, in _batch_reduce\n    [v[0] for v in value_destination_pairs])\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/cross_device_ops.py\", line 660, in _batch_all_reduce\n    device_grad_packs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/cross_device_utils.py\", line 41, in aggregate_gradients_using_nccl\n    agg_grads = nccl_ops.all_sum(single_grads)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nccl_ops.py\", line 45, in all_sum\n    return _apply_all_reduce('sum', tensors)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nccl_ops.py\", line 224, in _apply_all_reduce\n    shared_name=shared_name))\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_nccl_ops.py\", line 84, in nccl_all_reduce\n    name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): No OpKernel was registered to support Op 'NcclAllReduce' used by node training/TFOptimizer/NcclAllReduce (defined at /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py:1254) with these attrs: [num_devices=1, reduction=\"sum\", shared_name=\"c0\", T=DT_FLOAT]\nRegistered devices: [CPU, GPU, XLA_CPU, XLA_GPU]\nRegistered kernels:\n  <no registered kernels>\n\n\t [[node training/TFOptimizer/NcclAllReduce (defined at /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py:1254) ]]\n"
          ]
        }
      ]
    }
  ]
}