{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2*\n",
    "\n",
    "# Sprint Challenge - Neural Network Foundations\n",
    "\n",
    "Table of Problems\n",
    "\n",
    "1. [Defining Neural Networks](#Q1)\n",
    "2. [Perceptron on XOR Gates](#Q2)\n",
    "3. [Multilayer Perceptron](#Q3)\n",
    "4. [Keras MMP](#Q4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Q1\"></a>\n",
    "## 1. Define the following terms:\n",
    "\n",
    "- **Neuron:**\n",
    "- **Input Layer:**\n",
    "- **Hidden Layer:**\n",
    "- **Output Layer:**\n",
    "- **Activation:**\n",
    "- **Backpropagation:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neuron: \n",
    "A neuron is the basic unit of a neural network. In Artificial Neural Networks the neurons or \"nodes\" receive inputs and pass on their signal to the next layer of nodes if a certain threshold is reached. What a neuron does is it takes each of the input values, multplies each of them by a weight, sums all of these products up, and then passes the sum through what is called an \"activation function\" the result of which is the final value.\n",
    "\n",
    "### Input Layer: \n",
    "The input layer of a neural network consists of units (or input neurons) that you assign a value to. It doesn’t apply any operations on the input signals(values) & has no weights and biases values associated.\n",
    "\n",
    "### Hidden Layer: \n",
    "Layers after the input layer are called Hidden Layers. This is because they cannot be accessed except through the input layer. They're inside of the network and they perform their functions, but we don't directly interact with them. The values from the input layer are passed to the neuron(s) of the hidden layer, which apply different transformations to the input data. These transformed values are then passed on to the output layer. All the neurons in a hidden layer are connected to each and every neuron in the next layer, hence we have fully connected hidden layers.\n",
    "\n",
    "### Output Layer: \n",
    "The final layer is called the Output Layer. The purpose of the output layer is to output a vector of values that is in a format that is suitable for the type of problem that we're trying to address. Typically the output value is modified by an \"activation function\" to transform it into a format that makes sense for its context.\n",
    "\n",
    "### Activation Function: \n",
    "In Neural Networks, each node has an activation function. Each node in a given layer typically has the same activation function. The activation function decides whether a cell \"fires\" or not (or, is 'activated' or not). n Artificial Neural Networks activation functions decide how much signal to pass onto the next layer. This is why they are sometimes referred to as transfer functions because they determine how much signal is transferred to the next layer. Activation functions are used to introduce non-linearity to neural networks. It squashes the values into a smaller range.\n",
    "\n",
    "### Backpropagation\n",
    "Backpropagation is a supervised learning technique for neural networks that calculates the gradient of descent for weighting different variables. It stands for backward propagation of errors, since the error is computed at the output and distributed backwards throughout the network’s layers. The weights of the neurons in the hidden layers are adjusted up or down, accordingly, to attempt to reduce loss on subsequent feed-forwards through the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Perceptron on NAND Gates <a id=\"Q3=2\"></a>\n",
    "\n",
    "Create a perceptron class that can model the behavior of an AND gate. You can use the following table as your training data:\n",
    "\n",
    "|x1\t|x2|x3|\ty|\n",
    "|---|---|---|---|\n",
    "1|\t1|\t1|\t1|\n",
    "1|\t0|\t1|\t0|\n",
    "0|\t1|\t1|\t0|\n",
    "0|\t0|\t1|\t0|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4, 3), (4,))"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "X = np.array([[1,1,1], [1,0,1], [0,1,1], [0,0,1]])\n",
    "y = np.array([1,0,0,0])#.reshape(-1,1)\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "class Perceptron(object):\n",
    "    def __init__(self, l_rate, epochs):\n",
    "        self.l_rate = l_rate\n",
    "        self.epochs = epochs\n",
    "\n",
    "    def train_weights(self, X, y):\n",
    "        #initialize weights and bias w/ value = 0\n",
    "        weights = [0.0 for i in range(len(X[0]))]\n",
    "        bias = 0.0\n",
    "    \n",
    "        #initialize min_error as inifinite\n",
    "        min_error = float(\"inf\")\n",
    "        #iterate n_epoch times:\n",
    "        for epoch in range(self.epochs):\n",
    "            #initialize sum squared error for this iteration as 0\n",
    "            sum_error = 0.0\n",
    "        \n",
    "            #iterate thru each row in X_train\n",
    "            for i in range(len(X)):\n",
    "                row = X[i]\n",
    "            \n",
    "                #call the predict function to get the predicted outcome for each row\n",
    "                prediction = self.predict(row, weights, bias)\n",
    "            \n",
    "                #calc the error\n",
    "                error = y[i] - prediction\n",
    "            \n",
    "                #update the sum squared error for this iteration w/ current weights and bias\n",
    "                sum_error += error**2\n",
    "            \n",
    "                #update the bias\n",
    "                bias += self.l_rate * error\n",
    "                #iterate thru each feature and update the corresponding weight:\n",
    "                for j in range(len(row)):\n",
    "                    weights[j] += self.l_rate * error * row[j]\n",
    "            #if the sum squared error is less than prev minimum, store the weights, bias, and min_error in        \n",
    "            if sum_error < min_error:\n",
    "                min_error = sum_error\n",
    "                best = [weights, bias]#, min_error]\n",
    "                best_epoch = epoch\n",
    "        return best\n",
    "\n",
    "    def predict(self, row, weights, bias):\n",
    "        activation = bias\n",
    "        for i in range(len(row)):\n",
    "            activation += weights[i] * row[i]\n",
    "        return 1.0 if activation >= 0.0 else 0.0\n",
    "    \n",
    "    def get_predictions(self, X, y):\n",
    "        best = self.train_weights(X, y)\n",
    "        weights, bias = best[0], best[1]\n",
    "        y_pred = []\n",
    "        for i in range(len(X)):\n",
    "            y_pred.append(int(self.predict(X[i], weights, bias)))\n",
    "        return np.array(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "#intstantiate the perceptron\n",
    "p = Perceptron(l_rate=0.1, epochs=6)\n",
    "\n",
    "#get predictions from just 6 epochs\n",
    "y_pred = p.get_predictions(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify accuracy of predictions:\n",
    "y == y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Multilayer Perceptron <a id=\"Q3\"></a>\n",
    "\n",
    "Implement a Neural Network Multilayer Perceptron class that uses backpropagation to update the network's weights.\n",
    "Your network must have one hidden layer.\n",
    "You do not have to update weights via gradient descent. You can use something like the derivative of the sigmoid function to update weights.\n",
    "Train your model on the Heart Disease dataset from UCI:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork: \n",
    "    def __init__(self, inputs, hiddenNodes, outputNodes):\n",
    "        # Set upArchietecture \n",
    "        self.inputs = inputs\n",
    "        self.hiddenNodes = hiddenNodes\n",
    "        self.outputNodes = outputNodes\n",
    "        \n",
    "        #Initial weights\n",
    "        self.weights1 = np.random.randn(self.inputs, self.hiddenNodes) \n",
    "        self.weights2 = np.random.rand(self.hiddenNodes, self.outputNodes) \n",
    "    \n",
    "    def sigmoid(self, s):\n",
    "        return 1 / (1+np.exp(-s))\n",
    "    \n",
    "    def sigmoidPrime(self, s):\n",
    "        #derivative of the sigmoid\n",
    "        return s * (1 - s)\n",
    "    \n",
    "    def feed_forward(self, X):\n",
    "        \"\"\"\n",
    "        Calculate the NN inference using feed forward.\n",
    "        \"\"\"\n",
    "        \n",
    "        #Weighted sume of inputs and hidden layer\n",
    "        self.hidden_sum = np.dot(X, self.weights1)\n",
    "        \n",
    "        #Acivations of weighted sum\n",
    "        self.activated_hidden = self.sigmoid(self.hidden_sum)\n",
    "        \n",
    "        # Weight sum between hidden and output\n",
    "        self.output_sum = np.dot(self.activated_hidden, self.weights2)\n",
    "        \n",
    "        #Final activation of output\n",
    "        self.activated_output = self.sigmoid(self.output_sum)\n",
    "        return self.activated_output\n",
    "    \n",
    "    def backward(self, X, y, o):\n",
    "        \"\"\"\n",
    "        Backward propagate through the network\n",
    "        \"\"\"\n",
    "        self.o_error = y - o #error in output\n",
    "        self.o_delta = self.o_error * self.sigmoidPrime(o) # apply derivative of sigmoid to error\n",
    "        \n",
    "        self.z2_error = self.o_delta.dot(self.weights2.T) # z2 error: how much our hidden layer weights were off\n",
    "        self.z2_delta = self.z2_error*self.sigmoidPrime(self.activated_hidden)\n",
    "        \n",
    "        self.weights1 += X.T.dot(self.z2_delta) #Adjust first set (input => hidden) weights\n",
    "        self.weights2 += self.activated_hidden.T.dot(self.o_delta) #adjust second set (hidden => output) weights\n",
    "        \n",
    "    def train(self, X, y):\n",
    "        o = self.feed_forward(X)\n",
    "        self.backward(X, y, o)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        output = self.feed_forward(X)\n",
    "        pred = []\n",
    "        for o in output:\n",
    "            pred.append([1]) if o >= 0.5 else pred.append([0])\n",
    "        return np.array(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "url = 'https://raw.githubusercontent.com/ryanleeallred/datasets/master/heart.csv'\n",
    "df = pd.read_csv(url)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((242, 13), (61, 13), (242, 1), (61, 1))"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop('target', axis=1).values.astype('float32')\n",
    "y = df['target'].values.reshape(-1,1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize the X matrix\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate the neural network\n",
    "nn = NeuralNetwork(inputs=13, hiddenNodes=7, outputNodes=1)\n",
    "\n",
    "#train the nn:\n",
    "epochs = 1000\n",
    "for i in range(epochs):\n",
    "    nn.train(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 83.607\n",
      "Precision: 89.286\n",
      "Recall: 78.125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8360655737704918, 0.8928571428571429, 0.78125)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "def get_accuracy(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    print('Accuracy: ' + str(round(accuracy*100, 3)))\n",
    "    print('Precision: ' + str(round(precision*100, 3)))\n",
    "    print('Recall: ' + str(round(recall*100, 3)))\n",
    "    return accuracy, precision, recall\n",
    "\n",
    "#generate predictions from the trained nn w/ X_test:\n",
    "y_pred = nn.predict(X_test)\n",
    "\n",
    "get_accuracy(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Keras MMP <a id=\"Q4\"></a>\n",
    "\n",
    "Implement a Multilayer Perceptron architecture of your choosing using the Keras library. Train your model and report its baseline accuracy. Then hyperparameter tune at least two parameters and report your model's accuracy.\n",
    "Use the Heart Disease Dataset (binary classification)\n",
    "Use an appropriate loss function for a binary classification task\n",
    "Use an appropriate activation function on the final layer of your network.\n",
    "Train your model using verbose output for ease of grading.\n",
    "Use GridSearchCV to hyperparameter tune your model. (for at least two hyperparameters)\n",
    "When hyperparameter tuning, show you work by adding code cells for each new experiment.\n",
    "Report the accuracy for each combination of hyperparameters as you test them so that we can easily see which resulted in the highest accuracy.\n",
    "You must hyperparameter tune at least 5 parameters in order to get a 3 on this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((303, 13), (303,))"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://raw.githubusercontent.com/ryanleeallred/datasets/master/heart.csv'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "X = df.drop('target', axis=1).values.astype('float32')\n",
    "y = df['target'].values#.reshape(-1,1)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_91 (Dense)             (None, 6)                 84        \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 3)                 21        \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 109\n",
      "Trainable params: 109\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#instantiate model\n",
    "model = Sequential()\n",
    "\n",
    "#hidden layers\n",
    "model.add(Dense(6, input_shape=(13,), activation=\"relu\"))\n",
    "model.add(Dense(3, activation='relu'))\n",
    "\n",
    "#output layer\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "#compile the model            \n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#inspect the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 78.261\n",
      "Precision: 82.143\n",
      "Recall: 82.143\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=99)\n",
    "\n",
    "model.fit(X_train, y_train, epochs=25, verbose=0)\n",
    "\n",
    "y_pred_proba = model.predict(X_test)\n",
    "\n",
    "y_pred = []\n",
    "for pred in y_pred_proba:\n",
    "    y_pred.append([1]) if pred[0] >= 0.5 else y_pred.append([0])\n",
    "y_pred = np.array(y_pred)\n",
    "    \n",
    "baseline_accuracy = get_accuracy(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hidden Layer Neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(layer1=10, layer2=8):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(layer1, input_shape=(13,), kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(layer2, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, verbose=1)\n",
    "\n",
    "# define the grid search parameters\n",
    "layer1 = [3, 6, 9, 12]\n",
    "layer2 = [2, 5, 8, 11]\n",
    "param_grid = dict(layer1=layer1, layer2=layer2)\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=2, verbose=1)\n",
    "grid_result = grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_layer1</th>\n",
       "      <th>param_layer2</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.936603</td>\n",
       "      <td>0.033025</td>\n",
       "      <td>0.097828</td>\n",
       "      <td>0.015922</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>{'layer1': 12, 'layer2': 11}</td>\n",
       "      <td>0.623762</td>\n",
       "      <td>0.851485</td>\n",
       "      <td>0.534653</td>\n",
       "      <td>0.669967</td>\n",
       "      <td>0.133408</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4.866275</td>\n",
       "      <td>0.156392</td>\n",
       "      <td>0.648530</td>\n",
       "      <td>0.037524</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>{'layer1': 9, 'layer2': 8}</td>\n",
       "      <td>0.613861</td>\n",
       "      <td>0.792079</td>\n",
       "      <td>0.544554</td>\n",
       "      <td>0.650165</td>\n",
       "      <td>0.104261</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5.574532</td>\n",
       "      <td>0.201089</td>\n",
       "      <td>0.745319</td>\n",
       "      <td>0.041466</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>{'layer1': 9, 'layer2': 11}</td>\n",
       "      <td>0.603960</td>\n",
       "      <td>0.782178</td>\n",
       "      <td>0.564356</td>\n",
       "      <td>0.650165</td>\n",
       "      <td>0.094737</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5.355411</td>\n",
       "      <td>0.307748</td>\n",
       "      <td>0.769404</td>\n",
       "      <td>0.052476</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>{'layer1': 12, 'layer2': 2}</td>\n",
       "      <td>0.564356</td>\n",
       "      <td>0.772277</td>\n",
       "      <td>0.594059</td>\n",
       "      <td>0.643564</td>\n",
       "      <td>0.091818</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4.527716</td>\n",
       "      <td>1.086518</td>\n",
       "      <td>0.596112</td>\n",
       "      <td>0.370829</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>{'layer1': 12, 'layer2': 8}</td>\n",
       "      <td>0.564356</td>\n",
       "      <td>0.792079</td>\n",
       "      <td>0.544554</td>\n",
       "      <td>0.633663</td>\n",
       "      <td>0.112308</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_layer1  \\\n",
       "15       2.936603      0.033025         0.097828        0.015922           12   \n",
       "10       4.866275      0.156392         0.648530        0.037524            9   \n",
       "11       5.574532      0.201089         0.745319        0.041466            9   \n",
       "12       5.355411      0.307748         0.769404        0.052476           12   \n",
       "14       4.527716      1.086518         0.596112        0.370829           12   \n",
       "\n",
       "   param_layer2                        params  split0_test_score  \\\n",
       "15           11  {'layer1': 12, 'layer2': 11}           0.623762   \n",
       "10            8    {'layer1': 9, 'layer2': 8}           0.613861   \n",
       "11           11   {'layer1': 9, 'layer2': 11}           0.603960   \n",
       "12            2   {'layer1': 12, 'layer2': 2}           0.564356   \n",
       "14            8   {'layer1': 12, 'layer2': 8}           0.564356   \n",
       "\n",
       "    split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "15           0.851485           0.534653         0.669967        0.133408   \n",
       "10           0.792079           0.544554         0.650165        0.104261   \n",
       "11           0.782178           0.564356         0.650165        0.094737   \n",
       "12           0.772277           0.594059         0.643564        0.091818   \n",
       "14           0.792079           0.544554         0.633663        0.112308   \n",
       "\n",
       "    rank_test_score  \n",
       "15                1  \n",
       "10                2  \n",
       "11                2  \n",
       "12                4  \n",
       "14                5  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_result.cv_results_).sort_values(by='rank_test_score').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best accuracy score using 12 neurons for layer 1 and 11 neurons for layer 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1 = 12\n",
    "layer2 = 11\n",
    "\n",
    "def create_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(layer1, input_shape=(13,), kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(layer2, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, verbose=1)\n",
    "\n",
    "# define the grid search parameters\n",
    "batch_size = [8, 16, 32, 64, 128]\n",
    "param_grid = dict(batch_size=batch_size)\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=2, verbose=1)\n",
    "grid_result = grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_batch_size</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.781235</td>\n",
       "      <td>0.344072</td>\n",
       "      <td>0.163487</td>\n",
       "      <td>0.018386</td>\n",
       "      <td>16</td>\n",
       "      <td>{'batch_size': 16}</td>\n",
       "      <td>0.623762</td>\n",
       "      <td>0.831683</td>\n",
       "      <td>0.544554</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.121082</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.703731</td>\n",
       "      <td>0.339733</td>\n",
       "      <td>0.104259</td>\n",
       "      <td>0.025207</td>\n",
       "      <td>8</td>\n",
       "      <td>{'batch_size': 8}</td>\n",
       "      <td>0.633663</td>\n",
       "      <td>0.762376</td>\n",
       "      <td>0.534653</td>\n",
       "      <td>0.643564</td>\n",
       "      <td>0.093231</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.748890</td>\n",
       "      <td>0.105292</td>\n",
       "      <td>0.199400</td>\n",
       "      <td>0.018264</td>\n",
       "      <td>32</td>\n",
       "      <td>{'batch_size': 32}</td>\n",
       "      <td>0.584158</td>\n",
       "      <td>0.811881</td>\n",
       "      <td>0.504950</td>\n",
       "      <td>0.633663</td>\n",
       "      <td>0.130102</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.247298</td>\n",
       "      <td>0.158231</td>\n",
       "      <td>0.232438</td>\n",
       "      <td>0.013560</td>\n",
       "      <td>64</td>\n",
       "      <td>{'batch_size': 64}</td>\n",
       "      <td>0.524752</td>\n",
       "      <td>0.792079</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.438944</td>\n",
       "      <td>0.329008</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.788707</td>\n",
       "      <td>0.134544</td>\n",
       "      <td>0.322337</td>\n",
       "      <td>0.051650</td>\n",
       "      <td>128</td>\n",
       "      <td>{'batch_size': 128}</td>\n",
       "      <td>0.326733</td>\n",
       "      <td>0.772277</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.366337</td>\n",
       "      <td>0.316522</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "1       4.781235      0.344072         0.163487        0.018386   \n",
       "0       7.703731      0.339733         0.104259        0.025207   \n",
       "2       3.748890      0.105292         0.199400        0.018264   \n",
       "3       3.247298      0.158231         0.232438        0.013560   \n",
       "4       2.788707      0.134544         0.322337        0.051650   \n",
       "\n",
       "  param_batch_size               params  split0_test_score  split1_test_score  \\\n",
       "1               16   {'batch_size': 16}           0.623762           0.831683   \n",
       "0                8    {'batch_size': 8}           0.633663           0.762376   \n",
       "2               32   {'batch_size': 32}           0.584158           0.811881   \n",
       "3               64   {'batch_size': 64}           0.524752           0.792079   \n",
       "4              128  {'batch_size': 128}           0.326733           0.772277   \n",
       "\n",
       "   split2_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "1           0.544554         0.666667        0.121082                1  \n",
       "0           0.534653         0.643564        0.093231                2  \n",
       "2           0.504950         0.633663        0.130102                3  \n",
       "3           0.000000         0.438944        0.329008                4  \n",
       "4           0.000000         0.366337        0.316522                5  "
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_result.cv_results_).sort_values(by='rank_test_score').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch Size of 16 is the winner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "def create_model(init_mode='uniform'):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(layer1, input_shape=(13,), kernel_initializer=init_mode, activation='relu'))\n",
    "    model.add(Dense(layer2, kernel_initializer=init_mode, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer=init_mode, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, batch_size=batch_size, epochs=100, verbose=1)\n",
    "\n",
    "# define the grid search parameters\n",
    "init_mode = ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', \n",
    "             'he_normal', 'he_uniform']\n",
    "\n",
    "param_grid = dict(init_mode=init_mode)\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=2, verbose=1)\n",
    "grid_result = grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_init_mode</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.262644</td>\n",
       "      <td>0.099856</td>\n",
       "      <td>0.365401</td>\n",
       "      <td>0.025851</td>\n",
       "      <td>glorot_normal</td>\n",
       "      <td>{'init_mode': 'glorot_normal'}</td>\n",
       "      <td>0.722772</td>\n",
       "      <td>0.792079</td>\n",
       "      <td>0.554455</td>\n",
       "      <td>0.689769</td>\n",
       "      <td>0.099777</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.694395</td>\n",
       "      <td>0.184594</td>\n",
       "      <td>0.504761</td>\n",
       "      <td>0.035258</td>\n",
       "      <td>he_normal</td>\n",
       "      <td>{'init_mode': 'he_normal'}</td>\n",
       "      <td>0.693069</td>\n",
       "      <td>0.792079</td>\n",
       "      <td>0.564356</td>\n",
       "      <td>0.683168</td>\n",
       "      <td>0.093231</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.873749</td>\n",
       "      <td>0.138017</td>\n",
       "      <td>0.201604</td>\n",
       "      <td>0.020263</td>\n",
       "      <td>normal</td>\n",
       "      <td>{'init_mode': 'normal'}</td>\n",
       "      <td>0.653465</td>\n",
       "      <td>0.831683</td>\n",
       "      <td>0.564356</td>\n",
       "      <td>0.683168</td>\n",
       "      <td>0.111138</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.552819</td>\n",
       "      <td>0.045352</td>\n",
       "      <td>0.133764</td>\n",
       "      <td>0.023464</td>\n",
       "      <td>lecun_uniform</td>\n",
       "      <td>{'init_mode': 'lecun_uniform'}</td>\n",
       "      <td>0.623762</td>\n",
       "      <td>0.841584</td>\n",
       "      <td>0.574257</td>\n",
       "      <td>0.679868</td>\n",
       "      <td>0.116123</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.838858</td>\n",
       "      <td>0.249449</td>\n",
       "      <td>0.376984</td>\n",
       "      <td>0.051642</td>\n",
       "      <td>glorot_uniform</td>\n",
       "      <td>{'init_mode': 'glorot_uniform'}</td>\n",
       "      <td>0.653465</td>\n",
       "      <td>0.752475</td>\n",
       "      <td>0.613861</td>\n",
       "      <td>0.673267</td>\n",
       "      <td>0.058295</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "4       5.262644      0.099856         0.365401        0.025851   \n",
       "6       5.694395      0.184594         0.504761        0.035258   \n",
       "2       4.873749      0.138017         0.201604        0.020263   \n",
       "1       4.552819      0.045352         0.133764        0.023464   \n",
       "5       5.838858      0.249449         0.376984        0.051642   \n",
       "\n",
       "  param_init_mode                           params  split0_test_score  \\\n",
       "4   glorot_normal   {'init_mode': 'glorot_normal'}           0.722772   \n",
       "6       he_normal       {'init_mode': 'he_normal'}           0.693069   \n",
       "2          normal          {'init_mode': 'normal'}           0.653465   \n",
       "1   lecun_uniform   {'init_mode': 'lecun_uniform'}           0.623762   \n",
       "5  glorot_uniform  {'init_mode': 'glorot_uniform'}           0.653465   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "4           0.792079           0.554455         0.689769        0.099777   \n",
       "6           0.792079           0.564356         0.683168        0.093231   \n",
       "2           0.831683           0.564356         0.683168        0.111138   \n",
       "1           0.841584           0.574257         0.679868        0.116123   \n",
       "5           0.752475           0.613861         0.673267        0.058295   \n",
       "\n",
       "   rank_test_score  \n",
       "4                1  \n",
       "6                2  \n",
       "2                3  \n",
       "1                4  \n",
       "5                5  "
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_result.cv_results_).sort_values(by='rank_test_score').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Glorot_normal is the winner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_mode = 'glorot_normal'\n",
    "\n",
    "def create_model(activation='relu'):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(layer1, input_shape=(13,), kernel_initializer=init_mode, activation=activation))\n",
    "    model.add(Dense(layer2, kernel_initializer=init_mode, activation=activation))\n",
    "    model.add(Dense(1, kernel_initializer=init_mode, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, batch_size=batch_size, epochs=100, verbose=1)\n",
    "\n",
    "# define the grid search parameters\n",
    "activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n",
    "\n",
    "param_grid = dict(activation=activation)\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=2, verbose=1)\n",
    "grid_result = grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_activation</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.655740</td>\n",
       "      <td>0.233078</td>\n",
       "      <td>0.219190</td>\n",
       "      <td>0.018438</td>\n",
       "      <td>softsign</td>\n",
       "      <td>{'activation': 'softsign'}</td>\n",
       "      <td>0.653465</td>\n",
       "      <td>0.841584</td>\n",
       "      <td>0.574257</td>\n",
       "      <td>0.689769</td>\n",
       "      <td>0.112114</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.428058</td>\n",
       "      <td>0.017549</td>\n",
       "      <td>0.343883</td>\n",
       "      <td>0.018000</td>\n",
       "      <td>tanh</td>\n",
       "      <td>{'activation': 'tanh'}</td>\n",
       "      <td>0.643564</td>\n",
       "      <td>0.782178</td>\n",
       "      <td>0.594059</td>\n",
       "      <td>0.673267</td>\n",
       "      <td>0.079619</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.178172</td>\n",
       "      <td>0.034478</td>\n",
       "      <td>0.613458</td>\n",
       "      <td>0.025152</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'activation': 'linear'}</td>\n",
       "      <td>0.633663</td>\n",
       "      <td>0.811881</td>\n",
       "      <td>0.574257</td>\n",
       "      <td>0.673267</td>\n",
       "      <td>0.100971</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.090239</td>\n",
       "      <td>0.010475</td>\n",
       "      <td>0.143422</td>\n",
       "      <td>0.016271</td>\n",
       "      <td>softplus</td>\n",
       "      <td>{'activation': 'softplus'}</td>\n",
       "      <td>0.603960</td>\n",
       "      <td>0.831683</td>\n",
       "      <td>0.544554</td>\n",
       "      <td>0.660066</td>\n",
       "      <td>0.123751</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.323265</td>\n",
       "      <td>0.475546</td>\n",
       "      <td>0.242803</td>\n",
       "      <td>0.015668</td>\n",
       "      <td>relu</td>\n",
       "      <td>{'activation': 'relu'}</td>\n",
       "      <td>0.603960</td>\n",
       "      <td>0.811881</td>\n",
       "      <td>0.524752</td>\n",
       "      <td>0.646865</td>\n",
       "      <td>0.121082</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "2       5.655740      0.233078         0.219190        0.018438   \n",
       "4       5.428058      0.017549         0.343883        0.018000   \n",
       "7       7.178172      0.034478         0.613458        0.025152   \n",
       "1       5.090239      0.010475         0.143422        0.016271   \n",
       "3       5.323265      0.475546         0.242803        0.015668   \n",
       "\n",
       "  param_activation                      params  split0_test_score  \\\n",
       "2         softsign  {'activation': 'softsign'}           0.653465   \n",
       "4             tanh      {'activation': 'tanh'}           0.643564   \n",
       "7           linear    {'activation': 'linear'}           0.633663   \n",
       "1         softplus  {'activation': 'softplus'}           0.603960   \n",
       "3             relu      {'activation': 'relu'}           0.603960   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "2           0.841584           0.574257         0.689769        0.112114   \n",
       "4           0.782178           0.594059         0.673267        0.079619   \n",
       "7           0.811881           0.574257         0.673267        0.100971   \n",
       "1           0.831683           0.544554         0.660066        0.123751   \n",
       "3           0.811881           0.524752         0.646865        0.121082   \n",
       "\n",
       "   rank_test_score  \n",
       "2                1  \n",
       "4                2  \n",
       "7                2  \n",
       "1                4  \n",
       "3                5  "
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_result.cv_results_).sort_values(by='rank_test_score').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Softsign is the winner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = 'softsign'\n",
    "\n",
    "def create_model(optimizer='adam'):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(layer1, input_shape=(13,), kernel_initializer=init_mode, activation=activation))\n",
    "    model.add(Dense(layer2, kernel_initializer=init_mode, activation=activation))\n",
    "    model.add(Dense(1, kernel_initializer=init_mode, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, batch_size=batch_size, epochs=100, verbose=1)\n",
    "\n",
    "# define the grid search parameters\n",
    "optimizer = optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "param_grid = dict(optimizer=optimizer)\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=2, verbose=1)\n",
    "grid_result = grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_optimizer</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.724592</td>\n",
       "      <td>0.164289</td>\n",
       "      <td>0.144771</td>\n",
       "      <td>0.038771</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>{'optimizer': 'RMSprop'}</td>\n",
       "      <td>0.673267</td>\n",
       "      <td>0.841584</td>\n",
       "      <td>0.584158</td>\n",
       "      <td>0.699670</td>\n",
       "      <td>0.106739</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.638242</td>\n",
       "      <td>0.660434</td>\n",
       "      <td>0.412358</td>\n",
       "      <td>0.024616</td>\n",
       "      <td>Nadam</td>\n",
       "      <td>{'optimizer': 'Nadam'}</td>\n",
       "      <td>0.683168</td>\n",
       "      <td>0.811881</td>\n",
       "      <td>0.584158</td>\n",
       "      <td>0.693069</td>\n",
       "      <td>0.093231</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.494347</td>\n",
       "      <td>0.322629</td>\n",
       "      <td>0.296397</td>\n",
       "      <td>0.062389</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>{'optimizer': 'Adadelta'}</td>\n",
       "      <td>0.702970</td>\n",
       "      <td>0.801980</td>\n",
       "      <td>0.564356</td>\n",
       "      <td>0.689769</td>\n",
       "      <td>0.097458</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.273129</td>\n",
       "      <td>0.180235</td>\n",
       "      <td>0.231829</td>\n",
       "      <td>0.010873</td>\n",
       "      <td>Adagrad</td>\n",
       "      <td>{'optimizer': 'Adagrad'}</td>\n",
       "      <td>0.653465</td>\n",
       "      <td>0.831683</td>\n",
       "      <td>0.574257</td>\n",
       "      <td>0.686469</td>\n",
       "      <td>0.107654</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.863513</td>\n",
       "      <td>0.391960</td>\n",
       "      <td>0.373640</td>\n",
       "      <td>0.072089</td>\n",
       "      <td>Adam</td>\n",
       "      <td>{'optimizer': 'Adam'}</td>\n",
       "      <td>0.683168</td>\n",
       "      <td>0.782178</td>\n",
       "      <td>0.584158</td>\n",
       "      <td>0.683168</td>\n",
       "      <td>0.080841</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "1       4.724592      0.164289         0.144771        0.038771   \n",
       "6       6.638242      0.660434         0.412358        0.024616   \n",
       "3       6.494347      0.322629         0.296397        0.062389   \n",
       "2       5.273129      0.180235         0.231829        0.010873   \n",
       "4       7.863513      0.391960         0.373640        0.072089   \n",
       "\n",
       "  param_optimizer                     params  split0_test_score  \\\n",
       "1         RMSprop   {'optimizer': 'RMSprop'}           0.673267   \n",
       "6           Nadam     {'optimizer': 'Nadam'}           0.683168   \n",
       "3        Adadelta  {'optimizer': 'Adadelta'}           0.702970   \n",
       "2         Adagrad   {'optimizer': 'Adagrad'}           0.653465   \n",
       "4            Adam      {'optimizer': 'Adam'}           0.683168   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "1           0.841584           0.584158         0.699670        0.106739   \n",
       "6           0.811881           0.584158         0.693069        0.093231   \n",
       "3           0.801980           0.564356         0.689769        0.097458   \n",
       "2           0.831683           0.574257         0.686469        0.107654   \n",
       "4           0.782178           0.584158         0.683168        0.080841   \n",
       "\n",
       "   rank_test_score  \n",
       "1                1  \n",
       "6                2  \n",
       "3                3  \n",
       "2                4  \n",
       "4                5  "
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_result.cv_results_).sort_values(by='rank_test_score').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSprop is the winner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout regularization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.constraints import maxnorm\n",
    "\n",
    "optimizer = 'RMSprop'\n",
    "\n",
    "def create_model(dropout_rate=0.0, weight_constraint=0):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(layer1, input_shape=(13,), kernel_initializer=init_mode, activation=activation, \n",
    "                    kernel_constraint=maxnorm(weight_constraint)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(layer2, kernel_initializer=init_mode, activation=activation, \n",
    "                    kernel_constraint=maxnorm(weight_constraint)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, kernel_initializer=init_mode, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, batch_size=batch_size, epochs=100, verbose=1)\n",
    "\n",
    "# define the grid search parameters\n",
    "weight_constraint = [1, 2, 3]\n",
    "dropout_rate = [0.0, 0.1, 0.2, 0.3]\n",
    "param_grid = dict(dropout_rate=dropout_rate, weight_constraint=weight_constraint)\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=2, verbose=1)\n",
    "grid_result = grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_dropout_rate</th>\n",
       "      <th>param_weight_constraint</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.807321</td>\n",
       "      <td>0.337038</td>\n",
       "      <td>0.662258</td>\n",
       "      <td>0.027473</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>{'dropout_rate': 0.0, 'weight_constraint': 3}</td>\n",
       "      <td>0.673267</td>\n",
       "      <td>0.821782</td>\n",
       "      <td>0.584158</td>\n",
       "      <td>0.693069</td>\n",
       "      <td>0.098015</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.772218</td>\n",
       "      <td>0.398087</td>\n",
       "      <td>0.535562</td>\n",
       "      <td>0.043048</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>{'dropout_rate': 0.0, 'weight_constraint': 2}</td>\n",
       "      <td>0.693069</td>\n",
       "      <td>0.801980</td>\n",
       "      <td>0.564356</td>\n",
       "      <td>0.686469</td>\n",
       "      <td>0.097122</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6.558165</td>\n",
       "      <td>0.403338</td>\n",
       "      <td>0.307074</td>\n",
       "      <td>0.031322</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "      <td>{'dropout_rate': 0.3, 'weight_constraint': 2}</td>\n",
       "      <td>0.702970</td>\n",
       "      <td>0.811881</td>\n",
       "      <td>0.524752</td>\n",
       "      <td>0.679868</td>\n",
       "      <td>0.118353</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.566388</td>\n",
       "      <td>1.258503</td>\n",
       "      <td>0.792292</td>\n",
       "      <td>0.491068</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>{'dropout_rate': 0.2, 'weight_constraint': 2}</td>\n",
       "      <td>0.693069</td>\n",
       "      <td>0.811881</td>\n",
       "      <td>0.524752</td>\n",
       "      <td>0.676568</td>\n",
       "      <td>0.117799</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.099014</td>\n",
       "      <td>0.262785</td>\n",
       "      <td>0.765559</td>\n",
       "      <td>0.062480</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>{'dropout_rate': 0.1, 'weight_constraint': 2}</td>\n",
       "      <td>0.663366</td>\n",
       "      <td>0.801980</td>\n",
       "      <td>0.554455</td>\n",
       "      <td>0.673267</td>\n",
       "      <td>0.101294</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "2        6.807321      0.337038         0.662258        0.027473   \n",
       "1        6.772218      0.398087         0.535562        0.043048   \n",
       "10       6.558165      0.403338         0.307074        0.031322   \n",
       "7        7.566388      1.258503         0.792292        0.491068   \n",
       "4        8.099014      0.262785         0.765559        0.062480   \n",
       "\n",
       "   param_dropout_rate param_weight_constraint  \\\n",
       "2                   0                       3   \n",
       "1                   0                       2   \n",
       "10                0.3                       2   \n",
       "7                 0.2                       2   \n",
       "4                 0.1                       2   \n",
       "\n",
       "                                           params  split0_test_score  \\\n",
       "2   {'dropout_rate': 0.0, 'weight_constraint': 3}           0.673267   \n",
       "1   {'dropout_rate': 0.0, 'weight_constraint': 2}           0.693069   \n",
       "10  {'dropout_rate': 0.3, 'weight_constraint': 2}           0.702970   \n",
       "7   {'dropout_rate': 0.2, 'weight_constraint': 2}           0.693069   \n",
       "4   {'dropout_rate': 0.1, 'weight_constraint': 2}           0.663366   \n",
       "\n",
       "    split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "2            0.821782           0.584158         0.693069        0.098015   \n",
       "1            0.801980           0.564356         0.686469        0.097122   \n",
       "10           0.811881           0.524752         0.679868        0.118353   \n",
       "7            0.811881           0.524752         0.676568        0.117799   \n",
       "4            0.801980           0.554455         0.673267        0.101294   \n",
       "\n",
       "    rank_test_score  \n",
       "2                 1  \n",
       "1                 2  \n",
       "10                3  \n",
       "7                 4  \n",
       "4                 5  "
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_result.cv_results_).sort_values(by='rank_test_score').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dropout= 0, weight_constraint = 3 is the winner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Epochs and Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import RMSprop\n",
    "\n",
    "dropout_rate = 0.0\n",
    "weight_constraint = 3\n",
    "\n",
    "def create_model(lr=0.01):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(layer1, input_shape=(13,), kernel_initializer=init_mode, activation=activation, \n",
    "                    kernel_constraint=maxnorm(weight_constraint)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(layer2, kernel_initializer=init_mode, activation=activation, \n",
    "                    kernel_constraint=maxnorm(weight_constraint)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, kernel_initializer=init_mode, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    optimizer = RMSprop(lr=lr)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, batch_size=batch_size, epochs=epochs, verbose=1)\n",
    "\n",
    "# define the grid search parameters\n",
    "epochs = [75, 200]\n",
    "lr = [0.001, 0.01, 0.1, 0.5]\n",
    "param_grid = dict(epochs=epochs, lr=lr)\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=2, verbose=1)\n",
    "grid_result = grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_epochs</th>\n",
       "      <th>param_lr</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.809377</td>\n",
       "      <td>0.067526</td>\n",
       "      <td>0.308544</td>\n",
       "      <td>0.034504</td>\n",
       "      <td>200</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'epochs': 200, 'lr': 0.001}</td>\n",
       "      <td>0.693069</td>\n",
       "      <td>0.801980</td>\n",
       "      <td>0.574257</td>\n",
       "      <td>0.689769</td>\n",
       "      <td>0.092997</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.622927</td>\n",
       "      <td>0.041567</td>\n",
       "      <td>0.102014</td>\n",
       "      <td>0.021971</td>\n",
       "      <td>75</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'epochs': 75, 'lr': 0.001}</td>\n",
       "      <td>0.663366</td>\n",
       "      <td>0.801980</td>\n",
       "      <td>0.574257</td>\n",
       "      <td>0.679868</td>\n",
       "      <td>0.093697</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.016843</td>\n",
       "      <td>0.068657</td>\n",
       "      <td>0.396711</td>\n",
       "      <td>0.025759</td>\n",
       "      <td>200</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'epochs': 200, 'lr': 0.01}</td>\n",
       "      <td>0.415842</td>\n",
       "      <td>0.792079</td>\n",
       "      <td>0.683168</td>\n",
       "      <td>0.630363</td>\n",
       "      <td>0.158072</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.450925</td>\n",
       "      <td>0.130410</td>\n",
       "      <td>0.165057</td>\n",
       "      <td>0.016116</td>\n",
       "      <td>75</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'epochs': 75, 'lr': 0.01}</td>\n",
       "      <td>0.584158</td>\n",
       "      <td>0.782178</td>\n",
       "      <td>0.504950</td>\n",
       "      <td>0.623762</td>\n",
       "      <td>0.116591</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.772882</td>\n",
       "      <td>0.055635</td>\n",
       "      <td>0.238296</td>\n",
       "      <td>0.012846</td>\n",
       "      <td>75</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'epochs': 75, 'lr': 0.1}</td>\n",
       "      <td>0.376238</td>\n",
       "      <td>0.801980</td>\n",
       "      <td>0.633663</td>\n",
       "      <td>0.603960</td>\n",
       "      <td>0.175073</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_epochs  \\\n",
       "4       9.809377      0.067526         0.308544        0.034504          200   \n",
       "0       4.622927      0.041567         0.102014        0.021971           75   \n",
       "5      10.016843      0.068657         0.396711        0.025759          200   \n",
       "1       4.450925      0.130410         0.165057        0.016116           75   \n",
       "2       4.772882      0.055635         0.238296        0.012846           75   \n",
       "\n",
       "  param_lr                        params  split0_test_score  \\\n",
       "4    0.001  {'epochs': 200, 'lr': 0.001}           0.693069   \n",
       "0    0.001   {'epochs': 75, 'lr': 0.001}           0.663366   \n",
       "5     0.01   {'epochs': 200, 'lr': 0.01}           0.415842   \n",
       "1     0.01    {'epochs': 75, 'lr': 0.01}           0.584158   \n",
       "2      0.1     {'epochs': 75, 'lr': 0.1}           0.376238   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "4           0.801980           0.574257         0.689769        0.092997   \n",
       "0           0.801980           0.574257         0.679868        0.093697   \n",
       "5           0.792079           0.683168         0.630363        0.158072   \n",
       "1           0.782178           0.504950         0.623762        0.116591   \n",
       "2           0.801980           0.633663         0.603960        0.175073   \n",
       "\n",
       "   rank_test_score  \n",
       "4                1  \n",
       "0                2  \n",
       "5                3  \n",
       "1                4  \n",
       "2                5  "
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_result.cv_results_).sort_values(by='rank_test_score').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best learn rate and # epochs : 200 and 0.001:\n",
    "Since the learn rate is so small and # epochs iss large, run gridsearch again with higher # epochs and see if that improves "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(lr=0.01):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(layer1, input_shape=(13,), kernel_initializer=init_mode, activation=activation, \n",
    "                    kernel_constraint=maxnorm(weight_constraint)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(layer2, kernel_initializer=init_mode, activation=activation, \n",
    "                    kernel_constraint=maxnorm(weight_constraint)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, kernel_initializer=init_mode, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    optimizer = RMSprop(lr=lr)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, batch_size=batch_size, verbose=1)\n",
    "\n",
    "# define the grid search parameters\n",
    "epochs = [175, 300, 500]\n",
    "lr = [0.001, 0.005]\n",
    "param_grid = dict(epochs=epochs, lr=lr)\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=2, verbose=1)\n",
    "grid_result = grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_epochs</th>\n",
       "      <th>param_lr</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.528824</td>\n",
       "      <td>0.652418</td>\n",
       "      <td>0.190313</td>\n",
       "      <td>0.034570</td>\n",
       "      <td>175</td>\n",
       "      <td>0.005</td>\n",
       "      <td>{'epochs': 175, 'lr': 0.005}</td>\n",
       "      <td>0.673267</td>\n",
       "      <td>0.821782</td>\n",
       "      <td>0.643564</td>\n",
       "      <td>0.712871</td>\n",
       "      <td>0.077960</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22.867647</td>\n",
       "      <td>0.731623</td>\n",
       "      <td>0.351138</td>\n",
       "      <td>0.018046</td>\n",
       "      <td>500</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'epochs': 500, 'lr': 0.001}</td>\n",
       "      <td>0.673267</td>\n",
       "      <td>0.821782</td>\n",
       "      <td>0.603960</td>\n",
       "      <td>0.699670</td>\n",
       "      <td>0.090864</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.320076</td>\n",
       "      <td>0.378161</td>\n",
       "      <td>0.294596</td>\n",
       "      <td>0.058786</td>\n",
       "      <td>300</td>\n",
       "      <td>0.005</td>\n",
       "      <td>{'epochs': 300, 'lr': 0.005}</td>\n",
       "      <td>0.673267</td>\n",
       "      <td>0.782178</td>\n",
       "      <td>0.643564</td>\n",
       "      <td>0.699670</td>\n",
       "      <td>0.059589</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.044495</td>\n",
       "      <td>0.158138</td>\n",
       "      <td>0.103685</td>\n",
       "      <td>0.017522</td>\n",
       "      <td>175</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'epochs': 175, 'lr': 0.001}</td>\n",
       "      <td>0.673267</td>\n",
       "      <td>0.782178</td>\n",
       "      <td>0.594059</td>\n",
       "      <td>0.683168</td>\n",
       "      <td>0.077118</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>21.134149</td>\n",
       "      <td>0.657949</td>\n",
       "      <td>0.340150</td>\n",
       "      <td>0.044028</td>\n",
       "      <td>500</td>\n",
       "      <td>0.005</td>\n",
       "      <td>{'epochs': 500, 'lr': 0.005}</td>\n",
       "      <td>0.702970</td>\n",
       "      <td>0.762376</td>\n",
       "      <td>0.544554</td>\n",
       "      <td>0.669967</td>\n",
       "      <td>0.091937</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_epochs  \\\n",
       "1       8.528824      0.652418         0.190313        0.034570          175   \n",
       "4      22.867647      0.731623         0.351138        0.018046          500   \n",
       "3      15.320076      0.378161         0.294596        0.058786          300   \n",
       "0       8.044495      0.158138         0.103685        0.017522          175   \n",
       "5      21.134149      0.657949         0.340150        0.044028          500   \n",
       "\n",
       "  param_lr                        params  split0_test_score  \\\n",
       "1    0.005  {'epochs': 175, 'lr': 0.005}           0.673267   \n",
       "4    0.001  {'epochs': 500, 'lr': 0.001}           0.673267   \n",
       "3    0.005  {'epochs': 300, 'lr': 0.005}           0.673267   \n",
       "0    0.001  {'epochs': 175, 'lr': 0.001}           0.673267   \n",
       "5    0.005  {'epochs': 500, 'lr': 0.005}           0.702970   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "1           0.821782           0.643564         0.712871        0.077960   \n",
       "4           0.821782           0.603960         0.699670        0.090864   \n",
       "3           0.782178           0.643564         0.699670        0.059589   \n",
       "0           0.782178           0.594059         0.683168        0.077118   \n",
       "5           0.762376           0.544554         0.669967        0.091937   \n",
       "\n",
       "   rank_test_score  \n",
       "1                1  \n",
       "4                2  \n",
       "3                3  \n",
       "0                4  \n",
       "5                5  "
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_result.cv_results_).sort_values(by='rank_test_score').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One last finetuning:\n",
    "def create_model(lr=0.01):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(layer1, input_shape=(13,), kernel_initializer=init_mode, activation=activation, \n",
    "                    kernel_constraint=maxnorm(weight_constraint)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(layer2, kernel_initializer=init_mode, activation=activation, \n",
    "                    kernel_constraint=maxnorm(weight_constraint)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, kernel_initializer=init_mode, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    optimizer = RMSprop(lr=lr)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, batch_size=batch_size, verbose=1)\n",
    "\n",
    "# define the grid search parameters\n",
    "epochs = [140, 165, 180]\n",
    "lr = [0.003, 0.004, 0.005, 0.006, 0.007]\n",
    "param_grid = dict(epochs=epochs, lr=lr)\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=2, verbose=1)\n",
    "grid_result = grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_epochs</th>\n",
       "      <th>param_lr</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9.217514</td>\n",
       "      <td>0.615243</td>\n",
       "      <td>0.535745</td>\n",
       "      <td>0.007938</td>\n",
       "      <td>180</td>\n",
       "      <td>0.004</td>\n",
       "      <td>{'epochs': 180, 'lr': 0.004}</td>\n",
       "      <td>0.801980</td>\n",
       "      <td>0.841584</td>\n",
       "      <td>0.643564</td>\n",
       "      <td>0.762376</td>\n",
       "      <td>0.085554</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8.329626</td>\n",
       "      <td>0.319037</td>\n",
       "      <td>0.361162</td>\n",
       "      <td>0.018857</td>\n",
       "      <td>165</td>\n",
       "      <td>0.007</td>\n",
       "      <td>{'epochs': 165, 'lr': 0.007}</td>\n",
       "      <td>0.732673</td>\n",
       "      <td>0.821782</td>\n",
       "      <td>0.693069</td>\n",
       "      <td>0.749175</td>\n",
       "      <td>0.053827</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10.942259</td>\n",
       "      <td>0.030027</td>\n",
       "      <td>0.556416</td>\n",
       "      <td>0.050115</td>\n",
       "      <td>180</td>\n",
       "      <td>0.005</td>\n",
       "      <td>{'epochs': 180, 'lr': 0.005}</td>\n",
       "      <td>0.792079</td>\n",
       "      <td>0.801980</td>\n",
       "      <td>0.643564</td>\n",
       "      <td>0.745875</td>\n",
       "      <td>0.072457</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.730639</td>\n",
       "      <td>0.125757</td>\n",
       "      <td>0.356799</td>\n",
       "      <td>0.067109</td>\n",
       "      <td>165</td>\n",
       "      <td>0.006</td>\n",
       "      <td>{'epochs': 165, 'lr': 0.006}</td>\n",
       "      <td>0.554455</td>\n",
       "      <td>0.841584</td>\n",
       "      <td>0.762376</td>\n",
       "      <td>0.719472</td>\n",
       "      <td>0.121082</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.522777</td>\n",
       "      <td>0.103490</td>\n",
       "      <td>0.605091</td>\n",
       "      <td>0.046021</td>\n",
       "      <td>140</td>\n",
       "      <td>0.006</td>\n",
       "      <td>{'epochs': 140, 'lr': 0.006}</td>\n",
       "      <td>0.683168</td>\n",
       "      <td>0.841584</td>\n",
       "      <td>0.594059</td>\n",
       "      <td>0.706271</td>\n",
       "      <td>0.102363</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_epochs  \\\n",
       "11       9.217514      0.615243         0.535745        0.007938          180   \n",
       "9        8.329626      0.319037         0.361162        0.018857          165   \n",
       "12      10.942259      0.030027         0.556416        0.050115          180   \n",
       "8        7.730639      0.125757         0.356799        0.067109          165   \n",
       "3        8.522777      0.103490         0.605091        0.046021          140   \n",
       "\n",
       "   param_lr                        params  split0_test_score  \\\n",
       "11    0.004  {'epochs': 180, 'lr': 0.004}           0.801980   \n",
       "9     0.007  {'epochs': 165, 'lr': 0.007}           0.732673   \n",
       "12    0.005  {'epochs': 180, 'lr': 0.005}           0.792079   \n",
       "8     0.006  {'epochs': 165, 'lr': 0.006}           0.554455   \n",
       "3     0.006  {'epochs': 140, 'lr': 0.006}           0.683168   \n",
       "\n",
       "    split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "11           0.841584           0.643564         0.762376        0.085554   \n",
       "9            0.821782           0.693069         0.749175        0.053827   \n",
       "12           0.801980           0.643564         0.745875        0.072457   \n",
       "8            0.841584           0.762376         0.719472        0.121082   \n",
       "3            0.841584           0.594059         0.706271        0.102363   \n",
       "\n",
       "    rank_test_score  \n",
       "11                1  \n",
       "9                 2  \n",
       "12                3  \n",
       "8                 4  \n",
       "3                 5  "
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_result.cv_results_).sort_values(by='rank_test_score').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model Predictions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.782608695652174, 0.8214285714285714, 0.8214285714285714)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_accuracy\n",
    "#accuracy, precision, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 1s 24ms/step\n",
      "Accuracy: 84.783\n",
      "Precision: 86.207\n",
      "Recall: 89.286\n"
     ]
    }
   ],
   "source": [
    "model = grid_result.best_estimator_\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=99)\n",
    "model.fit(X_train, y_train, verbose=0)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "tuned_accuracy = get_accuracy(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "nteract": {
   "version": "0.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
