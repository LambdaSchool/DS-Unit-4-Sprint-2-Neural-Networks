{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y6SKlgYrpcym"
   },
   "source": [
    "# Neural Networks Sprint Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BrEbRrjVphPM"
   },
   "source": [
    "## 1) Define the following terms:\n",
    "\n",
    "- Neuron\n",
    "- Input Layer\n",
    "- Hidden Layer\n",
    "- Output Layer\n",
    "- Activation\n",
    "- Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q5EksLqnp4oB"
   },
   "source": [
    "**Neuron:**\n",
    "A node in A Neural Network. They modeled after biological neurons. Neurons read the activation state of all the neurons in the previous layer, weighs them individually, and passes the sum  thru a function that decides on a final output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input Layer:**\n",
    "The first/input layer of a neural network. A set of variables that correspond directly to a feature in the data. \n",
    "\n",
    "**Hidden Layer:**\n",
    "Internal layers of a neural network. Existing between them, it connects input and output layers. \n",
    "\n",
    "**Output Layer:**\n",
    "The last/output layer of a neural network. Each node is a function like the hidden layers, but its output corresponds to the NN's predictions for a single outcome variable. Note that the nodes in this layer don't usually have an activation function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Activation Function:**\n",
    "Each neuron must sum and weight inputs then produce a single output. The activation function shapes that output to be within useful bounds. All the nodes in a layer of the NN usually have the same activation function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Backpropagation:** Short for \"Backwards Propagation of errors\" and refers to a specific algorithm for how weights in a neural network are updated in reverse order at the end of each training epoch. It 'assigns blame' to weights and works backwards to nudge the weights until they 'improve' the prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ri_gRA2Jp728"
   },
   "source": [
    "## 2) Create a perceptron class that can model the behavior of an AND gate. You can use the following table as your training data:\n",
    "\n",
    "| x1 | x2 | x3 | y |\n",
    "|----|----|----|---|\n",
    "| 1  | 1  | 1  | 1 |\n",
    "| 1  | 0  | 1  | 0 |\n",
    "| 0  | 1  | 1  | 0 |\n",
    "| 0  | 0  | 1  | 0 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ig6ZTH8tpQ19"
   },
   "outputs": [],
   "source": [
    "class Perceptron(object):\n",
    "\n",
    "    def __init__(self, no_of_inputs, threshold=100, learning_rate=0.01):\n",
    "        self.threshold = threshold\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weights = np.zeros(no_of_inputs + 1)\n",
    "           \n",
    "    def predict(self, inputs):\n",
    "        summation = np.dot(inputs, self.weights[1:]) + self.weights[0]\n",
    "        if summation > 0:\n",
    "            activation = 1\n",
    "        else:\n",
    "            activation = 0            \n",
    "        return activation\n",
    "\n",
    "    def train(self, training_inputs, labels):\n",
    "        for _ in range(self.threshold):\n",
    "            for inputs, label in zip(training_inputs, labels):\n",
    "                prediction = self.predict(inputs)\n",
    "                self.weights[1:] += self.learning_rate * (label - prediction) * inputs\n",
    "                self.weights[0] += self.learning_rate * (label - prediction)\n",
    "\n",
    "inputs = np.array([[1,1,1],\n",
    "                   [1,0,1],\n",
    "                   [0,1,1],\n",
    "                   [0,0,1]])\n",
    "\n",
    "correct_outputs = np.array([[1],\n",
    "                            [0],\n",
    "                            [0],\n",
    "                            [0]])\n",
    "\n",
    "pn = Perceptron(no_of_inputs=3, threshold=100, learning_rate=0.01)\n",
    "pn.train(inputs, correct_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     AND Gate\n",
      "1 1 1 --> 1\n",
      "1 0 1 --> 0\n",
      "0 1 1 --> 0\n",
      "0 0 1 --> 0\n"
     ]
    }
   ],
   "source": [
    "print(\"     AND Gate\")\n",
    "for row in inputs:\n",
    "    print(f'{row[0]} {row[1]} {row[2]} --> {pn.predict(row)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "86HyRi8Osr3U"
   },
   "source": [
    "## 3) Implement a Neural Network Multilayer Perceptron class that uses backpropagation to update the network's weights. \n",
    "- Your network must have one hidden layer. \n",
    "- You do not have to update weights via gradient descent. You can use something like the derivative of the sigmoid function to update weights.\n",
    "- Train your model on the Heart Disease dataset from UCI:\n",
    "\n",
    "[Github Dataset](https://github.com/ryanleeallred/datasets/blob/master/heart.csv)\n",
    "\n",
    "[Raw File on Github](https://raw.githubusercontent.com/ryanleeallred/datasets/master/heart.csv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CNfiajv3v4Ed"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#from mlxtend.preprocessing import shuffle_arrays_unison\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Inspect Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach',\n",
      "       'exang', 'oldpeak', 'slope', 'ca', 'thal', 'target'],\n",
      "      dtype='object')\n",
      "(303, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url=\"https://raw.githubusercontent.com/ryanleeallred/datasets/master/heart.csv\"\n",
    "df=pd.read_csv(url)\n",
    "print(df.columns)\n",
    "print(df.shape)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.target.values\n",
    "X = df.drop(columns = ['target']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(303, 13)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=y.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(303, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(y.shape)\n",
    "y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = 13\n",
    "# 2 hidden layers of 16 each, \n",
    "# output of 1 variables (the probability prediction)\n",
    "class NN_2L16(object):\n",
    "    def __init__(self):\n",
    "        self.inputs = 13\n",
    "        self.L1Nodes = 16\n",
    "        self.L2Nodes = 16\n",
    "        self.outputNodes = 1\n",
    "\n",
    "        # Initlize Weights\n",
    "        self.L1_weights = np.random.randn(self.inputs, self.L1Nodes) # (784x16)\n",
    "        self.L2_weights = np.random.randn(self.L1Nodes, self.L2Nodes) # (16x16)\n",
    "        self.output_weights = np.random.randn(self.L2Nodes, self.outputNodes) # (16x10)\n",
    "\n",
    "    def feed_forward(self, X):\n",
    "        # Sum and activate flows to L1\n",
    "        self.activated_L1 = self.sigmoid(np.dot(X, self.L1_weights)) \n",
    "        # Sum and activate flows to L2\n",
    "        self.activated_L2 = self.sigmoid(np.dot(self.activated_L1, self.L2_weights))\n",
    "        # Sum and activate flows to output\n",
    "        self.activated_output = self.sigmoid(np.dot(self.activated_L2, self.output_weights))\n",
    "        return self.activated_output\n",
    "        \n",
    "    def sigmoid(self, s):\n",
    "        return 1/(1+np.exp(-s))\n",
    "    \n",
    "    def sigmoidPrime(self, s):\n",
    "        return s * (1 - s)\n",
    "    \n",
    "    def backward(self, X, y, output):\n",
    "        ## backward propgate through the network, calculating error and delta at each layer\n",
    "        # Output\n",
    "        self.output_error = y - output # error in this layer\n",
    "        self.output_delta = self.output_error*self.sigmoidPrime(output) # apply derivative of sigmoid to error\n",
    "        \n",
    "        # L2\n",
    "        self.L2_error = self.output_delta.dot(self.output_weights.T) \n",
    "        self.L2_delta = self.L2_error*self.sigmoidPrime(self.activated_L2)\n",
    "        \n",
    "        # L1\n",
    "        self.L1_error = self.L2_delta.dot(self.L2_weights.T) \n",
    "        self.L1_delta = self.L1_error*self.sigmoidPrime(self.activated_L1)\n",
    "        \n",
    "        \n",
    "        ## Update all weights\n",
    "        self.L1_weights += X.T.dot(self.L1_delta) \n",
    "        self.L2_weights += self.activated_L1.T.dot(self.L2_delta)\n",
    "        self.output_weights += self.activated_L2.T.dot(self.output_delta)\n",
    "        \n",
    "    def train (self, X, y):\n",
    "        output = self.feed_forward(X)\n",
    "        self.backward(X, y, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------- EPOCH 1 -----------+\n",
      "Loss: \n",
      "0.48727738719106406\n",
      "\n",
      "\n",
      "+---------- EPOCH 2 -----------+\n",
      "Loss: \n",
      "0.45544554455445546\n",
      "\n",
      "\n",
      "+---------- EPOCH 3 -----------+\n",
      "Loss: \n",
      "0.45544554455445546\n",
      "\n",
      "\n",
      "+---------- EPOCH 500 -----------+\n",
      "Loss: \n",
      "0.45544554455445546\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:26: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------- EPOCH 1000 -----------+\n",
      "Loss: \n",
      "0.45544554455445546\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = NN_2L16()\n",
    "epochs=1000\n",
    "for i in range(epochs): \n",
    "    if i+1 in [1,2,3] or (i+1) % 500 == 0:\n",
    "        print('+---------- EPOCH', i+1, '-----------+')\n",
    "        #print(\"Input: \\n\", X) \n",
    "        #print(\"Actual Output: \\n\", y)  \n",
    "        #print(\"Predicted Output: \\n\" + str(model.feed_forward(X))) \n",
    "        print(\"Loss: \\n\" + str(np.mean(np.square(y - model.feed_forward(X))))) # mean sum squared loss\n",
    "        print(\"\\n\")\n",
    "    model.train(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GGT1oRzXw3H9"
   },
   "source": [
    "## 4) Implement a Multilayer Perceptron architecture of your choosing using the Keras library. Train your model and report its baseline accuracy. Then hyperparameter tune at least two parameters and report your model's accuracy. \n",
    "\n",
    "- Use the Heart Disease Dataset (binary classification)\n",
    "- Use an appropriate loss function for a binary classification task\n",
    "- Use an appropriate activation function on the final layer of your network. \n",
    "- Train your model using verbose output for ease of grading.\n",
    "- Use GridSearchCV to hyperparameter tune your model. (for at least two hyperparameters)\n",
    "- When hyperparameter tuning, show you work by adding code cells for each new experiment. \n",
    "- Report the accuracy for each combination of hyperparameters as you test them so that we can easily see which resulted in the highest accuracy.\n",
    "- You must hyperparameter tune at least 5 parameters in order to get a 3 on this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XWw4IYxLxKwH"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline : 1 Hidden 16 node Layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAErCAYAAAAi4t8iAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3XmcFNW5//HPw74o+76rLK6AMKKgIoobSNREgxoX0ERMjIlETX6uV29MvBo1GnNvFBNRVIwal4gKbiiaRAFHZBlWEYZ1hk2Gfef5/VE12jTTMzVMb8x8369XvXq6zqmqp3t6+pk6p+occ3dERESiqJbpAERE5OChpCEiIpEpaYiISGRKGiIiEpmShoiIRKakISIikSlpiGQZM7vHzNzMBmQ6FpF4ShqSVOGXXfyyw8zyzWyMmR2V5nieCWPoVM7tBiR4LfssBxjT8HD74QeyfaaEMU/KdBySWTUyHYBUWv8d83NDoA9wFXCRmZ3i7tMzE1a5LQGeSfMx/xd4EVia5uOKlElJQ1LC3e+JX2dmfwZuAEYCw9Mc0oHKL+m1pJK7rwXWpvOYIlGpeUrS6b3wsXlJhWZ2mZl9ZGZFZrbdzOaa2Z1mVruEuqea2Ztmtjxs/io0s8lmdndMHQeGhU8XxzQr5Sf7hYXHO9zMnjSzhWa2zcy+MbNZZvaEmTUN60wCng43eTquuatTWKfEPo3i5iEza2lmo81slZltMbNPzezUsE59M3vQzJaE78tsM/thCbE2NLNfm9mH4Xu408zWmNk4M+sbV3d4TFPcaXEx3xNXd6iZfWJmG8L3YJaZ3Zbgd5gfLg3M7I/hz7vi9ynZRWcakk5nho+58QVmNhq4GlgOvAoUAScB9wIDzewsd98d1j0XeBvYCIwDVgBNgKOA6/muaey/gQuBHsCfwn0S85g0ZtYa+BxoAIwPX0Md4DDgSoImp3UETV1FwAXAG0BsM12UuBoB/wE2AX8neN2XAu+GX/ajwnVvATWBy4CXzGyZu0+O2c9RwO+BTwjey/VAB+B8YJCZfc/d3wnrTid4L+9m/+a6STHvwX3AbQRnSS8Am4FBwH3AOWZ2trvvjHs9tYAPw5jfI/idLo7wPkimuLsWLUlbAA+Xe2KWPwL/AvYCbwKHxm0zPNzmNaBuXNk9YdmNMeteDdf1KOH4zeKePxPW7VTO1zEg3C4/7rXELpfG1P9FfJwxZfVjX1fM6x2e4NjFr3lAgvf2CaBazPorw/XfhO9vnZiyU8Oy1+P21TD+vQrXtwNWAnMT/G4nJYi5b1i+FGgVs75GGJMDt8dtkx+u/wCon+nPrpZoS8YD0FK5lpgvtpKW2cCPStjmS2AX0KiEsuoE/7lOjVlXnDS6RoinokmjtOWfMfWLk8aICPuuSNLYwv5Jt3r4/jlweAn7WwwsLsdrfyzcV4cSjj8pwTZ/TfT6ga7AHmBR3PripLFf8teSvYuapyQl3N2Kfzaz+sAxwP3AWDM7xt3vCMvqETQfrQVGmllJu9tB0JxSbCzwA2CKmb0EfAT8x92Xp+ClfOzuAyLUG0fQDPN/ZnYO8C5BM9IcD78hk2SBu2+KXeHue8xsFcF/64tK2GYFcGL8SjM7GbiR4CyhBUFTUay2RL+Cq1f4+GF8gbsvMLPlwGFm1tDdN8QUbwdmRjyGZAElDUk5d98CTDWzHxD0WfzGzJ5w92VAY8AIOsfvLmU3sft7zcyGADcD1wDXAZjZF8Bt7v5+Cl5GWTEtMbM+BGcJ5xIkNYBlZvaQuz+WpENtSLB+dxll+/ytm9n3gVcIvrTfB74mOIvZS3CWdRqwX+d1KRqGjwUJygsI+kwaxcW5OslJVVJMSUPSxt2LzGw+wX+lvYBlfPcF8qW790q48f77eht4OzyLOREYAvwMeMvMjnf3OcmNPlJMc4FLzKwGwdnTmQTNVn8ysy3u/lS6YyrFvcBOICeM+1tmNoogaZRH8e+xFUECitc6rl4xJYyDjC65lXRrHD5WA3D3zQR9HceYWZPy7szdt7j7h+5+E0HzUC2CK3aK7Qkfqx94yOWOabe7f+HuDxBcvQTBVVwZi6kEnQmazuITRjXglATb7CVxzF+GjwPiC8ysM0EH+2J3T/qVa5JeShqSNmZ2IcElqLuAT2OK/kjwZT/azBqVsF1jM+sV87x/+N98vJbh49aYdevCxw4Vib0sZtbbzBqWUJSxmMqQD3QxszbFKyzoULoHODrBNuuA9gnKRoePd5rZt/fhmFl14CGC75psOtOSA6TmKUmJuBu06hN8ERWfAdzu7quKC919tJn1JrjH4msze5egA7YJQZLpT3BD3E/DTR4D2prZfwi+/HYCvYEzCO4jeDHm2BOBXwN/NbNXCe5vKHL3/434UjqVcbPZo+F/z1cC15nZvwmaZ9YDRwDfI+jIfzRmm88IksjI8Ka/wnD9n+M6iVPpEYJLd78M35ddwMkEv6c3w7jjTQQuNbM3gWnhNp+4+yfu/qmZ/QH4DZBnZq8Q9JEMAo4F/g08mOLXJOmQ6cu3tFSuhZIvTd1N0BH6BnBWKdsOIbgpbTVBIigEpgK/A46MqTeU4Ma2rwhuINsI5BHcrNa8hP3eBMwl+PJ2gqFBynodAxK8lvilU1j/ROBxYAbB/RLbgIUEye7YEvZ/LkHy2FzCvu4h8SW3kxLEm5/odRHcgOclrB9OcOPeFoKr114Hjivl+C0IbtpbRdDE5sA9cXUuJUgQmwg62WcDdxBz70iUmLVk72LhL09ERKRM6tMQEZHIlDRERCQyJQ0REYlMSUNERCJT0hARkciUNEREJDIlDRERiUxJQ0REIlPSEBGRyJQ0REQkMiUNERGJTElDREQiS2vSMLPRZrbazPJi1jUxs/fN7KvwsXG43szsMTNbaGYzY+dTEBGRzEj3mcYzBENCx7oVmOjuXQjG6781XD8I6BIuIwiGnRYRkQxKa9Jw908I5hqIdQEwJvx5DN9Ni3kB8KwHJgONzKw1IiKSMdkwc19Ldy8Ify7ku+kx2wLLYuotD9cVEMfMRhCcjVC/fv3eRx55ZOqiFRGphL744ou17t68rHrZkDS+5e5uZuWeFcrdnwSeBMjJyfHc3NykxyYiUpmZ2ZIo9bLh6qlVxc1O4ePqcP0K9p3Evl24TkREMiQbksY4YFj48zCCeaSL118VXkV1ErAhphlLREQyIK3NU2b2d2AA0MzMlgN3A/cDL5vZj4ElwNCw+nhgMLAQ2Apcnc5YRURkf2lNGu5+WYKigSXUdeDnqY1IRETKIxuap0RE5CChpCEiIpEpaYiISGRKGiIiEpmShoiIRKakISIikSlpiIhIZEoaIiISmZKGiIhEpqQhIiKRKWmIiEhkShoiIhKZkoaIiESmpCEiIpEpaYiISGRKGiIiEpmShoiIRKakISIikWVN0jCzG80sz8xmm9nIcN09ZrbCzKaHy+BMxykiUpWldY7wRMzsWOBaoA+wE3jHzN4Kix9x94cyFpyIiHwrK5IGcBQwxd23ApjZx8APMhuSiIjEy5bmqTzgVDNramb1gMFA+7DsBjObaWajzaxx5kIUEZGsSBruPhd4AHgPeAeYDuwBHgeOAHoCBcDDJW1vZiPMLNfMctesWZOeoEVEqqCsSBoA7v6Uu/d29/7AemCBu69y9z3uvhf4K0GfR0nbPunuOe6e07x583SGLSJSpWRN0jCzFuFjB4L+jBfMrHVMle8TNGOJiEiGZEtHOMCrZtYU2AX83N2LzOzPZtYTcCAfuC6TAYqIVHVZkzTc/dQS1l2ZiVhERKRkWdM8JSIi2U9JQ0REIlPSEBGRyJQ0REQkMiUNERGJTElDREQiU9IQEZHIlDRERCQyJQ0REYlMSUNERCJT0hARkciUNEREJDIlDRERiUxJQ0REIlPSEBGRyJQ0REQkMiUNERGJTElDREQiy5qkYWY3mlmemc02s5HhuiZm9r6ZfRU+Ns50nCIiVVlWJA0zOxa4FugD9ACGmFln4FZgort3ASaGz0VEJEOyImkARwFT3H2ru+8GPgZ+AFwAjAnrjAEuzFB8IiIC1Mh0AKE84Pdm1hTYBgwGcoGW7l4Q1ikEWpa1o/nz5zNgwIB91g0dOpTrr7+erVu3Mnjw4P22GT58OMOHD2ft2rVcfPHF+5X/7Gc/45JLLmHZsmVceeWV+5XffPPNfO9732P+/Plcd911+5XfeeednHnmmUyfPp2RI0fuV37ffffRr18/Pv30U26//fb9yh999FF69uzJBx98wO9+97v9ykeNGkW3bt148803efjhh/crf+6552jfvj0vvfQSjz/++H7lr7zyCs2aNeOZZ57hmWee2a98/Pjx1KtXj7/85S+8/PLL+5VPmjQJgIceeoi33nprn7K6desyYcIEAO69914mTpy4T3nTpk159dVXAbjtttv47LPP9ilv164dzz//PAAjR45k+vTp+5R37dqVJ598EoARI0awYMGCfcp79uzJo48+CsAVV1zB8uXL9ynv27cv//M//wPARRddxLp16/YpHzhwIHfddRcAgwYNYtu2bfuUDxkyhFtuuQVgv88d6LOnz97B+9lLJCuShrvPNbMHgPeALcB0YE9cHTczL2l7MxsBjACoXbt2iqMVEam6zL3E7+GMMrP7gOXAjcAAdy8ws9bAJHfvVtq2OTk5npubm44wRUQqDTP7wt1zyqqXLX0amFmL8LEDQX/GC8A4YFhYZRjwRmaiExERyJLmqdCrYZ/GLuDn7l5kZvcDL5vZj4ElwNCMRigiUsVlTdJw91NLWLcOGJiBcEREpARZ0zwlIiLZT0lDREQiU9IQEZHIlDRERCSySEnDzM5OdSAiIpL9op5pvGNmC83s12bWLKURiYhI1oqaNM4APgfuBZab2QtmdlrqwhIRkWwUKWm4+yR3vwxoB9wF5AAfmdnccB4MzXMhIlIFlKsj3N3XuvuD7t4VOAtYC/yR4OzjGTM7LhVBiohIdjigq6fMbDDwS+AkYDXwHHAaMM3Mfpa88EREJJtEThpm1srM7jCzxcBbQCPgCqC9u/8U6AyMAv4rJZGKiEjGRRp7ysxeBYYA24Hngb+4++zYOu6+x8xeAK5PepQiIpIVog5Y2AUYCTzn7ptLqTcLOL3CUYmISFaKlDTcvXvEepsI5vcWEZFKKOod4UPM7IYEZT8PO8ZFRKSSi9oRfhdQP0FZ3bBcREQquahJ40hgWoKy6cBRyQlHRESyWdSkUQ04JEHZoUDN5IQjIiLZLGrSmAFcnqDscmBmcsIREZFsFjVpPAz8wMz+YWZnm9nRZnaWmf0D+D7wYEUDMbNfmdlsM8szs7+bWZ1waJLFZjY9XHpW9DgiInLgol5y+7qZ3Qj8HvhBuNqAzcAv3f21igRhZm0JhiU52t23mdnLwKVh8a/d/ZWK7F9ERJIj6s19uPufzewZoB/QlGCwwk/LuNmvvLHUNbNdQD1gZZL2KyIiSVLeUW43ufu77v6Cu7+XrITh7iuAh4ClQAGwwd3fC4t/b2YzzewRM6td0vZmNsLMcs0sd82aNckISURESmDuHr1yMG9GF6BOfJm7f3LAQQT7fRW4BCgC/gG8AkwECoFawJPA1+7+29L2lZOT47m5uQcaiohIlWRmX7h7Tln1og5YWAcYDQwl6MsoSfXo4e3nTGCxu68Jj/ca0M/dnw/Ld5jZ08AtFTiGiIhUUHnuCB8ADCNIGjcAPwH+DXxNMAJuRSwFTjKzemZmwEBgrpm1BgjXXQjkVfA4IiJSAVGTxkXAb4EXw+dT3P1pdz+N4B6OcysShLtPIWiOmkYwUm41guaosWY2K1zXDPhdRY4jIiIVE/XqqQ7A7HDOjF3sOw7VaOBp4MaKBOLudwN3x60+oyL7FBGR5Ip6prGO74YRWQb0iClrRjBooYiIVHJRzzQmA8cDEwiucrrXzA4FdgM3E/RtiIhIJRc1aTxA0EQFQb9CZ4I+juoECeVnyQ9NRESyTdRhRHKB3PDnTcBF4Y12td19YwrjExGRLFJmn4aZ1TKzaWZ2dux6d9+hhCEiUrWUmTTcfSdwGEH/hYiIVGFRr556Hzi7zFoiIlKpRe0I/zPwvJnVAP5JMKjgPoNWufuiJMcmIiJZJmrS+Dh8vAn4VYI6FRl7SkREDgJRk8bVKY1CREQOClEvuR2T6kBERCT7lWsSJhERqdqizqcxuowq7u4/TkI8IiKSxaL2aZxB3NVSQBPgUIKZ9oqSGZSIiGSnqH0anUpab2b9gSeAy5MYk4iIZKkK9WmE84I/QnAfh4iIVHLJ6AhfRDBsuoiIVHIVShrhHeLDgeVJiUZEpArau9cZ82k+6zbvyHQoZYp69dSHJayuBXQFmgI/rWggZvYr4CcEHe6zCG4obE0wL3lT4AvgynAARRGRSmPSgtXcPW42i9Zs5r8vODbT4ZQq6plGNcDilk3Aa8BAd/9rRYIws7bAL4Ecdz+WYEiSSwkmf3rE3TsD6wFd1isilc7YyUsBeOWL5WzavivD0ZQu6tVTA1IcBwSx1DWzXUA9gkERzwB+FJaPAe4BHk9DLCIiabF8/VY+nL+aAd2aM2n+Gl79YjnDTz4s02El5u5ZsQA3ApuBNcBYoBmwMKa8PZCXYNsRBDML5jZs2NAJmrgc8NzcXM/Nzd1n3d133+3u7q1bt/52Xa9evdzd/dprr92n7ooVK3zcuHH7rBs1apR7cOBvlyFDhri7+5AhQ/ZZ7+4+atSofdaNGzfOV6xYsc+6a6+91t3de/Xq9e261q1bu7v73Xffrdek16TXVElf00PvzvOm596wz7p//vONTLymXI/wXW3B6yqdmT0CNHP3K0soew4odPdfl7mjxPtvDLwKXEJwo+A/gFeAezxomsLM2gMTPGi+SignJ8dzc3MPNBQRkbTZtWcv/e7/kOPaNmT08BN4/cvl/OqlGYy5pg+ndW2e1ljM7At3zymrXtQ+jfOB9xKUvQtcGDWwBM4EFrv7GnffRdBXcjLQKLxCC6AdsKKCxxERyRofzFnFmk07uPzEDgAMPq41zQ6pxZhP8zMbWCmiJo22wNIEZcvD8opYCpxkZvXMzICBwBzgI+DisM4w4I0KHkdEJGu8MHUpbRrWYUC3FgDUrlGdH/XpwEfzV7Nk3ZYMR1eyqEljPdA5QVlngr6IA+buUwiao6YRXG5bDXgS+H/ATWa2kOCy26cqchwRkWyRv3YL//pqLZf16UD1avbt+stP6kh1M577bEkGo0ssatL4ALjTzFrGrgyf304wh3iFuPvd7n6kux/r7le6+w53X+Tufdy9s7v/0N2z/84XEZEI/j51KdWrGZec0H6f9S0b1OHcY1vxcu4ytu7cnaHoEouaNO4CDgG+MrMXzOwPZjYWWADUB+5MVYAiIpXNjt17eDl3GWcf3ZIWDersVz68Xyc2bt/N619mXzdupKTh7vnACcA/gdOBkeHj60Afd1+cqgBFRCqbd/IKWb91F5ef2LHE8t4dG3NMmwaM+TSfKFe4plPksafcPd/dr3L31u5ey93buPtwd8/OhjcRkSw1dvJSOjatR78jmpZYbmYM69eJBas289midWmOrnSRkoaZNTezrgnKuppZs+SGJSJSOS1YtYmp+d/woz4dqBbTAR7v/B5taFyvZtZdfhv1TOMvwM0Jyn4VlouISBlemLKUWtWrcXHvdqXWq1OzOpec0IH356xiRdG2NEVXtqhJ4xSCm/hK8h7BjXgiIlKKbTv38Oq05Qw6rhVND6ldZv0rTgpu+nt+cvb0AkRNGo2BDQnKNhLcQyEiclDau9f5ZMEatu/ak9LjvDlzJZu2707YAR6vXeN6nHV0S16cujTlsUUVNWksB05MUHYiwYi0IiIHpQfemcdVo6dy9xuzU3qcsVOW0qXFIZzQqXHkbYb168T6rbsYN2NlCiOLLmrSeAW4zczOi10ZPr8VeDnZgYmIpMPofy9m1CeL6NS0Hi/lLuODOatScpy8FRuYsayIy0/sQDBaUjR9D29Kt5aHZs3lt1GTxm8JhvcYZ2YrzGyqma0AxoXr/ztVAYqIpMpbM1dy79tzOPvolrwzsj9HtjqUW1+bxTdbkj9B6NgpS6lTsxrf71V6B3g8M+Oqfh2ZvXIjXyxZn/S4yivqzX1bgdOAa4FPCIYv/5hgJr3TwnIRkYPGZ1+v46aXZtC7Q2Meu+x46tSsziOX9GTDtp3c8fqspP5Xv2n7Lt6YvoLze7ShYd2a5d7+wp5tObRODZ7Jgstvy3Nz3y53H+3ul7n72e7+I3d/xt13m1m9VAYpIpJM8wo3MuK5XDo0rcffhuVQp2Z1AI5q3YCbzurGhLxC3pievD6Ef05fydadeyJ3gMerX7sGQ3Pa805eIas2bk9aXAcictIoiZmdbmZPA4VJikdEJKVWFm1j+OjPqVerOmOu6UOjerX2KR/R/3B6d2zMXW/kUbCh4vdHuDtjJy/hmDYN6N6u4QHv56q+HdnjztgpiWapSI9yJw0z62Jm95pZPsHot5cQ9G2IiGS1DVt3MWz0VLbs2M0zV/ehbaO6+9WpXs14+Ic92L3H+fU/ZrJ3b8WaqaYtLWJe4SYuP7FjuTrA43VsWp/Tu7XghSlL2bl7b4Viqoiow4g0NLPrzOxTYB5wB8Gc3Q8Ard39ihTGKCJSYdt37eHaZ3PJX7eFUVf15qjWDRLW7dSsPnecdxT/XriW56dU7Ma6F6Ys5ZDaNTi/Z5sK7QeCy2/Xbt7B+FmZu8shYdIws2pmdp6ZvUzQ/PQ4QaL4A8Ed4Aa84+6JbvoTEckKe/Y6v3ppOlPzv+HhoT3pd0TZw+VdfmIH+ndtzn3j57J47YHNole0dSdvzVzJhce34ZDaNcreoAyndm7G4c3qZ7RDvLQzjZUEzU6DCO7TOAfo4O63EUzFKiKS9dyd3745mwl5hdx53lGc3yPaf/xmxh8u6k7tGtW56eXp7N5T/iahV6etYMfuvfyoz4F1gMerVs24qm9Hpi8rYsayoqTss9wxlFLWguBsYirBPBqTPBvuLBERKYcnPl7EmM+WcO2ph/GTUw8v17atGtbh3guP5culRYz6ZFG5tnV3xk5ZQq8OjTi6TeKmsPK6qHc76teqzpjP8pO2z/IoLWmcAvwV6EVwx3ehmf3FzE5KdhBm1s3MpscsG81spJndE95MWLx+cLKPLSKV12vTlvPAO/M4v0cbbht01AHt4/webRjSvTWPvL+AvBXRW+MnL/qGRWu2HPBltokcWqcmF/Vux1szCli7Of0zYCdsZHP3T4FPzeyXwPeBYQQ3910HLAWcYCDDCnP3+UBPADOrDqwgmBXwauARd38oGccRkdRYWbSNkS9Nr9Cd1DWqGX2PaMqQ7q05vn3jUueaiOKTBWv4zSsz6XdEUx78YfcK7e/eC45lyuJvuPnlGbxxw8nf3tdRmrFTltCwbk3O6976gI+byFV9O/HsZ0t4cepSbjijS9L3X5oye2bcfQfwIvCimbUCrgSuImi6etXMJgGj3f2FJMU0EPja3ZdU5PI0EUmf+yfMY8ayIs48quUB72PTjt2MnbKUp/+TT+uGdRh8XGvO696a49s3KvelqnkrNvCz57+gc4tDeOLK3tSuUfaXfGka16/FHy7qztXPfM4j7y/gtsGln7Ws2bSDd2cXclXfTpESTHl1bnEIp3ZpxvOTl3LdaUdQs3qFbrkrl3J157t7IfAg8KCZ9QKGA5cCzwHJShqXAn+PeX6DmV0F5AI3u/t+g6+Y2QhgBECHDh2SFIaIRDF9WRHjZqzkhtM7c8s53Sq0r03bdzFx7mremlnAc58t4al/L6Zto7oMPq4V53VvQ492DctMIEvXbWX401NpVK8WY67pQ4M65R+2oySnH9mCy/p04Ml/LeLMo1tyQqcmCev+44tl7NrjXNYndd9Hw/p24ifP5vLe7FUpOZtJxCrat21mNYDz3P2NCgdjVovgqq1j3H2VmbUE1hI0hd1LcE/INaXtIycnx3NzcysaiohE4O4MHfUZi9duZdKvByTlstJiG7fv4oM5q3h7ZgGffLWGXXucto3qMqR7cAZyXNv9E8i6zTu4+InPWL91J6/8tB+dWxyStHgAtuzYzaA//QvHmXBj/xJf7969zmkPfUTbRnV5cUTfpB4/1p69zoCHPqJ1g7q8/NOKH8fMvnD3nLLqVficxt13JyNhhAYB09x9VbjvVe6+x933EnTK90nScUQkCd6dXcjn+eu56ayuSU0YAA3q1OQHvdrx1PATyL3zLB76YQ+6tjyEp/69mPP/9z/0f/Aj7p8wj7wVG3B3tu7czTVjcllZtI2nhuUkPWFAMAbUw0N7sHz9Nn7/9twS6/xr4VqWfbMt6R3g8apXM646qRNT879hzsqNKT1WrOT+livuMmKapsystbsX3/r4fSAvI1GJyH527t7L/RPm0bXlIQzNKd9w3+XVsG5NLu7djot7t6No607eC89A/vavRTzx8dd0bFqPRnVrMmvFBh6/oje9OyZuOqqoEzo1YUT/wxn18SLOProlpx/ZYp/ysZOX0LR+Lc45plXKYig2NKc9f3x/Ac9+ls/9F3VP+fEgCWcayWJm9YGzgNdiVv/BzGaZ2UzgdOBXGQlORPbz3OQl5K/byu2Dj6JGGjtiG9WrxdCc9oy5pg+f33EmD1x0HB2a1GNuwSbuvfDYtHxZ33RWV7q1PJTfvDqT9TFXjBVs2MbEeasZekJ7atVI/XvSsF5NLjy+Lf+cvoKircmfA6QkWZM03H2LuzeNHZbE3a909+Pcvbu7nx9z1iEiGVS0dSePTfyKU7s0Y0C3FmVvkCKN69fikhM68NyPT2TeveemvEmoWO0a1fnjJT0o2rqTu974rgHkpc+Xsdedy05I3wU5w/p1ZPuuvbz0+bK0HC9rkoaIHDz+/OFCNm3fxR3nHdgNc6lQ0fs6yuuYNg0ZeWZX3ppZwLgZK9m9Zy8vTl1G/y7N6dA0fVMMHdmqASce1oTnJi9hTwVH5I3igJKGmTU2s0FmNtjMUtd4KCJZJ3/tFp79LJ+hOe05slXyhsc4GF3X/3CO79CIu/6Zx9+nLqVw43YuPzH9l/0P79eJ5eu3MXFuauY3j3Ug82mcBnxNcG9iCLopAAAS0UlEQVTGS8DXZjYw2YGJSHb6w7vzqFm9Gjed1TXToWRcjerV+OPQnuzcvZe73phNqwZ1OOPI9DfXnXV0SwYd24pDk3RPSmkO5EzjEeAmd29GMIzI34FHkxqViGSl3PxvGD+rkOv6H0GLBnUyHU5WOKxZfW4ffCQAl5zQPq0XBRSrUb0aj1/Rm75HNE39sRIVmNmfgdvdfVNcUSeCYUUI5wd/DdAkTCKVnLvzu7fn0rJBba7tf1imw8kqV5zUkfZN6qXlSzvTSkuJhwPzzexHceunAI+Y2dFm1ge4PVwnIpXYmzMLmL6siFvO7ka9Wtl2i1dmmRkDurWo8BhXB4OEScPdzwN+DtxnZhPNrLgB86dAd4Ib7SYD9QhGvhWRSmr7rj08MGEeR7duwEW9Unsjn2S3Uhvf3P114CjgcyDXzH4PrHL3k4EGQEN3P8ndyzc7iYgcVJ75NJ8VRdu487yj0n5pq2SXMnts3H2bu98KnBguc8xsiLtvLqG/Q0QqmXWbd/B/Hy5k4JEt6Ne57Lm1pXIrNWmYWbVwVr0ewGJ3PxO4ExhlZm+YWfu0RCkiGfOniV+xddcebguvEJKqLWHSMLPuwDxgLvAlsNzMvh9OtnQksBiYZWb/LxweXUQqma/XbGbslKVc1qc9nVscmulwJAuUdqbxJEGyaAU0BP4XeNbMarv7JncfCZwGfA+YkfJIRSTt/mf8POrWrM7IM3UjnwRKSxpHA0+6++qw7+JRoD7w7Yhg7j7D3U8BNIe3SCXz2dfr+GDuKq4//QiaHVI70+FIliitWelz4FYzKwK2AzcA64D9rpRy96dTE56IZMLevc7vx8+hbaO6XHOybuST75R2pvFjoDZB8pgFnAFc7O670xGYiGTO61+uIG/FRn5zbjfq1Kz8N6xJdAnPNNw9H+hvZvWAWu5elLaoRCRjtu3cw4PvzqdHu4Z8r3ubTIcjWabMq57cfSuwNQ2xiEgW+Nu/FlG4cTuPXXa8buST/WgSJhH51upN23n8468555iW9DlMU+XI/rIiaYQ3EE6PWTaa2Ugza2Jm75vZV+Fj40zHKlKZPfL+V+zcvZdbB2XPjHySXbIiabj7fHfv6e49gd4EzWGvA7cCE929CzAxfC4iKTC/cBMvfb6UK/t25LBm9TMdjmSprEgacQYCX7v7EuACYEy4fgxwYcaiEqnk7hs/l0Nq1+DGgV0yHYpksWxMGpcSzAYI0NLdC8KfC4GWJW1gZiPMLNfMctesWZOOGEUqlWlL1/PxgjX84owuNKpXK9PhSBbLqqRhZrWA84F/xJe5uwNe0nbu/qS757h7TvPmzVMcpUjl89aMAmrVqMZlJ3bIdCiS5bIqaQCDgGnuvip8vsrMWgOEj6szFplIJbV3rzMhr4DTujbnkNoae1RKl21J4zK+a5oCGAcMC38eBryR9ohEKrkvlxVRsGE7g49rlelQ5CCQNUnDzOoDZwGvxay+HzjLzL4Czgyfi0gSTZhVQK3q1Rh4VIldhiL7yJpzUXffAjSNW7eO4GoqEUkBd2dCXiH9uzajQZ2amQ5HDgJZc6YhIuk3fVkRK4q2MejY1pkORQ4SShoiVdiEvEJqVjfOPFpNUxKNkoZIFeXuvD2zgFO7NKdhXTVNSTRKGiJV1MzlG8KmKV01JdEpaYhUUePzCqhZ3Tj7aCUNiU5JQ6QKcnfGzyrg5M7NaFhPTVMSnZKGSBWUt2Ijy77ZxmBdNSXlpKQhUgWNzyugRjXj7GN01ZSUj5KGSBVT3DTVr3MzjWgr5aakIVLFzF65kSXrtjJYV03JAVDSEKliJuQVUL2acfYxShpSfkoaIlVI0DRVSL8jmtKkvpqmpPyUNESqkLkFm1i8dovGmpIDpqQhUoWMnxU0TZ2jq6bkAClpiFQRxVdNnXR4E5oeUjvT4chBSklDpIqYv2oTi9Q0JRWkpCFSRYyfWUA1g3N1qa1UgJKGSBUxPq+QEw9rSjM1TUkFZE3SMLNGZvaKmc0zs7lm1tfM7jGzFWY2PVwGZzpOkYPRglWbWLh6M4OP01mGVEzWzBEO/Al4x90vNrNaQD3gHOARd38os6GJHNzenlmAGZyjpimpoKxIGmbWEOgPDAdw953ATjPLZFgilcaEvAL6dGpCi0PrZDoUOchlS/PUYcAa4Gkz+9LM/mZm9cOyG8xsppmNNrPGGYxR5KC0cPUmFqzazODjdNWUVFy2JI0aQC/gcXc/HtgC3Ao8DhwB9AQKgIdL2tjMRphZrpnlrlmzJk0hixwc3p5ZiBma1lWSIluSxnJgubtPCZ+/AvRy91Xuvsfd9wJ/BfqUtLG7P+nuOe6e07x58zSFLHJwmJBXwAkdm9CigZqmpOKyImm4eyGwzMy6hasGAnPMLPZ8+vtAXtqDEzmIfb1mM/MKNzFIV01JkmRFR3joF8DY8MqpRcDVwGNm1hNwIB+4LnPhiRx8xs8sANBd4JI0WZM03H06kBO3+spMxCJSWYzPKySnY2NaNVTTlCRHVjRPiUjyLV67hbkFGxmkq6YkiZQ0RCqp8bOKm6bUnyHJo6QhUkmNn1XA8R0a0aZR3UyHIpWIkoZIJbRk3RZmr9zIeWqakiRT0hCphN4ubppS0pAkU9IQqYQmzCqkR/tGtFXTlCSZkoZIJbN03VZmrdjAebqhT1JASUOkkhmfpxv6JHWUNEQqmQmzCujeriHtm9TLdChSCSlpiFQiy77ZyozlGzQMuqSMkoZIJTIhbJoarKYpSRElDZFKZPysQo5t24AOTdU0JamhpCFSSawo2sb0ZUVqmpKUUtIQqSQmzFLTlKSekoZIJTF+VgFHt25Ap2b1Mx2KVGJKGiKVwLJvtjJtaRHndddZhqSWkobIQc7dueuNPOrUrMYFPdtkOhyp5JQ0RA5yf5+6jEnz13DboKNo11hXTUlqKWmIHMSWrNvC796ewymdm3HlSR0zHY5UAVmTNMyskZm9YmbzzGyumfU1syZm9r6ZfRU+Ns50nCLZYs9e5+aXZ1C9mvGHi7tTrZplOiSpArImaQB/At5x9yOBHsBc4FZgort3ASaGz0UE+Ou/FpG7ZD2/veAYzc4naZMVScPMGgL9gacA3H2nuxcBFwBjwmpjgAszE6FIdplXuJE/vreAc49pxYU922Y6HKlCzN0zHQNm1hN4EphDcJbxBXAjsMLdG4V1DFhf/Dxu+xHAiPBpN2D+AYbSDFh7gNumg+KrGMVXcdkeo+I7cB3dvXlZlbIlaeQAk4GT3X2Kmf0J2Aj8IjZJmNl6d09Zv4aZ5bp7Tqr2X1GKr2IUX8Vle4yKL/WyonkKWA4sd/cp4fNXgF7AKjNrDRA+rs5QfCIiQpYkDXcvBJaZWbdw1UCCpqpxwLBw3TDgjQyEJyIioRqZDiDGL4CxZlYLWARcTZDUXjazHwNLgKEpjuHJFO+/ohRfxSi+isv2GBVfimVFn4aIiBwcsqJ5SkREDg5KGiIiElmVTBpmdq6ZzTezhWa2313mZlbbzF4Ky6eYWac0xtbezD4yszlmNtvMbiyhzgAz22Bm08Plv9IVX3j8fDObFR47t4RyM7PHwvdvppn1SmNs3WLel+lmttHMRsbVSfv7Z2ajzWy1meXFrIs0TI6ZDQvrfGVmw0qqk4LYHgyH9JlpZq+b2X73R4X1Sv0spDjGe8xsRczvcXCCbUv9e09hfC/FxJZvZtMTbJuW9zBp3L1KLUB14GvgcKAWMAM4Oq7O9cAT4c+XAi+lMb7WQK/w50OBBSXENwB4K4PvYT7QrJTywcAEwICTgCkZ/F0XEty0lNH3j2DEg15AXsy6PwC3hj/fCjxQwnZNCC4MaQI0Dn9unIbYzgZqhD8/UFJsUT4LKY7xHuCWCJ+BUv/eUxVfXPnDwH9l8j1M1lIVzzT6AAvdfZG77wReJBiuJFbs8CWvAAPDO9JTzt0L3H1a+PMmgjG4DrZxIi4AnvXAZKBR8f02aTYQ+Nrdl2Tg2Ptw90+Ab+JWRxkm5xzgfXf/xt3XA+8D56Y6Nnd/z913h08nA+2SeczySvD+RRHl773CSosv/O4YCvw92cfNhKqYNNoCy2KeL2f/L+Vv64R/OBuApmmJLkbYLHY8MKWE4r5mNsPMJpjZMWkNDBx4z8y+CIdwiRflPU6HS0n8h5rJ969YS3cvCH8uBFqWUCcb3strCM4cS1LWZyHVbgib0EYnaN7LhvfvVGCVu3+VoDzT72G5VMWkcVAws0OAV4GR7r4xrngaQZNLD+DPwD/THN4p7t4LGAT83Mz6p/n4ZQrv9zkf+EcJxZl+//bjQTtF1l3/bmZ3ALuBsQmqZPKz8DhwBNATKCBoAspGl1H6WUbW/z3FqopJYwXQPuZ5u3BdiXXMrAbQEFiXluiCY9YkSBhj3f21+HJ33+jum8OfxwM1zaxZuuJz9xXh42rgdYImgFhR3uNUGwRMc/dV8QWZfv9iRBkmJ2PvpZkNB4YAl4dJbT8RPgsp4+6r3H2Pu+8F/prg2Bn9LIbfHz8AXkpUJ5Pv4YGoiknjc6CLmR0W/jd6KcFwJbFihy+5GPgw0R9NsoXtn08Bc939jwnqtCruYzGzPgS/x7QkNTOrb2aHFv9M0GGaF1dtHHBVeBXVScCGmGaYdEn4310m3784UYbJeRc428wah80vZ4frUsrMzgV+A5zv7lsT1InyWUhljLH9ZN9PcOwof++pdCYwz92Xl1SY6ffwgGS6Jz4TC8HVPQsIrqq4I1z3W4I/EIA6BM0aC4GpwOFpjO0UgmaKmcD0cBkM/BT4aVjnBmA2wZUgk4F+aYzv8PC4M8IYit+/2PgM+L/w/Z0F5KT591ufIAk0jFmX0fePIIEVALsI2tV/TNBPNhH4CvgAaBLWzQH+FrPtNeFncSFwdZpiW0jQF1D8GSy+mrANML60z0Ia37/nws/XTIJE0Do+xvD5fn/v6YgvXP9M8ecupm5G3sNkLRpGREREIquKzVMiInKAlDRERCQyJQ0REYlMSUNERCJT0hARkciUNKTKMLMrzWxpzPM5ZnZ9xG3zzcwTLCPL3kNqmFmnMIafZCoGqVqyabpXkVTrDXwB3w7T0q34eUTvEoysGi+/ooGJHCyUNKQq6c13d1P3AvYS3FQV1VoPRu0VqbLUPCVVgplVIxjYrvjMIgeY4+7bk3ycfDN73syuDSf92W5m08zs9BLqXhGOtLvdzNaa2XMlDSEf7muamW0zs/Vm9rGZ9YurVt3MfmtmBWZWZGZvmlm7uP38yMy+NLPNFkxONcvMrkvm65fKT3eES6VmZvlAxwhVD3P3/DL28x++GyvqW/7dvBPF9WoAmwiasnYA/49giPse7j4/rDcCGEUwkN2zBENL3AcUEUzCtTms9xBwM8F4ZG8QnB2dBMx29xfD4fMXA0uATwmG1mhBMOJrnrsPCPdzCvAJ8BjwFsE/jEcCdd39gQjvjwigpCGVnJkdTTBj21UEExpdHhZ9AtwNfBQ+n+PBJD2J9pNP4uRzgrvnxtRrAxzh7svCdYcSfKm/7e5Xmll1YGV4zG/PQMIv9n8BN7r7Y2bWGZgP/Mndb0oQVyeCpPFxcYII198CPAi0dfeV4fPb3b1JotcoEoWap6RSc/c57j6dYHjsSeHPWwim0v2Hu08Pl4QJI8YE4IQSljlx9SYXJ4wwhk3A20DfcFU3grOBfeaocPd/EySX08JVZxL8jT4ZIbbxcc9nhY8dwsfPgcZh09kQSzDnt0hZ1BEulVb4H33xNL0nA78J5zc4lWBOhcLw+R6Pdsr9TfEZRRn2m8MjXFc8Y1zxf/slDRdfGFNePFtkicNqx8cW93xH+FgHwN0/NrMfAr8gmLMBM/sYuMndZ0bYvwigMw2p3CYSDFW9C2hN0N6/i6B/oG1M2WmJdnCASpq2tSXfTf5T/AXfqoR6rWLK14aPSZme1N1fcffTgMYE80+0Bt4JLxIQiUQfFqnMriNoPnqIYH6I4uakNcCdMc/Lc69GFCeZ2bezxYV9GucBn4Wr5hOceVwau1F4RVRHYFK46gOCju+kzhvt7pvd/S2CjvjWfHdGI1ImNU9JpRVzpdJdBJ3QuWbWDWgGPOXuheXcZbNwJsJ4hXFXXq0C3jOze/ju6qn6wL1hXHvM7L+AUWb2PPA8wdnE7wkmZBod1vvazB4BbgoTzzhgD8F0oPPcPeEUovHM7LcEZzsfEXTCtwN+CUx39zVR9yOipCGVWjjF50CCaXshmDv8ywNIGBBcfXVOCev/j2A2wGIfE5wt3Efw5TwHGOTuC4oruPuTZrYV+DXBpbSbCTqzf+PuW2Lq3WJmC4HrCS733UIwU9175Yx9CkGSeISgz2R1uI+7yrkfqeJ0ya1IEoWX3P7b3a/IdCwiqaA+DRERiUxJQ0REIlPzlIiIRKYzDRERiUxJQ0REIlPSEBGRyJQ0REQkMiUNERGJ7P8DEyI4HSBiz54AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Cross Validation Score: 0.72277228 used {'batch_size': 20, 'epochs': 20}\n",
      "\n",
      "CPU times: user 4.56 s, sys: 3.9 s, total: 8.46 s\n",
      "Wall time: 6.63 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# random seed to reproduce later\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(16, input_dim=13, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# instantiate model obj\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "\n",
    "# GridSearchCV hyperparameters\n",
    "batch_size = [20]\n",
    "epochs = [20]\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "c_v = StratifiedKFold(n_splits=4,\n",
    "                      shuffle=True,\n",
    "                      random_state=seed) # 4-fold CV\n",
    "\n",
    "# instantiate GridSearchCV obj\n",
    "cv_grid = GridSearchCV(estimator=model, \n",
    "                    param_grid=param_grid, \n",
    "                    n_jobs=-1, \n",
    "                    cv=c_v)\n",
    "\n",
    "# run the cross validation\n",
    "xval_result = cv_grid.fit(X, y)\n",
    "\n",
    "# Plot the accuracy \n",
    "acc = [x*100 for x in xval_result.best_estimator_.model.history.history['acc']]\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(acc)\n",
    "ax.set_xlabel('# Epochs', fontsize=16)\n",
    "ax.set_ylabel('% Accuracy', fontsize=16)\n",
    "ax.set_ylim(60,100)\n",
    "ax.axhline(80, color='k', linestyle='--', linewidth=1)\n",
    "ax.axhline(90, color='k', linestyle='--')\n",
    "plt.title('Best Estimator', fontsize=20, y=1.05)\n",
    "plt.show()\n",
    "\n",
    "# Report Results\n",
    "print(f\"Baseline Cross Validation Score: {xval_result.best_score_:.8f} used {xval_result.best_params_}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypertune Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "Epoch 1/20\n",
      "Epoch 1/20\n",
      "Epoch 1/20\n",
      "Epoch 1/20\n",
      "Epoch 1/20\n",
      "Epoch 1/20\n",
      "Epoch 1/20\n",
      "Epoch 1/20\n",
      "Epoch 1/20\n",
      "Epoch 1/20\n",
      "Epoch 1/20\n",
      "Epoch 1/20\n",
      "Epoch 1/20\n",
      "Epoch 1/20\n",
      "Epoch 1/20\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Parameters -----------------------------------------------\n",
    "batch_size = [20]\n",
    "epochs = [20]\n",
    "optimizer = ['adam','sgd','rmsprop','nadam']\n",
    "param_grid = dict(batch_size=batch_size, \n",
    "                  epochs=epochs,\n",
    "                  optimizer=optimizer)\n",
    "# -----------------------------------------------\n",
    "\n",
    "# random seed to reproduce later\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "def create_model(optimizer='adam'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(16, input_dim=13, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# instantiate model obj\n",
    "model = KerasClassifier(build_fn=create_model, verbose=1)\n",
    "\n",
    "# GridSearchCV hyperparameters\n",
    "c_v = StratifiedKFold(n_splits=4,\n",
    "                      shuffle=True,\n",
    "                      random_state=seed) # 4-fold CV\n",
    "\n",
    "# instantiate GridSearchCV obj\n",
    "cv_grid = GridSearchCV(estimator=model, \n",
    "                    param_grid=param_grid, \n",
    "                    n_jobs=-1, \n",
    "                    cv=c_v)\n",
    "\n",
    "# run the cross validation\n",
    "xval_result = cv_grid.fit(X, y)\n",
    "\n",
    "# Plot the accuracy \n",
    "acc = [x*100 for x in xval_result.best_estimator_.model.history.history['acc']]\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(acc)\n",
    "ax.set_xlabel('# Epochs', fontsize=16)\n",
    "ax.set_ylabel('% Accuracy', fontsize=16)\n",
    "ax.set_ylim(60,100)\n",
    "ax.axhline(80, color='k', linestyle='--', linewidth=1)\n",
    "ax.axhline(90, color='k', linestyle='--')\n",
    "plt.title('Best Estimator', fontsize=20, y=1.05)\n",
    "plt.show()\n",
    "\n",
    "# Report Results\n",
    "print(f\"Best Cross Validation Score: {xval_result.best_score_:.8f} used {xval_result.best_params_}\\n\")\n",
    "mean_scores = [x*100 for x in grid_result.cv_results_['mean_test_score']]\n",
    "std_scores  = [x*100 for x in grid_result.cv_results_['std_test_score']]\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(mean_scores, std_scorse, params):\n",
    "    print(f\"Means: {mean:.3f}, Stdev: {stdev:.3f} with: {param}\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypertune Batch size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Parameters -----------------------------------------------\n",
    "batch_size = [10, 50, 100, 150, 250, 300]\n",
    "epochs = [20]\n",
    "param_grid = dict(batch_size=batch_size, \n",
    "                  epochs=epochs)\n",
    "# -----------------------------------------------\n",
    "\n",
    "# random seed to reproduce later\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "def create_model(optimizer='adam'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(16, input_dim=13, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# instantiate model obj\n",
    "model = KerasClassifier(build_fn=create_model, verbose=1)\n",
    "\n",
    "# GridSearchCV hyperparameters\n",
    "c_v = StratifiedKFold(n_splits=4,\n",
    "                      shuffle=True,\n",
    "                      random_state=seed) # 4-fold CV\n",
    "\n",
    "# instantiate GridSearchCV obj\n",
    "cv_grid = GridSearchCV(estimator=model, \n",
    "                    param_grid=param_grid, \n",
    "                    n_jobs=-1, \n",
    "                    cv=c_v)\n",
    "\n",
    "# run the cross validation\n",
    "xval_result = cv_grid.fit(X, y)\n",
    "\n",
    "# Plot the accuracy \n",
    "acc = [x*100 for x in xval_result.best_estimator_.model.history.history['acc']]\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(acc)\n",
    "ax.set_xlabel('# Epochs', fontsize=16)\n",
    "ax.set_ylabel('% Accuracy', fontsize=16)\n",
    "ax.set_ylim(60,100)\n",
    "ax.axhline(80, color='k', linestyle='--', linewidth=1)\n",
    "ax.axhline(90, color='k', linestyle='--')\n",
    "plt.title('Best Estimator', fontsize=20, y=1.05)\n",
    "plt.show()\n",
    "\n",
    "# Report Results\n",
    "print(f\"Best Cross Validation Score: {xval_result.best_score_:.8f} used {xval_result.best_params_}\\n\")\n",
    "mean_scores = [x*100 for x in grid_result.cv_results_['mean_test_score']]\n",
    "std_scores  = [x*100 for x in grid_result.cv_results_['std_test_score']]\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(mean_scores, std_scorse, params):\n",
    "    print(f\"Means: {mean:.3f}, Stdev: {stdev:.3f} with: {param}\") "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "DS43SC.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
