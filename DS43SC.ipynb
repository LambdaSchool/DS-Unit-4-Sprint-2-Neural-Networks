{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y6SKlgYrpcym"
   },
   "source": [
    "# Neural Networks Sprint Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BrEbRrjVphPM"
   },
   "source": [
    "## 1) Define the following terms:\n",
    "\n",
    "- Neuron - a node in a network\n",
    "- Input Layer - first layer, receives input from the dataset\n",
    "- Hidden Layer - layers after the input layer, before the output layer. Deep learning is using two or more of these layers\n",
    "- Output Layer - the last layer of a neural network\n",
    "- Activation - function which decides how much signal to pass onto the next layer. Common functions: sigmoid, tanh, step, relu\n",
    "- Backpropagation - used to calculate a gradient needed for the weights used in the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q5EksLqnp4oB"
   },
   "source": [
    " YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ri_gRA2Jp728"
   },
   "source": [
    "## 2) Create a perceptron class that can model the behavior of an AND gate. You can use the following table as your training data:\n",
    "\n",
    "| x1 | x2 | x3 | y |\n",
    "|----|----|----|---|\n",
    "| 1  | 1  | 1  | 1 |\n",
    "| 1  | 0  | 1  | 0 |\n",
    "| 0  | 1  | 1  | 0 |\n",
    "| 0  | 0  | 1  | 0 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ig6ZTH8tpQ19"
   },
   "outputs": [],
   "source": [
    "##### Your Code Here #####\n",
    "import numpy as np\n",
    "\n",
    "inputs = np.array([[1,1,1],\n",
    "                   [1,0,1],\n",
    "                   [0,1,1],\n",
    "                   [0,0,1]])\n",
    "\n",
    "correct_outputs = [[1],\n",
    "                   [0],\n",
    "                   [0],\n",
    "                   [0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Perceptron(object):\n",
    "    def __init__(self, rate = 0.01, niter = 10):\n",
    "        self.rate = rate\n",
    "        self.niter = niter\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit training data\n",
    "        X : Training vectors, X.shape : [#samples, #features]\n",
    "        y : Target values, y.shape : [#samples]\n",
    "        \"\"\"\n",
    "\n",
    "        # weights\n",
    "        self.weight = np.zeros(1 + X.shape[1])\n",
    "\n",
    "        # Number of misclassifications\n",
    "        self.errors = []  # Number of misclassifications\n",
    "\n",
    "        for i in range(self.niter):\n",
    "            err = 0\n",
    "            for xi, target in zip(X, y):\n",
    "                delta_w = self.rate * (target - self.predict(xi))\n",
    "                self.weight[1:] += delta_w * xi\n",
    "                self.weight[0] += delta_w\n",
    "                err += int(delta_w != 0.0)\n",
    "            self.errors.append(err)\n",
    "            return self\n",
    "\n",
    "    def net_input(self, X):\n",
    "        \"\"\"Calculate net input\"\"\"\n",
    "        return np.dot(X, self.weight[1:]) + self.weight[0]\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Return class label after unit step\"\"\"\n",
    "        return np.where(self.net_input(X) >= 0.0, 1, 0)\n",
    "    \n",
    "pn = Perceptron(0.1, 10)\n",
    "pn.fit(inputs, correct_outputs)\n",
    "pn.predict(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "86HyRi8Osr3U"
   },
   "source": [
    "## 3) Implement a Neural Network Multilayer Perceptron class that uses backpropagation to update the network's weights. \n",
    "- Your network must have one hidden layer. \n",
    "- You do not have to update weights via gradient descent. You can use something like the derivative of the sigmoid function to update weights.\n",
    "- Train your model on the Heart Disease dataset from UCI:\n",
    "\n",
    "[Github Dataset](https://github.com/ryanleeallred/datasets/blob/master/heart.csv)\n",
    "\n",
    "[Raw File on Github](https://raw.githubusercontent.com/ryanleeallred/datasets/master/heart.csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CNfiajv3v4Ed"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((303, 13), (303, 1))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Your Code Here #####\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/ryanleeallred/datasets/master/heart.csv')\n",
    "df.head()\n",
    "\n",
    "X = df.drop('target', axis=1)\n",
    "y = df.target\n",
    "\n",
    "X = np.array(X)\n",
    "\n",
    "y=np.array(y)\n",
    "y=np.reshape(y, (303,1))\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neural_Network(object):\n",
    "    def __init__(self):\n",
    "        self.inputs = 13\n",
    "        self.hiddenNodes = 12\n",
    "        self.outputNodes = 1\n",
    "        \n",
    "        # Initialize weights\n",
    "        self.L1_weights = np.random.randn(self.inputs, self.hiddenNodes)\n",
    "        self.L2_weights = np.random.randn(self.hiddenNodes, self.outputNodes)\n",
    "        \n",
    "    def feed_forward(self, X):\n",
    "        # Weighted sum between inputs and hidden layer\n",
    "        self.hidden_sum = np.dot(X, self.L1_weights)\n",
    "        # Activations of weighted sum\n",
    "        self.activated_hidden = self.sigmoid(self.hidden_sum)\n",
    "        # Weighted sum between hidden and output\n",
    "        self.output_sum = np.dot(self.activated_hidden, self.L2_weights)\n",
    "        # final actiavtion of output\n",
    "        self.activated_output = self.sigmoid(self.output_sum)\n",
    "        return self.activated_output\n",
    "    \n",
    "    def sigmoid(self, s):\n",
    "        return 1/(1+np.exp(-s))\n",
    "    \n",
    "    def sigmoidPrime(self, s):\n",
    "        return s * (1-s)\n",
    "    \n",
    "    def backward(self, X, y, o):\n",
    "        # backward propagate through the network\n",
    "        self.o_error = y - o # error in output\n",
    "        self.o_delta = self.o_error*self.sigmoidPrime(o) # applying derivative of sigmoid to error \n",
    "        \n",
    "        self.z2_error = self.o_delta.dot(self.L2_weights.T) # z2 error: how much our hidden layer weights contributed to output error\n",
    "        self.z2_delta = self.z2_error*self.sigmoidPrime(self.activated_hidden) # applying derivative of sigmoid to z2 error\n",
    "        \n",
    "        self.L1_weights += X.T.dot(self.z2_delta)\n",
    "        self.L2_weights += self.activated_hidden.T.dot(self.o_delta) # adjusting second set (hidden --> output) weights\n",
    "    \n",
    "    def train(self, X, y):\n",
    "        o = self.feed_forward(X)\n",
    "        self.backward(X, y, o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35],\n",
       "       [3.82687048e-35]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN = Neural_Network()\n",
    "\n",
    "for _ in range(1000):\n",
    "    NN.train(X, y)\n",
    "NN.feed_forward(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GGT1oRzXw3H9"
   },
   "source": [
    "## 4) Implement a Multilayer Perceptron architecture of your choosing using the Keras library. Train your model and report its baseline accuracy. Then hyperparameter tune at least two parameters and report your model's accuracy. \n",
    "\n",
    "- Use the Heart Disease Dataset (binary classification)\n",
    "- Use an appropriate loss function for a binary classification task\n",
    "- Use an appropriate activation function on the final layer of your network. \n",
    "- Train your model using verbose output for ease of grading.\n",
    "- Use GridSearchCV to hyperparameter tune your model. (for at least two hyperparameters)\n",
    "- When hyperparameter tuning, show you work by adding code cells for each new experiment. \n",
    "- Report the accuracy for each combination of hyperparameters as you test them so that we can easily see which resulted in the highest accuracy.\n",
    "- You must hyperparameter tune at least 5 parameters in order to get a 3 on this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XWw4IYxLxKwH"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joshsolis/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/joshsolis/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/joshsolis/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 16)                224       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 513\n",
      "Trainable params: 513\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "##### Your Code Here #####\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "import numpy as np\n",
    "\n",
    "batch_size = 64\n",
    "num_classes = 1\n",
    "epochs = 50\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(16, activation = 'relu', input_shape=(13,)))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(num_classes, activation='sigmoid'))\n",
    "model.compile(loss='mse', optimizer = 'adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/joshsolis/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 272 samples, validate on 31 samples\n",
      "Epoch 1/50\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X, y, epochs=epochs, validation_split=.1)\n",
    "scores = model.evaluate(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "DS43SC.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
