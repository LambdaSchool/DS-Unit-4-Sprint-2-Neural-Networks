{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD, Adam, Nadam\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y6SKlgYrpcym"
   },
   "source": [
    "# Neural Networks Sprint Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BrEbRrjVphPM"
   },
   "source": [
    "## 1) Define the following terms:\n",
    "\n",
    "- Neuron\n",
    "- Input Layer\n",
    "- Hidden Layer\n",
    "- Output Layer\n",
    "- Activation\n",
    "- Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q5EksLqnp4oB"
   },
   "source": [
    "**Neuron**\n",
    "\n",
    "A 'neuron' is one node in a neural network, inspired by the analogy drawn to biological neurons. In the simplest terms, a neuron receives information from previous nodes in the network, computes an output based on weights given to those pieces of information, and passes on a signal to other nodes via an activation function.\n",
    "\n",
    "**Input Layer**\n",
    "\n",
    "An input layer is the first layer in a standard feed forward neural network. This layer receives information directly from the features in the data, meaning each neuron is fully connected to all input features.\n",
    "\n",
    "**Hidden Layer**\n",
    "\n",
    "Hidden layers lie between the input layer and output layer. Hidden layers are composed of a user-specified number of neurons, and allow neural networks to fit non-linear patterns in data.\n",
    "\n",
    "**Output Layer**\n",
    "\n",
    "The output layer receives information from the last hidden layer (or input layer in the case of a perceptron) and transforms this information into output.\n",
    "\n",
    "The exact functional form of the output layer is determined by the task the network needs to perform. For example, in multi-class classification problems, the output layer generally must use a softmax activation function.\n",
    "\n",
    "**Activation**\n",
    "\n",
    "Activation refers to a function that controls how much 'signal' gets passed from one layer of a neural network to the next. Examples include sigmoid, ReLU, leaky ReLU, linear, etc.\n",
    "\n",
    "**Backpropagation**\n",
    "\n",
    "Backpropagation refers to an algorithm for updating parameters (weights and biases) of neural networks. A common method of backpropagation in gradient descent (or some version of it), in which weights are updated in the inverse direction of the cost function's gradient.\n",
    "\n",
    "This 'updating' is performed from the output layer backwards through the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ri_gRA2Jp728"
   },
   "source": [
    "## 2) Create a perceptron class that can model the behavior of an AND gate. You can use the following table as your training data:\n",
    "\n",
    "| x1 | x2 | x3 | y |\n",
    "|----|----|----|---|\n",
    "| 1  | 1  | 1  | 1 |\n",
    "| 1  | 0  | 1  | 0 |\n",
    "| 0  | 1  | 1  | 0 |\n",
    "| 0  | 0  | 1  | 0 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ig6ZTH8tpQ19"
   },
   "outputs": [],
   "source": [
    "class PerceptronClassifier():\n",
    "    \"\"\"\n",
    "    Basic perceptron class for binary classification\n",
    "    \"\"\"\n",
    "    def __init__(self, learning_rate=0.1, n_iter=100, tolerance=0.000001):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iter = n_iter\n",
    "        self.tolerance = tolerance\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit perceptron to a set of training data using gradient descent\n",
    "        \"\"\"\n",
    "        # initialize weights and cost list\n",
    "        self.weights_ = np.random.uniform(-0.01, 0.01, X.shape[1] + 1)\n",
    "        self.costs_ = []\n",
    "        # iterate until fit is adequate\n",
    "        for i in range(self.n_iter):\n",
    "            preds = self.predict_proba(X)\n",
    "            errors = preds - y\n",
    "            cost = np.sum(errors ** 2)\n",
    "            self.costs_.append(cost)\n",
    "            gradient = np.dot(X.T, errors)\n",
    "            self.weights_[1:] -= self.learning_rate * gradient\n",
    "            self.weights_[0] -= np.mean(errors)\n",
    "            \n",
    "            # break the loop if we are close enough\n",
    "            if cost < self.tolerance:\n",
    "                break\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Computes sigmoid output value given X\n",
    "        \"\"\"\n",
    "        return 1. / (1. + np.exp(-(np.dot(X, self.weights_[1:]) + self.weights_[0])))\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predicts the binary class of X values\n",
    "        \"\"\"\n",
    "        return np.where(self.predict_proba(X)>=0.5, 1, 0)\n",
    "    \n",
    "    def show_loss(self):\n",
    "        \"\"\"\n",
    "        Shows loss along epochs\n",
    "        \"\"\"\n",
    "        try:\n",
    "            iters = range(len(self.costs_))\n",
    "            fig, ax = plt.subplots()\n",
    "            ax.plot(iters, self.costs_)\n",
    "            ax.set_xlabel('Number of Iterations')\n",
    "            ax.set_ylabel('Training Loss (SSE)')\n",
    "            ax.set_title('Training Loss')\n",
    "            plt.show()\n",
    "        except:\n",
    "            print ('Please train me first :)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting NAND Gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([[1,0,1],\n",
    "            [1,1,1],\n",
    "            [0,0,1],\n",
    "            [0,1,1]])\n",
    "y = np.array([1,1,0,0])\n",
    "\n",
    "ppn = PerceptronClassifier(learning_rate = 1.0, n_iter=100)\n",
    "ppn.fit(X, y)\n",
    "ppn.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "86HyRi8Osr3U"
   },
   "source": [
    "## 3) Implement a Neural Network Multilayer Perceptron class that uses backpropagation to update the network's weights. \n",
    "- Your network must have one hidden layer. \n",
    "- You do not have to update weights via gradient descent. You can use something like the derivative of the sigmoid function to update weights.\n",
    "- Train your model on the Heart Disease dataset from UCI:\n",
    "\n",
    "[Github Dataset](https://github.com/ryanleeallred/datasets/blob/master/heart.csv)\n",
    "\n",
    "[Raw File on Github](https://raw.githubusercontent.com/ryanleeallred/datasets/master/heart.csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading data\n",
    "data = pd.read_csv('https://raw.githubusercontent.com/ryanleeallred/datasets/master/heart.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network MLP Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CNfiajv3v4Ed"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "class NeuralNetMLP(object):\n",
    "    \"\"\"\n",
    "    Feed forward nueral network / multi-layer perceptron classifier\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n_hidden : int (default: 30)\n",
    "        Number of hidden units\n",
    "    l2 : float (default 0.)\n",
    "        Lambda value for l2 normalization\n",
    "    epochs : int (default: 100)\n",
    "        Number of training epochs\n",
    "    eta : float (default = 0.001)\n",
    "        Learning rate\n",
    "    shuffle : bool (default: True)\n",
    "        Shuffles the training data every epoch if True\n",
    "    minibatch_size : int (default : 1)\n",
    "        Number of training samples per minibatch\n",
    "    seed : int (default: None)\n",
    "        Random seed for initalizing weights and shuffling\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    eval_ : dict\n",
    "        Dictionary collecting the cost, training accuracy,\n",
    "        and validation accuracy for each epoch during training\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_hidden=30, l2=0.,\n",
    "                epochs=100, eta=0.0001,\n",
    "                shuffle=True, minibatch_size=1, seed=None):\n",
    "        self.random = np.random.RandomState(seed)\n",
    "        self.n_hidden = n_hidden\n",
    "        self.l2 = l2\n",
    "        self.epochs = epochs\n",
    "        self.eta = eta\n",
    "        self.shuffle = shuffle\n",
    "        self.minibatch_size = minibatch_size\n",
    "        \n",
    "    def _onehot(self, y, n_classes):\n",
    "        \"\"\"\n",
    "        Encode labels into one hot representation\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        y : array, shape = [n_samples]\n",
    "            Target values\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        onehot : array, shape = (n_samples, n_labels)\n",
    "        \"\"\"\n",
    "        \n",
    "        onehot = np.zeros((n_classes, y.shape[0]))\n",
    "        for idx, val in enumerate(y.astype(int)):\n",
    "            onehot[val, idx] = 1.\n",
    "        return onehot.T\n",
    "    \n",
    "    def _sigmoid(self, z):\n",
    "        \"\"\"\n",
    "        Compute logistic function (sigmoid)\n",
    "        \"\"\"\n",
    "        return 1. / (1. + np.exp(-np.clip(z, -250, 250)))\n",
    "    \n",
    "    def _forward(self, X):\n",
    "        \"\"\"\n",
    "        Compute forward propogation step\n",
    "        \"\"\"\n",
    "        # step 1: net input of hidden layer\n",
    "        z_h = np.dot(X, self.w_h) + self.b_h\n",
    "        \n",
    "        # step 2: activation of hidden layer\n",
    "        a_h = self._sigmoid(z_h)\n",
    "        \n",
    "        # step 3: net input of output layer\n",
    "        z_out = np.dot(a_h, self.w_out) + self.b_out\n",
    "        \n",
    "        # step 4: activation layer output\n",
    "        a_out = self._sigmoid(z_out)\n",
    "        \n",
    "        return z_h, a_h, z_out, a_out\n",
    "    \n",
    "    def _compute_cost(self, y_enc, output):\n",
    "        \"\"\"\n",
    "        Compute cost function\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        y_enc : array, shape = (n_samples, n_labels)\n",
    "            one-hot encoded class labels\n",
    "        output : array, shape = [n_samples, n_output_units]\n",
    "            Activation of the output layer (forward propoagation)\n",
    "        Returns\n",
    "        -------\n",
    "        cost : float\n",
    "            Regularized cost\n",
    "        \"\"\"\n",
    "        e = 0.000000001\n",
    "        L2_term = (self.l2 *\n",
    "                  (np.sum(self.w_h ** 2.) + \n",
    "                  np.sum(self.w_out ** 2.)))\n",
    "        term1 = -y_enc * (np.log(output + e))\n",
    "        term2 = (1. - y_enc) * np.log(1. - output + e)\n",
    "        cost = np.sum(term1 - term2) + L2_term\n",
    "        return cost\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict class labels\n",
    "        \n",
    "        Paramters\n",
    "        ---------\n",
    "        X : array, shape = [n_samples, n_features]\n",
    "            Input layer with original features\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        y_pred : array, shape = [n_samples]\n",
    "            Predicted class labels\n",
    "        \"\"\"\n",
    "        z_h, a_h, z_out, a_out = self._forward(X)\n",
    "        y_pred = np.argmax(z_out, axis=1)\n",
    "        return y_pred\n",
    "    \n",
    "    def fit(self, X_train, y_train, X_valid, y_valid):\n",
    "        \"\"\"\n",
    "        Learn weights from training data\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X_train : array, shape = [n_samples, n_features]\n",
    "            Input layer with original features\n",
    "        y_train : array, shape = [n_samples]\n",
    "            Target class labels\n",
    "        X_test : array, shape = [n_samples, n_features]\n",
    "            Sample features for validation during training\n",
    "        y_test : array, shape = [n_samples]\n",
    "            Samples test class labels for validation during training\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        self\n",
    "        \"\"\"\n",
    "        n_output = np.unique(y_train).shape[0]\n",
    "        n_features = X_train.shape[1]\n",
    "        \n",
    "        #######################\n",
    "        # Weight Initialization\n",
    "        #######################\n",
    "        \n",
    "        # weights for input -> hidden\n",
    "        self.b_h = np.zeros(self.n_hidden)\n",
    "        self.w_h = self.random.normal(loc=0.0,\n",
    "                                     scale=0.1,\n",
    "                                     size=(n_features,\n",
    "                                          self.n_hidden))\n",
    "        \n",
    "        # weights for hidden -> output\n",
    "        self.b_out = np.zeros(n_output)\n",
    "        self.w_out = self.random.normal(loc=0.0,\n",
    "                                       scale=0.1,\n",
    "                                       size=(self.n_hidden,\n",
    "                                       n_output))\n",
    "        \n",
    "        epoch_strlen = len(str(self.epochs)) # for progr. format\n",
    "        self.eval_ = {'train_cost' : [],\n",
    "                      'val_cost' : [],\n",
    "                     'train_acc' : [],\n",
    "                     'valid_acc' : []}\n",
    "        \n",
    "        y_train_enc = self._onehot(y_train, n_output)\n",
    "        y_valid_enc = self._onehot(y_valid, n_output)\n",
    "        \n",
    "        # iterate over training epochs\n",
    "        for i in range(self.epochs):\n",
    "            \n",
    "            # iterate over mini batches\n",
    "            indices = np.arange(X_train.shape[0])\n",
    "            \n",
    "            if self.shuffle:\n",
    "                self.random.shuffle(indices)\n",
    "            \n",
    "            for start_idx in range(0, indices.shape[0] - self.minibatch_size + 1, self.minibatch_size):\n",
    "                batch_idx = indices[start_idx:start_idx + self.minibatch_size]\n",
    "                \n",
    "                # forward propagation\n",
    "                z_h, a_h, z_out, a_out = self._forward(X_train[batch_idx])\n",
    "                \n",
    "                #################\n",
    "                # Backpropagation\n",
    "                #################\n",
    "                \n",
    "                # [n_samples, n_classlabels]\n",
    "                sigma_out = a_out - y_train_enc[batch_idx]\n",
    "                \n",
    "                # [n_samples, n_hidden]\n",
    "                sigmoid_derivative_h = a_h * (1. - a_h)\n",
    "                \n",
    "                # [n_samples, n_classlabels] dot [n_classlabels, n_hidden]\n",
    "                # -> [n_samples, n_hidden]\n",
    "                sigma_h = (np.dot(sigma_out, self.w_out.T) * sigmoid_derivative_h)\n",
    "                \n",
    "                # [n_features, n_samples] dot [n_samples, n_hidden]\n",
    "                # -> [n_features, n_hidden]\n",
    "                grad_w_h = np.dot(X_train[batch_idx].T, sigma_h)\n",
    "                grad_b_h = np.sum(sigma_h, axis=0)\n",
    "                \n",
    "                # [n_hidden, n_samples] dot [n_samples, n_classlabels]\n",
    "                # -> [n_hidden, n_classlabels]\n",
    "                grad_w_out = np.dot(a_h.T, sigma_out)\n",
    "                grad_b_out = np.sum(sigma_out, axis=0)\n",
    "                \n",
    "                # Regularization and weight updates\n",
    "                delta_w_h = (grad_w_h + self.l2 * self.w_h)\n",
    "                delta_b_h = grad_b_h # bias is not regularized\n",
    "                self.w_h -= self.eta * delta_w_h\n",
    "                self.b_h -= self.eta * delta_b_h\n",
    "                \n",
    "                delta_w_out = grad_w_out + self.l2 * self.w_out\n",
    "                delta_b_out = grad_b_out # bias is not regularized\n",
    "                self.w_out -= self.eta * delta_w_out\n",
    "                self.b_out -= self.eta * delta_b_out\n",
    "                \n",
    "            ############\n",
    "            # Evaluation\n",
    "            ############\n",
    "\n",
    "            # evaluation after each epoch during training\n",
    "            z_h, a_h, z_out, a_out = self._forward(X_train)\n",
    "            z_h_val, a_h_val, z_out_val, a_out_val = self._forward(X_valid)\n",
    "            \n",
    "            cost = self._compute_cost(y_enc=y_train_enc, output=a_out) / a_out.shape[0]\n",
    "            cost_val = self._compute_cost(y_enc=y_valid_enc, output=a_out_val) / a_out_val.shape[0]\n",
    "            \n",
    "            y_train_pred = self.predict(X_train)\n",
    "            y_valid_pred = self.predict(X_valid)\n",
    "            \n",
    "            train_acc = ((np.sum(y_train == y_train_pred)).astype(np.float) / X_train.shape[0])\n",
    "            valid_acc = ((np.sum(y_valid == y_valid_pred)).astype(np.float) / X_valid.shape[0])\n",
    "            \n",
    "            sys.stderr.write('\\r%0*d/%d | Cost: %.2f | Train/Valid Acc: %.2f%%/%.2f%%'\n",
    "                            % (epoch_strlen, i+1, self.epochs, cost, train_acc*100, valid_acc*100))\n",
    "            sys.stderr.flush()\n",
    "            \n",
    "            self.eval_['train_cost'].append(cost)\n",
    "            self.eval_['val_cost'].append(cost_val)\n",
    "            self.eval_['train_acc'].append(train_acc)\n",
    "            self.eval_['valid_acc'].append(valid_acc)\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    def plot_training(self):\n",
    "        \"\"\"\n",
    "        Plots training loss and accuracy\n",
    "        \"\"\"\n",
    "        fig, ax = plt.subplots(ncols=2, figsize=(12,7))\n",
    "        \n",
    "        # plotting loss\n",
    "        ax[0].plot(range(self.epochs), self.eval_['train_cost'], label='Train')\n",
    "        ax[0].plot(range(self.epochs), self.eval_['val_cost'], label='Validation')\n",
    "        ax[0].set_xlabel('Epochs')\n",
    "        ax[0].set_ylabel('Cost')\n",
    "        ax[0].set_title('Training Cost')\n",
    "        ax[0].legend(loc='best')\n",
    "        \n",
    "        ax[1].plot(range(self.epochs), self.eval_['train_acc'], label='Train')\n",
    "        ax[1].plot(range(self.epochs), self.eval_['valid_acc'], label='Validation')\n",
    "        ax[1].set_xlabel('Epochs')\n",
    "        ax[1].set_ylabel('Cost')\n",
    "        ax[1].set_title('Training Accuracy')\n",
    "        ax[0].legend(loc='best')\n",
    "        \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zach/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/zach/anaconda3/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/Users/zach/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "X = data.drop(columns='target')\n",
    "y = data.target\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, \n",
    "                                                  y,\n",
    "                                                 stratify=y)\n",
    "# scale data\n",
    "scale = StandardScaler()\n",
    "X_train = scale.fit_transform(X_train)\n",
    "X_val = scale.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100/100 | Cost: 0.73 | Train/Valid Acc: 86.34%/82.89%"
     ]
    }
   ],
   "source": [
    "mlp = NeuralNetMLP(n_hidden=30,\n",
    "                  eta=0.001)\n",
    "mlp.fit(X_train=X_train, \n",
    "        y_train=y_train.values, \n",
    "        X_valid=X_val, \n",
    "        y_valid=y_val.values);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting training\n",
    "mlp.plot_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GGT1oRzXw3H9"
   },
   "source": [
    "## 4) Implement a Multilayer Perceptron architecture of your choosing using the Keras library. Train your model and report its baseline accuracy. Then hyperparameter tune at least two parameters and report your model's accuracy. \n",
    "\n",
    "- Use the Heart Disease Dataset (binary classification)\n",
    "- Use an appropriate loss function for a binary classification task\n",
    "- Use an appropriate activation function on the final layer of your network. \n",
    "- Train your model using verbose output for ease of grading.\n",
    "- Use GridSearchCV to hyperparameter tune your model. (for at least two hyperparameters)\n",
    "- When hyperparameter tuning, show you work by adding code cells for each new experiment. \n",
    "- Report the accuracy for each combination of hyperparameters as you test them so that we can easily see which resulted in the highest accuracy.\n",
    "- You must hyperparameter tune at least 5 parameters in order to get a 3 on this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XWw4IYxLxKwH"
   },
   "outputs": [],
   "source": [
    "# harness for hyper parameter tuning\n",
    "def create_model(dense_layers=2,\n",
    "                 dense_nodes=5,\n",
    "                 dropout=False,\n",
    "                 dropout_pct=0.0,\n",
    "                 activation='sigmoid',\n",
    "                 weight_initializer='glorot_uniform',\n",
    "                 optimizer=SGD,\n",
    "                 lr=0.0001,\n",
    "                 input_shape=(X_train.shape[1],)):\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    # add input layer\n",
    "    model.add(Dense(dense_nodes, \n",
    "                    input_shape=input_shape,\n",
    "                    kernel_initializer=weight_initializer,\n",
    "                    activation=activation))\n",
    "    \n",
    "    # add dense layers and drop out\n",
    "    for _ in range(dense_layers):\n",
    "        # dense\n",
    "        model.add(Dense(dense_nodes,\n",
    "                        kernel_initializer=weight_initializer,\n",
    "                        activation=activation))\n",
    "        # dropout\n",
    "        if dropout:\n",
    "            model.add(Dropout(rate=dropout_pct))\n",
    "\n",
    "    # add final activation layer\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # optimizer\n",
    "    optimizer=optimizer(lr=lr)\n",
    "    # compile model\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['acc'])\n",
    "              \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zach/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.47577092156536255 using {}\n",
      "Means: 0.47577092156536255, Stdev: 0.08628836569890079 with: {}\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "batch_size = 20\n",
    "\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, \n",
    "                               epochs=epochs,\n",
    "                               batch_size=batch_size,\n",
    "                               verbose=0)\n",
    "\n",
    "# define the grid search parameters\n",
    "param_grid = {}\n",
    "\n",
    "# Create Grid Search\n",
    "grid = GridSearchCV(estimator=model, \n",
    "                    param_grid=param_grid, \n",
    "                    cv=5,\n",
    "                    n_jobs=1)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# Report Results\n",
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning Batch Size and Epochs\n",
    "\n",
    "That was pretty bad, worse than my custom NN above. Let's see if batch size/epochs makes a difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zach/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.581497804643299 using {'batch_size': 10, 'epochs': 30}\n",
      "Means: 0.581497804643299, Stdev: 0.03729396406797063 with: {'batch_size': 10, 'epochs': 30}\n",
      "Means: 0.4669603579369936, Stdev: 0.08331334300258571 with: {'batch_size': 10, 'epochs': 60}\n",
      "Means: 0.47577093279046634, Stdev: 0.08628837365236437 with: {'batch_size': 10, 'epochs': 90}\n",
      "Means: 0.4757709291800528, Stdev: 0.12672989193586745 with: {'batch_size': 20, 'epochs': 30}\n",
      "Means: 0.47577092812975075, Stdev: 0.08628837030581885 with: {'batch_size': 20, 'epochs': 60}\n",
      "Means: 0.4889867910335768, Stdev: 0.08894628178698452 with: {'batch_size': 20, 'epochs': 90}\n",
      "Means: 0.4889867784299514, Stdev: 0.08894628394859308 with: {'batch_size': 40, 'epochs': 30}\n",
      "Means: 0.524229075349375, Stdev: 0.08628838145129525 with: {'batch_size': 40, 'epochs': 60}\n",
      "Means: 0.5462555116625084, Stdev: 0.0767669237337744 with: {'batch_size': 40, 'epochs': 90}\n",
      "Means: 0.4889867905740696, Stdev: 0.08894627777438986 with: {'batch_size': 60, 'epochs': 30}\n",
      "Means: 0.5110132150713043, Stdev: 0.08894628076547172 with: {'batch_size': 60, 'epochs': 60}\n",
      "Means: 0.49779736299871874, Stdev: 0.08959844789503058 with: {'batch_size': 60, 'epochs': 90}\n",
      "Means: 0.5242290792223641, Stdev: 0.08628837628624599 with: {'batch_size': 80, 'epochs': 30}\n",
      "Means: 0.5242290792223641, Stdev: 0.08628837628624599 with: {'batch_size': 80, 'epochs': 60}\n",
      "Means: 0.4537444901098764, Stdev: 0.07676690606166567 with: {'batch_size': 80, 'epochs': 90}\n"
     ]
    }
   ],
   "source": [
    "# define the grid search parameters\n",
    "param_grid = {'batch_size': [10, 20, 40, 60, 80],\n",
    "              'epochs': [30, 60, 90]}\n",
    "\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, \n",
    "                               epochs=epochs,\n",
    "                               batch_size=batch_size,\n",
    "                               verbose=0)\n",
    "\n",
    "# Create Grid Search\n",
    "grid = GridSearchCV(estimator=model, \n",
    "                    param_grid=param_grid, \n",
    "                    cv=5,\n",
    "                    n_jobs=1)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# Report Results\n",
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer\n",
    "\n",
    "Still not very good. I suspect our optimizer/learning rate is poorly specified.\n",
    "\n",
    "Let's try out some different optimizers and learning rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zach/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.7797356754672685 using {'lr': 0.01, 'optimizer': <class 'keras.optimizers.Adam'>}\n",
      "Means: 0.5462555159950047, Stdev: 0.033552196045384924 with: {'lr': 0.01, 'optimizer': <class 'keras.optimizers.SGD'>}\n",
      "Means: 0.7797356754672685, Stdev: 0.01521847293301942 with: {'lr': 0.01, 'optimizer': <class 'keras.optimizers.Adam'>}\n",
      "Means: 0.7665198185370357, Stdev: 0.01514131870576511 with: {'lr': 0.01, 'optimizer': <class 'keras.optimizers.Nadam'>}\n",
      "Means: 0.5242290832922847, Stdev: 0.05175204079553771 with: {'lr': 0.001, 'optimizer': <class 'keras.optimizers.SGD'>}\n",
      "Means: 0.6872246730170061, Stdev: 0.13890650084315634 with: {'lr': 0.001, 'optimizer': <class 'keras.optimizers.Adam'>}\n",
      "Means: 0.5462555159950047, Stdev: 0.033552196045384924 with: {'lr': 0.001, 'optimizer': <class 'keras.optimizers.Nadam'>}\n",
      "Means: 0.4845815081690902, Stdev: 0.05502355653536972 with: {'lr': 0.0001, 'optimizer': <class 'keras.optimizers.SGD'>}\n",
      "Means: 0.5242290832922847, Stdev: 0.05175204079553771 with: {'lr': 0.0001, 'optimizer': <class 'keras.optimizers.Adam'>}\n",
      "Means: 0.5242290832922847, Stdev: 0.05175204079553771 with: {'lr': 0.0001, 'optimizer': <class 'keras.optimizers.Nadam'>}\n",
      "Means: 0.5242290832922847, Stdev: 0.05175204079553771 with: {'lr': 1e-05, 'optimizer': <class 'keras.optimizers.SGD'>}\n",
      "Means: 0.5154185071915782, Stdev: 0.05502355619207511 with: {'lr': 1e-05, 'optimizer': <class 'keras.optimizers.Adam'>}\n",
      "Means: 0.5462555159950047, Stdev: 0.033552196045384924 with: {'lr': 1e-05, 'optimizer': <class 'keras.optimizers.Nadam'>}\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, \n",
    "                               epochs=30,\n",
    "                               batch_size=10,\n",
    "                               verbose=0)\n",
    "\n",
    "# define the grid search parameters\n",
    "param_grid = {'optimizer': [SGD, Adam, Nadam],\n",
    "              'lr': [.01, .001, .0001, .00001]}\n",
    "\n",
    "# Create Grid Search\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# Report Results\n",
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Functions\n",
    "\n",
    "Learning rate and optimizer made a big difference for us! We'll stick with Adam and LR=0.01 from now on.\n",
    "\n",
    "Let's test out a few activation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zach/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.7797356846574119 using {'activation': 'relu', 'lr': 0.01, 'optimizer': <class 'keras.optimizers.Adam'>}\n",
      "Means: 0.7797356762549951, Stdev: 0.00486859543559746 with: {'activation': 'sigmoid', 'lr': 0.01, 'optimizer': <class 'keras.optimizers.Adam'>}\n",
      "Means: 0.7797356775678727, Stdev: 0.013863117810513203 with: {'activation': 'tanh', 'lr': 0.01, 'optimizer': <class 'keras.optimizers.Adam'>}\n",
      "Means: 0.7797356846574119, Stdev: 0.021528095280969405 with: {'activation': 'relu', 'lr': 0.01, 'optimizer': <class 'keras.optimizers.Adam'>}\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, \n",
    "                               epochs=30,\n",
    "                               batch_size=10,\n",
    "                               verbose=0)\n",
    "\n",
    "# define the grid search parameters\n",
    "param_grid = {'activation': ['sigmoid', 'tanh', 'relu'],\n",
    "              'optimizer': [Adam],\n",
    "              'lr': [.01]}\n",
    "\n",
    "# Create Grid Search\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# Report Results\n",
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Weight Initialization\n",
    "\n",
    "Relu seems to give *slightly* better results.\n",
    "\n",
    "Let's look at some different network weight initializations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zach/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.8061673979927265 using {'activation': 'relu', 'lr': 0.01, 'optimizer': <class 'keras.optimizers.Adam'>, 'weight_initializer': 'random_uniform'}\n",
      "Means: 0.7885462541937303, Stdev: 0.045826304959705015 with: {'activation': 'relu', 'lr': 0.01, 'optimizer': <class 'keras.optimizers.Adam'>, 'weight_initializer': 'glorot_uniform'}\n",
      "Means: 0.8061673979927265, Stdev: 0.005033634466795536 with: {'activation': 'relu', 'lr': 0.01, 'optimizer': <class 'keras.optimizers.Adam'>, 'weight_initializer': 'random_uniform'}\n",
      "Means: 0.6916299608704277, Stdev: 0.1123605559438172 with: {'activation': 'relu', 'lr': 0.01, 'optimizer': <class 'keras.optimizers.Adam'>, 'weight_initializer': 'random_normal'}\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, \n",
    "                               epochs=30,\n",
    "                               batch_size=10,\n",
    "                               verbose=0)\n",
    "\n",
    "# define the grid search parameters\n",
    "param_grid = {'weight_initializer': ['glorot_uniform', \n",
    "                                     'random_uniform', \n",
    "                                     'random_normal'],\n",
    "              'activation' : ['relu'],\n",
    "             'optimizer' : [Adam],\n",
    "             'lr' : [0.01]}\n",
    "\n",
    "# Create Grid Search\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# Report Results\n",
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout Regularization\n",
    "\n",
    "Random uniform gave us slightly better results.\n",
    "\n",
    "Let's test out the use of dropout regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/zach/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zach/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.7753303993641018 using {'activation': 'relu', 'dropout': False, 'dropout_pct': 0.2, 'lr': 0.01, 'optimizer': <class 'keras.optimizers.Adam'>, 'weight_initializer': 'random_uniform'}\n",
      "Means: 0.7224669590395453, Stdev: 0.09472069582062491 with: {'activation': 'relu', 'dropout': True, 'dropout_pct': 0.1, 'lr': 0.01, 'optimizer': <class 'keras.optimizers.Adam'>, 'weight_initializer': 'random_uniform'}\n",
      "Means: 0.7709251080315543, Stdev: 0.0337885577851833 with: {'activation': 'relu', 'dropout': True, 'dropout_pct': 0.2, 'lr': 0.01, 'optimizer': <class 'keras.optimizers.Adam'>, 'weight_initializer': 'random_uniform'}\n",
      "Means: 0.7356828185955333, Stdev: 0.10206357915174222 with: {'activation': 'relu', 'dropout': True, 'dropout_pct': 0.3, 'lr': 0.01, 'optimizer': <class 'keras.optimizers.Adam'>, 'weight_initializer': 'random_uniform'}\n",
      "Means: 0.7400881033636925, Stdev: 0.10564713566135996 with: {'activation': 'relu', 'dropout': False, 'dropout_pct': 0.1, 'lr': 0.01, 'optimizer': <class 'keras.optimizers.Adam'>, 'weight_initializer': 'random_uniform'}\n",
      "Means: 0.7753303993641018, Stdev: 0.04910156302727074 with: {'activation': 'relu', 'dropout': False, 'dropout_pct': 0.2, 'lr': 0.01, 'optimizer': <class 'keras.optimizers.Adam'>, 'weight_initializer': 'random_uniform'}\n",
      "Means: 0.7004405264681132, Stdev: 0.11750604853095319 with: {'activation': 'relu', 'dropout': False, 'dropout_pct': 0.3, 'lr': 0.01, 'optimizer': <class 'keras.optimizers.Adam'>, 'weight_initializer': 'random_uniform'}\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, \n",
    "                               epochs=30,\n",
    "                               batch_size=10,\n",
    "                               verbose=0)\n",
    "\n",
    "# define the grid search parameters\n",
    "param_grid = {'dropout' : [True, False],\n",
    "             'dropout_pct' : [0.1, 0.2, 0.3],\n",
    "              'weight_initializer': ['random_uniform'],\n",
    "              'activation' : ['relu'],\n",
    "             'optimizer' : [Adam],\n",
    "             'lr' : [0.01]}\n",
    "\n",
    "# Create Grid Search\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# Report Results\n",
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Neurons in Hidden Layers and Number of Hidden Layers\n",
    "\n",
    "I suspect that dropout may actually be helpful if we add more neurons. I'll re-tune that parameter after we tune the neuron count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zach/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.8149779675290448 using {'activation': 'relu', 'dense_layers': 1, 'dense_nodes': 5, 'lr': 0.01, 'optimizer': <class 'keras.optimizers.Adam'>, 'weight_initializer': 'random_uniform'}\n",
      "Means: 0.8149779675290448, Stdev: 0.021564989582932906 with: {'activation': 'relu', 'dense_layers': 1, 'dense_nodes': 5, 'lr': 0.01, 'optimizer': <class 'keras.optimizers.Adam'>, 'weight_initializer': 'random_uniform'}\n",
      "Means: 0.7665198298277834, Stdev: 0.04742083036873768 with: {'activation': 'relu', 'dense_layers': 1, 'dense_nodes': 10, 'lr': 0.01, 'optimizer': <class 'keras.optimizers.Adam'>, 'weight_initializer': 'random_uniform'}\n",
      "Means: 0.7709251119701873, Stdev: 0.0316753038246943 with: {'activation': 'relu', 'dense_layers': 1, 'dense_nodes': 15, 'lr': 0.01, 'optimizer': <class 'keras.optimizers.Adam'>, 'weight_initializer': 'random_uniform'}\n",
      "Means: 0.8017621137497184, Stdev: 0.02054181555003272 with: {'activation': 'relu', 'dense_layers': 1, 'dense_nodes': 20, 'lr': 0.01, 'optimizer': <class 'keras.optimizers.Adam'>, 'weight_initializer': 'random_uniform'}\n",
      "Means: 0.7753303967383465, Stdev: 0.01800692338194564 with: {'activation': 'relu', 'dense_layers': 1, 'dense_nodes': 25, 'lr': 0.01, 'optimizer': <class 'keras.optimizers.Adam'>, 'weight_initializer': 'random_uniform'}\n",
      "Means: 0.7753303993641018, Stdev: 0.019411428798401256 with: {'activation': 'relu', 'dense_layers': 2, 'dense_nodes': 5, 'lr': 0.01, 'optimizer': <class 'keras.optimizers.Adam'>, 'weight_initializer': 'random_uniform'}\n",
      "Means: 0.7841409694255711, Stdev: 0.00566831506225597 with: {'activation': 'relu', 'dense_layers': 2, 'dense_nodes': 10, 'lr': 0.01, 'optimizer': <class 'keras.optimizers.Adam'>, 'weight_initializer': 'random_uniform'}\n",
      "Means: 0.7797356820316567, Stdev: 0.015218469868713336 with: {'activation': 'relu', 'dense_layers': 2, 'dense_nodes': 15, 'lr': 0.01, 'optimizer': <class 'keras.optimizers.Adam'>, 'weight_initializer': 'random_uniform'}\n",
      "Means: 0.7797356820316567, Stdev: 0.025940380866681288 with: {'activation': 'relu', 'dense_layers': 2, 'dense_nodes': 20, 'lr': 0.01, 'optimizer': <class 'keras.optimizers.Adam'>, 'weight_initializer': 'random_uniform'}\n",
      "Means: 0.7709251098695831, Stdev: 0.03675746354090927 with: {'activation': 'relu', 'dense_layers': 2, 'dense_nodes': 25, 'lr': 0.01, 'optimizer': <class 'keras.optimizers.Adam'>, 'weight_initializer': 'random_uniform'}\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, \n",
    "                               epochs=30,\n",
    "                               batch_size=10,\n",
    "                               verbose=0)\n",
    "\n",
    "# define the grid search parameters\n",
    "param_grid = {'dense_layers' : [1,2],\n",
    "              'dense_nodes' : [5, 10, 15, 20, 25],\n",
    "              'weight_initializer': ['random_uniform'],\n",
    "              'activation' : ['relu'],\n",
    "             'optimizer' : [Adam],\n",
    "             'lr' : [0.01]}\n",
    "\n",
    "# Create Grid Search\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# Report Results\n",
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Best Parameters\n",
    "\n",
    "- Activation : 'relu'\n",
    "- Hidden Layers : 1\n",
    "- Hidden Layer Neurons : 1\n",
    "- Learning Rate : 0.01\n",
    "- Kernel Initializer : 'random_uniform'\n",
    "- Optimizer : Adam\n",
    "\n",
    "However, this all is giving me worse accuracy than the my network from Part III. It could be that my training set is too small for adequate info to be extracted from 3 cross-folds.\n",
    "\n",
    "Let's try one more time with fewer epochs to prevent overfitting, which I suspect will result in better accuracy. now that the other parameters have been tuned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "227/227 [==============================] - 7s 32ms/step - loss: 0.6425 - acc: 0.7577\n",
      "Epoch 2/5\n",
      "227/227 [==============================] - 0s 576us/step - loss: 0.4427 - acc: 0.8194\n",
      "Epoch 3/5\n",
      "227/227 [==============================] - 0s 588us/step - loss: 0.3626 - acc: 0.8458\n",
      "Epoch 4/5\n",
      "227/227 [==============================] - 0s 600us/step - loss: 0.3437 - acc: 0.8546\n",
      "Epoch 5/5\n",
      "227/227 [==============================] - 0s 593us/step - loss: 0.3328 - acc: 0.8590\n",
      "Best: 0.8061674024565104 using {'activation': 'relu', 'dense_layers': 1, 'dense_nodes': 5, 'lr': 0.01, 'optimizer': <class 'keras.optimizers.Adam'>, 'weight_initializer': 'random_uniform'}\n",
      "Means: 0.8061674024565104, Stdev: 0.032070329431680956 with: {'activation': 'relu', 'dense_layers': 1, 'dense_nodes': 5, 'lr': 0.01, 'optimizer': <class 'keras.optimizers.Adam'>, 'weight_initializer': 'random_uniform'}\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, \n",
    "                               epochs=5,\n",
    "                               batch_size=10,\n",
    "                               verbose=1)\n",
    "\n",
    "# define the grid search parameters\n",
    "param_grid = {'dense_layers' : [1],\n",
    "              'dense_nodes' : [5],\n",
    "              'weight_initializer': ['random_uniform'],\n",
    "              'activation' : ['relu'],\n",
    "             'optimizer' : [Adam],\n",
    "             'lr' : [0.01]}\n",
    "\n",
    "# Create Grid Search\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# Report Results\n",
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "DS43SC.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
