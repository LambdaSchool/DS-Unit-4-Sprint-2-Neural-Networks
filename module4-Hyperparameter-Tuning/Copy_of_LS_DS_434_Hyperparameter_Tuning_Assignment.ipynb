{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Ryp-TVm4njD"
   },
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "\n",
    "# Hyperparameter Tuning\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2 Assignment 4*\n",
    "\n",
    "## Your Mission, should you choose to accept it...\n",
    "\n",
    "To hyperparameter tune and extract every ounce of accuracy out of this telecom customer churn dataset: [Available Here](https://lambdaschool-data-science.s3.amazonaws.com/telco-churn/WA_Fn-UseC_-Telco-Customer-Churn+(1).csv)\n",
    "\n",
    "## Requirements\n",
    "\n",
    "- Load the data\n",
    "- Clean the data if necessary (it will be)\n",
    "- Create and fit a baseline Keras MLP model to the data.\n",
    "- Hyperparameter tune (at least) the following parameters:\n",
    " - batch_size\n",
    " - training epochs\n",
    " - optimizer\n",
    " - learning rate (if applicable to optimizer)\n",
    " - momentum (if applicable to optimizer)\n",
    " - activation functions\n",
    " - network weight initialization\n",
    " - dropout regularization\n",
    " - number of neurons in the hidden layer\n",
    " \n",
    " You must use Grid Search and Cross Validation for your initial pass of the above hyperparameters\n",
    " \n",
    " Try and get the maximum accuracy possible out of this data! You'll save big telecoms millions! Doesn't that sound great?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d9aXsIh97WCn"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NNJ-tOBs4jM1"
   },
   "outputs": [],
   "source": [
    "url = \"https://lambdaschool-data-science.s3.amazonaws.com/telco-churn/WA_Fn-UseC_-Telco-Customer-Churn+(1).csv\"\n",
    "\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "colab_type": "code",
    "id": "5_oyxk_97cVI",
    "outputId": "ba007ee2-b783-4c22-d375-48b80fd34ca9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customerID          False\n",
       "gender              False\n",
       "SeniorCitizen       False\n",
       "Partner             False\n",
       "Dependents          False\n",
       "tenure              False\n",
       "PhoneService        False\n",
       "MultipleLines       False\n",
       "InternetService     False\n",
       "OnlineSecurity      False\n",
       "OnlineBackup        False\n",
       "DeviceProtection    False\n",
       "TechSupport         False\n",
       "StreamingTV         False\n",
       "StreamingMovies     False\n",
       "Contract            False\n",
       "PaperlessBilling    False\n",
       "PaymentMethod       False\n",
       "MonthlyCharges      False\n",
       "TotalCharges        False\n",
       "Churn               False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 212
    },
    "colab_type": "code",
    "id": "GGI1DXWC7wP6",
    "outputId": "b2a7035c-cf7b-4429-a5fc-1eec5ade4036"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerID</th>\n",
       "      <th>gender</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>OnlineBackup</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7043</td>\n",
       "      <td>7043</td>\n",
       "      <td>7043</td>\n",
       "      <td>7043</td>\n",
       "      <td>7043</td>\n",
       "      <td>7043</td>\n",
       "      <td>7043</td>\n",
       "      <td>7043</td>\n",
       "      <td>7043</td>\n",
       "      <td>7043</td>\n",
       "      <td>7043</td>\n",
       "      <td>7043</td>\n",
       "      <td>7043</td>\n",
       "      <td>7043</td>\n",
       "      <td>7043</td>\n",
       "      <td>7043</td>\n",
       "      <td>7043</td>\n",
       "      <td>7043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>7043</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6531</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>0899-LIIBW</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td></td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>3555</td>\n",
       "      <td>3641</td>\n",
       "      <td>4933</td>\n",
       "      <td>6361</td>\n",
       "      <td>3390</td>\n",
       "      <td>3096</td>\n",
       "      <td>3498</td>\n",
       "      <td>3088</td>\n",
       "      <td>3095</td>\n",
       "      <td>3473</td>\n",
       "      <td>2810</td>\n",
       "      <td>2785</td>\n",
       "      <td>3875</td>\n",
       "      <td>4171</td>\n",
       "      <td>2365</td>\n",
       "      <td>11</td>\n",
       "      <td>5174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        customerID gender Partner Dependents PhoneService MultipleLines  \\\n",
       "count         7043   7043    7043       7043         7043          7043   \n",
       "unique        7043      2       2          2            2             3   \n",
       "top     0899-LIIBW   Male      No         No          Yes            No   \n",
       "freq             1   3555    3641       4933         6361          3390   \n",
       "\n",
       "       InternetService OnlineSecurity OnlineBackup DeviceProtection  \\\n",
       "count             7043           7043         7043             7043   \n",
       "unique               3              3            3                3   \n",
       "top        Fiber optic             No           No               No   \n",
       "freq              3096           3498         3088             3095   \n",
       "\n",
       "       TechSupport StreamingTV StreamingMovies        Contract  \\\n",
       "count         7043        7043            7043            7043   \n",
       "unique           3           3               3               3   \n",
       "top             No          No              No  Month-to-month   \n",
       "freq          3473        2810            2785            3875   \n",
       "\n",
       "       PaperlessBilling     PaymentMethod TotalCharges Churn  \n",
       "count              7043              7043         7043  7043  \n",
       "unique                2                 4         6531     2  \n",
       "top                 Yes  Electronic check                 No  \n",
       "freq               4171              2365           11  5174  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(exclude='number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "ZgwUgVcI8B6g",
    "outputId": "1d79be05-f51d-4201-abc3-22b17de0b2c0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['No phone service', 'No', 'Yes'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['MultipleLines'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "9h-ojIuK8PFf",
    "outputId": "ad411287-9885-4ddf-e5b9-7399483a2723"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['No', 'Yes', 'No internet service'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['OnlineSecurity'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "id": "tst7fmpg8-81",
    "outputId": "4060e0f4-9a28-4cb3-dce3-70dd67ac8b6f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "           11\n",
       "20.2       11\n",
       "19.75       9\n",
       "19.9        8\n",
       "19.65       8\n",
       "           ..\n",
       "7767.25     1\n",
       "8196.4      1\n",
       "4209.95     1\n",
       "24.6        1\n",
       "2230.85     1\n",
       "Name: TotalCharges, Length: 6531, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['TotalCharges'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j4iC29399It7"
   },
   "outputs": [],
   "source": [
    "df['TotalCharges'] = df['TotalCharges'].replace(' ',0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y_Kgc2Gi9TOl"
   },
   "outputs": [],
   "source": [
    "df['TotalCharges'] = df['TotalCharges'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S_bhGQuwJO4J"
   },
   "outputs": [],
   "source": [
    "df['MonthlyCharges'] = df['MonthlyCharges'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m92-O8OB9sFb"
   },
   "outputs": [],
   "source": [
    "df = df.drop('customerID', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2jsogeriHQxe"
   },
   "outputs": [],
   "source": [
    "df['Churn'] = df['Churn'].replace([\"Yes\", \"No\"], [1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "f_zQDjRf984B",
    "outputId": "cb524640-8d64-412a-cd79-4dfc42ef68e7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "TmkNSjK7_U3g",
    "outputId": "5aee8c6c-b2a9-41a2-de7b-9ea2bfc40ab0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>OnlineBackup</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>34</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>45</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  SeniorCitizen Partner Dependents  tenure PhoneService  \\\n",
       "0  Female              0     Yes         No       1           No   \n",
       "1    Male              0      No         No      34          Yes   \n",
       "2    Male              0      No         No       2          Yes   \n",
       "3    Male              0      No         No      45           No   \n",
       "4  Female              0      No         No       2          Yes   \n",
       "\n",
       "      MultipleLines InternetService OnlineSecurity OnlineBackup  \\\n",
       "0  No phone service             DSL             No          Yes   \n",
       "1                No             DSL            Yes           No   \n",
       "2                No             DSL            Yes          Yes   \n",
       "3  No phone service             DSL            Yes           No   \n",
       "4                No     Fiber optic             No           No   \n",
       "\n",
       "  DeviceProtection TechSupport StreamingTV StreamingMovies        Contract  \\\n",
       "0               No          No          No              No  Month-to-month   \n",
       "1              Yes          No          No              No        One year   \n",
       "2               No          No          No              No  Month-to-month   \n",
       "3              Yes         Yes          No              No        One year   \n",
       "4               No          No          No              No  Month-to-month   \n",
       "\n",
       "  PaperlessBilling              PaymentMethod  MonthlyCharges  TotalCharges  \\\n",
       "0              Yes           Electronic check           29.85         29.85   \n",
       "1               No               Mailed check           56.95       1889.50   \n",
       "2              Yes               Mailed check           53.85        108.15   \n",
       "3               No  Bank transfer (automatic)           42.30       1840.75   \n",
       "4              Yes           Electronic check           70.70        151.65   \n",
       "\n",
       "   Churn  \n",
       "0      0  \n",
       "1      0  \n",
       "2      1  \n",
       "3      0  \n",
       "4      1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jXZI0Vz1BylQ"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "train, test = train_test_split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wMu1fVVz_l1q"
   },
   "outputs": [],
   "source": [
    "X_train = train.drop('Churn', axis=1)\n",
    "y_train = train['Churn']\n",
    "X_test = test.drop('Churn', axis=1)\n",
    "y_test = test['Churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i-NcJcTXCwEj"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['Female', 'Male'], dtype=object),\n",
       " array([0, 1], dtype=int64),\n",
       " array(['No', 'Yes'], dtype=object),\n",
       " array(['No', 'Yes'], dtype=object),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "        34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
       "        51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n",
       "        68, 69, 70, 71, 72], dtype=int64),\n",
       " array(['No', 'Yes'], dtype=object),\n",
       " array(['No', 'No phone service', 'Yes'], dtype=object),\n",
       " array(['DSL', 'Fiber optic', 'No'], dtype=object),\n",
       " array(['No', 'No internet service', 'Yes'], dtype=object),\n",
       " array(['No', 'No internet service', 'Yes'], dtype=object),\n",
       " array(['No', 'No internet service', 'Yes'], dtype=object),\n",
       " array(['No', 'No internet service', 'Yes'], dtype=object),\n",
       " array(['No', 'No internet service', 'Yes'], dtype=object),\n",
       " array(['No', 'No internet service', 'Yes'], dtype=object),\n",
       " array(['Month-to-month', 'One year', 'Two year'], dtype=object),\n",
       " array(['No', 'Yes'], dtype=object),\n",
       " array(['Bank transfer (automatic)', 'Credit card (automatic)',\n",
       "        'Electronic check', 'Mailed check'], dtype=object),\n",
       " array([ 18.25,  18.55,  18.7 , ..., 118.6 , 118.65, 118.75]),\n",
       " array([   0.  ,   18.8 ,   18.85, ..., 8594.4 , 8672.45, 8684.8 ])]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "X_train_encoded = encoder.fit_transform(X_train)\n",
    "X_test_encoded = encoder.transform(X_test)\n",
    "encoder.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Iex_kIjMCkKl"
   },
   "outputs": [],
   "source": [
    "X_train_encoded = X_train_encoded.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "-Sz8VuhGJIA7",
    "outputId": "0312b73a-36a0-478a-b71e-68cb2f4f0db4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5282, 6551)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P08XukltHvER"
   },
   "outputs": [],
   "source": [
    "X_test_encoded = X_test_encoded.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "YB_c0y-DMkBF",
    "outputId": "da4dca79-6be3-45b9-b09b-592ad28b3104"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1761, 6551)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5282,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p1PNtRAd_Mjy"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1280, input_dim=X_train_encoded.shape[1], activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PSSWBcCOBZW1"
   },
   "outputs": [],
   "source": [
    "stop = EarlyStopping(min_delta=0.01, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 685
    },
    "colab_type": "code",
    "id": "mz32flRsBf3d",
    "outputId": "126e7b7d-49a6-448c-91de-626036e3fc85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5282 samples, validate on 1761 samples\n",
      "Epoch 1/100\n",
      "5282/5282 [==============================] - 2s 335us/sample - loss: 0.4456 - accuracy: 0.7808 - val_loss: 0.4335 - val_accuracy: 0.7876\n",
      "Epoch 2/100\n",
      "5282/5282 [==============================] - 1s 268us/sample - loss: 0.3552 - accuracy: 0.8389 - val_loss: 0.4441 - val_accuracy: 0.7797\n",
      "Epoch 3/100\n",
      "5282/5282 [==============================] - 1s 272us/sample - loss: 0.2078 - accuracy: 0.9123 - val_loss: 0.5884 - val_accuracy: 0.7632\n",
      "Epoch 4/100\n",
      "5282/5282 [==============================] - 1s 281us/sample - loss: 0.0801 - accuracy: 0.9680 - val_loss: 0.7303 - val_accuracy: 0.7183\n",
      "Epoch 5/100\n",
      "5282/5282 [==============================] - 1s 274us/sample - loss: 0.0385 - accuracy: 0.9866 - val_loss: 1.0345 - val_accuracy: 0.7087\n",
      "Epoch 6/100\n",
      "5282/5282 [==============================] - 1s 279us/sample - loss: 0.0345 - accuracy: 0.9858 - val_loss: 0.9193 - val_accuracy: 0.7394\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x192117b6148>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_encoded, y_train, epochs=100, validation_data=(X_test_encoded, y_test), callbacks=[stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1280, input_dim=X_train_encoded.shape[1], activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn=create_model, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4225 samples, validate on 1761 samples\n",
      "Epoch 1/20\n",
      "4225/4225 [==============================] - 4s 834us/sample - loss: 0.4510 - accuracy: 0.7792 - val_loss: 0.4389 - val_accuracy: 0.7978\n",
      "Epoch 2/20\n",
      "4225/4225 [==============================] - 3s 778us/sample - loss: 0.3488 - accuracy: 0.8362 - val_loss: 0.4907 - val_accuracy: 0.7763\n",
      "Epoch 3/20\n",
      "4225/4225 [==============================] - 3s 772us/sample - loss: 0.2071 - accuracy: 0.9176 - val_loss: 0.6092 - val_accuracy: 0.7462\n",
      "Epoch 4/20\n",
      "4225/4225 [==============================] - 3s 776us/sample - loss: 0.0745 - accuracy: 0.9718 - val_loss: 0.9037 - val_accuracy: 0.7138\n",
      "Epoch 5/20\n",
      "4225/4225 [==============================] - 3s 772us/sample - loss: 0.0398 - accuracy: 0.9853 - val_loss: 0.9863 - val_accuracy: 0.6848\n",
      "Epoch 6/20\n",
      "4225/4225 [==============================] - 3s 782us/sample - loss: 0.0249 - accuracy: 0.9875 - val_loss: 1.1051 - val_accuracy: 0.7058\n",
      "Epoch 7/20\n",
      "4225/4225 [==============================] - 3s 745us/sample - loss: 0.0243 - accuracy: 0.9903 - val_loss: 1.0238 - val_accuracy: 0.7450\n",
      "Epoch 8/20\n",
      "4225/4225 [==============================] - 3s 776us/sample - loss: 0.0210 - accuracy: 0.9898 - val_loss: 1.1787 - val_accuracy: 0.7422\n",
      "Epoch 9/20\n",
      "4225/4225 [==============================] - 3s 787us/sample - loss: 0.0217 - accuracy: 0.9896 - val_loss: 1.3970 - val_accuracy: 0.6894\n",
      "Epoch 10/20\n",
      "4225/4225 [==============================] - 3s 771us/sample - loss: 0.0349 - accuracy: 0.9844 - val_loss: 1.4963 - val_accuracy: 0.6263\n",
      "Epoch 11/20\n",
      "4225/4225 [==============================] - 3s 800us/sample - loss: 0.0373 - accuracy: 0.9844 - val_loss: 1.2052 - val_accuracy: 0.6979\n",
      "Epoch 12/20\n",
      "4225/4225 [==============================] - 3s 776us/sample - loss: 0.0243 - accuracy: 0.9875 - val_loss: 1.4328 - val_accuracy: 0.7428\n",
      "Epoch 13/20\n",
      "4225/4225 [==============================] - 3s 794us/sample - loss: 0.0152 - accuracy: 0.9920 - val_loss: 1.5927 - val_accuracy: 0.7013\n",
      "Epoch 14/20\n",
      "4225/4225 [==============================] - 3s 776us/sample - loss: 0.0153 - accuracy: 0.9938 - val_loss: 1.3289 - val_accuracy: 0.7246\n",
      "Epoch 15/20\n",
      "4225/4225 [==============================] - 3s 783us/sample - loss: 0.0138 - accuracy: 0.9922 - val_loss: 1.5155 - val_accuracy: 0.7314\n",
      "Epoch 16/20\n",
      "4225/4225 [==============================] - 3s 794us/sample - loss: 0.0277 - accuracy: 0.9896 - val_loss: 1.2793 - val_accuracy: 0.7098\n",
      "Epoch 17/20\n",
      "4225/4225 [==============================] - 3s 779us/sample - loss: 0.0259 - accuracy: 0.9884 - val_loss: 1.4503 - val_accuracy: 0.7206\n",
      "Epoch 18/20\n",
      "4225/4225 [==============================] - 3s 772us/sample - loss: 0.0127 - accuracy: 0.9938 - val_loss: 1.2516 - val_accuracy: 0.6877\n",
      "Epoch 19/20\n",
      "4225/4225 [==============================] - 3s 783us/sample - loss: 0.0107 - accuracy: 0.9948 - val_loss: 1.4569 - val_accuracy: 0.7303\n",
      "Epoch 20/20\n",
      "4225/4225 [==============================] - 3s 780us/sample - loss: 0.0118 - accuracy: 0.9950 - val_loss: 1.4860 - val_accuracy: 0.7269\n",
      "1057/1057 [==============================] - 0s 264us/sample - loss: 1.5316 - accuracy: 0.7379\n",
      "Train on 4225 samples, validate on 1761 samples\n",
      "Epoch 1/20\n",
      "4225/4225 [==============================] - 4s 838us/sample - loss: 0.4445 - accuracy: 0.7822 - val_loss: 0.4402 - val_accuracy: 0.7961\n",
      "Epoch 2/20\n",
      "4225/4225 [==============================] - 3s 788us/sample - loss: 0.3468 - accuracy: 0.8374 - val_loss: 0.4966 - val_accuracy: 0.7819\n",
      "Epoch 3/20\n",
      "4225/4225 [==============================] - 3s 774us/sample - loss: 0.2054 - accuracy: 0.9148 - val_loss: 0.5909 - val_accuracy: 0.7587\n",
      "Epoch 4/20\n",
      "4225/4225 [==============================] - 3s 792us/sample - loss: 0.0887 - accuracy: 0.9695 - val_loss: 0.7327 - val_accuracy: 0.7365\n",
      "Epoch 5/20\n",
      "4225/4225 [==============================] - 3s 782us/sample - loss: 0.0461 - accuracy: 0.9811 - val_loss: 0.8901 - val_accuracy: 0.7223\n",
      "Epoch 6/20\n",
      "4225/4225 [==============================] - 3s 780us/sample - loss: 0.0366 - accuracy: 0.9834 - val_loss: 1.2386 - val_accuracy: 0.7660\n",
      "Epoch 7/20\n",
      "4225/4225 [==============================] - 3s 765us/sample - loss: 0.0307 - accuracy: 0.9865 - val_loss: 1.1273 - val_accuracy: 0.7371\n",
      "Epoch 8/20\n",
      "4225/4225 [==============================] - 3s 774us/sample - loss: 0.0245 - accuracy: 0.9860 - val_loss: 1.2676 - val_accuracy: 0.6826\n",
      "Epoch 9/20\n",
      "4225/4225 [==============================] - 3s 787us/sample - loss: 0.0226 - accuracy: 0.9884 - val_loss: 1.3482 - val_accuracy: 0.7286\n",
      "Epoch 10/20\n",
      "4225/4225 [==============================] - 3s 760us/sample - loss: 0.0375 - accuracy: 0.9830 - val_loss: 1.3936 - val_accuracy: 0.6934\n",
      "Epoch 11/20\n",
      "4225/4225 [==============================] - 3s 792us/sample - loss: 0.0279 - accuracy: 0.9865 - val_loss: 1.5182 - val_accuracy: 0.6695\n",
      "Epoch 12/20\n",
      "4225/4225 [==============================] - 3s 783us/sample - loss: 0.0234 - accuracy: 0.9870 - val_loss: 1.4133 - val_accuracy: 0.7342\n",
      "Epoch 13/20\n",
      "4225/4225 [==============================] - 3s 802us/sample - loss: 0.0262 - accuracy: 0.9882 - val_loss: 1.4477 - val_accuracy: 0.7183\n",
      "Epoch 14/20\n",
      "4225/4225 [==============================] - 3s 768us/sample - loss: 0.0166 - accuracy: 0.9908 - val_loss: 1.4661 - val_accuracy: 0.6871\n",
      "Epoch 15/20\n",
      "4225/4225 [==============================] - 3s 794us/sample - loss: 0.0172 - accuracy: 0.9908 - val_loss: 1.3739 - val_accuracy: 0.7240\n",
      "Epoch 16/20\n",
      "4225/4225 [==============================] - 3s 776us/sample - loss: 0.0165 - accuracy: 0.9924 - val_loss: 1.7202 - val_accuracy: 0.6928\n",
      "Epoch 17/20\n",
      "4225/4225 [==============================] - 3s 760us/sample - loss: 0.0275 - accuracy: 0.9870 - val_loss: 1.6566 - val_accuracy: 0.7416\n",
      "Epoch 18/20\n",
      "4225/4225 [==============================] - 3s 776us/sample - loss: 0.0207 - accuracy: 0.9889 - val_loss: 1.5601 - val_accuracy: 0.7212\n",
      "Epoch 19/20\n",
      "4225/4225 [==============================] - 3s 774us/sample - loss: 0.0141 - accuracy: 0.9920 - val_loss: 1.5194 - val_accuracy: 0.7388\n",
      "Epoch 20/20\n",
      "4225/4225 [==============================] - 3s 787us/sample - loss: 0.0191 - accuracy: 0.9920 - val_loss: 1.7567 - val_accuracy: 0.6917\n",
      "1057/1057 [==============================] - 0s 249us/sample - loss: 1.8548 - accuracy: 0.6840\n",
      "Train on 4226 samples, validate on 1761 samples\n",
      "Epoch 1/20\n",
      "4226/4226 [==============================] - 4s 862us/sample - loss: 0.4517 - accuracy: 0.7795 - val_loss: 0.4345 - val_accuracy: 0.7757\n",
      "Epoch 2/20\n",
      "4226/4226 [==============================] - 3s 776us/sample - loss: 0.3568 - accuracy: 0.8377 - val_loss: 0.4603 - val_accuracy: 0.7785\n",
      "Epoch 3/20\n",
      "4226/4226 [==============================] - 3s 772us/sample - loss: 0.2094 - accuracy: 0.9096 - val_loss: 0.5775 - val_accuracy: 0.7558\n",
      "Epoch 4/20\n",
      "4226/4226 [==============================] - 3s 790us/sample - loss: 0.0896 - accuracy: 0.9650 - val_loss: 0.7954 - val_accuracy: 0.6809\n",
      "Epoch 5/20\n",
      "4226/4226 [==============================] - 3s 794us/sample - loss: 0.0425 - accuracy: 0.9837 - val_loss: 0.8771 - val_accuracy: 0.7490\n",
      "Epoch 6/20\n",
      "4226/4226 [==============================] - 3s 785us/sample - loss: 0.0368 - accuracy: 0.9851 - val_loss: 1.0716 - val_accuracy: 0.7076\n",
      "Epoch 7/20\n",
      "4226/4226 [==============================] - 3s 790us/sample - loss: 0.0231 - accuracy: 0.9910 - val_loss: 1.0211 - val_accuracy: 0.7558\n",
      "Epoch 8/20\n",
      "4226/4226 [==============================] - 3s 756us/sample - loss: 0.0238 - accuracy: 0.9889 - val_loss: 1.2715 - val_accuracy: 0.7513\n",
      "Epoch 9/20\n",
      "4226/4226 [==============================] - 3s 794us/sample - loss: 0.0410 - accuracy: 0.9853 - val_loss: 1.0568 - val_accuracy: 0.7098\n",
      "Epoch 10/20\n",
      "4226/4226 [==============================] - 3s 799us/sample - loss: 0.0193 - accuracy: 0.9908 - val_loss: 1.1382 - val_accuracy: 0.7371\n",
      "Epoch 11/20\n",
      "4226/4226 [==============================] - 3s 767us/sample - loss: 0.0175 - accuracy: 0.9922 - val_loss: 1.3942 - val_accuracy: 0.7286\n",
      "Epoch 12/20\n",
      "4226/4226 [==============================] - 3s 796us/sample - loss: 0.0279 - accuracy: 0.9867 - val_loss: 1.4505 - val_accuracy: 0.6934\n",
      "Epoch 13/20\n",
      "4226/4226 [==============================] - 3s 799us/sample - loss: 0.0168 - accuracy: 0.9917 - val_loss: 1.5925 - val_accuracy: 0.6843\n",
      "Epoch 14/20\n",
      "4226/4226 [==============================] - 3s 783us/sample - loss: 0.0167 - accuracy: 0.9917 - val_loss: 1.3274 - val_accuracy: 0.7683\n",
      "Epoch 15/20\n",
      "4226/4226 [==============================] - 3s 790us/sample - loss: 0.0252 - accuracy: 0.9894 - val_loss: 1.2518 - val_accuracy: 0.7411\n",
      "Epoch 16/20\n",
      "4226/4226 [==============================] - 3s 776us/sample - loss: 0.0162 - accuracy: 0.9929 - val_loss: 1.4195 - val_accuracy: 0.7456\n",
      "Epoch 17/20\n",
      "4226/4226 [==============================] - 3s 754us/sample - loss: 0.0129 - accuracy: 0.9936 - val_loss: 1.5791 - val_accuracy: 0.7172\n",
      "Epoch 18/20\n",
      "4226/4226 [==============================] - 3s 796us/sample - loss: 0.0105 - accuracy: 0.9936 - val_loss: 1.4252 - val_accuracy: 0.7513\n",
      "Epoch 19/20\n",
      "4226/4226 [==============================] - 3s 776us/sample - loss: 0.0106 - accuracy: 0.9938 - val_loss: 1.7272 - val_accuracy: 0.7019\n",
      "Epoch 20/20\n",
      "4226/4226 [==============================] - 3s 754us/sample - loss: 0.0143 - accuracy: 0.9927 - val_loss: 1.6120 - val_accuracy: 0.7399\n",
      "1056/1056 [==============================] - 0s 220us/sample - loss: 1.6039 - accuracy: 0.7273\n",
      "Train on 4226 samples, validate on 1761 samples\n",
      "Epoch 1/20\n",
      "4226/4226 [==============================] - 4s 878us/sample - loss: 0.4513 - accuracy: 0.7797 - val_loss: 0.4466 - val_accuracy: 0.7746\n",
      "Epoch 2/20\n",
      "4226/4226 [==============================] - 3s 803us/sample - loss: 0.3612 - accuracy: 0.8370 - val_loss: 0.4417 - val_accuracy: 0.7973\n",
      "Epoch 3/20\n",
      "4226/4226 [==============================] - 3s 776us/sample - loss: 0.2153 - accuracy: 0.9120 - val_loss: 0.5691 - val_accuracy: 0.7291\n",
      "Epoch 4/20\n",
      "4226/4226 [==============================] - 3s 790us/sample - loss: 0.0850 - accuracy: 0.9685 - val_loss: 0.8979 - val_accuracy: 0.7660\n",
      "Epoch 5/20\n",
      "4226/4226 [==============================] - 3s 799us/sample - loss: 0.0488 - accuracy: 0.9799 - val_loss: 0.8521 - val_accuracy: 0.7172\n",
      "Epoch 6/20\n",
      "4226/4226 [==============================] - 3s 787us/sample - loss: 0.0269 - accuracy: 0.9884 - val_loss: 1.0415 - val_accuracy: 0.7587\n",
      "Epoch 7/20\n",
      "4226/4226 [==============================] - 3s 787us/sample - loss: 0.0231 - accuracy: 0.9877 - val_loss: 1.0987 - val_accuracy: 0.7348\n",
      "Epoch 8/20\n",
      "4226/4226 [==============================] - 3s 759us/sample - loss: 0.0315 - accuracy: 0.9856 - val_loss: 1.1015 - val_accuracy: 0.7144\n",
      "Epoch 9/20\n",
      "4226/4226 [==============================] - 3s 763us/sample - loss: 0.0205 - accuracy: 0.9898 - val_loss: 1.1673 - val_accuracy: 0.7252\n",
      "Epoch 10/20\n",
      "4226/4226 [==============================] - 3s 759us/sample - loss: 0.0497 - accuracy: 0.9830 - val_loss: 1.1655 - val_accuracy: 0.7223\n",
      "Epoch 11/20\n",
      "4226/4226 [==============================] - 3s 768us/sample - loss: 0.0182 - accuracy: 0.9908 - val_loss: 1.3174 - val_accuracy: 0.7002\n",
      "Epoch 12/20\n",
      "4226/4226 [==============================] - 3s 783us/sample - loss: 0.0159 - accuracy: 0.9920 - val_loss: 1.2661 - val_accuracy: 0.7178\n",
      "Epoch 13/20\n",
      "4226/4226 [==============================] - 3s 778us/sample - loss: 0.0143 - accuracy: 0.9931 - val_loss: 1.3217 - val_accuracy: 0.7246\n",
      "Epoch 14/20\n",
      "4226/4226 [==============================] - 3s 788us/sample - loss: 0.0121 - accuracy: 0.9941 - val_loss: 1.3896 - val_accuracy: 0.7354\n",
      "Epoch 15/20\n",
      "4226/4226 [==============================] - 3s 794us/sample - loss: 0.0230 - accuracy: 0.9905 - val_loss: 1.3536 - val_accuracy: 0.7359\n",
      "Epoch 16/20\n",
      "4226/4226 [==============================] - 3s 814us/sample - loss: 0.0243 - accuracy: 0.9870 - val_loss: 1.3905 - val_accuracy: 0.7439\n",
      "Epoch 17/20\n",
      "4226/4226 [==============================] - 3s 783us/sample - loss: 0.0216 - accuracy: 0.9912 - val_loss: 1.4719 - val_accuracy: 0.7070\n",
      "Epoch 18/20\n",
      "4226/4226 [==============================] - 3s 792us/sample - loss: 0.0120 - accuracy: 0.9938 - val_loss: 1.5237 - val_accuracy: 0.7149\n",
      "Epoch 19/20\n",
      "4226/4226 [==============================] - 3s 767us/sample - loss: 0.0110 - accuracy: 0.9946 - val_loss: 1.6526 - val_accuracy: 0.6956\n",
      "Epoch 20/20\n",
      "4226/4226 [==============================] - 3s 779us/sample - loss: 0.0096 - accuracy: 0.9950 - val_loss: 1.9560 - val_accuracy: 0.6905\n",
      "1056/1056 [==============================] - 0s 255us/sample - loss: 2.1267 - accuracy: 0.6733\n",
      "Train on 4226 samples, validate on 1761 samples\n",
      "Epoch 1/20\n",
      "4226/4226 [==============================] - 4s 855us/sample - loss: 0.4472 - accuracy: 0.7795 - val_loss: 0.4268 - val_accuracy: 0.7853\n",
      "Epoch 2/20\n",
      "4226/4226 [==============================] - 3s 765us/sample - loss: 0.3514 - accuracy: 0.8405 - val_loss: 0.4755 - val_accuracy: 0.7871\n",
      "Epoch 3/20\n",
      "4226/4226 [==============================] - 3s 779us/sample - loss: 0.2146 - accuracy: 0.9080 - val_loss: 0.5486 - val_accuracy: 0.7876\n",
      "Epoch 4/20\n",
      "4226/4226 [==============================] - 3s 783us/sample - loss: 0.0930 - accuracy: 0.9636 - val_loss: 0.7593 - val_accuracy: 0.7371\n",
      "Epoch 5/20\n",
      "4226/4226 [==============================] - 3s 783us/sample - loss: 0.0378 - accuracy: 0.9844 - val_loss: 1.0099 - val_accuracy: 0.7547\n",
      "Epoch 6/20\n",
      "4226/4226 [==============================] - 3s 759us/sample - loss: 0.0302 - accuracy: 0.9865 - val_loss: 1.0491 - val_accuracy: 0.7479\n",
      "Epoch 7/20\n",
      "4226/4226 [==============================] - 3s 774us/sample - loss: 0.0273 - accuracy: 0.9875 - val_loss: 1.1369 - val_accuracy: 0.7070\n",
      "Epoch 8/20\n",
      "4226/4226 [==============================] - 3s 792us/sample - loss: 0.0291 - accuracy: 0.9860 - val_loss: 1.5895 - val_accuracy: 0.7564\n",
      "Epoch 9/20\n",
      "4226/4226 [==============================] - 3s 767us/sample - loss: 0.0440 - accuracy: 0.9815 - val_loss: 1.1778 - val_accuracy: 0.7229\n",
      "Epoch 10/20\n",
      "4226/4226 [==============================] - 3s 783us/sample - loss: 0.0226 - accuracy: 0.9886 - val_loss: 1.3133 - val_accuracy: 0.7388\n",
      "Epoch 11/20\n",
      "4226/4226 [==============================] - 3s 794us/sample - loss: 0.0202 - accuracy: 0.9903 - val_loss: 1.2977 - val_accuracy: 0.7399\n",
      "Epoch 12/20\n",
      "4226/4226 [==============================] - 3s 776us/sample - loss: 0.0202 - accuracy: 0.9894 - val_loss: 1.3900 - val_accuracy: 0.7399\n",
      "Epoch 13/20\n",
      "4226/4226 [==============================] - 3s 794us/sample - loss: 0.0265 - accuracy: 0.9884 - val_loss: 1.3982 - val_accuracy: 0.7507\n",
      "Epoch 14/20\n",
      "4226/4226 [==============================] - 3s 770us/sample - loss: 0.0253 - accuracy: 0.9889 - val_loss: 1.4853 - val_accuracy: 0.6854\n",
      "Epoch 15/20\n",
      "4226/4226 [==============================] - 3s 796us/sample - loss: 0.0317 - accuracy: 0.9886 - val_loss: 1.2753 - val_accuracy: 0.7036\n",
      "Epoch 16/20\n",
      "4226/4226 [==============================] - 3s 790us/sample - loss: 0.0150 - accuracy: 0.9927 - val_loss: 1.2196 - val_accuracy: 0.7450\n",
      "Epoch 17/20\n",
      "4226/4226 [==============================] - 3s 783us/sample - loss: 0.0121 - accuracy: 0.9931 - val_loss: 1.3748 - val_accuracy: 0.7325\n",
      "Epoch 18/20\n",
      "4226/4226 [==============================] - 3s 794us/sample - loss: 0.0127 - accuracy: 0.9943 - val_loss: 1.4663 - val_accuracy: 0.7638\n",
      "Epoch 19/20\n",
      "4226/4226 [==============================] - 3s 759us/sample - loss: 0.0171 - accuracy: 0.9924 - val_loss: 1.8161 - val_accuracy: 0.6780\n",
      "Epoch 20/20\n",
      "4226/4226 [==============================] - 3s 761us/sample - loss: 0.0224 - accuracy: 0.9896 - val_loss: 1.5456 - val_accuracy: 0.7445\n",
      "1056/1056 [==============================] - 0s 234us/sample - loss: 1.5049 - accuracy: 0.7472\n",
      "Train on 4225 samples, validate on 1761 samples\n",
      "Epoch 1/20\n",
      "4225/4225 [==============================] - 3s 595us/sample - loss: 0.4471 - accuracy: 0.7839 - val_loss: 0.4275 - val_accuracy: 0.7933\n",
      "Epoch 2/20\n",
      "4225/4225 [==============================] - 2s 435us/sample - loss: 0.3455 - accuracy: 0.8440 - val_loss: 0.4505 - val_accuracy: 0.7729\n",
      "Epoch 3/20\n",
      "4225/4225 [==============================] - 2s 435us/sample - loss: 0.1999 - accuracy: 0.9174 - val_loss: 0.6148 - val_accuracy: 0.7166\n",
      "Epoch 4/20\n",
      "4225/4225 [==============================] - 2s 432us/sample - loss: 0.0736 - accuracy: 0.9747 - val_loss: 0.8638 - val_accuracy: 0.7615\n",
      "Epoch 5/20\n",
      "4225/4225 [==============================] - 2s 435us/sample - loss: 0.0408 - accuracy: 0.9853 - val_loss: 0.9337 - val_accuracy: 0.7524\n",
      "Epoch 6/20\n",
      "4225/4225 [==============================] - 2s 416us/sample - loss: 0.0276 - accuracy: 0.9863 - val_loss: 0.9871 - val_accuracy: 0.7575\n",
      "Epoch 7/20\n",
      "4225/4225 [==============================] - 2s 435us/sample - loss: 0.0212 - accuracy: 0.9917 - val_loss: 1.0286 - val_accuracy: 0.7235\n",
      "Epoch 8/20\n",
      "4225/4225 [==============================] - 2s 427us/sample - loss: 0.0214 - accuracy: 0.9905 - val_loss: 1.1742 - val_accuracy: 0.6979\n",
      "Epoch 9/20\n",
      "4225/4225 [==============================] - 2s 435us/sample - loss: 0.0162 - accuracy: 0.9922 - val_loss: 1.2063 - val_accuracy: 0.7308\n",
      "Epoch 10/20\n",
      "4225/4225 [==============================] - 2s 423us/sample - loss: 0.0146 - accuracy: 0.9936 - val_loss: 1.2470 - val_accuracy: 0.7541\n",
      "Epoch 11/20\n",
      "4225/4225 [==============================] - 2s 415us/sample - loss: 0.0119 - accuracy: 0.9950 - val_loss: 1.2569 - val_accuracy: 0.7365\n",
      "Epoch 12/20\n",
      "4225/4225 [==============================] - 2s 405us/sample - loss: 0.0140 - accuracy: 0.9920 - val_loss: 1.2695 - val_accuracy: 0.7337\n",
      "Epoch 13/20\n",
      "4225/4225 [==============================] - 2s 415us/sample - loss: 0.0137 - accuracy: 0.9922 - val_loss: 1.4431 - val_accuracy: 0.7558\n",
      "Epoch 14/20\n",
      "4225/4225 [==============================] - 2s 420us/sample - loss: 0.0553 - accuracy: 0.9787 - val_loss: 1.4660 - val_accuracy: 0.7030\n",
      "Epoch 15/20\n",
      "4225/4225 [==============================] - 2s 418us/sample - loss: 0.0156 - accuracy: 0.9931 - val_loss: 1.4984 - val_accuracy: 0.6996\n",
      "Epoch 16/20\n",
      "4225/4225 [==============================] - 2s 423us/sample - loss: 0.0122 - accuracy: 0.9938 - val_loss: 1.4232 - val_accuracy: 0.7507\n",
      "Epoch 17/20\n",
      "4225/4225 [==============================] - 2s 423us/sample - loss: 0.0132 - accuracy: 0.9943 - val_loss: 1.3999 - val_accuracy: 0.7087\n",
      "Epoch 18/20\n",
      "4225/4225 [==============================] - 2s 423us/sample - loss: 0.0092 - accuracy: 0.9953 - val_loss: 1.6614 - val_accuracy: 0.6644\n",
      "Epoch 19/20\n",
      "4225/4225 [==============================] - 2s 431us/sample - loss: 0.0081 - accuracy: 0.9964 - val_loss: 1.5911 - val_accuracy: 0.7041\n",
      "Epoch 20/20\n",
      "4225/4225 [==============================] - 2s 435us/sample - loss: 0.0074 - accuracy: 0.9962 - val_loss: 1.6663 - val_accuracy: 0.7183\n",
      "1057/1057 [==============================] - 0s 154us/sample - loss: 1.6975 - accuracy: 0.7219\n",
      "Train on 4225 samples, validate on 1761 samples\n",
      "Epoch 1/20\n",
      "4225/4225 [==============================] - 2s 493us/sample - loss: 0.4451 - accuracy: 0.7884 - val_loss: 0.4226 - val_accuracy: 0.7933\n",
      "Epoch 2/20\n",
      "4225/4225 [==============================] - 2s 431us/sample - loss: 0.3457 - accuracy: 0.8424 - val_loss: 0.4679 - val_accuracy: 0.7615\n",
      "Epoch 3/20\n",
      "4225/4225 [==============================] - 2s 435us/sample - loss: 0.1981 - accuracy: 0.9200 - val_loss: 0.6063 - val_accuracy: 0.7763\n",
      "Epoch 4/20\n",
      "4225/4225 [==============================] - 2s 435us/sample - loss: 0.0834 - accuracy: 0.9673 - val_loss: 0.7571 - val_accuracy: 0.7467\n",
      "Epoch 5/20\n",
      "4225/4225 [==============================] - 2s 420us/sample - loss: 0.0451 - accuracy: 0.9822 - val_loss: 0.9980 - val_accuracy: 0.6695\n",
      "Epoch 6/20\n",
      "4225/4225 [==============================] - 2s 427us/sample - loss: 0.0317 - accuracy: 0.9853 - val_loss: 0.9781 - val_accuracy: 0.7286\n",
      "Epoch 7/20\n",
      "4225/4225 [==============================] - 2s 416us/sample - loss: 0.0226 - accuracy: 0.9879 - val_loss: 0.9495 - val_accuracy: 0.7439\n",
      "Epoch 8/20\n",
      "4225/4225 [==============================] - 2s 435us/sample - loss: 0.0197 - accuracy: 0.9896 - val_loss: 0.9233 - val_accuracy: 0.7394\n",
      "Epoch 9/20\n",
      "4225/4225 [==============================] - 2s 423us/sample - loss: 0.0191 - accuracy: 0.9891 - val_loss: 1.0504 - val_accuracy: 0.7575\n",
      "Epoch 10/20\n",
      "4225/4225 [==============================] - 2s 431us/sample - loss: 0.0172 - accuracy: 0.9917 - val_loss: 1.0741 - val_accuracy: 0.7479\n",
      "Epoch 11/20\n",
      "4225/4225 [==============================] - 2s 423us/sample - loss: 0.0179 - accuracy: 0.9912 - val_loss: 1.0795 - val_accuracy: 0.7467\n",
      "Epoch 12/20\n",
      "4225/4225 [==============================] - 2s 431us/sample - loss: 0.0164 - accuracy: 0.9912 - val_loss: 1.3167 - val_accuracy: 0.6809\n",
      "Epoch 13/20\n",
      "4225/4225 [==============================] - 2s 438us/sample - loss: 0.0177 - accuracy: 0.9912 - val_loss: 1.3145 - val_accuracy: 0.7166\n",
      "Epoch 14/20\n",
      "4225/4225 [==============================] - 2s 436us/sample - loss: 0.0373 - accuracy: 0.9844 - val_loss: 1.3320 - val_accuracy: 0.7541\n",
      "Epoch 15/20\n",
      "4225/4225 [==============================] - 2s 431us/sample - loss: 0.0388 - accuracy: 0.9830 - val_loss: 1.3442 - val_accuracy: 0.7507\n",
      "Epoch 16/20\n",
      "4225/4225 [==============================] - 2s 415us/sample - loss: 0.0281 - accuracy: 0.9872 - val_loss: 1.1988 - val_accuracy: 0.7337\n",
      "Epoch 17/20\n",
      "4225/4225 [==============================] - 2s 427us/sample - loss: 0.0141 - accuracy: 0.9917 - val_loss: 1.3848 - val_accuracy: 0.7172\n",
      "Epoch 18/20\n",
      "4225/4225 [==============================] - 2s 420us/sample - loss: 0.0155 - accuracy: 0.9920 - val_loss: 1.4811 - val_accuracy: 0.6865\n",
      "Epoch 19/20\n",
      "4225/4225 [==============================] - 2s 423us/sample - loss: 0.0122 - accuracy: 0.9948 - val_loss: 1.3078 - val_accuracy: 0.7263\n",
      "Epoch 20/20\n",
      "4225/4225 [==============================] - 2s 420us/sample - loss: 0.0130 - accuracy: 0.9938 - val_loss: 1.3401 - val_accuracy: 0.7473\n",
      "1057/1057 [==============================] - 0s 154us/sample - loss: 1.4583 - accuracy: 0.7398\n",
      "Train on 4226 samples, validate on 1761 samples\n",
      "Epoch 1/20\n",
      "4226/4226 [==============================] - 2s 502us/sample - loss: 0.4471 - accuracy: 0.7802 - val_loss: 0.4313 - val_accuracy: 0.7819\n",
      "Epoch 2/20\n",
      "4226/4226 [==============================] - 2s 423us/sample - loss: 0.3514 - accuracy: 0.8464 - val_loss: 0.4732 - val_accuracy: 0.7967\n",
      "Epoch 3/20\n",
      "4226/4226 [==============================] - 2s 414us/sample - loss: 0.1924 - accuracy: 0.9224 - val_loss: 0.6179 - val_accuracy: 0.7768\n",
      "Epoch 4/20\n",
      "4226/4226 [==============================] - 2s 416us/sample - loss: 0.0681 - accuracy: 0.9744 - val_loss: 0.8952 - val_accuracy: 0.7558\n",
      "Epoch 5/20\n",
      "4226/4226 [==============================] - 2s 427us/sample - loss: 0.0382 - accuracy: 0.9860 - val_loss: 0.9231 - val_accuracy: 0.7422\n",
      "Epoch 6/20\n",
      "4226/4226 [==============================] - 2s 427us/sample - loss: 0.0243 - accuracy: 0.9896 - val_loss: 1.0946 - val_accuracy: 0.6973\n",
      "Epoch 7/20\n",
      "4226/4226 [==============================] - 2s 414us/sample - loss: 0.0253 - accuracy: 0.9901 - val_loss: 1.0352 - val_accuracy: 0.7382\n",
      "Epoch 8/20\n",
      "4226/4226 [==============================] - 2s 416us/sample - loss: 0.0174 - accuracy: 0.9920 - val_loss: 1.1891 - val_accuracy: 0.7371\n",
      "Epoch 9/20\n",
      "4226/4226 [==============================] - 2s 431us/sample - loss: 0.0230 - accuracy: 0.9879 - val_loss: 1.3412 - val_accuracy: 0.7399\n",
      "Epoch 10/20\n",
      "4226/4226 [==============================] - 2s 416us/sample - loss: 0.0212 - accuracy: 0.9905 - val_loss: 1.3193 - val_accuracy: 0.7473\n",
      "Epoch 11/20\n",
      "4226/4226 [==============================] - 2s 423us/sample - loss: 0.0135 - accuracy: 0.9927 - val_loss: 1.4149 - val_accuracy: 0.6939\n",
      "Epoch 12/20\n",
      "4226/4226 [==============================] - 2s 422us/sample - loss: 0.0129 - accuracy: 0.9943 - val_loss: 1.3412 - val_accuracy: 0.7246\n",
      "Epoch 13/20\n",
      "4226/4226 [==============================] - 2s 416us/sample - loss: 0.0112 - accuracy: 0.9943 - val_loss: 1.3595 - val_accuracy: 0.7609\n",
      "Epoch 14/20\n",
      "4226/4226 [==============================] - 2s 431us/sample - loss: 0.0116 - accuracy: 0.9946 - val_loss: 1.4525 - val_accuracy: 0.7132\n",
      "Epoch 15/20\n",
      "4226/4226 [==============================] - 2s 431us/sample - loss: 0.0268 - accuracy: 0.9891 - val_loss: 1.6737 - val_accuracy: 0.6559\n",
      "Epoch 16/20\n",
      "4226/4226 [==============================] - 2s 423us/sample - loss: 0.0317 - accuracy: 0.9870 - val_loss: 1.3221 - val_accuracy: 0.7030\n",
      "Epoch 17/20\n",
      "4226/4226 [==============================] - 2s 416us/sample - loss: 0.0115 - accuracy: 0.9948 - val_loss: 1.6050 - val_accuracy: 0.7513\n",
      "Epoch 18/20\n",
      "4226/4226 [==============================] - 2s 418us/sample - loss: 0.0163 - accuracy: 0.9929 - val_loss: 1.4208 - val_accuracy: 0.7132\n",
      "Epoch 19/20\n",
      "4226/4226 [==============================] - 2s 431us/sample - loss: 0.0101 - accuracy: 0.9948 - val_loss: 1.3620 - val_accuracy: 0.7439\n",
      "Epoch 20/20\n",
      "4226/4226 [==============================] - 2s 416us/sample - loss: 0.0088 - accuracy: 0.9962 - val_loss: 1.4688 - val_accuracy: 0.7456\n",
      "1056/1056 [==============================] - 0s 145us/sample - loss: 1.6284 - accuracy: 0.6989\n",
      "Train on 4226 samples, validate on 1761 samples\n",
      "Epoch 1/20\n",
      "4226/4226 [==============================] - 2s 491us/sample - loss: 0.4524 - accuracy: 0.7769 - val_loss: 0.4236 - val_accuracy: 0.7893\n",
      "Epoch 2/20\n",
      "4226/4226 [==============================] - 2s 426us/sample - loss: 0.3534 - accuracy: 0.8365 - val_loss: 0.4351 - val_accuracy: 0.7961\n",
      "Epoch 3/20\n",
      "4226/4226 [==============================] - 2s 422us/sample - loss: 0.2040 - accuracy: 0.9167 - val_loss: 0.6361 - val_accuracy: 0.7399\n",
      "Epoch 4/20\n",
      "4226/4226 [==============================] - 2s 427us/sample - loss: 0.0910 - accuracy: 0.9657 - val_loss: 0.7310 - val_accuracy: 0.7535\n",
      "Epoch 5/20\n",
      "4226/4226 [==============================] - 2s 416us/sample - loss: 0.0351 - accuracy: 0.9844 - val_loss: 0.8965 - val_accuracy: 0.7308\n",
      "Epoch 6/20\n",
      "4226/4226 [==============================] - 2s 420us/sample - loss: 0.0306 - accuracy: 0.9865 - val_loss: 0.8682 - val_accuracy: 0.7564\n",
      "Epoch 7/20\n",
      "4226/4226 [==============================] - 2s 435us/sample - loss: 0.0206 - accuracy: 0.9896 - val_loss: 0.9938 - val_accuracy: 0.7115\n",
      "Epoch 8/20\n",
      "4226/4226 [==============================] - 2s 431us/sample - loss: 0.0196 - accuracy: 0.9912 - val_loss: 1.0484 - val_accuracy: 0.6882\n",
      "Epoch 9/20\n",
      "4226/4226 [==============================] - 2s 431us/sample - loss: 0.0145 - accuracy: 0.9924 - val_loss: 1.2382 - val_accuracy: 0.7553\n",
      "Epoch 10/20\n",
      "4226/4226 [==============================] - 2s 431us/sample - loss: 0.0213 - accuracy: 0.9896 - val_loss: 1.2283 - val_accuracy: 0.6655\n",
      "Epoch 11/20\n",
      "4226/4226 [==============================] - 2s 423us/sample - loss: 0.0136 - accuracy: 0.9924 - val_loss: 1.1903 - val_accuracy: 0.6797\n",
      "Epoch 12/20\n",
      "4226/4226 [==============================] - 2s 416us/sample - loss: 0.0151 - accuracy: 0.9931 - val_loss: 1.2243 - val_accuracy: 0.7320\n",
      "Epoch 13/20\n",
      "4226/4226 [==============================] - 2s 423us/sample - loss: 0.0173 - accuracy: 0.9917 - val_loss: 1.6410 - val_accuracy: 0.6990\n",
      "Epoch 14/20\n",
      "4226/4226 [==============================] - 2s 434us/sample - loss: 0.0420 - accuracy: 0.9858 - val_loss: 1.3554 - val_accuracy: 0.7110\n",
      "Epoch 15/20\n",
      "4226/4226 [==============================] - 2s 458us/sample - loss: 0.0159 - accuracy: 0.9931 - val_loss: 1.3091 - val_accuracy: 0.7501\n",
      "Epoch 16/20\n",
      "4226/4226 [==============================] - 2s 416us/sample - loss: 0.0265 - accuracy: 0.9884 - val_loss: 1.2578 - val_accuracy: 0.7229\n",
      "Epoch 17/20\n",
      "4226/4226 [==============================] - 2s 418us/sample - loss: 0.0221 - accuracy: 0.9927 - val_loss: 1.4420 - val_accuracy: 0.7541\n",
      "Epoch 18/20\n",
      "4226/4226 [==============================] - 2s 423us/sample - loss: 0.0080 - accuracy: 0.9957 - val_loss: 1.5633 - val_accuracy: 0.7172\n",
      "Epoch 19/20\n",
      "4226/4226 [==============================] - 2s 431us/sample - loss: 0.0075 - accuracy: 0.9967 - val_loss: 1.5080 - val_accuracy: 0.7433\n",
      "Epoch 20/20\n",
      "4226/4226 [==============================] - 2s 456us/sample - loss: 0.0120 - accuracy: 0.9948 - val_loss: 1.4657 - val_accuracy: 0.7467\n",
      "1056/1056 [==============================] - 0s 175us/sample - loss: 1.5390 - accuracy: 0.7254\n",
      "Train on 4226 samples, validate on 1761 samples\n",
      "Epoch 1/20\n",
      "4226/4226 [==============================] - 2s 522us/sample - loss: 0.4524 - accuracy: 0.7802 - val_loss: 0.4274 - val_accuracy: 0.7882\n",
      "Epoch 2/20\n",
      "4226/4226 [==============================] - 2s 420us/sample - loss: 0.3549 - accuracy: 0.8384 - val_loss: 0.4516 - val_accuracy: 0.7853\n",
      "Epoch 3/20\n",
      "4226/4226 [==============================] - 2s 411us/sample - loss: 0.2109 - accuracy: 0.9167 - val_loss: 0.5634 - val_accuracy: 0.7490\n",
      "Epoch 4/20\n",
      "4226/4226 [==============================] - 2s 423us/sample - loss: 0.0821 - accuracy: 0.9673 - val_loss: 0.7766 - val_accuracy: 0.7655\n",
      "Epoch 5/20\n",
      "4226/4226 [==============================] - 2s 412us/sample - loss: 0.0418 - accuracy: 0.9832 - val_loss: 0.8310 - val_accuracy: 0.7394\n",
      "Epoch 6/20\n",
      "4226/4226 [==============================] - 2s 418us/sample - loss: 0.0336 - accuracy: 0.9834 - val_loss: 0.9324 - val_accuracy: 0.7416\n",
      "Epoch 7/20\n",
      "4226/4226 [==============================] - 2s 431us/sample - loss: 0.0254 - accuracy: 0.9879 - val_loss: 0.9423 - val_accuracy: 0.7462\n",
      "Epoch 8/20\n",
      "4226/4226 [==============================] - 2s 416us/sample - loss: 0.0249 - accuracy: 0.9891 - val_loss: 1.1156 - val_accuracy: 0.7076\n",
      "Epoch 9/20\n",
      "4226/4226 [==============================] - 2s 418us/sample - loss: 0.0172 - accuracy: 0.9929 - val_loss: 1.0800 - val_accuracy: 0.7376\n",
      "Epoch 10/20\n",
      "4226/4226 [==============================] - 2s 420us/sample - loss: 0.0180 - accuracy: 0.9903 - val_loss: 1.2174 - val_accuracy: 0.7024\n",
      "Epoch 11/20\n",
      "4226/4226 [==============================] - 2s 420us/sample - loss: 0.0159 - accuracy: 0.9927 - val_loss: 1.1579 - val_accuracy: 0.7331\n",
      "Epoch 12/20\n",
      "4226/4226 [==============================] - 2s 420us/sample - loss: 0.0137 - accuracy: 0.9927 - val_loss: 1.2735 - val_accuracy: 0.7388\n",
      "Epoch 13/20\n",
      "4226/4226 [==============================] - 2s 414us/sample - loss: 0.0161 - accuracy: 0.9927 - val_loss: 1.4698 - val_accuracy: 0.7246\n",
      "Epoch 14/20\n",
      "4226/4226 [==============================] - 2s 427us/sample - loss: 0.0158 - accuracy: 0.9934 - val_loss: 1.4496 - val_accuracy: 0.7553\n",
      "Epoch 15/20\n",
      "4226/4226 [==============================] - 2s 423us/sample - loss: 0.0463 - accuracy: 0.9801 - val_loss: 1.4154 - val_accuracy: 0.6905\n",
      "Epoch 16/20\n",
      "4226/4226 [==============================] - 2s 467us/sample - loss: 0.0158 - accuracy: 0.9927 - val_loss: 1.5362 - val_accuracy: 0.7382\n",
      "Epoch 17/20\n",
      "4226/4226 [==============================] - 2s 455us/sample - loss: 0.0174 - accuracy: 0.9938 - val_loss: 1.4141 - val_accuracy: 0.7450\n",
      "Epoch 18/20\n",
      "4226/4226 [==============================] - 2s 474us/sample - loss: 0.0112 - accuracy: 0.9938 - val_loss: 1.3858 - val_accuracy: 0.7291\n",
      "Epoch 19/20\n",
      "4226/4226 [==============================] - 2s 420us/sample - loss: 0.0091 - accuracy: 0.9953 - val_loss: 1.5125 - val_accuracy: 0.7041\n",
      "Epoch 20/20\n",
      "4226/4226 [==============================] - 2s 418us/sample - loss: 0.0069 - accuracy: 0.9969 - val_loss: 1.6263 - val_accuracy: 0.6973\n",
      "1056/1056 [==============================] - 0s 145us/sample - loss: 1.6034 - accuracy: 0.6979\n",
      "Train on 4225 samples, validate on 1761 samples\n",
      "Epoch 1/20\n",
      "4225/4225 [==============================] - 2s 411us/sample - loss: 0.4497 - accuracy: 0.7792 - val_loss: 0.4297 - val_accuracy: 0.7927\n",
      "Epoch 2/20\n",
      "4225/4225 [==============================] - 1s 254us/sample - loss: 0.3432 - accuracy: 0.8433 - val_loss: 0.4640 - val_accuracy: 0.7876\n",
      "Epoch 3/20\n",
      "4225/4225 [==============================] - 1s 252us/sample - loss: 0.1833 - accuracy: 0.9276 - val_loss: 0.6150 - val_accuracy: 0.7354\n",
      "Epoch 4/20\n",
      "4225/4225 [==============================] - 1s 257us/sample - loss: 0.0642 - accuracy: 0.9794 - val_loss: 0.7750 - val_accuracy: 0.7178\n",
      "Epoch 5/20\n",
      "4225/4225 [==============================] - 1s 250us/sample - loss: 0.0360 - accuracy: 0.9875 - val_loss: 0.8432 - val_accuracy: 0.7553\n",
      "Epoch 6/20\n",
      "4225/4225 [==============================] - 1s 257us/sample - loss: 0.0273 - accuracy: 0.9901 - val_loss: 1.0384 - val_accuracy: 0.7626\n",
      "Epoch 7/20\n",
      "4225/4225 [==============================] - 1s 257us/sample - loss: 0.0221 - accuracy: 0.9903 - val_loss: 0.9480 - val_accuracy: 0.7547\n",
      "Epoch 8/20\n",
      "4225/4225 [==============================] - 1s 256us/sample - loss: 0.0198 - accuracy: 0.9922 - val_loss: 0.9796 - val_accuracy: 0.7240\n",
      "Epoch 9/20\n",
      "4225/4225 [==============================] - 1s 265us/sample - loss: 0.0164 - accuracy: 0.9927 - val_loss: 1.2936 - val_accuracy: 0.6809\n",
      "Epoch 10/20\n",
      "4225/4225 [==============================] - 1s 252us/sample - loss: 0.0179 - accuracy: 0.9934 - val_loss: 1.0867 - val_accuracy: 0.7320\n",
      "Epoch 11/20\n",
      "4225/4225 [==============================] - 1s 254us/sample - loss: 0.0153 - accuracy: 0.9938 - val_loss: 1.0930 - val_accuracy: 0.7121\n",
      "Epoch 12/20\n",
      "4225/4225 [==============================] - 1s 257us/sample - loss: 0.0147 - accuracy: 0.9948 - val_loss: 1.1126 - val_accuracy: 0.7411\n",
      "Epoch 13/20\n",
      "4225/4225 [==============================] - 1s 256us/sample - loss: 0.0143 - accuracy: 0.9946 - val_loss: 1.3696 - val_accuracy: 0.6729\n",
      "Epoch 14/20\n",
      "4225/4225 [==============================] - 1s 250us/sample - loss: 0.0135 - accuracy: 0.9924 - val_loss: 1.2766 - val_accuracy: 0.7030\n",
      "Epoch 15/20\n",
      "4225/4225 [==============================] - 1s 257us/sample - loss: 0.0158 - accuracy: 0.9931 - val_loss: 1.5124 - val_accuracy: 0.6457\n",
      "Epoch 16/20\n",
      "4225/4225 [==============================] - 1s 261us/sample - loss: 0.0252 - accuracy: 0.9896 - val_loss: 1.3239 - val_accuracy: 0.7212\n",
      "Epoch 17/20\n",
      "4225/4225 [==============================] - 1s 248us/sample - loss: 0.0108 - accuracy: 0.9955 - val_loss: 1.4602 - val_accuracy: 0.7507\n",
      "Epoch 18/20\n",
      "4225/4225 [==============================] - 1s 250us/sample - loss: 0.0089 - accuracy: 0.9957 - val_loss: 1.2969 - val_accuracy: 0.7365\n",
      "Epoch 19/20\n",
      "4225/4225 [==============================] - 1s 324us/sample - loss: 0.0087 - accuracy: 0.9964 - val_loss: 1.2493 - val_accuracy: 0.7087\n",
      "Epoch 20/20\n",
      "4225/4225 [==============================] - 1s 246us/sample - loss: 0.0084 - accuracy: 0.9955 - val_loss: 1.5484 - val_accuracy: 0.7518\n",
      "1057/1057 [==============================] - 0s 110us/sample - loss: 1.6159 - accuracy: 0.7436\n",
      "Train on 4225 samples, validate on 1761 samples\n",
      "Epoch 1/20\n",
      "4225/4225 [==============================] - 1s 316us/sample - loss: 0.4398 - accuracy: 0.7853 - val_loss: 0.4200 - val_accuracy: 0.7967\n",
      "Epoch 2/20\n",
      "4225/4225 [==============================] - 1s 261us/sample - loss: 0.3420 - accuracy: 0.8466 - val_loss: 0.4493 - val_accuracy: 0.7871\n",
      "Epoch 3/20\n",
      "4225/4225 [==============================] - 1s 250us/sample - loss: 0.1911 - accuracy: 0.9245 - val_loss: 0.6105 - val_accuracy: 0.7206\n",
      "Epoch 4/20\n",
      "4225/4225 [==============================] - 1s 248us/sample - loss: 0.0786 - accuracy: 0.9695 - val_loss: 0.7196 - val_accuracy: 0.7303\n",
      "Epoch 5/20\n",
      "4225/4225 [==============================] - 1s 250us/sample - loss: 0.0427 - accuracy: 0.9808 - val_loss: 0.8069 - val_accuracy: 0.7632\n",
      "Epoch 6/20\n",
      "4225/4225 [==============================] - 1s 248us/sample - loss: 0.0311 - accuracy: 0.9870 - val_loss: 0.8374 - val_accuracy: 0.7479\n",
      "Epoch 7/20\n",
      "4225/4225 [==============================] - 1s 257us/sample - loss: 0.0252 - accuracy: 0.9903 - val_loss: 0.9732 - val_accuracy: 0.7547\n",
      "Epoch 8/20\n",
      "4225/4225 [==============================] - 1s 250us/sample - loss: 0.0227 - accuracy: 0.9898 - val_loss: 0.9302 - val_accuracy: 0.7331\n",
      "Epoch 9/20\n",
      "4225/4225 [==============================] - 1s 252us/sample - loss: 0.0181 - accuracy: 0.9920 - val_loss: 1.0337 - val_accuracy: 0.7524\n",
      "Epoch 10/20\n",
      "4225/4225 [==============================] - 1s 254us/sample - loss: 0.0190 - accuracy: 0.9889 - val_loss: 1.3522 - val_accuracy: 0.6542\n",
      "Epoch 11/20\n",
      "4225/4225 [==============================] - 1s 254us/sample - loss: 0.0176 - accuracy: 0.9929 - val_loss: 1.0097 - val_accuracy: 0.7450\n",
      "Epoch 12/20\n",
      "4225/4225 [==============================] - 1s 252us/sample - loss: 0.0154 - accuracy: 0.9912 - val_loss: 1.0209 - val_accuracy: 0.7269\n",
      "Epoch 13/20\n",
      "4225/4225 [==============================] - 1s 250us/sample - loss: 0.0141 - accuracy: 0.9929 - val_loss: 1.0805 - val_accuracy: 0.7183\n",
      "Epoch 14/20\n",
      "4225/4225 [==============================] - 1s 254us/sample - loss: 0.0137 - accuracy: 0.9929 - val_loss: 1.0845 - val_accuracy: 0.7144\n",
      "Epoch 15/20\n",
      "4225/4225 [==============================] - 1s 252us/sample - loss: 0.0138 - accuracy: 0.9931 - val_loss: 1.0593 - val_accuracy: 0.7325\n",
      "Epoch 16/20\n",
      "4225/4225 [==============================] - 1s 254us/sample - loss: 0.0112 - accuracy: 0.9938 - val_loss: 1.1113 - val_accuracy: 0.7314\n",
      "Epoch 17/20\n",
      "4225/4225 [==============================] - 1s 248us/sample - loss: 0.0118 - accuracy: 0.9938 - val_loss: 1.3003 - val_accuracy: 0.7098\n",
      "Epoch 18/20\n",
      "4225/4225 [==============================] - 1s 254us/sample - loss: 0.0117 - accuracy: 0.9938 - val_loss: 1.2395 - val_accuracy: 0.7365\n",
      "Epoch 19/20\n",
      "4225/4225 [==============================] - 1s 254us/sample - loss: 0.0109 - accuracy: 0.9943 - val_loss: 1.2138 - val_accuracy: 0.7416\n",
      "Epoch 20/20\n",
      "4225/4225 [==============================] - 1s 252us/sample - loss: 0.0101 - accuracy: 0.9936 - val_loss: 1.2351 - val_accuracy: 0.7303\n",
      "1057/1057 [==============================] - 0s 110us/sample - loss: 1.3327 - accuracy: 0.7114\n",
      "Train on 4226 samples, validate on 1761 samples\n",
      "Epoch 1/20\n",
      "4226/4226 [==============================] - 2s 381us/sample - loss: 0.4537 - accuracy: 0.7776 - val_loss: 0.4307 - val_accuracy: 0.7836\n",
      "Epoch 2/20\n",
      "4226/4226 [==============================] - 1s 250us/sample - loss: 0.3602 - accuracy: 0.8348 - val_loss: 0.4516 - val_accuracy: 0.7871\n",
      "Epoch 3/20\n",
      "4226/4226 [==============================] - 1s 252us/sample - loss: 0.2076 - accuracy: 0.9174 - val_loss: 0.5664 - val_accuracy: 0.7723\n",
      "Epoch 4/20\n",
      "4226/4226 [==============================] - 1s 250us/sample - loss: 0.0725 - accuracy: 0.9749 - val_loss: 0.7613 - val_accuracy: 0.7217\n",
      "Epoch 5/20\n",
      "4226/4226 [==============================] - 1s 257us/sample - loss: 0.0382 - accuracy: 0.9856 - val_loss: 0.8639 - val_accuracy: 0.6865\n",
      "Epoch 6/20\n",
      "4226/4226 [==============================] - 1s 248us/sample - loss: 0.0294 - accuracy: 0.9901 - val_loss: 0.8275 - val_accuracy: 0.7632\n",
      "Epoch 7/20\n",
      "4226/4226 [==============================] - 1s 248us/sample - loss: 0.0208 - accuracy: 0.9912 - val_loss: 1.0464 - val_accuracy: 0.7041\n",
      "Epoch 8/20\n",
      "4226/4226 [==============================] - 1s 241us/sample - loss: 0.0168 - accuracy: 0.9929 - val_loss: 0.9170 - val_accuracy: 0.7450\n",
      "Epoch 9/20\n",
      "4226/4226 [==============================] - 1s 245us/sample - loss: 0.0126 - accuracy: 0.9938 - val_loss: 1.0637 - val_accuracy: 0.7212\n",
      "Epoch 10/20\n",
      "4226/4226 [==============================] - 1s 241us/sample - loss: 0.0137 - accuracy: 0.9936 - val_loss: 1.0066 - val_accuracy: 0.7422\n",
      "Epoch 11/20\n",
      "4226/4226 [==============================] - 1s 250us/sample - loss: 0.0116 - accuracy: 0.9948 - val_loss: 1.2397 - val_accuracy: 0.7195\n",
      "Epoch 12/20\n",
      "4226/4226 [==============================] - 1s 248us/sample - loss: 0.0122 - accuracy: 0.9948 - val_loss: 1.0982 - val_accuracy: 0.7405\n",
      "Epoch 13/20\n",
      "4226/4226 [==============================] - 1s 254us/sample - loss: 0.0129 - accuracy: 0.9936 - val_loss: 1.0559 - val_accuracy: 0.7496\n",
      "Epoch 14/20\n",
      "4226/4226 [==============================] - 1s 245us/sample - loss: 0.0110 - accuracy: 0.9960 - val_loss: 1.1590 - val_accuracy: 0.7592\n",
      "Epoch 15/20\n",
      "4226/4226 [==============================] - 1s 250us/sample - loss: 0.0114 - accuracy: 0.9950 - val_loss: 1.1582 - val_accuracy: 0.7558\n",
      "Epoch 16/20\n",
      "4226/4226 [==============================] - 1s 254us/sample - loss: 0.0072 - accuracy: 0.9965 - val_loss: 1.2298 - val_accuracy: 0.7217\n",
      "Epoch 17/20\n",
      "4226/4226 [==============================] - 1s 245us/sample - loss: 0.0063 - accuracy: 0.9974 - val_loss: 1.2458 - val_accuracy: 0.7354\n",
      "Epoch 18/20\n",
      "4226/4226 [==============================] - 1s 250us/sample - loss: 0.0081 - accuracy: 0.9962 - val_loss: 1.2089 - val_accuracy: 0.7189\n",
      "Epoch 19/20\n",
      "4226/4226 [==============================] - 1s 252us/sample - loss: 0.0077 - accuracy: 0.9967 - val_loss: 1.2756 - val_accuracy: 0.7717\n",
      "Epoch 20/20\n",
      "4226/4226 [==============================] - 1s 250us/sample - loss: 0.0090 - accuracy: 0.9955 - val_loss: 1.4662 - val_accuracy: 0.7229\n",
      "1056/1056 [==============================] - 0s 125us/sample - loss: 1.6425 - accuracy: 0.6979\n",
      "Train on 4226 samples, validate on 1761 samples\n",
      "Epoch 1/20\n",
      "4226/4226 [==============================] - 2s 374us/sample - loss: 0.4573 - accuracy: 0.7667 - val_loss: 0.4340 - val_accuracy: 0.7836\n",
      "Epoch 2/20\n",
      "4226/4226 [==============================] - 1s 266us/sample - loss: 0.3621 - accuracy: 0.8336 - val_loss: 0.4355 - val_accuracy: 0.7956\n",
      "Epoch 3/20\n",
      "4226/4226 [==============================] - 1s 292us/sample - loss: 0.2227 - accuracy: 0.9065 - val_loss: 0.5575 - val_accuracy: 0.7808\n",
      "Epoch 4/20\n",
      "4226/4226 [==============================] - 1s 285us/sample - loss: 0.0830 - accuracy: 0.9723 - val_loss: 0.7309 - val_accuracy: 0.7501\n",
      "Epoch 5/20\n",
      "4226/4226 [==============================] - 1s 277us/sample - loss: 0.0372 - accuracy: 0.9872 - val_loss: 0.8108 - val_accuracy: 0.7575\n",
      "Epoch 6/20\n",
      "4226/4226 [==============================] - 1s 272us/sample - loss: 0.0291 - accuracy: 0.9889 - val_loss: 0.8931 - val_accuracy: 0.7729\n",
      "Epoch 7/20\n",
      "4226/4226 [==============================] - 1s 274us/sample - loss: 0.0266 - accuracy: 0.9894 - val_loss: 0.9355 - val_accuracy: 0.7439\n",
      "Epoch 8/20\n",
      "4226/4226 [==============================] - 1s 268us/sample - loss: 0.0198 - accuracy: 0.9898 - val_loss: 0.9920 - val_accuracy: 0.7621\n",
      "Epoch 9/20\n",
      "4226/4226 [==============================] - 1s 250us/sample - loss: 0.0167 - accuracy: 0.9910 - val_loss: 1.0755 - val_accuracy: 0.6951\n",
      "Epoch 10/20\n",
      "4226/4226 [==============================] - 1s 252us/sample - loss: 0.0202 - accuracy: 0.9917 - val_loss: 1.0109 - val_accuracy: 0.7325\n",
      "Epoch 11/20\n",
      "4226/4226 [==============================] - 1s 254us/sample - loss: 0.0164 - accuracy: 0.9924 - val_loss: 1.0244 - val_accuracy: 0.7524\n",
      "Epoch 12/20\n",
      "4226/4226 [==============================] - 1s 265us/sample - loss: 0.0123 - accuracy: 0.9941 - val_loss: 1.1398 - val_accuracy: 0.7683\n",
      "Epoch 13/20\n",
      "4226/4226 [==============================] - 1s 261us/sample - loss: 0.0105 - accuracy: 0.9962 - val_loss: 1.0601 - val_accuracy: 0.7524\n",
      "Epoch 14/20\n",
      "4226/4226 [==============================] - 1s 257us/sample - loss: 0.0110 - accuracy: 0.9950 - val_loss: 1.1246 - val_accuracy: 0.7405\n",
      "Epoch 15/20\n",
      "4226/4226 [==============================] - 1s 250us/sample - loss: 0.0103 - accuracy: 0.9938 - val_loss: 1.1851 - val_accuracy: 0.6792\n",
      "Epoch 16/20\n",
      "4226/4226 [==============================] - 1s 254us/sample - loss: 0.0119 - accuracy: 0.9953 - val_loss: 1.3512 - val_accuracy: 0.6962\n",
      "Epoch 17/20\n",
      "4226/4226 [==============================] - 1s 285us/sample - loss: 0.0080 - accuracy: 0.9960 - val_loss: 1.3214 - val_accuracy: 0.7047\n",
      "Epoch 18/20\n",
      "4226/4226 [==============================] - 1s 256us/sample - loss: 0.0068 - accuracy: 0.9965 - val_loss: 1.3046 - val_accuracy: 0.7189\n",
      "Epoch 19/20\n",
      "4226/4226 [==============================] - 1s 250us/sample - loss: 0.0097 - accuracy: 0.9955 - val_loss: 1.1938 - val_accuracy: 0.7535\n",
      "Epoch 20/20\n",
      "4226/4226 [==============================] - 1s 257us/sample - loss: 0.0086 - accuracy: 0.9969 - val_loss: 1.2238 - val_accuracy: 0.7422\n",
      "1056/1056 [==============================] - 0s 110us/sample - loss: 1.3990 - accuracy: 0.7150\n",
      "Train on 4226 samples, validate on 1761 samples\n",
      "Epoch 1/20\n",
      "4226/4226 [==============================] - 1s 328us/sample - loss: 0.4522 - accuracy: 0.7709 - val_loss: 0.4260 - val_accuracy: 0.7853\n",
      "Epoch 2/20\n",
      "4226/4226 [==============================] - 1s 252us/sample - loss: 0.3456 - accuracy: 0.8415 - val_loss: 0.5052 - val_accuracy: 0.7484\n",
      "Epoch 3/20\n",
      "4226/4226 [==============================] - 1s 246us/sample - loss: 0.2005 - accuracy: 0.9179 - val_loss: 0.6362 - val_accuracy: 0.7178\n",
      "Epoch 4/20\n",
      "4226/4226 [==============================] - 1s 252us/sample - loss: 0.0828 - accuracy: 0.9702 - val_loss: 0.6559 - val_accuracy: 0.7553\n",
      "Epoch 5/20\n",
      "4226/4226 [==============================] - 1s 257us/sample - loss: 0.0426 - accuracy: 0.9834 - val_loss: 0.8082 - val_accuracy: 0.7541\n",
      "Epoch 6/20\n",
      "4226/4226 [==============================] - 1s 250us/sample - loss: 0.0339 - accuracy: 0.9865 - val_loss: 0.8738 - val_accuracy: 0.7058\n",
      "Epoch 7/20\n",
      "4226/4226 [==============================] - 1s 241us/sample - loss: 0.0229 - accuracy: 0.9898 - val_loss: 0.9089 - val_accuracy: 0.7575\n",
      "Epoch 8/20\n",
      "4226/4226 [==============================] - 1s 241us/sample - loss: 0.0209 - accuracy: 0.9905 - val_loss: 0.8708 - val_accuracy: 0.7570\n",
      "Epoch 9/20\n",
      "4226/4226 [==============================] - 1s 254us/sample - loss: 0.0206 - accuracy: 0.9903 - val_loss: 1.0133 - val_accuracy: 0.7484\n",
      "Epoch 10/20\n",
      "4226/4226 [==============================] - 1s 257us/sample - loss: 0.0142 - accuracy: 0.9927 - val_loss: 1.1190 - val_accuracy: 0.7507\n",
      "Epoch 11/20\n",
      "4226/4226 [==============================] - 1s 245us/sample - loss: 0.0168 - accuracy: 0.9929 - val_loss: 1.1063 - val_accuracy: 0.7206\n",
      "Epoch 12/20\n",
      "4226/4226 [==============================] - 1s 254us/sample - loss: 0.0127 - accuracy: 0.9934 - val_loss: 1.2272 - val_accuracy: 0.7013\n",
      "Epoch 13/20\n",
      "4226/4226 [==============================] - 1s 254us/sample - loss: 0.0139 - accuracy: 0.9936 - val_loss: 1.2981 - val_accuracy: 0.7269\n",
      "Epoch 14/20\n",
      "4226/4226 [==============================] - 1s 248us/sample - loss: 0.0128 - accuracy: 0.9941 - val_loss: 1.1796 - val_accuracy: 0.7115\n",
      "Epoch 15/20\n",
      "4226/4226 [==============================] - 1s 241us/sample - loss: 0.0102 - accuracy: 0.9946 - val_loss: 1.1783 - val_accuracy: 0.7320\n",
      "Epoch 16/20\n",
      "4226/4226 [==============================] - 1s 243us/sample - loss: 0.0109 - accuracy: 0.9943 - val_loss: 1.2378 - val_accuracy: 0.7002\n",
      "Epoch 17/20\n",
      "4226/4226 [==============================] - 1s 252us/sample - loss: 0.0079 - accuracy: 0.9962 - val_loss: 1.2464 - val_accuracy: 0.7467\n",
      "Epoch 18/20\n",
      "4226/4226 [==============================] - 1s 261us/sample - loss: 0.0090 - accuracy: 0.9960 - val_loss: 1.1758 - val_accuracy: 0.7518\n",
      "Epoch 19/20\n",
      "4226/4226 [==============================] - 1s 266us/sample - loss: 0.0104 - accuracy: 0.9950 - val_loss: 1.2966 - val_accuracy: 0.7405\n",
      "Epoch 20/20\n",
      "4226/4226 [==============================] - 1s 259us/sample - loss: 0.0144 - accuracy: 0.9931 - val_loss: 1.7044 - val_accuracy: 0.7570\n",
      "1056/1056 [==============================] - 0s 125us/sample - loss: 1.6769 - accuracy: 0.7481\n",
      "Train on 4225 samples, validate on 1761 samples\n",
      "Epoch 1/20\n",
      "4225/4225 [==============================] - 1s 260us/sample - loss: 0.4596 - accuracy: 0.7702 - val_loss: 0.4330 - val_accuracy: 0.7802\n",
      "Epoch 2/20\n",
      "4225/4225 [==============================] - 1s 181us/sample - loss: 0.3574 - accuracy: 0.8331 - val_loss: 0.4653 - val_accuracy: 0.7700\n",
      "Epoch 3/20\n",
      "4225/4225 [==============================] - 1s 186us/sample - loss: 0.2119 - accuracy: 0.9146 - val_loss: 0.5778 - val_accuracy: 0.7575\n",
      "Epoch 4/20\n",
      "4225/4225 [==============================] - 1s 182us/sample - loss: 0.0748 - accuracy: 0.9740 - val_loss: 0.7150 - val_accuracy: 0.7286\n",
      "Epoch 5/20\n",
      "4225/4225 [==============================] - 1s 194us/sample - loss: 0.0384 - accuracy: 0.9867 - val_loss: 0.8215 - val_accuracy: 0.7138\n",
      "Epoch 6/20\n",
      "4225/4225 [==============================] - 1s 205us/sample - loss: 0.0300 - accuracy: 0.9889 - val_loss: 0.9599 - val_accuracy: 0.7053\n",
      "Epoch 7/20\n",
      "4225/4225 [==============================] - 1s 188us/sample - loss: 0.0218 - accuracy: 0.9924 - val_loss: 0.9464 - val_accuracy: 0.7484\n",
      "Epoch 8/20\n",
      "4225/4225 [==============================] - 1s 199us/sample - loss: 0.0235 - accuracy: 0.9905 - val_loss: 0.9112 - val_accuracy: 0.7484\n",
      "Epoch 9/20\n",
      "4225/4225 [==============================] - 1s 201us/sample - loss: 0.0142 - accuracy: 0.9943 - val_loss: 0.9890 - val_accuracy: 0.7058\n",
      "Epoch 10/20\n",
      "4225/4225 [==============================] - 1s 199us/sample - loss: 0.0138 - accuracy: 0.9934 - val_loss: 1.0167 - val_accuracy: 0.6962\n",
      "Epoch 11/20\n",
      "4225/4225 [==============================] - 1s 214us/sample - loss: 0.0137 - accuracy: 0.9922 - val_loss: 0.9966 - val_accuracy: 0.7195\n",
      "Epoch 12/20\n",
      "4225/4225 [==============================] - 1s 214us/sample - loss: 0.0118 - accuracy: 0.9943 - val_loss: 1.0230 - val_accuracy: 0.7314\n",
      "Epoch 13/20\n",
      "4225/4225 [==============================] - 1s 217us/sample - loss: 0.0126 - accuracy: 0.9943 - val_loss: 1.2438 - val_accuracy: 0.6689\n",
      "Epoch 14/20\n",
      "4225/4225 [==============================] - 1s 197us/sample - loss: 0.0175 - accuracy: 0.9929 - val_loss: 1.0602 - val_accuracy: 0.7445\n",
      "Epoch 15/20\n",
      "4225/4225 [==============================] - 1s 206us/sample - loss: 0.0126 - accuracy: 0.9948 - val_loss: 1.1650 - val_accuracy: 0.7178\n",
      "Epoch 16/20\n",
      "4225/4225 [==============================] - 1s 206us/sample - loss: 0.0101 - accuracy: 0.9955 - val_loss: 1.4116 - val_accuracy: 0.7553\n",
      "Epoch 17/20\n",
      "4225/4225 [==============================] - 1s 212us/sample - loss: 0.0120 - accuracy: 0.9948 - val_loss: 1.1812 - val_accuracy: 0.7496\n",
      "Epoch 18/20\n",
      "4225/4225 [==============================] - 1s 190us/sample - loss: 0.0100 - accuracy: 0.9955 - val_loss: 1.1765 - val_accuracy: 0.7376\n",
      "Epoch 19/20\n",
      "4225/4225 [==============================] - 1s 186us/sample - loss: 0.0088 - accuracy: 0.9950 - val_loss: 1.2823 - val_accuracy: 0.7433\n",
      "Epoch 20/20\n",
      "4225/4225 [==============================] - 1s 182us/sample - loss: 0.0081 - accuracy: 0.9969 - val_loss: 1.2937 - val_accuracy: 0.6843\n",
      "1057/1057 [==============================] - 0s 95us/sample - loss: 1.3474 - accuracy: 0.6925\n",
      "Train on 4225 samples, validate on 1761 samples\n",
      "Epoch 1/20\n",
      "4225/4225 [==============================] - 1s 267us/sample - loss: 0.4511 - accuracy: 0.7789 - val_loss: 0.4240 - val_accuracy: 0.7933\n",
      "Epoch 2/20\n",
      "4225/4225 [==============================] - 1s 197us/sample - loss: 0.3426 - accuracy: 0.8447 - val_loss: 0.4676 - val_accuracy: 0.7694\n",
      "Epoch 3/20\n",
      "4225/4225 [==============================] - 1s 190us/sample - loss: 0.2053 - accuracy: 0.9205 - val_loss: 0.5555 - val_accuracy: 0.7666\n",
      "Epoch 4/20\n",
      "4225/4225 [==============================] - 1s 186us/sample - loss: 0.0854 - accuracy: 0.9714 - val_loss: 0.7107 - val_accuracy: 0.7535\n",
      "Epoch 5/20\n",
      "4225/4225 [==============================] - 1s 186us/sample - loss: 0.0454 - accuracy: 0.9837 - val_loss: 0.7551 - val_accuracy: 0.7274\n",
      "Epoch 6/20\n",
      "4225/4225 [==============================] - 1s 194us/sample - loss: 0.0292 - accuracy: 0.9875 - val_loss: 0.7815 - val_accuracy: 0.7473\n",
      "Epoch 7/20\n",
      "4225/4225 [==============================] - 1s 182us/sample - loss: 0.0259 - accuracy: 0.9872 - val_loss: 0.8364 - val_accuracy: 0.7166\n",
      "Epoch 8/20\n",
      "4225/4225 [==============================] - 1s 186us/sample - loss: 0.0287 - accuracy: 0.9879 - val_loss: 0.9991 - val_accuracy: 0.6854\n",
      "Epoch 9/20\n",
      "4225/4225 [==============================] - 1s 186us/sample - loss: 0.0240 - accuracy: 0.9891 - val_loss: 0.8431 - val_accuracy: 0.7399\n",
      "Epoch 10/20\n",
      "4225/4225 [==============================] - 1s 186us/sample - loss: 0.0201 - accuracy: 0.9917 - val_loss: 0.9097 - val_accuracy: 0.7518\n",
      "Epoch 11/20\n",
      "4225/4225 [==============================] - 1s 190us/sample - loss: 0.0162 - accuracy: 0.9915 - val_loss: 0.8589 - val_accuracy: 0.7445\n",
      "Epoch 12/20\n",
      "4225/4225 [==============================] - 1s 214us/sample - loss: 0.0179 - accuracy: 0.9922 - val_loss: 0.9004 - val_accuracy: 0.7598\n",
      "Epoch 13/20\n",
      "4225/4225 [==============================] - 1s 205us/sample - loss: 0.0153 - accuracy: 0.9936 - val_loss: 1.0010 - val_accuracy: 0.7456\n",
      "Epoch 14/20\n",
      "4225/4225 [==============================] - 1s 182us/sample - loss: 0.0157 - accuracy: 0.9931 - val_loss: 0.9380 - val_accuracy: 0.7212\n",
      "Epoch 15/20\n",
      "4225/4225 [==============================] - 1s 190us/sample - loss: 0.0134 - accuracy: 0.9936 - val_loss: 0.9831 - val_accuracy: 0.7445\n",
      "Epoch 16/20\n",
      "4225/4225 [==============================] - 1s 199us/sample - loss: 0.0132 - accuracy: 0.9936 - val_loss: 0.9680 - val_accuracy: 0.7428\n",
      "Epoch 17/20\n",
      "4225/4225 [==============================] - 1s 190us/sample - loss: 0.0119 - accuracy: 0.9934 - val_loss: 1.1257 - val_accuracy: 0.7121\n",
      "Epoch 18/20\n",
      "4225/4225 [==============================] - 1s 190us/sample - loss: 0.0097 - accuracy: 0.9948 - val_loss: 1.0285 - val_accuracy: 0.7462\n",
      "Epoch 19/20\n",
      "4225/4225 [==============================] - 1s 190us/sample - loss: 0.0109 - accuracy: 0.9941 - val_loss: 1.2637 - val_accuracy: 0.7621\n",
      "Epoch 20/20\n",
      "4225/4225 [==============================] - 1s 197us/sample - loss: 0.0097 - accuracy: 0.9957 - val_loss: 1.1935 - val_accuracy: 0.7553\n",
      "1057/1057 [==============================] - 0s 80us/sample - loss: 1.2822 - accuracy: 0.7408\n",
      "Train on 4226 samples, validate on 1761 samples\n",
      "Epoch 1/20\n",
      "4226/4226 [==============================] - 1s 261us/sample - loss: 0.4520 - accuracy: 0.7830 - val_loss: 0.4215 - val_accuracy: 0.8092\n",
      "Epoch 2/20\n",
      "4226/4226 [==============================] - 1s 194us/sample - loss: 0.3579 - accuracy: 0.8391 - val_loss: 0.4370 - val_accuracy: 0.7956\n",
      "Epoch 3/20\n",
      "4226/4226 [==============================] - 1s 193us/sample - loss: 0.2091 - accuracy: 0.9177 - val_loss: 0.6150 - val_accuracy: 0.7195\n",
      "Epoch 4/20\n",
      "4226/4226 [==============================] - 1s 186us/sample - loss: 0.0834 - accuracy: 0.9730 - val_loss: 0.6838 - val_accuracy: 0.7638\n",
      "Epoch 5/20\n",
      "4226/4226 [==============================] - 1s 190us/sample - loss: 0.0384 - accuracy: 0.9894 - val_loss: 0.7587 - val_accuracy: 0.7422\n",
      "Epoch 6/20\n",
      "4226/4226 [==============================] - 1s 197us/sample - loss: 0.0271 - accuracy: 0.9910 - val_loss: 0.8354 - val_accuracy: 0.7240\n",
      "Epoch 7/20\n",
      "4226/4226 [==============================] - 1s 194us/sample - loss: 0.0231 - accuracy: 0.9915 - val_loss: 0.8112 - val_accuracy: 0.7439\n",
      "Epoch 8/20\n",
      "4226/4226 [==============================] - 1s 195us/sample - loss: 0.0167 - accuracy: 0.9931 - val_loss: 0.8914 - val_accuracy: 0.7359\n",
      "Epoch 9/20\n",
      "4226/4226 [==============================] - 1s 193us/sample - loss: 0.0171 - accuracy: 0.9934 - val_loss: 0.8900 - val_accuracy: 0.7445\n",
      "Epoch 10/20\n",
      "4226/4226 [==============================] - 1s 217us/sample - loss: 0.0158 - accuracy: 0.9938 - val_loss: 0.8863 - val_accuracy: 0.7405\n",
      "Epoch 11/20\n",
      "4226/4226 [==============================] - 1s 214us/sample - loss: 0.0140 - accuracy: 0.9941 - val_loss: 0.9789 - val_accuracy: 0.7342\n",
      "Epoch 12/20\n",
      "4226/4226 [==============================] - 1s 210us/sample - loss: 0.0105 - accuracy: 0.9955 - val_loss: 1.0809 - val_accuracy: 0.6985\n",
      "Epoch 13/20\n",
      "4226/4226 [==============================] - 1s 208us/sample - loss: 0.0110 - accuracy: 0.9950 - val_loss: 1.0226 - val_accuracy: 0.7308\n",
      "Epoch 14/20\n",
      "4226/4226 [==============================] - 1s 195us/sample - loss: 0.0106 - accuracy: 0.9955 - val_loss: 1.2153 - val_accuracy: 0.7581\n",
      "Epoch 15/20\n",
      "4226/4226 [==============================] - 1s 208us/sample - loss: 0.0099 - accuracy: 0.9962 - val_loss: 1.0283 - val_accuracy: 0.7473\n",
      "Epoch 16/20\n",
      "4226/4226 [==============================] - 1s 202us/sample - loss: 0.0076 - accuracy: 0.9972 - val_loss: 1.3048 - val_accuracy: 0.6763\n",
      "Epoch 17/20\n",
      "4226/4226 [==============================] - 1s 206us/sample - loss: 0.0089 - accuracy: 0.9965 - val_loss: 1.1089 - val_accuracy: 0.7422\n",
      "Epoch 18/20\n",
      "4226/4226 [==============================] - 1s 201us/sample - loss: 0.0082 - accuracy: 0.9960 - val_loss: 1.1013 - val_accuracy: 0.7456\n",
      "Epoch 19/20\n",
      "4226/4226 [==============================] - 1s 214us/sample - loss: 0.0070 - accuracy: 0.9962 - val_loss: 1.1138 - val_accuracy: 0.7649\n",
      "Epoch 20/20\n",
      "4226/4226 [==============================] - 1s 206us/sample - loss: 0.0075 - accuracy: 0.9972 - val_loss: 1.1584 - val_accuracy: 0.7416\n",
      "1056/1056 [==============================] - 0s 95us/sample - loss: 1.2785 - accuracy: 0.7235\n",
      "Train on 4226 samples, validate on 1761 samples\n",
      "Epoch 1/20\n",
      "4226/4226 [==============================] - 1s 265us/sample - loss: 0.4632 - accuracy: 0.7724 - val_loss: 0.4274 - val_accuracy: 0.7842\n",
      "Epoch 2/20\n",
      "4226/4226 [==============================] - 1s 186us/sample - loss: 0.3693 - accuracy: 0.8308 - val_loss: 0.4364 - val_accuracy: 0.7814\n",
      "Epoch 3/20\n",
      "4226/4226 [==============================] - 1s 202us/sample - loss: 0.2251 - accuracy: 0.9110 - val_loss: 0.5402 - val_accuracy: 0.7888\n",
      "Epoch 4/20\n",
      "4226/4226 [==============================] - 1s 186us/sample - loss: 0.0803 - accuracy: 0.9730 - val_loss: 0.6897 - val_accuracy: 0.7280\n",
      "Epoch 5/20\n",
      "4226/4226 [==============================] - 1s 190us/sample - loss: 0.0395 - accuracy: 0.9865 - val_loss: 0.7574 - val_accuracy: 0.7677\n",
      "Epoch 6/20\n",
      "4226/4226 [==============================] - 1s 185us/sample - loss: 0.0304 - accuracy: 0.9877 - val_loss: 0.8381 - val_accuracy: 0.7564\n",
      "Epoch 7/20\n",
      "4226/4226 [==============================] - 1s 219us/sample - loss: 0.0251 - accuracy: 0.9886 - val_loss: 0.8829 - val_accuracy: 0.7297\n",
      "Epoch 8/20\n",
      "4226/4226 [==============================] - 1s 194us/sample - loss: 0.0231 - accuracy: 0.9905 - val_loss: 0.9081 - val_accuracy: 0.7547\n",
      "Epoch 9/20\n",
      "4226/4226 [==============================] - 1s 205us/sample - loss: 0.0187 - accuracy: 0.9910 - val_loss: 0.9686 - val_accuracy: 0.7558\n",
      "Epoch 10/20\n",
      "4226/4226 [==============================] - 1s 195us/sample - loss: 0.0190 - accuracy: 0.9912 - val_loss: 0.9938 - val_accuracy: 0.7558\n",
      "Epoch 11/20\n",
      "4226/4226 [==============================] - 1s 194us/sample - loss: 0.0127 - accuracy: 0.9938 - val_loss: 1.0486 - val_accuracy: 0.7115\n",
      "Epoch 12/20\n",
      "4226/4226 [==============================] - 1s 205us/sample - loss: 0.0121 - accuracy: 0.9943 - val_loss: 1.0418 - val_accuracy: 0.7331\n",
      "Epoch 13/20\n",
      "4226/4226 [==============================] - 1s 190us/sample - loss: 0.0123 - accuracy: 0.9948 - val_loss: 1.0132 - val_accuracy: 0.7484\n",
      "Epoch 14/20\n",
      "4226/4226 [==============================] - 1s 199us/sample - loss: 0.0115 - accuracy: 0.9950 - val_loss: 0.9922 - val_accuracy: 0.7484\n",
      "Epoch 15/20\n",
      "4226/4226 [==============================] - 1s 197us/sample - loss: 0.0098 - accuracy: 0.9946 - val_loss: 1.3020 - val_accuracy: 0.7064\n",
      "Epoch 16/20\n",
      "4226/4226 [==============================] - 1s 186us/sample - loss: 0.0095 - accuracy: 0.9950 - val_loss: 1.1714 - val_accuracy: 0.7604\n",
      "Epoch 17/20\n",
      "4226/4226 [==============================] - 1s 186us/sample - loss: 0.0100 - accuracy: 0.9962 - val_loss: 1.1268 - val_accuracy: 0.7217\n",
      "Epoch 18/20\n",
      "4226/4226 [==============================] - 1s 190us/sample - loss: 0.0066 - accuracy: 0.9962 - val_loss: 1.1243 - val_accuracy: 0.7263\n",
      "Epoch 19/20\n",
      "4226/4226 [==============================] - 1s 190us/sample - loss: 0.0071 - accuracy: 0.9957 - val_loss: 1.1238 - val_accuracy: 0.7348\n",
      "Epoch 20/20\n",
      "4226/4226 [==============================] - 1s 190us/sample - loss: 0.0069 - accuracy: 0.9960 - val_loss: 1.1143 - val_accuracy: 0.7524\n",
      "1056/1056 [==============================] - 0s 95us/sample - loss: 1.2750 - accuracy: 0.7206\n",
      "Train on 4226 samples, validate on 1761 samples\n",
      "Epoch 1/20\n",
      "4226/4226 [==============================] - 1s 341us/sample - loss: 0.4530 - accuracy: 0.7728 - val_loss: 0.4360 - val_accuracy: 0.7763\n",
      "Epoch 2/20\n",
      "4226/4226 [==============================] - 1s 214us/sample - loss: 0.3558 - accuracy: 0.8372 - val_loss: 0.4559 - val_accuracy: 0.7842\n",
      "Epoch 3/20\n",
      "4226/4226 [==============================] - 1s 194us/sample - loss: 0.2143 - accuracy: 0.9134 - val_loss: 0.5967 - val_accuracy: 0.7314\n",
      "Epoch 4/20\n",
      "4226/4226 [==============================] - 1s 181us/sample - loss: 0.0875 - accuracy: 0.9692 - val_loss: 0.7437 - val_accuracy: 0.7235\n",
      "Epoch 5/20\n",
      "4226/4226 [==============================] - 1s 199us/sample - loss: 0.0459 - accuracy: 0.9830 - val_loss: 0.9438 - val_accuracy: 0.7655\n",
      "Epoch 6/20\n",
      "4226/4226 [==============================] - 1s 205us/sample - loss: 0.0362 - accuracy: 0.9875 - val_loss: 0.8334 - val_accuracy: 0.7638\n",
      "Epoch 7/20\n",
      "4226/4226 [==============================] - 1s 206us/sample - loss: 0.0278 - accuracy: 0.9889 - val_loss: 0.8705 - val_accuracy: 0.7445\n",
      "Epoch 8/20\n",
      "4226/4226 [==============================] - 1s 210us/sample - loss: 0.0251 - accuracy: 0.9891 - val_loss: 0.9091 - val_accuracy: 0.7195\n",
      "Epoch 9/20\n",
      "4226/4226 [==============================] - 1s 197us/sample - loss: 0.0166 - accuracy: 0.9931 - val_loss: 0.9415 - val_accuracy: 0.7484\n",
      "Epoch 10/20\n",
      "4226/4226 [==============================] - 1s 206us/sample - loss: 0.0174 - accuracy: 0.9924 - val_loss: 1.0631 - val_accuracy: 0.7104\n",
      "Epoch 11/20\n",
      "4226/4226 [==============================] - 1s 202us/sample - loss: 0.0150 - accuracy: 0.9943 - val_loss: 1.1865 - val_accuracy: 0.6797\n",
      "Epoch 12/20\n",
      "4226/4226 [==============================] - 1s 193us/sample - loss: 0.0151 - accuracy: 0.9931 - val_loss: 1.1018 - val_accuracy: 0.6888\n",
      "Epoch 13/20\n",
      "4226/4226 [==============================] - 1s 190us/sample - loss: 0.0137 - accuracy: 0.9948 - val_loss: 0.9649 - val_accuracy: 0.7354\n",
      "Epoch 14/20\n",
      "4226/4226 [==============================] - 1s 190us/sample - loss: 0.0103 - accuracy: 0.9957 - val_loss: 1.0359 - val_accuracy: 0.7235\n",
      "Epoch 15/20\n",
      "4226/4226 [==============================] - 1s 190us/sample - loss: 0.0113 - accuracy: 0.9955 - val_loss: 1.1510 - val_accuracy: 0.6650\n",
      "Epoch 16/20\n",
      "4226/4226 [==============================] - 1s 186us/sample - loss: 0.0123 - accuracy: 0.9943 - val_loss: 1.0632 - val_accuracy: 0.7388\n",
      "Epoch 17/20\n",
      "4226/4226 [==============================] - 1s 190us/sample - loss: 0.0082 - accuracy: 0.9962 - val_loss: 1.1351 - val_accuracy: 0.7348\n",
      "Epoch 18/20\n",
      "4226/4226 [==============================] - 1s 185us/sample - loss: 0.0116 - accuracy: 0.9953 - val_loss: 1.4066 - val_accuracy: 0.6803\n",
      "Epoch 19/20\n",
      "4226/4226 [==============================] - 1s 195us/sample - loss: 0.0085 - accuracy: 0.9962 - val_loss: 1.2584 - val_accuracy: 0.7138\n",
      "Epoch 20/20\n",
      "4226/4226 [==============================] - 1s 194us/sample - loss: 0.0076 - accuracy: 0.9967 - val_loss: 1.4088 - val_accuracy: 0.6780\n",
      "1056/1056 [==============================] - 0s 95us/sample - loss: 1.4178 - accuracy: 0.6572\n",
      "Train on 4225 samples, validate on 1761 samples\n",
      "Epoch 1/20\n",
      "4225/4225 [==============================] - 1s 323us/sample - loss: 0.4616 - accuracy: 0.7792 - val_loss: 0.4353 - val_accuracy: 0.7734\n",
      "Epoch 2/20\n",
      "4225/4225 [==============================] - 1s 175us/sample - loss: 0.3623 - accuracy: 0.8334 - val_loss: 0.4408 - val_accuracy: 0.7802\n",
      "Epoch 3/20\n",
      "4225/4225 [==============================] - 1s 177us/sample - loss: 0.2220 - accuracy: 0.9127 - val_loss: 0.5327 - val_accuracy: 0.7655\n",
      "Epoch 4/20\n",
      "4225/4225 [==============================] - 1s 155us/sample - loss: 0.0843 - accuracy: 0.9725 - val_loss: 0.6903 - val_accuracy: 0.7694\n",
      "Epoch 5/20\n",
      "4225/4225 [==============================] - 1s 157us/sample - loss: 0.0406 - accuracy: 0.9870 - val_loss: 0.7658 - val_accuracy: 0.7570\n",
      "Epoch 6/20\n",
      "4225/4225 [==============================] - 1s 159us/sample - loss: 0.0266 - accuracy: 0.9910 - val_loss: 0.8267 - val_accuracy: 0.7530\n",
      "Epoch 7/20\n",
      "4225/4225 [==============================] - 1s 166us/sample - loss: 0.0229 - accuracy: 0.9908 - val_loss: 0.8933 - val_accuracy: 0.7365\n",
      "Epoch 8/20\n",
      "4225/4225 [==============================] - 1s 170us/sample - loss: 0.0212 - accuracy: 0.9931 - val_loss: 0.8897 - val_accuracy: 0.7195\n",
      "Epoch 9/20\n",
      "4225/4225 [==============================] - 1s 162us/sample - loss: 0.0210 - accuracy: 0.9922 - val_loss: 0.8986 - val_accuracy: 0.7325\n",
      "Epoch 10/20\n",
      "4225/4225 [==============================] - 1s 162us/sample - loss: 0.0187 - accuracy: 0.9915 - val_loss: 0.9417 - val_accuracy: 0.7501\n",
      "Epoch 11/20\n",
      "4225/4225 [==============================] - 1s 162us/sample - loss: 0.0154 - accuracy: 0.9934 - val_loss: 1.0127 - val_accuracy: 0.7269\n",
      "Epoch 12/20\n",
      "4225/4225 [==============================] - 1s 157us/sample - loss: 0.0116 - accuracy: 0.9950 - val_loss: 0.9905 - val_accuracy: 0.7382\n",
      "Epoch 13/20\n",
      "4225/4225 [==============================] - 1s 166us/sample - loss: 0.0159 - accuracy: 0.9938 - val_loss: 1.0469 - val_accuracy: 0.6962\n",
      "Epoch 14/20\n",
      "4225/4225 [==============================] - 1s 175us/sample - loss: 0.0113 - accuracy: 0.9957 - val_loss: 1.0322 - val_accuracy: 0.7399\n",
      "Epoch 15/20\n",
      "4225/4225 [==============================] - 1s 153us/sample - loss: 0.0094 - accuracy: 0.9967 - val_loss: 1.0887 - val_accuracy: 0.7240\n",
      "Epoch 16/20\n",
      "4225/4225 [==============================] - 1s 162us/sample - loss: 0.0114 - accuracy: 0.9964 - val_loss: 1.1050 - val_accuracy: 0.7382\n",
      "Epoch 17/20\n",
      "4225/4225 [==============================] - 1s 159us/sample - loss: 0.0156 - accuracy: 0.9934 - val_loss: 1.1757 - val_accuracy: 0.7053\n",
      "Epoch 18/20\n",
      "4225/4225 [==============================] - 1s 166us/sample - loss: 0.0091 - accuracy: 0.9955 - val_loss: 1.0880 - val_accuracy: 0.7342\n",
      "Epoch 19/20\n",
      "4225/4225 [==============================] - 1s 161us/sample - loss: 0.0086 - accuracy: 0.9957 - val_loss: 1.3949 - val_accuracy: 0.6712\n",
      "Epoch 20/20\n",
      "4225/4225 [==============================] - 1s 159us/sample - loss: 0.0094 - accuracy: 0.9967 - val_loss: 1.3283 - val_accuracy: 0.7467\n",
      "1057/1057 [==============================] - 0s 80us/sample - loss: 1.3673 - accuracy: 0.7474\n",
      "Train on 4225 samples, validate on 1761 samples\n",
      "Epoch 1/20\n",
      "4225/4225 [==============================] - 1s 231us/sample - loss: 0.4517 - accuracy: 0.7775 - val_loss: 0.4331 - val_accuracy: 0.7990\n",
      "Epoch 2/20\n",
      "4225/4225 [==============================] - 1s 157us/sample - loss: 0.3524 - accuracy: 0.8452 - val_loss: 0.4409 - val_accuracy: 0.7865\n",
      "Epoch 3/20\n",
      "4225/4225 [==============================] - 1s 171us/sample - loss: 0.2068 - accuracy: 0.9212 - val_loss: 0.5505 - val_accuracy: 0.7763\n",
      "Epoch 4/20\n",
      "4225/4225 [==============================] - 1s 165us/sample - loss: 0.0839 - accuracy: 0.9740 - val_loss: 0.6643 - val_accuracy: 0.7280\n",
      "Epoch 5/20\n",
      "4225/4225 [==============================] - 1s 155us/sample - loss: 0.0445 - accuracy: 0.9860 - val_loss: 0.7023 - val_accuracy: 0.7507\n",
      "Epoch 6/20\n",
      "4225/4225 [==============================] - 1s 159us/sample - loss: 0.0312 - accuracy: 0.9882 - val_loss: 0.7891 - val_accuracy: 0.7683\n",
      "Epoch 7/20\n",
      "4225/4225 [==============================] - 1s 181us/sample - loss: 0.0271 - accuracy: 0.9908 - val_loss: 0.8590 - val_accuracy: 0.7115\n",
      "Epoch 8/20\n",
      "4225/4225 [==============================] - 1s 171us/sample - loss: 0.0251 - accuracy: 0.9903 - val_loss: 0.8474 - val_accuracy: 0.7064\n",
      "Epoch 9/20\n",
      "4225/4225 [==============================] - 1s 165us/sample - loss: 0.0222 - accuracy: 0.9896 - val_loss: 0.8469 - val_accuracy: 0.7342\n",
      "Epoch 10/20\n",
      "4225/4225 [==============================] - 1s 159us/sample - loss: 0.0192 - accuracy: 0.9920 - val_loss: 0.8591 - val_accuracy: 0.7575\n",
      "Epoch 11/20\n",
      "4225/4225 [==============================] - 1s 162us/sample - loss: 0.0188 - accuracy: 0.9915 - val_loss: 0.8846 - val_accuracy: 0.7507\n",
      "Epoch 12/20\n",
      "4225/4225 [==============================] - 1s 162us/sample - loss: 0.0198 - accuracy: 0.9905 - val_loss: 1.1741 - val_accuracy: 0.6650\n",
      "Epoch 13/20\n",
      "4225/4225 [==============================] - 1s 159us/sample - loss: 0.0189 - accuracy: 0.9920 - val_loss: 0.9138 - val_accuracy: 0.7104\n",
      "Epoch 14/20\n",
      "4225/4225 [==============================] - 1s 157us/sample - loss: 0.0158 - accuracy: 0.9938 - val_loss: 0.9459 - val_accuracy: 0.7252\n",
      "Epoch 15/20\n",
      "4225/4225 [==============================] - 1s 162us/sample - loss: 0.0119 - accuracy: 0.9946 - val_loss: 0.9309 - val_accuracy: 0.7411\n",
      "Epoch 16/20\n",
      "4225/4225 [==============================] - 1s 177us/sample - loss: 0.0114 - accuracy: 0.9946 - val_loss: 1.0085 - val_accuracy: 0.7314\n",
      "Epoch 17/20\n",
      "4225/4225 [==============================] - 1s 159us/sample - loss: 0.0123 - accuracy: 0.9955 - val_loss: 0.9674 - val_accuracy: 0.7638\n",
      "Epoch 18/20\n",
      "4225/4225 [==============================] - 1s 155us/sample - loss: 0.0123 - accuracy: 0.9948 - val_loss: 0.9802 - val_accuracy: 0.7541\n",
      "Epoch 19/20\n",
      "4225/4225 [==============================] - 1s 161us/sample - loss: 0.0158 - accuracy: 0.9929 - val_loss: 1.0101 - val_accuracy: 0.7263\n",
      "Epoch 20/20\n",
      "4225/4225 [==============================] - 1s 159us/sample - loss: 0.0131 - accuracy: 0.9938 - val_loss: 1.0043 - val_accuracy: 0.7411\n",
      "1057/1057 [==============================] - 0s 80us/sample - loss: 1.0861 - accuracy: 0.7200\n",
      "Train on 4226 samples, validate on 1761 samples\n",
      "Epoch 1/20\n",
      "4226/4226 [==============================] - 1s 233us/sample - loss: 0.4569 - accuracy: 0.7757 - val_loss: 0.4325 - val_accuracy: 0.7712\n",
      "Epoch 2/20\n",
      "4226/4226 [==============================] - 1s 157us/sample - loss: 0.3637 - accuracy: 0.8334 - val_loss: 0.4414 - val_accuracy: 0.7780\n",
      "Epoch 3/20\n",
      "4226/4226 [==============================] - 1s 162us/sample - loss: 0.2184 - accuracy: 0.9155 - val_loss: 0.5407 - val_accuracy: 0.7791\n",
      "Epoch 4/20\n",
      "4226/4226 [==============================] - 1s 170us/sample - loss: 0.0836 - accuracy: 0.9735 - val_loss: 0.6714 - val_accuracy: 0.7581\n",
      "Epoch 5/20\n",
      "4226/4226 [==============================] - 1s 162us/sample - loss: 0.0353 - accuracy: 0.9891 - val_loss: 0.7562 - val_accuracy: 0.7592\n",
      "Epoch 6/20\n",
      "4226/4226 [==============================] - 1s 166us/sample - loss: 0.0258 - accuracy: 0.9917 - val_loss: 0.8166 - val_accuracy: 0.7354\n",
      "Epoch 7/20\n",
      "4226/4226 [==============================] - 1s 159us/sample - loss: 0.0218 - accuracy: 0.9922 - val_loss: 1.0769 - val_accuracy: 0.6769\n",
      "Epoch 8/20\n",
      "4226/4226 [==============================] - 1s 162us/sample - loss: 0.0207 - accuracy: 0.9931 - val_loss: 0.8823 - val_accuracy: 0.7604\n",
      "Epoch 9/20\n",
      "4226/4226 [==============================] - 1s 161us/sample - loss: 0.0198 - accuracy: 0.9931 - val_loss: 0.9138 - val_accuracy: 0.7274\n",
      "Epoch 10/20\n",
      "4226/4226 [==============================] - 1s 159us/sample - loss: 0.0156 - accuracy: 0.9941 - val_loss: 0.9103 - val_accuracy: 0.7388\n",
      "Epoch 11/20\n",
      "4226/4226 [==============================] - 1s 166us/sample - loss: 0.0158 - accuracy: 0.9938 - val_loss: 0.9475 - val_accuracy: 0.7541\n",
      "Epoch 12/20\n",
      "4226/4226 [==============================] - 1s 159us/sample - loss: 0.0142 - accuracy: 0.9943 - val_loss: 0.9523 - val_accuracy: 0.7200\n",
      "Epoch 13/20\n",
      "4226/4226 [==============================] - 1s 182us/sample - loss: 0.0086 - accuracy: 0.9969 - val_loss: 1.0499 - val_accuracy: 0.7252\n",
      "Epoch 14/20\n",
      "4226/4226 [==============================] - 1s 181us/sample - loss: 0.0102 - accuracy: 0.9960 - val_loss: 0.9631 - val_accuracy: 0.7382\n",
      "Epoch 15/20\n",
      "4226/4226 [==============================] - 1s 173us/sample - loss: 0.0080 - accuracy: 0.9967 - val_loss: 0.9829 - val_accuracy: 0.7428\n",
      "Epoch 16/20\n",
      "4226/4226 [==============================] - 1s 179us/sample - loss: 0.0099 - accuracy: 0.9967 - val_loss: 1.0251 - val_accuracy: 0.7467\n",
      "Epoch 17/20\n",
      "4226/4226 [==============================] - 1s 182us/sample - loss: 0.0086 - accuracy: 0.9965 - val_loss: 1.0115 - val_accuracy: 0.7530\n",
      "Epoch 18/20\n",
      "4226/4226 [==============================] - 1s 186us/sample - loss: 0.0058 - accuracy: 0.9974 - val_loss: 1.1324 - val_accuracy: 0.7280\n",
      "Epoch 19/20\n",
      "4226/4226 [==============================] - 1s 181us/sample - loss: 0.0063 - accuracy: 0.9972 - val_loss: 1.3574 - val_accuracy: 0.6474\n",
      "Epoch 20/20\n",
      "4226/4226 [==============================] - 1s 186us/sample - loss: 0.0060 - accuracy: 0.9976 - val_loss: 1.2223 - val_accuracy: 0.7155\n",
      "1056/1056 [==============================] - 0s 95us/sample - loss: 1.3353 - accuracy: 0.6913\n",
      "Train on 4226 samples, validate on 1761 samples\n",
      "Epoch 1/20\n",
      "4226/4226 [==============================] - 1s 267us/sample - loss: 0.4699 - accuracy: 0.7655 - val_loss: 0.4348 - val_accuracy: 0.7842\n",
      "Epoch 2/20\n",
      "4226/4226 [==============================] - 1s 179us/sample - loss: 0.3654 - accuracy: 0.8339 - val_loss: 0.4396 - val_accuracy: 0.7853\n",
      "Epoch 3/20\n",
      "4226/4226 [==============================] - 1s 185us/sample - loss: 0.2273 - accuracy: 0.9080 - val_loss: 0.5183 - val_accuracy: 0.7706\n",
      "Epoch 4/20\n",
      "4226/4226 [==============================] - 1s 171us/sample - loss: 0.0854 - accuracy: 0.9752 - val_loss: 0.6209 - val_accuracy: 0.7518\n",
      "Epoch 5/20\n",
      "4226/4226 [==============================] - 1s 185us/sample - loss: 0.0419 - accuracy: 0.9837 - val_loss: 0.8471 - val_accuracy: 0.6792\n",
      "Epoch 6/20\n",
      "4226/4226 [==============================] - 1s 190us/sample - loss: 0.0255 - accuracy: 0.9901 - val_loss: 0.8608 - val_accuracy: 0.7456\n",
      "Epoch 7/20\n",
      "4226/4226 [==============================] - 1s 182us/sample - loss: 0.0215 - accuracy: 0.9915 - val_loss: 0.8182 - val_accuracy: 0.7655\n",
      "Epoch 8/20\n",
      "4226/4226 [==============================] - 1s 175us/sample - loss: 0.0220 - accuracy: 0.9917 - val_loss: 1.0103 - val_accuracy: 0.6633\n",
      "Epoch 9/20\n",
      "4226/4226 [==============================] - 1s 161us/sample - loss: 0.0211 - accuracy: 0.9924 - val_loss: 0.9206 - val_accuracy: 0.7604\n",
      "Epoch 10/20\n",
      "4226/4226 [==============================] - 1s 186us/sample - loss: 0.0159 - accuracy: 0.9924 - val_loss: 1.0374 - val_accuracy: 0.7649\n",
      "Epoch 11/20\n",
      "4226/4226 [==============================] - 1s 170us/sample - loss: 0.0161 - accuracy: 0.9946 - val_loss: 1.0005 - val_accuracy: 0.7609\n",
      "Epoch 12/20\n",
      "4226/4226 [==============================] - 1s 162us/sample - loss: 0.0124 - accuracy: 0.9953 - val_loss: 0.9509 - val_accuracy: 0.7547\n",
      "Epoch 13/20\n",
      "4226/4226 [==============================] - 1s 162us/sample - loss: 0.0133 - accuracy: 0.9948 - val_loss: 0.9467 - val_accuracy: 0.7098\n",
      "Epoch 14/20\n",
      "4226/4226 [==============================] - 1s 175us/sample - loss: 0.0124 - accuracy: 0.9943 - val_loss: 1.0624 - val_accuracy: 0.7729\n",
      "Epoch 15/20\n",
      "4226/4226 [==============================] - 1s 165us/sample - loss: 0.0103 - accuracy: 0.9962 - val_loss: 0.9580 - val_accuracy: 0.7575\n",
      "Epoch 16/20\n",
      "4226/4226 [==============================] - 1s 166us/sample - loss: 0.0111 - accuracy: 0.9960 - val_loss: 1.4455 - val_accuracy: 0.6224\n",
      "Epoch 17/20\n",
      "4226/4226 [==============================] - 1s 162us/sample - loss: 0.0106 - accuracy: 0.9960 - val_loss: 0.9583 - val_accuracy: 0.7422\n",
      "Epoch 18/20\n",
      "4226/4226 [==============================] - 1s 159us/sample - loss: 0.0108 - accuracy: 0.9962 - val_loss: 1.0358 - val_accuracy: 0.7592\n",
      "Epoch 19/20\n",
      "4226/4226 [==============================] - 1s 182us/sample - loss: 0.0072 - accuracy: 0.9969 - val_loss: 1.2273 - val_accuracy: 0.7030\n",
      "Epoch 20/20\n",
      "4226/4226 [==============================] - 1s 162us/sample - loss: 0.0093 - accuracy: 0.9962 - val_loss: 1.0506 - val_accuracy: 0.7070\n",
      "1056/1056 [==============================] - 0s 80us/sample - loss: 1.1985 - accuracy: 0.6922\n",
      "Train on 4226 samples, validate on 1761 samples\n",
      "Epoch 1/20\n",
      "4226/4226 [==============================] - 1s 245us/sample - loss: 0.4500 - accuracy: 0.7759 - val_loss: 0.4241 - val_accuracy: 0.7899\n",
      "Epoch 2/20\n",
      "4226/4226 [==============================] - 1s 161us/sample - loss: 0.3518 - accuracy: 0.8393 - val_loss: 0.4703 - val_accuracy: 0.7819\n",
      "Epoch 3/20\n",
      "4226/4226 [==============================] - 1s 162us/sample - loss: 0.2156 - accuracy: 0.9179 - val_loss: 0.5301 - val_accuracy: 0.7530\n",
      "Epoch 4/20\n",
      "4226/4226 [==============================] - 1s 155us/sample - loss: 0.0819 - accuracy: 0.9740 - val_loss: 0.6843 - val_accuracy: 0.7694\n",
      "Epoch 5/20\n",
      "4226/4226 [==============================] - 1s 157us/sample - loss: 0.0442 - accuracy: 0.9825 - val_loss: 0.7557 - val_accuracy: 0.7354\n",
      "Epoch 6/20\n",
      "4226/4226 [==============================] - 1s 159us/sample - loss: 0.0251 - accuracy: 0.9910 - val_loss: 0.8311 - val_accuracy: 0.7155\n",
      "Epoch 7/20\n",
      "4226/4226 [==============================] - 1s 162us/sample - loss: 0.0233 - accuracy: 0.9894 - val_loss: 0.8686 - val_accuracy: 0.7626\n",
      "Epoch 8/20\n",
      "4226/4226 [==============================] - 1s 157us/sample - loss: 0.0270 - accuracy: 0.9908 - val_loss: 0.8561 - val_accuracy: 0.7388\n",
      "Epoch 9/20\n",
      "4226/4226 [==============================] - 1s 162us/sample - loss: 0.0196 - accuracy: 0.9920 - val_loss: 0.8860 - val_accuracy: 0.7371\n",
      "Epoch 10/20\n",
      "4226/4226 [==============================] - 1s 159us/sample - loss: 0.0196 - accuracy: 0.9931 - val_loss: 0.8993 - val_accuracy: 0.7490\n",
      "Epoch 11/20\n",
      "4226/4226 [==============================] - 1s 159us/sample - loss: 0.0158 - accuracy: 0.9934 - val_loss: 0.8962 - val_accuracy: 0.7416\n",
      "Epoch 12/20\n",
      "4226/4226 [==============================] - 1s 161us/sample - loss: 0.0114 - accuracy: 0.9941 - val_loss: 0.9490 - val_accuracy: 0.7581\n",
      "Epoch 13/20\n",
      "4226/4226 [==============================] - 1s 159us/sample - loss: 0.0148 - accuracy: 0.9943 - val_loss: 0.9819 - val_accuracy: 0.7592\n",
      "Epoch 14/20\n",
      "4226/4226 [==============================] - 1s 159us/sample - loss: 0.0115 - accuracy: 0.9957 - val_loss: 1.0475 - val_accuracy: 0.7541\n",
      "Epoch 15/20\n",
      "4226/4226 [==============================] - 1s 159us/sample - loss: 0.0118 - accuracy: 0.9948 - val_loss: 1.0089 - val_accuracy: 0.7592\n",
      "Epoch 16/20\n",
      "4226/4226 [==============================] - 1s 165us/sample - loss: 0.0094 - accuracy: 0.9960 - val_loss: 1.0888 - val_accuracy: 0.7371\n",
      "Epoch 17/20\n",
      "4226/4226 [==============================] - 1s 157us/sample - loss: 0.0105 - accuracy: 0.9953 - val_loss: 1.0202 - val_accuracy: 0.7513\n",
      "Epoch 18/20\n",
      "4226/4226 [==============================] - 1s 159us/sample - loss: 0.0098 - accuracy: 0.9957 - val_loss: 1.1475 - val_accuracy: 0.7609\n",
      "Epoch 19/20\n",
      "4226/4226 [==============================] - 1s 166us/sample - loss: 0.0105 - accuracy: 0.9950 - val_loss: 1.7290 - val_accuracy: 0.6303\n",
      "Epoch 20/20\n",
      "4226/4226 [==============================] - 1s 170us/sample - loss: 0.0082 - accuracy: 0.9972 - val_loss: 1.3891 - val_accuracy: 0.7706\n",
      "1056/1056 [==============================] - 0s 80us/sample - loss: 1.3907 - accuracy: 0.7595\n",
      "Train on 4225 samples, validate on 1761 samples\n",
      "Epoch 1/20\n",
      "4225/4225 [==============================] - 1s 217us/sample - loss: 0.4632 - accuracy: 0.7742 - val_loss: 0.4273 - val_accuracy: 0.7933\n",
      "Epoch 2/20\n",
      "4225/4225 [==============================] - 1s 139us/sample - loss: 0.3595 - accuracy: 0.8357 - val_loss: 0.4422 - val_accuracy: 0.7791\n",
      "Epoch 3/20\n",
      "4225/4225 [==============================] - 1s 139us/sample - loss: 0.2320 - accuracy: 0.9067 - val_loss: 0.5445 - val_accuracy: 0.7422\n",
      "Epoch 4/20\n",
      "4225/4225 [==============================] - 1s 142us/sample - loss: 0.0923 - accuracy: 0.9711 - val_loss: 0.6682 - val_accuracy: 0.7462\n",
      "Epoch 5/20\n",
      "4225/4225 [==============================] - 1s 139us/sample - loss: 0.0413 - accuracy: 0.9865 - val_loss: 0.8247 - val_accuracy: 0.7547\n",
      "Epoch 6/20\n",
      "4225/4225 [==============================] - 1s 153us/sample - loss: 0.0318 - accuracy: 0.9884 - val_loss: 0.9162 - val_accuracy: 0.6865\n",
      "Epoch 7/20\n",
      "4225/4225 [==============================] - 1s 155us/sample - loss: 0.0232 - accuracy: 0.9908 - val_loss: 0.8114 - val_accuracy: 0.7371\n",
      "Epoch 8/20\n",
      "4225/4225 [==============================] - 1s 142us/sample - loss: 0.0203 - accuracy: 0.9920 - val_loss: 0.8360 - val_accuracy: 0.7587\n",
      "Epoch 9/20\n",
      "4225/4225 [==============================] - 1s 142us/sample - loss: 0.0170 - accuracy: 0.9934 - val_loss: 0.9309 - val_accuracy: 0.6956\n",
      "Epoch 10/20\n",
      "4225/4225 [==============================] - 1s 146us/sample - loss: 0.0157 - accuracy: 0.9929 - val_loss: 0.9666 - val_accuracy: 0.7149\n",
      "Epoch 11/20\n",
      "4225/4225 [==============================] - 1s 142us/sample - loss: 0.0135 - accuracy: 0.9941 - val_loss: 0.9126 - val_accuracy: 0.7541\n",
      "Epoch 12/20\n",
      "4225/4225 [==============================] - 1s 146us/sample - loss: 0.0148 - accuracy: 0.9927 - val_loss: 0.9298 - val_accuracy: 0.7405\n",
      "Epoch 13/20\n",
      "4225/4225 [==============================] - 1s 142us/sample - loss: 0.0131 - accuracy: 0.9950 - val_loss: 0.9966 - val_accuracy: 0.7024\n",
      "Epoch 14/20\n",
      "4225/4225 [==============================] - 1s 139us/sample - loss: 0.0103 - accuracy: 0.9957 - val_loss: 0.9449 - val_accuracy: 0.7286\n",
      "Epoch 15/20\n",
      "4225/4225 [==============================] - 1s 142us/sample - loss: 0.0111 - accuracy: 0.9967 - val_loss: 0.9548 - val_accuracy: 0.7348\n",
      "Epoch 16/20\n",
      "4225/4225 [==============================] - 1s 155us/sample - loss: 0.0118 - accuracy: 0.9960 - val_loss: 0.9845 - val_accuracy: 0.7354\n",
      "Epoch 17/20\n",
      "4225/4225 [==============================] - 1s 142us/sample - loss: 0.0095 - accuracy: 0.9953 - val_loss: 1.0024 - val_accuracy: 0.7354\n",
      "Epoch 18/20\n",
      "4225/4225 [==============================] - 1s 142us/sample - loss: 0.0094 - accuracy: 0.9960 - val_loss: 1.0472 - val_accuracy: 0.7490\n",
      "Epoch 19/20\n",
      "4225/4225 [==============================] - 1s 142us/sample - loss: 0.0107 - accuracy: 0.9960 - val_loss: 1.0819 - val_accuracy: 0.7638\n",
      "Epoch 20/20\n",
      "4225/4225 [==============================] - 1s 133us/sample - loss: 0.0112 - accuracy: 0.9957 - val_loss: 1.0592 - val_accuracy: 0.7541\n",
      "1057/1057 [==============================] - 0s 59us/sample - loss: 1.1403 - accuracy: 0.7436\n",
      "Train on 4225 samples, validate on 1761 samples\n",
      "Epoch 1/20\n",
      "4225/4225 [==============================] - 1s 277us/sample - loss: 0.4542 - accuracy: 0.7766 - val_loss: 0.4259 - val_accuracy: 0.7905\n",
      "Epoch 2/20\n",
      "4225/4225 [==============================] - 1s 146us/sample - loss: 0.3448 - accuracy: 0.8462 - val_loss: 0.4475 - val_accuracy: 0.7763\n",
      "Epoch 3/20\n",
      "4225/4225 [==============================] - 1s 139us/sample - loss: 0.2043 - accuracy: 0.9221 - val_loss: 0.5525 - val_accuracy: 0.7575\n",
      "Epoch 4/20\n",
      "4225/4225 [==============================] - 1s 142us/sample - loss: 0.0833 - accuracy: 0.9716 - val_loss: 0.6592 - val_accuracy: 0.7433\n",
      "Epoch 5/20\n",
      "4225/4225 [==============================] - 1s 142us/sample - loss: 0.0435 - accuracy: 0.9858 - val_loss: 0.7075 - val_accuracy: 0.7450\n",
      "Epoch 6/20\n",
      "4225/4225 [==============================] - 1s 139us/sample - loss: 0.0348 - accuracy: 0.9879 - val_loss: 0.8070 - val_accuracy: 0.7121\n",
      "Epoch 7/20\n",
      "4225/4225 [==============================] - 1s 142us/sample - loss: 0.0305 - accuracy: 0.9886 - val_loss: 0.9619 - val_accuracy: 0.7535\n",
      "Epoch 8/20\n",
      "4225/4225 [==============================] - 1s 142us/sample - loss: 0.0309 - accuracy: 0.9884 - val_loss: 0.7885 - val_accuracy: 0.7382\n",
      "Epoch 9/20\n",
      "4225/4225 [==============================] - 1s 146us/sample - loss: 0.0240 - accuracy: 0.9896 - val_loss: 0.8626 - val_accuracy: 0.7518\n",
      "Epoch 10/20\n",
      "4225/4225 [==============================] - 1s 142us/sample - loss: 0.0216 - accuracy: 0.9912 - val_loss: 0.8035 - val_accuracy: 0.7337\n",
      "Epoch 11/20\n",
      "4225/4225 [==============================] - 1s 150us/sample - loss: 0.0169 - accuracy: 0.9920 - val_loss: 0.8697 - val_accuracy: 0.7263\n",
      "Epoch 12/20\n",
      "4225/4225 [==============================] - 1s 142us/sample - loss: 0.0163 - accuracy: 0.9929 - val_loss: 0.9261 - val_accuracy: 0.7127\n",
      "Epoch 13/20\n",
      "4225/4225 [==============================] - 1s 142us/sample - loss: 0.0149 - accuracy: 0.9924 - val_loss: 0.9018 - val_accuracy: 0.7371\n",
      "Epoch 14/20\n",
      "4225/4225 [==============================] - 1s 139us/sample - loss: 0.0124 - accuracy: 0.9953 - val_loss: 1.0060 - val_accuracy: 0.7110\n",
      "Epoch 15/20\n",
      "4225/4225 [==============================] - 1s 142us/sample - loss: 0.0152 - accuracy: 0.9943 - val_loss: 0.9803 - val_accuracy: 0.7269\n",
      "Epoch 16/20\n",
      "4225/4225 [==============================] - 1s 139us/sample - loss: 0.0144 - accuracy: 0.9934 - val_loss: 0.9825 - val_accuracy: 0.7473\n",
      "Epoch 17/20\n",
      "4225/4225 [==============================] - 1s 139us/sample - loss: 0.0128 - accuracy: 0.9936 - val_loss: 1.0952 - val_accuracy: 0.7626\n",
      "Epoch 18/20\n",
      "4225/4225 [==============================] - 1s 142us/sample - loss: 0.0118 - accuracy: 0.9950 - val_loss: 1.0592 - val_accuracy: 0.7155\n",
      "Epoch 19/20\n",
      "4225/4225 [==============================] - 1s 142us/sample - loss: 0.0133 - accuracy: 0.9948 - val_loss: 0.9752 - val_accuracy: 0.7513\n",
      "Epoch 20/20\n",
      "4225/4225 [==============================] - 1s 142us/sample - loss: 0.0106 - accuracy: 0.9957 - val_loss: 1.0103 - val_accuracy: 0.7439\n",
      "1057/1057 [==============================] - 0s 65us/sample - loss: 1.0782 - accuracy: 0.7332\n",
      "Train on 4226 samples, validate on 1761 samples\n",
      "Epoch 1/20\n",
      "4226/4226 [==============================] - 1s 221us/sample - loss: 0.4577 - accuracy: 0.7648 - val_loss: 0.4268 - val_accuracy: 0.7939\n",
      "Epoch 2/20\n",
      "4226/4226 [==============================] - 1s 146us/sample - loss: 0.3572 - accuracy: 0.8391 - val_loss: 0.4536 - val_accuracy: 0.7814\n",
      "Epoch 3/20\n",
      "4226/4226 [==============================] - 1s 142us/sample - loss: 0.2233 - accuracy: 0.9108 - val_loss: 0.5092 - val_accuracy: 0.7677\n",
      "Epoch 4/20\n",
      "4226/4226 [==============================] - 1s 139us/sample - loss: 0.0863 - accuracy: 0.9733 - val_loss: 0.6605 - val_accuracy: 0.7501\n",
      "Epoch 5/20\n",
      "4226/4226 [==============================] - 1s 142us/sample - loss: 0.0431 - accuracy: 0.9867 - val_loss: 0.9134 - val_accuracy: 0.7689\n",
      "Epoch 6/20\n",
      "4226/4226 [==============================] - 1s 146us/sample - loss: 0.0314 - accuracy: 0.9901 - val_loss: 0.8228 - val_accuracy: 0.7598\n",
      "Epoch 7/20\n",
      "4226/4226 [==============================] - 1s 142us/sample - loss: 0.0219 - accuracy: 0.9917 - val_loss: 0.8260 - val_accuracy: 0.7484\n",
      "Epoch 8/20\n",
      "4226/4226 [==============================] - 1s 142us/sample - loss: 0.0212 - accuracy: 0.9920 - val_loss: 0.8064 - val_accuracy: 0.7570\n",
      "Epoch 9/20\n",
      "4226/4226 [==============================] - 1s 139us/sample - loss: 0.0190 - accuracy: 0.9934 - val_loss: 0.9128 - val_accuracy: 0.7649\n",
      "Epoch 10/20\n",
      "4226/4226 [==============================] - 1s 142us/sample - loss: 0.0122 - accuracy: 0.9950 - val_loss: 0.9453 - val_accuracy: 0.7280\n",
      "Epoch 11/20\n",
      "4226/4226 [==============================] - 1s 142us/sample - loss: 0.0187 - accuracy: 0.9931 - val_loss: 0.9402 - val_accuracy: 0.7558\n",
      "Epoch 12/20\n",
      "4226/4226 [==============================] - 1s 139us/sample - loss: 0.0152 - accuracy: 0.9943 - val_loss: 0.9217 - val_accuracy: 0.7666\n",
      "Epoch 13/20\n",
      "4226/4226 [==============================] - 1s 146us/sample - loss: 0.0133 - accuracy: 0.9938 - val_loss: 1.0500 - val_accuracy: 0.6792\n",
      "Epoch 14/20\n",
      "4226/4226 [==============================] - 1s 139us/sample - loss: 0.0098 - accuracy: 0.9965 - val_loss: 0.9827 - val_accuracy: 0.7513\n",
      "Epoch 15/20\n",
      "4226/4226 [==============================] - 1s 142us/sample - loss: 0.0082 - accuracy: 0.9960 - val_loss: 0.9646 - val_accuracy: 0.7558\n",
      "Epoch 16/20\n",
      "4226/4226 [==============================] - 1s 142us/sample - loss: 0.0109 - accuracy: 0.9953 - val_loss: 1.0928 - val_accuracy: 0.7592\n",
      "Epoch 17/20\n",
      "4226/4226 [==============================] - 1s 139us/sample - loss: 0.0074 - accuracy: 0.9972 - val_loss: 1.0167 - val_accuracy: 0.7433\n",
      "Epoch 18/20\n",
      "4226/4226 [==============================] - 1s 146us/sample - loss: 0.0079 - accuracy: 0.9972 - val_loss: 1.0594 - val_accuracy: 0.7518\n",
      "Epoch 19/20\n",
      "4226/4226 [==============================] - 1s 139us/sample - loss: 0.0093 - accuracy: 0.9965 - val_loss: 0.9856 - val_accuracy: 0.7450\n",
      "Epoch 20/20\n",
      "4226/4226 [==============================] - 1s 139us/sample - loss: 0.0074 - accuracy: 0.9967 - val_loss: 1.0809 - val_accuracy: 0.7643\n",
      "1056/1056 [==============================] - 0s 80us/sample - loss: 1.1637 - accuracy: 0.7500\n",
      "Train on 4226 samples, validate on 1761 samples\n",
      "Epoch 1/20\n",
      "4226/4226 [==============================] - 1s 212us/sample - loss: 0.4706 - accuracy: 0.7705 - val_loss: 0.4245 - val_accuracy: 0.7922\n",
      "Epoch 2/20\n",
      "4226/4226 [==============================] - 1s 150us/sample - loss: 0.3646 - accuracy: 0.8405 - val_loss: 0.4294 - val_accuracy: 0.7973\n",
      "Epoch 3/20\n",
      "4226/4226 [==============================] - 1s 142us/sample - loss: 0.2388 - accuracy: 0.9025 - val_loss: 0.5061 - val_accuracy: 0.7717\n",
      "Epoch 4/20\n",
      "4226/4226 [==============================] - 1s 139us/sample - loss: 0.1053 - accuracy: 0.9662 - val_loss: 0.6969 - val_accuracy: 0.6899\n",
      "Epoch 5/20\n",
      "4226/4226 [==============================] - 1s 142us/sample - loss: 0.0499 - accuracy: 0.9832 - val_loss: 0.6767 - val_accuracy: 0.7541\n",
      "Epoch 6/20\n",
      "4226/4226 [==============================] - 1s 139us/sample - loss: 0.0284 - accuracy: 0.9889 - val_loss: 0.7352 - val_accuracy: 0.7626\n",
      "Epoch 7/20\n",
      "4226/4226 [==============================] - 1s 142us/sample - loss: 0.0271 - accuracy: 0.9896 - val_loss: 0.8883 - val_accuracy: 0.6922\n",
      "Epoch 8/20\n",
      "4226/4226 [==============================] - 1s 139us/sample - loss: 0.0215 - accuracy: 0.9927 - val_loss: 0.9709 - val_accuracy: 0.7706\n",
      "Epoch 9/20\n",
      "4226/4226 [==============================] - 1s 142us/sample - loss: 0.0187 - accuracy: 0.9934 - val_loss: 0.8069 - val_accuracy: 0.7581\n",
      "Epoch 10/20\n",
      "4226/4226 [==============================] - 1s 142us/sample - loss: 0.0154 - accuracy: 0.9938 - val_loss: 0.8770 - val_accuracy: 0.7376\n",
      "Epoch 11/20\n",
      "4226/4226 [==============================] - 1s 142us/sample - loss: 0.0192 - accuracy: 0.9927 - val_loss: 0.9426 - val_accuracy: 0.6911\n",
      "Epoch 12/20\n",
      "4226/4226 [==============================] - 1s 141us/sample - loss: 0.0160 - accuracy: 0.9934 - val_loss: 0.8534 - val_accuracy: 0.7411\n",
      "Epoch 13/20\n",
      "4226/4226 [==============================] - 1s 144us/sample - loss: 0.0117 - accuracy: 0.9960 - val_loss: 0.9221 - val_accuracy: 0.7558\n",
      "Epoch 14/20\n",
      "4226/4226 [==============================] - 1s 142us/sample - loss: 0.0119 - accuracy: 0.9950 - val_loss: 0.9197 - val_accuracy: 0.7348\n",
      "Epoch 15/20\n",
      "4226/4226 [==============================] - 1s 142us/sample - loss: 0.0138 - accuracy: 0.9950 - val_loss: 0.8874 - val_accuracy: 0.7490\n",
      "Epoch 16/20\n",
      "4226/4226 [==============================] - 1s 141us/sample - loss: 0.0088 - accuracy: 0.9962 - val_loss: 1.0637 - val_accuracy: 0.7643\n",
      "Epoch 17/20\n",
      "4226/4226 [==============================] - 1s 144us/sample - loss: 0.0099 - accuracy: 0.9960 - val_loss: 0.9463 - val_accuracy: 0.7331\n",
      "Epoch 18/20\n",
      "4226/4226 [==============================] - 1s 142us/sample - loss: 0.0113 - accuracy: 0.9955 - val_loss: 1.0444 - val_accuracy: 0.7115\n",
      "Epoch 19/20\n",
      "4226/4226 [==============================] - 1s 141us/sample - loss: 0.0091 - accuracy: 0.9969 - val_loss: 0.9444 - val_accuracy: 0.7547\n",
      "Epoch 20/20\n",
      "4226/4226 [==============================] - 1s 139us/sample - loss: 0.0078 - accuracy: 0.9969 - val_loss: 0.9472 - val_accuracy: 0.7462\n",
      "1056/1056 [==============================] - 0s 65us/sample - loss: 1.1233 - accuracy: 0.7197\n",
      "Train on 4226 samples, validate on 1761 samples\n",
      "Epoch 1/20\n",
      "4226/4226 [==============================] - 1s 212us/sample - loss: 0.4630 - accuracy: 0.7686 - val_loss: 0.4309 - val_accuracy: 0.7893\n",
      "Epoch 2/20\n",
      "4226/4226 [==============================] - 1s 141us/sample - loss: 0.3627 - accuracy: 0.8310 - val_loss: 0.4375 - val_accuracy: 0.7836\n",
      "Epoch 3/20\n",
      "4226/4226 [==============================] - 1s 142us/sample - loss: 0.2262 - accuracy: 0.9122 - val_loss: 0.5254 - val_accuracy: 0.7689\n",
      "Epoch 4/20\n",
      "4226/4226 [==============================] - 1s 137us/sample - loss: 0.0930 - accuracy: 0.9692 - val_loss: 0.7047 - val_accuracy: 0.7712\n",
      "Epoch 5/20\n",
      "4226/4226 [==============================] - 1s 142us/sample - loss: 0.0433 - accuracy: 0.9853 - val_loss: 0.7109 - val_accuracy: 0.7553\n",
      "Epoch 6/20\n",
      "4226/4226 [==============================] - 1s 142us/sample - loss: 0.0345 - accuracy: 0.9877 - val_loss: 0.7838 - val_accuracy: 0.7314\n",
      "Epoch 7/20\n",
      "4226/4226 [==============================] - 1s 139us/sample - loss: 0.0215 - accuracy: 0.9896 - val_loss: 0.8258 - val_accuracy: 0.7359\n",
      "Epoch 8/20\n",
      "4226/4226 [==============================] - 1s 142us/sample - loss: 0.0199 - accuracy: 0.9924 - val_loss: 0.8365 - val_accuracy: 0.7394\n",
      "Epoch 9/20\n",
      "4226/4226 [==============================] - 1s 139us/sample - loss: 0.0195 - accuracy: 0.9910 - val_loss: 0.9684 - val_accuracy: 0.7098\n",
      "Epoch 10/20\n",
      "4226/4226 [==============================] - 1s 142us/sample - loss: 0.0191 - accuracy: 0.9917 - val_loss: 0.9853 - val_accuracy: 0.7592\n",
      "Epoch 11/20\n",
      "4226/4226 [==============================] - 1s 142us/sample - loss: 0.0218 - accuracy: 0.9898 - val_loss: 1.2015 - val_accuracy: 0.6655\n",
      "Epoch 12/20\n",
      "4226/4226 [==============================] - 1s 146us/sample - loss: 0.0186 - accuracy: 0.9938 - val_loss: 1.0718 - val_accuracy: 0.7484\n",
      "Epoch 13/20\n",
      "4226/4226 [==============================] - 1s 142us/sample - loss: 0.0118 - accuracy: 0.9943 - val_loss: 1.0114 - val_accuracy: 0.7411\n",
      "Epoch 14/20\n",
      "4226/4226 [==============================] - 1s 142us/sample - loss: 0.0117 - accuracy: 0.9948 - val_loss: 0.9927 - val_accuracy: 0.7365\n",
      "Epoch 15/20\n",
      "4226/4226 [==============================] - 1s 148us/sample - loss: 0.0128 - accuracy: 0.9946 - val_loss: 0.9940 - val_accuracy: 0.7359\n",
      "Epoch 16/20\n",
      "4226/4226 [==============================] - 1s 142us/sample - loss: 0.0131 - accuracy: 0.9938 - val_loss: 1.1202 - val_accuracy: 0.7411\n",
      "Epoch 17/20\n",
      "4226/4226 [==============================] - 1s 142us/sample - loss: 0.0113 - accuracy: 0.9950 - val_loss: 1.0944 - val_accuracy: 0.7462\n",
      "Epoch 18/20\n",
      "4226/4226 [==============================] - 1s 141us/sample - loss: 0.0088 - accuracy: 0.9965 - val_loss: 1.0425 - val_accuracy: 0.7394\n",
      "Epoch 19/20\n",
      "4226/4226 [==============================] - 1s 144us/sample - loss: 0.0134 - accuracy: 0.9938 - val_loss: 1.1205 - val_accuracy: 0.7626\n",
      "Epoch 20/20\n",
      "4226/4226 [==============================] - 1s 137us/sample - loss: 0.0097 - accuracy: 0.9962 - val_loss: 1.1020 - val_accuracy: 0.7189\n",
      "1056/1056 [==============================] - 0s 74us/sample - loss: 1.1274 - accuracy: 0.6941\n",
      "Train on 5282 samples, validate on 1761 samples\n",
      "Epoch 1/20\n",
      "5282/5282 [==============================] - 1s 203us/sample - loss: 0.4593 - accuracy: 0.7732 - val_loss: 0.4312 - val_accuracy: 0.7916\n",
      "Epoch 2/20\n",
      "5282/5282 [==============================] - 1s 146us/sample - loss: 0.3573 - accuracy: 0.8362 - val_loss: 0.4641 - val_accuracy: 0.7604\n",
      "Epoch 3/20\n",
      "5282/5282 [==============================] - 1s 146us/sample - loss: 0.2205 - accuracy: 0.9133 - val_loss: 0.5270 - val_accuracy: 0.7694\n",
      "Epoch 4/20\n",
      "5282/5282 [==============================] - 1s 139us/sample - loss: 0.0803 - accuracy: 0.9741 - val_loss: 0.7200 - val_accuracy: 0.7638\n",
      "Epoch 5/20\n",
      "5282/5282 [==============================] - 1s 139us/sample - loss: 0.0419 - accuracy: 0.9847 - val_loss: 0.7628 - val_accuracy: 0.7524\n",
      "Epoch 6/20\n",
      "5282/5282 [==============================] - 1s 133us/sample - loss: 0.0300 - accuracy: 0.9881 - val_loss: 0.7925 - val_accuracy: 0.7513\n",
      "Epoch 7/20\n",
      "5282/5282 [==============================] - 1s 133us/sample - loss: 0.0250 - accuracy: 0.9909 - val_loss: 0.8117 - val_accuracy: 0.7416\n",
      "Epoch 8/20\n",
      "5282/5282 [==============================] - 1s 137us/sample - loss: 0.0211 - accuracy: 0.9932 - val_loss: 0.9410 - val_accuracy: 0.7558\n",
      "Epoch 9/20\n",
      "5282/5282 [==============================] - 1s 139us/sample - loss: 0.0213 - accuracy: 0.9913 - val_loss: 0.9378 - val_accuracy: 0.7445\n",
      "Epoch 10/20\n",
      "5282/5282 [==============================] - 1s 133us/sample - loss: 0.0195 - accuracy: 0.9911 - val_loss: 0.9371 - val_accuracy: 0.7513\n",
      "Epoch 11/20\n",
      "5282/5282 [==============================] - 1s 136us/sample - loss: 0.0146 - accuracy: 0.9943 - val_loss: 1.0198 - val_accuracy: 0.7598\n",
      "Epoch 12/20\n",
      "5282/5282 [==============================] - 1s 133us/sample - loss: 0.0137 - accuracy: 0.9936 - val_loss: 0.9301 - val_accuracy: 0.7501\n",
      "Epoch 13/20\n",
      "5282/5282 [==============================] - 1s 136us/sample - loss: 0.0138 - accuracy: 0.9941 - val_loss: 1.0864 - val_accuracy: 0.7235\n",
      "Epoch 14/20\n",
      "5282/5282 [==============================] - 1s 136us/sample - loss: 0.0142 - accuracy: 0.9947 - val_loss: 0.9471 - val_accuracy: 0.7354\n",
      "Epoch 15/20\n",
      "5282/5282 [==============================] - 1s 137us/sample - loss: 0.0113 - accuracy: 0.9960 - val_loss: 0.9773 - val_accuracy: 0.7376\n",
      "Epoch 16/20\n",
      "5282/5282 [==============================] - 1s 133us/sample - loss: 0.0100 - accuracy: 0.9962 - val_loss: 1.0618 - val_accuracy: 0.7604\n",
      "Epoch 17/20\n",
      "5282/5282 [==============================] - 1s 136us/sample - loss: 0.0110 - accuracy: 0.9960 - val_loss: 1.1099 - val_accuracy: 0.7070\n",
      "Epoch 18/20\n",
      "5282/5282 [==============================] - 1s 136us/sample - loss: 0.0098 - accuracy: 0.9958 - val_loss: 1.0388 - val_accuracy: 0.7178\n",
      "Epoch 19/20\n",
      "5282/5282 [==============================] - 1s 139us/sample - loss: 0.0089 - accuracy: 0.9960 - val_loss: 1.0664 - val_accuracy: 0.7342\n",
      "Epoch 20/20\n",
      "5282/5282 [==============================] - 1s 133us/sample - loss: 0.0095 - accuracy: 0.9953 - val_loss: 1.0357 - val_accuracy: 0.7450\n",
      "Best: 0.7281293988227844 using {'batch_size': 100, 'epochs': 20}\n",
      "Means: 0.7139352321624756, Stdev: 0.029681161388291268 with: {'batch_size': 10, 'epochs': 20}\n",
      "Means: 0.7167686343193054, Stdev: 0.016172806466536457 with: {'batch_size': 20, 'epochs': 20}\n",
      "Means: 0.723209273815155, Stdev: 0.019402442940594965 with: {'batch_size': 40, 'epochs': 20}\n",
      "Means: 0.7069255232810974, Stdev: 0.029286573684612575 with: {'batch_size': 60, 'epochs': 20}\n",
      "Means: 0.7220705866813659, Stdev: 0.027865308767413784 with: {'batch_size': 80, 'epochs': 20}\n",
      "Means: 0.7281293988227844, Stdev: 0.019854599813165914 with: {'batch_size': 100, 'epochs': 20}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "param_grid = {'batch_size': [10, 20, 40, 60, 80, 100],\n",
    "              'epochs': [20]}\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1)\n",
    "grid_result = grid.fit(X_train_encoded, y_train, validation_data=(X_test_encoded, y_test))\n",
    "\n",
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'batch_size': [100],\n",
    "              'epochs': [20, 40, 80, 100, 400]}\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1)\n",
    "grid_result = grid.fit(X_train_encoded, y_train, validation_data=(X_test_encoded, y_test))\n",
    "\n",
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FfZRtJ7MCN3x"
   },
   "source": [
    "## Stretch Goals:\n",
    "\n",
    "- Try to implement Random Search Hyperparameter Tuning on this dataset\n",
    "- Try to implement Bayesian Optimiation tuning on this dataset using hyperas or hyperopt (if you're brave)\n",
    "- Practice hyperparameter tuning other datasets that we have looked at. How high can you get MNIST? Above 99%?\n",
    "- Study for the Sprint Challenge\n",
    " - Can you implement both perceptron and MLP models from scratch with forward and backpropagation?\n",
    " - Can you implement both perceptron and MLP models in keras and tune their hyperparameters with cross validation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4iPzQV4n_Lz2"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Copy of LS_DS_434_Hyperparameter_Tuning_Assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "neural-networks",
   "language": "python",
   "name": "neural-networks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
