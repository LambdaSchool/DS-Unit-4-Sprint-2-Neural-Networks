{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Ryp-TVm4njD"
   },
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "\n",
    "# Hyperparameter Tuning\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2 Assignment 4*\n",
    "\n",
    "## Your Mission, should you choose to accept it...\n",
    "\n",
    "To hyperparameter tune and extract every ounce of accuracy out of this telecom customer churn dataset: <https://drive.google.com/file/d/1dfbAsM9DwA7tYhInyflIpZnYs7VT-0AQ/view> \n",
    "\n",
    "## Requirements\n",
    "\n",
    "- Load the data\n",
    "- Clean the data if necessary (it will be)\n",
    "- Create and fit a baseline Keras MLP model to the data.\n",
    "- Hyperparameter tune (at least) the following parameters:\n",
    " - batch_size\n",
    " - training epochs\n",
    " - optimizer\n",
    " - learning rate (if applicable to optimizer)\n",
    " - momentum (if applicable to optimizer)\n",
    " - activation functions\n",
    " - network weight initialization\n",
    " - dropout regularization\n",
    " - number of neurons in the hidden layer\n",
    " \n",
    " You must use Grid Search and Cross Validation for your initial pass of the above hyperparameters\n",
    " \n",
    " Try and get the maximum accuracy possible out of this data! You'll save big telecoms millions! Doesn't that sound great?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NNJ-tOBs4jM1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7043, 21)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerID</th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>...</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7590-VHVEG</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5575-GNVDE</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>34</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.5</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3668-QPYBK</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7795-CFOCW</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>45</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9237-HQITU</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   customerID  gender  SeniorCitizen Partner Dependents  tenure PhoneService  \\\n",
       "0  7590-VHVEG  Female              0     Yes         No       1           No   \n",
       "1  5575-GNVDE    Male              0      No         No      34          Yes   \n",
       "2  3668-QPYBK    Male              0      No         No       2          Yes   \n",
       "3  7795-CFOCW    Male              0      No         No      45           No   \n",
       "4  9237-HQITU  Female              0      No         No       2          Yes   \n",
       "\n",
       "      MultipleLines InternetService OnlineSecurity  ... DeviceProtection  \\\n",
       "0  No phone service             DSL             No  ...               No   \n",
       "1                No             DSL            Yes  ...              Yes   \n",
       "2                No             DSL            Yes  ...               No   \n",
       "3  No phone service             DSL            Yes  ...              Yes   \n",
       "4                No     Fiber optic             No  ...               No   \n",
       "\n",
       "  TechSupport StreamingTV StreamingMovies        Contract PaperlessBilling  \\\n",
       "0          No          No              No  Month-to-month              Yes   \n",
       "1          No          No              No        One year               No   \n",
       "2          No          No              No  Month-to-month              Yes   \n",
       "3         Yes          No              No        One year               No   \n",
       "4          No          No              No  Month-to-month              Yes   \n",
       "\n",
       "               PaymentMethod MonthlyCharges  TotalCharges Churn  \n",
       "0           Electronic check          29.85         29.85    No  \n",
       "1               Mailed check          56.95        1889.5    No  \n",
       "2               Mailed check          53.85        108.15   Yes  \n",
       "3  Bank transfer (automatic)          42.30       1840.75    No  \n",
       "4           Electronic check          70.70        151.65   Yes  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Your Code Here #####\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('https://lambdaschool-data-science.s3.amazonaws.com/telco-churn/WA_Fn-UseC_-Telco-Customer-Churn+(1).csv')\n",
    "\n",
    "print(df.shape)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Churn               0\n",
       "OnlineSecurity      0\n",
       "gender              0\n",
       "SeniorCitizen       0\n",
       "Partner             0\n",
       "Dependents          0\n",
       "tenure              0\n",
       "PhoneService        0\n",
       "MultipleLines       0\n",
       "InternetService     0\n",
       "OnlineBackup        0\n",
       "TotalCharges        0\n",
       "DeviceProtection    0\n",
       "TechSupport         0\n",
       "StreamingTV         0\n",
       "StreamingMovies     0\n",
       "Contract            0\n",
       "PaperlessBilling    0\n",
       "PaymentMethod       0\n",
       "MonthlyCharges      0\n",
       "customerID          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().sort_values(ascending=False)\n",
    "# no missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerID</th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>...</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3969</th>\n",
       "      <td>2920-RNCEZ</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Credit card (automatic)</td>\n",
       "      <td>69.95</td>\n",
       "      <td>69.95</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5759</th>\n",
       "      <td>9985-MWVIX</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>70.15</td>\n",
       "      <td>70.15</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2792</th>\n",
       "      <td>9163-GHAYE</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>15</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>No</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>48.85</td>\n",
       "      <td>736.8</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4588</th>\n",
       "      <td>2105-PHWON</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>33</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Credit card (automatic)</td>\n",
       "      <td>95.00</td>\n",
       "      <td>3008.15</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6752</th>\n",
       "      <td>9928-BZVLZ</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>12</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Two year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>49.85</td>\n",
       "      <td>552.1</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      customerID  gender  SeniorCitizen Partner Dependents  tenure  \\\n",
       "3969  2920-RNCEZ    Male              0     Yes        Yes       1   \n",
       "5759  9985-MWVIX  Female              0      No         No       1   \n",
       "2792  9163-GHAYE  Female              0      No         No      15   \n",
       "4588  2105-PHWON  Female              0     Yes         No      33   \n",
       "6752  9928-BZVLZ  Female              0      No         No      12   \n",
       "\n",
       "     PhoneService     MultipleLines InternetService OnlineSecurity  ...  \\\n",
       "3969          Yes                No     Fiber optic             No  ...   \n",
       "5759          Yes                No     Fiber optic             No  ...   \n",
       "2792          Yes                No             DSL             No  ...   \n",
       "4588          Yes               Yes     Fiber optic             No  ...   \n",
       "6752           No  No phone service             DSL            Yes  ...   \n",
       "\n",
       "     DeviceProtection TechSupport StreamingTV StreamingMovies        Contract  \\\n",
       "3969               No          No          No              No  Month-to-month   \n",
       "5759               No          No          No              No  Month-to-month   \n",
       "2792               No          No          No              No  Month-to-month   \n",
       "4588              Yes         Yes          No             Yes  Month-to-month   \n",
       "6752              Yes         Yes          No             Yes        Two year   \n",
       "\n",
       "     PaperlessBilling            PaymentMethod MonthlyCharges  TotalCharges  \\\n",
       "3969              Yes  Credit card (automatic)          69.95         69.95   \n",
       "5759              Yes             Mailed check          70.15         70.15   \n",
       "2792               No         Electronic check          48.85         736.8   \n",
       "4588              Yes  Credit card (automatic)          95.00       3008.15   \n",
       "6752               No             Mailed check          49.85         552.1   \n",
       "\n",
       "     Churn  \n",
       "3969    No  \n",
       "5759   Yes  \n",
       "2792    No  \n",
       "4588    No  \n",
       "6752    No  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(df)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customerID           object\n",
       "gender               object\n",
       "SeniorCitizen         int64\n",
       "Partner              object\n",
       "Dependents           object\n",
       "tenure                int64\n",
       "PhoneService         object\n",
       "MultipleLines        object\n",
       "InternetService      object\n",
       "OnlineSecurity       object\n",
       "OnlineBackup         object\n",
       "DeviceProtection     object\n",
       "TechSupport          object\n",
       "StreamingTV          object\n",
       "StreamingMovies      object\n",
       "Contract             object\n",
       "PaperlessBilling     object\n",
       "PaymentMethod        object\n",
       "MonthlyCharges      float64\n",
       "TotalCharges         object\n",
       "Churn                object\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerID</th>\n",
       "      <th>gender</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>OnlineBackup</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5282</td>\n",
       "      <td>5282</td>\n",
       "      <td>5282</td>\n",
       "      <td>5282</td>\n",
       "      <td>5282</td>\n",
       "      <td>5282</td>\n",
       "      <td>5282</td>\n",
       "      <td>5282</td>\n",
       "      <td>5282</td>\n",
       "      <td>5282</td>\n",
       "      <td>5282</td>\n",
       "      <td>5282</td>\n",
       "      <td>5282</td>\n",
       "      <td>5282</td>\n",
       "      <td>5282</td>\n",
       "      <td>5282</td>\n",
       "      <td>5282</td>\n",
       "      <td>5282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>5282</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4978</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>8937-RDTHP</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td></td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>2662</td>\n",
       "      <td>2679</td>\n",
       "      <td>3653</td>\n",
       "      <td>4764</td>\n",
       "      <td>2541</td>\n",
       "      <td>2268</td>\n",
       "      <td>2603</td>\n",
       "      <td>2301</td>\n",
       "      <td>2333</td>\n",
       "      <td>2568</td>\n",
       "      <td>2111</td>\n",
       "      <td>2078</td>\n",
       "      <td>2884</td>\n",
       "      <td>3116</td>\n",
       "      <td>1770</td>\n",
       "      <td>8</td>\n",
       "      <td>3886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        customerID gender Partner Dependents PhoneService MultipleLines  \\\n",
       "count         5282   5282    5282       5282         5282          5282   \n",
       "unique        5282      2       2          2            2             3   \n",
       "top     8937-RDTHP   Male      No         No          Yes            No   \n",
       "freq             1   2662    2679       3653         4764          2541   \n",
       "\n",
       "       InternetService OnlineSecurity OnlineBackup DeviceProtection  \\\n",
       "count             5282           5282         5282             5282   \n",
       "unique               3              3            3                3   \n",
       "top        Fiber optic             No           No               No   \n",
       "freq              2268           2603         2301             2333   \n",
       "\n",
       "       TechSupport StreamingTV StreamingMovies        Contract  \\\n",
       "count         5282        5282            5282            5282   \n",
       "unique           3           3               3               3   \n",
       "top             No          No              No  Month-to-month   \n",
       "freq          2568        2111            2078            2884   \n",
       "\n",
       "       PaperlessBilling     PaymentMethod TotalCharges Churn  \n",
       "count              5282              5282         5282  5282  \n",
       "unique                2                 4         4978     2  \n",
       "top                 Yes  Electronic check                 No  \n",
       "freq               3116              1770            8  3886  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "train.describe(exclude=np.number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No                  2541\n",
       "Yes                 2223\n",
       "No phone service     518\n",
       "Name: MultipleLines, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['MultipleLines'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No                     2568\n",
       "Yes                    1555\n",
       "No internet service    1159\n",
       "Name: TechSupport, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['TechSupport'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No                     2078\n",
       "Yes                    2045\n",
       "No internet service    1159\n",
       "Name: StreamingMovies, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['StreamingMovies'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Month-to-month    2884\n",
       "Two year          1299\n",
       "One year          1099\n",
       "Name: Contract, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Contract'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Electronic check             1770\n",
       "Mailed check                 1213\n",
       "Credit card (automatic)      1153\n",
       "Bank transfer (automatic)    1146\n",
       "Name: PaymentMethod, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['PaymentMethod'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['TotalCharges'].value_counts(ascending=False).keys()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>OnlineBackup</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3969</th>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>1</td>\n",
       "      <td>Credit card (automatic)</td>\n",
       "      <td>69.95</td>\n",
       "      <td>69.95</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5759</th>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>1</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>70.15</td>\n",
       "      <td>70.15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2792</th>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>DSL</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>0</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>48.85</td>\n",
       "      <td>736.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4588</th>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>1</td>\n",
       "      <td>Credit card (automatic)</td>\n",
       "      <td>95.00</td>\n",
       "      <td>3008.15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6752</th>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>DSL</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Two year</td>\n",
       "      <td>0</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>49.85</td>\n",
       "      <td>552.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender  SeniorCitizen  Partner  Dependents  tenure  PhoneService  \\\n",
       "3969    Male              0        1           1       1             1   \n",
       "5759  Female              0        0           0       1             1   \n",
       "2792  Female              0        0           0      15             1   \n",
       "4588  Female              0        1           0      33             1   \n",
       "6752  Female              0        0           0      12             0   \n",
       "\n",
       "      MultipleLines InternetService  OnlineSecurity  OnlineBackup  \\\n",
       "3969              0     Fiber optic               0             0   \n",
       "5759              0     Fiber optic               0             0   \n",
       "2792              0             DSL               0             1   \n",
       "4588              1     Fiber optic               0             0   \n",
       "6752              2             DSL               1             0   \n",
       "\n",
       "      DeviceProtection  TechSupport  StreamingTV  StreamingMovies  \\\n",
       "3969                 0            0            0                0   \n",
       "5759                 0            0            0                0   \n",
       "2792                 0            0            0                0   \n",
       "4588                 1            1            0                1   \n",
       "6752                 1            1            0                1   \n",
       "\n",
       "            Contract  PaperlessBilling            PaymentMethod  \\\n",
       "3969  Month-to-month                 1  Credit card (automatic)   \n",
       "5759  Month-to-month                 1             Mailed check   \n",
       "2792  Month-to-month                 0         Electronic check   \n",
       "4588  Month-to-month                 1  Credit card (automatic)   \n",
       "6752        Two year                 0             Mailed check   \n",
       "\n",
       "      MonthlyCharges  TotalCharges  Churn  \n",
       "3969           69.95         69.95      0  \n",
       "5759           70.15         70.15      1  \n",
       "2792           48.85        736.80      0  \n",
       "4588           95.00       3008.15      0  \n",
       "6752           49.85        552.10      0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def wrangle(X):\n",
    "    Y = X.copy()\n",
    "    \n",
    "    Y = Y.drop('customerID', axis=1)\n",
    "    Y['TotalCharges'] = Y['TotalCharges'].replace(' ', np.nan)\n",
    "    Y['TotalCharges'] = Y['TotalCharges'].astype('float')\n",
    "    \n",
    "    boolean_cols = []\n",
    "    desc = Y.describe(exclude=np.number)\n",
    "    for column in desc.columns:\n",
    "        if desc.loc['top', column] == 'Yes' or desc.loc['top', column] == 'No':\n",
    "            boolean_cols.append(column)\n",
    "                \n",
    "    for column in boolean_cols:\n",
    "        Y[column] = Y[column].replace({'Yes': 1, 'No': 0, 'No phone service': 2,\n",
    "                                       'No internet service': 2})\n",
    "        Y[column] = Y[column].astype('int')\n",
    "    \n",
    "    return Y\n",
    "\n",
    "train2 = wrangle(train)\n",
    "train2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender               object\n",
       "SeniorCitizen         int64\n",
       "Partner               int64\n",
       "Dependents            int64\n",
       "tenure                int64\n",
       "PhoneService          int64\n",
       "MultipleLines         int64\n",
       "InternetService      object\n",
       "OnlineSecurity        int64\n",
       "OnlineBackup          int64\n",
       "DeviceProtection      int64\n",
       "TechSupport           int64\n",
       "StreamingTV           int64\n",
       "StreamingMovies       int64\n",
       "Contract             object\n",
       "PaperlessBilling      int64\n",
       "PaymentMethod        object\n",
       "MonthlyCharges      float64\n",
       "TotalCharges        float64\n",
       "Churn                 int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender               object\n",
       "SeniorCitizen         int64\n",
       "Partner               int64\n",
       "Dependents            int64\n",
       "tenure                int64\n",
       "PhoneService          int64\n",
       "MultipleLines         int64\n",
       "InternetService      object\n",
       "OnlineSecurity        int64\n",
       "OnlineBackup          int64\n",
       "DeviceProtection      int64\n",
       "TechSupport           int64\n",
       "StreamingTV           int64\n",
       "StreamingMovies       int64\n",
       "Contract             object\n",
       "PaperlessBilling      int64\n",
       "PaymentMethod        object\n",
       "MonthlyCharges      float64\n",
       "TotalCharges        float64\n",
       "Churn                 int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2 = wrangle(test)\n",
    "test2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting category_encoders\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a0/52/c54191ad3782de633ea3d6ee3bb2837bda0cf3bc97644bb6375cf14150a0/category_encoders-2.1.0-py2.py3-none-any.whl (100kB)\n",
      "\u001b[K    100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102kB 18.8MB/s a 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: statsmodels>=0.6.1 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from category_encoders) (0.9.0)\n",
      "Requirement already satisfied: pandas>=0.21.1 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from category_encoders) (0.24.2)\n",
      "Requirement already satisfied: patsy>=0.4.1 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from category_encoders) (0.5.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from category_encoders) (1.16.4)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from category_encoders) (0.21.3)\n",
      "Requirement already satisfied: scipy>=0.19.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from category_encoders) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from pandas>=0.21.1->category_encoders) (2.7.3)\n",
      "Requirement already satisfied: pytz>=2011k in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from pandas>=0.21.1->category_encoders) (2018.4)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from patsy>=0.4.1->category_encoders) (1.11.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from scikit-learn>=0.20.0->category_encoders) (0.13.2)\n",
      "Installing collected packages: category-encoders\n",
      "Successfully installed category-encoders-2.1.0\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "ohe = ce.OneHotEncoder(use_cat_names=True)\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "y_train = train2['Churn']\n",
    "X_train = train2.drop('Churn', axis=1)\n",
    "y_test = test2['Churn']\n",
    "X_test = test2.drop('Churn', axis=1)\n",
    "\n",
    "X_train_encoded = ohe.fit_transform(X_train)\n",
    "X_test_encoded = ohe.transform(X_test)\n",
    "X_train_imputed = imputer.fit_transform(X_train_encoded)\n",
    "X_test_imputed = imputer.transform(X_test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.99207983, -0.99207983, -0.43762788,  1.01449351,  1.49749125,\n",
       "        -1.27850622,  0.3297456 , -0.93825035,  1.15278973, -0.73572397,\n",
       "        -0.5301943 , -0.91005765, -1.00493856, -0.99439426, -0.92055952,\n",
       "        -1.07033271, -1.08221811,  0.91185747, -0.57108325, -0.51257204,\n",
       "         0.83373974,  1.89237755, -0.54599235, -0.70991995, -0.52638323,\n",
       "         0.18624156, -0.97622673],\n",
       "       [-1.0079834 ,  1.0079834 , -0.43762788, -0.98571355, -0.66778353,\n",
       "        -1.27850622,  0.3297456 , -0.93825035,  1.15278973, -0.73572397,\n",
       "        -0.5301943 , -0.91005765, -1.00493856, -0.99439426, -0.92055952,\n",
       "        -1.07033271, -1.08221811,  0.91185747, -0.57108325, -0.51257204,\n",
       "         0.83373974, -0.52843578,  1.8315275 , -0.70991995, -0.52638323,\n",
       "         0.19289923, -0.97613831],\n",
       "       [-1.0079834 ,  1.0079834 , -0.43762788, -0.98571355, -0.66778353,\n",
       "        -0.71036318,  0.3297456 , -0.93825035, -0.86746089,  1.35920541,\n",
       "        -0.5301943 , -0.91005765,  0.27720769, -0.99439426, -0.92055952,\n",
       "        -1.07033271, -1.08221811,  0.91185747, -0.57108325, -0.51257204,\n",
       "        -1.19941506, -0.52843578, -0.54599235,  1.40860952, -0.52638323,\n",
       "        -0.51614304, -0.6814048 ],\n",
       "       [-1.0079834 ,  1.0079834 , -0.43762788,  1.01449351, -0.66778353,\n",
       "         0.02010643,  0.3297456 ,  0.58241192,  1.15278973, -0.73572397,\n",
       "        -0.5301943 , -0.91005765, -1.00493856,  0.28418181,  0.33490017,\n",
       "        -1.07033271,  0.22795289,  0.91185747, -0.57108325, -0.51257204,\n",
       "         0.83373974,  1.89237755, -0.54599235, -0.70991995, -0.52638323,\n",
       "         1.02011521,  0.32278473],\n",
       "       [-1.0079834 ,  1.0079834 , -0.43762788, -0.98571355, -0.66778353,\n",
       "        -0.83210812, -3.03264096,  2.1030742 , -0.86746089,  1.35920541,\n",
       "        -0.5301943 ,  0.34239793, -1.00493856,  0.28418181,  0.33490017,\n",
       "        -1.07033271,  0.22795289, -1.09666261,  1.75105819, -0.51257204,\n",
       "        -1.19941506, -0.52843578,  1.8315275 , -0.70991995, -0.52638323,\n",
       "        -0.48285467, -0.76306276]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
    "X_test_scaled = scaler.transform(X_test_imputed)\n",
    "X_train_scaled[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5282 samples, validate on 1761 samples\n",
      "Epoch 1/100\n",
      "5282/5282 [==============================] - 2s 402us/sample - loss: 0.4637 - acc: 0.7683 - val_loss: 0.4381 - val_acc: 0.7927\n",
      "Epoch 2/100\n",
      "5282/5282 [==============================] - 1s 250us/sample - loss: 0.4206 - acc: 0.8020 - val_loss: 0.4339 - val_acc: 0.7927\n",
      "Epoch 3/100\n",
      "5282/5282 [==============================] - 1s 249us/sample - loss: 0.4135 - acc: 0.8050 - val_loss: 0.4363 - val_acc: 0.8001\n",
      "Epoch 4/100\n",
      "5282/5282 [==============================] - 1s 250us/sample - loss: 0.4089 - acc: 0.8069 - val_loss: 0.4347 - val_acc: 0.7978\n",
      "Epoch 5/100\n",
      "5282/5282 [==============================] - 1s 249us/sample - loss: 0.4062 - acc: 0.8069 - val_loss: 0.4329 - val_acc: 0.7995\n",
      "Epoch 6/100\n",
      "5282/5282 [==============================] - 1s 249us/sample - loss: 0.4029 - acc: 0.8082 - val_loss: 0.4314 - val_acc: 0.7967\n",
      "Epoch 7/100\n",
      "5282/5282 [==============================] - 1s 247us/sample - loss: 0.3996 - acc: 0.8116 - val_loss: 0.4349 - val_acc: 0.8007\n",
      "Epoch 8/100\n",
      "5282/5282 [==============================] - 1s 249us/sample - loss: 0.3980 - acc: 0.8112 - val_loss: 0.4306 - val_acc: 0.8035\n",
      "Epoch 9/100\n",
      "5282/5282 [==============================] - 1s 249us/sample - loss: 0.3958 - acc: 0.8131 - val_loss: 0.4351 - val_acc: 0.7973\n",
      "Epoch 10/100\n",
      "5282/5282 [==============================] - 1s 250us/sample - loss: 0.3922 - acc: 0.8147 - val_loss: 0.4336 - val_acc: 0.8001\n",
      "Epoch 11/100\n",
      "5282/5282 [==============================] - 1s 248us/sample - loss: 0.3904 - acc: 0.8152 - val_loss: 0.4363 - val_acc: 0.7944\n",
      "Epoch 12/100\n",
      "5282/5282 [==============================] - 1s 249us/sample - loss: 0.3885 - acc: 0.8162 - val_loss: 0.4366 - val_acc: 0.7973\n",
      "Epoch 13/100\n",
      "5282/5282 [==============================] - 1s 250us/sample - loss: 0.3862 - acc: 0.8169 - val_loss: 0.4393 - val_acc: 0.7950\n",
      "Epoch 14/100\n",
      "5282/5282 [==============================] - 1s 250us/sample - loss: 0.3841 - acc: 0.8154 - val_loss: 0.4345 - val_acc: 0.8001\n",
      "Epoch 15/100\n",
      "5282/5282 [==============================] - 1s 251us/sample - loss: 0.3809 - acc: 0.8139 - val_loss: 0.4584 - val_acc: 0.7768\n",
      "Epoch 16/100\n",
      "5282/5282 [==============================] - 1s 248us/sample - loss: 0.3794 - acc: 0.8156 - val_loss: 0.4431 - val_acc: 0.7978\n",
      "Epoch 17/100\n",
      "5282/5282 [==============================] - 1s 248us/sample - loss: 0.3774 - acc: 0.8192 - val_loss: 0.4404 - val_acc: 0.7978\n",
      "Epoch 18/100\n",
      "5282/5282 [==============================] - 1s 248us/sample - loss: 0.3751 - acc: 0.8203 - val_loss: 0.4472 - val_acc: 0.8007\n",
      "Epoch 19/100\n",
      "5282/5282 [==============================] - 1s 250us/sample - loss: 0.3731 - acc: 0.8215 - val_loss: 0.4469 - val_acc: 0.7893\n",
      "Epoch 20/100\n",
      "5282/5282 [==============================] - 1s 248us/sample - loss: 0.3703 - acc: 0.8220 - val_loss: 0.4491 - val_acc: 0.7916\n",
      "Epoch 21/100\n",
      "5282/5282 [==============================] - 1s 254us/sample - loss: 0.3689 - acc: 0.8234 - val_loss: 0.4525 - val_acc: 0.7853\n",
      "Epoch 22/100\n",
      "5282/5282 [==============================] - 1s 248us/sample - loss: 0.3671 - acc: 0.8254 - val_loss: 0.4537 - val_acc: 0.7853\n",
      "Epoch 23/100\n",
      "5282/5282 [==============================] - 1s 250us/sample - loss: 0.3658 - acc: 0.8285 - val_loss: 0.4557 - val_acc: 0.7916\n",
      "Epoch 24/100\n",
      "5282/5282 [==============================] - 1s 249us/sample - loss: 0.3634 - acc: 0.8268 - val_loss: 0.4553 - val_acc: 0.7882\n",
      "Epoch 25/100\n",
      "5282/5282 [==============================] - 1s 250us/sample - loss: 0.3598 - acc: 0.8302 - val_loss: 0.4578 - val_acc: 0.7865\n",
      "Epoch 26/100\n",
      "5282/5282 [==============================] - 1s 251us/sample - loss: 0.3570 - acc: 0.8321 - val_loss: 0.4573 - val_acc: 0.7893\n",
      "Epoch 27/100\n",
      "5282/5282 [==============================] - 1s 249us/sample - loss: 0.3564 - acc: 0.8275 - val_loss: 0.4604 - val_acc: 0.7825\n",
      "Epoch 28/100\n",
      "5282/5282 [==============================] - 1s 248us/sample - loss: 0.3538 - acc: 0.8355 - val_loss: 0.4664 - val_acc: 0.7819\n",
      "Epoch 29/100\n",
      "5282/5282 [==============================] - 1s 248us/sample - loss: 0.3508 - acc: 0.8317 - val_loss: 0.4635 - val_acc: 0.7859\n",
      "Epoch 30/100\n",
      "5282/5282 [==============================] - 1s 248us/sample - loss: 0.3506 - acc: 0.8342 - val_loss: 0.4596 - val_acc: 0.7882\n",
      "Epoch 31/100\n",
      "5282/5282 [==============================] - 1s 259us/sample - loss: 0.3493 - acc: 0.8334 - val_loss: 0.4660 - val_acc: 0.7888\n",
      "Epoch 32/100\n",
      "5282/5282 [==============================] - 1s 247us/sample - loss: 0.3467 - acc: 0.8372 - val_loss: 0.4790 - val_acc: 0.7763\n",
      "Epoch 33/100\n",
      "5282/5282 [==============================] - 1s 255us/sample - loss: 0.3461 - acc: 0.8353 - val_loss: 0.4708 - val_acc: 0.7859\n",
      "Epoch 34/100\n",
      "5282/5282 [==============================] - 1s 258us/sample - loss: 0.3417 - acc: 0.8342 - val_loss: 0.4790 - val_acc: 0.7859\n",
      "Epoch 35/100\n",
      "5282/5282 [==============================] - 1s 257us/sample - loss: 0.3407 - acc: 0.8387 - val_loss: 0.4777 - val_acc: 0.7763\n",
      "Epoch 36/100\n",
      "5282/5282 [==============================] - 1s 268us/sample - loss: 0.3403 - acc: 0.8402 - val_loss: 0.4786 - val_acc: 0.7836\n",
      "Epoch 37/100\n",
      "5282/5282 [==============================] - 1s 252us/sample - loss: 0.3376 - acc: 0.8395 - val_loss: 0.4790 - val_acc: 0.7819\n",
      "Epoch 38/100\n",
      "5282/5282 [==============================] - 1s 248us/sample - loss: 0.3356 - acc: 0.8421 - val_loss: 0.4813 - val_acc: 0.7819\n",
      "Epoch 39/100\n",
      "5282/5282 [==============================] - 1s 249us/sample - loss: 0.3358 - acc: 0.8431 - val_loss: 0.4922 - val_acc: 0.7751\n",
      "Epoch 40/100\n",
      "5282/5282 [==============================] - 1s 249us/sample - loss: 0.3318 - acc: 0.8423 - val_loss: 0.4903 - val_acc: 0.7723\n",
      "Epoch 41/100\n",
      "5282/5282 [==============================] - 1s 251us/sample - loss: 0.3322 - acc: 0.8468 - val_loss: 0.4893 - val_acc: 0.7740\n",
      "Epoch 42/100\n",
      "5282/5282 [==============================] - 1s 250us/sample - loss: 0.3278 - acc: 0.8432 - val_loss: 0.5077 - val_acc: 0.7655\n",
      "Epoch 43/100\n",
      "5282/5282 [==============================] - 1s 249us/sample - loss: 0.3282 - acc: 0.8463 - val_loss: 0.4963 - val_acc: 0.7791\n",
      "Epoch 44/100\n",
      "5282/5282 [==============================] - 1s 250us/sample - loss: 0.3253 - acc: 0.8432 - val_loss: 0.4978 - val_acc: 0.7751\n",
      "Epoch 45/100\n",
      "5282/5282 [==============================] - 1s 250us/sample - loss: 0.3248 - acc: 0.8446 - val_loss: 0.4937 - val_acc: 0.7785\n",
      "Epoch 46/100\n",
      "5282/5282 [==============================] - 1s 249us/sample - loss: 0.3242 - acc: 0.8484 - val_loss: 0.5003 - val_acc: 0.7751\n",
      "Epoch 47/100\n",
      "5282/5282 [==============================] - 1s 250us/sample - loss: 0.3203 - acc: 0.8519 - val_loss: 0.5042 - val_acc: 0.7808\n",
      "Epoch 48/100\n",
      "5282/5282 [==============================] - 1s 250us/sample - loss: 0.3198 - acc: 0.8502 - val_loss: 0.5097 - val_acc: 0.7643\n",
      "Epoch 49/100\n",
      "5282/5282 [==============================] - 1s 249us/sample - loss: 0.3183 - acc: 0.8510 - val_loss: 0.5151 - val_acc: 0.7677\n",
      "Epoch 50/100\n",
      "5282/5282 [==============================] - 1s 249us/sample - loss: 0.3187 - acc: 0.8514 - val_loss: 0.5067 - val_acc: 0.7717\n",
      "Epoch 51/100\n",
      "5282/5282 [==============================] - 1s 250us/sample - loss: 0.3143 - acc: 0.8519 - val_loss: 0.5257 - val_acc: 0.7643\n",
      "Epoch 52/100\n",
      "5282/5282 [==============================] - 1s 248us/sample - loss: 0.3139 - acc: 0.8540 - val_loss: 0.5222 - val_acc: 0.7689\n",
      "Epoch 53/100\n",
      "5282/5282 [==============================] - 1s 250us/sample - loss: 0.3113 - acc: 0.8559 - val_loss: 0.5235 - val_acc: 0.7547\n",
      "Epoch 54/100\n",
      "5282/5282 [==============================] - 1s 250us/sample - loss: 0.3112 - acc: 0.8550 - val_loss: 0.5187 - val_acc: 0.7677\n",
      "Epoch 55/100\n",
      "5282/5282 [==============================] - 1s 250us/sample - loss: 0.3071 - acc: 0.8578 - val_loss: 0.5268 - val_acc: 0.7677\n",
      "Epoch 56/100\n",
      "5282/5282 [==============================] - 1s 250us/sample - loss: 0.3078 - acc: 0.8573 - val_loss: 0.5287 - val_acc: 0.7609\n",
      "Epoch 57/100\n",
      "5282/5282 [==============================] - 1s 251us/sample - loss: 0.3070 - acc: 0.8627 - val_loss: 0.5388 - val_acc: 0.7570\n",
      "Epoch 58/100\n",
      "5282/5282 [==============================] - 1s 250us/sample - loss: 0.3052 - acc: 0.8555 - val_loss: 0.5222 - val_acc: 0.7757\n",
      "Epoch 59/100\n",
      "5282/5282 [==============================] - 1s 248us/sample - loss: 0.3040 - acc: 0.8620 - val_loss: 0.5272 - val_acc: 0.7649\n",
      "Epoch 60/100\n",
      "5282/5282 [==============================] - 1s 250us/sample - loss: 0.3033 - acc: 0.8612 - val_loss: 0.5354 - val_acc: 0.7677\n",
      "Epoch 61/100\n",
      "5282/5282 [==============================] - 1s 248us/sample - loss: 0.3005 - acc: 0.8635 - val_loss: 0.5515 - val_acc: 0.7734\n",
      "Epoch 62/100\n",
      "5282/5282 [==============================] - 1s 249us/sample - loss: 0.3002 - acc: 0.8561 - val_loss: 0.5396 - val_acc: 0.7660\n",
      "Epoch 63/100\n",
      "5282/5282 [==============================] - 1s 251us/sample - loss: 0.2983 - acc: 0.8603 - val_loss: 0.5426 - val_acc: 0.7643\n",
      "Epoch 64/100\n",
      "5282/5282 [==============================] - 1s 251us/sample - loss: 0.2989 - acc: 0.8648 - val_loss: 0.5439 - val_acc: 0.7780\n",
      "Epoch 65/100\n",
      "5282/5282 [==============================] - 1s 251us/sample - loss: 0.2975 - acc: 0.8654 - val_loss: 0.5557 - val_acc: 0.7700\n",
      "Epoch 66/100\n",
      "5282/5282 [==============================] - 1s 252us/sample - loss: 0.2931 - acc: 0.8639 - val_loss: 0.5450 - val_acc: 0.7649\n",
      "Epoch 67/100\n",
      "5282/5282 [==============================] - 1s 250us/sample - loss: 0.2940 - acc: 0.8626 - val_loss: 0.5690 - val_acc: 0.7496\n",
      "Epoch 68/100\n",
      "5282/5282 [==============================] - 1s 250us/sample - loss: 0.2951 - acc: 0.8654 - val_loss: 0.5500 - val_acc: 0.7712\n",
      "Epoch 69/100\n",
      "5282/5282 [==============================] - 1s 250us/sample - loss: 0.2896 - acc: 0.8650 - val_loss: 0.5591 - val_acc: 0.7768\n",
      "Epoch 70/100\n",
      "5282/5282 [==============================] - 1s 253us/sample - loss: 0.2887 - acc: 0.8680 - val_loss: 0.5641 - val_acc: 0.7712\n",
      "Epoch 71/100\n",
      "5282/5282 [==============================] - 1s 250us/sample - loss: 0.2903 - acc: 0.8684 - val_loss: 0.5717 - val_acc: 0.7456\n",
      "Epoch 72/100\n",
      "5282/5282 [==============================] - 1s 250us/sample - loss: 0.2869 - acc: 0.8696 - val_loss: 0.5751 - val_acc: 0.7638\n",
      "Epoch 73/100\n",
      "5282/5282 [==============================] - 1s 249us/sample - loss: 0.2871 - acc: 0.8694 - val_loss: 0.5732 - val_acc: 0.7706\n",
      "Epoch 74/100\n",
      "5282/5282 [==============================] - 1s 251us/sample - loss: 0.2853 - acc: 0.8713 - val_loss: 0.5792 - val_acc: 0.7723\n",
      "Epoch 75/100\n",
      "5282/5282 [==============================] - 1s 250us/sample - loss: 0.2828 - acc: 0.8679 - val_loss: 0.6018 - val_acc: 0.7291\n",
      "Epoch 76/100\n",
      "5282/5282 [==============================] - 1s 249us/sample - loss: 0.2841 - acc: 0.8679 - val_loss: 0.5837 - val_acc: 0.7570\n",
      "Epoch 77/100\n",
      "5282/5282 [==============================] - 1s 251us/sample - loss: 0.2828 - acc: 0.8694 - val_loss: 0.5777 - val_acc: 0.7592\n",
      "Epoch 78/100\n",
      "5282/5282 [==============================] - 1s 249us/sample - loss: 0.2793 - acc: 0.8703 - val_loss: 0.5925 - val_acc: 0.7694\n",
      "Epoch 79/100\n",
      "5282/5282 [==============================] - 1s 249us/sample - loss: 0.2798 - acc: 0.8730 - val_loss: 0.5831 - val_acc: 0.7689\n",
      "Epoch 80/100\n",
      "5282/5282 [==============================] - 1s 250us/sample - loss: 0.2792 - acc: 0.8735 - val_loss: 0.5940 - val_acc: 0.7553\n",
      "Epoch 81/100\n",
      "5282/5282 [==============================] - 1s 251us/sample - loss: 0.2778 - acc: 0.8705 - val_loss: 0.5861 - val_acc: 0.7729\n",
      "Epoch 82/100\n",
      "5282/5282 [==============================] - 1s 250us/sample - loss: 0.2759 - acc: 0.8709 - val_loss: 0.6092 - val_acc: 0.7439\n",
      "Epoch 83/100\n",
      "5282/5282 [==============================] - 1s 249us/sample - loss: 0.2772 - acc: 0.8752 - val_loss: 0.6121 - val_acc: 0.7524\n",
      "Epoch 84/100\n",
      "5282/5282 [==============================] - 1s 249us/sample - loss: 0.2764 - acc: 0.8694 - val_loss: 0.6020 - val_acc: 0.7405\n",
      "Epoch 85/100\n",
      "5282/5282 [==============================] - 1s 251us/sample - loss: 0.2728 - acc: 0.8764 - val_loss: 0.6141 - val_acc: 0.7598\n",
      "Epoch 86/100\n",
      "5282/5282 [==============================] - 1s 250us/sample - loss: 0.2733 - acc: 0.8745 - val_loss: 0.6228 - val_acc: 0.7439\n",
      "Epoch 87/100\n",
      "5282/5282 [==============================] - 1s 250us/sample - loss: 0.2699 - acc: 0.8720 - val_loss: 0.6248 - val_acc: 0.7445\n",
      "Epoch 88/100\n",
      "5282/5282 [==============================] - 1s 251us/sample - loss: 0.2743 - acc: 0.8726 - val_loss: 0.6192 - val_acc: 0.7433\n",
      "Epoch 89/100\n",
      "5282/5282 [==============================] - 1s 251us/sample - loss: 0.2686 - acc: 0.8788 - val_loss: 0.6199 - val_acc: 0.7581\n",
      "Epoch 90/100\n",
      "5282/5282 [==============================] - 1s 250us/sample - loss: 0.2677 - acc: 0.8792 - val_loss: 0.6253 - val_acc: 0.7422\n",
      "Epoch 91/100\n",
      "5282/5282 [==============================] - 1s 252us/sample - loss: 0.2685 - acc: 0.8766 - val_loss: 0.6190 - val_acc: 0.7643\n",
      "Epoch 92/100\n",
      "5282/5282 [==============================] - 1s 249us/sample - loss: 0.2664 - acc: 0.8764 - val_loss: 0.6487 - val_acc: 0.7382\n",
      "Epoch 93/100\n",
      "5282/5282 [==============================] - 1s 251us/sample - loss: 0.2662 - acc: 0.8735 - val_loss: 0.6203 - val_acc: 0.7677\n",
      "Epoch 94/100\n",
      "5282/5282 [==============================] - 1s 250us/sample - loss: 0.2646 - acc: 0.8771 - val_loss: 0.6255 - val_acc: 0.7581\n",
      "Epoch 95/100\n",
      "5282/5282 [==============================] - 1s 249us/sample - loss: 0.2649 - acc: 0.8768 - val_loss: 0.6341 - val_acc: 0.7456\n",
      "Epoch 96/100\n",
      "5282/5282 [==============================] - 1s 249us/sample - loss: 0.2644 - acc: 0.8785 - val_loss: 0.6372 - val_acc: 0.7513\n",
      "Epoch 97/100\n",
      "5282/5282 [==============================] - 1s 250us/sample - loss: 0.2630 - acc: 0.8826 - val_loss: 0.6281 - val_acc: 0.7439\n",
      "Epoch 98/100\n",
      "5282/5282 [==============================] - 1s 251us/sample - loss: 0.2614 - acc: 0.8817 - val_loss: 0.6447 - val_acc: 0.7535\n",
      "Epoch 99/100\n",
      "5282/5282 [==============================] - 1s 250us/sample - loss: 0.2595 - acc: 0.8790 - val_loss: 0.6401 - val_acc: 0.7547\n",
      "Epoch 100/100\n",
      "5282/5282 [==============================] - 1s 252us/sample - loss: 0.2591 - acc: 0.8828 - val_loss: 0.6434 - val_acc: 0.7530\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f96235200b8>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "inputs = X_train_scaled.shape[1]\n",
    "epochs = 100\n",
    "batch_size = 10\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(30, activation='relu', input_shape=(inputs,)))\n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train_scaled, y_train,\n",
    "          validation_data=(X_test_scaled, y_test),\n",
    "          epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1761/1761 [==============================] - 0s 28us/sample - loss: 0.6434 - acc: 0.7530\n",
      "acc: 75.29812455177307%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test_scaled, y_test)\n",
    "print(f'{model.metrics_names[1]}: {scores[1]*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.7906096140370591 using {'batch_size': 80, 'epochs': 75}\n",
      "Mean: 0.7737599415045171, Stdev: 0.0006993917253716697 with: {'batch_size': 10, 'epochs': 75}\n",
      "Mean: 0.7837940199340848, Stdev: 0.005176316228158162 with: {'batch_size': 20, 'epochs': 75}\n",
      "Mean: 0.7864445160731633, Stdev: 0.006325068786510369 with: {'batch_size': 40, 'epochs': 75}\n",
      "Mean: 0.785119275135418, Stdev: 0.007001858867745473 with: {'batch_size': 60, 'epochs': 75}\n",
      "Mean: 0.7906096140370591, Stdev: 0.002705758826145271 with: {'batch_size': 80, 'epochs': 75}\n",
      "Mean: 0.7902309625878202, Stdev: 0.004788000738580977 with: {'batch_size': 100, 'epochs': 75}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "np.random.seed(500)\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_dim=inputs, activation='relu'))\n",
    "    model.add(Dense(20, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "\n",
    "param_grid = {'batch_size': [10, 20, 40, 60, 80, 100],\n",
    "              'epochs': [75]}\n",
    "\n",
    "def grid_search(model, param_grid, X, y):\n",
    "    grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=6)\n",
    "    grid_result = grid.fit(X, y)\n",
    "\n",
    "    print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}')\n",
    "    means = grid_result.cv_results_['mean_test_score']\n",
    "    stds = grid_result.cv_results_['std_test_score']\n",
    "    params = grid_result.cv_results_['params']\n",
    "    for mean, stdev, param in zip(means, stds, params):\n",
    "        print(f'Mean: {mean}, Stdev: {stdev} with: {param}')\n",
    "        \n",
    "grid_search(model, param_grid, X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.8029155483619592 using {'optimizer': 'sgd'}\n",
      "Mean: 0.8029155483619592, Stdev: 0.004789530356425239 with: {'optimizer': 'sgd'}\n",
      "Mean: 0.7934494633333379, Stdev: 0.004630640949935429 with: {'optimizer': 'rmsprop'}\n",
      "Mean: 0.7815221428013533, Stdev: 0.007748155857504255 with: {'optimizer': 'adagrad'}\n",
      "Mean: 0.46308216724554635, Stdev: 0.07219355348094761 with: {'optimizer': 'adadelta'}\n",
      "Mean: 0.801400978054706, Stdev: 0.004214593714306208 with: {'optimizer': 'adam'}\n",
      "Mean: 0.800075720246657, Stdev: 0.006082710681173571 with: {'optimizer': 'adamax'}\n",
      "Mean: 0.7902309721006403, Stdev: 0.011857101910926733 with: {'optimizer': 'nadam'}\n"
     ]
    }
   ],
   "source": [
    "def create_model(optimizer):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_dim=inputs, activation='relu'))\n",
    "    model.add(Dense(20, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, batch_size=80, epochs=75, verbose=0)\n",
    "\n",
    "param_grid = {'optimizer': ['sgd', 'rmsprop', 'adagrad', 'adadelta', 'adam', 'adamax', 'nadam']}\n",
    "\n",
    "grid_search(model, param_grid, X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.7976145496403616 using {'learning_rate': 0.01}\n",
      "Mean: 0.7703521455250559, Stdev: 0.006724029694641868 with: {'learning_rate': 0.001}\n",
      "Mean: 0.7976145496403616, Stdev: 0.0010036856268492952 with: {'learning_rate': 0.01}\n",
      "Mean: 0.7906096118930072, Stdev: 0.0042128456945346475 with: {'learning_rate': 0.1}\n",
      "Mean: 0.7868231804205675, Stdev: 0.007167711802994597 with: {'learning_rate': 0.2}\n",
      "Mean: 0.7786823113119905, Stdev: 0.012297443033994526 with: {'learning_rate': 0.3}\n",
      "Mean: 0.7629685878460265, Stdev: 0.015163232947735715 with: {'learning_rate': 0.5}\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "def create_model(learning_rate):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_dim=inputs, activation='relu'))\n",
    "    model.add(Dense(20, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    sgd = SGD(lr=learning_rate, momentum=0.0, nesterov=False)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, batch_size=80, epochs=75, verbose=0)\n",
    "\n",
    "param_grid = {'learning_rate': [.001, .01, .1, .2, .3, .5]}\n",
    "\n",
    "grid_search(model, param_grid, X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.7976145440432575 using {'learning_rate': 0.02}\n",
      "Mean: 0.7926921548151871, Stdev: 0.002382301809269182 with: {'learning_rate': 0.005}\n",
      "Mean: 0.7949640293412026, Stdev: 0.00489672463133881 with: {'learning_rate': 0.008}\n",
      "Mean: 0.7951533539599426, Stdev: 0.00217526565383601 with: {'learning_rate': 0.01}\n",
      "Mean: 0.7976145440432575, Stdev: 0.0057081861068193785 with: {'learning_rate': 0.02}\n",
      "Mean: 0.7943960774333041, Stdev: 0.0013921961202719526 with: {'learning_rate': 0.03}\n",
      "Mean: 0.7943960618607161, Stdev: 0.0060314851359607995 with: {'learning_rate': 0.05}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'learning_rate': [.005, .008, .01, .02, .03, .05]}\n",
    "\n",
    "grid_search(model, param_grid, X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.8010223374160028 using {'momentum': 0.1}\n",
      "Mean: 0.7979931665026568, Stdev: 0.005033486666759678 with: {'momentum': 0.0}\n",
      "Mean: 0.8010223374160028, Stdev: 0.0023406198174810364 with: {'momentum': 0.1}\n",
      "Mean: 0.7998863947815806, Stdev: 0.00515340990742532 with: {'momentum': 0.2}\n",
      "Mean: 0.7974252422868822, Stdev: 0.0031936718998612735 with: {'momentum': 0.5}\n",
      "Mean: 0.7900416539253406, Stdev: 0.006945337788922962 with: {'momentum': 0.7}\n",
      "Mean: 0.7820901055310722, Stdev: 0.003993895992655471 with: {'momentum': 0.9}\n"
     ]
    }
   ],
   "source": [
    "def create_model(momentum):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_dim=inputs, activation='relu'))\n",
    "    model.add(Dense(20, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    sgd = SGD(lr=0.02, momentum=momentum, nesterov=False)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, batch_size=80, epochs=75, verbose=0)\n",
    "\n",
    "param_grid = {'momentum': [0.0, 0.1, 0.2, 0.5, 0.7, 0.9]}\n",
    "\n",
    "grid_search(model, param_grid, X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.8049980930445186 using {'function': 'softplus'}\n",
      "Mean: 0.8021582636315008, Stdev: 0.00470920841058585 with: {'function': 'elu'}\n",
      "Mean: 0.7357061707648487, Stdev: 0.004241114820910208 with: {'function': 'softmax'}\n",
      "Mean: 0.8019689493719171, Stdev: 0.0021562637741134897 with: {'function': 'selu'}\n",
      "Mean: 0.8049980930445186, Stdev: 0.0026515756683963302 with: {'function': 'softplus'}\n",
      "Mean: 0.7998864038317369, Stdev: 0.0011620142823621955 with: {'function': 'softsign'}\n",
      "Mean: 0.8008330136435992, Stdev: 0.0012103523988104764 with: {'function': 'relu'}\n",
      "Mean: 0.800454363492076, Stdev: 0.003454084639723943 with: {'function': 'tanh'}\n",
      "Mean: 0.8008330218474191, Stdev: 0.0019680680950556243 with: {'function': 'sigmoid'}\n",
      "Mean: 0.7943960683831479, Stdev: 0.006611757441699523 with: {'function': 'hard_sigmoid'}\n",
      "Mean: 0.7357061707648487, Stdev: 0.004241114820910208 with: {'function': 'exponential'}\n",
      "Mean: 0.7868231695987473, Stdev: 0.019948397053356232 with: {'function': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "def create_model(function):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_dim=inputs, activation=function))\n",
    "    model.add(Dense(20, activation=function))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    sgd = SGD(lr=0.02, momentum=0.1, nesterov=False)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, batch_size=80, epochs=75, verbose=0)\n",
    "\n",
    "param_grid = {'function': ['elu', 'softmax', 'selu', 'softplus', 'softsign', 'relu',\n",
    "                           'tanh', 'sigmoid', 'hard_sigmoid', 'exponential', 'linear']}\n",
    "\n",
    "grid_search(model, param_grid, X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.8000757254600886 using {'function': 'softsign'}\n",
      "Mean: 0.57951533741366, Stdev: 0.22192948679151214 with: {'function': 'elu'}\n",
      "Mean: 0.26429382924079353, Stdev: 0.004241138415818782 with: {'function': 'softmax'}\n",
      "Mean: 0.57951533741366, Stdev: 0.22192948679151214 with: {'function': 'selu'}\n",
      "Mean: 0.6177584126179799, Stdev: 0.253956445009295 with: {'function': 'softplus'}\n",
      "Mean: 0.8000757254600886, Stdev: 0.0026239261169960994 with: {'function': 'softsign'}\n",
      "Mean: 0.4185914494624782, Stdev: 0.2212420364371055 with: {'function': 'relu'}\n",
      "Mean: 0.6213555384296127, Stdev: 0.25651897307662236 with: {'function': 'tanh'}\n",
      "Mean: 0.8000757194003206, Stdev: 0.0011745233987697265 with: {'function': 'sigmoid'}\n",
      "Mean: 0.44244603822850587, Stdev: 0.2529784747542864 with: {'function': 'hard_sigmoid'}\n",
      "Mean: 0.7794396045622344, Stdev: 0.03202923789736958 with: {'function': 'exponential'}\n",
      "Mean: 0.7357061707648487, Stdev: 0.004241114820910208 with: {'function': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "def create_model(function):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_dim=inputs, activation='softplus'))\n",
    "    model.add(Dense(20, activation='softplus'))\n",
    "    model.add(Dense(1, activation=function))\n",
    "    sgd = SGD(lr=0.02, momentum=0.1, nesterov=False)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, batch_size=80, epochs=75, verbose=0)\n",
    "\n",
    "param_grid = {'function': ['elu', 'softmax', 'selu', 'softplus', 'softsign', 'relu',\n",
    "                           'tanh', 'sigmoid', 'hard_sigmoid', 'exponential', 'linear']}\n",
    "\n",
    "grid_search(model, param_grid, X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.7830367275301772 using {'init': 'glorot_normal'}\n",
      "Mean: 0.7578568667207239, Stdev: 0.030563801920980054 with: {'init': 'uniform'}\n",
      "Mean: 0.7754638372655621, Stdev: 0.029183413684943402 with: {'init': 'lecun_uniform'}\n",
      "Mean: 0.7357061707648487, Stdev: 0.004241114820910208 with: {'init': 'normal'}\n",
      "Mean: 0.7357061707648487, Stdev: 0.004241114820910208 with: {'init': 'zero'}\n",
      "Mean: 0.7830367275301772, Stdev: 0.029386874962379454 with: {'init': 'glorot_normal'}\n",
      "Mean: 0.5965543414033394, Stdev: 0.2352722289701981 with: {'init': 'glorot_uniform'}\n",
      "Mean: 0.7790609412078648, Stdev: 0.02666910657265961 with: {'init': 'he_normal'}\n",
      "Mean: 0.6226808037700549, Stdev: 0.25045677616645623 with: {'init': 'he_uniform'}\n"
     ]
    }
   ],
   "source": [
    "def create_model(init):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_dim=inputs, kernel_initializer=init, activation='softplus'))\n",
    "    model.add(Dense(20, kernel_initializer=init, activation='softplus'))\n",
    "    model.add(Dense(1, kernel_initializer=init, activation='softsign'))\n",
    "    sgd = SGD(lr=0.02, momentum=0.1, nesterov=False)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, batch_size=80, epochs=75, verbose=0)\n",
    "\n",
    "param_grid = {'init': ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal',\n",
    "                       'glorot_uniform', 'he_normal', 'he_uniform']}\n",
    "\n",
    "grid_search(model, param_grid, X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.7807648632166196 using {'dropout': 0.01}\n",
      "Mean: 0.7758424792132654, Stdev: 0.0315353363575242 with: {'dropout': 0}\n",
      "Mean: 0.7807648632166196, Stdev: 0.03494916180552391 with: {'dropout': 0.01}\n",
      "Mean: 0.6137826660396203, Stdev: 0.2515076516050917 with: {'dropout': 0.1}\n",
      "Mean: 0.588981446957823, Stdev: 0.24203495369077083 with: {'dropout': 0.2}\n",
      "Mean: 0.39170768528059546, Stdev: 0.17616576839055537 with: {'dropout': 0.35}\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "def create_model(dropout):\n",
    "    model = Sequential()\n",
    "    model.add(Dropout(dropout, input_shape=(inputs,)))\n",
    "    model.add(Dense(20, kernel_initializer='glorot_normal', activation='softplus'))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(20, kernel_initializer='glorot_normal', activation='softplus'))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(1, kernel_initializer='glorot_normal', activation='softsign'))\n",
    "    sgd = SGD(lr=0.02, momentum=0.1, nesterov=False)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, batch_size=80, epochs=75, verbose=0)\n",
    "\n",
    "param_grid = {'dropout': [0, 0.01, 0.1, 0.2, 0.35]}\n",
    "\n",
    "grid_search(model, param_grid, X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.7485800717126145 using {'neurons': 10}\n",
      "Mean: 0.7485800717126145, Stdev: 0.038123564963497336 with: {'neurons': 10}\n",
      "Mean: 0.6224914826043669, Stdev: 0.2502769628112886 with: {'neurons': 15}\n",
      "Mean: 0.6173797719792767, Stdev: 0.2537053195440457 with: {'neurons': 20}\n",
      "Mean: 0.5976902859730505, Stdev: 0.23509494910858122 with: {'neurons': 30}\n",
      "Mean: 0.6425596197890043, Stdev: 0.1833404143097182 with: {'neurons': 50}\n"
     ]
    }
   ],
   "source": [
    "def create_model(neurons):\n",
    "    model = Sequential()\n",
    "    model.add(Dropout(0.01, input_shape=(inputs,)))\n",
    "    model.add(Dense(neurons, kernel_initializer='glorot_normal', activation='softplus'))\n",
    "    model.add(Dropout(0.01))\n",
    "    model.add(Dense(neurons, kernel_initializer='glorot_normal', activation='softplus'))\n",
    "    model.add(Dropout(0.01))\n",
    "    model.add(Dense(1, kernel_initializer='glorot_normal', activation='softsign'))\n",
    "    sgd = SGD(lr=0.02, momentum=0.1, nesterov=False)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, batch_size=80, epochs=75, verbose=0)\n",
    "\n",
    "param_grid = {'neurons': [10, 15, 20, 30, 50]}\n",
    "\n",
    "grid_search(model, param_grid, X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.8032942032642502 using {'epochs': 200}\n",
      "Mean: 0.7680802787514809, Stdev: 0.025943771009866334 with: {'epochs': 25}\n",
      "Mean: 0.48864067352346197, Stdev: 0.22171086963817635 with: {'epochs': 50}\n",
      "Mean: 0.4403635047796503, Stdev: 0.25202559233152877 with: {'epochs': 75}\n",
      "Mean: 0.7943960567149914, Stdev: 0.0053981066145754614 with: {'epochs': 100}\n",
      "Mean: 0.8032942032642502, Stdev: 0.0014581713626831757 with: {'epochs': 200}\n"
     ]
    }
   ],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dropout(0.01, input_shape=(inputs,)))\n",
    "    model.add(Dense(10, kernel_initializer='glorot_normal', activation='softplus'))\n",
    "    model.add(Dropout(0.01))\n",
    "    model.add(Dense(10, kernel_initializer='glorot_normal', activation='softplus'))\n",
    "    model.add(Dropout(0.01))\n",
    "    model.add(Dense(1, kernel_initializer='glorot_normal', activation='softsign'))\n",
    "    sgd = SGD(lr=0.02, momentum=0.1, nesterov=False)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, batch_size=80, verbose=0)\n",
    "\n",
    "param_grid = {'epochs': [25, 50, 75, 100, 200]}\n",
    "\n",
    "grid_search(model, param_grid, X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5282 samples, validate on 1761 samples\n",
      "Epoch 1/200\n",
      "5282/5282 [==============================] - 4s 718us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 2/200\n",
      "5282/5282 [==============================] - 1s 177us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 3/200\n",
      "5282/5282 [==============================] - 1s 199us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 4/200\n",
      "5282/5282 [==============================] - 1s 176us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 5/200\n",
      "5282/5282 [==============================] - 1s 175us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 6/200\n",
      "5282/5282 [==============================] - 1s 184us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 7/200\n",
      "5282/5282 [==============================] - 1s 183us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 8/200\n",
      "5282/5282 [==============================] - 1s 181us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 9/200\n",
      "5282/5282 [==============================] - 1s 183us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 10/200\n",
      "5282/5282 [==============================] - 1s 169us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 11/200\n",
      "5282/5282 [==============================] - ETA: 0s - loss: 4.0553 - acc: 0.737 - 1s 170us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 12/200\n",
      "5282/5282 [==============================] - 1s 180us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 13/200\n",
      "5282/5282 [==============================] - 1s 172us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 14/200\n",
      "5282/5282 [==============================] - 1s 175us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 15/200\n",
      "5282/5282 [==============================] - 1s 181us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 16/200\n",
      "5282/5282 [==============================] - 1s 197us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 17/200\n",
      "5282/5282 [==============================] - 1s 186us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 18/200\n",
      "5282/5282 [==============================] - 1s 203us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 19/200\n",
      "5282/5282 [==============================] - 1s 184us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 20/200\n",
      "5282/5282 [==============================] - 1s 177us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 21/200\n",
      "5282/5282 [==============================] - 1s 169us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 22/200\n",
      "5282/5282 [==============================] - 1s 173us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 23/200\n",
      "5282/5282 [==============================] - 1s 165us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 24/200\n",
      "5282/5282 [==============================] - 1s 167us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 25/200\n",
      "5282/5282 [==============================] - 1s 175us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 26/200\n",
      "5282/5282 [==============================] - 1s 175us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 27/200\n",
      "5282/5282 [==============================] - 1s 179us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 28/200\n",
      "5282/5282 [==============================] - 1s 195us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 29/200\n",
      "5282/5282 [==============================] - 1s 173us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 30/200\n",
      "5282/5282 [==============================] - 1s 170us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 31/200\n",
      "5282/5282 [==============================] - 1s 184us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 32/200\n",
      "5282/5282 [==============================] - 1s 170us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 33/200\n",
      "5282/5282 [==============================] - 1s 169us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 34/200\n",
      "5282/5282 [==============================] - 1s 167us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 35/200\n",
      "5282/5282 [==============================] - 1s 169us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 36/200\n",
      "5282/5282 [==============================] - 1s 181us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 37/200\n",
      "5282/5282 [==============================] - 1s 169us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 38/200\n",
      "5282/5282 [==============================] - 1s 171us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 39/200\n",
      "5282/5282 [==============================] - 1s 170us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 40/200\n",
      "5282/5282 [==============================] - 1s 194us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 41/200\n",
      "5282/5282 [==============================] - 1s 180us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 42/200\n",
      "5282/5282 [==============================] - 1s 161us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 43/200\n",
      "5282/5282 [==============================] - 1s 177us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 44/200\n",
      "5282/5282 [==============================] - 1s 167us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 45/200\n",
      "5282/5282 [==============================] - 1s 161us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 46/200\n",
      "5282/5282 [==============================] - 1s 171us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 47/200\n",
      "5282/5282 [==============================] - 1s 165us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 48/200\n",
      "5282/5282 [==============================] - 1s 176us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 49/200\n",
      "5282/5282 [==============================] - 1s 180us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 50/200\n",
      "5282/5282 [==============================] - 1s 172us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 51/200\n",
      "5282/5282 [==============================] - 1s 170us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 52/200\n",
      "5282/5282 [==============================] - 1s 190us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 53/200\n",
      "5282/5282 [==============================] - 1s 167us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 54/200\n",
      "5282/5282 [==============================] - 1s 167us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 55/200\n",
      "5282/5282 [==============================] - 1s 168us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 56/200\n",
      "5282/5282 [==============================] - 1s 172us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 57/200\n",
      "5282/5282 [==============================] - 1s 169us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 58/200\n",
      "5282/5282 [==============================] - 1s 177us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 59/200\n",
      "5282/5282 [==============================] - 1s 169us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 60/200\n",
      "5282/5282 [==============================] - 1s 169us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 61/200\n",
      "5282/5282 [==============================] - 1s 170us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 62/200\n",
      "5282/5282 [==============================] - 1s 161us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 63/200\n",
      "5282/5282 [==============================] - 1s 181us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 64/200\n",
      "5282/5282 [==============================] - 1s 162us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 65/200\n",
      "5282/5282 [==============================] - 1s 178us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 66/200\n",
      "5282/5282 [==============================] - 1s 186us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 67/200\n",
      "5282/5282 [==============================] - 1s 191us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 68/200\n",
      "5282/5282 [==============================] - 1s 187us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 69/200\n",
      "5282/5282 [==============================] - 1s 181us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 70/200\n",
      "5282/5282 [==============================] - 1s 175us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 71/200\n",
      "5282/5282 [==============================] - 1s 178us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 72/200\n",
      "5282/5282 [==============================] - 1s 181us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 73/200\n",
      "5282/5282 [==============================] - 1s 180us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 74/200\n",
      "5282/5282 [==============================] - 1s 171us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 75/200\n",
      "5282/5282 [==============================] - 1s 180us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 76/200\n",
      "5282/5282 [==============================] - 1s 194us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 77/200\n",
      "5282/5282 [==============================] - 1s 200us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 78/200\n",
      "5282/5282 [==============================] - 1s 188us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 79/200\n",
      "5282/5282 [==============================] - 1s 189us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 80/200\n",
      "5282/5282 [==============================] - 1s 189us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 81/200\n",
      "5282/5282 [==============================] - 1s 185us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 82/200\n",
      "5282/5282 [==============================] - 1s 219us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 83/200\n",
      "5282/5282 [==============================] - 1s 203us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 84/200\n",
      "5282/5282 [==============================] - 1s 185us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 85/200\n",
      "5282/5282 [==============================] - 1s 190us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 86/200\n",
      "5282/5282 [==============================] - 1s 190us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 87/200\n",
      "5282/5282 [==============================] - 1s 199us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 88/200\n",
      "5282/5282 [==============================] - 1s 196us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 89/200\n",
      "5282/5282 [==============================] - 1s 209us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 90/200\n",
      "5282/5282 [==============================] - 1s 201us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 91/200\n",
      "5282/5282 [==============================] - 1s 198us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 92/200\n",
      "5282/5282 [==============================] - 1s 179us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 93/200\n",
      "5282/5282 [==============================] - 1s 179us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 94/200\n",
      "5282/5282 [==============================] - 1s 179us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 95/200\n",
      "5282/5282 [==============================] - 1s 188us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 96/200\n",
      "5282/5282 [==============================] - 1s 169us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 97/200\n",
      "5282/5282 [==============================] - 1s 176us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 98/200\n",
      "5282/5282 [==============================] - 1s 181us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 99/200\n",
      "5282/5282 [==============================] - 1s 201us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 100/200\n",
      "5282/5282 [==============================] - 1s 186us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 101/200\n",
      "5282/5282 [==============================] - 1s 173us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 102/200\n",
      "5282/5282 [==============================] - 1s 181us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 103/200\n",
      "5282/5282 [==============================] - 1s 182us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 104/200\n",
      "5282/5282 [==============================] - 1s 179us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 105/200\n",
      "5282/5282 [==============================] - 1s 172us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 106/200\n",
      "5282/5282 [==============================] - 1s 183us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 107/200\n",
      "5282/5282 [==============================] - 1s 180us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 108/200\n",
      "5282/5282 [==============================] - 1s 183us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 109/200\n",
      "5282/5282 [==============================] - 1s 172us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 110/200\n",
      "5282/5282 [==============================] - 1s 180us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 111/200\n",
      "5282/5282 [==============================] - 1s 176us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 112/200\n",
      "5282/5282 [==============================] - 1s 199us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 113/200\n",
      "5282/5282 [==============================] - 1s 175us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 114/200\n",
      "5282/5282 [==============================] - 1s 184us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 115/200\n",
      "5282/5282 [==============================] - 1s 183us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 116/200\n",
      "5282/5282 [==============================] - 1s 180us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 117/200\n",
      "5282/5282 [==============================] - 1s 177us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 118/200\n",
      "5282/5282 [==============================] - 1s 190us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 119/200\n",
      "5282/5282 [==============================] - 1s 171us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 120/200\n",
      "5282/5282 [==============================] - 1s 182us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 121/200\n",
      "5282/5282 [==============================] - 1s 200us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 122/200\n",
      "5282/5282 [==============================] - 1s 197us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 123/200\n",
      "5282/5282 [==============================] - 1s 191us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 124/200\n",
      "5282/5282 [==============================] - 1s 172us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 125/200\n",
      "5282/5282 [==============================] - 1s 180us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 126/200\n",
      "5282/5282 [==============================] - 1s 181us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 127/200\n",
      "5282/5282 [==============================] - 1s 170us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 128/200\n",
      "5282/5282 [==============================] - 1s 177us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 129/200\n",
      "5282/5282 [==============================] - 1s 179us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 130/200\n",
      "5282/5282 [==============================] - 1s 172us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 131/200\n",
      "5282/5282 [==============================] - 1s 168us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 132/200\n",
      "5282/5282 [==============================] - 1s 184us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 133/200\n",
      "5282/5282 [==============================] - 1s 170us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 134/200\n",
      "5282/5282 [==============================] - 1s 169us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 135/200\n",
      "5282/5282 [==============================] - 1s 184us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 136/200\n",
      "5282/5282 [==============================] - 1s 192us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 137/200\n",
      "5282/5282 [==============================] - 1s 167us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 138/200\n",
      "5282/5282 [==============================] - 1s 169us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 139/200\n",
      "5282/5282 [==============================] - 1s 171us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 140/200\n",
      "5282/5282 [==============================] - 1s 169us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 141/200\n",
      "5282/5282 [==============================] - 1s 179us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 142/200\n",
      "5282/5282 [==============================] - 1s 215us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 143/200\n",
      "5282/5282 [==============================] - 1s 199us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 144/200\n",
      "5282/5282 [==============================] - 1s 201us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 145/200\n",
      "5282/5282 [==============================] - 1s 179us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 146/200\n",
      "5282/5282 [==============================] - 1s 180us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 147/200\n",
      "5282/5282 [==============================] - 1s 136us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 148/200\n",
      "5282/5282 [==============================] - 0s 32us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 149/200\n",
      "5282/5282 [==============================] - 0s 32us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 150/200\n",
      "5282/5282 [==============================] - 0s 31us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 151/200\n",
      "5282/5282 [==============================] - 0s 31us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 152/200\n",
      "5282/5282 [==============================] - 0s 31us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 153/200\n",
      "5282/5282 [==============================] - 0s 31us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 154/200\n",
      "5282/5282 [==============================] - 0s 31us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 155/200\n",
      "5282/5282 [==============================] - 0s 31us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 156/200\n",
      "5282/5282 [==============================] - 0s 31us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 157/200\n",
      "5282/5282 [==============================] - 0s 31us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 158/200\n",
      "5282/5282 [==============================] - 0s 32us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 159/200\n",
      "5282/5282 [==============================] - 0s 31us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 160/200\n",
      "5282/5282 [==============================] - 0s 31us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 161/200\n",
      "5282/5282 [==============================] - 0s 32us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 162/200\n",
      "5282/5282 [==============================] - 0s 32us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 163/200\n",
      "5282/5282 [==============================] - 0s 32us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 164/200\n",
      "5282/5282 [==============================] - 0s 32us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 165/200\n",
      "5282/5282 [==============================] - 0s 32us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 166/200\n",
      "5282/5282 [==============================] - 0s 32us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 167/200\n",
      "5282/5282 [==============================] - 0s 32us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 168/200\n",
      "5282/5282 [==============================] - 0s 32us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 169/200\n",
      "5282/5282 [==============================] - 0s 31us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 170/200\n",
      "5282/5282 [==============================] - 0s 31us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 171/200\n",
      "5282/5282 [==============================] - 0s 32us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 172/200\n",
      "5282/5282 [==============================] - 0s 32us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 173/200\n",
      "5282/5282 [==============================] - 0s 31us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 174/200\n",
      "5282/5282 [==============================] - 0s 31us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 175/200\n",
      "5282/5282 [==============================] - 0s 32us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 176/200\n",
      "5282/5282 [==============================] - 0s 31us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 177/200\n",
      "5282/5282 [==============================] - 0s 32us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 178/200\n",
      "5282/5282 [==============================] - 0s 31us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 179/200\n",
      "5282/5282 [==============================] - 0s 33us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 180/200\n",
      "5282/5282 [==============================] - 0s 31us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 181/200\n",
      "5282/5282 [==============================] - 0s 32us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 182/200\n",
      "5282/5282 [==============================] - 0s 32us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 183/200\n",
      "5282/5282 [==============================] - 0s 31us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 184/200\n",
      "5282/5282 [==============================] - 0s 31us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 185/200\n",
      "5282/5282 [==============================] - 0s 31us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 186/200\n",
      "5282/5282 [==============================] - 0s 31us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 187/200\n",
      "5282/5282 [==============================] - 0s 32us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 188/200\n",
      "5282/5282 [==============================] - 0s 31us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 189/200\n",
      "5282/5282 [==============================] - 0s 31us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 190/200\n",
      "5282/5282 [==============================] - 0s 31us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 191/200\n",
      "5282/5282 [==============================] - 0s 31us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 192/200\n",
      "5282/5282 [==============================] - 0s 32us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 193/200\n",
      "5282/5282 [==============================] - 0s 32us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 194/200\n",
      "5282/5282 [==============================] - 0s 32us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 195/200\n",
      "5282/5282 [==============================] - 0s 31us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 196/200\n",
      "5282/5282 [==============================] - 0s 31us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 197/200\n",
      "5282/5282 [==============================] - 0s 31us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 198/200\n",
      "5282/5282 [==============================] - 0s 31us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 199/200\n",
      "5282/5282 [==============================] - 0s 32us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n",
      "Epoch 200/200\n",
      "5282/5282 [==============================] - 0s 31us/sample - loss: 4.0767 - acc: 0.7357 - val_loss: 4.1431 - val_acc: 0.7314\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f95dd63bac8>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dropout(0.01, input_shape=(inputs,)))\n",
    "model.add(Dense(10, kernel_initializer='glorot_normal', activation='softplus'))\n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(10, kernel_initializer='glorot_normal', activation='softplus'))\n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(1, kernel_initializer='glorot_normal', activation='softsign'))\n",
    "sgd = SGD(lr=0.02, momentum=0.1, nesterov=False)\n",
    "model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train_scaled, y_train,\n",
    "          validation_data=(X_test_scaled, y_test),\n",
    "          epochs=200, batch_size=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1761/1761 [==============================] - 0s 28us/sample - loss: 4.1431 - acc: 0.7314\n",
      "acc: 73.14026355743408%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test_scaled, y_test)\n",
    "print(f'{model.metrics_names[1]}: {scores[1]*100}%')\n",
    "\n",
    "# Accuracy went down lol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FfZRtJ7MCN3x"
   },
   "source": [
    "## Stretch Goals:\n",
    "\n",
    "- Try to implement Random Search Hyperparameter Tuning on this dataset\n",
    "- Try to implement Bayesian Optimiation tuning on this dataset using hyperas or hyperopt (if you're brave)\n",
    "- Practice hyperparameter tuning other datasets that we have looked at. How high can you get MNIST? Above 99%?\n",
    "- Study for the Sprint Challenge\n",
    " - Can you implement both perceptron and MLP models from scratch with forward and backpropagation?\n",
    " - Can you implement both perceptron and MLP models in keras and tune their hyperparameters with cross validation?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "LS_DS_434_Hyperparameter_Tuning_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
