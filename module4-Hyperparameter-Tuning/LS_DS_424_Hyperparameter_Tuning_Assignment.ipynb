{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Ryp-TVm4njD"
   },
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "\n",
    "# Hyperparameter Tuning\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2 Assignment 4*\n",
    "\n",
    "## Your Mission, should you choose to accept it...\n",
    "\n",
    "To hyperparameter tune and extract every ounce of accuracy out of this telecom customer churn dataset: [Available Here](https://lambdaschool-data-science.s3.amazonaws.com/telco-churn/WA_Fn-UseC_-Telco-Customer-Churn+(1).csv)\n",
    "\n",
    "## Requirements\n",
    "\n",
    "- Load the data\n",
    "- Clean the data if necessary (it will be)\n",
    "- Create and fit a baseline Keras MLP model to the data.\n",
    "- Hyperparameter tune (at least) the following parameters:\n",
    " - batch_size\n",
    " - training epochs\n",
    " - optimizer\n",
    " - learning rate (if applicable to optimizer)\n",
    " - momentum (if applicable to optimizer)\n",
    " - activation functions\n",
    " - network weight initialization\n",
    " - dropout regularization\n",
    " - number of neurons in the hidden layer\n",
    " \n",
    " You must use Grid Search and Cross Validation for your initial pass of the above hyperparameters\n",
    " \n",
    " Try and get the maximum accuracy possible out of this data! You'll save big telecoms millions! Doesn't that sound great?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NNJ-tOBs4jM1"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install category_encoders==2.*\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import category_encoders as ce\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7043, 21)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = './WA_Fn-UseC_-Telco-Customer-Churn+.csv'\n",
    "df = pd.read_csv(data)\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TotalCharges'] = df['TotalCharges'].replace(' ', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customerID           0\n",
       "gender               0\n",
       "SeniorCitizen        0\n",
       "Partner              0\n",
       "Dependents           0\n",
       "tenure               0\n",
       "PhoneService         0\n",
       "MultipleLines        0\n",
       "InternetService      0\n",
       "OnlineSecurity       0\n",
       "OnlineBackup         0\n",
       "DeviceProtection     0\n",
       "TechSupport          0\n",
       "StreamingTV          0\n",
       "StreamingMovies      0\n",
       "Contract             0\n",
       "PaperlessBilling     0\n",
       "PaymentMethod        0\n",
       "MonthlyCharges       0\n",
       "TotalCharges        11\n",
       "Churn                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop null values\n",
    "df = df.dropna()\n",
    "\n",
    "# convert TotalCharges to float\n",
    "df['TotalCharges'] = df['TotalCharges'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features = df.drop(['Churn', 'customerID'], axis=1)\n",
    "y_labels = df['Churn']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>OnlineBackup</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7032</td>\n",
       "      <td>7032</td>\n",
       "      <td>7032</td>\n",
       "      <td>7032</td>\n",
       "      <td>7032</td>\n",
       "      <td>7032</td>\n",
       "      <td>7032</td>\n",
       "      <td>7032</td>\n",
       "      <td>7032</td>\n",
       "      <td>7032</td>\n",
       "      <td>7032</td>\n",
       "      <td>7032</td>\n",
       "      <td>7032</td>\n",
       "      <td>7032</td>\n",
       "      <td>7032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>3549</td>\n",
       "      <td>3639</td>\n",
       "      <td>4933</td>\n",
       "      <td>6352</td>\n",
       "      <td>3385</td>\n",
       "      <td>3096</td>\n",
       "      <td>3497</td>\n",
       "      <td>3087</td>\n",
       "      <td>3094</td>\n",
       "      <td>3472</td>\n",
       "      <td>2809</td>\n",
       "      <td>2781</td>\n",
       "      <td>3875</td>\n",
       "      <td>4168</td>\n",
       "      <td>2365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       gender Partner Dependents PhoneService MultipleLines InternetService  \\\n",
       "count    7032    7032       7032         7032          7032            7032   \n",
       "unique      2       2          2            2             3               3   \n",
       "top      Male      No         No          Yes            No     Fiber optic   \n",
       "freq     3549    3639       4933         6352          3385            3096   \n",
       "\n",
       "       OnlineSecurity OnlineBackup DeviceProtection TechSupport StreamingTV  \\\n",
       "count            7032         7032             7032        7032        7032   \n",
       "unique              3            3                3           3           3   \n",
       "top                No           No               No          No          No   \n",
       "freq             3497         3087             3094        3472        2809   \n",
       "\n",
       "       StreamingMovies        Contract PaperlessBilling     PaymentMethod  \n",
       "count             7032            7032             7032              7032  \n",
       "unique               3               3                2                 4  \n",
       "top                 No  Month-to-month              Yes  Electronic check  \n",
       "freq              2781            3875             4168              2365  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_features.describe(exclude='number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df_to_numpy(dataframe):\n",
    "    # create copy of dataframe\n",
    "    df = dataframe.copy()\n",
    "    \n",
    "    # one hot encode and convert to numpy array\n",
    "#     categorical_features = ['gender', 'SeniorCitizen', 'Partner',\n",
    "#                         'Dependents', 'PhoneService', 'MultipleLines',\n",
    "#                         'InternetService', 'OnlineSecurity', 'OnlineBackup',\n",
    "#                         'DeviceProtection', 'TechSupport', 'StreamingTV',\n",
    "#                         'StreamingMovies', 'Contract', 'PaperlessBilling',\n",
    "#                         'PaymentMethod']\n",
    "    \n",
    "    encoder = ce.OneHotEncoder(use_cat_names=True)\n",
    "    df = encoder.fit_transform(df)\n",
    "    df_to_array = df.to_numpy()\n",
    "    \n",
    "    return df_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the test train split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_features, y_labels, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = clean_df_to_numpy(X_train)\n",
    "X_test = clean_df_to_numpy(X_test)\n",
    "\n",
    "y_train = y_train.replace({'Yes': 1, 'No': 0})\n",
    "y_test = y_test.replace({'Yes': 1, 'No': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train) == len(y_train))\n",
    "print(len(X_test) == len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5625, 45)\n",
      "(1407, 45)\n",
      "(5625,)\n",
      "(1407,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Correct Encoding on Y\n",
    "# num_classes = 2\n",
    "# labels = keras.utils.to_categorical(telecom_labels, num_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline with average and baseline MLP Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No     0.734215\n",
       "Yes    0.265785\n",
       "Name: Churn, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what is the baseline\n",
    "df['Churn'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_classes = 2\n",
    "# y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "# y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 4.1925 - accuracy: 0.7276 - val_loss: 4.1002 - val_accuracy: 0.7342\n",
      "Epoch 2/15\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 4.0996 - accuracy: 0.7342 - val_loss: 4.1002 - val_accuracy: 0.7342\n",
      "Epoch 3/15\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 4.0996 - accuracy: 0.7342 - val_loss: 4.1002 - val_accuracy: 0.7342\n",
      "Epoch 4/15\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 4.0996 - accuracy: 0.7342 - val_loss: 4.1002 - val_accuracy: 0.7342\n",
      "Epoch 5/15\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 4.0996 - accuracy: 0.7342 - val_loss: 4.1002 - val_accuracy: 0.7342\n",
      "Epoch 6/15\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 4.0996 - accuracy: 0.7342 - val_loss: 4.1002 - val_accuracy: 0.7342\n",
      "Epoch 7/15\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 4.0996 - accuracy: 0.7342 - val_loss: 4.1002 - val_accuracy: 0.7342\n",
      "Epoch 8/15\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 4.0996 - accuracy: 0.7342 - val_loss: 4.1002 - val_accuracy: 0.7342\n",
      "Epoch 9/15\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 4.0996 - accuracy: 0.7342 - val_loss: 4.1002 - val_accuracy: 0.7342\n",
      "Epoch 10/15\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 4.0996 - accuracy: 0.7342 - val_loss: 4.1002 - val_accuracy: 0.7342\n",
      "Epoch 11/15\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 4.0996 - accuracy: 0.7342 - val_loss: 4.1002 - val_accuracy: 0.7342\n",
      "Epoch 12/15\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 4.0996 - accuracy: 0.7342 - val_loss: 4.1002 - val_accuracy: 0.7342\n",
      "Epoch 13/15\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 4.0996 - accuracy: 0.7342 - val_loss: 4.1002 - val_accuracy: 0.7342\n",
      "Epoch 14/15\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 4.0996 - accuracy: 0.7342 - val_loss: 4.1002 - val_accuracy: 0.7342\n",
      "Epoch 15/15\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 4.0996 - accuracy: 0.7342 - val_loss: 4.1002 - val_accuracy: 0.7342\n"
     ]
    }
   ],
   "source": [
    "# Instantiate sequential model with layers\n",
    "\n",
    "model = Sequential([\n",
    "    \n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1)]\n",
    ")\n",
    "\n",
    "# complie the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# fit the model\n",
    "fitted = model.fit(\n",
    "    x=X_train, \n",
    "    y=y_train, \n",
    "    epochs=15, \n",
    "    validation_data=(X_test, y_test),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [4.192538738250732,\n",
       "  4.099607944488525,\n",
       "  4.099608898162842,\n",
       "  4.099607467651367,\n",
       "  4.099607467651367,\n",
       "  4.099607467651367,\n",
       "  4.099607467651367,\n",
       "  4.099606990814209,\n",
       "  4.099608421325684,\n",
       "  4.099607467651367,\n",
       "  4.099606990814209,\n",
       "  4.099608421325684,\n",
       "  4.099608421325684,\n",
       "  4.099608421325684,\n",
       "  4.099608898162842],\n",
       " 'accuracy': [0.7276444435119629,\n",
       "  0.7342222332954407,\n",
       "  0.7342222332954407,\n",
       "  0.7342222332954407,\n",
       "  0.7342222332954407,\n",
       "  0.7342222332954407,\n",
       "  0.7342222332954407,\n",
       "  0.7342222332954407,\n",
       "  0.7342222332954407,\n",
       "  0.7342222332954407,\n",
       "  0.7342222332954407,\n",
       "  0.7342222332954407,\n",
       "  0.7342222332954407,\n",
       "  0.7342222332954407,\n",
       "  0.7342222332954407],\n",
       " 'val_loss': [4.100164413452148,\n",
       "  4.100164413452148,\n",
       "  4.100164413452148,\n",
       "  4.100164413452148,\n",
       "  4.100164413452148,\n",
       "  4.100164413452148,\n",
       "  4.100164413452148,\n",
       "  4.100164413452148,\n",
       "  4.100164413452148,\n",
       "  4.100164413452148,\n",
       "  4.100164413452148,\n",
       "  4.100164413452148,\n",
       "  4.100164413452148,\n",
       "  4.100164413452148,\n",
       "  4.100164413452148],\n",
       " 'val_accuracy': [0.7341862320899963,\n",
       "  0.7341862320899963,\n",
       "  0.7341862320899963,\n",
       "  0.7341862320899963,\n",
       "  0.7341862320899963,\n",
       "  0.7341862320899963,\n",
       "  0.7341862320899963,\n",
       "  0.7341862320899963,\n",
       "  0.7341862320899963,\n",
       "  0.7341862320899963,\n",
       "  0.7341862320899963,\n",
       "  0.7341862320899963,\n",
       "  0.7341862320899963,\n",
       "  0.7341862320899963,\n",
       "  0.7341862320899963]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitted.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tuning batch size and epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to create model, required for KerasClassifier\n",
    "# def create_model():\n",
    "#     # create model\n",
    "#     model = Sequential([\n",
    "    \n",
    "#     Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "#     Dense(64, activation='relu'),\n",
    "#     Dense(64, activation='relu'),\n",
    "#     Dense(1)]\n",
    "#     )\n",
    "    \n",
    "#     # Compile model\n",
    "#     model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#     return model\n",
    "\n",
    "# # create model\n",
    "# model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "\n",
    "# # define the grid search parameters\n",
    "# param_grid = {'batch_size': [8, 16, 32, 64, 128],\n",
    "#               'epochs': [10, 15, 20, 25]}\n",
    "\n",
    "# # Create Grid Search\n",
    "# grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1)\n",
    "# grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# # Report Results\n",
    "# print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
    "# means = grid_result.cv_results_['mean_test_score']\n",
    "# stds = grid_result.cv_results_['std_test_score']\n",
    "# params = grid_result.cv_results_['params']\n",
    "# for mean, stdev, param in zip(means, stds, params):\n",
    "#     print(f\"Means: {mean}, Stdev: {stdev} with: {param}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FfZRtJ7MCN3x"
   },
   "source": [
    "## Stretch Goals:\n",
    "\n",
    "- Try to implement Random Search Hyperparameter Tuning on this dataset\n",
    "- Try to implement Bayesian Optimiation tuning on this dataset using hyperas or hyperopt (if you're brave)\n",
    "- Practice hyperparameter tuning other datasets that we have looked at. How high can you get MNIST? Above 99%?\n",
    "- Study for the Sprint Challenge\n",
    " - Can you implement both perceptron and MLP models from scratch with forward and backpropagation?\n",
    " - Can you implement both perceptron and MLP models in keras and tune their hyperparameters with cross validation?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "LS_DS_434_Hyperparameter_Tuning_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
