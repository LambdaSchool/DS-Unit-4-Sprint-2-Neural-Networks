{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LS_DS_424_Hyperparameter_Tuning_Assignment.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3.7.0 64-bit ('lam4-nnf-s2': conda)",
      "language": "python",
      "name": "python37064bitlam4nnfs2condaa223e28e4e5343f49ecebf6cc0bb1d2c"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0-final"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/richardOlson/DS-Unit-4-Sprint-2-Neural-Networks/blob/master/LS_DS_424_Hyperparameter_Tuning_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9Ryp-TVm4njD"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "\n",
        "# Hyperparameter Tuning\n",
        "\n",
        "## *Data Science Unit 4 Sprint 2 Assignment 4*\n",
        "\n",
        "## Your Mission, should you choose to accept it...\n",
        "\n",
        "To hyperparameter tune and extract every ounce of accuracy out of this telecom customer churn dataset: [Available Here](https://lambdaschool-data-science.s3.amazonaws.com/telco-churn/WA_Fn-UseC_-Telco-Customer-Churn+(1).csv)\n",
        "\n",
        "## Requirements\n",
        "\n",
        "- Load the data\n",
        "- Clean the data if necessary (it will be)\n",
        "- Create and fit a baseline Keras MLP model to the data.\n",
        "- Hyperparameter tune (at least) the following parameters:\n",
        " - batch_size\n",
        " - training epochs\n",
        " - optimizer\n",
        " - learning rate (if applicable to optimizer)\n",
        " - momentum (if applicable to optimizer)\n",
        " - activation functions\n",
        " - network weight initialization\n",
        " - dropout regularization\n",
        " - number of neurons in the hidden layer\n",
        " \n",
        " You must use Grid Search and Cross Validation for your initial pass of the above hyperparameters\n",
        " \n",
        " Try and get the maximum accuracy possible out of this data! You'll save big telecoms millions! Doesn't that sound great?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NNJ-tOBs4jM1",
        "colab": {}
      },
      "source": [
        "# Doing some of the imports here\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51rB-9VxBEub",
        "colab_type": "code",
        "colab": {},
        "outputId": "d9a1354a-9023-48d5-f9fd-95c3c8888301"
      },
      "source": [
        "PATH = os.path.join(os.path.curdir, \"WA_Fn-UseC_-Telco-Customer-Churn+(1).csv\")\n",
        "PATH"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'.\\\\WA_Fn-UseC_-Telco-Customer-Churn+(1).csv'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8re91MHB6Yb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "colab_path = \"/content/WA_Fn-UseC_-Telco-Customer-Churn+(1).csv\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfg2c4GzCZ_E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "outputId": "db25f494-caf2-4306-c66d-076671689634"
      },
      "source": [
        "!pip install category-encoders"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting category-encoders\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/44/57/fcef41c248701ee62e8325026b90c432adea35555cbc870aff9cfba23727/category_encoders-2.2.2-py2.py3-none-any.whl (80kB)\n",
            "\r\u001b[K     |████                            | 10kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 20kB 1.9MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 30kB 2.4MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 40kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 51kB 2.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 61kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 71kB 3.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 2.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from category-encoders) (1.4.1)\n",
            "Requirement already satisfied: pandas>=0.21.1 in /usr/local/lib/python3.6/dist-packages (from category-encoders) (1.0.3)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.6/dist-packages (from category-encoders) (0.5.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from category-encoders) (1.18.4)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from category-encoders) (0.10.2)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.6/dist-packages (from category-encoders) (0.22.2.post1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category-encoders) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category-encoders) (2.8.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from patsy>=0.5.1->category-encoders) (1.12.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20.0->category-encoders) (0.15.1)\n",
            "Installing collected packages: category-encoders\n",
            "Successfully installed category-encoders-2.2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_2wGtS8CHby",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(colab_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PV54cG1_CO3h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "78547f8e-8e3b-48be-fca9-41487a7b57e5"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7043, 21)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2WTKJhwBEue",
        "colab_type": "code",
        "colab": {},
        "outputId": "f530fd87-7292-43d8-e398-648e5d16bb26"
      },
      "source": [
        "# Loading the data set\n",
        "df = pd.read_csv(PATH)\n",
        "df.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7043, 21)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qB6IescBEuh",
        "colab_type": "code",
        "colab": {},
        "outputId": "1ade5d6f-bf3b-48d4-9dbc-5f9b4b4915c5"
      },
      "source": [
        "# Looking for null values\n",
        "df.isnull().sum()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "customerID          0\n",
              "gender              0\n",
              "SeniorCitizen       0\n",
              "Partner             0\n",
              "Dependents          0\n",
              "tenure              0\n",
              "PhoneService        0\n",
              "MultipleLines       0\n",
              "InternetService     0\n",
              "OnlineSecurity      0\n",
              "OnlineBackup        0\n",
              "DeviceProtection    0\n",
              "TechSupport         0\n",
              "StreamingTV         0\n",
              "StreamingMovies     0\n",
              "Contract            0\n",
              "PaperlessBilling    0\n",
              "PaymentMethod       0\n",
              "MonthlyCharges      0\n",
              "TotalCharges        0\n",
              "Churn               0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9Q4P6yCBEuk",
        "colab_type": "code",
        "colab": {},
        "outputId": "617e1060-f693-4621-ad4f-17a129cb221a"
      },
      "source": [
        "# This means that we are doing a binary classification for this data\n",
        "df[\"Churn\"].unique()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['No', 'Yes'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycDH3ybiBEum",
        "colab_type": "code",
        "colab": {},
        "outputId": "095f41c8-7115-41dc-f33f-51a649645e9b"
      },
      "source": [
        "df.head(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   customerID  gender  SeniorCitizen Partner Dependents  tenure PhoneService  \\\n",
              "0  7590-VHVEG  Female              0     Yes         No       1           No   \n",
              "1  5575-GNVDE    Male              0      No         No      34          Yes   \n",
              "\n",
              "      MultipleLines InternetService OnlineSecurity  ... DeviceProtection  \\\n",
              "0  No phone service             DSL             No  ...               No   \n",
              "1                No             DSL            Yes  ...              Yes   \n",
              "\n",
              "  TechSupport StreamingTV StreamingMovies        Contract PaperlessBilling  \\\n",
              "0          No          No              No  Month-to-month              Yes   \n",
              "1          No          No              No        One year               No   \n",
              "\n",
              "      PaymentMethod MonthlyCharges  TotalCharges Churn  \n",
              "0  Electronic check          29.85         29.85    No  \n",
              "1      Mailed check          56.95        1889.5    No  \n",
              "\n",
              "[2 rows x 21 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>customerID</th>\n",
              "      <th>gender</th>\n",
              "      <th>SeniorCitizen</th>\n",
              "      <th>Partner</th>\n",
              "      <th>Dependents</th>\n",
              "      <th>tenure</th>\n",
              "      <th>PhoneService</th>\n",
              "      <th>MultipleLines</th>\n",
              "      <th>InternetService</th>\n",
              "      <th>OnlineSecurity</th>\n",
              "      <th>...</th>\n",
              "      <th>DeviceProtection</th>\n",
              "      <th>TechSupport</th>\n",
              "      <th>StreamingTV</th>\n",
              "      <th>StreamingMovies</th>\n",
              "      <th>Contract</th>\n",
              "      <th>PaperlessBilling</th>\n",
              "      <th>PaymentMethod</th>\n",
              "      <th>MonthlyCharges</th>\n",
              "      <th>TotalCharges</th>\n",
              "      <th>Churn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7590-VHVEG</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>1</td>\n",
              "      <td>No</td>\n",
              "      <td>No phone service</td>\n",
              "      <td>DSL</td>\n",
              "      <td>No</td>\n",
              "      <td>...</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Month-to-month</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Electronic check</td>\n",
              "      <td>29.85</td>\n",
              "      <td>29.85</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5575-GNVDE</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>34</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>DSL</td>\n",
              "      <td>Yes</td>\n",
              "      <td>...</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>One year</td>\n",
              "      <td>No</td>\n",
              "      <td>Mailed check</td>\n",
              "      <td>56.95</td>\n",
              "      <td>1889.5</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 21 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yy2YkIdtBEup",
        "colab_type": "code",
        "colab": {},
        "outputId": "8045336b-0554-4da0-f5f9-5535bbc48b1f"
      },
      "source": [
        "df.dtypes"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "customerID           object\n",
              "gender               object\n",
              "SeniorCitizen         int64\n",
              "Partner              object\n",
              "Dependents           object\n",
              "tenure                int64\n",
              "PhoneService         object\n",
              "MultipleLines        object\n",
              "InternetService      object\n",
              "OnlineSecurity       object\n",
              "OnlineBackup         object\n",
              "DeviceProtection     object\n",
              "TechSupport          object\n",
              "StreamingTV          object\n",
              "StreamingMovies      object\n",
              "Contract             object\n",
              "PaperlessBilling     object\n",
              "PaymentMethod        object\n",
              "MonthlyCharges      float64\n",
              "TotalCharges         object\n",
              "Churn                object\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5qa9oLSBEus",
        "colab_type": "code",
        "colab": {},
        "outputId": "2dd124b6-fd18-4c33-ea24-aaabf40f1dc2"
      },
      "source": [
        "for col in df.columns.tolist():\n",
        "    print(f\"vals for {col}\")\n",
        "    print(pd.unique(df[col]))\n",
        "    print(\"----------------\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vals for customerID\n",
            "['7590-VHVEG' '5575-GNVDE' '3668-QPYBK' ... '4801-JZAZL' '8361-LTMKD'\n",
            " '3186-AJIEK']\n",
            "----------------\n",
            "vals for gender\n",
            "['Female' 'Male']\n",
            "----------------\n",
            "vals for SeniorCitizen\n",
            "[0 1]\n",
            "----------------\n",
            "vals for Partner\n",
            "['Yes' 'No']\n",
            "----------------\n",
            "vals for Dependents\n",
            "['No' 'Yes']\n",
            "----------------\n",
            "vals for tenure\n",
            "[ 1 34  2 45  8 22 10 28 62 13 16 58 49 25 69 52 71 21 12 30 47 72 17 27\n",
            "  5 46 11 70 63 43 15 60 18 66  9  3 31 50 64 56  7 42 35 48 29 65 38 68\n",
            " 32 55 37 36 41  6  4 33 67 23 57 61 14 20 53 40 59 24 44 19 54 51 26  0\n",
            " 39]\n",
            "----------------\n",
            "vals for PhoneService\n",
            "['No' 'Yes']\n",
            "----------------\n",
            "vals for MultipleLines\n",
            "['No phone service' 'No' 'Yes']\n",
            "----------------\n",
            "vals for InternetService\n",
            "['DSL' 'Fiber optic' 'No']\n",
            "----------------\n",
            "vals for OnlineSecurity\n",
            "['No' 'Yes' 'No internet service']\n",
            "----------------\n",
            "vals for OnlineBackup\n",
            "['Yes' 'No' 'No internet service']\n",
            "----------------\n",
            "vals for DeviceProtection\n",
            "['No' 'Yes' 'No internet service']\n",
            "----------------\n",
            "vals for TechSupport\n",
            "['No' 'Yes' 'No internet service']\n",
            "----------------\n",
            "vals for StreamingTV\n",
            "['No' 'Yes' 'No internet service']\n",
            "----------------\n",
            "vals for StreamingMovies\n",
            "['No' 'Yes' 'No internet service']\n",
            "----------------\n",
            "vals for Contract\n",
            "['Month-to-month' 'One year' 'Two year']\n",
            "----------------\n",
            "vals for PaperlessBilling\n",
            "['Yes' 'No']\n",
            "----------------\n",
            "vals for PaymentMethod\n",
            "['Electronic check' 'Mailed check' 'Bank transfer (automatic)'\n",
            " 'Credit card (automatic)']\n",
            "----------------\n",
            "vals for MonthlyCharges\n",
            "[29.85 56.95 53.85 ... 63.1  44.2  78.7 ]\n",
            "----------------\n",
            "vals for TotalCharges\n",
            "['29.85' '1889.5' '108.15' ... '346.45' '306.6' '6844.5']\n",
            "----------------\n",
            "vals for Churn\n",
            "['No' 'Yes']\n",
            "----------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yWUGN2LBEuv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "628796d9-cdbe-4ae5-eab7-512e8d97e701"
      },
      "source": [
        "# Will be doing some one hot encoding of the values that are strings\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "import category_encoders as ce\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFrxeaelBEux",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# trying the drop of the dataframe\n",
        "d = df.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQep8vw4BEuz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prep_data(df, return_x_frame=False):\n",
        "    the_df = df.copy() # copying the data \n",
        "     \n",
        "    # doing some droping of the id\n",
        "    the_df = the_df.drop(columns=[\"customerID\"], axis=1)\n",
        "\n",
        "    # now doing going to change the TotalCharges to change it to \n",
        "    # a numeric\n",
        "    the_df[\"TotalCharges\"] = pd.to_numeric(the_df[\"TotalCharges\"], errors=\"coerce\")\n",
        "\n",
        "    # Will now do dropping of the rows that have null in them in the TotalCharges\n",
        "    the_df = the_df.dropna()\n",
        "\n",
        "    # will now split the dataFrame into y and x\n",
        "    y = the_df[\"Churn\"]\n",
        "    feature_names = [x for x in the_df.columns.tolist() if x != \"Churn\"]\n",
        "    x = the_df[feature_names]\n",
        "    # doing some ordinal encoding\n",
        "    # ord = OrdinalEncoder(categories=[\"gender\", \"Partner\", \"Dependents\"])\n",
        "    # create the one hot encoding\n",
        "    vals_to_encode = [\"gender\", \"Partner\", \"Dependents\", \"PhoneService\", \n",
        "                    \"MultipleLines\", \"InternetService\", \"OnlineSecurity\", \"OnlineBackup\", \n",
        "                    \"DeviceProtection\", \"TechSupport\", \"StreamingTV\", \n",
        "                    \"StreamingMovies\", \"Contract\", \"PaperlessBilling\", \"PaymentMethod\"]\n",
        "    encoder = ce.OneHotEncoder(use_cat_names=True, cols=vals_to_encode)\n",
        "    \n",
        "    encoded_data = encoder.fit_transform(x)\n",
        "\n",
        "    # using a scaler to scale the data\n",
        "    minScaler = MinMaxScaler()\n",
        "    scaled_data = minScaler.fit_transform(encoded_data)\n",
        "    \n",
        "    frame= pd.DataFrame(data=scaled_data, columns=encoder.get_feature_names())\n",
        "    if return_x_frame == True:\n",
        "        return frame, scaled_data, y\n",
        "    return scaled_data,  y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1Ea6NZIBEu2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x, y = prep_data(d)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Wno34CEBEu4",
        "colab_type": "code",
        "colab": {},
        "outputId": "ea4ca6fd-db8e-4c1e-941b-7846c43b580e"
      },
      "source": [
        "x.shape, y.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((7032, 45), (7032,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8a2ZDxMBEu9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Doing some imports for the model and tuning\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNx8Yva1BEu_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Doing more imports\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from tensorflow.keras.optimizers import Adam, SGD"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BnG0QHABEvB",
        "colab_type": "code",
        "colab": {},
        "outputId": "48982999-c0d9-4ace-b6f2-6ed4797a82d4"
      },
      "source": [
        "# checking what a good size of epochs would be\n",
        "\n",
        "# Doing a random seed\n",
        "seed = 42\n",
        "np.random.seed(seed=seed)\n",
        "\n",
        "# Creating the function that will do building of model\n",
        "\n",
        "def build_model(x=x, optimizer = Adam):\n",
        "\n",
        "    # making it so that we get the optizmizer\n",
        "    opt = optimizer()\n",
        "\n",
        "\n",
        "    model = Sequential()\n",
        "    # add layers\n",
        "    model.add(Dense(128, activation=\"sigmoid\", input_shape=(x.shape[1],)))\n",
        "    model.add(Dense(64, activation=\"relu\"))\n",
        "    model.add(Dense(1, activation=\"sigmoid\"))\n",
        "    # compile the model\n",
        "    model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\", \"mse\"])\n",
        "    # returning the model\n",
        "    return model\n",
        "\n",
        "    # will now put the model in the kerasclassifier\n",
        "model = KerasClassifier(build_fn=build_model)\n",
        "\n",
        "params = {\n",
        "    \"epochs\": [10, 15, 25, 50, 100]\n",
        "}\n",
        "\n",
        "# now getting the grid search\n",
        "grid = GridSearchCV(estimator=model, param_grid=params, n_jobs=4, verbose=1)\n",
        "grid.fit(x, y)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
            "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=4)]: Done  25 out of  25 | elapsed:  2.1min finished\n",
            "Train on 7032 samples\n",
            "Epoch 1/25\n",
            "7032/7032 [==============================] - 1s 127us/sample - loss: 0.4760 - accuracy: 0.7632 - mse: 0.1568\n",
            "Epoch 2/25\n",
            "7032/7032 [==============================] - 0s 45us/sample - loss: 0.4306 - accuracy: 0.7951 - mse: 0.1405\n",
            "Epoch 3/25\n",
            "7032/7032 [==============================] - 0s 42us/sample - loss: 0.4279 - accuracy: 0.7947 - mse: 0.1395\n",
            "Epoch 4/25\n",
            "7032/7032 [==============================] - 0s 44us/sample - loss: 0.4246 - accuracy: 0.7985 - mse: 0.1384\n",
            "Epoch 5/25\n",
            "7032/7032 [==============================] - 0s 45us/sample - loss: 0.4225 - accuracy: 0.8023 - mse: 0.1374\n",
            "Epoch 6/25\n",
            "7032/7032 [==============================] - 0s 43us/sample - loss: 0.4214 - accuracy: 0.7991 - mse: 0.1373\n",
            "Epoch 7/25\n",
            "7032/7032 [==============================] - 0s 43us/sample - loss: 0.4218 - accuracy: 0.7988 - mse: 0.1373\n",
            "Epoch 8/25\n",
            "7032/7032 [==============================] - 0s 43us/sample - loss: 0.4220 - accuracy: 0.7978 - mse: 0.1374\n",
            "Epoch 9/25\n",
            "7032/7032 [==============================] - 0s 44us/sample - loss: 0.4211 - accuracy: 0.7985 - mse: 0.1372\n",
            "Epoch 10/25\n",
            "7032/7032 [==============================] - 0s 43us/sample - loss: 0.4210 - accuracy: 0.8009 - mse: 0.1372\n",
            "Epoch 11/25\n",
            "7032/7032 [==============================] - 0s 46us/sample - loss: 0.4186 - accuracy: 0.8035 - mse: 0.1361\n",
            "Epoch 12/25\n",
            "7032/7032 [==============================] - 0s 45us/sample - loss: 0.4174 - accuracy: 0.8033 - mse: 0.1359\n",
            "Epoch 13/25\n",
            "7032/7032 [==============================] - 0s 44us/sample - loss: 0.4171 - accuracy: 0.8009 - mse: 0.1359\n",
            "Epoch 14/25\n",
            "7032/7032 [==============================] - 0s 42us/sample - loss: 0.4168 - accuracy: 0.8009 - mse: 0.1357\n",
            "Epoch 15/25\n",
            "7032/7032 [==============================] - 0s 43us/sample - loss: 0.4168 - accuracy: 0.7995 - mse: 0.1357\n",
            "Epoch 16/25\n",
            "7032/7032 [==============================] - 0s 43us/sample - loss: 0.4165 - accuracy: 0.8026 - mse: 0.1355\n",
            "Epoch 17/25\n",
            "7032/7032 [==============================] - 0s 44us/sample - loss: 0.4149 - accuracy: 0.8066 - mse: 0.1350\n",
            "Epoch 18/25\n",
            "7032/7032 [==============================] - 0s 43us/sample - loss: 0.4137 - accuracy: 0.8033 - mse: 0.1347\n",
            "Epoch 19/25\n",
            "7032/7032 [==============================] - 0s 42us/sample - loss: 0.4159 - accuracy: 0.8025 - mse: 0.1356\n",
            "Epoch 20/25\n",
            "7032/7032 [==============================] - 0s 45us/sample - loss: 0.4142 - accuracy: 0.8020 - mse: 0.1348\n",
            "Epoch 21/25\n",
            "7032/7032 [==============================] - 0s 43us/sample - loss: 0.4161 - accuracy: 0.8029 - mse: 0.1355\n",
            "Epoch 22/25\n",
            "7032/7032 [==============================] - 0s 45us/sample - loss: 0.4150 - accuracy: 0.8052 - mse: 0.1350\n",
            "Epoch 23/25\n",
            "7032/7032 [==============================] - 0s 43us/sample - loss: 0.4140 - accuracy: 0.8050 - mse: 0.1347\n",
            "Epoch 24/25\n",
            "7032/7032 [==============================] - 0s 52us/sample - loss: 0.4145 - accuracy: 0.8030 - mse: 0.1349\n",
            "Epoch 25/25\n",
            "7032/7032 [==============================] - 0s 58us/sample - loss: 0.4135 - accuracy: 0.8038 - mse: 0.1345\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(estimator=<tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x000001D1E415E588>,\n",
              "             n_jobs=4, param_grid={'epochs': [10, 15, 25, 50, 100]}, verbose=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiAu9I7KBEvD",
        "colab_type": "code",
        "colab": {},
        "outputId": "024783dc-bc8a-4a92-b2b0-f5f71209dd3e"
      },
      "source": [
        "# These were the params that we did\n",
        "print(\"the best param for the epoch size is: \", grid.best_params_)\n",
        "print(\"the best score was: \", grid.best_score_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the best param for the epoch size is:  {'epochs': 25}\n",
            "the best score was:  0.8041794657707214\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSqqykpFBEvF",
        "colab_type": "code",
        "colab": {},
        "outputId": "72086506-1ee8-4d85-bb5c-c3c50a238db3"
      },
      "source": [
        "# Doiing the hyperparameter tuning but this time leaving the epoch at 25\n",
        "# tuning the batch size\n",
        "\n",
        "# Doing a random seed\n",
        "seed = 42\n",
        "np.random.seed(seed=seed)\n",
        "\n",
        "# Creating the function that will do building of model\n",
        "\n",
        "def build_model(x=x, optimizer = Adam):\n",
        "\n",
        "    # making it so that we get the optizmizer\n",
        "    opt = optimizer()\n",
        "\n",
        "\n",
        "    model = Sequential()\n",
        "    # add layers\n",
        "    model.add(Dense(128, activation=\"sigmoid\", input_shape=(x.shape[1],)))\n",
        "    model.add(Dense(64, activation=\"relu\"))\n",
        "    model.add(Dense(1, activation=\"sigmoid\"))\n",
        "    # compile the model\n",
        "    model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\", \"mse\"])\n",
        "    # returning the model\n",
        "    return model\n",
        "\n",
        "    # will now put the model in the kerasclassifier\n",
        "model = KerasClassifier(build_fn=build_model, verbose=1)\n",
        "\n",
        "params = {\n",
        "    \"epochs\": [25], \n",
        "    \"batch_size\": [2,8, 16, 32]\n",
        "}\n",
        "\n",
        "# now getting the grid search\n",
        "grid = GridSearchCV(estimator=model, param_grid=params, n_jobs=4, verbose=1)\n",
        "grid.fit(x, y)\n",
        "\n",
        "\n",
        "# These were the params that we did\n",
        "print(\"the best params for are: \", grid.best_params_)\n",
        "print(\"the best score was: \", grid.best_score_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
            "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:  4.9min finished\n",
            "Train on 7032 samples\n",
            "Epoch 1/25\n",
            "7032/7032 [==============================] - 1s 93us/sample - loss: 0.4670 - accuracy: 0.7760 - mse: 0.1531\n",
            "Epoch 2/25\n",
            "7032/7032 [==============================] - 0s 49us/sample - loss: 0.4326 - accuracy: 0.7910 - mse: 0.1411\n",
            "Epoch 3/25\n",
            "7032/7032 [==============================] - 0s 42us/sample - loss: 0.4259 - accuracy: 0.7964 - mse: 0.1387\n",
            "Epoch 4/25\n",
            "7032/7032 [==============================] - 0s 42us/sample - loss: 0.4259 - accuracy: 0.7985 - mse: 0.1388\n",
            "Epoch 5/25\n",
            "7032/7032 [==============================] - 0s 41us/sample - loss: 0.4239 - accuracy: 0.7964 - mse: 0.1383\n",
            "Epoch 6/25\n",
            "7032/7032 [==============================] - 0s 41us/sample - loss: 0.4207 - accuracy: 0.8006 - mse: 0.1372\n",
            "Epoch 7/25\n",
            "7032/7032 [==============================] - 0s 43us/sample - loss: 0.4236 - accuracy: 0.7984 - mse: 0.1383\n",
            "Epoch 8/25\n",
            "7032/7032 [==============================] - 0s 42us/sample - loss: 0.4205 - accuracy: 0.7989 - mse: 0.1372\n",
            "Epoch 9/25\n",
            "7032/7032 [==============================] - 0s 43us/sample - loss: 0.4196 - accuracy: 0.7991 - mse: 0.1369\n",
            "Epoch 10/25\n",
            "7032/7032 [==============================] - 0s 40us/sample - loss: 0.4181 - accuracy: 0.8018 - mse: 0.1363\n",
            "Epoch 11/25\n",
            "7032/7032 [==============================] - 0s 42us/sample - loss: 0.4183 - accuracy: 0.8030 - mse: 0.1364\n",
            "Epoch 12/25\n",
            "7032/7032 [==============================] - 0s 42us/sample - loss: 0.4177 - accuracy: 0.8039 - mse: 0.1360\n",
            "Epoch 13/25\n",
            "7032/7032 [==============================] - 0s 41us/sample - loss: 0.4188 - accuracy: 0.8012 - mse: 0.1366\n",
            "Epoch 14/25\n",
            "7032/7032 [==============================] - 0s 42us/sample - loss: 0.4184 - accuracy: 0.8039 - mse: 0.1362\n",
            "Epoch 15/25\n",
            "7032/7032 [==============================] - 0s 41us/sample - loss: 0.4162 - accuracy: 0.8045 - mse: 0.1356\n",
            "Epoch 16/25\n",
            "7032/7032 [==============================] - 0s 47us/sample - loss: 0.4162 - accuracy: 0.8045 - mse: 0.1356\n",
            "Epoch 17/25\n",
            "7032/7032 [==============================] - 0s 41us/sample - loss: 0.4165 - accuracy: 0.8002 - mse: 0.1357\n",
            "Epoch 18/25\n",
            "7032/7032 [==============================] - 0s 40us/sample - loss: 0.4166 - accuracy: 0.7988 - mse: 0.1359\n",
            "Epoch 19/25\n",
            "7032/7032 [==============================] - 0s 42us/sample - loss: 0.4142 - accuracy: 0.8018 - mse: 0.1350\n",
            "Epoch 20/25\n",
            "7032/7032 [==============================] - 0s 40us/sample - loss: 0.4157 - accuracy: 0.8009 - mse: 0.1353\n",
            "Epoch 21/25\n",
            "7032/7032 [==============================] - 0s 39us/sample - loss: 0.4138 - accuracy: 0.8065 - mse: 0.1345\n",
            "Epoch 22/25\n",
            "7032/7032 [==============================] - 0s 40us/sample - loss: 0.4137 - accuracy: 0.8028 - mse: 0.1344\n",
            "Epoch 23/25\n",
            "7032/7032 [==============================] - 0s 40us/sample - loss: 0.4132 - accuracy: 0.8039 - mse: 0.1344\n",
            "Epoch 24/25\n",
            "7032/7032 [==============================] - 0s 41us/sample - loss: 0.4144 - accuracy: 0.8033 - mse: 0.1350\n",
            "Epoch 25/25\n",
            "7032/7032 [==============================] - 0s 41us/sample - loss: 0.4128 - accuracy: 0.8049 - mse: 0.1342\n",
            "the best params for are:  {'batch_size': 32, 'epochs': 25}\n",
            "the best score was:  0.801193368434906\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYckbfd7Es47",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.optimizers import SGD"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZDtpPGrC06D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 939
        },
        "outputId": "5d6e8fd8-9761-48b0-9116-b78a29ed8d91"
      },
      "source": [
        "# Doiing the hyperparameter tuning but this time leaving the epoch at 25\n",
        "# and the batch_size of 32\n",
        "# \n",
        "#  Trying a new type of optimizer sgd\n",
        "# Doing a random seed\n",
        "seed = 42\n",
        "np.random.seed(seed=seed)\n",
        "\n",
        "# Creating the function that will do building of model\n",
        "\n",
        "def build_model(x=x, optimizer = SGD):\n",
        "\n",
        "    # making it so that we get the optizmizer\n",
        "    opt = optimizer()\n",
        "\n",
        "\n",
        "    model = Sequential()\n",
        "    # add layers\n",
        "    model.add(Dense(128, activation=\"sigmoid\", input_shape=(x.shape[1],)))\n",
        "    model.add(Dense(64, activation=\"relu\"))\n",
        "    model.add(Dense(1, activation=\"sigmoid\"))\n",
        "    # compile the model\n",
        "    model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\", \"mse\"])\n",
        "    # returning the model\n",
        "    return model\n",
        "\n",
        "    # will now put the model in the kerasclassifier\n",
        "model = KerasClassifier(build_fn=build_model, verbose=1)\n",
        "\n",
        "params = {\n",
        "    \"epochs\": [25], \n",
        "    \"batch_size\": [32], \n",
        "\n",
        "}\n",
        "\n",
        "# now getting the grid search\n",
        "grid = GridSearchCV(estimator=model, param_grid=params, n_jobs=-1, verbose=1)\n",
        "grid.fit(x, y)\n",
        "\n",
        "\n",
        "# These were the params that we did\n",
        "print(\"the best params for are: \", grid.best_params_)\n",
        "print(\"the best score was: \", grid.best_score_)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   25.5s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.5611 - accuracy: 0.7342 - mse: 0.1882\n",
            "Epoch 2/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.5293 - accuracy: 0.7342 - mse: 0.1757\n",
            "Epoch 3/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.5045 - accuracy: 0.7344 - mse: 0.1661\n",
            "Epoch 4/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4821 - accuracy: 0.7408 - mse: 0.1577\n",
            "Epoch 5/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4641 - accuracy: 0.7648 - mse: 0.1512\n",
            "Epoch 6/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4523 - accuracy: 0.7782 - mse: 0.1473\n",
            "Epoch 7/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4442 - accuracy: 0.7861 - mse: 0.1446\n",
            "Epoch 8/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4405 - accuracy: 0.7921 - mse: 0.1435\n",
            "Epoch 9/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4379 - accuracy: 0.7904 - mse: 0.1427\n",
            "Epoch 10/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4353 - accuracy: 0.7912 - mse: 0.1418\n",
            "Epoch 11/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4342 - accuracy: 0.7894 - mse: 0.1416\n",
            "Epoch 12/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4336 - accuracy: 0.7915 - mse: 0.1413\n",
            "Epoch 13/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4314 - accuracy: 0.7945 - mse: 0.1405\n",
            "Epoch 14/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4311 - accuracy: 0.7942 - mse: 0.1404\n",
            "Epoch 15/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4308 - accuracy: 0.7939 - mse: 0.1403\n",
            "Epoch 16/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4296 - accuracy: 0.7920 - mse: 0.1401\n",
            "Epoch 17/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4292 - accuracy: 0.7959 - mse: 0.1399\n",
            "Epoch 18/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4295 - accuracy: 0.7947 - mse: 0.1399\n",
            "Epoch 19/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4285 - accuracy: 0.7948 - mse: 0.1396\n",
            "Epoch 20/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4280 - accuracy: 0.7937 - mse: 0.1394\n",
            "Epoch 21/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4270 - accuracy: 0.7993 - mse: 0.1391\n",
            "Epoch 22/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4263 - accuracy: 0.7952 - mse: 0.1390\n",
            "Epoch 23/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4264 - accuracy: 0.7955 - mse: 0.1389\n",
            "Epoch 24/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4261 - accuracy: 0.7979 - mse: 0.1388\n",
            "Epoch 25/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4256 - accuracy: 0.7975 - mse: 0.1386\n",
            "the best params for are:  {'batch_size': 32, 'epochs': 25}\n",
            "the best score was:  0.7959317564964294\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdVqCisgFW_8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This shows that ADAm was better, so we will keep adam and now tune the learning rate"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jOUWo1sFerT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 939
        },
        "outputId": "312090eb-192b-4c42-a3b6-7febf017bede"
      },
      "source": [
        "# Doiing the hyperparameter tuning but this time leaving the epoch at 25\n",
        "# and the batch_size of 32\n",
        "# \n",
        "#  Tuning the learning rate of the Adam\n",
        "# Doing a random seed\n",
        "seed = 42\n",
        "np.random.seed(seed=seed)\n",
        "\n",
        "# Creating the function that will do building of model\n",
        "\n",
        "def build_model(x=x, optimizer = Adam, lr=.001):\n",
        "\n",
        "    # making it so that we get the optizmizer\n",
        "    opt = optimizer(learning_rate=lr)\n",
        "\n",
        "\n",
        "    model = Sequential()\n",
        "    # add layers\n",
        "    model.add(Dense(128, activation=\"sigmoid\", input_shape=(x.shape[1],)))\n",
        "    model.add(Dense(64, activation=\"relu\"))\n",
        "    model.add(Dense(1, activation=\"sigmoid\"))\n",
        "    # compile the model\n",
        "    model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\", \"mse\"])\n",
        "    # returning the model\n",
        "    return model\n",
        "\n",
        "    # will now put the model in the kerasclassifier\n",
        "model = KerasClassifier(build_fn=build_model, verbose=1)\n",
        "\n",
        "params = {\n",
        "    \"epochs\": [25], \n",
        "    \"batch_size\": [32], \n",
        "    \"lr\": [.001, .01, .1, .0001]\n",
        "\n",
        "}\n",
        "\n",
        "# now getting the grid search\n",
        "grid = GridSearchCV(estimator=model, param_grid=params, n_jobs=-1, verbose=1)\n",
        "grid.fit(x, y)\n",
        "\n",
        "\n",
        "# These were the params that we did\n",
        "print(\"the best params for are: \", grid.best_params_)\n",
        "print(\"the best score was: \", grid.best_score_)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:  2.0min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "220/220 [==============================] - 0s 2ms/step - loss: 0.4786 - accuracy: 0.7621 - mse: 0.1580\n",
            "Epoch 2/25\n",
            "220/220 [==============================] - 0s 2ms/step - loss: 0.4336 - accuracy: 0.7920 - mse: 0.1414\n",
            "Epoch 3/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4265 - accuracy: 0.7935 - mse: 0.1389\n",
            "Epoch 4/25\n",
            "220/220 [==============================] - 0s 2ms/step - loss: 0.4256 - accuracy: 0.7982 - mse: 0.1384\n",
            "Epoch 5/25\n",
            "220/220 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.7944 - mse: 0.1390\n",
            "Epoch 6/25\n",
            "220/220 [==============================] - 0s 2ms/step - loss: 0.4225 - accuracy: 0.8020 - mse: 0.1376\n",
            "Epoch 7/25\n",
            "220/220 [==============================] - 0s 2ms/step - loss: 0.4206 - accuracy: 0.7993 - mse: 0.1367\n",
            "Epoch 8/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4234 - accuracy: 0.7981 - mse: 0.1382\n",
            "Epoch 9/25\n",
            "220/220 [==============================] - 0s 2ms/step - loss: 0.4206 - accuracy: 0.7979 - mse: 0.1371\n",
            "Epoch 10/25\n",
            "220/220 [==============================] - 0s 2ms/step - loss: 0.4204 - accuracy: 0.8003 - mse: 0.1368\n",
            "Epoch 11/25\n",
            "220/220 [==============================] - 0s 2ms/step - loss: 0.4194 - accuracy: 0.8022 - mse: 0.1364\n",
            "Epoch 12/25\n",
            "220/220 [==============================] - 0s 2ms/step - loss: 0.4192 - accuracy: 0.8016 - mse: 0.1365\n",
            "Epoch 13/25\n",
            "220/220 [==============================] - 0s 2ms/step - loss: 0.4195 - accuracy: 0.8008 - mse: 0.1366\n",
            "Epoch 14/25\n",
            "220/220 [==============================] - 0s 2ms/step - loss: 0.4183 - accuracy: 0.7999 - mse: 0.1362\n",
            "Epoch 15/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4171 - accuracy: 0.8026 - mse: 0.1358\n",
            "Epoch 16/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4169 - accuracy: 0.8025 - mse: 0.1358\n",
            "Epoch 17/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4167 - accuracy: 0.8026 - mse: 0.1358\n",
            "Epoch 18/25\n",
            "220/220 [==============================] - 0s 2ms/step - loss: 0.4148 - accuracy: 0.8057 - mse: 0.1350\n",
            "Epoch 19/25\n",
            "220/220 [==============================] - 0s 2ms/step - loss: 0.4159 - accuracy: 0.8013 - mse: 0.1354\n",
            "Epoch 20/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4161 - accuracy: 0.8012 - mse: 0.1356\n",
            "Epoch 21/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4158 - accuracy: 0.8023 - mse: 0.1355\n",
            "Epoch 22/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4155 - accuracy: 0.8043 - mse: 0.1356\n",
            "Epoch 23/25\n",
            "220/220 [==============================] - 0s 2ms/step - loss: 0.4146 - accuracy: 0.8003 - mse: 0.1351\n",
            "Epoch 24/25\n",
            "220/220 [==============================] - 0s 2ms/step - loss: 0.4148 - accuracy: 0.8043 - mse: 0.1352\n",
            "Epoch 25/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4140 - accuracy: 0.8056 - mse: 0.1348\n",
            "the best params for are:  {'batch_size': 32, 'epochs': 25, 'lr': 0.001}\n",
            "the best score was:  0.8014769554138184\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZdRTus6Jj9t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 939
        },
        "outputId": "54389717-b485-46d5-a106-bbc99fe6a24a"
      },
      "source": [
        "# Tuning now if I should change the number of layers\n",
        "# I am taking out one of the layers to see if the model gets better\n",
        "# \n",
        "# Doing a random seed\n",
        "seed = 42\n",
        "np.random.seed(seed=seed)\n",
        "\n",
        "# Creating the function that will do building of model\n",
        "\n",
        "def build_model(x=x, optimizer = Adam, lr=.001):\n",
        "\n",
        "    # making it so that we get the optizmizer\n",
        "    opt = optimizer(learning_rate=lr)\n",
        "\n",
        "\n",
        "    model = Sequential()\n",
        "    # add layers\n",
        "    model.add(Dense(128, activation=\"sigmoid\", input_shape=(x.shape[1],)))\n",
        "    #model.add(Dense(64, activation=\"relu\")) \n",
        "    model.add(Dense(1, activation=\"sigmoid\"))\n",
        "    # compile the model\n",
        "    model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\", \"mse\"])\n",
        "    # returning the model\n",
        "    return model\n",
        "\n",
        "    # will now put the model in the kerasclassifier\n",
        "model = KerasClassifier(build_fn=build_model, verbose=1)\n",
        "\n",
        "params = {\n",
        "    \"epochs\": [25], \n",
        "    \"batch_size\": [32], \n",
        "    \"lr\": [.001 ]\n",
        "\n",
        "}\n",
        "\n",
        "# now getting the grid search\n",
        "grid = GridSearchCV(estimator=model, param_grid=params, n_jobs=-1, verbose=1)\n",
        "grid.fit(x, y)\n",
        "\n",
        "\n",
        "# These were the params that we did\n",
        "print(\"the best params for are: \", grid.best_params_)\n",
        "print(\"the best score was: \", grid.best_score_)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   29.6s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4700 - accuracy: 0.7713 - mse: 0.1543\n",
            "Epoch 2/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4317 - accuracy: 0.7925 - mse: 0.1408\n",
            "Epoch 3/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4258 - accuracy: 0.7954 - mse: 0.1387\n",
            "Epoch 4/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4230 - accuracy: 0.8002 - mse: 0.1376\n",
            "Epoch 5/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4209 - accuracy: 0.8025 - mse: 0.1369\n",
            "Epoch 6/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4218 - accuracy: 0.8016 - mse: 0.1373\n",
            "Epoch 7/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4211 - accuracy: 0.8009 - mse: 0.1369\n",
            "Epoch 8/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4203 - accuracy: 0.8029 - mse: 0.1367\n",
            "Epoch 9/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4201 - accuracy: 0.7996 - mse: 0.1366\n",
            "Epoch 10/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4205 - accuracy: 0.8029 - mse: 0.1367\n",
            "Epoch 11/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4202 - accuracy: 0.8009 - mse: 0.1369\n",
            "Epoch 12/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4206 - accuracy: 0.7995 - mse: 0.1368\n",
            "Epoch 13/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4194 - accuracy: 0.8035 - mse: 0.1365\n",
            "Epoch 14/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4190 - accuracy: 0.8029 - mse: 0.1362\n",
            "Epoch 15/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4197 - accuracy: 0.8009 - mse: 0.1367\n",
            "Epoch 16/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4188 - accuracy: 0.8035 - mse: 0.1363\n",
            "Epoch 17/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4180 - accuracy: 0.8035 - mse: 0.1359\n",
            "Epoch 18/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4177 - accuracy: 0.8019 - mse: 0.1358\n",
            "Epoch 19/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4178 - accuracy: 0.8013 - mse: 0.1360\n",
            "Epoch 20/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4170 - accuracy: 0.8026 - mse: 0.1357\n",
            "Epoch 21/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4180 - accuracy: 0.8013 - mse: 0.1361\n",
            "Epoch 22/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4174 - accuracy: 0.8009 - mse: 0.1359\n",
            "Epoch 23/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4170 - accuracy: 0.8030 - mse: 0.1356\n",
            "Epoch 24/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4166 - accuracy: 0.8055 - mse: 0.1356\n",
            "Epoch 25/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4168 - accuracy: 0.8038 - mse: 0.1356\n",
            "the best params for are:  {'batch_size': 32, 'epochs': 25, 'lr': 0.001}\n",
            "the best score was:  0.8011932730674743\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPrvqv5nKkqU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# removing the layer made it only slightly worsened"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3klRynHOK2fs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 939
        },
        "outputId": "1b22558e-758a-455b-9439-07a4367269d0"
      },
      "source": [
        "# Tunning now the activation function\n",
        "# will be changing the activation function to all relu except at the end\n",
        "\n",
        "# Doing a random seed\n",
        "seed = 42\n",
        "np.random.seed(seed=seed)\n",
        "\n",
        "# Creating the function that will do building of model\n",
        "\n",
        "def build_model(x=x, optimizer = Adam, lr=.001):\n",
        "\n",
        "    # making it so that we get the optizmizer\n",
        "    opt = optimizer(learning_rate=lr)\n",
        "\n",
        "\n",
        "    model = Sequential()\n",
        "    # add layers\n",
        "    model.add(Dense(128, activation=\"relu\", input_shape=(x.shape[1],)))\n",
        "    model.add(Dense(64, activation=\"relu\"))\n",
        "    model.add(Dense(1, activation=\"sigmoid\"))\n",
        "    # compile the model\n",
        "    model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\", \"mse\"])\n",
        "    # returning the model\n",
        "    return model\n",
        "\n",
        "    # will now put the model in the kerasclassifier\n",
        "model = KerasClassifier(build_fn=build_model, verbose=1)\n",
        "\n",
        "params = {\n",
        "    \"epochs\": [25], \n",
        "    \"batch_size\": [32], \n",
        "    \"lr\": [.001]\n",
        "\n",
        "}\n",
        "\n",
        "# now getting the grid search\n",
        "grid = GridSearchCV(estimator=model, param_grid=params, n_jobs=-1, verbose=1)\n",
        "grid.fit(x, y)\n",
        "\n",
        "\n",
        "# These were the params that we did\n",
        "print(\"the best params for are: \", grid.best_params_)\n",
        "print(\"the best score was: \", grid.best_score_)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   30.5s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "220/220 [==============================] - 0s 2ms/step - loss: 0.4449 - accuracy: 0.7840 - mse: 0.1457\n",
            "Epoch 2/25\n",
            "220/220 [==============================] - 0s 2ms/step - loss: 0.4209 - accuracy: 0.7991 - mse: 0.1372\n",
            "Epoch 3/25\n",
            "220/220 [==============================] - 0s 2ms/step - loss: 0.4171 - accuracy: 0.8033 - mse: 0.1361\n",
            "Epoch 4/25\n",
            "220/220 [==============================] - 0s 2ms/step - loss: 0.4130 - accuracy: 0.8036 - mse: 0.1345\n",
            "Epoch 5/25\n",
            "220/220 [==============================] - 0s 2ms/step - loss: 0.4079 - accuracy: 0.8082 - mse: 0.1326\n",
            "Epoch 6/25\n",
            "220/220 [==============================] - 0s 2ms/step - loss: 0.4071 - accuracy: 0.8062 - mse: 0.1325\n",
            "Epoch 7/25\n",
            "220/220 [==============================] - 0s 2ms/step - loss: 0.4054 - accuracy: 0.8094 - mse: 0.1317\n",
            "Epoch 8/25\n",
            "220/220 [==============================] - 0s 2ms/step - loss: 0.4012 - accuracy: 0.8107 - mse: 0.1303\n",
            "Epoch 9/25\n",
            "220/220 [==============================] - 0s 2ms/step - loss: 0.3991 - accuracy: 0.8094 - mse: 0.1300\n",
            "Epoch 10/25\n",
            "220/220 [==============================] - 0s 2ms/step - loss: 0.3943 - accuracy: 0.8168 - mse: 0.1280\n",
            "Epoch 11/25\n",
            "220/220 [==============================] - 0s 2ms/step - loss: 0.3913 - accuracy: 0.8171 - mse: 0.1270\n",
            "Epoch 12/25\n",
            "220/220 [==============================] - 0s 2ms/step - loss: 0.3880 - accuracy: 0.8181 - mse: 0.1260\n",
            "Epoch 13/25\n",
            "220/220 [==============================] - 0s 2ms/step - loss: 0.3855 - accuracy: 0.8191 - mse: 0.1250\n",
            "Epoch 14/25\n",
            "220/220 [==============================] - 0s 2ms/step - loss: 0.3812 - accuracy: 0.8195 - mse: 0.1238\n",
            "Epoch 15/25\n",
            "220/220 [==============================] - 0s 2ms/step - loss: 0.3751 - accuracy: 0.8239 - mse: 0.1218\n",
            "Epoch 16/25\n",
            "220/220 [==============================] - 0s 2ms/step - loss: 0.3733 - accuracy: 0.8228 - mse: 0.1213\n",
            "Epoch 17/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.3695 - accuracy: 0.8269 - mse: 0.1198\n",
            "Epoch 18/25\n",
            "220/220 [==============================] - 0s 2ms/step - loss: 0.3655 - accuracy: 0.8244 - mse: 0.1187\n",
            "Epoch 19/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.3599 - accuracy: 0.8274 - mse: 0.1169\n",
            "Epoch 20/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.3547 - accuracy: 0.8275 - mse: 0.1152\n",
            "Epoch 21/25\n",
            "220/220 [==============================] - 0s 2ms/step - loss: 0.3502 - accuracy: 0.8352 - mse: 0.1136\n",
            "Epoch 22/25\n",
            "220/220 [==============================] - 0s 2ms/step - loss: 0.3451 - accuracy: 0.8373 - mse: 0.1118\n",
            "Epoch 23/25\n",
            "220/220 [==============================] - 0s 2ms/step - loss: 0.3426 - accuracy: 0.8403 - mse: 0.1109\n",
            "Epoch 24/25\n",
            "220/220 [==============================] - 0s 2ms/step - loss: 0.3382 - accuracy: 0.8397 - mse: 0.1094\n",
            "Epoch 25/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.3357 - accuracy: 0.8387 - mse: 0.1089\n",
            "the best params for are:  {'batch_size': 32, 'epochs': 25, 'lr': 0.001}\n",
            "the best score was:  0.7817106246948242\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBMGB8SULL-k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# When changing the first layer to a relu layer, it caused the model to worsen from \n",
        "# .8014 to .7817"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itz_xgeTLc0O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 939
        },
        "outputId": "ab0044f2-3922-4683-c09d-27ec8b2ed5b2"
      },
      "source": [
        "# Will now be making all the activation functions sigmoid\n",
        "\n",
        "# Doing a random seed\n",
        "seed = 42\n",
        "np.random.seed(seed=seed)\n",
        "\n",
        "# Creating the function that will do building of model\n",
        "\n",
        "def build_model(x=x, optimizer = Adam, lr=.001):\n",
        "\n",
        "    # making it so that we get the optizmizer\n",
        "    opt = optimizer(learning_rate=lr)\n",
        "\n",
        "\n",
        "    model = Sequential()\n",
        "    # add layers\n",
        "    model.add(Dense(128, activation=\"sigmoid\", input_shape=(x.shape[1],)))\n",
        "    model.add(Dense(64, activation=\"sigmoid\"))\n",
        "    model.add(Dense(1, activation=\"sigmoid\"))\n",
        "    # compile the model\n",
        "    model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\", \"mse\"])\n",
        "    # returning the model\n",
        "    return model\n",
        "\n",
        "    # will now put the model in the kerasclassifier\n",
        "model = KerasClassifier(build_fn=build_model, verbose=1)\n",
        "\n",
        "params = {\n",
        "    \"epochs\": [25], \n",
        "    \"batch_size\": [32], \n",
        "    \"lr\": [.001]\n",
        "\n",
        "}\n",
        "\n",
        "# now getting the grid search\n",
        "grid = GridSearchCV(estimator=model, param_grid=params, n_jobs=-1, verbose=1)\n",
        "grid.fit(x, y)\n",
        "\n",
        "\n",
        "# These were the params that we did\n",
        "print(\"the best params for are: \", grid.best_params_)\n",
        "print(\"the best score was: \", grid.best_score_)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   30.0s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4927 - accuracy: 0.7585 - mse: 0.1625\n",
            "Epoch 2/25\n",
            "220/220 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.7961 - mse: 0.1402\n",
            "Epoch 3/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4270 - accuracy: 0.7939 - mse: 0.1388\n",
            "Epoch 4/25\n",
            "220/220 [==============================] - 0s 2ms/step - loss: 0.4238 - accuracy: 0.7985 - mse: 0.1379\n",
            "Epoch 5/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4242 - accuracy: 0.8032 - mse: 0.1378\n",
            "Epoch 6/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4225 - accuracy: 0.7985 - mse: 0.1376\n",
            "Epoch 7/25\n",
            "220/220 [==============================] - 0s 2ms/step - loss: 0.4237 - accuracy: 0.7969 - mse: 0.1378\n",
            "Epoch 8/25\n",
            "220/220 [==============================] - 0s 2ms/step - loss: 0.4232 - accuracy: 0.7993 - mse: 0.1376\n",
            "Epoch 9/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4210 - accuracy: 0.7993 - mse: 0.1368\n",
            "Epoch 10/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4208 - accuracy: 0.8005 - mse: 0.1367\n",
            "Epoch 11/25\n",
            "220/220 [==============================] - 0s 2ms/step - loss: 0.4224 - accuracy: 0.8001 - mse: 0.1376\n",
            "Epoch 12/25\n",
            "220/220 [==============================] - 0s 2ms/step - loss: 0.4202 - accuracy: 0.8030 - mse: 0.1367\n",
            "Epoch 13/25\n",
            "220/220 [==============================] - 0s 2ms/step - loss: 0.4200 - accuracy: 0.8009 - mse: 0.1364\n",
            "Epoch 14/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4201 - accuracy: 0.8005 - mse: 0.1366\n",
            "Epoch 15/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4202 - accuracy: 0.8023 - mse: 0.1368\n",
            "Epoch 16/25\n",
            "220/220 [==============================] - 0s 2ms/step - loss: 0.4188 - accuracy: 0.8019 - mse: 0.1362\n",
            "Epoch 17/25\n",
            "220/220 [==============================] - 0s 2ms/step - loss: 0.4179 - accuracy: 0.8049 - mse: 0.1360\n",
            "Epoch 18/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4181 - accuracy: 0.8005 - mse: 0.1360\n",
            "Epoch 19/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4183 - accuracy: 0.8023 - mse: 0.1363\n",
            "Epoch 20/25\n",
            "220/220 [==============================] - 0s 2ms/step - loss: 0.4177 - accuracy: 0.8008 - mse: 0.1360\n",
            "Epoch 21/25\n",
            "220/220 [==============================] - 0s 2ms/step - loss: 0.4166 - accuracy: 0.8015 - mse: 0.1356\n",
            "Epoch 22/25\n",
            "220/220 [==============================] - 0s 2ms/step - loss: 0.4164 - accuracy: 0.8023 - mse: 0.1356\n",
            "Epoch 23/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4165 - accuracy: 0.8011 - mse: 0.1356\n",
            "Epoch 24/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4174 - accuracy: 0.8019 - mse: 0.1360\n",
            "Epoch 25/25\n",
            "220/220 [==============================] - 0s 2ms/step - loss: 0.4167 - accuracy: 0.8049 - mse: 0.1355\n",
            "the best params for are:  {'batch_size': 32, 'epochs': 25, 'lr': 0.001}\n",
            "the best score was:  0.8007669448852539\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMNZd95_Lr68",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# When making all the activation functions into a sigmoid activation function \n",
        "# it cause the model to do also worse at .80007 compared to .8014"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piiPjlnnL7oy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 939
        },
        "outputId": "c7173629-6ea3-4e04-89fa-68ac9f22e770"
      },
      "source": [
        "# Will try to tune the number of neurons in the layers\n",
        "# will try to lessen the number of the first hidden layer to 64\n",
        "\n",
        "# Doing a random seed\n",
        "seed = 42\n",
        "np.random.seed(seed=seed)\n",
        "\n",
        "# Creating the function that will do building of model\n",
        "\n",
        "def build_model(x=x, optimizer = Adam, lr=.001):\n",
        "\n",
        "    # making it so that we get the optizmizer\n",
        "    opt = optimizer(learning_rate=lr)\n",
        "\n",
        "\n",
        "    model = Sequential()\n",
        "    # add layers\n",
        "    model.add(Dense(64, activation=\"sigmoid\", input_shape=(x.shape[1],)))\n",
        "    model.add(Dense(64, activation=\"relu\"))\n",
        "    model.add(Dense(1, activation=\"sigmoid\"))\n",
        "    # compile the model\n",
        "    model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\", \"mse\"])\n",
        "    # returning the model\n",
        "    return model\n",
        "\n",
        "    # will now put the model in the kerasclassifier\n",
        "model = KerasClassifier(build_fn=build_model, verbose=1)\n",
        "\n",
        "params = {\n",
        "    \"epochs\": [25], \n",
        "    \"batch_size\": [32], \n",
        "    \"lr\": [.001]\n",
        "\n",
        "}\n",
        "\n",
        "# now getting the grid search\n",
        "grid = GridSearchCV(estimator=model, param_grid=params, n_jobs=-1, verbose=1)\n",
        "grid.fit(x, y)\n",
        "\n",
        "\n",
        "# These were the params that we did\n",
        "print(\"the best params for are: \", grid.best_params_)\n",
        "print(\"the best score was: \", grid.best_score_)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   28.9s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4814 - accuracy: 0.7602 - mse: 0.1587\n",
            "Epoch 2/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4311 - accuracy: 0.7932 - mse: 0.1403\n",
            "Epoch 3/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.7948 - mse: 0.1392\n",
            "Epoch 4/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4233 - accuracy: 0.7991 - mse: 0.1381\n",
            "Epoch 5/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4260 - accuracy: 0.7978 - mse: 0.1389\n",
            "Epoch 6/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4225 - accuracy: 0.7971 - mse: 0.1378\n",
            "Epoch 7/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4213 - accuracy: 0.7978 - mse: 0.1374\n",
            "Epoch 8/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4201 - accuracy: 0.7989 - mse: 0.1368\n",
            "Epoch 9/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4203 - accuracy: 0.7999 - mse: 0.1369\n",
            "Epoch 10/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4190 - accuracy: 0.8036 - mse: 0.1366\n",
            "Epoch 11/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4182 - accuracy: 0.8013 - mse: 0.1362\n",
            "Epoch 12/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4186 - accuracy: 0.8028 - mse: 0.1364\n",
            "Epoch 13/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4178 - accuracy: 0.8023 - mse: 0.1361\n",
            "Epoch 14/25\n",
            "220/220 [==============================] - 0s 2ms/step - loss: 0.4160 - accuracy: 0.8043 - mse: 0.1355\n",
            "Epoch 15/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4162 - accuracy: 0.8015 - mse: 0.1353\n",
            "Epoch 16/25\n",
            "220/220 [==============================] - 0s 2ms/step - loss: 0.4152 - accuracy: 0.8032 - mse: 0.1352\n",
            "Epoch 17/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4141 - accuracy: 0.8025 - mse: 0.1349\n",
            "Epoch 18/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4141 - accuracy: 0.8050 - mse: 0.1347\n",
            "Epoch 19/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4169 - accuracy: 0.8030 - mse: 0.1358\n",
            "Epoch 20/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4139 - accuracy: 0.8066 - mse: 0.1348\n",
            "Epoch 21/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4140 - accuracy: 0.8039 - mse: 0.1349\n",
            "Epoch 22/25\n",
            "220/220 [==============================] - 0s 2ms/step - loss: 0.4137 - accuracy: 0.8065 - mse: 0.1348\n",
            "Epoch 23/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4126 - accuracy: 0.8055 - mse: 0.1343\n",
            "Epoch 24/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4128 - accuracy: 0.8049 - mse: 0.1343\n",
            "Epoch 25/25\n",
            "220/220 [==============================] - 0s 2ms/step - loss: 0.4120 - accuracy: 0.8069 - mse: 0.1341\n",
            "the best params for are:  {'batch_size': 32, 'epochs': 25, 'lr': 0.001}\n",
            "the best score was:  0.803041398525238\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lM9KvW0Mtlu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# When making the number of nuerons in the first layer to 64 instead of 128. \n",
        "# It improved the model to .8030 from .8014\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJEa1PuqNN05",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 939
        },
        "outputId": "625166b0-3fb6-4e5b-f477-96dd48d08b29"
      },
      "source": [
        "# Will try to lower the amount in the second hidden layer to just 32\n",
        "\n",
        "\n",
        "# Doing a random seed\n",
        "seed = 42\n",
        "np.random.seed(seed=seed)\n",
        "\n",
        "# Creating the function that will do building of model\n",
        "\n",
        "def build_model(x=x, optimizer = Adam, lr=.001):\n",
        "\n",
        "    # making it so that we get the optizmizer\n",
        "    opt = optimizer(learning_rate=lr)\n",
        "\n",
        "\n",
        "    model = Sequential()\n",
        "    # add layers\n",
        "    model.add(Dense(64, activation=\"sigmoid\", input_shape=(x.shape[1],)))\n",
        "    model.add(Dense(32, activation=\"relu\"))\n",
        "    model.add(Dense(1, activation=\"sigmoid\"))\n",
        "    # compile the model\n",
        "    model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\", \"mse\"])\n",
        "    # returning the model\n",
        "    return model\n",
        "\n",
        "    # will now put the model in the kerasclassifier\n",
        "model = KerasClassifier(build_fn=build_model, verbose=1)\n",
        "\n",
        "params = {\n",
        "    \"epochs\": [25], \n",
        "    \"batch_size\": [32], \n",
        "    \"lr\": [.001]\n",
        "\n",
        "}\n",
        "\n",
        "# now getting the grid search\n",
        "grid = GridSearchCV(estimator=model, param_grid=params, n_jobs=-1, verbose=1)\n",
        "grid.fit(x, y)\n",
        "\n",
        "\n",
        "# These were the params that we did\n",
        "print(\"the best params for are: \", grid.best_params_)\n",
        "print(\"the best score was: \", grid.best_score_)\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   28.2s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.5137 - accuracy: 0.7336 - mse: 0.1714\n",
            "Epoch 2/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4364 - accuracy: 0.7948 - mse: 0.1423\n",
            "Epoch 3/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4278 - accuracy: 0.7958 - mse: 0.1394\n",
            "Epoch 4/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4254 - accuracy: 0.7976 - mse: 0.1385\n",
            "Epoch 5/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4235 - accuracy: 0.7996 - mse: 0.1378\n",
            "Epoch 6/25\n",
            "220/220 [==============================] - 0s 2ms/step - loss: 0.4231 - accuracy: 0.8029 - mse: 0.1377\n",
            "Epoch 7/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4221 - accuracy: 0.7979 - mse: 0.1375\n",
            "Epoch 8/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4212 - accuracy: 0.7974 - mse: 0.1373\n",
            "Epoch 9/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4205 - accuracy: 0.8015 - mse: 0.1369\n",
            "Epoch 10/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4198 - accuracy: 0.8023 - mse: 0.1366\n",
            "Epoch 11/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4198 - accuracy: 0.8039 - mse: 0.1366\n",
            "Epoch 12/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4182 - accuracy: 0.8020 - mse: 0.1362\n",
            "Epoch 13/25\n",
            "220/220 [==============================] - 0s 2ms/step - loss: 0.4172 - accuracy: 0.8047 - mse: 0.1357\n",
            "Epoch 14/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4178 - accuracy: 0.8045 - mse: 0.1361\n",
            "Epoch 15/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4175 - accuracy: 0.8025 - mse: 0.1359\n",
            "Epoch 16/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4168 - accuracy: 0.8055 - mse: 0.1357\n",
            "Epoch 17/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4158 - accuracy: 0.8059 - mse: 0.1354\n",
            "Epoch 18/25\n",
            "220/220 [==============================] - 0s 2ms/step - loss: 0.4160 - accuracy: 0.8030 - mse: 0.1353\n",
            "Epoch 19/25\n",
            "220/220 [==============================] - 0s 2ms/step - loss: 0.4158 - accuracy: 0.8033 - mse: 0.1353\n",
            "Epoch 20/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4154 - accuracy: 0.8035 - mse: 0.1353\n",
            "Epoch 21/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4142 - accuracy: 0.8055 - mse: 0.1348\n",
            "Epoch 22/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4152 - accuracy: 0.8016 - mse: 0.1351\n",
            "Epoch 23/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4145 - accuracy: 0.8043 - mse: 0.1349\n",
            "Epoch 24/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4131 - accuracy: 0.8072 - mse: 0.1345\n",
            "Epoch 25/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4131 - accuracy: 0.8056 - mse: 0.1343\n",
            "the best params for are:  {'batch_size': 32, 'epochs': 25, 'lr': 0.001}\n",
            "the best score was:  0.8006249785423278\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrfiqRd5Ng6n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Lowering the second hidden layer to just 32 from 64 made the model\n",
        "# perform just a little worse from .803 to .80006"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKH8QEbNNwMf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 939
        },
        "outputId": "2b1f236e-d8c0-487b-9a0a-04b08ca03994"
      },
      "source": [
        "# Will try to raise the number of neurons in the second layer to 128\n",
        "\n",
        "# Doing a random seed\n",
        "seed = 42\n",
        "np.random.seed(seed=seed)\n",
        "\n",
        "# Creating the function that will do building of model\n",
        "\n",
        "def build_model(x=x, optimizer = Adam, lr=.001):\n",
        "\n",
        "    # making it so that we get the optizmizer\n",
        "    opt = optimizer(learning_rate=lr)\n",
        "\n",
        "\n",
        "    model = Sequential()\n",
        "    # add layers\n",
        "    model.add(Dense(64, activation=\"sigmoid\", input_shape=(x.shape[1],)))\n",
        "    model.add(Dense(128, activation=\"relu\"))\n",
        "    model.add(Dense(1, activation=\"sigmoid\"))\n",
        "    # compile the model\n",
        "    model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\", \"mse\"])\n",
        "    # returning the model\n",
        "    return model\n",
        "\n",
        "    # will now put the model in the kerasclassifier\n",
        "model = KerasClassifier(build_fn=build_model, verbose=1)\n",
        "\n",
        "params = {\n",
        "    \"epochs\": [25], \n",
        "    \"batch_size\": [32], \n",
        "    \"lr\": [.001]\n",
        "\n",
        "}\n",
        "\n",
        "# now getting the grid search\n",
        "grid = GridSearchCV(estimator=model, param_grid=params, n_jobs=-1, verbose=1)\n",
        "grid.fit(x, y)\n",
        "\n",
        "\n",
        "# These were the params that we did\n",
        "print(\"the best params for are: \", grid.best_params_)\n",
        "print(\"the best score was: \", grid.best_score_)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   29.7s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4921 - accuracy: 0.7634 - mse: 0.1623\n",
            "Epoch 2/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4339 - accuracy: 0.7910 - mse: 0.1414\n",
            "Epoch 3/25\n",
            "220/220 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.7966 - mse: 0.1391\n",
            "Epoch 4/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4258 - accuracy: 0.7974 - mse: 0.1388\n",
            "Epoch 5/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4247 - accuracy: 0.8003 - mse: 0.1384\n",
            "Epoch 6/25\n",
            "220/220 [==============================] - 0s 2ms/step - loss: 0.4231 - accuracy: 0.8002 - mse: 0.1378\n",
            "Epoch 7/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4207 - accuracy: 0.8025 - mse: 0.1369\n",
            "Epoch 8/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4224 - accuracy: 0.7992 - mse: 0.1377\n",
            "Epoch 9/25\n",
            "220/220 [==============================] - 0s 2ms/step - loss: 0.4240 - accuracy: 0.8013 - mse: 0.1382\n",
            "Epoch 10/25\n",
            "220/220 [==============================] - 0s 2ms/step - loss: 0.4200 - accuracy: 0.8008 - mse: 0.1370\n",
            "Epoch 11/25\n",
            "220/220 [==============================] - 0s 2ms/step - loss: 0.4195 - accuracy: 0.8018 - mse: 0.1364\n",
            "Epoch 12/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4200 - accuracy: 0.7998 - mse: 0.1370\n",
            "Epoch 13/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4196 - accuracy: 0.7995 - mse: 0.1367\n",
            "Epoch 14/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4231 - accuracy: 0.8009 - mse: 0.1378\n",
            "Epoch 15/25\n",
            "220/220 [==============================] - 0s 2ms/step - loss: 0.4201 - accuracy: 0.8009 - mse: 0.1370\n",
            "Epoch 16/25\n",
            "220/220 [==============================] - 0s 2ms/step - loss: 0.4185 - accuracy: 0.8018 - mse: 0.1363\n",
            "Epoch 17/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4181 - accuracy: 0.8039 - mse: 0.1362\n",
            "Epoch 18/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4175 - accuracy: 0.8029 - mse: 0.1360\n",
            "Epoch 19/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4165 - accuracy: 0.8052 - mse: 0.1356\n",
            "Epoch 20/25\n",
            "220/220 [==============================] - 0s 2ms/step - loss: 0.4167 - accuracy: 0.8009 - mse: 0.1356\n",
            "Epoch 21/25\n",
            "220/220 [==============================] - 0s 2ms/step - loss: 0.4149 - accuracy: 0.8063 - mse: 0.1350\n",
            "Epoch 22/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4150 - accuracy: 0.8067 - mse: 0.1350\n",
            "Epoch 23/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4151 - accuracy: 0.8047 - mse: 0.1352\n",
            "Epoch 24/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4141 - accuracy: 0.8042 - mse: 0.1348\n",
            "Epoch 25/25\n",
            "220/220 [==============================] - 0s 2ms/step - loss: 0.4132 - accuracy: 0.8040 - mse: 0.1345\n",
            "the best params for are:  {'batch_size': 32, 'epochs': 25, 'lr': 0.001}\n",
            "the best score was:  0.8023313641548157\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EdQgcZ_N8m4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# When increasing the number of the neurons in the second hidden layer\n",
        "# it made the model perform just a little worse from .803 to .802"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KschnECGQJFv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import  Dropout"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DO9JQqnIONZj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 939
        },
        "outputId": "c6bd6828-5507-4125-910d-bce53a0229e2"
      },
      "source": [
        "# Tuning using dropout\n",
        "\n",
        "# Doing a random seed\n",
        "seed = 42\n",
        "np.random.seed(seed=seed)\n",
        "\n",
        "# Creating the function that will do building of model\n",
        "\n",
        "def build_model(x=x, optimizer = Adam, lr=.001, drop_out_1=True):\n",
        "\n",
        "    # making it so that we get the optizmizer\n",
        "    opt = optimizer(learning_rate=lr)\n",
        "\n",
        "\n",
        "    model = Sequential()\n",
        "    # add layers\n",
        "    model.add(Dense(64, activation=\"sigmoid\", input_shape=(x.shape[1],)))\n",
        "    # Adding the possibility to have a dropout layer\n",
        "    if drop_out_1 == True:\n",
        "      model.add(Dropout(.2))\n",
        "    model.add(Dense(64, activation=\"relu\"))\n",
        "    model.add(Dense(1, activation=\"sigmoid\"))\n",
        "    # compile the model\n",
        "    model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\", \"mse\"])\n",
        "    # returning the model\n",
        "    return model\n",
        "\n",
        "    # will now put the model in the kerasclassifier\n",
        "model = KerasClassifier(build_fn=build_model, verbose=1)\n",
        "\n",
        "params = {\n",
        "    \"epochs\": [25], \n",
        "    \"batch_size\": [32], \n",
        "    \"lr\": [.001], \n",
        "    \"drop_out_1\": [True, False]\n",
        "\n",
        "}\n",
        "\n",
        "# now getting the grid search\n",
        "grid = GridSearchCV(estimator=model, param_grid=params, n_jobs=-1, verbose=1)\n",
        "grid.fit(x, y)\n",
        "\n",
        "\n",
        "# These were the params that we did\n",
        "print(\"the best params for are: \", grid.best_params_)\n",
        "print(\"the best score was: \", grid.best_score_)\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  1.0min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4790 - accuracy: 0.7679 - mse: 0.1580\n",
            "Epoch 2/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4315 - accuracy: 0.7948 - mse: 0.1406\n",
            "Epoch 3/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4268 - accuracy: 0.7968 - mse: 0.1390\n",
            "Epoch 4/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4267 - accuracy: 0.7954 - mse: 0.1391\n",
            "Epoch 5/25\n",
            "220/220 [==============================] - 0s 2ms/step - loss: 0.4236 - accuracy: 0.7991 - mse: 0.1379\n",
            "Epoch 6/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4238 - accuracy: 0.7991 - mse: 0.1381\n",
            "Epoch 7/25\n",
            "220/220 [==============================] - 0s 2ms/step - loss: 0.4229 - accuracy: 0.7995 - mse: 0.1377\n",
            "Epoch 8/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4223 - accuracy: 0.7996 - mse: 0.1374\n",
            "Epoch 9/25\n",
            "220/220 [==============================] - 0s 2ms/step - loss: 0.4209 - accuracy: 0.8018 - mse: 0.1370\n",
            "Epoch 10/25\n",
            "220/220 [==============================] - 0s 2ms/step - loss: 0.4203 - accuracy: 0.8011 - mse: 0.1368\n",
            "Epoch 11/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4207 - accuracy: 0.8013 - mse: 0.1370\n",
            "Epoch 12/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4194 - accuracy: 0.7984 - mse: 0.1366\n",
            "Epoch 13/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4185 - accuracy: 0.8011 - mse: 0.1363\n",
            "Epoch 14/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4181 - accuracy: 0.8026 - mse: 0.1361\n",
            "Epoch 15/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4174 - accuracy: 0.8056 - mse: 0.1356\n",
            "Epoch 16/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4181 - accuracy: 0.8001 - mse: 0.1362\n",
            "Epoch 17/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4183 - accuracy: 0.8035 - mse: 0.1364\n",
            "Epoch 18/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4165 - accuracy: 0.8033 - mse: 0.1355\n",
            "Epoch 19/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4157 - accuracy: 0.8002 - mse: 0.1354\n",
            "Epoch 20/25\n",
            "220/220 [==============================] - 0s 2ms/step - loss: 0.4161 - accuracy: 0.8046 - mse: 0.1354\n",
            "Epoch 21/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4151 - accuracy: 0.8040 - mse: 0.1350\n",
            "Epoch 22/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4153 - accuracy: 0.8033 - mse: 0.1352\n",
            "Epoch 23/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4152 - accuracy: 0.8016 - mse: 0.1353\n",
            "Epoch 24/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4147 - accuracy: 0.8056 - mse: 0.1350\n",
            "Epoch 25/25\n",
            "220/220 [==============================] - 0s 1ms/step - loss: 0.4142 - accuracy: 0.8045 - mse: 0.1348\n",
            "the best params for are:  {'batch_size': 32, 'drop_out_1': False, 'epochs': 25, 'lr': 0.001}\n",
            "the best score was:  0.8014771580696106\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NU7hS0PQ8to",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This shows that the dropout when set to False seemed to be the best"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PX2ZBizDRDyL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# I am using the default initialization mode.\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FfZRtJ7MCN3x"
      },
      "source": [
        "## Stretch Goals:\n",
        "\n",
        "- Try to implement Random Search Hyperparameter Tuning on this dataset\n",
        "- Try to implement Bayesian Optimiation tuning on this dataset using hyperas or hyperopt (if you're brave)\n",
        "- Practice hyperparameter tuning other datasets that we have looked at. How high can you get MNIST? Above 99%?\n",
        "- Study for the Sprint Challenge\n",
        " - Can you implement both perceptron and MLP models from scratch with forward and backpropagation?\n",
        " - Can you implement both perceptron and MLP models in keras and tune their hyperparameters with cross validation?"
      ]
    }
  ]
}
