{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Ryp-TVm4njD"
   },
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "\n",
    "# Hyperparameter Tuning\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2 Assignment 4*\n",
    "\n",
    "## Your Mission, should you choose to accept it...\n",
    "\n",
    "To hyperparameter tune and extract every ounce of accuracy out of this telecom customer churn dataset: [Available Here](https://lambdaschool-data-science.s3.amazonaws.com/telco-churn/WA_Fn-UseC_-Telco-Customer-Churn+(1).csv)\n",
    "\n",
    "## Requirements\n",
    "\n",
    "- Load the data\n",
    "- Clean the data if necessary (it will be)\n",
    "- Create and fit a baseline Keras MLP model to the data.\n",
    "- Hyperparameter tune (at least) the following parameters:\n",
    " - batch_size\n",
    " - training epochs\n",
    " - optimizer\n",
    " - learning rate (if applicable to optimizer)\n",
    " - momentum (if applicable to optimizer)\n",
    " - activation functions\n",
    " - network weight initialization\n",
    " - dropout regularization\n",
    " - number of neurons in the hidden layer\n",
    " \n",
    " You must use Grid Search and Cross Validation for your initial pass of the above hyperparameters\n",
    " \n",
    " Try and get the maximum accuracy possible out of this data! You'll save big telecoms millions! Doesn't that sound great?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NNJ-tOBs4jM1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerID</th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>...</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7590-VHVEG</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5575-GNVDE</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>34</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.5</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3668-QPYBK</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7795-CFOCW</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>45</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9237-HQITU</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7038</th>\n",
       "      <td>6840-RESVB</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>24</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>One year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>84.80</td>\n",
       "      <td>1990.5</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7039</th>\n",
       "      <td>2234-XADUH</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>72</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>One year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Credit card (automatic)</td>\n",
       "      <td>103.20</td>\n",
       "      <td>7362.9</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7040</th>\n",
       "      <td>4801-JZAZL</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>11</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>29.60</td>\n",
       "      <td>346.45</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7041</th>\n",
       "      <td>8361-LTMKD</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>4</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>74.40</td>\n",
       "      <td>306.6</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7042</th>\n",
       "      <td>3186-AJIEK</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>66</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Two year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>105.65</td>\n",
       "      <td>6844.5</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7043 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      customerID  gender  SeniorCitizen Partner Dependents  tenure  \\\n",
       "0     7590-VHVEG  Female              0     Yes         No       1   \n",
       "1     5575-GNVDE    Male              0      No         No      34   \n",
       "2     3668-QPYBK    Male              0      No         No       2   \n",
       "3     7795-CFOCW    Male              0      No         No      45   \n",
       "4     9237-HQITU  Female              0      No         No       2   \n",
       "...          ...     ...            ...     ...        ...     ...   \n",
       "7038  6840-RESVB    Male              0     Yes        Yes      24   \n",
       "7039  2234-XADUH  Female              0     Yes        Yes      72   \n",
       "7040  4801-JZAZL  Female              0     Yes        Yes      11   \n",
       "7041  8361-LTMKD    Male              1     Yes         No       4   \n",
       "7042  3186-AJIEK    Male              0      No         No      66   \n",
       "\n",
       "     PhoneService     MultipleLines InternetService OnlineSecurity  ...  \\\n",
       "0              No  No phone service             DSL             No  ...   \n",
       "1             Yes                No             DSL            Yes  ...   \n",
       "2             Yes                No             DSL            Yes  ...   \n",
       "3              No  No phone service             DSL            Yes  ...   \n",
       "4             Yes                No     Fiber optic             No  ...   \n",
       "...           ...               ...             ...            ...  ...   \n",
       "7038          Yes               Yes             DSL            Yes  ...   \n",
       "7039          Yes               Yes     Fiber optic             No  ...   \n",
       "7040           No  No phone service             DSL            Yes  ...   \n",
       "7041          Yes               Yes     Fiber optic             No  ...   \n",
       "7042          Yes                No     Fiber optic            Yes  ...   \n",
       "\n",
       "     DeviceProtection TechSupport StreamingTV StreamingMovies        Contract  \\\n",
       "0                  No          No          No              No  Month-to-month   \n",
       "1                 Yes          No          No              No        One year   \n",
       "2                  No          No          No              No  Month-to-month   \n",
       "3                 Yes         Yes          No              No        One year   \n",
       "4                  No          No          No              No  Month-to-month   \n",
       "...               ...         ...         ...             ...             ...   \n",
       "7038              Yes         Yes         Yes             Yes        One year   \n",
       "7039              Yes          No         Yes             Yes        One year   \n",
       "7040               No          No          No              No  Month-to-month   \n",
       "7041               No          No          No              No  Month-to-month   \n",
       "7042              Yes         Yes         Yes             Yes        Two year   \n",
       "\n",
       "     PaperlessBilling              PaymentMethod MonthlyCharges  TotalCharges  \\\n",
       "0                 Yes           Electronic check          29.85         29.85   \n",
       "1                  No               Mailed check          56.95        1889.5   \n",
       "2                 Yes               Mailed check          53.85        108.15   \n",
       "3                  No  Bank transfer (automatic)          42.30       1840.75   \n",
       "4                 Yes           Electronic check          70.70        151.65   \n",
       "...               ...                        ...            ...           ...   \n",
       "7038              Yes               Mailed check          84.80        1990.5   \n",
       "7039              Yes    Credit card (automatic)         103.20        7362.9   \n",
       "7040              Yes           Electronic check          29.60        346.45   \n",
       "7041              Yes               Mailed check          74.40         306.6   \n",
       "7042              Yes  Bank transfer (automatic)         105.65        6844.5   \n",
       "\n",
       "     Churn  \n",
       "0       No  \n",
       "1       No  \n",
       "2      Yes  \n",
       "3       No  \n",
       "4      Yes  \n",
       "...    ...  \n",
       "7038    No  \n",
       "7039    No  \n",
       "7040    No  \n",
       "7041   Yes  \n",
       "7042    No  \n",
       "\n",
       "[7043 rows x 21 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the data if necessary (it will be)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customerID          0\n",
       "gender              0\n",
       "SeniorCitizen       0\n",
       "Partner             0\n",
       "Dependents          0\n",
       "tenure              0\n",
       "PhoneService        0\n",
       "MultipleLines       0\n",
       "InternetService     0\n",
       "OnlineSecurity      0\n",
       "OnlineBackup        0\n",
       "DeviceProtection    0\n",
       "TechSupport         0\n",
       "StreamingTV         0\n",
       "StreamingMovies     0\n",
       "Contract            0\n",
       "PaperlessBilling    0\n",
       "PaymentMethod       0\n",
       "MonthlyCharges      0\n",
       "TotalCharges        0\n",
       "Churn               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customerID           object\n",
       "gender               object\n",
       "SeniorCitizen         int64\n",
       "Partner              object\n",
       "Dependents           object\n",
       "tenure                int64\n",
       "PhoneService         object\n",
       "MultipleLines        object\n",
       "InternetService      object\n",
       "OnlineSecurity       object\n",
       "OnlineBackup         object\n",
       "DeviceProtection     object\n",
       "TechSupport          object\n",
       "StreamingTV          object\n",
       "StreamingMovies      object\n",
       "Contract             object\n",
       "PaperlessBilling     object\n",
       "PaymentMethod        object\n",
       "MonthlyCharges      float64\n",
       "TotalCharges         object\n",
       "Churn                object\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No     5174\n",
       "Yes    1869\n",
       "Name: Churn, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Churn'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5174\n",
       "1    1869\n",
       "Name: Churn, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Churn'].map({\n",
    "    'No': 0,\n",
    "    'Yes': 1\n",
    "}).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Male      3555\n",
       "Female    3488\n",
       "Name: gender, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- customerID -----\n",
      "5832-EXGTT    1\n",
      "2607-DHDAK    1\n",
      "9068-VPWQQ    1\n",
      "9919-YLNNG    1\n",
      "9408-HRXRK    1\n",
      "             ..\n",
      "4193-IBKSW    1\n",
      "9026-RNUJS    1\n",
      "8309-IEYJD    1\n",
      "8148-BPLZQ    1\n",
      "7943-RQCHR    1\n",
      "Name: customerID, Length: 7043, dtype: int64\n",
      "\n",
      "----- gender -----\n",
      "Male      3555\n",
      "Female    3488\n",
      "Name: gender, dtype: int64\n",
      "\n",
      "----- SeniorCitizen -----\n",
      "0    5901\n",
      "1    1142\n",
      "Name: SeniorCitizen, dtype: int64\n",
      "\n",
      "----- Partner -----\n",
      "No     3641\n",
      "Yes    3402\n",
      "Name: Partner, dtype: int64\n",
      "\n",
      "----- Dependents -----\n",
      "No     4933\n",
      "Yes    2110\n",
      "Name: Dependents, dtype: int64\n",
      "\n",
      "----- tenure -----\n",
      "1     613\n",
      "72    362\n",
      "2     238\n",
      "3     200\n",
      "4     176\n",
      "     ... \n",
      "28     57\n",
      "39     56\n",
      "44     51\n",
      "36     50\n",
      "0      11\n",
      "Name: tenure, Length: 73, dtype: int64\n",
      "\n",
      "----- PhoneService -----\n",
      "Yes    6361\n",
      "No      682\n",
      "Name: PhoneService, dtype: int64\n",
      "\n",
      "----- MultipleLines -----\n",
      "No                  3390\n",
      "Yes                 2971\n",
      "No phone service     682\n",
      "Name: MultipleLines, dtype: int64\n",
      "\n",
      "----- InternetService -----\n",
      "Fiber optic    3096\n",
      "DSL            2421\n",
      "No             1526\n",
      "Name: InternetService, dtype: int64\n",
      "\n",
      "----- OnlineSecurity -----\n",
      "No                     3498\n",
      "Yes                    2019\n",
      "No internet service    1526\n",
      "Name: OnlineSecurity, dtype: int64\n",
      "\n",
      "----- OnlineBackup -----\n",
      "No                     3088\n",
      "Yes                    2429\n",
      "No internet service    1526\n",
      "Name: OnlineBackup, dtype: int64\n",
      "\n",
      "----- DeviceProtection -----\n",
      "No                     3095\n",
      "Yes                    2422\n",
      "No internet service    1526\n",
      "Name: DeviceProtection, dtype: int64\n",
      "\n",
      "----- TechSupport -----\n",
      "No                     3473\n",
      "Yes                    2044\n",
      "No internet service    1526\n",
      "Name: TechSupport, dtype: int64\n",
      "\n",
      "----- StreamingTV -----\n",
      "No                     2810\n",
      "Yes                    2707\n",
      "No internet service    1526\n",
      "Name: StreamingTV, dtype: int64\n",
      "\n",
      "----- StreamingMovies -----\n",
      "No                     2785\n",
      "Yes                    2732\n",
      "No internet service    1526\n",
      "Name: StreamingMovies, dtype: int64\n",
      "\n",
      "----- Contract -----\n",
      "Month-to-month    3875\n",
      "Two year          1695\n",
      "One year          1473\n",
      "Name: Contract, dtype: int64\n",
      "\n",
      "----- PaperlessBilling -----\n",
      "Yes    4171\n",
      "No     2872\n",
      "Name: PaperlessBilling, dtype: int64\n",
      "\n",
      "----- PaymentMethod -----\n",
      "Electronic check             2365\n",
      "Mailed check                 1612\n",
      "Bank transfer (automatic)    1544\n",
      "Credit card (automatic)      1522\n",
      "Name: PaymentMethod, dtype: int64\n",
      "\n",
      "----- MonthlyCharges -----\n",
      "20.05     61\n",
      "19.85     45\n",
      "19.95     44\n",
      "19.90     44\n",
      "20.00     43\n",
      "          ..\n",
      "114.75     1\n",
      "103.60     1\n",
      "113.40     1\n",
      "57.65      1\n",
      "113.30     1\n",
      "Name: MonthlyCharges, Length: 1585, dtype: int64\n",
      "\n",
      "----- TotalCharges -----\n",
      "20.2       11\n",
      "           11\n",
      "19.75       9\n",
      "19.9        8\n",
      "19.65       8\n",
      "           ..\n",
      "6669.05     1\n",
      "76.2        1\n",
      "2625.55     1\n",
      "8152.3      1\n",
      "6339.45     1\n",
      "Name: TotalCharges, Length: 6531, dtype: int64\n",
      "\n",
      "----- Churn -----\n",
      "No     5174\n",
      "Yes    1869\n",
      "Name: Churn, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for column in df.columns:\n",
    "    print('-'*5, column, '-'*5)\n",
    "    print(df[column].value_counts())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- --\n",
      "-- --\n",
      "-- --\n",
      "-- --\n",
      "-- --\n",
      "-- --\n",
      "-- --\n",
      "-- --\n",
      "-- --\n",
      "-- --\n",
      "-- --\n"
     ]
    }
   ],
   "source": [
    "for tcharge in df[df['TotalCharges'].str.contains('[^0-9.]')]['TotalCharges']:\n",
    "    print(f'--{tcharge}--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         29.85\n",
       "1       1889.50\n",
       "2        108.15\n",
       "3       1840.75\n",
       "4        151.65\n",
       "         ...   \n",
       "7038    1990.50\n",
       "7039    7362.90\n",
       "7040     346.45\n",
       "7041     306.60\n",
       "7042    6844.50\n",
       "Name: TotalCharges, Length: 7043, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['TotalCharges'].str.replace(' ', '0').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrangle(dataframe):\n",
    "    df = dataframe.copy()\n",
    "\n",
    "    # drop customerID - all samples unique\n",
    "    df = df.drop(columns='customerID')\n",
    "\n",
    "    # one-hot encode types of internet service\n",
    "    #  not dropping the column because i am converting to yes/no (1/0) later\n",
    "    df['fiber_optic'] = df['InternetService'] == 'Fiber optic'\n",
    "    df['dsl'] = df['InternetService'] == 'DSL'\n",
    "    \n",
    "    # one-hot encode contract types\n",
    "    df['contract_mtm'] = df['Contract'] == 'Month-to-month'\n",
    "    df['contract_2yr'] = df['Contract'] == 'Two year'\n",
    "    df['contract_1yr'] = df['Contract'] == 'One year'\n",
    "    df = df.drop(columns='Contract')\n",
    "\n",
    "    # one-hot encode payment method\n",
    "    df['payment_echeck'] = df['PaymentMethod'] == 'Electronic check'\n",
    "    df['payment_mcheck'] = df['PaymentMethod'] == 'Mailed check'\n",
    "    df['payment_bank'] = df['PaymentMethod'] == 'Bank transfer (automatic)'\n",
    "    df['payment_ccard'] = df['PaymentMethod'] == 'Credit card (automatic)'\n",
    "    df = df.drop(columns='PaymentMethod')\n",
    "    \n",
    "    # encode binary categorical columns\n",
    "    binary_columns = ['gender', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines',\n",
    "                      'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n",
    "                      'TechSupport', 'StreamingTV', 'StreamingMovies', 'PaperlessBilling',\n",
    "                      'Churn']\n",
    "    for column in binary_columns:\n",
    "        df[column] = df[column].map({\n",
    "            'Male': 0,\n",
    "            'Female': 1,\n",
    "            'No': 0,\n",
    "            'Yes': 1,\n",
    "            'No phone service': 0,\n",
    "            'Fiber optic': 1,\n",
    "            'DSL': 1,\n",
    "            'No internet service': 0,\n",
    "        })\n",
    "\n",
    "    # replace empty total with 0 then convert to float\n",
    "    df['TotalCharges'] = df['TotalCharges'].str.replace(' ', '0').astype(float)\n",
    "    \n",
    "    for column in df.columns:\n",
    "        df[column] = df[column].astype(float)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = wrangle(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>OnlineBackup</th>\n",
       "      <th>...</th>\n",
       "      <th>Churn</th>\n",
       "      <th>fiber_optic</th>\n",
       "      <th>dsl</th>\n",
       "      <th>contract_mtm</th>\n",
       "      <th>contract_2yr</th>\n",
       "      <th>contract_1yr</th>\n",
       "      <th>payment_echeck</th>\n",
       "      <th>payment_mcheck</th>\n",
       "      <th>payment_bank</th>\n",
       "      <th>payment_ccard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7038</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7039</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7040</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7041</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7042</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7043 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender  SeniorCitizen  Partner  Dependents  tenure  PhoneService  \\\n",
       "0        1.0            0.0      1.0         0.0     1.0           0.0   \n",
       "1        0.0            0.0      0.0         0.0    34.0           1.0   \n",
       "2        0.0            0.0      0.0         0.0     2.0           1.0   \n",
       "3        0.0            0.0      0.0         0.0    45.0           0.0   \n",
       "4        1.0            0.0      0.0         0.0     2.0           1.0   \n",
       "...      ...            ...      ...         ...     ...           ...   \n",
       "7038     0.0            0.0      1.0         1.0    24.0           1.0   \n",
       "7039     1.0            0.0      1.0         1.0    72.0           1.0   \n",
       "7040     1.0            0.0      1.0         1.0    11.0           0.0   \n",
       "7041     0.0            1.0      1.0         0.0     4.0           1.0   \n",
       "7042     0.0            0.0      0.0         0.0    66.0           1.0   \n",
       "\n",
       "      MultipleLines  InternetService  OnlineSecurity  OnlineBackup  ...  \\\n",
       "0               0.0              1.0             0.0           1.0  ...   \n",
       "1               0.0              1.0             1.0           0.0  ...   \n",
       "2               0.0              1.0             1.0           1.0  ...   \n",
       "3               0.0              1.0             1.0           0.0  ...   \n",
       "4               0.0              1.0             0.0           0.0  ...   \n",
       "...             ...              ...             ...           ...  ...   \n",
       "7038            1.0              1.0             1.0           0.0  ...   \n",
       "7039            1.0              1.0             0.0           1.0  ...   \n",
       "7040            0.0              1.0             1.0           0.0  ...   \n",
       "7041            1.0              1.0             0.0           0.0  ...   \n",
       "7042            0.0              1.0             1.0           0.0  ...   \n",
       "\n",
       "      Churn  fiber_optic  dsl  contract_mtm  contract_2yr  contract_1yr  \\\n",
       "0       0.0          0.0  1.0           1.0           0.0           0.0   \n",
       "1       0.0          0.0  1.0           0.0           0.0           1.0   \n",
       "2       1.0          0.0  1.0           1.0           0.0           0.0   \n",
       "3       0.0          0.0  1.0           0.0           0.0           1.0   \n",
       "4       1.0          1.0  0.0           1.0           0.0           0.0   \n",
       "...     ...          ...  ...           ...           ...           ...   \n",
       "7038    0.0          0.0  1.0           0.0           0.0           1.0   \n",
       "7039    0.0          1.0  0.0           0.0           0.0           1.0   \n",
       "7040    0.0          0.0  1.0           1.0           0.0           0.0   \n",
       "7041    1.0          1.0  0.0           1.0           0.0           0.0   \n",
       "7042    0.0          1.0  0.0           0.0           1.0           0.0   \n",
       "\n",
       "      payment_echeck  payment_mcheck  payment_bank  payment_ccard  \n",
       "0                1.0             0.0           0.0            0.0  \n",
       "1                0.0             1.0           0.0            0.0  \n",
       "2                0.0             1.0           0.0            0.0  \n",
       "3                0.0             0.0           1.0            0.0  \n",
       "4                1.0             0.0           0.0            0.0  \n",
       "...              ...             ...           ...            ...  \n",
       "7038             0.0             1.0           0.0            0.0  \n",
       "7039             0.0             0.0           0.0            1.0  \n",
       "7040             1.0             0.0           0.0            0.0  \n",
       "7041             0.0             1.0           0.0            0.0  \n",
       "7042             0.0             0.0           1.0            0.0  \n",
       "\n",
       "[7043 rows x 27 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.73463\n",
       "1.0    0.26537\n",
       "Name: Churn, dtype: float64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean['Churn'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X (7043, 26) <class 'numpy.ndarray'>\n",
      "y (7043,) <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import normalize\n",
    "\n",
    "target = 'Churn'\n",
    "features = df_clean.drop(columns=target).columns\n",
    "\n",
    "# X = normalize(df_clean[features].values)\n",
    "X = df_clean[features].values\n",
    "y = df_clean[target].values\n",
    "\n",
    "print('X', X.shape, type(X))\n",
    "print('y', y.shape, type(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and fit a baseline Keras MLP model to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and compile the model\n",
    "def create_model(additional_layers=0, nodes_per_layer=26, activation_per_layer='relu',\n",
    "                 loss_function='binary_crossentropy', optimizer='adam'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(nodes_per_layer, activation='relu', input_dim=26))\n",
    "    for _ in range(additional_layers):\n",
    "        model.add(Dense(nodes_per_layer, activation=activation_per_layer))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(loss=loss_function, optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5634 samples, validate on 1409 samples\n",
      "Epoch 1/10\n",
      "5634/5634 [==============================] - 1s 138us/sample - loss: 18.1286 - accuracy: 0.6819 - val_loss: 0.8012 - val_accuracy: 0.6359\n",
      "Epoch 2/10\n",
      "5634/5634 [==============================] - 0s 59us/sample - loss: 0.9497 - accuracy: 0.7306 - val_loss: 0.8062 - val_accuracy: 0.7850\n",
      "Epoch 3/10\n",
      "5634/5634 [==============================] - 0s 58us/sample - loss: 0.6444 - accuracy: 0.7606 - val_loss: 0.8328 - val_accuracy: 0.7913\n",
      "Epoch 4/10\n",
      "5634/5634 [==============================] - 0s 58us/sample - loss: 0.6623 - accuracy: 0.7707 - val_loss: 0.4734 - val_accuracy: 0.7942\n",
      "Epoch 5/10\n",
      "5634/5634 [==============================] - 0s 60us/sample - loss: 0.5844 - accuracy: 0.7684 - val_loss: 0.8206 - val_accuracy: 0.7935\n",
      "Epoch 6/10\n",
      "5634/5634 [==============================] - 0s 58us/sample - loss: 0.5686 - accuracy: 0.7682 - val_loss: 0.4444 - val_accuracy: 0.8034\n",
      "Epoch 7/10\n",
      "5634/5634 [==============================] - 0s 59us/sample - loss: 0.5043 - accuracy: 0.7813 - val_loss: 0.6408 - val_accuracy: 0.6714\n",
      "Epoch 8/10\n",
      "5634/5634 [==============================] - 0s 58us/sample - loss: 0.4980 - accuracy: 0.7787 - val_loss: 0.4420 - val_accuracy: 0.7828\n",
      "Epoch 9/10\n",
      "5634/5634 [==============================] - 0s 59us/sample - loss: 0.5484 - accuracy: 0.7749 - val_loss: 1.7481 - val_accuracy: 0.5025\n",
      "Epoch 10/10\n",
      "5634/5634 [==============================] - 0s 59us/sample - loss: 0.6716 - accuracy: 0.7693 - val_loss: 0.7166 - val_accuracy: 0.7991\n"
     ]
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn=create_model)\n",
    "\n",
    "results = model.fit(X, y, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tune (at least) the following parameters:\n",
    " - batch_size\n",
    " - training epochs\n",
    " - optimizer\n",
    " - learning rate (if applicable to optimizer)\n",
    " - momentum (if applicable to optimizer)\n",
    " - activation functions\n",
    " - network weight initialization\n",
    " - dropout regularization\n",
    " - number of neurons in the hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "stop = EarlyStopping(monitor='accuracy', min_delta=0.001, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4507/4507 [==============================] - 1s 158us/sample - loss: 117.1196 - accuracy: 0.5372 - val_loss: 2.8665 - val_accuracy: 0.5714\n",
      "Epoch 2/10\n",
      "4507/4507 [==============================] - 0s 64us/sample - loss: 1.1539 - accuracy: 0.7087 - val_loss: 0.6724 - val_accuracy: 0.7604\n",
      "Epoch 3/10\n",
      "4507/4507 [==============================] - 0s 59us/sample - loss: 0.8914 - accuracy: 0.7322 - val_loss: 0.6357 - val_accuracy: 0.7711\n",
      "Epoch 4/10\n",
      "4507/4507 [==============================] - 0s 58us/sample - loss: 0.9396 - accuracy: 0.7382 - val_loss: 0.4965 - val_accuracy: 0.7844\n",
      "Epoch 5/10\n",
      "4507/4507 [==============================] - 0s 58us/sample - loss: 0.6424 - accuracy: 0.7535 - val_loss: 0.5246 - val_accuracy: 0.7915\n",
      "Epoch 6/10\n",
      "4507/4507 [==============================] - 0s 57us/sample - loss: 0.6585 - accuracy: 0.7575 - val_loss: 0.9997 - val_accuracy: 0.7799\n",
      "Epoch 7/10\n",
      "4507/4507 [==============================] - 0s 57us/sample - loss: 0.5482 - accuracy: 0.7686 - val_loss: 0.4855 - val_accuracy: 0.8039\n",
      "Epoch 8/10\n",
      "4507/4507 [==============================] - 0s 57us/sample - loss: 0.6956 - accuracy: 0.7686 - val_loss: 0.6533 - val_accuracy: 0.7924\n",
      "Epoch 9/10\n",
      "4507/4507 [==============================] - 0s 57us/sample - loss: 0.5405 - accuracy: 0.7737 - val_loss: 0.4443 - val_accuracy: 0.8012\n",
      "Epoch 10/10\n",
      "4507/4507 [==============================] - 0s 57us/sample - loss: 0.9558 - accuracy: 0.7511 - val_loss: 0.8180 - val_accuracy: 0.8004\n",
      "1409/1409 [==============================] - 0s 30us/sample - loss: 0.6972 - accuracy: 0.8027\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4507/4507 [==============================] - 1s 150us/sample - loss: 14.7244 - accuracy: 0.6088 - val_loss: 1.2694 - val_accuracy: 0.4552\n",
      "Epoch 2/10\n",
      "4507/4507 [==============================] - 0s 58us/sample - loss: 0.5614 - accuracy: 0.7584 - val_loss: 0.6062 - val_accuracy: 0.6539\n",
      "Epoch 3/10\n",
      "4507/4507 [==============================] - 0s 58us/sample - loss: 0.6811 - accuracy: 0.7624 - val_loss: 0.4656 - val_accuracy: 0.7791\n",
      "Epoch 4/10\n",
      "4507/4507 [==============================] - 0s 58us/sample - loss: 0.7347 - accuracy: 0.7593 - val_loss: 0.9914 - val_accuracy: 0.5785\n",
      "Epoch 5/10\n",
      "4507/4507 [==============================] - 0s 58us/sample - loss: 0.6629 - accuracy: 0.7752 - val_loss: 0.5245 - val_accuracy: 0.7986\n",
      "Epoch 6/10\n",
      "4507/4507 [==============================] - 0s 58us/sample - loss: 0.7481 - accuracy: 0.7704 - val_loss: 0.5158 - val_accuracy: 0.7516\n",
      "Epoch 7/10\n",
      "4507/4507 [==============================] - 0s 60us/sample - loss: 0.5492 - accuracy: 0.7783 - val_loss: 0.5748 - val_accuracy: 0.7977\n",
      "Epoch 8/10\n",
      "4507/4507 [==============================] - 0s 63us/sample - loss: 0.6774 - accuracy: 0.7697 - val_loss: 0.7130 - val_accuracy: 0.7986\n",
      "Epoch 9/10\n",
      "4507/4507 [==============================] - 0s 62us/sample - loss: 0.5176 - accuracy: 0.7839 - val_loss: 0.6931 - val_accuracy: 0.6539\n",
      "Epoch 10/10\n",
      "4507/4507 [==============================] - 0s 59us/sample - loss: 0.5302 - accuracy: 0.7766 - val_loss: 0.5491 - val_accuracy: 0.7968\n",
      "1409/1409 [==============================] - 0s 30us/sample - loss: 0.5087 - accuracy: 0.7899\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4507/4507 [==============================] - 1s 171us/sample - loss: 38.4015 - accuracy: 0.5465 - val_loss: 1.0039 - val_accuracy: 0.5262\n",
      "Epoch 2/10\n",
      "4507/4507 [==============================] - 0s 59us/sample - loss: 0.6613 - accuracy: 0.7062 - val_loss: 0.4853 - val_accuracy: 0.7897\n",
      "Epoch 3/10\n",
      "4507/4507 [==============================] - 0s 59us/sample - loss: 0.5793 - accuracy: 0.7697 - val_loss: 0.4647 - val_accuracy: 0.7933\n",
      "Epoch 4/10\n",
      "4507/4507 [==============================] - 0s 59us/sample - loss: 0.5791 - accuracy: 0.7726 - val_loss: 0.7595 - val_accuracy: 0.6256\n",
      "Epoch 5/10\n",
      "4507/4507 [==============================] - 0s 58us/sample - loss: 0.5500 - accuracy: 0.7786 - val_loss: 0.5330 - val_accuracy: 0.7977\n",
      "Epoch 6/10\n",
      "4507/4507 [==============================] - 0s 58us/sample - loss: 0.5290 - accuracy: 0.7790 - val_loss: 0.4805 - val_accuracy: 0.7941\n",
      "Epoch 7/10\n",
      "4507/4507 [==============================] - 0s 59us/sample - loss: 0.5155 - accuracy: 0.7803 - val_loss: 1.5087 - val_accuracy: 0.7888\n",
      "Epoch 8/10\n",
      "4507/4507 [==============================] - 0s 59us/sample - loss: 0.7256 - accuracy: 0.7659 - val_loss: 0.5348 - val_accuracy: 0.7977\n",
      "Epoch 9/10\n",
      "4507/4507 [==============================] - 0s 59us/sample - loss: 0.5791 - accuracy: 0.7803 - val_loss: 0.4921 - val_accuracy: 0.8039\n",
      "Epoch 10/10\n",
      "4507/4507 [==============================] - 0s 60us/sample - loss: 0.6609 - accuracy: 0.7732 - val_loss: 0.6611 - val_accuracy: 0.6681\n",
      "1409/1409 [==============================] - 0s 29us/sample - loss: 0.6802 - accuracy: 0.6650\n",
      "Train on 4508 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4508/4508 [==============================] - 1s 177us/sample - loss: 2.3202 - accuracy: 0.5756 - val_loss: 0.9292 - val_accuracy: 0.6584\n",
      "Epoch 2/10\n",
      "4508/4508 [==============================] - 0s 59us/sample - loss: 0.6755 - accuracy: 0.7318 - val_loss: 0.6379 - val_accuracy: 0.7755\n",
      "Epoch 3/10\n",
      "4508/4508 [==============================] - 0s 58us/sample - loss: 0.6426 - accuracy: 0.7571 - val_loss: 0.4806 - val_accuracy: 0.7817\n",
      "Epoch 4/10\n",
      "4508/4508 [==============================] - 0s 58us/sample - loss: 0.5716 - accuracy: 0.7655 - val_loss: 0.5785 - val_accuracy: 0.7941\n",
      "Epoch 5/10\n",
      "4508/4508 [==============================] - 0s 58us/sample - loss: 0.5609 - accuracy: 0.7720 - val_loss: 0.5865 - val_accuracy: 0.7941\n",
      "Epoch 6/10\n",
      "4508/4508 [==============================] - 0s 57us/sample - loss: 0.4999 - accuracy: 0.7788 - val_loss: 0.4416 - val_accuracy: 0.7817\n",
      "Epoch 7/10\n",
      "4508/4508 [==============================] - 0s 58us/sample - loss: 0.6155 - accuracy: 0.7644 - val_loss: 0.4338 - val_accuracy: 0.7986\n",
      "Epoch 8/10\n",
      "4508/4508 [==============================] - 0s 58us/sample - loss: 0.5200 - accuracy: 0.7700 - val_loss: 0.7175 - val_accuracy: 0.7933\n",
      "Epoch 9/10\n",
      "4508/4508 [==============================] - 0s 58us/sample - loss: 0.5124 - accuracy: 0.7777 - val_loss: 0.5903 - val_accuracy: 0.7986\n",
      "Epoch 10/10\n",
      "4508/4508 [==============================] - 0s 60us/sample - loss: 0.5147 - accuracy: 0.7728 - val_loss: 0.5006 - val_accuracy: 0.8021\n",
      "1408/1408 [==============================] - 0s 94us/sample - loss: 0.4907 - accuracy: 0.7983\n",
      "Train on 4508 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4508/4508 [==============================] - 1s 174us/sample - loss: 2.2259 - accuracy: 0.6670 - val_loss: 1.0392 - val_accuracy: 0.4596\n",
      "Epoch 2/10\n",
      "4508/4508 [==============================] - 0s 59us/sample - loss: 0.6259 - accuracy: 0.7449 - val_loss: 0.5068 - val_accuracy: 0.7791\n",
      "Epoch 3/10\n",
      "4508/4508 [==============================] - 0s 59us/sample - loss: 0.6345 - accuracy: 0.7584 - val_loss: 0.5921 - val_accuracy: 0.7791\n",
      "Epoch 4/10\n",
      "4508/4508 [==============================] - 0s 57us/sample - loss: 0.5502 - accuracy: 0.7653 - val_loss: 0.4521 - val_accuracy: 0.7968\n",
      "Epoch 5/10\n",
      "4508/4508 [==============================] - 0s 60us/sample - loss: 0.6489 - accuracy: 0.7649 - val_loss: 0.4608 - val_accuracy: 0.7986\n",
      "Epoch 6/10\n",
      "4508/4508 [==============================] - 0s 60us/sample - loss: 0.5135 - accuracy: 0.7819 - val_loss: 0.4523 - val_accuracy: 0.8021\n",
      "Epoch 7/10\n",
      "4508/4508 [==============================] - 0s 58us/sample - loss: 0.5685 - accuracy: 0.7693 - val_loss: 1.1906 - val_accuracy: 0.5794\n",
      "Epoch 8/10\n",
      "4508/4508 [==============================] - 0s 60us/sample - loss: 0.6138 - accuracy: 0.7671 - val_loss: 0.4933 - val_accuracy: 0.7516\n",
      "Epoch 9/10\n",
      "4508/4508 [==============================] - 0s 61us/sample - loss: 0.5864 - accuracy: 0.7740 - val_loss: 0.6204 - val_accuracy: 0.7764\n",
      "Epoch 10/10\n",
      "4508/4508 [==============================] - 0s 63us/sample - loss: 0.6770 - accuracy: 0.7624 - val_loss: 0.7532 - val_accuracy: 0.6504\n",
      "1408/1408 [==============================] - 0s 93us/sample - loss: 0.6981 - accuracy: 0.6577\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4507/4507 [==============================] - 1s 315us/sample - loss: 3.4214 - accuracy: 0.6807 - val_loss: 1.6562 - val_accuracy: 0.7782\n",
      "Epoch 2/10\n",
      "4507/4507 [==============================] - 0s 64us/sample - loss: 0.7324 - accuracy: 0.7393 - val_loss: 0.4594 - val_accuracy: 0.7924\n",
      "Epoch 3/10\n",
      "4507/4507 [==============================] - 0s 60us/sample - loss: 0.6714 - accuracy: 0.7535 - val_loss: 0.8098 - val_accuracy: 0.7941\n",
      "Epoch 4/10\n",
      "4507/4507 [==============================] - 0s 58us/sample - loss: 0.6828 - accuracy: 0.7602 - val_loss: 0.4343 - val_accuracy: 0.7995\n",
      "Epoch 5/10\n",
      "4507/4507 [==============================] - 0s 59us/sample - loss: 0.6526 - accuracy: 0.7675 - val_loss: 1.4115 - val_accuracy: 0.7950\n",
      "Epoch 6/10\n",
      "4507/4507 [==============================] - 0s 63us/sample - loss: 0.8337 - accuracy: 0.7577 - val_loss: 0.5661 - val_accuracy: 0.8039\n",
      "Epoch 7/10\n",
      "4507/4507 [==============================] - 0s 58us/sample - loss: 0.7118 - accuracy: 0.7579 - val_loss: 0.7098 - val_accuracy: 0.7950\n",
      "Epoch 8/10\n",
      "4507/4507 [==============================] - 0s 57us/sample - loss: 0.9599 - accuracy: 0.7617 - val_loss: 1.5733 - val_accuracy: 0.7888\n",
      "Epoch 9/10\n",
      "4507/4507 [==============================] - 0s 58us/sample - loss: 0.6955 - accuracy: 0.7726 - val_loss: 0.4593 - val_accuracy: 0.7933\n",
      "Epoch 10/10\n",
      "4507/4507 [==============================] - 0s 62us/sample - loss: 0.7593 - accuracy: 0.7639 - val_loss: 0.6198 - val_accuracy: 0.7986\n",
      "1409/1409 [==============================] - 0s 31us/sample - loss: 0.5375 - accuracy: 0.8070\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4507/4507 [==============================] - 1s 168us/sample - loss: 1.8472 - accuracy: 0.6814 - val_loss: 0.4702 - val_accuracy: 0.7844\n",
      "Epoch 2/10\n",
      "4507/4507 [==============================] - 0s 61us/sample - loss: 1.0824 - accuracy: 0.7428 - val_loss: 1.9006 - val_accuracy: 0.4827\n",
      "Epoch 3/10\n",
      "4507/4507 [==============================] - 0s 60us/sample - loss: 0.8618 - accuracy: 0.7468 - val_loss: 1.2767 - val_accuracy: 0.7862\n",
      "Epoch 4/10\n",
      "4507/4507 [==============================] - 0s 62us/sample - loss: 1.4683 - accuracy: 0.7389 - val_loss: 0.8832 - val_accuracy: 0.6300\n",
      "Epoch 5/10\n",
      "4507/4507 [==============================] - 0s 61us/sample - loss: 0.9019 - accuracy: 0.7641 - val_loss: 0.9396 - val_accuracy: 0.6256\n",
      "Epoch 6/10\n",
      "4507/4507 [==============================] - 0s 59us/sample - loss: 0.7206 - accuracy: 0.7644 - val_loss: 0.5333 - val_accuracy: 0.7303\n",
      "Epoch 7/10\n",
      "4507/4507 [==============================] - 0s 60us/sample - loss: 0.9092 - accuracy: 0.7613 - val_loss: 1.4143 - val_accuracy: 0.5528\n",
      "Epoch 8/10\n",
      "4507/4507 [==============================] - 0s 59us/sample - loss: 0.9738 - accuracy: 0.7621 - val_loss: 0.8938 - val_accuracy: 0.6247\n",
      "Epoch 9/10\n",
      "4507/4507 [==============================] - 0s 59us/sample - loss: 1.0044 - accuracy: 0.7621 - val_loss: 0.5769 - val_accuracy: 0.8012\n",
      "Epoch 10/10\n",
      "4507/4507 [==============================] - 0s 59us/sample - loss: 0.7898 - accuracy: 0.7739 - val_loss: 3.4394 - val_accuracy: 0.7844\n",
      "1409/1409 [==============================] - 0s 30us/sample - loss: 3.1782 - accuracy: 0.7750\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4507/4507 [==============================] - 1s 178us/sample - loss: 2.9595 - accuracy: 0.6639 - val_loss: 2.6062 - val_accuracy: 0.7853\n",
      "Epoch 2/10\n",
      "4507/4507 [==============================] - 0s 61us/sample - loss: 1.0376 - accuracy: 0.7331 - val_loss: 0.6520 - val_accuracy: 0.6575\n",
      "Epoch 3/10\n",
      "4507/4507 [==============================] - 0s 58us/sample - loss: 0.7691 - accuracy: 0.7579 - val_loss: 0.6388 - val_accuracy: 0.7995\n",
      "Epoch 4/10\n",
      "4507/4507 [==============================] - 0s 58us/sample - loss: 0.9222 - accuracy: 0.7506 - val_loss: 1.0057 - val_accuracy: 0.7906\n",
      "Epoch 5/10\n",
      "4507/4507 [==============================] - 0s 60us/sample - loss: 0.9374 - accuracy: 0.7602 - val_loss: 0.5213 - val_accuracy: 0.7853\n",
      "Epoch 6/10\n",
      "4507/4507 [==============================] - 0s 60us/sample - loss: 0.9660 - accuracy: 0.7555 - val_loss: 0.7491 - val_accuracy: 0.7968\n",
      "Epoch 7/10\n",
      "4507/4507 [==============================] - 0s 59us/sample - loss: 0.8150 - accuracy: 0.7650 - val_loss: 0.4797 - val_accuracy: 0.7862\n",
      "Epoch 8/10\n",
      "4507/4507 [==============================] - 0s 58us/sample - loss: 0.9169 - accuracy: 0.7617 - val_loss: 0.6722 - val_accuracy: 0.6912\n",
      "Epoch 9/10\n",
      "4507/4507 [==============================] - 0s 58us/sample - loss: 0.8872 - accuracy: 0.7595 - val_loss: 0.5014 - val_accuracy: 0.7782\n",
      "Epoch 10/10\n",
      "4507/4507 [==============================] - 0s 60us/sample - loss: 0.7630 - accuracy: 0.7639 - val_loss: 1.2202 - val_accuracy: 0.8012\n",
      "1409/1409 [==============================] - 0s 30us/sample - loss: 1.0360 - accuracy: 0.7842\n",
      "Train on 4508 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4508/4508 [==============================] - 1s 171us/sample - loss: 35.5185 - accuracy: 0.6453 - val_loss: 0.5702 - val_accuracy: 0.7205\n",
      "Epoch 2/10\n",
      "4508/4508 [==============================] - 0s 61us/sample - loss: 0.7283 - accuracy: 0.7540 - val_loss: 0.5332 - val_accuracy: 0.7072\n",
      "Epoch 3/10\n",
      "4508/4508 [==============================] - 0s 63us/sample - loss: 0.7211 - accuracy: 0.7567 - val_loss: 1.5271 - val_accuracy: 0.5280\n",
      "Epoch 4/10\n",
      "4508/4508 [==============================] - 0s 58us/sample - loss: 0.8506 - accuracy: 0.7516 - val_loss: 0.7521 - val_accuracy: 0.7995\n",
      "Epoch 5/10\n",
      "4508/4508 [==============================] - 0s 62us/sample - loss: 0.9245 - accuracy: 0.7569 - val_loss: 0.6696 - val_accuracy: 0.7844\n",
      "Epoch 6/10\n",
      "4508/4508 [==============================] - 0s 60us/sample - loss: 0.5823 - accuracy: 0.7713 - val_loss: 0.4895 - val_accuracy: 0.7986\n",
      "Epoch 7/10\n",
      "4508/4508 [==============================] - 0s 62us/sample - loss: 0.9377 - accuracy: 0.7560 - val_loss: 0.5896 - val_accuracy: 0.8021\n",
      "Epoch 8/10\n",
      "4508/4508 [==============================] - 0s 59us/sample - loss: 0.5479 - accuracy: 0.7819 - val_loss: 0.4654 - val_accuracy: 0.7782\n",
      "Epoch 9/10\n",
      "4508/4508 [==============================] - 0s 58us/sample - loss: 0.7920 - accuracy: 0.7664 - val_loss: 0.9747 - val_accuracy: 0.8021\n",
      "Epoch 10/10\n",
      "4508/4508 [==============================] - 0s 58us/sample - loss: 0.8066 - accuracy: 0.7680 - val_loss: 1.3952 - val_accuracy: 0.7959\n",
      "1408/1408 [==============================] - 0s 90us/sample - loss: 1.2276 - accuracy: 0.7926\n",
      "Train on 4508 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4508/4508 [==============================] - 1s 158us/sample - loss: 26.4998 - accuracy: 0.6138 - val_loss: 0.5566 - val_accuracy: 0.7578\n",
      "Epoch 2/10\n",
      "4508/4508 [==============================] - 0s 59us/sample - loss: 0.7100 - accuracy: 0.7427 - val_loss: 2.1665 - val_accuracy: 0.7604\n",
      "Epoch 3/10\n",
      "4508/4508 [==============================] - 0s 58us/sample - loss: 0.9997 - accuracy: 0.7440 - val_loss: 0.8086 - val_accuracy: 0.7702\n",
      "Epoch 4/10\n",
      "4508/4508 [==============================] - 0s 58us/sample - loss: 0.8188 - accuracy: 0.7502 - val_loss: 0.5664 - val_accuracy: 0.7799\n",
      "Epoch 5/10\n",
      "4508/4508 [==============================] - 0s 58us/sample - loss: 0.9272 - accuracy: 0.7511 - val_loss: 1.1592 - val_accuracy: 0.7915\n",
      "Epoch 6/10\n",
      "4508/4508 [==============================] - 0s 58us/sample - loss: 1.1523 - accuracy: 0.7549 - val_loss: 1.0604 - val_accuracy: 0.7897\n",
      "Epoch 7/10\n",
      "4508/4508 [==============================] - 0s 58us/sample - loss: 1.2342 - accuracy: 0.7429 - val_loss: 0.8001 - val_accuracy: 0.7968\n",
      "Epoch 8/10\n",
      "4508/4508 [==============================] - 0s 58us/sample - loss: 0.7966 - accuracy: 0.7642 - val_loss: 2.1905 - val_accuracy: 0.7657\n",
      "Epoch 9/10\n",
      "4508/4508 [==============================] - 0s 58us/sample - loss: 0.9874 - accuracy: 0.7527 - val_loss: 0.5558 - val_accuracy: 0.7870\n",
      "Epoch 10/10\n",
      "4508/4508 [==============================] - 0s 58us/sample - loss: 0.6439 - accuracy: 0.7724 - val_loss: 0.4973 - val_accuracy: 0.8048\n",
      "1408/1408 [==============================] - 0s 86us/sample - loss: 0.4945 - accuracy: 0.7976\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4507/4507 [==============================] - 1s 155us/sample - loss: 25.2326 - accuracy: 0.6652 - val_loss: 0.4814 - val_accuracy: 0.7649\n",
      "Epoch 2/10\n",
      "4507/4507 [==============================] - 0s 59us/sample - loss: 0.6889 - accuracy: 0.7482 - val_loss: 1.5831 - val_accuracy: 0.7879\n",
      "Epoch 3/10\n",
      "4507/4507 [==============================] - 0s 59us/sample - loss: 1.0161 - accuracy: 0.7413 - val_loss: 0.8912 - val_accuracy: 0.7906\n",
      "Epoch 4/10\n",
      "4507/4507 [==============================] - 0s 59us/sample - loss: 0.7609 - accuracy: 0.7528 - val_loss: 1.5217 - val_accuracy: 0.7915\n",
      "Epoch 5/10\n",
      "4507/4507 [==============================] - 0s 59us/sample - loss: 1.1351 - accuracy: 0.7422 - val_loss: 0.7219 - val_accuracy: 0.7995\n",
      "Epoch 6/10\n",
      "4507/4507 [==============================] - 0s 59us/sample - loss: 1.2399 - accuracy: 0.7462 - val_loss: 1.5661 - val_accuracy: 0.5537\n",
      "Epoch 7/10\n",
      "4507/4507 [==============================] - 0s 59us/sample - loss: 1.1236 - accuracy: 0.7502 - val_loss: 0.8688 - val_accuracy: 0.6406\n",
      "Epoch 8/10\n",
      "4507/4507 [==============================] - 0s 58us/sample - loss: 0.9122 - accuracy: 0.7555 - val_loss: 0.7785 - val_accuracy: 0.6548\n",
      "Epoch 9/10\n",
      "4507/4507 [==============================] - 0s 58us/sample - loss: 0.8645 - accuracy: 0.7617 - val_loss: 0.5315 - val_accuracy: 0.7906\n",
      "Epoch 10/10\n",
      "4507/4507 [==============================] - 0s 59us/sample - loss: 0.9593 - accuracy: 0.7590 - val_loss: 3.7703 - val_accuracy: 0.7817\n",
      "1409/1409 [==============================] - 0s 30us/sample - loss: 3.1572 - accuracy: 0.7764\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4507/4507 [==============================] - 1s 155us/sample - loss: 7.1898 - accuracy: 0.7131 - val_loss: 0.7436 - val_accuracy: 0.8004\n",
      "Epoch 2/10\n",
      "4507/4507 [==============================] - 0s 60us/sample - loss: 0.8782 - accuracy: 0.7477 - val_loss: 0.8312 - val_accuracy: 0.6353\n",
      "Epoch 3/10\n",
      "4507/4507 [==============================] - 0s 59us/sample - loss: 0.8098 - accuracy: 0.7559 - val_loss: 1.0353 - val_accuracy: 0.6096\n",
      "Epoch 4/10\n",
      "4507/4507 [==============================] - 0s 59us/sample - loss: 1.1784 - accuracy: 0.7422 - val_loss: 0.5384 - val_accuracy: 0.7498\n",
      "Epoch 5/10\n",
      "4507/4507 [==============================] - 0s 59us/sample - loss: 1.0478 - accuracy: 0.7511 - val_loss: 0.7096 - val_accuracy: 0.7995\n",
      "Epoch 6/10\n",
      "4507/4507 [==============================] - 0s 59us/sample - loss: 0.8856 - accuracy: 0.7637 - val_loss: 0.5218 - val_accuracy: 0.7977\n",
      "Epoch 7/10\n",
      "4507/4507 [==============================] - 0s 59us/sample - loss: 1.0774 - accuracy: 0.7526 - val_loss: 0.8495 - val_accuracy: 0.7826\n",
      "Epoch 8/10\n",
      "4507/4507 [==============================] - 0s 59us/sample - loss: 0.9199 - accuracy: 0.7575 - val_loss: 0.5445 - val_accuracy: 0.7986\n",
      "Epoch 9/10\n",
      "4507/4507 [==============================] - 0s 59us/sample - loss: 0.7050 - accuracy: 0.7570 - val_loss: 1.1830 - val_accuracy: 0.7968\n",
      "Epoch 10/10\n",
      "4507/4507 [==============================] - 0s 59us/sample - loss: 0.8641 - accuracy: 0.7633 - val_loss: 2.5176 - val_accuracy: 0.7711\n",
      "1409/1409 [==============================] - 0s 29us/sample - loss: 2.3006 - accuracy: 0.7736\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4507/4507 [==============================] - 1s 155us/sample - loss: 18.7720 - accuracy: 0.5684 - val_loss: 1.8926 - val_accuracy: 0.6247\n",
      "Epoch 2/10\n",
      "4507/4507 [==============================] - 0s 59us/sample - loss: 1.1018 - accuracy: 0.6858 - val_loss: 0.6129 - val_accuracy: 0.7870\n",
      "Epoch 3/10\n",
      "4507/4507 [==============================] - 0s 59us/sample - loss: 1.0331 - accuracy: 0.7524 - val_loss: 0.5505 - val_accuracy: 0.7915\n",
      "Epoch 4/10\n",
      "4507/4507 [==============================] - 0s 59us/sample - loss: 0.9588 - accuracy: 0.7477 - val_loss: 1.0101 - val_accuracy: 0.7995\n",
      "Epoch 5/10\n",
      "4507/4507 [==============================] - 0s 58us/sample - loss: 0.8778 - accuracy: 0.7590 - val_loss: 1.0756 - val_accuracy: 0.5892\n",
      "Epoch 6/10\n",
      "4507/4507 [==============================] - 0s 60us/sample - loss: 1.0242 - accuracy: 0.7482 - val_loss: 0.6017 - val_accuracy: 0.7826\n",
      "Epoch 7/10\n",
      "4507/4507 [==============================] - 0s 61us/sample - loss: 0.8983 - accuracy: 0.7626 - val_loss: 0.5949 - val_accuracy: 0.7737\n",
      "Epoch 8/10\n",
      "4507/4507 [==============================] - 0s 60us/sample - loss: 0.7795 - accuracy: 0.7684 - val_loss: 2.1809 - val_accuracy: 0.7888\n",
      "Epoch 9/10\n",
      "4507/4507 [==============================] - 0s 62us/sample - loss: 0.8411 - accuracy: 0.7590 - val_loss: 0.4921 - val_accuracy: 0.7924\n",
      "Epoch 10/10\n",
      "4507/4507 [==============================] - 0s 62us/sample - loss: 0.6467 - accuracy: 0.7721 - val_loss: 0.6145 - val_accuracy: 0.8057\n",
      "1409/1409 [==============================] - 0s 30us/sample - loss: 0.5541 - accuracy: 0.7892\n",
      "Train on 4508 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4508/4508 [==============================] - 1s 159us/sample - loss: 22.5245 - accuracy: 0.6693 - val_loss: 0.4867 - val_accuracy: 0.7791\n",
      "Epoch 2/10\n",
      "4508/4508 [==============================] - 0s 61us/sample - loss: 0.6550 - accuracy: 0.7644 - val_loss: 0.4827 - val_accuracy: 0.7888\n",
      "Epoch 3/10\n",
      "4508/4508 [==============================] - 0s 59us/sample - loss: 0.8002 - accuracy: 0.7584 - val_loss: 0.9586 - val_accuracy: 0.6034\n",
      "Epoch 4/10\n",
      "4508/4508 [==============================] - 0s 59us/sample - loss: 0.7517 - accuracy: 0.7555 - val_loss: 1.4019 - val_accuracy: 0.7755\n",
      "Epoch 5/10\n",
      "4508/4508 [==============================] - 0s 59us/sample - loss: 0.6365 - accuracy: 0.7746 - val_loss: 0.7487 - val_accuracy: 0.7968\n",
      "Epoch 6/10\n",
      "4508/4508 [==============================] - 0s 59us/sample - loss: 0.6650 - accuracy: 0.7651 - val_loss: 0.6437 - val_accuracy: 0.8021\n",
      "Epoch 7/10\n",
      "4508/4508 [==============================] - 0s 62us/sample - loss: 0.9181 - accuracy: 0.7631 - val_loss: 0.4621 - val_accuracy: 0.7915\n",
      "Epoch 8/10\n",
      "4508/4508 [==============================] - 0s 60us/sample - loss: 0.6653 - accuracy: 0.7748 - val_loss: 0.9888 - val_accuracy: 0.7995\n",
      "Epoch 9/10\n",
      "4508/4508 [==============================] - 0s 59us/sample - loss: 0.7756 - accuracy: 0.7538 - val_loss: 0.6158 - val_accuracy: 0.8030\n",
      "Epoch 10/10\n",
      "4508/4508 [==============================] - 0s 59us/sample - loss: 0.7989 - accuracy: 0.7633 - val_loss: 0.5709 - val_accuracy: 0.7169\n",
      "1408/1408 [==============================] - 0s 85us/sample - loss: 0.6140 - accuracy: 0.7081\n",
      "Train on 4508 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4508/4508 [==============================] - 1s 152us/sample - loss: 64.6822 - accuracy: 0.6462 - val_loss: 0.6755 - val_accuracy: 0.7187\n",
      "Epoch 2/10\n",
      "4508/4508 [==============================] - 0s 60us/sample - loss: 1.0453 - accuracy: 0.7460 - val_loss: 1.2464 - val_accuracy: 0.6362\n",
      "Epoch 3/10\n",
      "4508/4508 [==============================] - 0s 59us/sample - loss: 1.1159 - accuracy: 0.7549 - val_loss: 1.5934 - val_accuracy: 0.5998\n",
      "Epoch 4/10\n",
      "4508/4508 [==============================] - 0s 59us/sample - loss: 0.6777 - accuracy: 0.7684 - val_loss: 0.5446 - val_accuracy: 0.7613\n",
      "Epoch 5/10\n",
      "4508/4508 [==============================] - 0s 59us/sample - loss: 0.9302 - accuracy: 0.7600 - val_loss: 1.4526 - val_accuracy: 0.6016\n",
      "Epoch 6/10\n",
      "4508/4508 [==============================] - 0s 59us/sample - loss: 0.6893 - accuracy: 0.7700 - val_loss: 1.8088 - val_accuracy: 0.7649\n",
      "Epoch 7/10\n",
      "4508/4508 [==============================] - 0s 59us/sample - loss: 1.1528 - accuracy: 0.7522 - val_loss: 0.6002 - val_accuracy: 0.7791\n",
      "Epoch 8/10\n",
      "4508/4508 [==============================] - 0s 59us/sample - loss: 0.8884 - accuracy: 0.7635 - val_loss: 0.5583 - val_accuracy: 0.7808\n",
      "Epoch 9/10\n",
      "4508/4508 [==============================] - 0s 59us/sample - loss: 0.9910 - accuracy: 0.7567 - val_loss: 1.0215 - val_accuracy: 0.6362\n",
      "Epoch 10/10\n",
      "4508/4508 [==============================] - 0s 60us/sample - loss: 1.2776 - accuracy: 0.7555 - val_loss: 0.5386 - val_accuracy: 0.7657\n",
      "1408/1408 [==============================] - 0s 89us/sample - loss: 0.5003 - accuracy: 0.7706\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4507/4507 [==============================] - 1s 176us/sample - loss: 2.1340 - accuracy: 0.6075 - val_loss: 1.4273 - val_accuracy: 0.7879\n",
      "Epoch 2/10\n",
      "4507/4507 [==============================] - 0s 60us/sample - loss: 0.9639 - accuracy: 0.7364 - val_loss: 1.3821 - val_accuracy: 0.7915\n",
      "Epoch 3/10\n",
      "4507/4507 [==============================] - 0s 65us/sample - loss: 1.0264 - accuracy: 0.7546 - val_loss: 0.5565 - val_accuracy: 0.7045\n",
      "Epoch 4/10\n",
      "4507/4507 [==============================] - 0s 61us/sample - loss: 0.6625 - accuracy: 0.7646 - val_loss: 0.5562 - val_accuracy: 0.7986\n",
      "Epoch 5/10\n",
      "4507/4507 [==============================] - 0s 59us/sample - loss: 1.5017 - accuracy: 0.7428 - val_loss: 0.9422 - val_accuracy: 0.7915\n",
      "Epoch 6/10\n",
      "4507/4507 [==============================] - 0s 60us/sample - loss: 0.9486 - accuracy: 0.7544 - val_loss: 0.5296 - val_accuracy: 0.7950\n",
      "Epoch 7/10\n",
      "4507/4507 [==============================] - 0s 59us/sample - loss: 0.8938 - accuracy: 0.7564 - val_loss: 0.4971 - val_accuracy: 0.7968\n",
      "Epoch 8/10\n",
      "4507/4507 [==============================] - 0s 63us/sample - loss: 0.9299 - accuracy: 0.7584 - val_loss: 3.8436 - val_accuracy: 0.7773\n",
      "Epoch 9/10\n",
      "4507/4507 [==============================] - 0s 64us/sample - loss: 0.9632 - accuracy: 0.7555 - val_loss: 0.4540 - val_accuracy: 0.7915\n",
      "Epoch 10/10\n",
      "4507/4507 [==============================] - 0s 62us/sample - loss: 0.6448 - accuracy: 0.7741 - val_loss: 0.5519 - val_accuracy: 0.8110\n",
      "1409/1409 [==============================] - 0s 31us/sample - loss: 0.4834 - accuracy: 0.8041\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4507/4507 [==============================] - 1s 175us/sample - loss: 8.2178 - accuracy: 0.7069 - val_loss: 1.0177 - val_accuracy: 0.5909\n",
      "Epoch 2/10\n",
      "4507/4507 [==============================] - 0s 62us/sample - loss: 0.9438 - accuracy: 0.7508 - val_loss: 0.4574 - val_accuracy: 0.7959\n",
      "Epoch 3/10\n",
      "4507/4507 [==============================] - 0s 63us/sample - loss: 0.7706 - accuracy: 0.7577 - val_loss: 0.5075 - val_accuracy: 0.7888\n",
      "Epoch 4/10\n",
      "4507/4507 [==============================] - 0s 63us/sample - loss: 0.8240 - accuracy: 0.7624 - val_loss: 0.6974 - val_accuracy: 0.6655\n",
      "Epoch 5/10\n",
      "4507/4507 [==============================] - 0s 62us/sample - loss: 1.1110 - accuracy: 0.7468 - val_loss: 1.2264 - val_accuracy: 0.8004\n",
      "Epoch 6/10\n",
      "4507/4507 [==============================] - 0s 64us/sample - loss: 0.9104 - accuracy: 0.7597 - val_loss: 0.6208 - val_accuracy: 0.7924\n",
      "Epoch 7/10\n",
      "4507/4507 [==============================] - 0s 62us/sample - loss: 1.0451 - accuracy: 0.7584 - val_loss: 0.5292 - val_accuracy: 0.7915\n",
      "Epoch 8/10\n",
      "4507/4507 [==============================] - 0s 62us/sample - loss: 0.8975 - accuracy: 0.7655 - val_loss: 0.5151 - val_accuracy: 0.7977\n",
      "Epoch 9/10\n",
      "4507/4507 [==============================] - 0s 63us/sample - loss: 0.8295 - accuracy: 0.7566 - val_loss: 0.9558 - val_accuracy: 0.7986\n",
      "Epoch 10/10\n",
      "4507/4507 [==============================] - 0s 60us/sample - loss: 1.0060 - accuracy: 0.7626 - val_loss: 0.5750 - val_accuracy: 0.8039\n",
      "1409/1409 [==============================] - 0s 31us/sample - loss: 0.5181 - accuracy: 0.8062\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4507/4507 [==============================] - 1s 176us/sample - loss: 23.9949 - accuracy: 0.6685 - val_loss: 0.6624 - val_accuracy: 0.7924\n",
      "Epoch 2/10\n",
      "4507/4507 [==============================] - 0s 64us/sample - loss: 0.6836 - accuracy: 0.7653 - val_loss: 2.1429 - val_accuracy: 0.7755\n",
      "Epoch 3/10\n",
      "4507/4507 [==============================] - 0s 65us/sample - loss: 0.8130 - accuracy: 0.7513 - val_loss: 0.5449 - val_accuracy: 0.7959\n",
      "Epoch 4/10\n",
      "4507/4507 [==============================] - 0s 63us/sample - loss: 1.5924 - accuracy: 0.7357 - val_loss: 0.5546 - val_accuracy: 0.7995\n",
      "Epoch 5/10\n",
      "4507/4507 [==============================] - 0s 62us/sample - loss: 1.5668 - accuracy: 0.7550 - val_loss: 0.5521 - val_accuracy: 0.7782\n",
      "Epoch 6/10\n",
      "4507/4507 [==============================] - 0s 62us/sample - loss: 1.0603 - accuracy: 0.7526 - val_loss: 0.5517 - val_accuracy: 0.7657\n",
      "Epoch 7/10\n",
      "4507/4507 [==============================] - 0s 62us/sample - loss: 0.9684 - accuracy: 0.7604 - val_loss: 2.3213 - val_accuracy: 0.7791\n",
      "Epoch 8/10\n",
      "4507/4507 [==============================] - 0s 65us/sample - loss: 0.8803 - accuracy: 0.7619 - val_loss: 0.4876 - val_accuracy: 0.7924\n",
      "Epoch 9/10\n",
      "4507/4507 [==============================] - 0s 63us/sample - loss: 0.8492 - accuracy: 0.7670 - val_loss: 1.3604 - val_accuracy: 0.5821\n",
      "Epoch 10/10\n",
      "4507/4507 [==============================] - 0s 64us/sample - loss: 0.6828 - accuracy: 0.7752 - val_loss: 1.9141 - val_accuracy: 0.5288\n",
      "1409/1409 [==============================] - 0s 31us/sample - loss: 1.8627 - accuracy: 0.5344\n",
      "Train on 4508 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4508/4508 [==============================] - 1s 167us/sample - loss: 1.3465 - accuracy: 0.7189 - val_loss: 0.9099 - val_accuracy: 0.7906\n",
      "Epoch 2/10\n",
      "4508/4508 [==============================] - 0s 63us/sample - loss: 1.2574 - accuracy: 0.7394 - val_loss: 6.4682 - val_accuracy: 0.7684\n",
      "Epoch 3/10\n",
      "4508/4508 [==============================] - 0s 61us/sample - loss: 1.4790 - accuracy: 0.7389 - val_loss: 0.7086 - val_accuracy: 0.7844\n",
      "Epoch 4/10\n",
      "4508/4508 [==============================] - 0s 63us/sample - loss: 0.9699 - accuracy: 0.7524 - val_loss: 1.0975 - val_accuracy: 0.7862\n",
      "Epoch 5/10\n",
      "4508/4508 [==============================] - 0s 59us/sample - loss: 1.0256 - accuracy: 0.7609 - val_loss: 0.6641 - val_accuracy: 0.7968\n",
      "Epoch 6/10\n",
      "4508/4508 [==============================] - 0s 59us/sample - loss: 1.0210 - accuracy: 0.7551 - val_loss: 1.1637 - val_accuracy: 0.7995\n",
      "Epoch 7/10\n",
      "4508/4508 [==============================] - 0s 64us/sample - loss: 0.7844 - accuracy: 0.7626 - val_loss: 0.8810 - val_accuracy: 0.6460\n",
      "Epoch 8/10\n",
      "4508/4508 [==============================] - 0s 61us/sample - loss: 0.7628 - accuracy: 0.7675 - val_loss: 0.8874 - val_accuracy: 0.8030\n",
      "Epoch 9/10\n",
      "4508/4508 [==============================] - 0s 59us/sample - loss: 0.7815 - accuracy: 0.7735 - val_loss: 0.8756 - val_accuracy: 0.8004\n",
      "Epoch 10/10\n",
      "4508/4508 [==============================] - 0s 61us/sample - loss: 0.6727 - accuracy: 0.7786 - val_loss: 1.2122 - val_accuracy: 0.7817\n",
      "1408/1408 [==============================] - 0s 94us/sample - loss: 1.0990 - accuracy: 0.7685\n",
      "Train on 4508 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4508/4508 [==============================] - 1s 175us/sample - loss: 94.8003 - accuracy: 0.6111 - val_loss: 0.5681 - val_accuracy: 0.7365\n",
      "Epoch 2/10\n",
      "4508/4508 [==============================] - 0s 60us/sample - loss: 0.7194 - accuracy: 0.7622 - val_loss: 0.7449 - val_accuracy: 0.6477\n",
      "Epoch 3/10\n",
      "4508/4508 [==============================] - 0s 65us/sample - loss: 0.5845 - accuracy: 0.7711 - val_loss: 0.5116 - val_accuracy: 0.7400\n",
      "Epoch 4/10\n",
      "4508/4508 [==============================] - 0s 64us/sample - loss: 1.1526 - accuracy: 0.7460 - val_loss: 0.7612 - val_accuracy: 0.7870\n",
      "Epoch 5/10\n",
      "4508/4508 [==============================] - 0s 60us/sample - loss: 0.6938 - accuracy: 0.7724 - val_loss: 1.7549 - val_accuracy: 0.7649\n",
      "Epoch 6/10\n",
      "4508/4508 [==============================] - 0s 64us/sample - loss: 0.9428 - accuracy: 0.7591 - val_loss: 2.8164 - val_accuracy: 0.4925\n",
      "Epoch 7/10\n",
      "4508/4508 [==============================] - 0s 60us/sample - loss: 0.7470 - accuracy: 0.7631 - val_loss: 0.4695 - val_accuracy: 0.8092\n",
      "Epoch 8/10\n",
      "4508/4508 [==============================] - 0s 64us/sample - loss: 0.8304 - accuracy: 0.7649 - val_loss: 0.6856 - val_accuracy: 0.7764\n",
      "Epoch 9/10\n",
      "4508/4508 [==============================] - 0s 62us/sample - loss: 0.7175 - accuracy: 0.7615 - val_loss: 0.9226 - val_accuracy: 0.7879\n",
      "Epoch 10/10\n",
      "4508/4508 [==============================] - 0s 63us/sample - loss: 0.8001 - accuracy: 0.7618 - val_loss: 0.5645 - val_accuracy: 0.7347\n",
      "1408/1408 [==============================] - 0s 95us/sample - loss: 0.5296 - accuracy: 0.7408\n",
      "Train on 5634 samples, validate on 1409 samples\n",
      "Epoch 1/10\n",
      "5634/5634 [==============================] - 1s 155us/sample - loss: 7.0580 - accuracy: 0.6484 - val_loss: 0.5494 - val_accuracy: 0.7119\n",
      "Epoch 2/10\n",
      "5634/5634 [==============================] - 0s 60us/sample - loss: 0.6457 - accuracy: 0.7467 - val_loss: 0.8346 - val_accuracy: 0.7857\n",
      "Epoch 3/10\n",
      "5634/5634 [==============================] - 0s 63us/sample - loss: 0.6544 - accuracy: 0.7652 - val_loss: 0.4493 - val_accuracy: 0.7928\n",
      "Epoch 4/10\n",
      "5634/5634 [==============================] - 0s 60us/sample - loss: 0.9801 - accuracy: 0.7552 - val_loss: 0.4442 - val_accuracy: 0.7949\n",
      "Epoch 5/10\n",
      "5634/5634 [==============================] - 0s 59us/sample - loss: 0.7385 - accuracy: 0.7650 - val_loss: 0.7326 - val_accuracy: 0.6508\n",
      "Epoch 6/10\n",
      "5634/5634 [==============================] - 0s 64us/sample - loss: 0.6820 - accuracy: 0.7709 - val_loss: 0.4752 - val_accuracy: 0.7708\n",
      "Epoch 7/10\n",
      "5634/5634 [==============================] - 0s 59us/sample - loss: 0.9454 - accuracy: 0.7551 - val_loss: 0.6266 - val_accuracy: 0.7984\n",
      "Epoch 8/10\n",
      "5634/5634 [==============================] - 0s 58us/sample - loss: 0.9753 - accuracy: 0.7588 - val_loss: 1.4675 - val_accuracy: 0.7913\n",
      "Epoch 9/10\n",
      "5634/5634 [==============================] - 0s 58us/sample - loss: 0.7996 - accuracy: 0.7636 - val_loss: 0.4740 - val_accuracy: 0.7764\n",
      "Epoch 10/10\n",
      "5634/5634 [==============================] - 0s 58us/sample - loss: 0.6810 - accuracy: 0.7680 - val_loss: 0.4869 - val_accuracy: 0.7708\n",
      "\n",
      "Best score: 0.7912832021713256\n",
      "Best params: {'nodes_per_layer': 52}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# tune number of nodes\n",
    "params = {\n",
    "    'nodes_per_layer': [26, 52, 78, 100]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=KerasClassifier(build_fn=create_model),\n",
    "    param_grid=params,\n",
    "    n_jobs=1,\n",
    "    cv=5,\n",
    ")\n",
    "\n",
    "grid.fit(X, y, callbacks=[stop], epochs=10, validation_split=0.2)\n",
    "\n",
    "print()\n",
    "print('Best score:', grid.best_score_)\n",
    "print('Best params:', grid.best_params_)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4507/4507 [==============================] - 1s 301us/sample - loss: 0.5750 - accuracy: 0.7533 - val_loss: 0.5407 - val_accuracy: 0.7640\n",
      "Epoch 2/10\n",
      "4507/4507 [==============================] - 1s 114us/sample - loss: 0.5711 - accuracy: 0.7528 - val_loss: 0.5343 - val_accuracy: 0.7728\n",
      "Epoch 3/10\n",
      "4507/4507 [==============================] - 0s 106us/sample - loss: 0.5407 - accuracy: 0.7633 - val_loss: 0.5394 - val_accuracy: 0.7684\n",
      "Epoch 4/10\n",
      "4507/4507 [==============================] - 0s 100us/sample - loss: 0.5355 - accuracy: 0.7617 - val_loss: 0.5240 - val_accuracy: 0.7755\n",
      "Epoch 5/10\n",
      "4507/4507 [==============================] - 0s 96us/sample - loss: 0.5311 - accuracy: 0.7626 - val_loss: 0.5180 - val_accuracy: 0.7782\n",
      "Epoch 6/10\n",
      "4507/4507 [==============================] - 0s 95us/sample - loss: 0.5157 - accuracy: 0.7655 - val_loss: 0.5395 - val_accuracy: 0.7888\n",
      "Epoch 7/10\n",
      "4507/4507 [==============================] - 0s 108us/sample - loss: 0.5429 - accuracy: 0.7626 - val_loss: 0.5252 - val_accuracy: 0.7746\n",
      "Epoch 8/10\n",
      "4507/4507 [==============================] - 0s 103us/sample - loss: 0.5280 - accuracy: 0.7641 - val_loss: 0.5178 - val_accuracy: 0.7755\n",
      "Epoch 9/10\n",
      "4507/4507 [==============================] - 0s 95us/sample - loss: 0.4987 - accuracy: 0.7688 - val_loss: 0.4777 - val_accuracy: 0.7968\n",
      "Epoch 10/10\n",
      "4507/4507 [==============================] - 0s 98us/sample - loss: 0.4828 - accuracy: 0.7701 - val_loss: 0.4430 - val_accuracy: 0.7941\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4507/4507 [==============================] - 1s 299us/sample - loss: 0.5885 - accuracy: 0.7464 - val_loss: 0.5464 - val_accuracy: 0.7684\n",
      "Epoch 2/10\n",
      "4507/4507 [==============================] - 0s 96us/sample - loss: 0.5493 - accuracy: 0.7593 - val_loss: 0.5525 - val_accuracy: 0.7764\n",
      "Epoch 3/10\n",
      "4507/4507 [==============================] - 0s 101us/sample - loss: 0.5354 - accuracy: 0.7595 - val_loss: 0.5330 - val_accuracy: 0.7711\n",
      "Epoch 4/10\n",
      "4507/4507 [==============================] - 0s 96us/sample - loss: 0.5203 - accuracy: 0.7706 - val_loss: 0.5575 - val_accuracy: 0.7728\n",
      "Epoch 5/10\n",
      "4507/4507 [==============================] - 0s 95us/sample - loss: 0.4983 - accuracy: 0.7728 - val_loss: 0.4761 - val_accuracy: 0.7844\n",
      "Epoch 6/10\n",
      "4507/4507 [==============================] - 0s 100us/sample - loss: 0.4830 - accuracy: 0.7750 - val_loss: 0.4618 - val_accuracy: 0.7933\n",
      "Epoch 7/10\n",
      "4507/4507 [==============================] - 0s 100us/sample - loss: 0.4923 - accuracy: 0.7766 - val_loss: 0.4697 - val_accuracy: 0.7933\n",
      "Epoch 8/10\n",
      "4507/4507 [==============================] - 0s 96us/sample - loss: 0.4714 - accuracy: 0.7832 - val_loss: 0.4534 - val_accuracy: 0.7879\n",
      "Epoch 9/10\n",
      "4507/4507 [==============================] - 0s 95us/sample - loss: 0.4688 - accuracy: 0.7777 - val_loss: 0.4577 - val_accuracy: 0.7897\n",
      "Epoch 10/10\n",
      "4507/4507 [==============================] - 0s 95us/sample - loss: 0.4663 - accuracy: 0.7783 - val_loss: 0.4712 - val_accuracy: 0.7835\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4507/4507 [==============================] - 2s 479us/sample - loss: 0.5879 - accuracy: 0.7446 - val_loss: 0.5648 - val_accuracy: 0.7817\n",
      "Epoch 2/10\n",
      "4507/4507 [==============================] - 0s 102us/sample - loss: 0.5614 - accuracy: 0.7599 - val_loss: 0.5650 - val_accuracy: 0.7294\n",
      "Epoch 3/10\n",
      "4507/4507 [==============================] - 0s 102us/sample - loss: 0.5578 - accuracy: 0.7568 - val_loss: 0.5195 - val_accuracy: 0.7853\n",
      "Epoch 4/10\n",
      "4507/4507 [==============================] - 0s 103us/sample - loss: 0.5281 - accuracy: 0.7768 - val_loss: 0.5287 - val_accuracy: 0.7755\n",
      "Epoch 5/10\n",
      "4507/4507 [==============================] - 0s 98us/sample - loss: 0.5066 - accuracy: 0.7797 - val_loss: 0.5086 - val_accuracy: 0.7915\n",
      "Epoch 6/10\n",
      "4507/4507 [==============================] - 0s 101us/sample - loss: 0.5048 - accuracy: 0.7768 - val_loss: 0.5516 - val_accuracy: 0.7702\n",
      "Epoch 7/10\n",
      "4507/4507 [==============================] - 0s 96us/sample - loss: 0.5127 - accuracy: 0.7741 - val_loss: 0.5019 - val_accuracy: 0.7870\n",
      "Epoch 8/10\n",
      "4507/4507 [==============================] - 0s 101us/sample - loss: 0.4934 - accuracy: 0.7819 - val_loss: 0.4811 - val_accuracy: 0.7897\n",
      "Epoch 9/10\n",
      "4507/4507 [==============================] - 0s 97us/sample - loss: 0.4759 - accuracy: 0.7799 - val_loss: 0.4601 - val_accuracy: 0.7835\n",
      "Epoch 10/10\n",
      "4507/4507 [==============================] - 0s 99us/sample - loss: 0.4780 - accuracy: 0.7834 - val_loss: 0.4770 - val_accuracy: 0.7950\n",
      "Train on 4508 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4508/4508 [==============================] - 1s 300us/sample - loss: 0.5847 - accuracy: 0.7385 - val_loss: 0.5516 - val_accuracy: 0.7684\n",
      "Epoch 2/10\n",
      "4508/4508 [==============================] - 0s 98us/sample - loss: 0.5386 - accuracy: 0.7680 - val_loss: 0.5602 - val_accuracy: 0.7640\n",
      "Epoch 3/10\n",
      "4508/4508 [==============================] - 0s 102us/sample - loss: 0.5422 - accuracy: 0.7638 - val_loss: 0.5295 - val_accuracy: 0.7773\n",
      "Epoch 4/10\n",
      "4508/4508 [==============================] - 0s 97us/sample - loss: 0.5155 - accuracy: 0.7728 - val_loss: 0.5526 - val_accuracy: 0.7524\n",
      "Epoch 5/10\n",
      "4508/4508 [==============================] - 0s 103us/sample - loss: 0.5210 - accuracy: 0.7724 - val_loss: 0.5125 - val_accuracy: 0.7933\n",
      "Epoch 6/10\n",
      "4508/4508 [==============================] - 0s 96us/sample - loss: 0.5046 - accuracy: 0.7651 - val_loss: 0.4793 - val_accuracy: 0.7950\n",
      "Epoch 7/10\n",
      "4508/4508 [==============================] - 0s 100us/sample - loss: 0.4810 - accuracy: 0.7802 - val_loss: 0.4774 - val_accuracy: 0.7782\n",
      "Epoch 8/10\n",
      "4508/4508 [==============================] - 0s 97us/sample - loss: 0.4722 - accuracy: 0.7760 - val_loss: 0.4596 - val_accuracy: 0.7959\n",
      "Epoch 9/10\n",
      "4508/4508 [==============================] - 0s 97us/sample - loss: 0.4655 - accuracy: 0.7784 - val_loss: 0.4477 - val_accuracy: 0.7933\n",
      "Epoch 10/10\n",
      "4508/4508 [==============================] - 0s 98us/sample - loss: 0.4605 - accuracy: 0.7793 - val_loss: 0.4439 - val_accuracy: 0.7977\n",
      "Train on 4508 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4508/4508 [==============================] - 1s 300us/sample - loss: 0.5896 - accuracy: 0.7327 - val_loss: 0.5357 - val_accuracy: 0.7737\n",
      "Epoch 2/10\n",
      "4508/4508 [==============================] - 0s 99us/sample - loss: 0.5558 - accuracy: 0.7562 - val_loss: 0.5464 - val_accuracy: 0.7489\n",
      "Epoch 3/10\n",
      "4508/4508 [==============================] - 0s 99us/sample - loss: 0.5429 - accuracy: 0.7555 - val_loss: 0.5376 - val_accuracy: 0.7551\n",
      "Epoch 4/10\n",
      "4508/4508 [==============================] - 0s 98us/sample - loss: 0.5228 - accuracy: 0.7680 - val_loss: 0.4940 - val_accuracy: 0.7693\n",
      "Epoch 5/10\n",
      "4508/4508 [==============================] - 0s 101us/sample - loss: 0.4862 - accuracy: 0.7720 - val_loss: 0.7759 - val_accuracy: 0.7791\n",
      "Epoch 6/10\n",
      "4508/4508 [==============================] - 0s 98us/sample - loss: 0.5026 - accuracy: 0.7731 - val_loss: 0.5391 - val_accuracy: 0.7471\n",
      "Epoch 7/10\n",
      "4508/4508 [==============================] - 0s 98us/sample - loss: 0.4836 - accuracy: 0.7791 - val_loss: 0.4646 - val_accuracy: 0.7835\n",
      "Epoch 8/10\n",
      "4508/4508 [==============================] - 0s 111us/sample - loss: 0.4867 - accuracy: 0.7660 - val_loss: 0.5170 - val_accuracy: 0.7267\n",
      "Epoch 9/10\n",
      "4508/4508 [==============================] - 0s 104us/sample - loss: 0.4737 - accuracy: 0.7673 - val_loss: 0.4975 - val_accuracy: 0.7560\n",
      "Epoch 10/10\n",
      "4508/4508 [==============================] - 0s 98us/sample - loss: 0.4711 - accuracy: 0.7788 - val_loss: 0.4724 - val_accuracy: 0.7835\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4507/4507 [==============================] - 1s 255us/sample - loss: 0.6831 - accuracy: 0.7397 - val_loss: 0.5570 - val_accuracy: 0.7817\n",
      "Epoch 2/10\n",
      "4507/4507 [==============================] - 0s 87us/sample - loss: 0.5505 - accuracy: 0.7659 - val_loss: 0.5705 - val_accuracy: 0.7826\n",
      "Epoch 3/10\n",
      "4507/4507 [==============================] - 0s 86us/sample - loss: 0.5286 - accuracy: 0.7666 - val_loss: 0.4696 - val_accuracy: 0.7924\n",
      "Epoch 4/10\n",
      "4507/4507 [==============================] - 0s 87us/sample - loss: 0.5255 - accuracy: 0.7621 - val_loss: 0.4915 - val_accuracy: 0.7808\n",
      "Epoch 5/10\n",
      "4507/4507 [==============================] - 0s 92us/sample - loss: 0.4721 - accuracy: 0.7768 - val_loss: 0.4518 - val_accuracy: 0.7941\n",
      "Epoch 6/10\n",
      "4507/4507 [==============================] - 0s 85us/sample - loss: 0.4776 - accuracy: 0.7708 - val_loss: 0.4712 - val_accuracy: 0.7870\n",
      "Epoch 7/10\n",
      "4507/4507 [==============================] - 0s 85us/sample - loss: 0.4777 - accuracy: 0.7772 - val_loss: 0.4748 - val_accuracy: 0.7755\n",
      "Epoch 8/10\n",
      "4507/4507 [==============================] - 0s 84us/sample - loss: 0.4771 - accuracy: 0.7746 - val_loss: 0.4496 - val_accuracy: 0.7897\n",
      "Epoch 9/10\n",
      "4507/4507 [==============================] - 0s 84us/sample - loss: 0.4650 - accuracy: 0.7806 - val_loss: 0.4721 - val_accuracy: 0.7870\n",
      "Epoch 10/10\n",
      "4507/4507 [==============================] - 0s 91us/sample - loss: 0.4684 - accuracy: 0.7763 - val_loss: 0.4704 - val_accuracy: 0.7684\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4507/4507 [==============================] - 1s 281us/sample - loss: 0.7821 - accuracy: 0.7227 - val_loss: 0.7063 - val_accuracy: 0.7773\n",
      "Epoch 2/10\n",
      "4507/4507 [==============================] - 0s 86us/sample - loss: 0.5234 - accuracy: 0.7692 - val_loss: 0.4765 - val_accuracy: 0.7835\n",
      "Epoch 3/10\n",
      "4507/4507 [==============================] - 0s 93us/sample - loss: 0.5508 - accuracy: 0.7655 - val_loss: 0.6076 - val_accuracy: 0.6486\n",
      "Epoch 4/10\n",
      "4507/4507 [==============================] - 0s 84us/sample - loss: 0.5081 - accuracy: 0.7728 - val_loss: 0.4594 - val_accuracy: 0.7950\n",
      "Epoch 5/10\n",
      "4507/4507 [==============================] - 0s 83us/sample - loss: 0.4831 - accuracy: 0.7786 - val_loss: 0.4795 - val_accuracy: 0.7870\n",
      "Epoch 6/10\n",
      "4507/4507 [==============================] - 0s 85us/sample - loss: 0.4776 - accuracy: 0.7777 - val_loss: 0.4508 - val_accuracy: 0.7853\n",
      "Epoch 7/10\n",
      "4507/4507 [==============================] - 0s 90us/sample - loss: 0.4607 - accuracy: 0.7883 - val_loss: 0.4553 - val_accuracy: 0.7826\n",
      "Epoch 8/10\n",
      "4507/4507 [==============================] - 0s 89us/sample - loss: 0.4584 - accuracy: 0.7903 - val_loss: 0.4502 - val_accuracy: 0.7924\n",
      "Epoch 9/10\n",
      "4507/4507 [==============================] - 0s 91us/sample - loss: 0.4632 - accuracy: 0.7863 - val_loss: 0.4658 - val_accuracy: 0.7941\n",
      "Epoch 10/10\n",
      "4507/4507 [==============================] - 0s 92us/sample - loss: 0.4717 - accuracy: 0.7850 - val_loss: 0.4511 - val_accuracy: 0.7870\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4507/4507 [==============================] - 1s 300us/sample - loss: 0.8527 - accuracy: 0.7258 - val_loss: 0.6150 - val_accuracy: 0.7817\n",
      "Epoch 2/10\n",
      "4507/4507 [==============================] - 0s 90us/sample - loss: 0.5483 - accuracy: 0.7692 - val_loss: 0.5370 - val_accuracy: 0.7817\n",
      "Epoch 3/10\n",
      "4507/4507 [==============================] - 0s 93us/sample - loss: 0.5235 - accuracy: 0.7815 - val_loss: 0.4995 - val_accuracy: 0.7950\n",
      "Epoch 4/10\n",
      "4507/4507 [==============================] - 0s 96us/sample - loss: 0.5267 - accuracy: 0.7777 - val_loss: 0.4836 - val_accuracy: 0.7862\n",
      "Epoch 5/10\n",
      "4507/4507 [==============================] - 0s 86us/sample - loss: 0.5181 - accuracy: 0.7670 - val_loss: 0.4718 - val_accuracy: 0.7862\n",
      "Epoch 6/10\n",
      "4507/4507 [==============================] - 0s 89us/sample - loss: 0.4881 - accuracy: 0.7815 - val_loss: 0.5994 - val_accuracy: 0.7782\n",
      "Epoch 7/10\n",
      "4507/4507 [==============================] - 0s 90us/sample - loss: 0.4687 - accuracy: 0.7817 - val_loss: 0.4603 - val_accuracy: 0.7915\n",
      "Epoch 8/10\n",
      "4507/4507 [==============================] - 0s 89us/sample - loss: 0.4687 - accuracy: 0.7883 - val_loss: 0.4699 - val_accuracy: 0.7906\n",
      "Epoch 9/10\n",
      "4507/4507 [==============================] - 0s 83us/sample - loss: 0.4664 - accuracy: 0.7917 - val_loss: 0.4529 - val_accuracy: 0.7915\n",
      "Epoch 10/10\n",
      "4507/4507 [==============================] - 0s 90us/sample - loss: 0.4556 - accuracy: 0.7910 - val_loss: 0.4424 - val_accuracy: 0.7950\n",
      "Train on 4508 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4508/4508 [==============================] - 1s 291us/sample - loss: 0.7719 - accuracy: 0.7303 - val_loss: 0.5404 - val_accuracy: 0.7737\n",
      "Epoch 2/10\n",
      "4508/4508 [==============================] - 0s 85us/sample - loss: 0.5833 - accuracy: 0.7547 - val_loss: 0.5857 - val_accuracy: 0.7879\n",
      "Epoch 3/10\n",
      "4508/4508 [==============================] - 0s 87us/sample - loss: 0.5285 - accuracy: 0.7731 - val_loss: 0.4815 - val_accuracy: 0.7879\n",
      "Epoch 4/10\n",
      "4508/4508 [==============================] - 0s 88us/sample - loss: 0.4845 - accuracy: 0.7748 - val_loss: 0.5009 - val_accuracy: 0.7808\n",
      "Epoch 5/10\n",
      "4508/4508 [==============================] - 0s 89us/sample - loss: 0.5382 - accuracy: 0.7731 - val_loss: 0.4499 - val_accuracy: 0.7950\n",
      "Epoch 6/10\n",
      "4508/4508 [==============================] - 0s 83us/sample - loss: 0.4791 - accuracy: 0.7722 - val_loss: 0.4776 - val_accuracy: 0.7844\n",
      "Epoch 7/10\n",
      "4508/4508 [==============================] - 0s 91us/sample - loss: 0.4659 - accuracy: 0.7833 - val_loss: 0.4506 - val_accuracy: 0.7950\n",
      "Epoch 8/10\n",
      "4508/4508 [==============================] - 0s 89us/sample - loss: 0.4563 - accuracy: 0.7848 - val_loss: 0.4423 - val_accuracy: 0.7959\n",
      "Epoch 9/10\n",
      "4508/4508 [==============================] - 0s 90us/sample - loss: 0.4536 - accuracy: 0.7877 - val_loss: 0.4633 - val_accuracy: 0.7684\n",
      "Epoch 10/10\n",
      "4508/4508 [==============================] - 0s 84us/sample - loss: 0.4676 - accuracy: 0.7824 - val_loss: 0.4561 - val_accuracy: 0.7941\n",
      "Train on 4508 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4508/4508 [==============================] - 1s 272us/sample - loss: 0.6739 - accuracy: 0.7382 - val_loss: 0.5436 - val_accuracy: 0.7693\n",
      "Epoch 2/10\n",
      "4508/4508 [==============================] - 0s 87us/sample - loss: 0.5721 - accuracy: 0.7527 - val_loss: 0.5057 - val_accuracy: 0.7764\n",
      "Epoch 3/10\n",
      "4508/4508 [==============================] - 0s 83us/sample - loss: 0.5333 - accuracy: 0.7675 - val_loss: 0.4888 - val_accuracy: 0.7879\n",
      "Epoch 4/10\n",
      "4508/4508 [==============================] - 0s 87us/sample - loss: 0.4905 - accuracy: 0.7711 - val_loss: 0.4742 - val_accuracy: 0.7817\n",
      "Epoch 5/10\n",
      "4508/4508 [==============================] - 0s 82us/sample - loss: 0.5050 - accuracy: 0.7744 - val_loss: 0.5047 - val_accuracy: 0.7755\n",
      "Epoch 6/10\n",
      "4508/4508 [==============================] - 0s 81us/sample - loss: 0.4656 - accuracy: 0.7811 - val_loss: 0.4681 - val_accuracy: 0.7799\n",
      "Epoch 7/10\n",
      "4508/4508 [==============================] - 0s 84us/sample - loss: 0.4603 - accuracy: 0.7802 - val_loss: 0.4717 - val_accuracy: 0.7906\n",
      "Epoch 8/10\n",
      "4508/4508 [==============================] - 0s 83us/sample - loss: 0.4542 - accuracy: 0.7882 - val_loss: 0.4573 - val_accuracy: 0.7888\n",
      "Epoch 9/10\n",
      "4508/4508 [==============================] - 0s 85us/sample - loss: 0.4564 - accuracy: 0.7939 - val_loss: 0.5222 - val_accuracy: 0.7862\n",
      "Epoch 10/10\n",
      "4508/4508 [==============================] - 0s 84us/sample - loss: 0.4583 - accuracy: 0.7897 - val_loss: 0.4564 - val_accuracy: 0.7924\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4507/4507 [==============================] - 1s 219us/sample - loss: 2.0307 - accuracy: 0.6889 - val_loss: 1.0449 - val_accuracy: 0.4321\n",
      "Epoch 2/10\n",
      "4507/4507 [==============================] - 0s 69us/sample - loss: 1.0805 - accuracy: 0.7220 - val_loss: 0.5033 - val_accuracy: 0.7755\n",
      "Epoch 3/10\n",
      "4507/4507 [==============================] - 0s 69us/sample - loss: 0.6298 - accuracy: 0.7610 - val_loss: 1.2542 - val_accuracy: 0.4729\n",
      "Epoch 4/10\n",
      "4507/4507 [==============================] - 0s 68us/sample - loss: 0.6179 - accuracy: 0.7499 - val_loss: 0.8160 - val_accuracy: 0.7897\n",
      "Epoch 5/10\n",
      "4507/4507 [==============================] - 0s 68us/sample - loss: 0.6225 - accuracy: 0.7566 - val_loss: 0.4716 - val_accuracy: 0.7720\n",
      "Epoch 6/10\n",
      "4507/4507 [==============================] - 0s 70us/sample - loss: 0.5007 - accuracy: 0.7752 - val_loss: 0.6171 - val_accuracy: 0.7933\n",
      "Epoch 7/10\n",
      "4507/4507 [==============================] - 0s 68us/sample - loss: 0.5214 - accuracy: 0.7628 - val_loss: 0.4676 - val_accuracy: 0.7897\n",
      "Epoch 8/10\n",
      "4507/4507 [==============================] - 0s 68us/sample - loss: 0.5070 - accuracy: 0.7717 - val_loss: 0.5012 - val_accuracy: 0.7862\n",
      "Epoch 9/10\n",
      "4507/4507 [==============================] - 0s 69us/sample - loss: 0.4690 - accuracy: 0.7848 - val_loss: 0.4504 - val_accuracy: 0.7941\n",
      "Epoch 10/10\n",
      "4507/4507 [==============================] - 0s 68us/sample - loss: 0.4843 - accuracy: 0.7815 - val_loss: 0.4423 - val_accuracy: 0.7968\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4507/4507 [==============================] - 1s 201us/sample - loss: 2.6921 - accuracy: 0.6692 - val_loss: 1.0223 - val_accuracy: 0.7764\n",
      "Epoch 2/10\n",
      "4507/4507 [==============================] - 0s 69us/sample - loss: 1.0914 - accuracy: 0.7215 - val_loss: 0.7363 - val_accuracy: 0.7915\n",
      "Epoch 3/10\n",
      "4507/4507 [==============================] - 0s 68us/sample - loss: 0.9213 - accuracy: 0.7262 - val_loss: 1.3054 - val_accuracy: 0.7844\n",
      "Epoch 4/10\n",
      "4507/4507 [==============================] - 0s 69us/sample - loss: 0.7357 - accuracy: 0.7457 - val_loss: 0.5225 - val_accuracy: 0.7888\n",
      "Epoch 5/10\n",
      "4507/4507 [==============================] - 0s 69us/sample - loss: 0.6186 - accuracy: 0.7533 - val_loss: 0.5734 - val_accuracy: 0.7941\n",
      "Epoch 6/10\n",
      "4507/4507 [==============================] - 0s 68us/sample - loss: 0.6425 - accuracy: 0.7613 - val_loss: 0.5037 - val_accuracy: 0.7941\n",
      "Epoch 7/10\n",
      "4507/4507 [==============================] - 0s 69us/sample - loss: 0.7826 - accuracy: 0.7404 - val_loss: 0.6790 - val_accuracy: 0.7924\n",
      "Epoch 8/10\n",
      "4507/4507 [==============================] - 0s 68us/sample - loss: 0.5653 - accuracy: 0.7699 - val_loss: 0.4576 - val_accuracy: 0.7755\n",
      "Epoch 9/10\n",
      "4507/4507 [==============================] - 0s 68us/sample - loss: 0.6263 - accuracy: 0.7535 - val_loss: 0.5455 - val_accuracy: 0.6788\n",
      "Epoch 10/10\n",
      "4507/4507 [==============================] - 0s 71us/sample - loss: 0.5375 - accuracy: 0.7755 - val_loss: 0.4382 - val_accuracy: 0.7888\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4507/4507 [==============================] - 1s 203us/sample - loss: 1.1792 - accuracy: 0.7056 - val_loss: 0.6385 - val_accuracy: 0.7791\n",
      "Epoch 2/10\n",
      "4507/4507 [==============================] - 0s 71us/sample - loss: 1.0468 - accuracy: 0.7098 - val_loss: 1.1030 - val_accuracy: 0.4650\n",
      "Epoch 3/10\n",
      "4507/4507 [==============================] - 0s 70us/sample - loss: 0.7010 - accuracy: 0.7375 - val_loss: 0.5060 - val_accuracy: 0.7870\n",
      "Epoch 4/10\n",
      "4507/4507 [==============================] - 0s 71us/sample - loss: 0.5515 - accuracy: 0.7692 - val_loss: 0.4598 - val_accuracy: 0.7968\n",
      "Epoch 5/10\n",
      "4507/4507 [==============================] - 0s 76us/sample - loss: 0.5451 - accuracy: 0.7684 - val_loss: 0.4580 - val_accuracy: 0.7862\n",
      "Epoch 6/10\n",
      "4507/4507 [==============================] - 0s 76us/sample - loss: 0.5480 - accuracy: 0.7686 - val_loss: 0.4584 - val_accuracy: 0.7844\n",
      "Epoch 7/10\n",
      "4507/4507 [==============================] - 0s 80us/sample - loss: 0.6020 - accuracy: 0.7613 - val_loss: 0.5268 - val_accuracy: 0.7888\n",
      "Epoch 8/10\n",
      "4507/4507 [==============================] - 0s 94us/sample - loss: 0.7204 - accuracy: 0.7546 - val_loss: 0.4890 - val_accuracy: 0.7986\n",
      "Epoch 9/10\n",
      "4507/4507 [==============================] - 0s 81us/sample - loss: 0.5027 - accuracy: 0.7806 - val_loss: 0.4480 - val_accuracy: 0.8012\n",
      "Epoch 10/10\n",
      "4507/4507 [==============================] - 0s 83us/sample - loss: 0.4757 - accuracy: 0.7826 - val_loss: 0.4821 - val_accuracy: 0.8004\n",
      "Train on 4508 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4508/4508 [==============================] - 1s 246us/sample - loss: 2.6704 - accuracy: 0.6830 - val_loss: 0.7967 - val_accuracy: 0.7791\n",
      "Epoch 2/10\n",
      "4508/4508 [==============================] - 0s 81us/sample - loss: 1.0946 - accuracy: 0.7212 - val_loss: 0.5409 - val_accuracy: 0.7817\n",
      "Epoch 3/10\n",
      "4508/4508 [==============================] - 0s 89us/sample - loss: 0.8023 - accuracy: 0.7387 - val_loss: 0.5403 - val_accuracy: 0.7303\n",
      "Epoch 4/10\n",
      "4508/4508 [==============================] - 0s 89us/sample - loss: 0.5355 - accuracy: 0.7689 - val_loss: 1.4092 - val_accuracy: 0.5058\n",
      "Epoch 5/10\n",
      "4508/4508 [==============================] - 0s 83us/sample - loss: 0.6387 - accuracy: 0.7520 - val_loss: 0.7804 - val_accuracy: 0.7746\n",
      "Epoch 6/10\n",
      "4508/4508 [==============================] - 0s 81us/sample - loss: 0.5294 - accuracy: 0.7655 - val_loss: 0.4669 - val_accuracy: 0.7897\n",
      "Epoch 7/10\n",
      "4508/4508 [==============================] - 0s 81us/sample - loss: 0.5339 - accuracy: 0.7702 - val_loss: 0.4378 - val_accuracy: 0.8030\n",
      "Epoch 8/10\n",
      "4508/4508 [==============================] - 0s 88us/sample - loss: 0.5109 - accuracy: 0.7671 - val_loss: 0.4434 - val_accuracy: 0.7835\n",
      "Epoch 9/10\n",
      "4508/4508 [==============================] - 0s 99us/sample - loss: 0.4756 - accuracy: 0.7806 - val_loss: 0.4572 - val_accuracy: 0.7977\n",
      "Epoch 10/10\n",
      "4508/4508 [==============================] - 0s 93us/sample - loss: 0.5097 - accuracy: 0.7702 - val_loss: 0.4664 - val_accuracy: 0.7995\n",
      "Train on 4508 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4508/4508 [==============================] - 1s 253us/sample - loss: 4.9111 - accuracy: 0.6735 - val_loss: 1.2091 - val_accuracy: 0.7684\n",
      "Epoch 2/10\n",
      "4508/4508 [==============================] - 0s 91us/sample - loss: 1.3901 - accuracy: 0.7030 - val_loss: 0.8877 - val_accuracy: 0.7471\n",
      "Epoch 3/10\n",
      "4508/4508 [==============================] - 0s 89us/sample - loss: 0.8402 - accuracy: 0.7276 - val_loss: 0.8538 - val_accuracy: 0.7799\n",
      "Epoch 4/10\n",
      "4508/4508 [==============================] - 0s 92us/sample - loss: 0.9502 - accuracy: 0.7318 - val_loss: 0.5588 - val_accuracy: 0.7613\n",
      "Epoch 5/10\n",
      "4508/4508 [==============================] - 0s 93us/sample - loss: 0.5576 - accuracy: 0.7582 - val_loss: 0.4809 - val_accuracy: 0.7720\n",
      "Epoch 6/10\n",
      "4508/4508 [==============================] - 0s 88us/sample - loss: 0.5453 - accuracy: 0.7638 - val_loss: 0.5518 - val_accuracy: 0.7817\n",
      "Epoch 7/10\n",
      "4508/4508 [==============================] - 0s 81us/sample - loss: 0.5840 - accuracy: 0.7655 - val_loss: 0.4807 - val_accuracy: 0.7986\n",
      "Epoch 8/10\n",
      "4508/4508 [==============================] - 0s 82us/sample - loss: 0.4971 - accuracy: 0.7837 - val_loss: 0.4921 - val_accuracy: 0.7826\n",
      "Epoch 9/10\n",
      "4508/4508 [==============================] - 0s 94us/sample - loss: 0.4915 - accuracy: 0.7762 - val_loss: 0.5195 - val_accuracy: 0.7870\n",
      "Epoch 10/10\n",
      "4508/4508 [==============================] - 0s 87us/sample - loss: 0.5575 - accuracy: 0.7622 - val_loss: 0.4552 - val_accuracy: 0.7870\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4507/4507 [==============================] - 1s 225us/sample - loss: 63.4421 - accuracy: 0.6150 - val_loss: 0.8815 - val_accuracy: 0.7702\n",
      "Epoch 2/10\n",
      "4507/4507 [==============================] - 1s 119us/sample - loss: 0.5963 - accuracy: 0.7599 - val_loss: 0.5114 - val_accuracy: 0.7941\n",
      "Epoch 3/10\n",
      "4507/4507 [==============================] - 0s 81us/sample - loss: 0.7325 - accuracy: 0.7542 - val_loss: 1.1522 - val_accuracy: 0.7995\n",
      "Epoch 4/10\n",
      "4507/4507 [==============================] - 0s 76us/sample - loss: 0.8942 - accuracy: 0.7542 - val_loss: 1.8278 - val_accuracy: 0.7711\n",
      "Epoch 5/10\n",
      "4507/4507 [==============================] - 0s 77us/sample - loss: 0.7956 - accuracy: 0.7617 - val_loss: 0.4919 - val_accuracy: 0.7542\n",
      "Epoch 6/10\n",
      "4507/4507 [==============================] - 0s 82us/sample - loss: 0.7102 - accuracy: 0.7635 - val_loss: 0.5585 - val_accuracy: 0.8021\n",
      "Epoch 7/10\n",
      "4507/4507 [==============================] - 0s 82us/sample - loss: 1.0845 - accuracy: 0.7575 - val_loss: 1.7974 - val_accuracy: 0.5040\n",
      "Epoch 8/10\n",
      "4507/4507 [==============================] - 0s 69us/sample - loss: 0.8335 - accuracy: 0.7597 - val_loss: 0.5868 - val_accuracy: 0.7977\n",
      "Epoch 9/10\n",
      "4507/4507 [==============================] - 0s 78us/sample - loss: 0.7160 - accuracy: 0.7655 - val_loss: 0.7658 - val_accuracy: 0.8057\n",
      "Epoch 10/10\n",
      "4507/4507 [==============================] - 0s 71us/sample - loss: 0.9892 - accuracy: 0.7564 - val_loss: 0.7073 - val_accuracy: 0.7977\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4507/4507 [==============================] - 2s 405us/sample - loss: 4.0679 - accuracy: 0.5824 - val_loss: 1.0510 - val_accuracy: 0.7294\n",
      "Epoch 2/10\n",
      "4507/4507 [==============================] - 0s 73us/sample - loss: 1.0513 - accuracy: 0.7215 - val_loss: 1.9218 - val_accuracy: 0.7862\n",
      "Epoch 3/10\n",
      "4507/4507 [==============================] - 0s 78us/sample - loss: 0.8108 - accuracy: 0.7535 - val_loss: 0.6349 - val_accuracy: 0.7844\n",
      "Epoch 4/10\n",
      "4507/4507 [==============================] - 0s 83us/sample - loss: 0.6350 - accuracy: 0.7679 - val_loss: 0.4614 - val_accuracy: 0.7915\n",
      "Epoch 5/10\n",
      "4507/4507 [==============================] - 0s 83us/sample - loss: 0.9162 - accuracy: 0.7590 - val_loss: 1.3133 - val_accuracy: 0.7906\n",
      "Epoch 6/10\n",
      "4507/4507 [==============================] - 0s 82us/sample - loss: 0.6400 - accuracy: 0.7750 - val_loss: 0.4468 - val_accuracy: 0.7995\n",
      "Epoch 7/10\n",
      "4507/4507 [==============================] - 0s 81us/sample - loss: 0.6725 - accuracy: 0.7666 - val_loss: 0.4678 - val_accuracy: 0.8004\n",
      "Epoch 8/10\n",
      "4507/4507 [==============================] - 0s 81us/sample - loss: 0.5374 - accuracy: 0.7806 - val_loss: 0.9556 - val_accuracy: 0.7933\n",
      "Epoch 9/10\n",
      "4507/4507 [==============================] - 0s 76us/sample - loss: 0.6200 - accuracy: 0.7726 - val_loss: 0.6214 - val_accuracy: 0.6735\n",
      "Epoch 10/10\n",
      "4507/4507 [==============================] - 0s 65us/sample - loss: 0.8083 - accuracy: 0.7624 - val_loss: 0.5631 - val_accuracy: 0.7045\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4507/4507 [==============================] - 1s 168us/sample - loss: 2.4104 - accuracy: 0.7096 - val_loss: 0.7354 - val_accuracy: 0.7950\n",
      "Epoch 2/10\n",
      "4507/4507 [==============================] - 0s 59us/sample - loss: 0.7292 - accuracy: 0.7624 - val_loss: 0.8872 - val_accuracy: 0.7870\n",
      "Epoch 3/10\n",
      "4507/4507 [==============================] - 0s 59us/sample - loss: 0.9367 - accuracy: 0.7657 - val_loss: 1.1565 - val_accuracy: 0.7879\n",
      "Epoch 4/10\n",
      "4507/4507 [==============================] - 0s 59us/sample - loss: 0.7376 - accuracy: 0.7701 - val_loss: 0.6348 - val_accuracy: 0.8004\n",
      "Epoch 5/10\n",
      "4507/4507 [==============================] - 0s 58us/sample - loss: 0.8963 - accuracy: 0.7644 - val_loss: 0.9973 - val_accuracy: 0.6158\n",
      "Epoch 6/10\n",
      "4507/4507 [==============================] - 0s 58us/sample - loss: 1.2935 - accuracy: 0.7515 - val_loss: 1.9963 - val_accuracy: 0.7835\n",
      "Epoch 7/10\n",
      "4507/4507 [==============================] - 0s 58us/sample - loss: 1.0570 - accuracy: 0.7557 - val_loss: 2.1067 - val_accuracy: 0.5075\n",
      "Epoch 8/10\n",
      "4507/4507 [==============================] - 0s 58us/sample - loss: 0.7164 - accuracy: 0.7748 - val_loss: 0.8619 - val_accuracy: 0.8021\n",
      "Epoch 9/10\n",
      "4507/4507 [==============================] - 0s 59us/sample - loss: 0.9822 - accuracy: 0.7684 - val_loss: 0.5005 - val_accuracy: 0.7657\n",
      "Epoch 10/10\n",
      "4507/4507 [==============================] - 0s 63us/sample - loss: 0.7133 - accuracy: 0.7708 - val_loss: 1.9902 - val_accuracy: 0.7853\n",
      "Train on 4508 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4508/4508 [==============================] - 1s 164us/sample - loss: 12.2031 - accuracy: 0.6710 - val_loss: 0.5156 - val_accuracy: 0.7587\n",
      "Epoch 2/10\n",
      "4508/4508 [==============================] - 0s 62us/sample - loss: 1.1272 - accuracy: 0.7123 - val_loss: 0.8991 - val_accuracy: 0.7737\n",
      "Epoch 3/10\n",
      "4508/4508 [==============================] - 0s 63us/sample - loss: 0.9501 - accuracy: 0.7451 - val_loss: 1.5620 - val_accuracy: 0.7764\n",
      "Epoch 4/10\n",
      "4508/4508 [==============================] - 0s 63us/sample - loss: 0.7180 - accuracy: 0.7527 - val_loss: 0.8195 - val_accuracy: 0.7941\n",
      "Epoch 5/10\n",
      "4508/4508 [==============================] - 0s 59us/sample - loss: 0.8965 - accuracy: 0.7542 - val_loss: 0.4964 - val_accuracy: 0.7755\n",
      "Epoch 6/10\n",
      "4508/4508 [==============================] - 0s 65us/sample - loss: 0.9922 - accuracy: 0.7507 - val_loss: 0.6763 - val_accuracy: 0.7977\n",
      "Epoch 7/10\n",
      "4508/4508 [==============================] - 0s 62us/sample - loss: 1.1575 - accuracy: 0.7480 - val_loss: 0.5644 - val_accuracy: 0.7853\n",
      "Epoch 8/10\n",
      "4508/4508 [==============================] - 0s 59us/sample - loss: 0.6051 - accuracy: 0.7740 - val_loss: 0.8371 - val_accuracy: 0.8030\n",
      "Epoch 9/10\n",
      "4508/4508 [==============================] - 0s 63us/sample - loss: 0.9205 - accuracy: 0.7602 - val_loss: 1.0098 - val_accuracy: 0.7924\n",
      "Epoch 10/10\n",
      "4508/4508 [==============================] - 0s 60us/sample - loss: 0.7671 - accuracy: 0.7609 - val_loss: 1.0325 - val_accuracy: 0.8039\n",
      "Train on 4508 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4508/4508 [==============================] - 1s 168us/sample - loss: 1.8664 - accuracy: 0.7143 - val_loss: 1.8003 - val_accuracy: 0.7471\n",
      "Epoch 2/10\n",
      "4508/4508 [==============================] - 0s 59us/sample - loss: 0.9553 - accuracy: 0.7345 - val_loss: 1.9795 - val_accuracy: 0.7720\n",
      "Epoch 3/10\n",
      "4508/4508 [==============================] - 0s 62us/sample - loss: 0.7498 - accuracy: 0.7573 - val_loss: 0.9972 - val_accuracy: 0.7799\n",
      "Epoch 4/10\n",
      "4508/4508 [==============================] - 0s 58us/sample - loss: 0.6409 - accuracy: 0.7660 - val_loss: 0.5357 - val_accuracy: 0.7906\n",
      "Epoch 5/10\n",
      "4508/4508 [==============================] - 0s 60us/sample - loss: 0.7807 - accuracy: 0.7569 - val_loss: 0.5733 - val_accuracy: 0.7915\n",
      "Epoch 6/10\n",
      "4508/4508 [==============================] - 0s 65us/sample - loss: 0.8286 - accuracy: 0.7593 - val_loss: 0.4868 - val_accuracy: 0.7959\n",
      "Epoch 7/10\n",
      "4508/4508 [==============================] - 0s 63us/sample - loss: 0.6426 - accuracy: 0.7753 - val_loss: 0.5718 - val_accuracy: 0.7054\n",
      "Epoch 8/10\n",
      "4508/4508 [==============================] - 0s 63us/sample - loss: 0.6886 - accuracy: 0.7675 - val_loss: 0.4830 - val_accuracy: 0.7977\n",
      "Epoch 9/10\n",
      "4508/4508 [==============================] - 0s 61us/sample - loss: 0.6274 - accuracy: 0.7684 - val_loss: 1.3619 - val_accuracy: 0.7604\n",
      "Epoch 10/10\n",
      "4508/4508 [==============================] - 0s 63us/sample - loss: 0.6295 - accuracy: 0.7731 - val_loss: 0.5305 - val_accuracy: 0.7995\n",
      "Train on 5634 samples, validate on 1409 samples\n",
      "Epoch 1/10\n",
      "5634/5634 [==============================] - 1s 199us/sample - loss: 1.0665 - accuracy: 0.7144 - val_loss: 1.1983 - val_accuracy: 0.4053\n",
      "Epoch 2/10\n",
      "5634/5634 [==============================] - 0s 74us/sample - loss: 0.7589 - accuracy: 0.7194 - val_loss: 0.6197 - val_accuracy: 0.7779\n",
      "Epoch 3/10\n",
      "5634/5634 [==============================] - 0s 78us/sample - loss: 0.5376 - accuracy: 0.7659 - val_loss: 0.5729 - val_accuracy: 0.6402\n",
      "Epoch 4/10\n",
      "5634/5634 [==============================] - 0s 74us/sample - loss: 0.5113 - accuracy: 0.7732 - val_loss: 0.4761 - val_accuracy: 0.7850\n",
      "Epoch 5/10\n",
      "5634/5634 [==============================] - 0s 77us/sample - loss: 0.5843 - accuracy: 0.7719 - val_loss: 0.4872 - val_accuracy: 0.7949\n",
      "Epoch 6/10\n",
      "5634/5634 [==============================] - 0s 76us/sample - loss: 0.4737 - accuracy: 0.7852 - val_loss: 0.5167 - val_accuracy: 0.7019\n",
      "Epoch 7/10\n",
      "5634/5634 [==============================] - 0s 79us/sample - loss: 0.4978 - accuracy: 0.7749 - val_loss: 0.6890 - val_accuracy: 0.7850\n",
      "Epoch 8/10\n",
      "5634/5634 [==============================] - 0s 74us/sample - loss: 0.5085 - accuracy: 0.7765 - val_loss: 0.4388 - val_accuracy: 0.7892\n",
      "Epoch 9/10\n",
      "5634/5634 [==============================] - 0s 71us/sample - loss: 0.4609 - accuracy: 0.7852 - val_loss: 0.4719 - val_accuracy: 0.7814\n",
      "Epoch 10/10\n",
      "5634/5634 [==============================] - 0s 71us/sample - loss: 0.4779 - accuracy: 0.7819 - val_loss: 0.4713 - val_accuracy: 0.7956\n",
      "\n",
      "Best score: 0.7951155114846119\n",
      "Best params: {'additional_layers': 4, 'nodes_per_layer': 52}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# tune number of layers\n",
    "params = {\n",
    "    'nodes_per_layer': [52],\n",
    "    'additional_layers': [12, 8, 4, 0]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=KerasClassifier(build_fn=create_model),\n",
    "    param_grid=params,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=1,\n",
    "    cv=5,\n",
    ")\n",
    "\n",
    "grid.fit(X, y, callbacks=[stop], epochs=10, validation_split=0.2)\n",
    "\n",
    "print()\n",
    "print('Best score:', grid.best_score_)\n",
    "print('Best params:', grid.best_params_)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4507/4507 [==============================] - 2s 350us/sample - loss: 1.5032 - accuracy: 0.7011 - val_loss: 0.6414 - val_accuracy: 0.6371\n",
      "Epoch 2/10\n",
      "4507/4507 [==============================] - 1s 228us/sample - loss: 0.6706 - accuracy: 0.7506 - val_loss: 0.5083 - val_accuracy: 0.7853\n",
      "Epoch 3/10\n",
      "4507/4507 [==============================] - 1s 227us/sample - loss: 0.5644 - accuracy: 0.7562 - val_loss: 0.6821 - val_accuracy: 0.7853\n",
      "Epoch 4/10\n",
      "4507/4507 [==============================] - 1s 214us/sample - loss: 0.5786 - accuracy: 0.7637 - val_loss: 0.9773 - val_accuracy: 0.7844\n",
      "Epoch 5/10\n",
      "4507/4507 [==============================] - 1s 212us/sample - loss: 0.5529 - accuracy: 0.7584 - val_loss: 0.4925 - val_accuracy: 0.7888\n",
      "Epoch 6/10\n",
      "4507/4507 [==============================] - 1s 213us/sample - loss: 0.4923 - accuracy: 0.7732 - val_loss: 0.4514 - val_accuracy: 0.7933\n",
      "Epoch 7/10\n",
      "4507/4507 [==============================] - 1s 211us/sample - loss: 0.4758 - accuracy: 0.7801 - val_loss: 0.4446 - val_accuracy: 0.7844\n",
      "Epoch 8/10\n",
      "4507/4507 [==============================] - 1s 210us/sample - loss: 0.4818 - accuracy: 0.7792 - val_loss: 0.5399 - val_accuracy: 0.7924\n",
      "Epoch 9/10\n",
      "4507/4507 [==============================] - 1s 210us/sample - loss: 0.4801 - accuracy: 0.7815 - val_loss: 0.5394 - val_accuracy: 0.7853\n",
      "Epoch 10/10\n",
      "4507/4507 [==============================] - 1s 212us/sample - loss: 0.4630 - accuracy: 0.7866 - val_loss: 0.4552 - val_accuracy: 0.7870\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4507/4507 [==============================] - 2s 379us/sample - loss: 1.0871 - accuracy: 0.7162 - val_loss: 1.0827 - val_accuracy: 0.7817\n",
      "Epoch 2/10\n",
      "4507/4507 [==============================] - 1s 229us/sample - loss: 0.6352 - accuracy: 0.7564 - val_loss: 0.5501 - val_accuracy: 0.7906\n",
      "Epoch 3/10\n",
      "4507/4507 [==============================] - 1s 224us/sample - loss: 0.5591 - accuracy: 0.7650 - val_loss: 0.7212 - val_accuracy: 0.7906\n",
      "Epoch 4/10\n",
      "4507/4507 [==============================] - 1s 221us/sample - loss: 0.5736 - accuracy: 0.7681 - val_loss: 0.4775 - val_accuracy: 0.7862\n",
      "Epoch 5/10\n",
      "4507/4507 [==============================] - 1s 221us/sample - loss: 0.5044 - accuracy: 0.7772 - val_loss: 0.4649 - val_accuracy: 0.7853\n",
      "Epoch 6/10\n",
      "4507/4507 [==============================] - 1s 223us/sample - loss: 0.4760 - accuracy: 0.7834 - val_loss: 0.4524 - val_accuracy: 0.7933\n",
      "Epoch 7/10\n",
      "4507/4507 [==============================] - 1s 240us/sample - loss: 0.4764 - accuracy: 0.7841 - val_loss: 0.4628 - val_accuracy: 0.7924\n",
      "Epoch 8/10\n",
      "4507/4507 [==============================] - 1s 241us/sample - loss: 0.4682 - accuracy: 0.7908 - val_loss: 0.4463 - val_accuracy: 0.7906\n",
      "Epoch 9/10\n",
      "4507/4507 [==============================] - 1s 224us/sample - loss: 0.4598 - accuracy: 0.7890 - val_loss: 0.5306 - val_accuracy: 0.7915\n",
      "Epoch 10/10\n",
      "4507/4507 [==============================] - 1s 227us/sample - loss: 0.4628 - accuracy: 0.7832 - val_loss: 0.4572 - val_accuracy: 0.7888\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4507/4507 [==============================] - 2s 372us/sample - loss: 1.0020 - accuracy: 0.7193 - val_loss: 0.5514 - val_accuracy: 0.7737\n",
      "Epoch 2/10\n",
      "4507/4507 [==============================] - 1s 224us/sample - loss: 0.5853 - accuracy: 0.7604 - val_loss: 0.5467 - val_accuracy: 0.7764\n",
      "Epoch 3/10\n",
      "4507/4507 [==============================] - 1s 215us/sample - loss: 0.5542 - accuracy: 0.7653 - val_loss: 0.4992 - val_accuracy: 0.7879\n",
      "Epoch 4/10\n",
      "4507/4507 [==============================] - 1s 213us/sample - loss: 0.5215 - accuracy: 0.7724 - val_loss: 0.5033 - val_accuracy: 0.7791\n",
      "Epoch 5/10\n",
      "4507/4507 [==============================] - 1s 216us/sample - loss: 0.5037 - accuracy: 0.7826 - val_loss: 0.4841 - val_accuracy: 0.7897\n",
      "Epoch 6/10\n",
      "4507/4507 [==============================] - 1s 209us/sample - loss: 0.5052 - accuracy: 0.7766 - val_loss: 0.4857 - val_accuracy: 0.7879\n",
      "Epoch 7/10\n",
      "4507/4507 [==============================] - 1s 212us/sample - loss: 0.5023 - accuracy: 0.7790 - val_loss: 0.4902 - val_accuracy: 0.7862\n",
      "Epoch 8/10\n",
      "4507/4507 [==============================] - 1s 209us/sample - loss: 0.4977 - accuracy: 0.7810 - val_loss: 0.4816 - val_accuracy: 0.7870\n",
      "Epoch 9/10\n",
      "4507/4507 [==============================] - 1s 209us/sample - loss: 0.4868 - accuracy: 0.7832 - val_loss: 0.5003 - val_accuracy: 0.7702\n",
      "Epoch 10/10\n",
      "4507/4507 [==============================] - 1s 209us/sample - loss: 0.4887 - accuracy: 0.7799 - val_loss: 0.4711 - val_accuracy: 0.7906\n",
      "Train on 4508 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4508/4508 [==============================] - 2s 339us/sample - loss: 1.0398 - accuracy: 0.7252 - val_loss: 0.5779 - val_accuracy: 0.7897\n",
      "Epoch 2/10\n",
      "4508/4508 [==============================] - 1s 209us/sample - loss: 0.7404 - accuracy: 0.7407 - val_loss: 0.5417 - val_accuracy: 0.7924\n",
      "Epoch 3/10\n",
      "4508/4508 [==============================] - 1s 212us/sample - loss: 0.5614 - accuracy: 0.7584 - val_loss: 0.6000 - val_accuracy: 0.5892\n",
      "Epoch 4/10\n",
      "4508/4508 [==============================] - 1s 210us/sample - loss: 0.5410 - accuracy: 0.7642 - val_loss: 0.5214 - val_accuracy: 0.7063\n",
      "Epoch 5/10\n",
      "4508/4508 [==============================] - 1s 209us/sample - loss: 0.5086 - accuracy: 0.7691 - val_loss: 0.4576 - val_accuracy: 0.7924\n",
      "Epoch 6/10\n",
      "4508/4508 [==============================] - 1s 210us/sample - loss: 0.4930 - accuracy: 0.7728 - val_loss: 0.4498 - val_accuracy: 0.7835\n",
      "Epoch 7/10\n",
      "4508/4508 [==============================] - 1s 213us/sample - loss: 0.4959 - accuracy: 0.7693 - val_loss: 0.7275 - val_accuracy: 0.5750\n",
      "Epoch 8/10\n",
      "4508/4508 [==============================] - 1s 209us/sample - loss: 0.4821 - accuracy: 0.7737 - val_loss: 0.4589 - val_accuracy: 0.7897\n",
      "Epoch 9/10\n",
      "4508/4508 [==============================] - 1s 210us/sample - loss: 0.4638 - accuracy: 0.7811 - val_loss: 0.4514 - val_accuracy: 0.7950\n",
      "Epoch 10/10\n",
      "4508/4508 [==============================] - 1s 209us/sample - loss: 0.4774 - accuracy: 0.7788 - val_loss: 0.4490 - val_accuracy: 0.7995\n",
      "Train on 4508 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4508/4508 [==============================] - 2s 342us/sample - loss: 1.8088 - accuracy: 0.6912 - val_loss: 1.0542 - val_accuracy: 0.4729\n",
      "Epoch 2/10\n",
      "4508/4508 [==============================] - 1s 217us/sample - loss: 0.6495 - accuracy: 0.7555 - val_loss: 0.6770 - val_accuracy: 0.7808\n",
      "Epoch 3/10\n",
      "4508/4508 [==============================] - 1s 233us/sample - loss: 0.5663 - accuracy: 0.7640 - val_loss: 0.4876 - val_accuracy: 0.7853\n",
      "Epoch 4/10\n",
      "4508/4508 [==============================] - 1s 227us/sample - loss: 0.5022 - accuracy: 0.7757 - val_loss: 0.5381 - val_accuracy: 0.7879\n",
      "Epoch 5/10\n",
      "4508/4508 [==============================] - 1s 224us/sample - loss: 0.4904 - accuracy: 0.7786 - val_loss: 0.4802 - val_accuracy: 0.7853\n",
      "Epoch 6/10\n",
      "4508/4508 [==============================] - 1s 219us/sample - loss: 0.4928 - accuracy: 0.7811 - val_loss: 0.4485 - val_accuracy: 0.7941\n",
      "Epoch 7/10\n",
      "4508/4508 [==============================] - 1s 215us/sample - loss: 0.4956 - accuracy: 0.7724 - val_loss: 0.4695 - val_accuracy: 0.7870\n",
      "Epoch 8/10\n",
      "4508/4508 [==============================] - 1s 225us/sample - loss: 0.4709 - accuracy: 0.7808 - val_loss: 0.5236 - val_accuracy: 0.7879\n",
      "Epoch 9/10\n",
      "4508/4508 [==============================] - 1s 215us/sample - loss: 0.4680 - accuracy: 0.7864 - val_loss: 0.4582 - val_accuracy: 0.7888\n",
      "Epoch 10/10\n",
      "4508/4508 [==============================] - 1s 232us/sample - loss: 0.4573 - accuracy: 0.7879 - val_loss: 0.4817 - val_accuracy: 0.7879\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4507/4507 [==============================] - 1s 285us/sample - loss: 1.1585 - accuracy: 0.7027 - val_loss: 0.8874 - val_accuracy: 0.7915\n",
      "Epoch 2/10\n",
      "4507/4507 [==============================] - 1s 112us/sample - loss: 0.7384 - accuracy: 0.7377 - val_loss: 1.3468 - val_accuracy: 0.7817\n",
      "Epoch 3/10\n",
      "4507/4507 [==============================] - 0s 111us/sample - loss: 0.6890 - accuracy: 0.7477 - val_loss: 0.4910 - val_accuracy: 0.7924\n",
      "Epoch 4/10\n",
      "4507/4507 [==============================] - 1s 117us/sample - loss: 0.5527 - accuracy: 0.7686 - val_loss: 0.4951 - val_accuracy: 0.7595\n",
      "Epoch 5/10\n",
      "4507/4507 [==============================] - 1s 115us/sample - loss: 0.6633 - accuracy: 0.7524 - val_loss: 0.4918 - val_accuracy: 0.7870\n",
      "Epoch 6/10\n",
      "4507/4507 [==============================] - 1s 111us/sample - loss: 0.5277 - accuracy: 0.7635 - val_loss: 0.4575 - val_accuracy: 0.7853\n",
      "Epoch 7/10\n",
      "4507/4507 [==============================] - 0s 111us/sample - loss: 0.5461 - accuracy: 0.7675 - val_loss: 0.4476 - val_accuracy: 0.7906\n",
      "Epoch 8/10\n",
      "4507/4507 [==============================] - 1s 113us/sample - loss: 0.4851 - accuracy: 0.7801 - val_loss: 0.4581 - val_accuracy: 0.7941\n",
      "Epoch 9/10\n",
      "4507/4507 [==============================] - 0s 110us/sample - loss: 0.5179 - accuracy: 0.7710 - val_loss: 0.4582 - val_accuracy: 0.7941\n",
      "Epoch 10/10\n",
      "4507/4507 [==============================] - 1s 111us/sample - loss: 0.4806 - accuracy: 0.7766 - val_loss: 0.4806 - val_accuracy: 0.7782\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4507/4507 [==============================] - 1s 267us/sample - loss: 1.9544 - accuracy: 0.6965 - val_loss: 0.5865 - val_accuracy: 0.7711\n",
      "Epoch 2/10\n",
      "4507/4507 [==============================] - 0s 110us/sample - loss: 0.7172 - accuracy: 0.7377 - val_loss: 0.9159 - val_accuracy: 0.7870\n",
      "Epoch 3/10\n",
      "4507/4507 [==============================] - 0s 111us/sample - loss: 0.5889 - accuracy: 0.7597 - val_loss: 1.1620 - val_accuracy: 0.7826\n",
      "Epoch 4/10\n",
      "4507/4507 [==============================] - 1s 113us/sample - loss: 0.6272 - accuracy: 0.7515 - val_loss: 0.6153 - val_accuracy: 0.7817\n",
      "Epoch 5/10\n",
      "4507/4507 [==============================] - 0s 110us/sample - loss: 0.5664 - accuracy: 0.7593 - val_loss: 0.7353 - val_accuracy: 0.7888\n",
      "Epoch 6/10\n",
      "4507/4507 [==============================] - 1s 118us/sample - loss: 0.5998 - accuracy: 0.7546 - val_loss: 0.4702 - val_accuracy: 0.7862\n",
      "Epoch 7/10\n",
      "4507/4507 [==============================] - 1s 117us/sample - loss: 0.4850 - accuracy: 0.7799 - val_loss: 0.4847 - val_accuracy: 0.7959\n",
      "Epoch 8/10\n",
      "4507/4507 [==============================] - 1s 114us/sample - loss: 0.4819 - accuracy: 0.7832 - val_loss: 0.4763 - val_accuracy: 0.7959\n",
      "Epoch 9/10\n",
      "4507/4507 [==============================] - 0s 109us/sample - loss: 0.5661 - accuracy: 0.7664 - val_loss: 0.5064 - val_accuracy: 0.7888\n",
      "Epoch 10/10\n",
      "4507/4507 [==============================] - 0s 109us/sample - loss: 0.5332 - accuracy: 0.7673 - val_loss: 0.4667 - val_accuracy: 0.7933\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4507/4507 [==============================] - 1s 243us/sample - loss: 0.8912 - accuracy: 0.7195 - val_loss: 0.5231 - val_accuracy: 0.7799\n",
      "Epoch 2/10\n",
      "4507/4507 [==============================] - 0s 111us/sample - loss: 0.6086 - accuracy: 0.7579 - val_loss: 0.6323 - val_accuracy: 0.7817\n",
      "Epoch 3/10\n",
      "4507/4507 [==============================] - 1s 117us/sample - loss: 0.5584 - accuracy: 0.7688 - val_loss: 0.5513 - val_accuracy: 0.7870\n",
      "Epoch 4/10\n",
      "4507/4507 [==============================] - 0s 110us/sample - loss: 0.5002 - accuracy: 0.7826 - val_loss: 0.5927 - val_accuracy: 0.7870\n",
      "Epoch 5/10\n",
      "4507/4507 [==============================] - 0s 109us/sample - loss: 0.5167 - accuracy: 0.7726 - val_loss: 0.5051 - val_accuracy: 0.7924\n",
      "Epoch 6/10\n",
      "4507/4507 [==============================] - 1s 112us/sample - loss: 0.4751 - accuracy: 0.7828 - val_loss: 0.4787 - val_accuracy: 0.7933\n",
      "Epoch 7/10\n",
      "4507/4507 [==============================] - 1s 114us/sample - loss: 0.4778 - accuracy: 0.7744 - val_loss: 0.4585 - val_accuracy: 0.7933\n",
      "Epoch 8/10\n",
      "4507/4507 [==============================] - 0s 109us/sample - loss: 0.4958 - accuracy: 0.7744 - val_loss: 0.4770 - val_accuracy: 0.7844\n",
      "Epoch 9/10\n",
      "4507/4507 [==============================] - 1s 116us/sample - loss: 0.4891 - accuracy: 0.7812 - val_loss: 0.4448 - val_accuracy: 0.7968\n",
      "Train on 4508 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4508/4508 [==============================] - 1s 253us/sample - loss: 1.3471 - accuracy: 0.7008 - val_loss: 0.7864 - val_accuracy: 0.7409\n",
      "Epoch 2/10\n",
      "4508/4508 [==============================] - 0s 111us/sample - loss: 0.8103 - accuracy: 0.7316 - val_loss: 0.7712 - val_accuracy: 0.7799\n",
      "Epoch 3/10\n",
      "4508/4508 [==============================] - 0s 111us/sample - loss: 0.7180 - accuracy: 0.7480 - val_loss: 0.5237 - val_accuracy: 0.7968\n",
      "Epoch 4/10\n",
      "4508/4508 [==============================] - 0s 110us/sample - loss: 0.6236 - accuracy: 0.7467 - val_loss: 0.8532 - val_accuracy: 0.7799\n",
      "Epoch 5/10\n",
      "4508/4508 [==============================] - 1s 111us/sample - loss: 0.5265 - accuracy: 0.7724 - val_loss: 0.4526 - val_accuracy: 0.7888\n",
      "Epoch 6/10\n",
      "4508/4508 [==============================] - 1s 112us/sample - loss: 0.5193 - accuracy: 0.7715 - val_loss: 0.5747 - val_accuracy: 0.7870\n",
      "Epoch 7/10\n",
      "4508/4508 [==============================] - 1s 112us/sample - loss: 0.5295 - accuracy: 0.7713 - val_loss: 0.4756 - val_accuracy: 0.7897\n",
      "Epoch 8/10\n",
      "4508/4508 [==============================] - 0s 110us/sample - loss: 0.4787 - accuracy: 0.7822 - val_loss: 0.4894 - val_accuracy: 0.7595\n",
      "Epoch 9/10\n",
      "4508/4508 [==============================] - 1s 114us/sample - loss: 0.5197 - accuracy: 0.7753 - val_loss: 0.4437 - val_accuracy: 0.7879\n",
      "Epoch 10/10\n",
      "4508/4508 [==============================] - 1s 121us/sample - loss: 0.4874 - accuracy: 0.7797 - val_loss: 0.4383 - val_accuracy: 0.7941\n",
      "Train on 4508 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4508/4508 [==============================] - 1s 274us/sample - loss: 2.9566 - accuracy: 0.7008 - val_loss: 0.5167 - val_accuracy: 0.7320\n",
      "Epoch 2/10\n",
      "4508/4508 [==============================] - 1s 114us/sample - loss: 0.8918 - accuracy: 0.7283 - val_loss: 1.3261 - val_accuracy: 0.7587\n",
      "Epoch 3/10\n",
      "4508/4508 [==============================] - 1s 125us/sample - loss: 0.6689 - accuracy: 0.7465 - val_loss: 0.8946 - val_accuracy: 0.5643\n",
      "Epoch 4/10\n",
      "4508/4508 [==============================] - 1s 112us/sample - loss: 0.5762 - accuracy: 0.7644 - val_loss: 0.6802 - val_accuracy: 0.7799\n",
      "Epoch 5/10\n",
      "4508/4508 [==============================] - 0s 109us/sample - loss: 0.6741 - accuracy: 0.7591 - val_loss: 0.5156 - val_accuracy: 0.7950\n",
      "Epoch 6/10\n",
      "4508/4508 [==============================] - 0s 110us/sample - loss: 0.5671 - accuracy: 0.7713 - val_loss: 0.7690 - val_accuracy: 0.7879\n",
      "Epoch 7/10\n",
      "4508/4508 [==============================] - 0s 111us/sample - loss: 0.5852 - accuracy: 0.7624 - val_loss: 0.4679 - val_accuracy: 0.7844\n",
      "Epoch 8/10\n",
      "4508/4508 [==============================] - 0s 108us/sample - loss: 0.5287 - accuracy: 0.7693 - val_loss: 0.5907 - val_accuracy: 0.6610\n",
      "Epoch 9/10\n",
      "4508/4508 [==============================] - 0s 110us/sample - loss: 0.4821 - accuracy: 0.7835 - val_loss: 0.4564 - val_accuracy: 0.7924\n",
      "Epoch 10/10\n",
      "4508/4508 [==============================] - 1s 111us/sample - loss: 0.4781 - accuracy: 0.7813 - val_loss: 0.4845 - val_accuracy: 0.7941\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4507/4507 [==============================] - 1s 186us/sample - loss: 2.4873 - accuracy: 0.6670 - val_loss: 0.7081 - val_accuracy: 0.4845\n",
      "Epoch 2/10\n",
      "4507/4507 [==============================] - 0s 48us/sample - loss: 0.9615 - accuracy: 0.6672 - val_loss: 2.5902 - val_accuracy: 0.7702\n",
      "Epoch 3/10\n",
      "4507/4507 [==============================] - 0s 48us/sample - loss: 1.0945 - accuracy: 0.7098 - val_loss: 1.7276 - val_accuracy: 0.3283\n",
      "Epoch 4/10\n",
      "4507/4507 [==============================] - 0s 48us/sample - loss: 0.7645 - accuracy: 0.7318 - val_loss: 0.5229 - val_accuracy: 0.7888\n",
      "Epoch 5/10\n",
      "4507/4507 [==============================] - 0s 48us/sample - loss: 0.5973 - accuracy: 0.7586 - val_loss: 0.4733 - val_accuracy: 0.7968\n",
      "Epoch 6/10\n",
      "4507/4507 [==============================] - 0s 48us/sample - loss: 0.8830 - accuracy: 0.7335 - val_loss: 0.5874 - val_accuracy: 0.7853\n",
      "Epoch 7/10\n",
      "4507/4507 [==============================] - 0s 48us/sample - loss: 0.5518 - accuracy: 0.7657 - val_loss: 0.5200 - val_accuracy: 0.7720\n",
      "Epoch 8/10\n",
      "4507/4507 [==============================] - 0s 53us/sample - loss: 0.5975 - accuracy: 0.7528 - val_loss: 0.6737 - val_accuracy: 0.7879\n",
      "Epoch 9/10\n",
      "4507/4507 [==============================] - 0s 47us/sample - loss: 0.4971 - accuracy: 0.7797 - val_loss: 0.4780 - val_accuracy: 0.7933\n",
      "Epoch 10/10\n",
      "4507/4507 [==============================] - 0s 47us/sample - loss: 0.5275 - accuracy: 0.7790 - val_loss: 0.6109 - val_accuracy: 0.6362\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4507/4507 [==============================] - 1s 196us/sample - loss: 1.8147 - accuracy: 0.6856 - val_loss: 0.5902 - val_accuracy: 0.7072\n",
      "Epoch 2/10\n",
      "4507/4507 [==============================] - 0s 49us/sample - loss: 0.7971 - accuracy: 0.7062 - val_loss: 1.2301 - val_accuracy: 0.7808\n",
      "Epoch 3/10\n",
      "4507/4507 [==============================] - 0s 48us/sample - loss: 0.7691 - accuracy: 0.7400 - val_loss: 0.8064 - val_accuracy: 0.5537\n",
      "Epoch 4/10\n",
      "4507/4507 [==============================] - 0s 47us/sample - loss: 0.6285 - accuracy: 0.7499 - val_loss: 0.4739 - val_accuracy: 0.7941\n",
      "Epoch 5/10\n",
      "4507/4507 [==============================] - 0s 47us/sample - loss: 0.5325 - accuracy: 0.7688 - val_loss: 0.6609 - val_accuracy: 0.7879\n",
      "Epoch 6/10\n",
      "4507/4507 [==============================] - 0s 47us/sample - loss: 0.6649 - accuracy: 0.7519 - val_loss: 0.5279 - val_accuracy: 0.7968\n",
      "Epoch 7/10\n",
      "4507/4507 [==============================] - 0s 48us/sample - loss: 0.6004 - accuracy: 0.7564 - val_loss: 0.6706 - val_accuracy: 0.7897\n",
      "Epoch 8/10\n",
      "4507/4507 [==============================] - 0s 48us/sample - loss: 0.5607 - accuracy: 0.7595 - val_loss: 1.0916 - val_accuracy: 0.7844\n",
      "Epoch 9/10\n",
      "4507/4507 [==============================] - 0s 48us/sample - loss: 0.5788 - accuracy: 0.7670 - val_loss: 0.4683 - val_accuracy: 0.7870\n",
      "Epoch 10/10\n",
      "4507/4507 [==============================] - 0s 51us/sample - loss: 0.5556 - accuracy: 0.7684 - val_loss: 0.6031 - val_accuracy: 0.7844\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4507/4507 [==============================] - 1s 185us/sample - loss: 2.1787 - accuracy: 0.6872 - val_loss: 1.0673 - val_accuracy: 0.7764\n",
      "Epoch 2/10\n",
      "4507/4507 [==============================] - 0s 51us/sample - loss: 1.0039 - accuracy: 0.7111 - val_loss: 0.5201 - val_accuracy: 0.7365\n",
      "Epoch 3/10\n",
      "4507/4507 [==============================] - 0s 48us/sample - loss: 0.6790 - accuracy: 0.7391 - val_loss: 0.4982 - val_accuracy: 0.7542\n",
      "Epoch 4/10\n",
      "4507/4507 [==============================] - 0s 52us/sample - loss: 0.7287 - accuracy: 0.7393 - val_loss: 1.4312 - val_accuracy: 0.7835\n",
      "Epoch 5/10\n",
      "4507/4507 [==============================] - 0s 51us/sample - loss: 0.5969 - accuracy: 0.7568 - val_loss: 0.4661 - val_accuracy: 0.7959\n",
      "Epoch 6/10\n",
      "4507/4507 [==============================] - 0s 51us/sample - loss: 0.5999 - accuracy: 0.7579 - val_loss: 0.9611 - val_accuracy: 0.7853\n",
      "Epoch 7/10\n",
      "4507/4507 [==============================] - 0s 52us/sample - loss: 0.6222 - accuracy: 0.7588 - val_loss: 0.5358 - val_accuracy: 0.7986\n",
      "Epoch 8/10\n",
      "4507/4507 [==============================] - 0s 52us/sample - loss: 0.5581 - accuracy: 0.7708 - val_loss: 0.5755 - val_accuracy: 0.7906\n",
      "Epoch 9/10\n",
      "4507/4507 [==============================] - 0s 49us/sample - loss: 0.6260 - accuracy: 0.7573 - val_loss: 0.4660 - val_accuracy: 0.7764\n",
      "Epoch 10/10\n",
      "4507/4507 [==============================] - 0s 49us/sample - loss: 0.4766 - accuracy: 0.7874 - val_loss: 0.4691 - val_accuracy: 0.7906\n",
      "Train on 4508 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4508/4508 [==============================] - 1s 183us/sample - loss: 4.9408 - accuracy: 0.6799 - val_loss: 0.6761 - val_accuracy: 0.5599\n",
      "Epoch 2/10\n",
      "4508/4508 [==============================] - 0s 49us/sample - loss: 0.7816 - accuracy: 0.7296 - val_loss: 0.5840 - val_accuracy: 0.7862\n",
      "Epoch 3/10\n",
      "4508/4508 [==============================] - 0s 48us/sample - loss: 0.7393 - accuracy: 0.7385 - val_loss: 0.7392 - val_accuracy: 0.5652\n",
      "Epoch 4/10\n",
      "4508/4508 [==============================] - 0s 48us/sample - loss: 0.6293 - accuracy: 0.7535 - val_loss: 0.8063 - val_accuracy: 0.7879\n",
      "Epoch 5/10\n",
      "4508/4508 [==============================] - 0s 48us/sample - loss: 0.5653 - accuracy: 0.7595 - val_loss: 0.6748 - val_accuracy: 0.7888\n",
      "Epoch 6/10\n",
      "4508/4508 [==============================] - 0s 49us/sample - loss: 0.6218 - accuracy: 0.7595 - val_loss: 0.4683 - val_accuracy: 0.7959\n",
      "Epoch 7/10\n",
      "4508/4508 [==============================] - 0s 52us/sample - loss: 0.5827 - accuracy: 0.7591 - val_loss: 0.4960 - val_accuracy: 0.7986\n",
      "Epoch 8/10\n",
      "4508/4508 [==============================] - 0s 51us/sample - loss: 0.6514 - accuracy: 0.7633 - val_loss: 0.5137 - val_accuracy: 0.7294\n",
      "Epoch 9/10\n",
      "4508/4508 [==============================] - 0s 51us/sample - loss: 0.4734 - accuracy: 0.7859 - val_loss: 0.5243 - val_accuracy: 0.7897\n",
      "Epoch 10/10\n",
      "4508/4508 [==============================] - 0s 49us/sample - loss: 0.5929 - accuracy: 0.7638 - val_loss: 0.7718 - val_accuracy: 0.5785\n",
      "Train on 4508 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4508/4508 [==============================] - 1s 187us/sample - loss: 3.6680 - accuracy: 0.6881 - val_loss: 2.3468 - val_accuracy: 0.3993\n",
      "Epoch 2/10\n",
      "4508/4508 [==============================] - 0s 55us/sample - loss: 1.1004 - accuracy: 0.7072 - val_loss: 0.5346 - val_accuracy: 0.7746\n",
      "Epoch 3/10\n",
      "4508/4508 [==============================] - 0s 50us/sample - loss: 0.9536 - accuracy: 0.7227 - val_loss: 1.9903 - val_accuracy: 0.7560\n",
      "Epoch 4/10\n",
      "4508/4508 [==============================] - 0s 49us/sample - loss: 0.6904 - accuracy: 0.7524 - val_loss: 0.5377 - val_accuracy: 0.7862\n",
      "Epoch 5/10\n",
      "4508/4508 [==============================] - 0s 48us/sample - loss: 0.6018 - accuracy: 0.7558 - val_loss: 0.5227 - val_accuracy: 0.7906\n",
      "Epoch 6/10\n",
      "4508/4508 [==============================] - 0s 49us/sample - loss: 0.6298 - accuracy: 0.7562 - val_loss: 3.1740 - val_accuracy: 0.4508\n",
      "Epoch 7/10\n",
      "4508/4508 [==============================] - 0s 52us/sample - loss: 0.8242 - accuracy: 0.7391 - val_loss: 0.5444 - val_accuracy: 0.7933\n",
      "Epoch 8/10\n",
      "4508/4508 [==============================] - 0s 48us/sample - loss: 0.6107 - accuracy: 0.7600 - val_loss: 0.6558 - val_accuracy: 0.7915\n",
      "Epoch 9/10\n",
      "4508/4508 [==============================] - 0s 48us/sample - loss: 0.6317 - accuracy: 0.7549 - val_loss: 0.5785 - val_accuracy: 0.6779\n",
      "Epoch 10/10\n",
      "4508/4508 [==============================] - 0s 48us/sample - loss: 0.4906 - accuracy: 0.7799 - val_loss: 0.4552 - val_accuracy: 0.7941\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4507/4507 [==============================] - 1s 182us/sample - loss: 6.2147 - accuracy: 0.6388 - val_loss: 0.6201 - val_accuracy: 0.6247\n",
      "Epoch 2/10\n",
      "4507/4507 [==============================] - 0s 27us/sample - loss: 0.6705 - accuracy: 0.7076 - val_loss: 0.7081 - val_accuracy: 0.7755\n",
      "Epoch 3/10\n",
      "4507/4507 [==============================] - 0s 28us/sample - loss: 0.7267 - accuracy: 0.7508 - val_loss: 0.7075 - val_accuracy: 0.7755\n",
      "Epoch 4/10\n",
      "4507/4507 [==============================] - 0s 28us/sample - loss: 0.9531 - accuracy: 0.7291 - val_loss: 3.0983 - val_accuracy: 0.3691\n",
      "Epoch 5/10\n",
      "4507/4507 [==============================] - 0s 28us/sample - loss: 0.9179 - accuracy: 0.7275 - val_loss: 0.5524 - val_accuracy: 0.7933\n",
      "Epoch 6/10\n",
      "4507/4507 [==============================] - 0s 27us/sample - loss: 0.5565 - accuracy: 0.7597 - val_loss: 0.4876 - val_accuracy: 0.7835\n",
      "Epoch 7/10\n",
      "4507/4507 [==============================] - 0s 27us/sample - loss: 0.6202 - accuracy: 0.7471 - val_loss: 0.6906 - val_accuracy: 0.7897\n",
      "Epoch 8/10\n",
      "4507/4507 [==============================] - 0s 27us/sample - loss: 0.5317 - accuracy: 0.7644 - val_loss: 0.5801 - val_accuracy: 0.7888\n",
      "Epoch 9/10\n",
      "4507/4507 [==============================] - 0s 27us/sample - loss: 0.7132 - accuracy: 0.7479 - val_loss: 1.2617 - val_accuracy: 0.7791\n",
      "Epoch 10/10\n",
      "4507/4507 [==============================] - 0s 29us/sample - loss: 0.9669 - accuracy: 0.7506 - val_loss: 0.8595 - val_accuracy: 0.7879\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4507/4507 [==============================] - 1s 167us/sample - loss: 4.0011 - accuracy: 0.6827 - val_loss: 0.5297 - val_accuracy: 0.7391\n",
      "Epoch 2/10\n",
      "4507/4507 [==============================] - 0s 28us/sample - loss: 0.5454 - accuracy: 0.7437 - val_loss: 0.6487 - val_accuracy: 0.7853\n",
      "Epoch 3/10\n",
      "4507/4507 [==============================] - 0s 27us/sample - loss: 0.7350 - accuracy: 0.7386 - val_loss: 0.4928 - val_accuracy: 0.7728\n",
      "Epoch 4/10\n",
      "4507/4507 [==============================] - 0s 27us/sample - loss: 0.8510 - accuracy: 0.7211 - val_loss: 0.7885 - val_accuracy: 0.7853\n",
      "Epoch 5/10\n",
      "4507/4507 [==============================] - 0s 27us/sample - loss: 0.5564 - accuracy: 0.7566 - val_loss: 4.0525 - val_accuracy: 0.3319\n",
      "Epoch 6/10\n",
      "4507/4507 [==============================] - 0s 27us/sample - loss: 1.0844 - accuracy: 0.7169 - val_loss: 0.7728 - val_accuracy: 0.7746\n",
      "Epoch 7/10\n",
      "4507/4507 [==============================] - 0s 29us/sample - loss: 0.5406 - accuracy: 0.7777 - val_loss: 0.4796 - val_accuracy: 0.7968\n",
      "Epoch 8/10\n",
      "4507/4507 [==============================] - 0s 30us/sample - loss: 0.5049 - accuracy: 0.7735 - val_loss: 0.6876 - val_accuracy: 0.5989\n",
      "Epoch 9/10\n",
      "4507/4507 [==============================] - 0s 27us/sample - loss: 0.5357 - accuracy: 0.7615 - val_loss: 1.5267 - val_accuracy: 0.4783\n",
      "Epoch 10/10\n",
      "4507/4507 [==============================] - 0s 27us/sample - loss: 0.7199 - accuracy: 0.7484 - val_loss: 0.5232 - val_accuracy: 0.7303\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4507/4507 [==============================] - 1s 173us/sample - loss: 4.1370 - accuracy: 0.6583 - val_loss: 5.8847 - val_accuracy: 0.7640\n",
      "Epoch 2/10\n",
      "4507/4507 [==============================] - 0s 28us/sample - loss: 1.8388 - accuracy: 0.6767 - val_loss: 0.5908 - val_accuracy: 0.7294\n",
      "Epoch 3/10\n",
      "4507/4507 [==============================] - 0s 27us/sample - loss: 1.1978 - accuracy: 0.6991 - val_loss: 2.9590 - val_accuracy: 0.3505\n",
      "Epoch 4/10\n",
      "4507/4507 [==============================] - 0s 27us/sample - loss: 1.4501 - accuracy: 0.7025 - val_loss: 0.9413 - val_accuracy: 0.4880\n",
      "Epoch 5/10\n",
      "4507/4507 [==============================] - 0s 27us/sample - loss: 0.7528 - accuracy: 0.7293 - val_loss: 0.4906 - val_accuracy: 0.7773\n",
      "Epoch 6/10\n",
      "4507/4507 [==============================] - 0s 29us/sample - loss: 0.7123 - accuracy: 0.7293 - val_loss: 0.7259 - val_accuracy: 0.7906\n",
      "Epoch 7/10\n",
      "4507/4507 [==============================] - 0s 31us/sample - loss: 0.7382 - accuracy: 0.7360 - val_loss: 0.5157 - val_accuracy: 0.7924\n",
      "Epoch 8/10\n",
      "4507/4507 [==============================] - 0s 30us/sample - loss: 0.5380 - accuracy: 0.7657 - val_loss: 0.7618 - val_accuracy: 0.7888\n",
      "Epoch 9/10\n",
      "4507/4507 [==============================] - 0s 27us/sample - loss: 0.5354 - accuracy: 0.7735 - val_loss: 0.6649 - val_accuracy: 0.7888\n",
      "Epoch 10/10\n",
      "4507/4507 [==============================] - 0s 27us/sample - loss: 0.6047 - accuracy: 0.7615 - val_loss: 0.4745 - val_accuracy: 0.7693\n",
      "Train on 4508 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4508/4508 [==============================] - 1s 183us/sample - loss: 1.9850 - accuracy: 0.6877 - val_loss: 1.0360 - val_accuracy: 0.4392\n",
      "Epoch 2/10\n",
      "4508/4508 [==============================] - 0s 29us/sample - loss: 1.1566 - accuracy: 0.7041 - val_loss: 3.3418 - val_accuracy: 0.7693\n",
      "Epoch 3/10\n",
      "4508/4508 [==============================] - 0s 28us/sample - loss: 1.0622 - accuracy: 0.7223 - val_loss: 0.6626 - val_accuracy: 0.7711\n",
      "Epoch 4/10\n",
      "4508/4508 [==============================] - 0s 28us/sample - loss: 0.9527 - accuracy: 0.7376 - val_loss: 0.7250 - val_accuracy: 0.7853\n",
      "Epoch 5/10\n",
      "4508/4508 [==============================] - 0s 31us/sample - loss: 1.1111 - accuracy: 0.7425 - val_loss: 1.2173 - val_accuracy: 0.7915\n",
      "Epoch 6/10\n",
      "4508/4508 [==============================] - 0s 30us/sample - loss: 1.6405 - accuracy: 0.7152 - val_loss: 4.1797 - val_accuracy: 0.7826\n",
      "Epoch 7/10\n",
      "4508/4508 [==============================] - 0s 28us/sample - loss: 1.8846 - accuracy: 0.7216 - val_loss: 0.8768 - val_accuracy: 0.7968\n",
      "Epoch 8/10\n",
      "4508/4508 [==============================] - 0s 28us/sample - loss: 0.6792 - accuracy: 0.7567 - val_loss: 0.4646 - val_accuracy: 0.7995\n",
      "Epoch 9/10\n",
      "4508/4508 [==============================] - 0s 32us/sample - loss: 0.7167 - accuracy: 0.7491 - val_loss: 2.3492 - val_accuracy: 0.4614\n",
      "Epoch 10/10\n",
      "4508/4508 [==============================] - 0s 29us/sample - loss: 0.9709 - accuracy: 0.7427 - val_loss: 3.8420 - val_accuracy: 0.4153\n",
      "Train on 4508 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4508/4508 [==============================] - 1s 186us/sample - loss: 4.5190 - accuracy: 0.6668 - val_loss: 0.7204 - val_accuracy: 0.4011\n",
      "Epoch 2/10\n",
      "4508/4508 [==============================] - 0s 31us/sample - loss: 0.9887 - accuracy: 0.6688 - val_loss: 1.7944 - val_accuracy: 0.7569\n",
      "Epoch 3/10\n",
      "4508/4508 [==============================] - 0s 31us/sample - loss: 1.8371 - accuracy: 0.6764 - val_loss: 0.5551 - val_accuracy: 0.7409\n",
      "Epoch 4/10\n",
      "4508/4508 [==============================] - 0s 28us/sample - loss: 1.0185 - accuracy: 0.6954 - val_loss: 0.6841 - val_accuracy: 0.7799\n",
      "Epoch 5/10\n",
      "4508/4508 [==============================] - 0s 28us/sample - loss: 0.7825 - accuracy: 0.7169 - val_loss: 0.8178 - val_accuracy: 0.7773\n",
      "Epoch 6/10\n",
      "4508/4508 [==============================] - 0s 31us/sample - loss: 0.5775 - accuracy: 0.7609 - val_loss: 0.6733 - val_accuracy: 0.7560\n",
      "Epoch 7/10\n",
      "4508/4508 [==============================] - 0s 30us/sample - loss: 0.7403 - accuracy: 0.7243 - val_loss: 1.2451 - val_accuracy: 0.4570\n",
      "Epoch 8/10\n",
      "4508/4508 [==============================] - 0s 29us/sample - loss: 0.6687 - accuracy: 0.7489 - val_loss: 0.5076 - val_accuracy: 0.7702\n",
      "Epoch 9/10\n",
      "4508/4508 [==============================] - 0s 27us/sample - loss: 0.5186 - accuracy: 0.7731 - val_loss: 0.4868 - val_accuracy: 0.7897\n",
      "Epoch 10/10\n",
      "4508/4508 [==============================] - 0s 30us/sample - loss: 0.4878 - accuracy: 0.7806 - val_loss: 0.5903 - val_accuracy: 0.7702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:  1.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5634 samples, validate on 1409 samples\n",
      "Epoch 1/10\n",
      "5634/5634 [==============================] - 2s 342us/sample - loss: 1.6593 - accuracy: 0.7153 - val_loss: 0.8584 - val_accuracy: 0.7750\n",
      "Epoch 2/10\n",
      "5634/5634 [==============================] - 1s 216us/sample - loss: 0.6200 - accuracy: 0.7591 - val_loss: 0.6298 - val_accuracy: 0.7693\n",
      "Epoch 3/10\n",
      "5634/5634 [==============================] - 1s 215us/sample - loss: 0.5533 - accuracy: 0.7613 - val_loss: 0.4666 - val_accuracy: 0.7906\n",
      "Epoch 4/10\n",
      "5634/5634 [==============================] - 1s 210us/sample - loss: 0.4993 - accuracy: 0.7776 - val_loss: 0.4675 - val_accuracy: 0.7921\n",
      "Epoch 5/10\n",
      "5634/5634 [==============================] - 1s 211us/sample - loss: 0.5030 - accuracy: 0.7822 - val_loss: 0.6792 - val_accuracy: 0.7764\n",
      "Epoch 6/10\n",
      "5634/5634 [==============================] - 1s 210us/sample - loss: 0.4917 - accuracy: 0.7824 - val_loss: 0.4424 - val_accuracy: 0.7899\n",
      "Epoch 7/10\n",
      "5634/5634 [==============================] - 1s 220us/sample - loss: 0.4727 - accuracy: 0.7820 - val_loss: 0.4346 - val_accuracy: 0.7928\n",
      "Epoch 8/10\n",
      "5634/5634 [==============================] - 1s 210us/sample - loss: 0.4682 - accuracy: 0.7875 - val_loss: 0.4452 - val_accuracy: 0.7921\n",
      "Epoch 9/10\n",
      "5634/5634 [==============================] - 1s 210us/sample - loss: 0.4789 - accuracy: 0.7865 - val_loss: 0.4751 - val_accuracy: 0.7835\n",
      "Epoch 10/10\n",
      "5634/5634 [==============================] - 1s 210us/sample - loss: 0.4830 - accuracy: 0.7781 - val_loss: 0.4815 - val_accuracy: 0.7857\n",
      "\n",
      "Best score: 0.7870237595973933\n",
      "Best params: {'additional_layers': 4, 'batch_size': 10, 'nodes_per_layer': 52}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# tune batch size\n",
    "params = {\n",
    "    'nodes_per_layer': [52],\n",
    "    'additional_layers': [4],\n",
    "    'batch_size': [10, 20, 50, 100],\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=KerasClassifier(build_fn=create_model),\n",
    "    param_grid=params,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=1,\n",
    "    cv=5,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid.fit(X, y, callbacks=[stop], epochs=10, validation_split=0.2)\n",
    "\n",
    "print()\n",
    "print('Best score:', grid.best_score_)\n",
    "print('Best params:', grid.best_params_)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4507/4507 [==============================] - 2s 352us/sample - loss: 1.3949 - accuracy: 0.6936 - val_loss: 0.9318 - val_accuracy: 0.7693\n",
      "Epoch 2/10\n",
      "4507/4507 [==============================] - 1s 210us/sample - loss: 0.6691 - accuracy: 0.7440 - val_loss: 0.6893 - val_accuracy: 0.5634\n",
      "Epoch 3/10\n",
      "4507/4507 [==============================] - 1s 211us/sample - loss: 0.5589 - accuracy: 0.7575 - val_loss: 0.5956 - val_accuracy: 0.7817\n",
      "Epoch 4/10\n",
      "4507/4507 [==============================] - 1s 210us/sample - loss: 0.5245 - accuracy: 0.7657 - val_loss: 0.5198 - val_accuracy: 0.7817\n",
      "Epoch 5/10\n",
      "4507/4507 [==============================] - 1s 221us/sample - loss: 0.6015 - accuracy: 0.7570 - val_loss: 0.4974 - val_accuracy: 0.7844\n",
      "Epoch 6/10\n",
      "4507/4507 [==============================] - 1s 216us/sample - loss: 0.5129 - accuracy: 0.7655 - val_loss: 0.4861 - val_accuracy: 0.7631\n",
      "Epoch 7/10\n",
      "4507/4507 [==============================] - 1s 228us/sample - loss: 0.4895 - accuracy: 0.7783 - val_loss: 0.4872 - val_accuracy: 0.7888\n",
      "Epoch 8/10\n",
      "4507/4507 [==============================] - 1s 215us/sample - loss: 0.4681 - accuracy: 0.7841 - val_loss: 0.4401 - val_accuracy: 0.8004\n",
      "Epoch 9/10\n",
      "4507/4507 [==============================] - 1s 213us/sample - loss: 0.4594 - accuracy: 0.7815 - val_loss: 0.4789 - val_accuracy: 0.7853\n",
      "Epoch 10/10\n",
      "4507/4507 [==============================] - 1s 229us/sample - loss: 0.4868 - accuracy: 0.7763 - val_loss: 0.4633 - val_accuracy: 0.7941\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4507/4507 [==============================] - 2s 374us/sample - loss: 1.0744 - accuracy: 0.7142 - val_loss: 0.6308 - val_accuracy: 0.7870\n",
      "Epoch 2/10\n",
      "4507/4507 [==============================] - 1s 219us/sample - loss: 0.6593 - accuracy: 0.7464 - val_loss: 0.4920 - val_accuracy: 0.7915\n",
      "Epoch 3/10\n",
      "4507/4507 [==============================] - 1s 219us/sample - loss: 0.5638 - accuracy: 0.7570 - val_loss: 0.5684 - val_accuracy: 0.6761\n",
      "Epoch 4/10\n",
      "4507/4507 [==============================] - 1s 214us/sample - loss: 0.5129 - accuracy: 0.7768 - val_loss: 0.4707 - val_accuracy: 0.7924\n",
      "Epoch 5/10\n",
      "4507/4507 [==============================] - 1s 214us/sample - loss: 0.5148 - accuracy: 0.7719 - val_loss: 0.6020 - val_accuracy: 0.7897\n",
      "Epoch 6/10\n",
      "4507/4507 [==============================] - 1s 214us/sample - loss: 0.5065 - accuracy: 0.7761 - val_loss: 0.4473 - val_accuracy: 0.8004\n",
      "Epoch 7/10\n",
      "4507/4507 [==============================] - 1s 214us/sample - loss: 0.4799 - accuracy: 0.7826 - val_loss: 0.4356 - val_accuracy: 0.7950\n",
      "Epoch 8/10\n",
      "4507/4507 [==============================] - 1s 212us/sample - loss: 0.4837 - accuracy: 0.7834 - val_loss: 0.4443 - val_accuracy: 0.7906\n",
      "Epoch 9/10\n",
      "4507/4507 [==============================] - 1s 213us/sample - loss: 0.4756 - accuracy: 0.7888 - val_loss: 0.4470 - val_accuracy: 0.7968\n",
      "Epoch 10/10\n",
      "4507/4507 [==============================] - 1s 214us/sample - loss: 0.4714 - accuracy: 0.7799 - val_loss: 0.5020 - val_accuracy: 0.7844\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4507/4507 [==============================] - 2s 345us/sample - loss: 2.3306 - accuracy: 0.6971 - val_loss: 1.2345 - val_accuracy: 0.7471\n",
      "Epoch 2/10\n",
      "4507/4507 [==============================] - 1s 214us/sample - loss: 0.8297 - accuracy: 0.7322 - val_loss: 0.5281 - val_accuracy: 0.7968\n",
      "Epoch 3/10\n",
      "4507/4507 [==============================] - 1s 214us/sample - loss: 0.8770 - accuracy: 0.7460 - val_loss: 0.5074 - val_accuracy: 0.7835\n",
      "Epoch 4/10\n",
      "4507/4507 [==============================] - 1s 214us/sample - loss: 0.5509 - accuracy: 0.7646 - val_loss: 0.5252 - val_accuracy: 0.7853\n",
      "Epoch 5/10\n",
      "4507/4507 [==============================] - 1s 217us/sample - loss: 0.5533 - accuracy: 0.7637 - val_loss: 0.5379 - val_accuracy: 0.7870\n",
      "Epoch 6/10\n",
      "4507/4507 [==============================] - 1s 227us/sample - loss: 0.5375 - accuracy: 0.7708 - val_loss: 0.5427 - val_accuracy: 0.7036\n",
      "Epoch 7/10\n",
      "4507/4507 [==============================] - 1s 222us/sample - loss: 0.5195 - accuracy: 0.7790 - val_loss: 0.5064 - val_accuracy: 0.7862\n",
      "Epoch 8/10\n",
      "4507/4507 [==============================] - 1s 211us/sample - loss: 0.5144 - accuracy: 0.7750 - val_loss: 0.4573 - val_accuracy: 0.7879\n",
      "Epoch 9/10\n",
      "4507/4507 [==============================] - 1s 214us/sample - loss: 0.4879 - accuracy: 0.7837 - val_loss: 0.4591 - val_accuracy: 0.7853\n",
      "Epoch 10/10\n",
      "4507/4507 [==============================] - 1s 218us/sample - loss: 0.5514 - accuracy: 0.7679 - val_loss: 0.4621 - val_accuracy: 0.7968\n",
      "Train on 4508 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4508/4508 [==============================] - 2s 369us/sample - loss: 1.6664 - accuracy: 0.7076 - val_loss: 0.7244 - val_accuracy: 0.5209\n",
      "Epoch 2/10\n",
      "4508/4508 [==============================] - 1s 215us/sample - loss: 0.6734 - accuracy: 0.7385 - val_loss: 0.6579 - val_accuracy: 0.5821\n",
      "Epoch 3/10\n",
      "4508/4508 [==============================] - 1s 214us/sample - loss: 0.5944 - accuracy: 0.7489 - val_loss: 0.4824 - val_accuracy: 0.7933\n",
      "Epoch 4/10\n",
      "4508/4508 [==============================] - 1s 213us/sample - loss: 0.5062 - accuracy: 0.7742 - val_loss: 0.4517 - val_accuracy: 0.8039\n",
      "Epoch 5/10\n",
      "4508/4508 [==============================] - 1s 220us/sample - loss: 0.5146 - accuracy: 0.7684 - val_loss: 0.4911 - val_accuracy: 0.7915\n",
      "Epoch 6/10\n",
      "4508/4508 [==============================] - 1s 216us/sample - loss: 0.4925 - accuracy: 0.7793 - val_loss: 0.4426 - val_accuracy: 0.7924\n",
      "Epoch 7/10\n",
      "4508/4508 [==============================] - 1s 219us/sample - loss: 0.4799 - accuracy: 0.7826 - val_loss: 0.4475 - val_accuracy: 0.7924\n",
      "Epoch 8/10\n",
      "4508/4508 [==============================] - 1s 214us/sample - loss: 0.4808 - accuracy: 0.7768 - val_loss: 0.4512 - val_accuracy: 0.7879\n",
      "Epoch 9/10\n",
      "4508/4508 [==============================] - 1s 214us/sample - loss: 0.4634 - accuracy: 0.7882 - val_loss: 0.4511 - val_accuracy: 0.7959\n",
      "Epoch 10/10\n",
      "4508/4508 [==============================] - 1s 216us/sample - loss: 0.4652 - accuracy: 0.7828 - val_loss: 0.4492 - val_accuracy: 0.7977\n",
      "Train on 4508 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4508/4508 [==============================] - 2s 356us/sample - loss: 1.8851 - accuracy: 0.6877 - val_loss: 0.6211 - val_accuracy: 0.7409\n",
      "Epoch 2/10\n",
      "4508/4508 [==============================] - 1s 215us/sample - loss: 0.6980 - accuracy: 0.7398 - val_loss: 0.6821 - val_accuracy: 0.7560\n",
      "Epoch 3/10\n",
      "4508/4508 [==============================] - 1s 220us/sample - loss: 0.5522 - accuracy: 0.7697 - val_loss: 0.5001 - val_accuracy: 0.7897\n",
      "Epoch 4/10\n",
      "4508/4508 [==============================] - 1s 220us/sample - loss: 0.5137 - accuracy: 0.7695 - val_loss: 0.5483 - val_accuracy: 0.6930\n",
      "Epoch 5/10\n",
      "4508/4508 [==============================] - 1s 211us/sample - loss: 0.4923 - accuracy: 0.7762 - val_loss: 0.5474 - val_accuracy: 0.7808\n",
      "Epoch 6/10\n",
      "4508/4508 [==============================] - 1s 222us/sample - loss: 0.4737 - accuracy: 0.7795 - val_loss: 0.4576 - val_accuracy: 0.7853\n",
      "Epoch 7/10\n",
      "4508/4508 [==============================] - 1s 220us/sample - loss: 0.4642 - accuracy: 0.7877 - val_loss: 0.4505 - val_accuracy: 0.7959\n",
      "Epoch 8/10\n",
      "4508/4508 [==============================] - 1s 224us/sample - loss: 0.4621 - accuracy: 0.7842 - val_loss: 0.4670 - val_accuracy: 0.7924\n",
      "Epoch 9/10\n",
      "4508/4508 [==============================] - 1s 218us/sample - loss: 0.4786 - accuracy: 0.7795 - val_loss: 0.4571 - val_accuracy: 0.7897\n",
      "Epoch 10/10\n",
      "4508/4508 [==============================] - 1s 206us/sample - loss: 0.4636 - accuracy: 0.7868 - val_loss: 0.4637 - val_accuracy: 0.7835\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/20\n",
      "4507/4507 [==============================] - 2s 347us/sample - loss: 0.8281 - accuracy: 0.7091 - val_loss: 0.5119 - val_accuracy: 0.7870\n",
      "Epoch 2/20\n",
      "4507/4507 [==============================] - 1s 210us/sample - loss: 0.5706 - accuracy: 0.7639 - val_loss: 0.5271 - val_accuracy: 0.7950\n",
      "Epoch 3/20\n",
      "4507/4507 [==============================] - 1s 211us/sample - loss: 0.5418 - accuracy: 0.7659 - val_loss: 0.5345 - val_accuracy: 0.7950\n",
      "Epoch 4/20\n",
      "4507/4507 [==============================] - 1s 209us/sample - loss: 0.5470 - accuracy: 0.7666 - val_loss: 0.5359 - val_accuracy: 0.7169\n",
      "Epoch 5/20\n",
      "4507/4507 [==============================] - 1s 214us/sample - loss: 0.4836 - accuracy: 0.7766 - val_loss: 0.5433 - val_accuracy: 0.7870\n",
      "Epoch 6/20\n",
      "4507/4507 [==============================] - 1s 216us/sample - loss: 0.4729 - accuracy: 0.7815 - val_loss: 0.4473 - val_accuracy: 0.7853\n",
      "Epoch 7/20\n",
      "4507/4507 [==============================] - 1s 222us/sample - loss: 0.4832 - accuracy: 0.7770 - val_loss: 0.4405 - val_accuracy: 0.7897\n",
      "Epoch 8/20\n",
      "4507/4507 [==============================] - 1s 221us/sample - loss: 0.4694 - accuracy: 0.7803 - val_loss: 0.4610 - val_accuracy: 0.7941\n",
      "Epoch 9/20\n",
      "4507/4507 [==============================] - 1s 214us/sample - loss: 0.4736 - accuracy: 0.7806 - val_loss: 0.4532 - val_accuracy: 0.7853\n",
      "Epoch 10/20\n",
      "4507/4507 [==============================] - 1s 225us/sample - loss: 0.4877 - accuracy: 0.7763 - val_loss: 0.4638 - val_accuracy: 0.7950\n",
      "Epoch 11/20\n",
      "4507/4507 [==============================] - 1s 215us/sample - loss: 0.4662 - accuracy: 0.7815 - val_loss: 0.4340 - val_accuracy: 0.7853\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/20\n",
      "4507/4507 [==============================] - 2s 347us/sample - loss: 1.1438 - accuracy: 0.6974 - val_loss: 0.5928 - val_accuracy: 0.7888\n",
      "Epoch 2/20\n",
      "4507/4507 [==============================] - 1s 215us/sample - loss: 0.6712 - accuracy: 0.7426 - val_loss: 0.5468 - val_accuracy: 0.7897\n",
      "Epoch 3/20\n",
      "4507/4507 [==============================] - 1s 228us/sample - loss: 0.5357 - accuracy: 0.7602 - val_loss: 0.5314 - val_accuracy: 0.7799\n",
      "Epoch 4/20\n",
      "4507/4507 [==============================] - 1s 215us/sample - loss: 0.5900 - accuracy: 0.7617 - val_loss: 0.4990 - val_accuracy: 0.7720\n",
      "Epoch 5/20\n",
      "4507/4507 [==============================] - 1s 215us/sample - loss: 0.5308 - accuracy: 0.7748 - val_loss: 0.6011 - val_accuracy: 0.7915\n",
      "Epoch 6/20\n",
      "4507/4507 [==============================] - 1s 215us/sample - loss: 0.5219 - accuracy: 0.7721 - val_loss: 0.4710 - val_accuracy: 0.7915\n",
      "Epoch 7/20\n",
      "4507/4507 [==============================] - 1s 214us/sample - loss: 0.4793 - accuracy: 0.7812 - val_loss: 0.4485 - val_accuracy: 0.7897\n",
      "Epoch 8/20\n",
      "4507/4507 [==============================] - 1s 214us/sample - loss: 0.4885 - accuracy: 0.7786 - val_loss: 0.4679 - val_accuracy: 0.7941\n",
      "Epoch 9/20\n",
      "4507/4507 [==============================] - 1s 213us/sample - loss: 0.4699 - accuracy: 0.7846 - val_loss: 0.4561 - val_accuracy: 0.7933\n",
      "Epoch 10/20\n",
      "4507/4507 [==============================] - 1s 215us/sample - loss: 0.4934 - accuracy: 0.7748 - val_loss: 0.4751 - val_accuracy: 0.7897\n",
      "Epoch 11/20\n",
      "4507/4507 [==============================] - 1s 216us/sample - loss: 0.4670 - accuracy: 0.7886 - val_loss: 0.4580 - val_accuracy: 0.7853\n",
      "Epoch 12/20\n",
      "4507/4507 [==============================] - 1s 221us/sample - loss: 0.4686 - accuracy: 0.7861 - val_loss: 0.4549 - val_accuracy: 0.7879\n",
      "Epoch 13/20\n",
      "4507/4507 [==============================] - 1s 214us/sample - loss: 0.4748 - accuracy: 0.7841 - val_loss: 0.4600 - val_accuracy: 0.7924\n",
      "Epoch 14/20\n",
      "4507/4507 [==============================] - 1s 216us/sample - loss: 0.4684 - accuracy: 0.7866 - val_loss: 0.4611 - val_accuracy: 0.7808\n",
      "Epoch 15/20\n",
      "4507/4507 [==============================] - 1s 219us/sample - loss: 0.4843 - accuracy: 0.7881 - val_loss: 0.4971 - val_accuracy: 0.7791\n",
      "Epoch 16/20\n",
      "4507/4507 [==============================] - 1s 216us/sample - loss: 0.4752 - accuracy: 0.7905 - val_loss: 0.4594 - val_accuracy: 0.7941\n",
      "Epoch 17/20\n",
      "4507/4507 [==============================] - 1s 215us/sample - loss: 0.4936 - accuracy: 0.7806 - val_loss: 0.4557 - val_accuracy: 0.7870\n",
      "Epoch 18/20\n",
      "4507/4507 [==============================] - 1s 212us/sample - loss: 0.4691 - accuracy: 0.7890 - val_loss: 0.4564 - val_accuracy: 0.7844\n",
      "Epoch 19/20\n",
      "4507/4507 [==============================] - 1s 214us/sample - loss: 0.4663 - accuracy: 0.7899 - val_loss: 0.4582 - val_accuracy: 0.7924\n",
      "Epoch 20/20\n",
      "4507/4507 [==============================] - 1s 217us/sample - loss: 0.4672 - accuracy: 0.7872 - val_loss: 0.4367 - val_accuracy: 0.7950\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/20\n",
      "4507/4507 [==============================] - 2s 361us/sample - loss: 1.6481 - accuracy: 0.6829 - val_loss: 0.8687 - val_accuracy: 0.7799\n",
      "Epoch 2/20\n",
      "4507/4507 [==============================] - 1s 211us/sample - loss: 0.6958 - accuracy: 0.7493 - val_loss: 0.6090 - val_accuracy: 0.6575\n",
      "Epoch 3/20\n",
      "4507/4507 [==============================] - 1s 211us/sample - loss: 0.6720 - accuracy: 0.7499 - val_loss: 0.6323 - val_accuracy: 0.6495\n",
      "Epoch 4/20\n",
      "4507/4507 [==============================] - 1s 214us/sample - loss: 0.6217 - accuracy: 0.7573 - val_loss: 0.6246 - val_accuracy: 0.6557\n",
      "Epoch 5/20\n",
      "4507/4507 [==============================] - 1s 213us/sample - loss: 0.5121 - accuracy: 0.7721 - val_loss: 0.4727 - val_accuracy: 0.7862\n",
      "Epoch 6/20\n",
      "4507/4507 [==============================] - 1s 214us/sample - loss: 0.5627 - accuracy: 0.7670 - val_loss: 0.5377 - val_accuracy: 0.7950\n",
      "Epoch 7/20\n",
      "4507/4507 [==============================] - 1s 211us/sample - loss: 0.5154 - accuracy: 0.7770 - val_loss: 0.4879 - val_accuracy: 0.7888\n",
      "Epoch 8/20\n",
      "4507/4507 [==============================] - 1s 210us/sample - loss: 0.4850 - accuracy: 0.7821 - val_loss: 0.4412 - val_accuracy: 0.7941\n",
      "Epoch 9/20\n",
      "4507/4507 [==============================] - 1s 216us/sample - loss: 0.4634 - accuracy: 0.7886 - val_loss: 0.5096 - val_accuracy: 0.7897\n",
      "Epoch 10/20\n",
      "4507/4507 [==============================] - 1s 228us/sample - loss: 0.4630 - accuracy: 0.7912 - val_loss: 0.4883 - val_accuracy: 0.7879\n",
      "Epoch 11/20\n",
      "4507/4507 [==============================] - 1s 213us/sample - loss: 0.4654 - accuracy: 0.7892 - val_loss: 0.4442 - val_accuracy: 0.8030\n",
      "Epoch 12/20\n",
      "4507/4507 [==============================] - 1s 215us/sample - loss: 0.4630 - accuracy: 0.7881 - val_loss: 0.4719 - val_accuracy: 0.7915\n",
      "Epoch 13/20\n",
      "4507/4507 [==============================] - 1s 224us/sample - loss: 0.4728 - accuracy: 0.7841 - val_loss: 0.4459 - val_accuracy: 0.7915\n",
      "Epoch 14/20\n",
      "4507/4507 [==============================] - 1s 217us/sample - loss: 0.4748 - accuracy: 0.7837 - val_loss: 0.4715 - val_accuracy: 0.7897\n",
      "Epoch 15/20\n",
      "4507/4507 [==============================] - 1s 225us/sample - loss: 0.4587 - accuracy: 0.7943 - val_loss: 0.4633 - val_accuracy: 0.7924\n",
      "Epoch 16/20\n",
      "4507/4507 [==============================] - 1s 212us/sample - loss: 0.4794 - accuracy: 0.7781 - val_loss: 0.5347 - val_accuracy: 0.6992\n",
      "Epoch 17/20\n",
      "4507/4507 [==============================] - 1s 213us/sample - loss: 0.4685 - accuracy: 0.7834 - val_loss: 0.4812 - val_accuracy: 0.7915\n",
      "Epoch 18/20\n",
      "4507/4507 [==============================] - 1s 221us/sample - loss: 0.4576 - accuracy: 0.7905 - val_loss: 0.5197 - val_accuracy: 0.7924\n",
      "Epoch 19/20\n",
      "4507/4507 [==============================] - 1s 216us/sample - loss: 0.4549 - accuracy: 0.7914 - val_loss: 0.4332 - val_accuracy: 0.7941\n",
      "Epoch 20/20\n",
      "4507/4507 [==============================] - 1s 216us/sample - loss: 0.4676 - accuracy: 0.7883 - val_loss: 0.4329 - val_accuracy: 0.7959\n",
      "Train on 4508 samples, validate on 1127 samples\n",
      "Epoch 1/20\n",
      "4508/4508 [==============================] - 2s 372us/sample - loss: 1.7634 - accuracy: 0.7050 - val_loss: 1.2955 - val_accuracy: 0.7773\n",
      "Epoch 2/20\n",
      "4508/4508 [==============================] - 1s 231us/sample - loss: 0.6699 - accuracy: 0.7496 - val_loss: 0.6402 - val_accuracy: 0.7844\n",
      "Epoch 3/20\n",
      "4508/4508 [==============================] - 1s 229us/sample - loss: 0.5633 - accuracy: 0.7657 - val_loss: 0.5117 - val_accuracy: 0.7817\n",
      "Epoch 4/20\n",
      "4508/4508 [==============================] - 1s 225us/sample - loss: 0.5605 - accuracy: 0.7604 - val_loss: 1.3315 - val_accuracy: 0.7746\n",
      "Epoch 5/20\n",
      "4508/4508 [==============================] - 1s 212us/sample - loss: 0.5706 - accuracy: 0.7649 - val_loss: 0.5355 - val_accuracy: 0.7808\n",
      "Epoch 6/20\n",
      "4508/4508 [==============================] - 1s 211us/sample - loss: 0.4901 - accuracy: 0.7753 - val_loss: 0.4692 - val_accuracy: 0.7915\n",
      "Epoch 7/20\n",
      "4508/4508 [==============================] - 1s 214us/sample - loss: 0.4922 - accuracy: 0.7715 - val_loss: 0.4333 - val_accuracy: 0.7933\n",
      "Epoch 8/20\n",
      "4508/4508 [==============================] - 1s 217us/sample - loss: 0.4827 - accuracy: 0.7802 - val_loss: 0.4494 - val_accuracy: 0.7924\n",
      "Epoch 9/20\n",
      "4508/4508 [==============================] - 1s 226us/sample - loss: 0.4672 - accuracy: 0.7826 - val_loss: 0.4556 - val_accuracy: 0.7941\n",
      "Epoch 10/20\n",
      "4508/4508 [==============================] - 1s 227us/sample - loss: 0.4929 - accuracy: 0.7746 - val_loss: 0.4437 - val_accuracy: 0.7941\n",
      "Epoch 11/20\n",
      "4508/4508 [==============================] - 1s 228us/sample - loss: 0.4702 - accuracy: 0.7811 - val_loss: 0.4526 - val_accuracy: 0.7844\n",
      "Epoch 12/20\n",
      "4508/4508 [==============================] - 1s 229us/sample - loss: 0.4878 - accuracy: 0.7771 - val_loss: 0.4707 - val_accuracy: 0.7915\n",
      "Epoch 13/20\n",
      "4508/4508 [==============================] - 1s 224us/sample - loss: 0.4685 - accuracy: 0.7808 - val_loss: 0.4564 - val_accuracy: 0.7959\n",
      "Epoch 14/20\n",
      "4508/4508 [==============================] - 1s 226us/sample - loss: 0.4662 - accuracy: 0.7806 - val_loss: 0.4405 - val_accuracy: 0.7941\n",
      "Train on 4508 samples, validate on 1127 samples\n",
      "Epoch 1/20\n",
      "4508/4508 [==============================] - 3s 595us/sample - loss: 1.3858 - accuracy: 0.7039 - val_loss: 0.9514 - val_accuracy: 0.7755\n",
      "Epoch 2/20\n",
      "4508/4508 [==============================] - 1s 230us/sample - loss: 0.6099 - accuracy: 0.7657 - val_loss: 0.4855 - val_accuracy: 0.7897\n",
      "Epoch 3/20\n",
      "4508/4508 [==============================] - 1s 224us/sample - loss: 0.5910 - accuracy: 0.7544 - val_loss: 0.5033 - val_accuracy: 0.7737\n",
      "Epoch 4/20\n",
      "4508/4508 [==============================] - 1s 222us/sample - loss: 0.5018 - accuracy: 0.7726 - val_loss: 0.5159 - val_accuracy: 0.7879\n",
      "Epoch 5/20\n",
      "4508/4508 [==============================] - 1s 222us/sample - loss: 0.4818 - accuracy: 0.7833 - val_loss: 0.5572 - val_accuracy: 0.7152\n",
      "Epoch 6/20\n",
      "4508/4508 [==============================] - 1s 227us/sample - loss: 0.5175 - accuracy: 0.7669 - val_loss: 0.4715 - val_accuracy: 0.7879\n",
      "Epoch 7/20\n",
      "4508/4508 [==============================] - 1s 231us/sample - loss: 0.4859 - accuracy: 0.7828 - val_loss: 0.5003 - val_accuracy: 0.7657\n",
      "Epoch 8/20\n",
      "4508/4508 [==============================] - 1s 221us/sample - loss: 0.4828 - accuracy: 0.7804 - val_loss: 0.4721 - val_accuracy: 0.7915\n",
      "Epoch 9/20\n",
      "4508/4508 [==============================] - 1s 229us/sample - loss: 0.4697 - accuracy: 0.7930 - val_loss: 0.4632 - val_accuracy: 0.7924\n",
      "Epoch 10/20\n",
      "4508/4508 [==============================] - 1s 228us/sample - loss: 0.4625 - accuracy: 0.7899 - val_loss: 0.4504 - val_accuracy: 0.7924\n",
      "Epoch 11/20\n",
      "4508/4508 [==============================] - 1s 231us/sample - loss: 0.4881 - accuracy: 0.7771 - val_loss: 0.5061 - val_accuracy: 0.7879\n",
      "Epoch 12/20\n",
      "4508/4508 [==============================] - 1s 229us/sample - loss: 0.4737 - accuracy: 0.7864 - val_loss: 0.4547 - val_accuracy: 0.7959\n",
      "Epoch 13/20\n",
      "4508/4508 [==============================] - 1s 232us/sample - loss: 0.4564 - accuracy: 0.7882 - val_loss: 0.4566 - val_accuracy: 0.7915\n",
      "Epoch 14/20\n",
      "4508/4508 [==============================] - 1s 233us/sample - loss: 0.4526 - accuracy: 0.7933 - val_loss: 0.4619 - val_accuracy: 0.7933\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/50\n",
      "4507/4507 [==============================] - 2s 371us/sample - loss: 0.8852 - accuracy: 0.7100 - val_loss: 0.6344 - val_accuracy: 0.6424\n",
      "Epoch 2/50\n",
      "4507/4507 [==============================] - 1s 231us/sample - loss: 0.6438 - accuracy: 0.7391 - val_loss: 0.4857 - val_accuracy: 0.7853\n",
      "Epoch 3/50\n",
      "4507/4507 [==============================] - 1s 217us/sample - loss: 0.5219 - accuracy: 0.7624 - val_loss: 0.6822 - val_accuracy: 0.5785\n",
      "Epoch 4/50\n",
      "4507/4507 [==============================] - 1s 228us/sample - loss: 0.5038 - accuracy: 0.7719 - val_loss: 0.6463 - val_accuracy: 0.6122\n",
      "Epoch 5/50\n",
      "4507/4507 [==============================] - 1s 214us/sample - loss: 0.4865 - accuracy: 0.7741 - val_loss: 0.4813 - val_accuracy: 0.7959\n",
      "Epoch 6/50\n",
      "4507/4507 [==============================] - 1s 214us/sample - loss: 0.5113 - accuracy: 0.7675 - val_loss: 0.4707 - val_accuracy: 0.7959\n",
      "Epoch 7/50\n",
      "4507/4507 [==============================] - 1s 215us/sample - loss: 0.4804 - accuracy: 0.7779 - val_loss: 0.4975 - val_accuracy: 0.7879\n",
      "Epoch 8/50\n",
      "4507/4507 [==============================] - 1s 218us/sample - loss: 0.4784 - accuracy: 0.7786 - val_loss: 0.4358 - val_accuracy: 0.7924\n",
      "Epoch 9/50\n",
      "4507/4507 [==============================] - 1s 218us/sample - loss: 0.5037 - accuracy: 0.7724 - val_loss: 0.4617 - val_accuracy: 0.7950\n",
      "Epoch 10/50\n",
      "4507/4507 [==============================] - 1s 216us/sample - loss: 0.4690 - accuracy: 0.7779 - val_loss: 0.4464 - val_accuracy: 0.7853\n",
      "Epoch 11/50\n",
      "4507/4507 [==============================] - 1s 213us/sample - loss: 0.4619 - accuracy: 0.7810 - val_loss: 0.4436 - val_accuracy: 0.7941\n",
      "Epoch 12/50\n",
      "4507/4507 [==============================] - 1s 218us/sample - loss: 0.4662 - accuracy: 0.7830 - val_loss: 0.4800 - val_accuracy: 0.7853\n",
      "Epoch 13/50\n",
      "4507/4507 [==============================] - 1s 220us/sample - loss: 0.4589 - accuracy: 0.7834 - val_loss: 0.4482 - val_accuracy: 0.7950\n",
      "Epoch 14/50\n",
      "4507/4507 [==============================] - 1s 212us/sample - loss: 0.4641 - accuracy: 0.7877 - val_loss: 0.4413 - val_accuracy: 0.7862\n",
      "Epoch 15/50\n",
      "4507/4507 [==============================] - 1s 214us/sample - loss: 0.4513 - accuracy: 0.7890 - val_loss: 0.4412 - val_accuracy: 0.8039\n",
      "Epoch 16/50\n",
      "4507/4507 [==============================] - 1s 211us/sample - loss: 0.4634 - accuracy: 0.7846 - val_loss: 0.4380 - val_accuracy: 0.7959\n",
      "Epoch 17/50\n",
      "4507/4507 [==============================] - 1s 223us/sample - loss: 0.4478 - accuracy: 0.7910 - val_loss: 0.4386 - val_accuracy: 0.7941\n",
      "Epoch 18/50\n",
      "4507/4507 [==============================] - 1s 212us/sample - loss: 0.4571 - accuracy: 0.7886 - val_loss: 0.4420 - val_accuracy: 0.7924\n",
      "Epoch 19/50\n",
      "4507/4507 [==============================] - 1s 212us/sample - loss: 0.4462 - accuracy: 0.7888 - val_loss: 0.4433 - val_accuracy: 0.7995\n",
      "Epoch 20/50\n",
      "4507/4507 [==============================] - 1s 217us/sample - loss: 0.4505 - accuracy: 0.7872 - val_loss: 0.4538 - val_accuracy: 0.7995\n",
      "Epoch 21/50\n",
      "4507/4507 [==============================] - 1s 216us/sample - loss: 0.4716 - accuracy: 0.7879 - val_loss: 0.4518 - val_accuracy: 0.7995\n",
      "Epoch 22/50\n",
      "4507/4507 [==============================] - 1s 214us/sample - loss: 0.4474 - accuracy: 0.7925 - val_loss: 0.4554 - val_accuracy: 0.8012\n",
      "Epoch 23/50\n",
      "4507/4507 [==============================] - 1s 213us/sample - loss: 0.4521 - accuracy: 0.7914 - val_loss: 0.4330 - val_accuracy: 0.7950\n",
      "Epoch 24/50\n",
      "4507/4507 [==============================] - 1s 214us/sample - loss: 0.4454 - accuracy: 0.7917 - val_loss: 0.4576 - val_accuracy: 0.7915\n",
      "Epoch 25/50\n",
      "4507/4507 [==============================] - 1s 212us/sample - loss: 0.4456 - accuracy: 0.7917 - val_loss: 0.4419 - val_accuracy: 0.7915\n",
      "Epoch 26/50\n",
      "4507/4507 [==============================] - 1s 213us/sample - loss: 0.4404 - accuracy: 0.7957 - val_loss: 0.4432 - val_accuracy: 0.7888\n",
      "Epoch 27/50\n",
      "4507/4507 [==============================] - 1s 213us/sample - loss: 0.4418 - accuracy: 0.7903 - val_loss: 0.4425 - val_accuracy: 0.7986\n",
      "Epoch 28/50\n",
      "4507/4507 [==============================] - 1s 215us/sample - loss: 0.4478 - accuracy: 0.7910 - val_loss: 0.4431 - val_accuracy: 0.7959\n",
      "Epoch 29/50\n",
      "4507/4507 [==============================] - 1s 222us/sample - loss: 0.4484 - accuracy: 0.7905 - val_loss: 0.4484 - val_accuracy: 0.7924\n",
      "Epoch 30/50\n",
      "4507/4507 [==============================] - 1s 212us/sample - loss: 0.4455 - accuracy: 0.7894 - val_loss: 0.4307 - val_accuracy: 0.7968\n",
      "Epoch 31/50\n",
      "4507/4507 [==============================] - 1s 215us/sample - loss: 0.4369 - accuracy: 0.7939 - val_loss: 0.4465 - val_accuracy: 0.7959\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/50\n",
      "4507/4507 [==============================] - 2s 355us/sample - loss: 1.3534 - accuracy: 0.6911 - val_loss: 0.6529 - val_accuracy: 0.6823\n",
      "Epoch 2/50\n",
      "4507/4507 [==============================] - 1s 219us/sample - loss: 0.6292 - accuracy: 0.7477 - val_loss: 0.4918 - val_accuracy: 0.7959\n",
      "Epoch 3/50\n",
      "4507/4507 [==============================] - 1s 218us/sample - loss: 0.5800 - accuracy: 0.7608 - val_loss: 0.7805 - val_accuracy: 0.7808\n",
      "Epoch 4/50\n",
      "4507/4507 [==============================] - 1s 215us/sample - loss: 0.5148 - accuracy: 0.7737 - val_loss: 0.5000 - val_accuracy: 0.7870\n",
      "Epoch 5/50\n",
      "4507/4507 [==============================] - 1s 213us/sample - loss: 0.4910 - accuracy: 0.7799 - val_loss: 0.4726 - val_accuracy: 0.7853\n",
      "Epoch 6/50\n",
      "4507/4507 [==============================] - 1s 218us/sample - loss: 0.4967 - accuracy: 0.7752 - val_loss: 0.4846 - val_accuracy: 0.7906\n",
      "Epoch 7/50\n",
      "4507/4507 [==============================] - 1s 212us/sample - loss: 0.4993 - accuracy: 0.7759 - val_loss: 0.4488 - val_accuracy: 0.7950\n",
      "Epoch 8/50\n",
      "4507/4507 [==============================] - 1s 218us/sample - loss: 0.4784 - accuracy: 0.7797 - val_loss: 0.4496 - val_accuracy: 0.7870\n",
      "Epoch 9/50\n",
      "4507/4507 [==============================] - 1s 212us/sample - loss: 0.4641 - accuracy: 0.7886 - val_loss: 0.5039 - val_accuracy: 0.7862\n",
      "Epoch 10/50\n",
      "4507/4507 [==============================] - 1s 212us/sample - loss: 0.4667 - accuracy: 0.7795 - val_loss: 0.5406 - val_accuracy: 0.7844\n",
      "Epoch 11/50\n",
      "4507/4507 [==============================] - 1s 218us/sample - loss: 0.4635 - accuracy: 0.7839 - val_loss: 0.4364 - val_accuracy: 0.7933\n",
      "Epoch 12/50\n",
      "4507/4507 [==============================] - 1s 214us/sample - loss: 0.4818 - accuracy: 0.7848 - val_loss: 0.4403 - val_accuracy: 0.7933\n",
      "Epoch 13/50\n",
      "4507/4507 [==============================] - 1s 217us/sample - loss: 0.4608 - accuracy: 0.7861 - val_loss: 0.4436 - val_accuracy: 0.7906\n",
      "Epoch 14/50\n",
      "4507/4507 [==============================] - 1s 214us/sample - loss: 0.4577 - accuracy: 0.7912 - val_loss: 0.4786 - val_accuracy: 0.7941\n",
      "Epoch 15/50\n",
      "4507/4507 [==============================] - 1s 216us/sample - loss: 0.4559 - accuracy: 0.7905 - val_loss: 0.4709 - val_accuracy: 0.7897\n",
      "Epoch 16/50\n",
      "4507/4507 [==============================] - 1s 213us/sample - loss: 0.4625 - accuracy: 0.7886 - val_loss: 0.4313 - val_accuracy: 0.7959\n",
      "Epoch 17/50\n",
      "4507/4507 [==============================] - 1s 218us/sample - loss: 0.4512 - accuracy: 0.7930 - val_loss: 0.4719 - val_accuracy: 0.8004\n",
      "Epoch 18/50\n",
      "4507/4507 [==============================] - 1s 214us/sample - loss: 0.4531 - accuracy: 0.7934 - val_loss: 0.4605 - val_accuracy: 0.7986\n",
      "Epoch 19/50\n",
      "4507/4507 [==============================] - 1s 219us/sample - loss: 0.4581 - accuracy: 0.7899 - val_loss: 0.4435 - val_accuracy: 0.7879\n",
      "Epoch 20/50\n",
      "4507/4507 [==============================] - 1s 219us/sample - loss: 0.4527 - accuracy: 0.7897 - val_loss: 0.4554 - val_accuracy: 0.7870\n",
      "Epoch 21/50\n",
      "4507/4507 [==============================] - 1s 214us/sample - loss: 0.4470 - accuracy: 0.7954 - val_loss: 0.4617 - val_accuracy: 0.7941\n",
      "Epoch 22/50\n",
      "4507/4507 [==============================] - 1s 218us/sample - loss: 0.4492 - accuracy: 0.7939 - val_loss: 0.4585 - val_accuracy: 0.7924\n",
      "Epoch 23/50\n",
      "4507/4507 [==============================] - 1s 212us/sample - loss: 0.4528 - accuracy: 0.7985 - val_loss: 0.4478 - val_accuracy: 0.7977\n",
      "Epoch 24/50\n",
      "4507/4507 [==============================] - 1s 219us/sample - loss: 0.4481 - accuracy: 0.7903 - val_loss: 0.4322 - val_accuracy: 0.7968\n",
      "Epoch 25/50\n",
      "4507/4507 [==============================] - 1s 214us/sample - loss: 0.4446 - accuracy: 0.7948 - val_loss: 0.4326 - val_accuracy: 0.7995\n",
      "Epoch 26/50\n",
      "4507/4507 [==============================] - 1s 218us/sample - loss: 0.4411 - accuracy: 0.7948 - val_loss: 0.4727 - val_accuracy: 0.7906\n",
      "Epoch 27/50\n",
      "4507/4507 [==============================] - 1s 218us/sample - loss: 0.4572 - accuracy: 0.7943 - val_loss: 0.4772 - val_accuracy: 0.7915\n",
      "Epoch 28/50\n",
      "4507/4507 [==============================] - 1s 216us/sample - loss: 0.4480 - accuracy: 0.7948 - val_loss: 0.4956 - val_accuracy: 0.7941\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/50\n",
      "4507/4507 [==============================] - 2s 360us/sample - loss: 1.2786 - accuracy: 0.6963 - val_loss: 0.5675 - val_accuracy: 0.7959\n",
      "Epoch 2/50\n",
      "4507/4507 [==============================] - 1s 221us/sample - loss: 0.6272 - accuracy: 0.7579 - val_loss: 0.6529 - val_accuracy: 0.7835\n",
      "Epoch 3/50\n",
      "4507/4507 [==============================] - 1s 214us/sample - loss: 0.5711 - accuracy: 0.7653 - val_loss: 0.4578 - val_accuracy: 0.7879\n",
      "Epoch 4/50\n",
      "4507/4507 [==============================] - 1s 217us/sample - loss: 0.6634 - accuracy: 0.7535 - val_loss: 0.8070 - val_accuracy: 0.7888\n",
      "Epoch 5/50\n",
      "4507/4507 [==============================] - 1s 213us/sample - loss: 0.5571 - accuracy: 0.7737 - val_loss: 0.4928 - val_accuracy: 0.7862\n",
      "Epoch 6/50\n",
      "4507/4507 [==============================] - 1s 213us/sample - loss: 0.4980 - accuracy: 0.7839 - val_loss: 0.4677 - val_accuracy: 0.7959\n",
      "Epoch 7/50\n",
      "4507/4507 [==============================] - 1s 213us/sample - loss: 0.4790 - accuracy: 0.7861 - val_loss: 0.4527 - val_accuracy: 0.7826\n",
      "Epoch 8/50\n",
      "4507/4507 [==============================] - 1s 214us/sample - loss: 0.4729 - accuracy: 0.7803 - val_loss: 0.5489 - val_accuracy: 0.7879\n",
      "Epoch 9/50\n",
      "4507/4507 [==============================] - 1s 215us/sample - loss: 0.4594 - accuracy: 0.7930 - val_loss: 0.4706 - val_accuracy: 0.7968\n",
      "Epoch 10/50\n",
      "4507/4507 [==============================] - 1s 222us/sample - loss: 0.4903 - accuracy: 0.7850 - val_loss: 0.4556 - val_accuracy: 0.7950\n",
      "Epoch 11/50\n",
      "4507/4507 [==============================] - 1s 215us/sample - loss: 0.4839 - accuracy: 0.7806 - val_loss: 0.4961 - val_accuracy: 0.7924\n",
      "Epoch 12/50\n",
      "4507/4507 [==============================] - 1s 212us/sample - loss: 0.4800 - accuracy: 0.7886 - val_loss: 0.4815 - val_accuracy: 0.7941\n",
      "Epoch 13/50\n",
      "4507/4507 [==============================] - 1s 214us/sample - loss: 0.4644 - accuracy: 0.7870 - val_loss: 0.5512 - val_accuracy: 0.6708\n",
      "Epoch 14/50\n",
      "4507/4507 [==============================] - 1s 218us/sample - loss: 0.4806 - accuracy: 0.7859 - val_loss: 0.4690 - val_accuracy: 0.7941\n",
      "Train on 4508 samples, validate on 1127 samples\n",
      "Epoch 1/50\n",
      "4508/4508 [==============================] - 2s 346us/sample - loss: 1.3986 - accuracy: 0.7061 - val_loss: 1.1163 - val_accuracy: 0.7764\n",
      "Epoch 2/50\n",
      "4508/4508 [==============================] - 1s 213us/sample - loss: 0.7103 - accuracy: 0.7496 - val_loss: 1.0098 - val_accuracy: 0.5022\n",
      "Epoch 3/50\n",
      "4508/4508 [==============================] - 1s 214us/sample - loss: 0.5732 - accuracy: 0.7638 - val_loss: 0.4883 - val_accuracy: 0.7915\n",
      "Epoch 4/50\n",
      "4508/4508 [==============================] - 1s 227us/sample - loss: 0.5725 - accuracy: 0.7573 - val_loss: 0.5273 - val_accuracy: 0.7835\n",
      "Epoch 5/50\n",
      "4508/4508 [==============================] - 1s 218us/sample - loss: 0.6551 - accuracy: 0.7498 - val_loss: 0.4739 - val_accuracy: 0.7657\n",
      "Epoch 6/50\n",
      "4508/4508 [==============================] - 1s 222us/sample - loss: 0.4803 - accuracy: 0.7771 - val_loss: 0.4550 - val_accuracy: 0.7870\n",
      "Epoch 7/50\n",
      "4508/4508 [==============================] - 1s 223us/sample - loss: 0.4745 - accuracy: 0.7806 - val_loss: 0.4504 - val_accuracy: 0.7959\n",
      "Epoch 8/50\n",
      "4508/4508 [==============================] - 1s 228us/sample - loss: 0.4605 - accuracy: 0.7824 - val_loss: 0.4600 - val_accuracy: 0.7950\n",
      "Epoch 9/50\n",
      "4508/4508 [==============================] - 1s 215us/sample - loss: 0.4678 - accuracy: 0.7757 - val_loss: 0.4595 - val_accuracy: 0.7906\n",
      "Epoch 10/50\n",
      "4508/4508 [==============================] - 1s 213us/sample - loss: 0.4791 - accuracy: 0.7859 - val_loss: 0.6530 - val_accuracy: 0.7835\n",
      "Epoch 11/50\n",
      "4508/4508 [==============================] - 1s 213us/sample - loss: 0.4633 - accuracy: 0.7873 - val_loss: 0.5207 - val_accuracy: 0.6637\n",
      "Epoch 12/50\n",
      "4508/4508 [==============================] - 1s 214us/sample - loss: 0.4658 - accuracy: 0.7850 - val_loss: 0.4388 - val_accuracy: 0.7924\n",
      "Epoch 13/50\n",
      "4508/4508 [==============================] - 1s 216us/sample - loss: 0.4563 - accuracy: 0.7877 - val_loss: 0.4997 - val_accuracy: 0.7897\n",
      "Epoch 14/50\n",
      "4508/4508 [==============================] - 1s 218us/sample - loss: 0.4587 - accuracy: 0.7850 - val_loss: 0.4406 - val_accuracy: 0.7977\n",
      "Epoch 15/50\n",
      "4508/4508 [==============================] - 1s 213us/sample - loss: 0.4576 - accuracy: 0.7893 - val_loss: 0.5082 - val_accuracy: 0.7879\n",
      "Epoch 16/50\n",
      "4508/4508 [==============================] - 1s 213us/sample - loss: 0.4474 - accuracy: 0.7893 - val_loss: 0.4375 - val_accuracy: 0.8012\n",
      "Epoch 17/50\n",
      "4508/4508 [==============================] - 1s 213us/sample - loss: 0.4490 - accuracy: 0.7855 - val_loss: 0.4666 - val_accuracy: 0.7906\n",
      "Epoch 18/50\n",
      "4508/4508 [==============================] - 1s 215us/sample - loss: 0.4458 - accuracy: 0.7888 - val_loss: 0.4609 - val_accuracy: 0.7924\n",
      "Epoch 19/50\n",
      "4508/4508 [==============================] - 1s 215us/sample - loss: 0.4494 - accuracy: 0.7864 - val_loss: 0.4258 - val_accuracy: 0.7941\n",
      "Epoch 20/50\n",
      "4508/4508 [==============================] - 1s 215us/sample - loss: 0.4544 - accuracy: 0.7857 - val_loss: 0.4374 - val_accuracy: 0.7968\n",
      "Train on 4508 samples, validate on 1127 samples\n",
      "Epoch 1/50\n",
      "4508/4508 [==============================] - 2s 343us/sample - loss: 1.5023 - accuracy: 0.7110 - val_loss: 0.6780 - val_accuracy: 0.5608\n",
      "Epoch 2/50\n",
      "4508/4508 [==============================] - 1s 210us/sample - loss: 0.5480 - accuracy: 0.7649 - val_loss: 0.6227 - val_accuracy: 0.7711\n",
      "Epoch 3/50\n",
      "4508/4508 [==============================] - 1s 212us/sample - loss: 0.5415 - accuracy: 0.7700 - val_loss: 0.5507 - val_accuracy: 0.7782\n",
      "Epoch 4/50\n",
      "4508/4508 [==============================] - 1s 212us/sample - loss: 0.5577 - accuracy: 0.7638 - val_loss: 0.5603 - val_accuracy: 0.7737\n",
      "Epoch 5/50\n",
      "4508/4508 [==============================] - 1s 213us/sample - loss: 0.4897 - accuracy: 0.7735 - val_loss: 0.4670 - val_accuracy: 0.7844\n",
      "Epoch 6/50\n",
      "4508/4508 [==============================] - 1s 211us/sample - loss: 0.4972 - accuracy: 0.7746 - val_loss: 0.5223 - val_accuracy: 0.7915\n",
      "Epoch 7/50\n",
      "4508/4508 [==============================] - 1s 213us/sample - loss: 0.4721 - accuracy: 0.7882 - val_loss: 0.4692 - val_accuracy: 0.7808\n",
      "Epoch 8/50\n",
      "4508/4508 [==============================] - 1s 210us/sample - loss: 0.4716 - accuracy: 0.7802 - val_loss: 0.6110 - val_accuracy: 0.6309\n",
      "Epoch 9/50\n",
      "4508/4508 [==============================] - 1s 212us/sample - loss: 0.4801 - accuracy: 0.7777 - val_loss: 0.4764 - val_accuracy: 0.7933\n",
      "Epoch 10/50\n",
      "4508/4508 [==============================] - 1s 213us/sample - loss: 0.4876 - accuracy: 0.7764 - val_loss: 0.5401 - val_accuracy: 0.7533\n",
      "Epoch 11/50\n",
      "4508/4508 [==============================] - 1s 212us/sample - loss: 0.4902 - accuracy: 0.7846 - val_loss: 0.4808 - val_accuracy: 0.7906\n",
      "Epoch 12/50\n",
      "4508/4508 [==============================] - 1s 218us/sample - loss: 0.4717 - accuracy: 0.7835 - val_loss: 0.5173 - val_accuracy: 0.7320\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/100\n",
      "4507/4507 [==============================] - 2s 388us/sample - loss: 1.4622 - accuracy: 0.7016 - val_loss: 0.6950 - val_accuracy: 0.7959\n",
      "Epoch 2/100\n",
      "4507/4507 [==============================] - 1s 216us/sample - loss: 0.8470 - accuracy: 0.7333 - val_loss: 0.4960 - val_accuracy: 0.7853\n",
      "Epoch 3/100\n",
      "4507/4507 [==============================] - 1s 215us/sample - loss: 0.5669 - accuracy: 0.7655 - val_loss: 0.8409 - val_accuracy: 0.7835\n",
      "Epoch 4/100\n",
      "4507/4507 [==============================] - 1s 216us/sample - loss: 0.5245 - accuracy: 0.7626 - val_loss: 0.4756 - val_accuracy: 0.7897\n",
      "Epoch 5/100\n",
      "4507/4507 [==============================] - 1s 218us/sample - loss: 0.5130 - accuracy: 0.7673 - val_loss: 0.7483 - val_accuracy: 0.7755\n",
      "Epoch 6/100\n",
      "4507/4507 [==============================] - 1s 226us/sample - loss: 0.5192 - accuracy: 0.7741 - val_loss: 0.4553 - val_accuracy: 0.7862\n",
      "Epoch 7/100\n",
      "4507/4507 [==============================] - 1s 230us/sample - loss: 0.5110 - accuracy: 0.7766 - val_loss: 0.4946 - val_accuracy: 0.7835\n",
      "Epoch 8/100\n",
      "4507/4507 [==============================] - 1s 222us/sample - loss: 0.5116 - accuracy: 0.7768 - val_loss: 0.4631 - val_accuracy: 0.7879\n",
      "Epoch 9/100\n",
      "4507/4507 [==============================] - 1s 222us/sample - loss: 0.4754 - accuracy: 0.7777 - val_loss: 0.4859 - val_accuracy: 0.7888\n",
      "Epoch 10/100\n",
      "4507/4507 [==============================] - 1s 214us/sample - loss: 0.4695 - accuracy: 0.7806 - val_loss: 0.4584 - val_accuracy: 0.7879\n",
      "Epoch 11/100\n",
      "4507/4507 [==============================] - 1s 215us/sample - loss: 0.4821 - accuracy: 0.7748 - val_loss: 0.5069 - val_accuracy: 0.7915\n",
      "Epoch 12/100\n",
      "4507/4507 [==============================] - 1s 215us/sample - loss: 0.5086 - accuracy: 0.7746 - val_loss: 0.4619 - val_accuracy: 0.7879\n",
      "Epoch 13/100\n",
      "4507/4507 [==============================] - 1s 217us/sample - loss: 0.4752 - accuracy: 0.7781 - val_loss: 0.4843 - val_accuracy: 0.7835\n",
      "Epoch 14/100\n",
      "4507/4507 [==============================] - 1s 216us/sample - loss: 0.4634 - accuracy: 0.7883 - val_loss: 0.4354 - val_accuracy: 0.7906\n",
      "Epoch 15/100\n",
      "4507/4507 [==============================] - 1s 216us/sample - loss: 0.4613 - accuracy: 0.7872 - val_loss: 0.5071 - val_accuracy: 0.7879\n",
      "Epoch 16/100\n",
      "4507/4507 [==============================] - 1s 215us/sample - loss: 0.4611 - accuracy: 0.7848 - val_loss: 0.4507 - val_accuracy: 0.7933\n",
      "Epoch 17/100\n",
      "4507/4507 [==============================] - 1s 215us/sample - loss: 0.4728 - accuracy: 0.7846 - val_loss: 0.4712 - val_accuracy: 0.7879\n",
      "Epoch 18/100\n",
      "4507/4507 [==============================] - 1s 214us/sample - loss: 0.4554 - accuracy: 0.7863 - val_loss: 0.4421 - val_accuracy: 0.7959\n",
      "Epoch 19/100\n",
      "4507/4507 [==============================] - 1s 214us/sample - loss: 0.4586 - accuracy: 0.7870 - val_loss: 0.4431 - val_accuracy: 0.7959\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/100\n",
      "4507/4507 [==============================] - 2s 357us/sample - loss: 1.1192 - accuracy: 0.7176 - val_loss: 0.5073 - val_accuracy: 0.7835\n",
      "Epoch 2/100\n",
      "4507/4507 [==============================] - 1s 217us/sample - loss: 0.6494 - accuracy: 0.7515 - val_loss: 0.6179 - val_accuracy: 0.7941\n",
      "Epoch 3/100\n",
      "4507/4507 [==============================] - 1s 214us/sample - loss: 0.5878 - accuracy: 0.7553 - val_loss: 0.4919 - val_accuracy: 0.7933\n",
      "Epoch 4/100\n",
      "4507/4507 [==============================] - 1s 212us/sample - loss: 0.5119 - accuracy: 0.7746 - val_loss: 0.6560 - val_accuracy: 0.7844\n",
      "Epoch 5/100\n",
      "4507/4507 [==============================] - 1s 213us/sample - loss: 0.4998 - accuracy: 0.7772 - val_loss: 0.4667 - val_accuracy: 0.7879\n",
      "Epoch 6/100\n",
      "4507/4507 [==============================] - 1s 213us/sample - loss: 0.4789 - accuracy: 0.7799 - val_loss: 0.4568 - val_accuracy: 0.7853\n",
      "Epoch 7/100\n",
      "4507/4507 [==============================] - 1s 215us/sample - loss: 0.4768 - accuracy: 0.7790 - val_loss: 0.4637 - val_accuracy: 0.7915\n",
      "Epoch 8/100\n",
      "4507/4507 [==============================] - 1s 214us/sample - loss: 0.4737 - accuracy: 0.7863 - val_loss: 0.4584 - val_accuracy: 0.7915\n",
      "Epoch 9/100\n",
      "4507/4507 [==============================] - 1s 213us/sample - loss: 0.4701 - accuracy: 0.7905 - val_loss: 0.4633 - val_accuracy: 0.7888\n",
      "Epoch 10/100\n",
      "4507/4507 [==============================] - 1s 215us/sample - loss: 0.4672 - accuracy: 0.7832 - val_loss: 0.4665 - val_accuracy: 0.7862\n",
      "Epoch 11/100\n",
      "4507/4507 [==============================] - 1s 216us/sample - loss: 0.5016 - accuracy: 0.7779 - val_loss: 0.4300 - val_accuracy: 0.7906\n",
      "Epoch 12/100\n",
      "4507/4507 [==============================] - 1s 214us/sample - loss: 0.4724 - accuracy: 0.7830 - val_loss: 0.4567 - val_accuracy: 0.7879\n",
      "Epoch 13/100\n",
      "4507/4507 [==============================] - 1s 215us/sample - loss: 0.4734 - accuracy: 0.7852 - val_loss: 0.4472 - val_accuracy: 0.7879\n",
      "Epoch 14/100\n",
      "4507/4507 [==============================] - 1s 214us/sample - loss: 0.4518 - accuracy: 0.7892 - val_loss: 0.4461 - val_accuracy: 0.7906\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/100\n",
      "4507/4507 [==============================] - 2s 352us/sample - loss: 1.3610 - accuracy: 0.6991 - val_loss: 0.5365 - val_accuracy: 0.7817\n",
      "Epoch 2/100\n",
      "4507/4507 [==============================] - 1s 219us/sample - loss: 0.5821 - accuracy: 0.7673 - val_loss: 0.6488 - val_accuracy: 0.7959\n",
      "Epoch 3/100\n",
      "4507/4507 [==============================] - 1s 216us/sample - loss: 0.5431 - accuracy: 0.7666 - val_loss: 0.4603 - val_accuracy: 0.7924\n",
      "Epoch 4/100\n",
      "4507/4507 [==============================] - 1s 216us/sample - loss: 0.5236 - accuracy: 0.7710 - val_loss: 0.4761 - val_accuracy: 0.7853\n",
      "Epoch 5/100\n",
      "4507/4507 [==============================] - 1s 215us/sample - loss: 0.5083 - accuracy: 0.7797 - val_loss: 0.4513 - val_accuracy: 0.7950\n",
      "Epoch 6/100\n",
      "4507/4507 [==============================] - 1s 216us/sample - loss: 0.4665 - accuracy: 0.7812 - val_loss: 0.5447 - val_accuracy: 0.6699\n",
      "Epoch 7/100\n",
      "4507/4507 [==============================] - 1s 216us/sample - loss: 0.4914 - accuracy: 0.7828 - val_loss: 0.4570 - val_accuracy: 0.7986\n",
      "Epoch 8/100\n",
      "4507/4507 [==============================] - 1s 218us/sample - loss: 0.4736 - accuracy: 0.7843 - val_loss: 0.4560 - val_accuracy: 0.7897\n",
      "Epoch 9/100\n",
      "4507/4507 [==============================] - 1s 214us/sample - loss: 0.4636 - accuracy: 0.7837 - val_loss: 0.4451 - val_accuracy: 0.7906\n",
      "Epoch 10/100\n",
      "4507/4507 [==============================] - 1s 216us/sample - loss: 0.4655 - accuracy: 0.7872 - val_loss: 0.4463 - val_accuracy: 0.7870\n",
      "Epoch 11/100\n",
      "4507/4507 [==============================] - 1s 214us/sample - loss: 0.4668 - accuracy: 0.7877 - val_loss: 0.4523 - val_accuracy: 0.7933\n",
      "Epoch 12/100\n",
      "4507/4507 [==============================] - 1s 214us/sample - loss: 0.4612 - accuracy: 0.7921 - val_loss: 0.4255 - val_accuracy: 0.7959\n",
      "Epoch 13/100\n",
      "4507/4507 [==============================] - 1s 217us/sample - loss: 0.4709 - accuracy: 0.7821 - val_loss: 0.4520 - val_accuracy: 0.7986\n",
      "Epoch 14/100\n",
      "4507/4507 [==============================] - 1s 214us/sample - loss: 0.4631 - accuracy: 0.7817 - val_loss: 0.4510 - val_accuracy: 0.7959\n",
      "Epoch 15/100\n",
      "4507/4507 [==============================] - 1s 215us/sample - loss: 0.4615 - accuracy: 0.7914 - val_loss: 0.4574 - val_accuracy: 0.7986\n",
      "Epoch 16/100\n",
      "4507/4507 [==============================] - 1s 213us/sample - loss: 0.4495 - accuracy: 0.7910 - val_loss: 0.4424 - val_accuracy: 0.7950\n",
      "Epoch 17/100\n",
      "4507/4507 [==============================] - 1s 215us/sample - loss: 0.4576 - accuracy: 0.7890 - val_loss: 0.5558 - val_accuracy: 0.7906\n",
      "Train on 4508 samples, validate on 1127 samples\n",
      "Epoch 1/100\n",
      "4508/4508 [==============================] - 2s 352us/sample - loss: 1.4852 - accuracy: 0.7005 - val_loss: 0.8258 - val_accuracy: 0.7782\n",
      "Epoch 2/100\n",
      "4508/4508 [==============================] - 1s 214us/sample - loss: 0.6978 - accuracy: 0.7365 - val_loss: 0.5035 - val_accuracy: 0.7933\n",
      "Epoch 3/100\n",
      "4508/4508 [==============================] - 1s 214us/sample - loss: 0.5810 - accuracy: 0.7549 - val_loss: 0.4801 - val_accuracy: 0.7835\n",
      "Epoch 4/100\n",
      "4508/4508 [==============================] - 1s 213us/sample - loss: 0.5074 - accuracy: 0.7615 - val_loss: 0.5458 - val_accuracy: 0.7347\n",
      "Epoch 5/100\n",
      "4508/4508 [==============================] - 1s 215us/sample - loss: 0.5310 - accuracy: 0.7640 - val_loss: 0.4606 - val_accuracy: 0.7888\n",
      "Epoch 6/100\n",
      "4508/4508 [==============================] - 1s 215us/sample - loss: 0.4921 - accuracy: 0.7711 - val_loss: 0.5703 - val_accuracy: 0.7897\n",
      "Epoch 7/100\n",
      "4508/4508 [==============================] - 1s 213us/sample - loss: 0.4827 - accuracy: 0.7813 - val_loss: 0.4389 - val_accuracy: 0.7959\n",
      "Epoch 8/100\n",
      "4508/4508 [==============================] - 1s 214us/sample - loss: 0.4709 - accuracy: 0.7826 - val_loss: 0.4453 - val_accuracy: 0.7950\n",
      "Epoch 9/100\n",
      "4508/4508 [==============================] - 1s 219us/sample - loss: 0.4678 - accuracy: 0.7875 - val_loss: 0.4858 - val_accuracy: 0.7711\n",
      "Epoch 10/100\n",
      "4508/4508 [==============================] - 1s 229us/sample - loss: 0.4658 - accuracy: 0.7855 - val_loss: 0.4537 - val_accuracy: 0.7933\n",
      "Epoch 11/100\n",
      "4508/4508 [==============================] - 1s 227us/sample - loss: 0.4700 - accuracy: 0.7846 - val_loss: 0.4465 - val_accuracy: 0.7995\n",
      "Epoch 12/100\n",
      "4508/4508 [==============================] - 1s 229us/sample - loss: 0.4547 - accuracy: 0.7857 - val_loss: 0.4614 - val_accuracy: 0.8004\n",
      "Epoch 13/100\n",
      "4508/4508 [==============================] - 1s 226us/sample - loss: 0.4627 - accuracy: 0.7864 - val_loss: 0.4658 - val_accuracy: 0.7968\n",
      "Epoch 14/100\n",
      "4508/4508 [==============================] - 1s 213us/sample - loss: 0.4636 - accuracy: 0.7853 - val_loss: 0.4837 - val_accuracy: 0.7888\n",
      "Train on 4508 samples, validate on 1127 samples\n",
      "Epoch 1/100\n",
      "4508/4508 [==============================] - 2s 348us/sample - loss: 1.4750 - accuracy: 0.6928 - val_loss: 0.6904 - val_accuracy: 0.5448\n",
      "Epoch 2/100\n",
      "4508/4508 [==============================] - 1s 223us/sample - loss: 0.6870 - accuracy: 0.7367 - val_loss: 0.6131 - val_accuracy: 0.7782\n",
      "Epoch 3/100\n",
      "4508/4508 [==============================] - 1s 220us/sample - loss: 0.5815 - accuracy: 0.7695 - val_loss: 0.4851 - val_accuracy: 0.7897\n",
      "Epoch 4/100\n",
      "4508/4508 [==============================] - 1s 218us/sample - loss: 0.5022 - accuracy: 0.7755 - val_loss: 0.4963 - val_accuracy: 0.7853\n",
      "Epoch 5/100\n",
      "4508/4508 [==============================] - 1s 214us/sample - loss: 0.5638 - accuracy: 0.7662 - val_loss: 0.4871 - val_accuracy: 0.7835\n",
      "Epoch 6/100\n",
      "4508/4508 [==============================] - 1s 215us/sample - loss: 0.4680 - accuracy: 0.7855 - val_loss: 0.4626 - val_accuracy: 0.7791\n",
      "Epoch 7/100\n",
      "4508/4508 [==============================] - 1s 219us/sample - loss: 0.4773 - accuracy: 0.7791 - val_loss: 0.6595 - val_accuracy: 0.7888\n",
      "Epoch 8/100\n",
      "4508/4508 [==============================] - 1s 214us/sample - loss: 0.4924 - accuracy: 0.7757 - val_loss: 0.4664 - val_accuracy: 0.7924\n",
      "Epoch 9/100\n",
      "4508/4508 [==============================] - 1s 222us/sample - loss: 0.4712 - accuracy: 0.7848 - val_loss: 0.5149 - val_accuracy: 0.7862\n",
      "Epoch 10/100\n",
      "4508/4508 [==============================] - 1s 216us/sample - loss: 0.4637 - accuracy: 0.7857 - val_loss: 0.4624 - val_accuracy: 0.7906\n",
      "Epoch 11/100\n",
      "4508/4508 [==============================] - 1s 218us/sample - loss: 0.4626 - accuracy: 0.7846 - val_loss: 0.4505 - val_accuracy: 0.7968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:  5.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5634 samples, validate on 1409 samples\n",
      "Epoch 1/100\n",
      "5634/5634 [==============================] - 2s 325us/sample - loss: 0.9322 - accuracy: 0.7201 - val_loss: 0.5174 - val_accuracy: 0.7764\n",
      "Epoch 2/100\n",
      "5634/5634 [==============================] - 1s 216us/sample - loss: 0.6126 - accuracy: 0.7543 - val_loss: 0.5322 - val_accuracy: 0.7899\n",
      "Epoch 3/100\n",
      "5634/5634 [==============================] - 1s 212us/sample - loss: 0.5198 - accuracy: 0.7707 - val_loss: 0.5910 - val_accuracy: 0.7821\n",
      "Epoch 4/100\n",
      "5634/5634 [==============================] - 1s 214us/sample - loss: 0.4951 - accuracy: 0.7719 - val_loss: 0.4484 - val_accuracy: 0.7793\n",
      "Epoch 5/100\n",
      "5634/5634 [==============================] - 1s 217us/sample - loss: 0.5069 - accuracy: 0.7728 - val_loss: 0.5821 - val_accuracy: 0.6317\n",
      "Epoch 6/100\n",
      "5634/5634 [==============================] - 1s 211us/sample - loss: 0.4706 - accuracy: 0.7822 - val_loss: 0.5142 - val_accuracy: 0.7793\n",
      "Epoch 7/100\n",
      "5634/5634 [==============================] - 1s 212us/sample - loss: 0.4766 - accuracy: 0.7819 - val_loss: 0.4520 - val_accuracy: 0.7835\n",
      "Epoch 8/100\n",
      "5634/5634 [==============================] - 1s 215us/sample - loss: 0.4647 - accuracy: 0.7852 - val_loss: 0.4569 - val_accuracy: 0.7906\n",
      "Epoch 9/100\n",
      "5634/5634 [==============================] - 1s 219us/sample - loss: 0.4635 - accuracy: 0.7868 - val_loss: 0.4500 - val_accuracy: 0.7885\n",
      "Epoch 10/100\n",
      "5634/5634 [==============================] - 1s 214us/sample - loss: 0.4639 - accuracy: 0.7843 - val_loss: 0.4434 - val_accuracy: 0.7885\n",
      "Epoch 11/100\n",
      "5634/5634 [==============================] - 1s 214us/sample - loss: 0.4545 - accuracy: 0.7888 - val_loss: 0.4583 - val_accuracy: 0.7942\n",
      "Epoch 12/100\n",
      "5634/5634 [==============================] - 1s 215us/sample - loss: 0.4584 - accuracy: 0.7890 - val_loss: 0.4537 - val_accuracy: 0.7857\n",
      "Epoch 13/100\n",
      "5634/5634 [==============================] - 1s 216us/sample - loss: 0.4600 - accuracy: 0.7920 - val_loss: 0.4505 - val_accuracy: 0.7949\n",
      "Epoch 14/100\n",
      "5634/5634 [==============================] - 1s 214us/sample - loss: 0.4519 - accuracy: 0.7930 - val_loss: 0.4418 - val_accuracy: 0.7970\n",
      "Epoch 15/100\n",
      "5634/5634 [==============================] - 1s 215us/sample - loss: 0.4557 - accuracy: 0.7875 - val_loss: 0.4410 - val_accuracy: 0.7892\n",
      "Epoch 16/100\n",
      "5634/5634 [==============================] - 1s 212us/sample - loss: 0.4483 - accuracy: 0.7946 - val_loss: 0.4390 - val_accuracy: 0.7928\n",
      "Epoch 17/100\n",
      "5634/5634 [==============================] - 1s 210us/sample - loss: 0.4492 - accuracy: 0.7939 - val_loss: 0.4340 - val_accuracy: 0.7935\n",
      "Epoch 18/100\n",
      "5634/5634 [==============================] - 1s 216us/sample - loss: 0.4462 - accuracy: 0.7955 - val_loss: 0.4299 - val_accuracy: 0.7949\n",
      "Epoch 19/100\n",
      "5634/5634 [==============================] - 1s 215us/sample - loss: 0.4440 - accuracy: 0.7991 - val_loss: 0.4276 - val_accuracy: 0.7977\n",
      "Epoch 20/100\n",
      "5634/5634 [==============================] - 1s 216us/sample - loss: 0.4436 - accuracy: 0.7969 - val_loss: 0.4439 - val_accuracy: 0.7935\n",
      "Epoch 21/100\n",
      "5634/5634 [==============================] - 1s 213us/sample - loss: 0.4400 - accuracy: 0.7961 - val_loss: 0.4274 - val_accuracy: 0.7949\n",
      "Epoch 22/100\n",
      "5634/5634 [==============================] - 1s 212us/sample - loss: 0.4404 - accuracy: 0.7980 - val_loss: 0.4341 - val_accuracy: 0.7949\n",
      "Epoch 23/100\n",
      "5634/5634 [==============================] - 1s 211us/sample - loss: 0.4368 - accuracy: 0.7984 - val_loss: 0.4483 - val_accuracy: 0.7956\n",
      "Epoch 24/100\n",
      "5634/5634 [==============================] - 1s 218us/sample - loss: 0.4374 - accuracy: 0.7996 - val_loss: 0.4377 - val_accuracy: 0.7963\n",
      "\n",
      "Best score: 0.7885842433382798\n",
      "Best params: {'additional_layers': 4, 'batch_size': 10, 'epochs': 100, 'nodes_per_layer': 52}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# tune epochs\n",
    "params = {\n",
    "    'nodes_per_layer': [52],\n",
    "    'additional_layers': [4],\n",
    "    'batch_size': [10],\n",
    "    'epochs': [10, 20, 50, 100],\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=KerasClassifier(build_fn=create_model),\n",
    "    param_grid=params,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=1,\n",
    "    cv=5,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid.fit(X, y, callbacks=[stop], validation_split=0.2)\n",
    "\n",
    "print()\n",
    "print('Best score:', grid.best_score_)\n",
    "print('Best params:', grid.best_params_)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4507/4507 [==============================] - 2s 355us/sample - loss: 1.0693 - accuracy: 0.7116 - val_loss: 0.8296 - val_accuracy: 0.5004\n",
      "Epoch 2/100\n",
      "4507/4507 [==============================] - 1s 219us/sample - loss: 0.5694 - accuracy: 0.7621 - val_loss: 0.4708 - val_accuracy: 0.7959\n",
      "Epoch 3/100\n",
      "4507/4507 [==============================] - 1s 220us/sample - loss: 0.5348 - accuracy: 0.7610 - val_loss: 0.5085 - val_accuracy: 0.7853\n",
      "Epoch 4/100\n",
      "4507/4507 [==============================] - 1s 221us/sample - loss: 0.5010 - accuracy: 0.7768 - val_loss: 0.4499 - val_accuracy: 0.7986\n",
      "Epoch 5/100\n",
      "4507/4507 [==============================] - 1s 218us/sample - loss: 0.5086 - accuracy: 0.7699 - val_loss: 0.4500 - val_accuracy: 0.7933\n",
      "Epoch 6/100\n",
      "4507/4507 [==============================] - 1s 223us/sample - loss: 0.4915 - accuracy: 0.7766 - val_loss: 0.5957 - val_accuracy: 0.7853\n",
      "Epoch 7/100\n",
      "4507/4507 [==============================] - 1s 221us/sample - loss: 0.4974 - accuracy: 0.7759 - val_loss: 0.5212 - val_accuracy: 0.7604\n",
      "Epoch 8/100\n",
      "4507/4507 [==============================] - 1s 216us/sample - loss: 0.4777 - accuracy: 0.7746 - val_loss: 0.4568 - val_accuracy: 0.7941\n",
      "Epoch 9/100\n",
      "4507/4507 [==============================] - 1s 213us/sample - loss: 0.4933 - accuracy: 0.7795 - val_loss: 0.5602 - val_accuracy: 0.7959\n",
      "Epoch 10/100\n",
      "4507/4507 [==============================] - 1s 211us/sample - loss: 0.4861 - accuracy: 0.7806 - val_loss: 0.4729 - val_accuracy: 0.7959\n",
      "Epoch 11/100\n",
      "4507/4507 [==============================] - 1s 214us/sample - loss: 0.4675 - accuracy: 0.7857 - val_loss: 0.4816 - val_accuracy: 0.7791\n",
      "Epoch 12/100\n",
      "4507/4507 [==============================] - 1s 213us/sample - loss: 0.4715 - accuracy: 0.7801 - val_loss: 0.4558 - val_accuracy: 0.7959\n",
      "Epoch 13/100\n",
      "4507/4507 [==============================] - 1s 213us/sample - loss: 0.4647 - accuracy: 0.7775 - val_loss: 0.4429 - val_accuracy: 0.7950\n",
      "Epoch 14/100\n",
      "4507/4507 [==============================] - 1s 214us/sample - loss: 0.4799 - accuracy: 0.7850 - val_loss: 0.4758 - val_accuracy: 0.7879\n",
      "Epoch 15/100\n",
      "4507/4507 [==============================] - 1s 216us/sample - loss: 0.4731 - accuracy: 0.7828 - val_loss: 0.4818 - val_accuracy: 0.7879\n",
      "Epoch 16/100\n",
      "4507/4507 [==============================] - 1s 210us/sample - loss: 0.4660 - accuracy: 0.7923 - val_loss: 0.5353 - val_accuracy: 0.6841\n",
      "Epoch 17/100\n",
      "4507/4507 [==============================] - 1s 211us/sample - loss: 0.4669 - accuracy: 0.7839 - val_loss: 0.4539 - val_accuracy: 0.7941\n",
      "Epoch 18/100\n",
      "4507/4507 [==============================] - 1s 213us/sample - loss: 0.4553 - accuracy: 0.7834 - val_loss: 0.4344 - val_accuracy: 0.7906\n",
      "Epoch 19/100\n",
      "4507/4507 [==============================] - 1s 211us/sample - loss: 0.4574 - accuracy: 0.7779 - val_loss: 0.4391 - val_accuracy: 0.7977\n",
      "Epoch 20/100\n",
      "4507/4507 [==============================] - 1s 215us/sample - loss: 0.4599 - accuracy: 0.7863 - val_loss: 0.4492 - val_accuracy: 0.7933\n",
      "Epoch 21/100\n",
      "4507/4507 [==============================] - 1s 240us/sample - loss: 0.4670 - accuracy: 0.7848 - val_loss: 0.4558 - val_accuracy: 0.7862\n",
      "1409/1409 [==============================] - 0s 100us/sample - loss: 0.4587 - accuracy: 0.7928\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/100\n",
      "4507/4507 [==============================] - 2s 371us/sample - loss: 1.5185 - accuracy: 0.7129 - val_loss: 1.2471 - val_accuracy: 0.4534\n",
      "Epoch 2/100\n",
      "4507/4507 [==============================] - 1s 250us/sample - loss: 0.7122 - accuracy: 0.7495 - val_loss: 0.5241 - val_accuracy: 0.7879\n",
      "Epoch 3/100\n",
      "4507/4507 [==============================] - 1s 251us/sample - loss: 0.5633 - accuracy: 0.7648 - val_loss: 0.5509 - val_accuracy: 0.7995\n",
      "Epoch 4/100\n",
      "4507/4507 [==============================] - 1s 243us/sample - loss: 0.4949 - accuracy: 0.7797 - val_loss: 0.5032 - val_accuracy: 0.7879\n",
      "Epoch 5/100\n",
      "4507/4507 [==============================] - 1s 221us/sample - loss: 0.5153 - accuracy: 0.7777 - val_loss: 0.4457 - val_accuracy: 0.7924\n",
      "Epoch 6/100\n",
      "4507/4507 [==============================] - 1s 218us/sample - loss: 0.4779 - accuracy: 0.7783 - val_loss: 0.4463 - val_accuracy: 0.7977\n",
      "Epoch 7/100\n",
      "4507/4507 [==============================] - 1s 222us/sample - loss: 0.5395 - accuracy: 0.7786 - val_loss: 0.4741 - val_accuracy: 0.7941\n",
      "Epoch 8/100\n",
      "4507/4507 [==============================] - 1s 218us/sample - loss: 0.4912 - accuracy: 0.7819 - val_loss: 0.5090 - val_accuracy: 0.7853\n",
      "Epoch 9/100\n",
      "4507/4507 [==============================] - 1s 229us/sample - loss: 0.4697 - accuracy: 0.7872 - val_loss: 0.4503 - val_accuracy: 0.7950\n",
      "Epoch 10/100\n",
      "4507/4507 [==============================] - 1s 223us/sample - loss: 0.4646 - accuracy: 0.7914 - val_loss: 0.4699 - val_accuracy: 0.7870\n",
      "Epoch 11/100\n",
      "4507/4507 [==============================] - 1s 214us/sample - loss: 0.4599 - accuracy: 0.7894 - val_loss: 0.4692 - val_accuracy: 0.7844\n",
      "Epoch 12/100\n",
      "4507/4507 [==============================] - 1s 211us/sample - loss: 0.4754 - accuracy: 0.7832 - val_loss: 0.4583 - val_accuracy: 0.7933\n",
      "Epoch 13/100\n",
      "4507/4507 [==============================] - 1s 213us/sample - loss: 0.4683 - accuracy: 0.7886 - val_loss: 0.4687 - val_accuracy: 0.7879\n",
      "Epoch 14/100\n",
      "4507/4507 [==============================] - 1s 221us/sample - loss: 0.4667 - accuracy: 0.7828 - val_loss: 0.4837 - val_accuracy: 0.7782\n",
      "Epoch 15/100\n",
      "4507/4507 [==============================] - 1s 224us/sample - loss: 0.4694 - accuracy: 0.7872 - val_loss: 0.4528 - val_accuracy: 0.7950\n",
      "1409/1409 [==============================] - 0s 99us/sample - loss: 0.4571 - accuracy: 0.7892\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/100\n",
      "4507/4507 [==============================] - 2s 367us/sample - loss: 1.0947 - accuracy: 0.7080 - val_loss: 0.6301 - val_accuracy: 0.7862\n",
      "Epoch 2/100\n",
      "4507/4507 [==============================] - 1s 215us/sample - loss: 0.6742 - accuracy: 0.7502 - val_loss: 0.5056 - val_accuracy: 0.7879\n",
      "Epoch 3/100\n",
      "4507/4507 [==============================] - 1s 214us/sample - loss: 0.5420 - accuracy: 0.7606 - val_loss: 0.5014 - val_accuracy: 0.7862\n",
      "Epoch 4/100\n",
      "4507/4507 [==============================] - 1s 215us/sample - loss: 0.5174 - accuracy: 0.7681 - val_loss: 0.5070 - val_accuracy: 0.7862\n",
      "Epoch 5/100\n",
      "4507/4507 [==============================] - 1s 214us/sample - loss: 0.4887 - accuracy: 0.7746 - val_loss: 0.4876 - val_accuracy: 0.7835\n",
      "Epoch 6/100\n",
      "4507/4507 [==============================] - 1s 214us/sample - loss: 0.4940 - accuracy: 0.7719 - val_loss: 0.5072 - val_accuracy: 0.7870\n",
      "Epoch 7/100\n",
      "4507/4507 [==============================] - 1s 214us/sample - loss: 0.4726 - accuracy: 0.7841 - val_loss: 0.4590 - val_accuracy: 0.7879\n",
      "Epoch 8/100\n",
      "4507/4507 [==============================] - 1s 215us/sample - loss: 0.4736 - accuracy: 0.7848 - val_loss: 0.4731 - val_accuracy: 0.7853\n",
      "Epoch 9/100\n",
      "4507/4507 [==============================] - 1s 219us/sample - loss: 0.4695 - accuracy: 0.7832 - val_loss: 0.4564 - val_accuracy: 0.7933\n",
      "Epoch 10/100\n",
      "4507/4507 [==============================] - 1s 236us/sample - loss: 0.4621 - accuracy: 0.7874 - val_loss: 0.4570 - val_accuracy: 0.7995\n",
      "Epoch 11/100\n",
      "4507/4507 [==============================] - 1s 217us/sample - loss: 0.4789 - accuracy: 0.7832 - val_loss: 0.4692 - val_accuracy: 0.7879\n",
      "Epoch 12/100\n",
      "4507/4507 [==============================] - 1s 217us/sample - loss: 0.4547 - accuracy: 0.7921 - val_loss: 0.4516 - val_accuracy: 0.7933\n",
      "Epoch 13/100\n",
      "4507/4507 [==============================] - 1s 225us/sample - loss: 0.4527 - accuracy: 0.7939 - val_loss: 0.4554 - val_accuracy: 0.7924\n",
      "Epoch 14/100\n",
      "4507/4507 [==============================] - 1s 222us/sample - loss: 0.4663 - accuracy: 0.7854 - val_loss: 0.4549 - val_accuracy: 0.7888\n",
      "Epoch 15/100\n",
      "4507/4507 [==============================] - 1s 223us/sample - loss: 0.4641 - accuracy: 0.7905 - val_loss: 0.4486 - val_accuracy: 0.7897\n",
      "Epoch 16/100\n",
      "4507/4507 [==============================] - 1s 218us/sample - loss: 0.4594 - accuracy: 0.7932 - val_loss: 0.5105 - val_accuracy: 0.7853\n",
      "Epoch 17/100\n",
      "4507/4507 [==============================] - 1s 219us/sample - loss: 0.4885 - accuracy: 0.7868 - val_loss: 0.4958 - val_accuracy: 0.7870\n",
      "Epoch 18/100\n",
      "4507/4507 [==============================] - 1s 217us/sample - loss: 0.4848 - accuracy: 0.7848 - val_loss: 0.4701 - val_accuracy: 0.7941\n",
      "1409/1409 [==============================] - 0s 102us/sample - loss: 0.4890 - accuracy: 0.7786\n",
      "Train on 4508 samples, validate on 1127 samples\n",
      "Epoch 1/100\n",
      "4508/4508 [==============================] - 2s 358us/sample - loss: 1.1801 - accuracy: 0.7065 - val_loss: 0.5666 - val_accuracy: 0.7533\n",
      "Epoch 2/100\n",
      "4508/4508 [==============================] - 1s 220us/sample - loss: 0.6311 - accuracy: 0.7496 - val_loss: 0.8961 - val_accuracy: 0.7720\n",
      "Epoch 3/100\n",
      "4508/4508 [==============================] - 1s 221us/sample - loss: 0.6306 - accuracy: 0.7511 - val_loss: 0.4999 - val_accuracy: 0.7817\n",
      "Epoch 4/100\n",
      "4508/4508 [==============================] - 1s 219us/sample - loss: 0.5520 - accuracy: 0.7638 - val_loss: 0.4962 - val_accuracy: 0.7711\n",
      "Epoch 5/100\n",
      "4508/4508 [==============================] - 1s 231us/sample - loss: 0.5154 - accuracy: 0.7633 - val_loss: 0.5385 - val_accuracy: 0.7888\n",
      "Epoch 6/100\n",
      "4508/4508 [==============================] - 1s 221us/sample - loss: 0.5511 - accuracy: 0.7695 - val_loss: 0.5073 - val_accuracy: 0.7835\n",
      "Epoch 7/100\n",
      "4508/4508 [==============================] - 1s 220us/sample - loss: 0.4970 - accuracy: 0.7755 - val_loss: 0.4561 - val_accuracy: 0.7995\n",
      "Epoch 8/100\n",
      "4508/4508 [==============================] - 1s 214us/sample - loss: 0.4747 - accuracy: 0.7826 - val_loss: 0.5021 - val_accuracy: 0.7915\n",
      "Epoch 9/100\n",
      "4508/4508 [==============================] - 1s 217us/sample - loss: 0.5198 - accuracy: 0.7649 - val_loss: 0.4719 - val_accuracy: 0.7897\n",
      "Epoch 10/100\n",
      "4508/4508 [==============================] - 1s 220us/sample - loss: 0.4688 - accuracy: 0.7815 - val_loss: 0.5626 - val_accuracy: 0.7933\n",
      "Epoch 11/100\n",
      "4508/4508 [==============================] - 1s 222us/sample - loss: 0.4741 - accuracy: 0.7797 - val_loss: 0.4743 - val_accuracy: 0.7799\n",
      "Epoch 12/100\n",
      "4508/4508 [==============================] - 1s 220us/sample - loss: 0.4618 - accuracy: 0.7893 - val_loss: 0.4506 - val_accuracy: 0.7888\n",
      "Epoch 13/100\n",
      "4508/4508 [==============================] - 1s 223us/sample - loss: 0.4713 - accuracy: 0.7753 - val_loss: 0.5484 - val_accuracy: 0.7906\n",
      "Epoch 14/100\n",
      "4508/4508 [==============================] - 1s 219us/sample - loss: 0.4707 - accuracy: 0.7831 - val_loss: 0.4722 - val_accuracy: 0.7853\n",
      "Epoch 15/100\n",
      "4508/4508 [==============================] - 1s 218us/sample - loss: 0.4679 - accuracy: 0.7839 - val_loss: 0.4569 - val_accuracy: 0.7915\n",
      "Epoch 16/100\n",
      "4508/4508 [==============================] - 1s 219us/sample - loss: 0.4626 - accuracy: 0.7895 - val_loss: 0.4489 - val_accuracy: 0.7959\n",
      "Epoch 17/100\n",
      "4508/4508 [==============================] - 1s 225us/sample - loss: 0.4624 - accuracy: 0.7819 - val_loss: 0.4519 - val_accuracy: 0.7933\n",
      "1408/1408 [==============================] - 0s 99us/sample - loss: 0.4692 - accuracy: 0.7955\n",
      "Train on 4508 samples, validate on 1127 samples\n",
      "Epoch 1/100\n",
      "4508/4508 [==============================] - 2s 370us/sample - loss: 1.0002 - accuracy: 0.7014 - val_loss: 0.6337 - val_accuracy: 0.7560\n",
      "Epoch 2/100\n",
      "4508/4508 [==============================] - 1s 220us/sample - loss: 0.5914 - accuracy: 0.7580 - val_loss: 0.4849 - val_accuracy: 0.7835\n",
      "Epoch 3/100\n",
      "4508/4508 [==============================] - 1s 220us/sample - loss: 0.5326 - accuracy: 0.7642 - val_loss: 0.6042 - val_accuracy: 0.7498\n",
      "Epoch 4/100\n",
      "4508/4508 [==============================] - 1s 220us/sample - loss: 0.5008 - accuracy: 0.7762 - val_loss: 0.6541 - val_accuracy: 0.7808\n",
      "Epoch 5/100\n",
      "4508/4508 [==============================] - 1s 220us/sample - loss: 0.5175 - accuracy: 0.7755 - val_loss: 0.4837 - val_accuracy: 0.7720\n",
      "Epoch 6/100\n",
      "4508/4508 [==============================] - 1s 218us/sample - loss: 0.4868 - accuracy: 0.7760 - val_loss: 0.4899 - val_accuracy: 0.7835\n",
      "Epoch 7/100\n",
      "4508/4508 [==============================] - 1s 221us/sample - loss: 0.4622 - accuracy: 0.7886 - val_loss: 0.4685 - val_accuracy: 0.7906\n",
      "Epoch 8/100\n",
      "4508/4508 [==============================] - 1s 217us/sample - loss: 0.4901 - accuracy: 0.7757 - val_loss: 0.4629 - val_accuracy: 0.7862\n",
      "Epoch 9/100\n",
      "4508/4508 [==============================] - 1s 222us/sample - loss: 0.4948 - accuracy: 0.7791 - val_loss: 0.4658 - val_accuracy: 0.7853\n",
      "Epoch 10/100\n",
      "4508/4508 [==============================] - 1s 222us/sample - loss: 0.4679 - accuracy: 0.7899 - val_loss: 0.6411 - val_accuracy: 0.6424\n",
      "Epoch 11/100\n",
      "4508/4508 [==============================] - 1s 220us/sample - loss: 0.4744 - accuracy: 0.7748 - val_loss: 0.4653 - val_accuracy: 0.7906\n",
      "Epoch 12/100\n",
      "4508/4508 [==============================] - 1s 222us/sample - loss: 0.4504 - accuracy: 0.7944 - val_loss: 0.4878 - val_accuracy: 0.7941\n",
      "Epoch 13/100\n",
      "4508/4508 [==============================] - 1s 221us/sample - loss: 0.4545 - accuracy: 0.7835 - val_loss: 0.4711 - val_accuracy: 0.7604\n",
      "Epoch 14/100\n",
      "4508/4508 [==============================] - 1s 219us/sample - loss: 0.4633 - accuracy: 0.7877 - val_loss: 0.4767 - val_accuracy: 0.7897\n",
      "Epoch 15/100\n",
      "4508/4508 [==============================] - 1s 219us/sample - loss: 0.4621 - accuracy: 0.7819 - val_loss: 0.4779 - val_accuracy: 0.7879\n",
      "Epoch 16/100\n",
      "4508/4508 [==============================] - 1s 221us/sample - loss: 0.4799 - accuracy: 0.7802 - val_loss: 0.4655 - val_accuracy: 0.7933\n",
      "Epoch 17/100\n",
      "4508/4508 [==============================] - 1s 225us/sample - loss: 0.4503 - accuracy: 0.7897 - val_loss: 0.4527 - val_accuracy: 0.7950\n",
      "1408/1408 [==============================] - 0s 102us/sample - loss: 0.4363 - accuracy: 0.7947\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/100\n",
      "4507/4507 [==============================] - 2s 341us/sample - loss: 24.8870 - accuracy: 0.2643 - val_loss: 15.6108 - val_accuracy: 0.2706\n",
      "Epoch 2/100\n",
      "4507/4507 [==============================] - 1s 204us/sample - loss: 5.4238 - accuracy: 0.3805 - val_loss: 0.7978 - val_accuracy: 0.6495\n",
      "Epoch 3/100\n",
      "4507/4507 [==============================] - 1s 210us/sample - loss: 0.7675 - accuracy: 0.6446 - val_loss: 0.7553 - val_accuracy: 0.6566\n",
      "Epoch 4/100\n",
      "4507/4507 [==============================] - 1s 207us/sample - loss: 0.7314 - accuracy: 0.6510 - val_loss: 0.7220 - val_accuracy: 0.6699\n",
      "Epoch 5/100\n",
      "4507/4507 [==============================] - 1s 201us/sample - loss: 0.7069 - accuracy: 0.6612 - val_loss: 0.6955 - val_accuracy: 0.6584\n",
      "Epoch 6/100\n",
      "4507/4507 [==============================] - 1s 206us/sample - loss: 0.6867 - accuracy: 0.6599 - val_loss: 0.6928 - val_accuracy: 0.6965\n",
      "Epoch 7/100\n",
      "4507/4507 [==============================] - 1s 210us/sample - loss: 0.6702 - accuracy: 0.6727 - val_loss: 0.6646 - val_accuracy: 0.6575\n",
      "Epoch 8/100\n",
      "4507/4507 [==============================] - 1s 203us/sample - loss: 0.6578 - accuracy: 0.6805 - val_loss: 0.6508 - val_accuracy: 0.6806\n",
      "Epoch 9/100\n",
      "4507/4507 [==============================] - 1s 204us/sample - loss: 0.6451 - accuracy: 0.6872 - val_loss: 0.6420 - val_accuracy: 0.7098\n",
      "Epoch 10/100\n",
      "4507/4507 [==============================] - 1s 206us/sample - loss: 0.6331 - accuracy: 0.6963 - val_loss: 0.6338 - val_accuracy: 0.7134\n",
      "Epoch 11/100\n",
      "4507/4507 [==============================] - 1s 205us/sample - loss: 0.6233 - accuracy: 0.7029 - val_loss: 0.6164 - val_accuracy: 0.7107\n",
      "Epoch 12/100\n",
      "4507/4507 [==============================] - 1s 204us/sample - loss: 0.6137 - accuracy: 0.7098 - val_loss: 0.6082 - val_accuracy: 0.7303\n",
      "Epoch 13/100\n",
      "4507/4507 [==============================] - 1s 201us/sample - loss: 0.6040 - accuracy: 0.7209 - val_loss: 0.6019 - val_accuracy: 0.7400\n",
      "Epoch 14/100\n",
      "4507/4507 [==============================] - 1s 203us/sample - loss: 0.5964 - accuracy: 0.7260 - val_loss: 0.5896 - val_accuracy: 0.7418\n",
      "Epoch 15/100\n",
      "4507/4507 [==============================] - 1s 202us/sample - loss: 0.5877 - accuracy: 0.7289 - val_loss: 0.5812 - val_accuracy: 0.7445\n",
      "Epoch 16/100\n",
      "4507/4507 [==============================] - 1s 202us/sample - loss: 0.5727 - accuracy: 0.7353 - val_loss: 0.5579 - val_accuracy: 0.7507\n",
      "Epoch 17/100\n",
      "4507/4507 [==============================] - 1s 204us/sample - loss: 0.5435 - accuracy: 0.7417 - val_loss: 0.5397 - val_accuracy: 0.7533\n",
      "Epoch 18/100\n",
      "4507/4507 [==============================] - 1s 205us/sample - loss: 0.5332 - accuracy: 0.7484 - val_loss: 0.5315 - val_accuracy: 0.7622\n",
      "Epoch 19/100\n",
      "4507/4507 [==============================] - 1s 205us/sample - loss: 0.5303 - accuracy: 0.7499 - val_loss: 0.5219 - val_accuracy: 0.7613\n",
      "Epoch 20/100\n",
      "4507/4507 [==============================] - 1s 204us/sample - loss: 0.5276 - accuracy: 0.7513 - val_loss: 0.5219 - val_accuracy: 0.7631\n",
      "Epoch 21/100\n",
      "4507/4507 [==============================] - 1s 202us/sample - loss: 0.5265 - accuracy: 0.7519 - val_loss: 0.5186 - val_accuracy: 0.7631\n",
      "Epoch 22/100\n",
      "4507/4507 [==============================] - 1s 206us/sample - loss: 0.5234 - accuracy: 0.7537 - val_loss: 0.5214 - val_accuracy: 0.7649\n",
      "Epoch 23/100\n",
      "4507/4507 [==============================] - 1s 205us/sample - loss: 0.5234 - accuracy: 0.7548 - val_loss: 0.5245 - val_accuracy: 0.7675\n",
      "Epoch 24/100\n",
      "4507/4507 [==============================] - 1s 204us/sample - loss: 0.5226 - accuracy: 0.7548 - val_loss: 0.5152 - val_accuracy: 0.7693\n",
      "Epoch 25/100\n",
      "4507/4507 [==============================] - 1s 204us/sample - loss: 0.5209 - accuracy: 0.7557 - val_loss: 0.5177 - val_accuracy: 0.7702\n",
      "Epoch 26/100\n",
      "4507/4507 [==============================] - 1s 203us/sample - loss: 0.5189 - accuracy: 0.7568 - val_loss: 0.5130 - val_accuracy: 0.7711\n",
      "Epoch 27/100\n",
      "4507/4507 [==============================] - 1s 199us/sample - loss: 0.5181 - accuracy: 0.7573 - val_loss: 0.5121 - val_accuracy: 0.7720\n",
      "Epoch 28/100\n",
      "4507/4507 [==============================] - 1s 202us/sample - loss: 0.5174 - accuracy: 0.7586 - val_loss: 0.5108 - val_accuracy: 0.7728\n",
      "Epoch 29/100\n",
      "4507/4507 [==============================] - 1s 203us/sample - loss: 0.5155 - accuracy: 0.7608 - val_loss: 0.5101 - val_accuracy: 0.7728\n",
      "Epoch 30/100\n",
      "4507/4507 [==============================] - 1s 206us/sample - loss: 0.5148 - accuracy: 0.7602 - val_loss: 0.5131 - val_accuracy: 0.7782\n",
      "Epoch 31/100\n",
      "4507/4507 [==============================] - 1s 202us/sample - loss: 0.5138 - accuracy: 0.7613 - val_loss: 0.5200 - val_accuracy: 0.7773\n",
      "Epoch 32/100\n",
      "4507/4507 [==============================] - 1s 202us/sample - loss: 0.5129 - accuracy: 0.7626 - val_loss: 0.5086 - val_accuracy: 0.7755\n",
      "Epoch 33/100\n",
      "4507/4507 [==============================] - 1s 213us/sample - loss: 0.5116 - accuracy: 0.7615 - val_loss: 0.5078 - val_accuracy: 0.7808\n",
      "Epoch 34/100\n",
      "4507/4507 [==============================] - 1s 200us/sample - loss: 0.5109 - accuracy: 0.7630 - val_loss: 0.5145 - val_accuracy: 0.7791\n",
      "Epoch 35/100\n",
      "4507/4507 [==============================] - 1s 210us/sample - loss: 0.5104 - accuracy: 0.7637 - val_loss: 0.5080 - val_accuracy: 0.7808\n",
      "Epoch 36/100\n",
      "4507/4507 [==============================] - 1s 211us/sample - loss: 0.5096 - accuracy: 0.7641 - val_loss: 0.5061 - val_accuracy: 0.7808\n",
      "Epoch 37/100\n",
      "4507/4507 [==============================] - 1s 199us/sample - loss: 0.5086 - accuracy: 0.7646 - val_loss: 0.5105 - val_accuracy: 0.7799\n",
      "Epoch 38/100\n",
      "4507/4507 [==============================] - 1s 199us/sample - loss: 0.5075 - accuracy: 0.7644 - val_loss: 0.5053 - val_accuracy: 0.7835\n",
      "Epoch 39/100\n",
      "4507/4507 [==============================] - 1s 205us/sample - loss: 0.5069 - accuracy: 0.7655 - val_loss: 0.5042 - val_accuracy: 0.7835\n",
      "Epoch 40/100\n",
      "4507/4507 [==============================] - 1s 204us/sample - loss: 0.5071 - accuracy: 0.7661 - val_loss: 0.5047 - val_accuracy: 0.7835\n",
      "Epoch 41/100\n",
      "4507/4507 [==============================] - 1s 199us/sample - loss: 0.5062 - accuracy: 0.7673 - val_loss: 0.5029 - val_accuracy: 0.7853\n",
      "Epoch 42/100\n",
      "4507/4507 [==============================] - 1s 201us/sample - loss: 0.5053 - accuracy: 0.7684 - val_loss: 0.5033 - val_accuracy: 0.7826\n",
      "Epoch 43/100\n",
      "4507/4507 [==============================] - 1s 204us/sample - loss: 0.5046 - accuracy: 0.7675 - val_loss: 0.5078 - val_accuracy: 0.7853\n",
      "Epoch 44/100\n",
      "4507/4507 [==============================] - 1s 205us/sample - loss: 0.5044 - accuracy: 0.7686 - val_loss: 0.5010 - val_accuracy: 0.7826\n",
      "Epoch 45/100\n",
      "4507/4507 [==============================] - 1s 207us/sample - loss: 0.5015 - accuracy: 0.7692 - val_loss: 0.5197 - val_accuracy: 0.7826\n",
      "Epoch 46/100\n",
      "4507/4507 [==============================] - 1s 204us/sample - loss: 0.5028 - accuracy: 0.7681 - val_loss: 0.5008 - val_accuracy: 0.7817\n",
      "Epoch 47/100\n",
      "4507/4507 [==============================] - 1s 204us/sample - loss: 0.5023 - accuracy: 0.7690 - val_loss: 0.5023 - val_accuracy: 0.7817\n",
      "1409/1409 [==============================] - 0s 102us/sample - loss: 0.4976 - accuracy: 0.7700\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/100\n",
      "4507/4507 [==============================] - 2s 542us/sample - loss: 37.9650 - accuracy: 0.2678 - val_loss: 30.0974 - val_accuracy: 0.2724\n",
      "Epoch 2/100\n",
      "4507/4507 [==============================] - 1s 204us/sample - loss: 18.4315 - accuracy: 0.2682 - val_loss: 4.9661 - val_accuracy: 0.2724\n",
      "Epoch 3/100\n",
      "4507/4507 [==============================] - 1s 201us/sample - loss: 0.9198 - accuracy: 0.6239 - val_loss: 0.5827 - val_accuracy: 0.7578\n",
      "Epoch 4/100\n",
      "4507/4507 [==============================] - 1s 204us/sample - loss: 0.5776 - accuracy: 0.7484 - val_loss: 0.5655 - val_accuracy: 0.7622\n",
      "Epoch 5/100\n",
      "4507/4507 [==============================] - 1s 203us/sample - loss: 0.5647 - accuracy: 0.7497 - val_loss: 0.5570 - val_accuracy: 0.7640\n",
      "Epoch 6/100\n",
      "4507/4507 [==============================] - 1s 204us/sample - loss: 0.5589 - accuracy: 0.7504 - val_loss: 0.5512 - val_accuracy: 0.7631\n",
      "Epoch 7/100\n",
      "4507/4507 [==============================] - 1s 203us/sample - loss: 0.5532 - accuracy: 0.7499 - val_loss: 0.5466 - val_accuracy: 0.7622\n",
      "Epoch 8/100\n",
      "4507/4507 [==============================] - 1s 203us/sample - loss: 0.5489 - accuracy: 0.7504 - val_loss: 0.5422 - val_accuracy: 0.7622\n",
      "Epoch 9/100\n",
      "4507/4507 [==============================] - 1s 206us/sample - loss: 0.5444 - accuracy: 0.7502 - val_loss: 0.5428 - val_accuracy: 0.7622\n",
      "Epoch 10/100\n",
      "4507/4507 [==============================] - 1s 208us/sample - loss: 0.5388 - accuracy: 0.7497 - val_loss: 0.5246 - val_accuracy: 0.7631\n",
      "1409/1409 [==============================] - 0s 100us/sample - loss: 0.5353 - accuracy: 0.7551\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/100\n",
      "4507/4507 [==============================] - 2s 355us/sample - loss: 1.3363 - accuracy: 0.7566 - val_loss: 0.5954 - val_accuracy: 0.7604\n",
      "Epoch 2/100\n",
      "4507/4507 [==============================] - 1s 205us/sample - loss: 0.5801 - accuracy: 0.7537 - val_loss: 0.5653 - val_accuracy: 0.7578\n",
      "Epoch 3/100\n",
      "4507/4507 [==============================] - 1s 203us/sample - loss: 0.5675 - accuracy: 0.7531 - val_loss: 0.5579 - val_accuracy: 0.7587\n",
      "Epoch 4/100\n",
      "4507/4507 [==============================] - 1s 203us/sample - loss: 0.5593 - accuracy: 0.7522 - val_loss: 0.5497 - val_accuracy: 0.7595\n",
      "Epoch 5/100\n",
      "4507/4507 [==============================] - 1s 202us/sample - loss: 0.5540 - accuracy: 0.7528 - val_loss: 0.5504 - val_accuracy: 0.7631\n",
      "Epoch 6/100\n",
      "4507/4507 [==============================] - 1s 202us/sample - loss: 0.5502 - accuracy: 0.7519 - val_loss: 0.5432 - val_accuracy: 0.7640\n",
      "1409/1409 [==============================] - 0s 100us/sample - loss: 0.5590 - accuracy: 0.7381\n",
      "Train on 4508 samples, validate on 1127 samples\n",
      "Epoch 1/100\n",
      "4508/4508 [==============================] - 2s 335us/sample - loss: 34.8804 - accuracy: 0.7378 - val_loss: 36.0364 - val_accuracy: 0.7294\n",
      "Epoch 2/100\n",
      "4508/4508 [==============================] - 1s 201us/sample - loss: 29.7223 - accuracy: 0.7378 - val_loss: 31.4280 - val_accuracy: 0.7294\n",
      "Epoch 3/100\n",
      "4508/4508 [==============================] - 1s 200us/sample - loss: 25.8137 - accuracy: 0.7378 - val_loss: 27.2658 - val_accuracy: 0.7294\n",
      "Epoch 4/100\n",
      "4508/4508 [==============================] - 1s 201us/sample - loss: 22.4510 - accuracy: 0.7378 - val_loss: 23.6148 - val_accuracy: 0.7294\n",
      "Epoch 5/100\n",
      "4508/4508 [==============================] - 1s 199us/sample - loss: 19.1245 - accuracy: 0.7378 - val_loss: 19.6039 - val_accuracy: 0.7294\n",
      "Epoch 6/100\n",
      "4508/4508 [==============================] - 1s 200us/sample - loss: 15.1603 - accuracy: 0.7378 - val_loss: 15.1320 - val_accuracy: 0.7276\n",
      "1408/1408 [==============================] - 0s 100us/sample - loss: 13.5247 - accuracy: 0.7287\n",
      "Train on 4508 samples, validate on 1127 samples\n",
      "Epoch 1/100\n",
      "4508/4508 [==============================] - 2s 340us/sample - loss: 11.4280 - accuracy: 0.7484 - val_loss: 10.5724 - val_accuracy: 0.7480\n",
      "Epoch 2/100\n",
      "4508/4508 [==============================] - 1s 218us/sample - loss: 9.2908 - accuracy: 0.7551 - val_loss: 8.2428 - val_accuracy: 0.7471\n",
      "Epoch 3/100\n",
      "4508/4508 [==============================] - 1s 207us/sample - loss: 6.7845 - accuracy: 0.7555 - val_loss: 5.6780 - val_accuracy: 0.7498\n",
      "Epoch 4/100\n",
      "4508/4508 [==============================] - 1s 218us/sample - loss: 4.4095 - accuracy: 0.7571 - val_loss: 3.4535 - val_accuracy: 0.7498\n",
      "Epoch 5/100\n",
      "4508/4508 [==============================] - 1s 212us/sample - loss: 2.6204 - accuracy: 0.7538 - val_loss: 1.8037 - val_accuracy: 0.7498\n",
      "Epoch 6/100\n",
      "4508/4508 [==============================] - 1s 215us/sample - loss: 0.9165 - accuracy: 0.7449 - val_loss: 0.5139 - val_accuracy: 0.7524\n",
      "Epoch 7/100\n",
      "4508/4508 [==============================] - 1s 208us/sample - loss: 0.5231 - accuracy: 0.7356 - val_loss: 0.5102 - val_accuracy: 0.7480\n",
      "Epoch 8/100\n",
      "4508/4508 [==============================] - 1s 215us/sample - loss: 0.5169 - accuracy: 0.7349 - val_loss: 0.5027 - val_accuracy: 0.7480\n",
      "Epoch 9/100\n",
      "4508/4508 [==============================] - 1s 209us/sample - loss: 0.5078 - accuracy: 0.7396 - val_loss: 0.5000 - val_accuracy: 0.7507\n",
      "1408/1408 [==============================] - 0s 105us/sample - loss: 0.4984 - accuracy: 0.7457\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/100\n",
      "4507/4507 [==============================] - 3s 588us/sample - loss: 1.9805 - accuracy: 0.6812 - val_loss: 0.7187 - val_accuracy: 0.7702\n",
      "Epoch 2/100\n",
      "4507/4507 [==============================] - 1s 293us/sample - loss: 0.9549 - accuracy: 0.7224 - val_loss: 1.0148 - val_accuracy: 0.7791\n",
      "Epoch 3/100\n",
      "4507/4507 [==============================] - 1s 303us/sample - loss: 0.5330 - accuracy: 0.7648 - val_loss: 0.5295 - val_accuracy: 0.7906\n",
      "Epoch 4/100\n",
      "4507/4507 [==============================] - 1s 311us/sample - loss: 0.7281 - accuracy: 0.7406 - val_loss: 0.5203 - val_accuracy: 0.7791\n",
      "Epoch 5/100\n",
      "4507/4507 [==============================] - 1s 323us/sample - loss: 0.5113 - accuracy: 0.7730 - val_loss: 0.5764 - val_accuracy: 0.7844\n",
      "Epoch 6/100\n",
      "4507/4507 [==============================] - 2s 356us/sample - loss: 0.4991 - accuracy: 0.7721 - val_loss: 0.4799 - val_accuracy: 0.7879\n",
      "Epoch 7/100\n",
      "4507/4507 [==============================] - 1s 328us/sample - loss: 0.4980 - accuracy: 0.7721 - val_loss: 0.5377 - val_accuracy: 0.7782\n",
      "Epoch 8/100\n",
      "4507/4507 [==============================] - 2s 336us/sample - loss: 0.4859 - accuracy: 0.7724 - val_loss: 0.4565 - val_accuracy: 0.7826\n",
      "Epoch 9/100\n",
      "4507/4507 [==============================] - 1s 327us/sample - loss: 0.4599 - accuracy: 0.7815 - val_loss: 0.4420 - val_accuracy: 0.7924\n",
      "Epoch 10/100\n",
      "4507/4507 [==============================] - 2s 362us/sample - loss: 0.4708 - accuracy: 0.7792 - val_loss: 0.4622 - val_accuracy: 0.8012\n",
      "Epoch 11/100\n",
      "4507/4507 [==============================] - 1s 320us/sample - loss: 0.4566 - accuracy: 0.7837 - val_loss: 0.4571 - val_accuracy: 0.8030\n",
      "Epoch 12/100\n",
      "4507/4507 [==============================] - 2s 349us/sample - loss: 0.4805 - accuracy: 0.7810 - val_loss: 0.4561 - val_accuracy: 0.7915\n",
      "Epoch 13/100\n",
      "4507/4507 [==============================] - 1s 328us/sample - loss: 0.4796 - accuracy: 0.7803 - val_loss: 0.4683 - val_accuracy: 0.7924\n",
      "Epoch 14/100\n",
      "4507/4507 [==============================] - 2s 344us/sample - loss: 0.4690 - accuracy: 0.7850 - val_loss: 0.4482 - val_accuracy: 0.7968\n",
      "Epoch 15/100\n",
      "4507/4507 [==============================] - 2s 342us/sample - loss: 0.4697 - accuracy: 0.7808 - val_loss: 0.8234 - val_accuracy: 0.7799\n",
      "Epoch 16/100\n",
      "4507/4507 [==============================] - 1s 300us/sample - loss: 0.4759 - accuracy: 0.7863 - val_loss: 0.4495 - val_accuracy: 0.7888\n",
      "Epoch 17/100\n",
      "4507/4507 [==============================] - 1s 323us/sample - loss: 0.4772 - accuracy: 0.7863 - val_loss: 0.4630 - val_accuracy: 0.7870\n",
      "Epoch 18/100\n",
      "4507/4507 [==============================] - 1s 308us/sample - loss: 0.4733 - accuracy: 0.7843 - val_loss: 0.4638 - val_accuracy: 0.7862\n",
      "Epoch 19/100\n",
      "4507/4507 [==============================] - 1s 296us/sample - loss: 0.4733 - accuracy: 0.7783 - val_loss: 0.4538 - val_accuracy: 0.7959\n",
      "Epoch 20/100\n",
      "4507/4507 [==============================] - 1s 298us/sample - loss: 0.4653 - accuracy: 0.7872 - val_loss: 1.1346 - val_accuracy: 0.5004\n",
      "Epoch 21/100\n",
      "4507/4507 [==============================] - 1s 303us/sample - loss: 0.4882 - accuracy: 0.7803 - val_loss: 0.4420 - val_accuracy: 0.7906\n",
      "1409/1409 [==============================] - 0s 102us/sample - loss: 0.4435 - accuracy: 0.7871\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/100\n",
      "4507/4507 [==============================] - 3s 600us/sample - loss: 1.4994 - accuracy: 0.7049 - val_loss: 0.5629 - val_accuracy: 0.7844\n",
      "Epoch 2/100\n",
      "4507/4507 [==============================] - 1s 299us/sample - loss: 0.5790 - accuracy: 0.7550 - val_loss: 0.5717 - val_accuracy: 0.7862\n",
      "Epoch 3/100\n",
      "4507/4507 [==============================] - 1s 313us/sample - loss: 0.5272 - accuracy: 0.7726 - val_loss: 0.5206 - val_accuracy: 0.7826\n",
      "Epoch 4/100\n",
      "4507/4507 [==============================] - 1s 313us/sample - loss: 0.5115 - accuracy: 0.7737 - val_loss: 0.5008 - val_accuracy: 0.7808\n",
      "Epoch 5/100\n",
      "4507/4507 [==============================] - 1s 301us/sample - loss: 0.5424 - accuracy: 0.7704 - val_loss: 0.4833 - val_accuracy: 0.7941\n",
      "Epoch 6/100\n",
      "4507/4507 [==============================] - 2s 354us/sample - loss: 0.4905 - accuracy: 0.7783 - val_loss: 0.4615 - val_accuracy: 0.7853\n",
      "Epoch 7/100\n",
      "4507/4507 [==============================] - 2s 335us/sample - loss: 0.4977 - accuracy: 0.7783 - val_loss: 0.4697 - val_accuracy: 0.7817\n",
      "Epoch 8/100\n",
      "4507/4507 [==============================] - 2s 419us/sample - loss: 0.4834 - accuracy: 0.7786 - val_loss: 0.4539 - val_accuracy: 0.7862\n",
      "Epoch 9/100\n",
      "4507/4507 [==============================] - 2s 426us/sample - loss: 0.4862 - accuracy: 0.7828 - val_loss: 0.4701 - val_accuracy: 0.7950\n",
      "Epoch 10/100\n",
      "4507/4507 [==============================] - 2s 352us/sample - loss: 0.5156 - accuracy: 0.7721 - val_loss: 1.1681 - val_accuracy: 0.5058\n",
      "Epoch 11/100\n",
      "4507/4507 [==============================] - 1s 297us/sample - loss: 0.5026 - accuracy: 0.7757 - val_loss: 0.4697 - val_accuracy: 0.7888\n",
      "Epoch 12/100\n",
      "4507/4507 [==============================] - 1s 279us/sample - loss: 0.4721 - accuracy: 0.7839 - val_loss: 0.4711 - val_accuracy: 0.7870\n",
      "Epoch 13/100\n",
      "4507/4507 [==============================] - 1s 268us/sample - loss: 0.4839 - accuracy: 0.7830 - val_loss: 0.4572 - val_accuracy: 0.7933\n",
      "Epoch 14/100\n",
      "4507/4507 [==============================] - 1s 267us/sample - loss: 0.4753 - accuracy: 0.7843 - val_loss: 0.4834 - val_accuracy: 0.7915\n",
      "Epoch 15/100\n",
      "4507/4507 [==============================] - 1s 266us/sample - loss: 0.4725 - accuracy: 0.7872 - val_loss: 0.4315 - val_accuracy: 0.7924\n",
      "Epoch 16/100\n",
      "4507/4507 [==============================] - 1s 300us/sample - loss: 0.4671 - accuracy: 0.7863 - val_loss: 0.4505 - val_accuracy: 0.8012\n",
      "Epoch 17/100\n",
      "4507/4507 [==============================] - 2s 378us/sample - loss: 0.4816 - accuracy: 0.7797 - val_loss: 0.4576 - val_accuracy: 0.7764\n",
      "Epoch 18/100\n",
      "4507/4507 [==============================] - 2s 365us/sample - loss: 0.4610 - accuracy: 0.7866 - val_loss: 0.4532 - val_accuracy: 0.7959\n",
      "Epoch 19/100\n",
      "4507/4507 [==============================] - 2s 343us/sample - loss: 0.4580 - accuracy: 0.7863 - val_loss: 0.4487 - val_accuracy: 0.7933\n",
      "Epoch 20/100\n",
      "4507/4507 [==============================] - 2s 348us/sample - loss: 0.4608 - accuracy: 0.7868 - val_loss: 0.4642 - val_accuracy: 0.7817\n",
      "1409/1409 [==============================] - 0s 121us/sample - loss: 0.4600 - accuracy: 0.7864\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/100\n",
      "4507/4507 [==============================] - 3s 672us/sample - loss: 1.6158 - accuracy: 0.6963 - val_loss: 0.6706 - val_accuracy: 0.7799\n",
      "Epoch 2/100\n",
      "4507/4507 [==============================] - 2s 370us/sample - loss: 0.5982 - accuracy: 0.7524 - val_loss: 0.5353 - val_accuracy: 0.7888\n",
      "Epoch 3/100\n",
      "4507/4507 [==============================] - 2s 345us/sample - loss: 0.5211 - accuracy: 0.7739 - val_loss: 0.4530 - val_accuracy: 0.7888\n",
      "Epoch 4/100\n",
      "4507/4507 [==============================] - 2s 370us/sample - loss: 0.5762 - accuracy: 0.7595 - val_loss: 0.5626 - val_accuracy: 0.7799\n",
      "Epoch 5/100\n",
      "4507/4507 [==============================] - 1s 319us/sample - loss: 0.4867 - accuracy: 0.7755 - val_loss: 0.4903 - val_accuracy: 0.7906\n",
      "Epoch 6/100\n",
      "4507/4507 [==============================] - 2s 342us/sample - loss: 0.4750 - accuracy: 0.7839 - val_loss: 0.4752 - val_accuracy: 0.7888\n",
      "Epoch 7/100\n",
      "4507/4507 [==============================] - 2s 340us/sample - loss: 0.4882 - accuracy: 0.7790 - val_loss: 0.4818 - val_accuracy: 0.7862\n",
      "Epoch 8/100\n",
      "4507/4507 [==============================] - 1s 320us/sample - loss: 0.4743 - accuracy: 0.7841 - val_loss: 0.6524 - val_accuracy: 0.7817\n",
      "Epoch 9/100\n",
      "4507/4507 [==============================] - 1s 306us/sample - loss: 0.4987 - accuracy: 0.7781 - val_loss: 0.4856 - val_accuracy: 0.7906\n",
      "Epoch 10/100\n",
      "4507/4507 [==============================] - 1s 306us/sample - loss: 0.4637 - accuracy: 0.7866 - val_loss: 0.4440 - val_accuracy: 0.7941\n",
      "Epoch 11/100\n",
      "4507/4507 [==============================] - 1s 315us/sample - loss: 0.4610 - accuracy: 0.7894 - val_loss: 0.4462 - val_accuracy: 0.7924\n",
      "Epoch 12/100\n",
      "4507/4507 [==============================] - 1s 321us/sample - loss: 0.4580 - accuracy: 0.7899 - val_loss: 0.4788 - val_accuracy: 0.7915\n",
      "Epoch 13/100\n",
      "4507/4507 [==============================] - 1s 318us/sample - loss: 0.4647 - accuracy: 0.7901 - val_loss: 0.4407 - val_accuracy: 0.8004\n",
      "Epoch 14/100\n",
      "4507/4507 [==============================] - 1s 297us/sample - loss: 0.4513 - accuracy: 0.7970 - val_loss: 0.4958 - val_accuracy: 0.7906\n",
      "Epoch 15/100\n",
      "4507/4507 [==============================] - 1s 302us/sample - loss: 0.4475 - accuracy: 0.7972 - val_loss: 0.4532 - val_accuracy: 0.7933\n",
      "Epoch 16/100\n",
      "4507/4507 [==============================] - 1s 285us/sample - loss: 0.4481 - accuracy: 0.7988 - val_loss: 0.4672 - val_accuracy: 0.7853\n",
      "Epoch 17/100\n",
      "4507/4507 [==============================] - 1s 289us/sample - loss: 0.4571 - accuracy: 0.8008 - val_loss: 0.4558 - val_accuracy: 0.7924\n",
      "Epoch 18/100\n",
      "4507/4507 [==============================] - 1s 284us/sample - loss: 0.4467 - accuracy: 0.7950 - val_loss: 0.4340 - val_accuracy: 0.7941\n",
      "Epoch 19/100\n",
      "4507/4507 [==============================] - 1s 297us/sample - loss: 0.4430 - accuracy: 0.7954 - val_loss: 0.4625 - val_accuracy: 0.7959\n",
      "Epoch 20/100\n",
      "4507/4507 [==============================] - 1s 295us/sample - loss: 0.4495 - accuracy: 0.7919 - val_loss: 0.4393 - val_accuracy: 0.7941\n",
      "Epoch 21/100\n",
      "4507/4507 [==============================] - 1s 292us/sample - loss: 0.4459 - accuracy: 0.7952 - val_loss: 0.4466 - val_accuracy: 0.7888\n",
      "Epoch 22/100\n",
      "4507/4507 [==============================] - 1s 297us/sample - loss: 0.4420 - accuracy: 0.8003 - val_loss: 0.4396 - val_accuracy: 0.7977\n",
      "1409/1409 [==============================] - 0s 104us/sample - loss: 0.4472 - accuracy: 0.7885\n",
      "Train on 4508 samples, validate on 1127 samples\n",
      "Epoch 1/100\n",
      "4508/4508 [==============================] - 3s 565us/sample - loss: 1.4559 - accuracy: 0.7019 - val_loss: 0.6842 - val_accuracy: 0.7862\n",
      "Epoch 2/100\n",
      "4508/4508 [==============================] - 1s 280us/sample - loss: 0.6612 - accuracy: 0.7409 - val_loss: 0.5092 - val_accuracy: 0.7844\n",
      "Epoch 3/100\n",
      "4508/4508 [==============================] - 1s 275us/sample - loss: 0.5319 - accuracy: 0.7655 - val_loss: 0.4464 - val_accuracy: 0.7879\n",
      "Epoch 4/100\n",
      "4508/4508 [==============================] - 1s 274us/sample - loss: 0.5017 - accuracy: 0.7722 - val_loss: 0.5163 - val_accuracy: 0.7782\n",
      "Epoch 5/100\n",
      "4508/4508 [==============================] - 1s 276us/sample - loss: 0.4898 - accuracy: 0.7744 - val_loss: 0.5207 - val_accuracy: 0.7906\n",
      "Epoch 6/100\n",
      "4508/4508 [==============================] - 1s 279us/sample - loss: 0.4971 - accuracy: 0.7709 - val_loss: 0.4839 - val_accuracy: 0.7915\n",
      "Epoch 7/100\n",
      "4508/4508 [==============================] - 1s 294us/sample - loss: 0.4884 - accuracy: 0.7753 - val_loss: 0.4970 - val_accuracy: 0.7950\n",
      "Epoch 8/100\n",
      "4508/4508 [==============================] - 1s 308us/sample - loss: 0.4987 - accuracy: 0.7702 - val_loss: 0.4486 - val_accuracy: 0.7924\n",
      "Epoch 9/100\n",
      "4508/4508 [==============================] - 1s 306us/sample - loss: 0.4699 - accuracy: 0.7866 - val_loss: 0.4585 - val_accuracy: 0.7870\n",
      "Epoch 10/100\n",
      "4508/4508 [==============================] - 1s 304us/sample - loss: 0.4540 - accuracy: 0.7826 - val_loss: 0.4283 - val_accuracy: 0.7986\n",
      "Epoch 11/100\n",
      "4508/4508 [==============================] - 1s 303us/sample - loss: 0.4504 - accuracy: 0.7839 - val_loss: 0.4386 - val_accuracy: 0.7968\n",
      "Epoch 12/100\n",
      "4508/4508 [==============================] - 1s 297us/sample - loss: 0.4518 - accuracy: 0.7842 - val_loss: 0.4405 - val_accuracy: 0.7870\n",
      "Epoch 13/100\n",
      "4508/4508 [==============================] - 1s 310us/sample - loss: 0.4506 - accuracy: 0.7813 - val_loss: 0.4404 - val_accuracy: 0.7906\n",
      "Epoch 14/100\n",
      "4508/4508 [==============================] - 1s 304us/sample - loss: 0.4578 - accuracy: 0.7875 - val_loss: 0.4540 - val_accuracy: 0.7782\n",
      "1408/1408 [==============================] - 0s 102us/sample - loss: 0.4814 - accuracy: 0.7777\n",
      "Train on 4508 samples, validate on 1127 samples\n",
      "Epoch 1/100\n",
      "4508/4508 [==============================] - 3s 596us/sample - loss: 1.1948 - accuracy: 0.6990 - val_loss: 0.5280 - val_accuracy: 0.7755\n",
      "Epoch 2/100\n",
      "4508/4508 [==============================] - 1s 285us/sample - loss: 0.6128 - accuracy: 0.7496 - val_loss: 0.6216 - val_accuracy: 0.6557\n",
      "Epoch 3/100\n",
      "4508/4508 [==============================] - 1s 327us/sample - loss: 0.5437 - accuracy: 0.7629 - val_loss: 0.5103 - val_accuracy: 0.7746\n",
      "Epoch 4/100\n",
      "4508/4508 [==============================] - 1s 315us/sample - loss: 0.5323 - accuracy: 0.7655 - val_loss: 0.5146 - val_accuracy: 0.7835\n",
      "Epoch 5/100\n",
      "4508/4508 [==============================] - 1s 300us/sample - loss: 0.4960 - accuracy: 0.7784 - val_loss: 0.4972 - val_accuracy: 0.7773\n",
      "Epoch 6/100\n",
      "4508/4508 [==============================] - 1s 322us/sample - loss: 0.5037 - accuracy: 0.7746 - val_loss: 0.4899 - val_accuracy: 0.7817\n",
      "Epoch 7/100\n",
      "4508/4508 [==============================] - 1s 286us/sample - loss: 0.4784 - accuracy: 0.7817 - val_loss: 0.4769 - val_accuracy: 0.7826\n",
      "Epoch 8/100\n",
      "4508/4508 [==============================] - 1s 295us/sample - loss: 0.4695 - accuracy: 0.7799 - val_loss: 0.4638 - val_accuracy: 0.7906\n",
      "Epoch 9/100\n",
      "4508/4508 [==============================] - 1s 303us/sample - loss: 0.4593 - accuracy: 0.7855 - val_loss: 0.4718 - val_accuracy: 0.7720\n",
      "Epoch 10/100\n",
      "4508/4508 [==============================] - 1s 322us/sample - loss: 0.4611 - accuracy: 0.7882 - val_loss: 0.4558 - val_accuracy: 0.7862\n",
      "Epoch 11/100\n",
      "4508/4508 [==============================] - 1s 293us/sample - loss: 0.4730 - accuracy: 0.7853 - val_loss: 0.4547 - val_accuracy: 0.7888\n",
      "Epoch 12/100\n",
      "4508/4508 [==============================] - 1s 303us/sample - loss: 0.4504 - accuracy: 0.7921 - val_loss: 0.4540 - val_accuracy: 0.7879\n",
      "Epoch 13/100\n",
      "4508/4508 [==============================] - 1s 300us/sample - loss: 0.4498 - accuracy: 0.7884 - val_loss: 0.4621 - val_accuracy: 0.7924\n",
      "Epoch 14/100\n",
      "4508/4508 [==============================] - 1s 288us/sample - loss: 0.4479 - accuracy: 0.7899 - val_loss: 0.4484 - val_accuracy: 0.7906\n",
      "Epoch 15/100\n",
      "4508/4508 [==============================] - 1s 287us/sample - loss: 0.4499 - accuracy: 0.7882 - val_loss: 0.4531 - val_accuracy: 0.7906\n",
      "Epoch 16/100\n",
      "4508/4508 [==============================] - 1s 298us/sample - loss: 0.4424 - accuracy: 0.7895 - val_loss: 0.4660 - val_accuracy: 0.7995\n",
      "Epoch 17/100\n",
      "4508/4508 [==============================] - 1s 301us/sample - loss: 0.4379 - accuracy: 0.7930 - val_loss: 0.4809 - val_accuracy: 0.7924\n",
      "1408/1408 [==============================] - 0s 99us/sample - loss: 0.4527 - accuracy: 0.7940\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/100\n",
      "4507/4507 [==============================] - 2s 447us/sample - loss: 1.7057 - accuracy: 0.6785 - val_loss: 0.8561 - val_accuracy: 0.7773\n",
      "Epoch 2/100\n",
      "4507/4507 [==============================] - 1s 229us/sample - loss: 0.6693 - accuracy: 0.7304 - val_loss: 0.5984 - val_accuracy: 0.7249\n",
      "Epoch 3/100\n",
      "4507/4507 [==============================] - 1s 228us/sample - loss: 0.5629 - accuracy: 0.7646 - val_loss: 0.5047 - val_accuracy: 0.7436\n",
      "Epoch 4/100\n",
      "4507/4507 [==============================] - 1s 234us/sample - loss: 0.5329 - accuracy: 0.7659 - val_loss: 0.5465 - val_accuracy: 0.7799\n",
      "Epoch 5/100\n",
      "4507/4507 [==============================] - 1s 232us/sample - loss: 0.5192 - accuracy: 0.7681 - val_loss: 0.5721 - val_accuracy: 0.7799\n",
      "Epoch 6/100\n",
      "4507/4507 [==============================] - 1s 230us/sample - loss: 0.5255 - accuracy: 0.7686 - val_loss: 0.4665 - val_accuracy: 0.7977\n",
      "Epoch 7/100\n",
      "4507/4507 [==============================] - 1s 231us/sample - loss: 0.5256 - accuracy: 0.7726 - val_loss: 0.6000 - val_accuracy: 0.5865\n",
      "Epoch 8/100\n",
      "4507/4507 [==============================] - 1s 225us/sample - loss: 0.5150 - accuracy: 0.7719 - val_loss: 0.4637 - val_accuracy: 0.7853\n",
      "Epoch 9/100\n",
      "4507/4507 [==============================] - 1s 238us/sample - loss: 0.5056 - accuracy: 0.7735 - val_loss: 0.4650 - val_accuracy: 0.7791\n",
      "Epoch 10/100\n",
      "4507/4507 [==============================] - 1s 258us/sample - loss: 0.5027 - accuracy: 0.7775 - val_loss: 0.4579 - val_accuracy: 0.7941\n",
      "Epoch 11/100\n",
      "4507/4507 [==============================] - 1s 232us/sample - loss: 0.5019 - accuracy: 0.7795 - val_loss: 0.4719 - val_accuracy: 0.7906\n",
      "Epoch 12/100\n",
      "4507/4507 [==============================] - 1s 226us/sample - loss: 0.4974 - accuracy: 0.7808 - val_loss: 0.5506 - val_accuracy: 0.7879\n",
      "Epoch 13/100\n",
      "4507/4507 [==============================] - 1s 220us/sample - loss: 0.4942 - accuracy: 0.7808 - val_loss: 0.4816 - val_accuracy: 0.7835\n",
      "Epoch 14/100\n",
      "4507/4507 [==============================] - 1s 220us/sample - loss: 0.4997 - accuracy: 0.7770 - val_loss: 0.4714 - val_accuracy: 0.7862\n",
      "Epoch 15/100\n",
      "4507/4507 [==============================] - 1s 222us/sample - loss: 0.4851 - accuracy: 0.7806 - val_loss: 0.4521 - val_accuracy: 0.7933\n",
      "Epoch 16/100\n",
      "4507/4507 [==============================] - 1s 229us/sample - loss: 0.4935 - accuracy: 0.7781 - val_loss: 0.4729 - val_accuracy: 0.7551\n",
      "Epoch 17/100\n",
      "4507/4507 [==============================] - 1s 222us/sample - loss: 0.4868 - accuracy: 0.7772 - val_loss: 0.4548 - val_accuracy: 0.7915\n",
      "1409/1409 [==============================] - 0s 104us/sample - loss: 0.4579 - accuracy: 0.8034\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/100\n",
      "4507/4507 [==============================] - 2s 454us/sample - loss: 1.8891 - accuracy: 0.6838 - val_loss: 0.5423 - val_accuracy: 0.7862\n",
      "Epoch 2/100\n",
      "4507/4507 [==============================] - 1s 227us/sample - loss: 0.7081 - accuracy: 0.7366 - val_loss: 1.0184 - val_accuracy: 0.7826\n",
      "Epoch 3/100\n",
      "4507/4507 [==============================] - 1s 236us/sample - loss: 0.6017 - accuracy: 0.7508 - val_loss: 0.4608 - val_accuracy: 0.7915\n",
      "Epoch 4/100\n",
      "4507/4507 [==============================] - 1s 253us/sample - loss: 0.5494 - accuracy: 0.7628 - val_loss: 0.5260 - val_accuracy: 0.7844\n",
      "Epoch 5/100\n",
      "4507/4507 [==============================] - 1s 261us/sample - loss: 0.5494 - accuracy: 0.7690 - val_loss: 0.4730 - val_accuracy: 0.7782\n",
      "Epoch 6/100\n",
      "4507/4507 [==============================] - 1s 254us/sample - loss: 0.5469 - accuracy: 0.7661 - val_loss: 0.4588 - val_accuracy: 0.7870\n",
      "Epoch 7/100\n",
      "4507/4507 [==============================] - 1s 257us/sample - loss: 0.5275 - accuracy: 0.7783 - val_loss: 0.4796 - val_accuracy: 0.7879\n",
      "Epoch 8/100\n",
      "4507/4507 [==============================] - 1s 234us/sample - loss: 0.5248 - accuracy: 0.7730 - val_loss: 0.4774 - val_accuracy: 0.7986\n",
      "Epoch 9/100\n",
      "4507/4507 [==============================] - 1s 222us/sample - loss: 0.5261 - accuracy: 0.7770 - val_loss: 0.4715 - val_accuracy: 0.7986\n",
      "Epoch 10/100\n",
      "4507/4507 [==============================] - 1s 222us/sample - loss: 0.5263 - accuracy: 0.7797 - val_loss: 0.4764 - val_accuracy: 0.7826\n",
      "Epoch 11/100\n",
      "4507/4507 [==============================] - 1s 231us/sample - loss: 0.5164 - accuracy: 0.7770 - val_loss: 0.5025 - val_accuracy: 0.7915\n",
      "Epoch 12/100\n",
      "4507/4507 [==============================] - 1s 243us/sample - loss: 0.4988 - accuracy: 0.7828 - val_loss: 0.5149 - val_accuracy: 0.7906\n",
      "Epoch 13/100\n",
      "4507/4507 [==============================] - 1s 259us/sample - loss: 0.5131 - accuracy: 0.7826 - val_loss: 0.4722 - val_accuracy: 0.7933\n",
      "Epoch 14/100\n",
      "4507/4507 [==============================] - 1s 255us/sample - loss: 0.4968 - accuracy: 0.7812 - val_loss: 0.5405 - val_accuracy: 0.7888\n",
      "Epoch 15/100\n",
      "4507/4507 [==============================] - 1s 254us/sample - loss: 0.4977 - accuracy: 0.7757 - val_loss: 0.4626 - val_accuracy: 0.7941\n",
      "Epoch 16/100\n",
      "4507/4507 [==============================] - 1s 245us/sample - loss: 0.4906 - accuracy: 0.7870 - val_loss: 0.5013 - val_accuracy: 0.7879\n",
      "Epoch 17/100\n",
      "4507/4507 [==============================] - 1s 251us/sample - loss: 0.4974 - accuracy: 0.7808 - val_loss: 1.4131 - val_accuracy: 0.7924\n",
      "Epoch 18/100\n",
      "4507/4507 [==============================] - 1s 244us/sample - loss: 0.4874 - accuracy: 0.7846 - val_loss: 0.4552 - val_accuracy: 0.7968\n",
      "Epoch 19/100\n",
      "4507/4507 [==============================] - 1s 255us/sample - loss: 0.4852 - accuracy: 0.7897 - val_loss: 0.4677 - val_accuracy: 0.7924\n",
      "Epoch 20/100\n",
      "4507/4507 [==============================] - 1s 255us/sample - loss: 0.4825 - accuracy: 0.7903 - val_loss: 0.4609 - val_accuracy: 0.7897\n",
      "Epoch 21/100\n",
      "4507/4507 [==============================] - 1s 251us/sample - loss: 0.4793 - accuracy: 0.7839 - val_loss: 0.4719 - val_accuracy: 0.7853\n",
      "Epoch 22/100\n",
      "4507/4507 [==============================] - 1s 249us/sample - loss: 0.4852 - accuracy: 0.7812 - val_loss: 0.4638 - val_accuracy: 0.7933\n",
      "Epoch 23/100\n",
      "4507/4507 [==============================] - 1s 257us/sample - loss: 0.4822 - accuracy: 0.7888 - val_loss: 0.4483 - val_accuracy: 0.7870\n",
      "Epoch 24/100\n",
      "4507/4507 [==============================] - 1s 250us/sample - loss: 0.4835 - accuracy: 0.7868 - val_loss: 0.4822 - val_accuracy: 0.7791\n",
      "1409/1409 [==============================] - 0s 116us/sample - loss: 0.4916 - accuracy: 0.7921\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/100\n",
      "4507/4507 [==============================] - 2s 475us/sample - loss: 1.3896 - accuracy: 0.6949 - val_loss: 1.0393 - val_accuracy: 0.7791\n",
      "Epoch 2/100\n",
      "4507/4507 [==============================] - 1s 244us/sample - loss: 0.5961 - accuracy: 0.7546 - val_loss: 0.9658 - val_accuracy: 0.5173\n",
      "Epoch 3/100\n",
      "4507/4507 [==============================] - 1s 233us/sample - loss: 0.5392 - accuracy: 0.7664 - val_loss: 0.5599 - val_accuracy: 0.7959\n",
      "Epoch 4/100\n",
      "4507/4507 [==============================] - 1s 234us/sample - loss: 0.5374 - accuracy: 0.7688 - val_loss: 0.4818 - val_accuracy: 0.7879\n",
      "Epoch 5/100\n",
      "4507/4507 [==============================] - 1s 240us/sample - loss: 0.5253 - accuracy: 0.7728 - val_loss: 0.4636 - val_accuracy: 0.7915\n",
      "Epoch 6/100\n",
      "4507/4507 [==============================] - 1s 231us/sample - loss: 0.5118 - accuracy: 0.7732 - val_loss: 0.4536 - val_accuracy: 0.7924\n",
      "Epoch 7/100\n",
      "4507/4507 [==============================] - 1s 231us/sample - loss: 0.5006 - accuracy: 0.7768 - val_loss: 0.5078 - val_accuracy: 0.7968\n",
      "Epoch 8/100\n",
      "4507/4507 [==============================] - 1s 240us/sample - loss: 0.5273 - accuracy: 0.7728 - val_loss: 0.4850 - val_accuracy: 0.7879\n",
      "Epoch 9/100\n",
      "4507/4507 [==============================] - 1s 234us/sample - loss: 0.5081 - accuracy: 0.7788 - val_loss: 0.4628 - val_accuracy: 0.7933\n",
      "Epoch 10/100\n",
      "4507/4507 [==============================] - 1s 234us/sample - loss: 0.4977 - accuracy: 0.7817 - val_loss: 0.5763 - val_accuracy: 0.7782\n",
      "Epoch 11/100\n",
      "4507/4507 [==============================] - 1s 226us/sample - loss: 0.5056 - accuracy: 0.7792 - val_loss: 0.5084 - val_accuracy: 0.7906\n",
      "Epoch 12/100\n",
      "4507/4507 [==============================] - 1s 234us/sample - loss: 0.4956 - accuracy: 0.7850 - val_loss: 0.4819 - val_accuracy: 0.7924\n",
      "Epoch 13/100\n",
      "4507/4507 [==============================] - 1s 240us/sample - loss: 0.4897 - accuracy: 0.7859 - val_loss: 0.5181 - val_accuracy: 0.7888\n",
      "Epoch 14/100\n",
      "4507/4507 [==============================] - 1s 239us/sample - loss: 0.4815 - accuracy: 0.7850 - val_loss: 0.4394 - val_accuracy: 0.7950\n",
      "Epoch 15/100\n",
      "4507/4507 [==============================] - 1s 236us/sample - loss: 0.4745 - accuracy: 0.7890 - val_loss: 0.4634 - val_accuracy: 0.7808\n",
      "Epoch 16/100\n",
      "4507/4507 [==============================] - 1s 232us/sample - loss: 0.4774 - accuracy: 0.7919 - val_loss: 0.6918 - val_accuracy: 0.7924\n",
      "Epoch 17/100\n",
      "4507/4507 [==============================] - 1s 228us/sample - loss: 0.4819 - accuracy: 0.7954 - val_loss: 0.4493 - val_accuracy: 0.7959\n",
      "Epoch 18/100\n",
      "4507/4507 [==============================] - 1s 227us/sample - loss: 0.4783 - accuracy: 0.7905 - val_loss: 0.4684 - val_accuracy: 0.7959\n",
      "Epoch 19/100\n",
      "4507/4507 [==============================] - 1s 226us/sample - loss: 0.4691 - accuracy: 0.7950 - val_loss: 0.4651 - val_accuracy: 0.7826\n",
      "Epoch 20/100\n",
      "4507/4507 [==============================] - 1s 225us/sample - loss: 0.4680 - accuracy: 0.7985 - val_loss: 0.4516 - val_accuracy: 0.7977\n",
      "Epoch 21/100\n",
      "4507/4507 [==============================] - 1s 223us/sample - loss: 0.4644 - accuracy: 0.7868 - val_loss: 0.4532 - val_accuracy: 0.7995\n",
      "Epoch 22/100\n",
      "4507/4507 [==============================] - 1s 225us/sample - loss: 0.4667 - accuracy: 0.7903 - val_loss: 0.4366 - val_accuracy: 0.8030\n",
      "Epoch 23/100\n",
      "4507/4507 [==============================] - 1s 225us/sample - loss: 0.4677 - accuracy: 0.7961 - val_loss: 0.4380 - val_accuracy: 0.8048\n",
      "Epoch 24/100\n",
      "4507/4507 [==============================] - 1s 233us/sample - loss: 0.4591 - accuracy: 0.7961 - val_loss: 0.4443 - val_accuracy: 0.7986\n",
      "Epoch 25/100\n",
      "4507/4507 [==============================] - 1s 238us/sample - loss: 0.4613 - accuracy: 0.7959 - val_loss: 0.5695 - val_accuracy: 0.8012\n",
      "1409/1409 [==============================] - 0s 105us/sample - loss: 0.5248 - accuracy: 0.7864\n",
      "Train on 4508 samples, validate on 1127 samples\n",
      "Epoch 1/100\n",
      "4508/4508 [==============================] - 2s 460us/sample - loss: 1.3962 - accuracy: 0.6713 - val_loss: 0.6613 - val_accuracy: 0.7746\n",
      "Epoch 2/100\n",
      "4508/4508 [==============================] - 1s 254us/sample - loss: 0.7071 - accuracy: 0.7318 - val_loss: 0.9110 - val_accuracy: 0.7817\n",
      "Epoch 3/100\n",
      "4508/4508 [==============================] - 1s 224us/sample - loss: 0.6004 - accuracy: 0.7502 - val_loss: 0.4840 - val_accuracy: 0.7870\n",
      "Epoch 4/100\n",
      "4508/4508 [==============================] - 1s 235us/sample - loss: 0.5495 - accuracy: 0.7587 - val_loss: 0.5090 - val_accuracy: 0.7879\n",
      "Epoch 5/100\n",
      "4508/4508 [==============================] - 1s 238us/sample - loss: 0.5467 - accuracy: 0.7662 - val_loss: 0.4730 - val_accuracy: 0.7968\n",
      "Epoch 6/100\n",
      "4508/4508 [==============================] - 1s 228us/sample - loss: 0.5177 - accuracy: 0.7646 - val_loss: 0.4803 - val_accuracy: 0.7844\n",
      "Epoch 7/100\n",
      "4508/4508 [==============================] - 1s 231us/sample - loss: 0.5233 - accuracy: 0.7709 - val_loss: 0.5218 - val_accuracy: 0.7356\n",
      "Epoch 8/100\n",
      "4508/4508 [==============================] - 1s 234us/sample - loss: 0.5237 - accuracy: 0.7764 - val_loss: 0.4611 - val_accuracy: 0.7870\n",
      "Epoch 9/100\n",
      "4508/4508 [==============================] - 1s 225us/sample - loss: 0.5084 - accuracy: 0.7693 - val_loss: 0.4659 - val_accuracy: 0.7968\n",
      "Epoch 10/100\n",
      "4508/4508 [==============================] - 1s 230us/sample - loss: 0.5186 - accuracy: 0.7673 - val_loss: 0.4794 - val_accuracy: 0.7906\n",
      "Epoch 11/100\n",
      "4508/4508 [==============================] - 1s 227us/sample - loss: 0.4981 - accuracy: 0.7773 - val_loss: 0.5178 - val_accuracy: 0.7853\n",
      "Epoch 12/100\n",
      "4508/4508 [==============================] - 1s 234us/sample - loss: 0.5046 - accuracy: 0.7757 - val_loss: 1.5177 - val_accuracy: 0.5226\n",
      "Epoch 13/100\n",
      "4508/4508 [==============================] - 1s 237us/sample - loss: 0.4976 - accuracy: 0.7784 - val_loss: 0.4681 - val_accuracy: 0.7870\n",
      "Epoch 14/100\n",
      "4508/4508 [==============================] - 1s 232us/sample - loss: 0.4822 - accuracy: 0.7813 - val_loss: 0.4972 - val_accuracy: 0.7995\n",
      "Epoch 15/100\n",
      "4508/4508 [==============================] - 1s 229us/sample - loss: 0.4968 - accuracy: 0.7793 - val_loss: 0.4430 - val_accuracy: 0.7906\n",
      "Epoch 16/100\n",
      "4508/4508 [==============================] - 1s 226us/sample - loss: 0.4820 - accuracy: 0.7822 - val_loss: 0.5406 - val_accuracy: 0.7950\n",
      "Epoch 17/100\n",
      "4508/4508 [==============================] - 1s 230us/sample - loss: 0.5028 - accuracy: 0.7828 - val_loss: 0.4803 - val_accuracy: 0.7817\n",
      "Epoch 18/100\n",
      "4508/4508 [==============================] - 1s 229us/sample - loss: 0.4756 - accuracy: 0.7837 - val_loss: 0.4457 - val_accuracy: 0.7924\n",
      "Epoch 19/100\n",
      "4508/4508 [==============================] - 1s 230us/sample - loss: 0.4708 - accuracy: 0.7873 - val_loss: 0.4796 - val_accuracy: 0.7870\n",
      "Epoch 20/100\n",
      "4508/4508 [==============================] - 1s 231us/sample - loss: 0.4964 - accuracy: 0.7864 - val_loss: 0.6534 - val_accuracy: 0.7888\n",
      "Epoch 21/100\n",
      "4508/4508 [==============================] - 1s 232us/sample - loss: 0.4814 - accuracy: 0.7888 - val_loss: 0.4419 - val_accuracy: 0.7941\n",
      "Epoch 22/100\n",
      "4508/4508 [==============================] - 1s 247us/sample - loss: 0.4708 - accuracy: 0.7822 - val_loss: 0.4586 - val_accuracy: 0.7915\n",
      "Epoch 23/100\n",
      "4508/4508 [==============================] - 1s 239us/sample - loss: 0.4787 - accuracy: 0.7848 - val_loss: 0.4415 - val_accuracy: 0.7933\n",
      "Epoch 24/100\n",
      "4508/4508 [==============================] - 1s 229us/sample - loss: 0.4767 - accuracy: 0.7777 - val_loss: 0.5654 - val_accuracy: 0.7755\n",
      "Epoch 25/100\n",
      "4508/4508 [==============================] - 1s 234us/sample - loss: 0.4744 - accuracy: 0.7877 - val_loss: 0.4385 - val_accuracy: 0.8004\n",
      "Epoch 26/100\n",
      "4508/4508 [==============================] - 1s 230us/sample - loss: 0.4814 - accuracy: 0.7855 - val_loss: 0.4551 - val_accuracy: 0.7941\n",
      "1408/1408 [==============================] - 0s 98us/sample - loss: 0.4701 - accuracy: 0.7869\n",
      "Train on 4508 samples, validate on 1127 samples\n",
      "Epoch 1/100\n",
      "4508/4508 [==============================] - 2s 425us/sample - loss: 1.8701 - accuracy: 0.6772 - val_loss: 1.4144 - val_accuracy: 0.3345\n",
      "Epoch 2/100\n",
      "4508/4508 [==============================] - 1s 228us/sample - loss: 0.7944 - accuracy: 0.7194 - val_loss: 0.7954 - val_accuracy: 0.4996\n",
      "Epoch 3/100\n",
      "4508/4508 [==============================] - 1s 226us/sample - loss: 0.6959 - accuracy: 0.7367 - val_loss: 1.6005 - val_accuracy: 0.4286\n",
      "Epoch 4/100\n",
      "4508/4508 [==============================] - 1s 237us/sample - loss: 0.5829 - accuracy: 0.7598 - val_loss: 0.5024 - val_accuracy: 0.7835\n",
      "Epoch 5/100\n",
      "4508/4508 [==============================] - 1s 229us/sample - loss: 0.5601 - accuracy: 0.7644 - val_loss: 0.4813 - val_accuracy: 0.7799\n",
      "Epoch 6/100\n",
      "4508/4508 [==============================] - 1s 234us/sample - loss: 0.5548 - accuracy: 0.7611 - val_loss: 0.4994 - val_accuracy: 0.7782\n",
      "Epoch 7/100\n",
      "4508/4508 [==============================] - 1s 234us/sample - loss: 0.5404 - accuracy: 0.7746 - val_loss: 0.4816 - val_accuracy: 0.7808\n",
      "Epoch 8/100\n",
      "4508/4508 [==============================] - 1s 228us/sample - loss: 0.5314 - accuracy: 0.7737 - val_loss: 0.5099 - val_accuracy: 0.7817\n",
      "Epoch 9/100\n",
      "4508/4508 [==============================] - 1s 225us/sample - loss: 0.5446 - accuracy: 0.7720 - val_loss: 0.4725 - val_accuracy: 0.7844\n",
      "Epoch 10/100\n",
      "4508/4508 [==============================] - 1s 223us/sample - loss: 0.5300 - accuracy: 0.7766 - val_loss: 0.4980 - val_accuracy: 0.7622\n",
      "Epoch 11/100\n",
      "4508/4508 [==============================] - 1s 226us/sample - loss: 0.5282 - accuracy: 0.7722 - val_loss: 0.4635 - val_accuracy: 0.7933\n",
      "Epoch 12/100\n",
      "4508/4508 [==============================] - 1s 226us/sample - loss: 0.5018 - accuracy: 0.7777 - val_loss: 0.4778 - val_accuracy: 0.7826\n",
      "Epoch 13/100\n",
      "4508/4508 [==============================] - 1s 231us/sample - loss: 0.4989 - accuracy: 0.7766 - val_loss: 0.5025 - val_accuracy: 0.7711\n",
      "Epoch 14/100\n",
      "4508/4508 [==============================] - 1s 238us/sample - loss: 0.5043 - accuracy: 0.7753 - val_loss: 0.5950 - val_accuracy: 0.7835\n",
      "Epoch 15/100\n",
      "4508/4508 [==============================] - 1s 232us/sample - loss: 0.5055 - accuracy: 0.7766 - val_loss: 0.4752 - val_accuracy: 0.7906\n",
      "Epoch 16/100\n",
      "4508/4508 [==============================] - 1s 227us/sample - loss: 0.4924 - accuracy: 0.7766 - val_loss: 0.4804 - val_accuracy: 0.7817\n",
      "Epoch 17/100\n",
      "4508/4508 [==============================] - 1s 225us/sample - loss: 0.4944 - accuracy: 0.7802 - val_loss: 0.8430 - val_accuracy: 0.7853\n",
      "Epoch 18/100\n",
      "4508/4508 [==============================] - 1s 226us/sample - loss: 0.4936 - accuracy: 0.7788 - val_loss: 0.4817 - val_accuracy: 0.7897\n",
      "Epoch 19/100\n",
      "4508/4508 [==============================] - 1s 233us/sample - loss: 0.4994 - accuracy: 0.7817 - val_loss: 0.5124 - val_accuracy: 0.7941\n",
      "Epoch 20/100\n",
      "4508/4508 [==============================] - 1s 240us/sample - loss: 0.4865 - accuracy: 0.7846 - val_loss: 0.4628 - val_accuracy: 0.7941\n",
      "Epoch 21/100\n",
      "4508/4508 [==============================] - 1s 233us/sample - loss: 0.4731 - accuracy: 0.7802 - val_loss: 0.6307 - val_accuracy: 0.7649\n",
      "Epoch 22/100\n",
      "4508/4508 [==============================] - 1s 236us/sample - loss: 0.4764 - accuracy: 0.7857 - val_loss: 0.5720 - val_accuracy: 0.7888\n",
      "Epoch 23/100\n",
      "4508/4508 [==============================] - 1s 235us/sample - loss: 0.4746 - accuracy: 0.7879 - val_loss: 0.5326 - val_accuracy: 0.7897\n",
      "Epoch 24/100\n",
      "4508/4508 [==============================] - 1s 235us/sample - loss: 0.4767 - accuracy: 0.7895 - val_loss: 0.4912 - val_accuracy: 0.7649\n",
      "Epoch 25/100\n",
      "4508/4508 [==============================] - 1s 225us/sample - loss: 0.4747 - accuracy: 0.7813 - val_loss: 0.5266 - val_accuracy: 0.7462\n",
      "Epoch 26/100\n",
      "4508/4508 [==============================] - 1s 227us/sample - loss: 0.4810 - accuracy: 0.7870 - val_loss: 0.4887 - val_accuracy: 0.7844\n",
      "Epoch 27/100\n",
      "4508/4508 [==============================] - 1s 227us/sample - loss: 0.4773 - accuracy: 0.7857 - val_loss: 0.5007 - val_accuracy: 0.7968\n",
      "Epoch 28/100\n",
      "4508/4508 [==============================] - 1s 222us/sample - loss: 0.4730 - accuracy: 0.7837 - val_loss: 0.5340 - val_accuracy: 0.7915\n",
      "Epoch 29/100\n",
      "4508/4508 [==============================] - 1s 223us/sample - loss: 0.4766 - accuracy: 0.7768 - val_loss: 0.5291 - val_accuracy: 0.7737\n",
      "1408/1408 [==============================] - 0s 101us/sample - loss: 0.4850 - accuracy: 0.7663\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/100\n",
      "4507/4507 [==============================] - 1s 332us/sample - loss: 1.1356 - accuracy: 0.6885 - val_loss: 0.6971 - val_accuracy: 0.7657\n",
      "Epoch 2/100\n",
      "4507/4507 [==============================] - 1s 205us/sample - loss: 0.6501 - accuracy: 0.7193 - val_loss: 0.5392 - val_accuracy: 0.7649\n",
      "Epoch 3/100\n",
      "4507/4507 [==============================] - 1s 211us/sample - loss: 0.5893 - accuracy: 0.7442 - val_loss: 0.5498 - val_accuracy: 0.7791\n",
      "Epoch 4/100\n",
      "4507/4507 [==============================] - 1s 215us/sample - loss: 0.5774 - accuracy: 0.7508 - val_loss: 0.5870 - val_accuracy: 0.7560\n",
      "Epoch 5/100\n",
      "4507/4507 [==============================] - 1s 208us/sample - loss: 0.5618 - accuracy: 0.7548 - val_loss: 0.5726 - val_accuracy: 0.7826\n",
      "Epoch 6/100\n",
      "4507/4507 [==============================] - 1s 206us/sample - loss: 0.5530 - accuracy: 0.7608 - val_loss: 0.6007 - val_accuracy: 0.7817\n",
      "Epoch 7/100\n",
      "4507/4507 [==============================] - 1s 205us/sample - loss: 0.5486 - accuracy: 0.7584 - val_loss: 0.5557 - val_accuracy: 0.7915\n",
      "Epoch 8/100\n",
      "4507/4507 [==============================] - 1s 208us/sample - loss: 0.5408 - accuracy: 0.7648 - val_loss: 0.5333 - val_accuracy: 0.7915\n",
      "Epoch 9/100\n",
      "4507/4507 [==============================] - 1s 214us/sample - loss: 0.5315 - accuracy: 0.7668 - val_loss: 0.5766 - val_accuracy: 0.7870\n",
      "Epoch 10/100\n",
      "4507/4507 [==============================] - 1s 224us/sample - loss: 0.5312 - accuracy: 0.7684 - val_loss: 0.5211 - val_accuracy: 0.7950\n",
      "Epoch 11/100\n",
      "4507/4507 [==============================] - 1s 219us/sample - loss: 0.5181 - accuracy: 0.7730 - val_loss: 0.5173 - val_accuracy: 0.7941\n",
      "Epoch 12/100\n",
      "4507/4507 [==============================] - 1s 213us/sample - loss: 0.5192 - accuracy: 0.7681 - val_loss: 0.5105 - val_accuracy: 0.7950\n",
      "Epoch 13/100\n",
      "4507/4507 [==============================] - 1s 212us/sample - loss: 0.5171 - accuracy: 0.7721 - val_loss: 0.5010 - val_accuracy: 0.7977\n",
      "Epoch 14/100\n",
      "4507/4507 [==============================] - 1s 219us/sample - loss: 0.5135 - accuracy: 0.7755 - val_loss: 0.5044 - val_accuracy: 0.7959\n",
      "Epoch 15/100\n",
      "4507/4507 [==============================] - 1s 230us/sample - loss: 0.5127 - accuracy: 0.7710 - val_loss: 0.5224 - val_accuracy: 0.7924\n",
      "Epoch 16/100\n",
      "4507/4507 [==============================] - 1s 229us/sample - loss: 0.5081 - accuracy: 0.7737 - val_loss: 0.5528 - val_accuracy: 0.7879\n",
      "Epoch 17/100\n",
      "4507/4507 [==============================] - 1s 228us/sample - loss: 0.5116 - accuracy: 0.7712 - val_loss: 0.5109 - val_accuracy: 0.8021\n",
      "Epoch 18/100\n",
      "4507/4507 [==============================] - 1s 226us/sample - loss: 0.5063 - accuracy: 0.7746 - val_loss: 0.4881 - val_accuracy: 0.7941\n",
      "Epoch 19/100\n",
      "4507/4507 [==============================] - 1s 229us/sample - loss: 0.5010 - accuracy: 0.7730 - val_loss: 0.4911 - val_accuracy: 0.7968\n",
      "1409/1409 [==============================] - 0s 106us/sample - loss: 0.4918 - accuracy: 0.7999\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/100\n",
      "4507/4507 [==============================] - 2s 368us/sample - loss: 1.3922 - accuracy: 0.7176 - val_loss: 0.6873 - val_accuracy: 0.6628\n",
      "Epoch 2/100\n",
      "4507/4507 [==============================] - 1s 205us/sample - loss: 0.5812 - accuracy: 0.7304 - val_loss: 0.6301 - val_accuracy: 0.7294\n",
      "Epoch 3/100\n",
      "4507/4507 [==============================] - 1s 204us/sample - loss: 0.5685 - accuracy: 0.7320 - val_loss: 0.6233 - val_accuracy: 0.7294\n",
      "Epoch 4/100\n",
      "4507/4507 [==============================] - 1s 205us/sample - loss: 0.5607 - accuracy: 0.7340 - val_loss: 0.5567 - val_accuracy: 0.7294\n",
      "Epoch 5/100\n",
      "4507/4507 [==============================] - 1s 206us/sample - loss: 0.5499 - accuracy: 0.7335 - val_loss: 0.5626 - val_accuracy: 0.7303\n",
      "Epoch 6/100\n",
      "4507/4507 [==============================] - 1s 204us/sample - loss: 0.5465 - accuracy: 0.7464 - val_loss: 0.5492 - val_accuracy: 0.7799\n",
      "Epoch 7/100\n",
      "4507/4507 [==============================] - 1s 205us/sample - loss: 0.5415 - accuracy: 0.7681 - val_loss: 0.5453 - val_accuracy: 0.7773\n",
      "Epoch 8/100\n",
      "4507/4507 [==============================] - 1s 205us/sample - loss: 0.5388 - accuracy: 0.7779 - val_loss: 0.5637 - val_accuracy: 0.7773\n",
      "Epoch 9/100\n",
      "4507/4507 [==============================] - 1s 205us/sample - loss: 0.5351 - accuracy: 0.7812 - val_loss: 0.5411 - val_accuracy: 0.7817\n",
      "Epoch 10/100\n",
      "4507/4507 [==============================] - 1s 207us/sample - loss: 0.5306 - accuracy: 0.7750 - val_loss: 0.5632 - val_accuracy: 0.7791\n",
      "Epoch 11/100\n",
      "4507/4507 [==============================] - 1s 222us/sample - loss: 0.5289 - accuracy: 0.7823 - val_loss: 0.5338 - val_accuracy: 0.7826\n",
      "Epoch 12/100\n",
      "4507/4507 [==============================] - 1s 204us/sample - loss: 0.5255 - accuracy: 0.7801 - val_loss: 0.5317 - val_accuracy: 0.7817\n",
      "Epoch 13/100\n",
      "4507/4507 [==============================] - 1s 208us/sample - loss: 0.5239 - accuracy: 0.7790 - val_loss: 0.5373 - val_accuracy: 0.7808\n",
      "Epoch 14/100\n",
      "4507/4507 [==============================] - 1s 204us/sample - loss: 0.5222 - accuracy: 0.7786 - val_loss: 0.5451 - val_accuracy: 0.7808\n",
      "Epoch 15/100\n",
      "4507/4507 [==============================] - 1s 206us/sample - loss: 0.5215 - accuracy: 0.7775 - val_loss: 0.5675 - val_accuracy: 0.7826\n",
      "Epoch 16/100\n",
      "4507/4507 [==============================] - 1s 205us/sample - loss: 0.5198 - accuracy: 0.7823 - val_loss: 0.5206 - val_accuracy: 0.7791\n",
      "1409/1409 [==============================] - 0s 104us/sample - loss: 0.5086 - accuracy: 0.7757\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/100\n",
      "4507/4507 [==============================] - 2s 342us/sample - loss: 0.7190 - accuracy: 0.7187 - val_loss: 0.6480 - val_accuracy: 0.7294\n",
      "Epoch 2/100\n",
      "4507/4507 [==============================] - 1s 205us/sample - loss: 0.5866 - accuracy: 0.7289 - val_loss: 0.5814 - val_accuracy: 0.7294\n",
      "Epoch 3/100\n",
      "4507/4507 [==============================] - 1s 216us/sample - loss: 0.5776 - accuracy: 0.7335 - val_loss: 0.5836 - val_accuracy: 0.7294\n",
      "Epoch 4/100\n",
      "4507/4507 [==============================] - 1s 211us/sample - loss: 0.5731 - accuracy: 0.7342 - val_loss: 0.5789 - val_accuracy: 0.7294\n",
      "Epoch 5/100\n",
      "4507/4507 [==============================] - 1s 207us/sample - loss: 0.5686 - accuracy: 0.7346 - val_loss: 0.5937 - val_accuracy: 0.7294\n",
      "Epoch 6/100\n",
      "4507/4507 [==============================] - 1s 206us/sample - loss: 0.5676 - accuracy: 0.7351 - val_loss: 0.5692 - val_accuracy: 0.7294\n",
      "Epoch 7/100\n",
      "4507/4507 [==============================] - 1s 207us/sample - loss: 0.5604 - accuracy: 0.7346 - val_loss: 0.5690 - val_accuracy: 0.7294\n",
      "Epoch 8/100\n",
      "4507/4507 [==============================] - 1s 205us/sample - loss: 0.5609 - accuracy: 0.7351 - val_loss: 0.5691 - val_accuracy: 0.7294\n",
      "Epoch 9/100\n",
      "4507/4507 [==============================] - 1s 205us/sample - loss: 0.5573 - accuracy: 0.7357 - val_loss: 0.5617 - val_accuracy: 0.7338\n",
      "Epoch 10/100\n",
      "4507/4507 [==============================] - 1s 204us/sample - loss: 0.5536 - accuracy: 0.7408 - val_loss: 0.5685 - val_accuracy: 0.7382\n",
      "Epoch 11/100\n",
      "4507/4507 [==============================] - 1s 204us/sample - loss: 0.5533 - accuracy: 0.7517 - val_loss: 0.5559 - val_accuracy: 0.7657\n",
      "Epoch 12/100\n",
      "4507/4507 [==============================] - 1s 212us/sample - loss: 0.5500 - accuracy: 0.7588 - val_loss: 0.5648 - val_accuracy: 0.7666\n",
      "Epoch 13/100\n",
      "4507/4507 [==============================] - 1s 221us/sample - loss: 0.5476 - accuracy: 0.7613 - val_loss: 0.5570 - val_accuracy: 0.7693\n",
      "Epoch 14/100\n",
      "4507/4507 [==============================] - 1s 224us/sample - loss: 0.5457 - accuracy: 0.7670 - val_loss: 0.5510 - val_accuracy: 0.7737\n",
      "Epoch 15/100\n",
      "4507/4507 [==============================] - 1s 238us/sample - loss: 0.5444 - accuracy: 0.7666 - val_loss: 0.5512 - val_accuracy: 0.7755\n",
      "Epoch 16/100\n",
      "4507/4507 [==============================] - 1s 222us/sample - loss: 0.5423 - accuracy: 0.7704 - val_loss: 0.5475 - val_accuracy: 0.7808\n",
      "Epoch 17/100\n",
      "4507/4507 [==============================] - 1s 212us/sample - loss: 0.5385 - accuracy: 0.7719 - val_loss: 0.5446 - val_accuracy: 0.7853\n",
      "Epoch 18/100\n",
      "4507/4507 [==============================] - 1s 216us/sample - loss: 0.5387 - accuracy: 0.7726 - val_loss: 0.5446 - val_accuracy: 0.7853\n",
      "Epoch 19/100\n",
      "4507/4507 [==============================] - 1s 225us/sample - loss: 0.5376 - accuracy: 0.7768 - val_loss: 0.5428 - val_accuracy: 0.7853\n",
      "Epoch 20/100\n",
      "4507/4507 [==============================] - 1s 231us/sample - loss: 0.5363 - accuracy: 0.7779 - val_loss: 0.5429 - val_accuracy: 0.7888\n",
      "Epoch 21/100\n",
      "4507/4507 [==============================] - 1s 241us/sample - loss: 0.5315 - accuracy: 0.7783 - val_loss: 0.5389 - val_accuracy: 0.7888\n",
      "Epoch 22/100\n",
      "4507/4507 [==============================] - 1s 266us/sample - loss: 0.5297 - accuracy: 0.7788 - val_loss: 0.5420 - val_accuracy: 0.7897\n",
      "Epoch 23/100\n",
      "4507/4507 [==============================] - 1s 220us/sample - loss: 0.5287 - accuracy: 0.7792 - val_loss: 0.5448 - val_accuracy: 0.7870\n",
      "Epoch 24/100\n",
      "4507/4507 [==============================] - 1s 230us/sample - loss: 0.5267 - accuracy: 0.7810 - val_loss: 0.5349 - val_accuracy: 0.7933\n",
      "Epoch 25/100\n",
      "4507/4507 [==============================] - 1s 220us/sample - loss: 0.5252 - accuracy: 0.7797 - val_loss: 0.5314 - val_accuracy: 0.7906\n",
      "Epoch 26/100\n",
      "4507/4507 [==============================] - 1s 216us/sample - loss: 0.5229 - accuracy: 0.7839 - val_loss: 0.5390 - val_accuracy: 0.7924\n",
      "Epoch 27/100\n",
      "4507/4507 [==============================] - 1s 211us/sample - loss: 0.5208 - accuracy: 0.7843 - val_loss: 0.5416 - val_accuracy: 0.7933\n",
      "Epoch 28/100\n",
      "4507/4507 [==============================] - 1s 206us/sample - loss: 0.5208 - accuracy: 0.7806 - val_loss: 0.5373 - val_accuracy: 0.7941\n",
      "Epoch 29/100\n",
      "4507/4507 [==============================] - 1s 209us/sample - loss: 0.5200 - accuracy: 0.7810 - val_loss: 0.5243 - val_accuracy: 0.7897\n",
      "Epoch 30/100\n",
      "4507/4507 [==============================] - 1s 217us/sample - loss: 0.5198 - accuracy: 0.7812 - val_loss: 0.5270 - val_accuracy: 0.7888\n",
      "Epoch 31/100\n",
      "4507/4507 [==============================] - 1s 243us/sample - loss: 0.5165 - accuracy: 0.7823 - val_loss: 0.5378 - val_accuracy: 0.7941\n",
      "1409/1409 [==============================] - 0s 133us/sample - loss: 0.5274 - accuracy: 0.7708\n",
      "Train on 4508 samples, validate on 1127 samples\n",
      "Epoch 1/100\n",
      "4508/4508 [==============================] - 2s 377us/sample - loss: 1.1840 - accuracy: 0.6883 - val_loss: 0.6588 - val_accuracy: 0.7294\n",
      "Epoch 2/100\n",
      "4508/4508 [==============================] - 1s 212us/sample - loss: 0.6594 - accuracy: 0.7205 - val_loss: 0.6331 - val_accuracy: 0.7622\n",
      "Epoch 3/100\n",
      "4508/4508 [==============================] - 1s 220us/sample - loss: 0.6187 - accuracy: 0.7303 - val_loss: 0.5372 - val_accuracy: 0.7631\n",
      "Epoch 4/100\n",
      "4508/4508 [==============================] - 1s 215us/sample - loss: 0.5943 - accuracy: 0.7367 - val_loss: 0.5589 - val_accuracy: 0.7666\n",
      "Epoch 5/100\n",
      "4508/4508 [==============================] - 1s 223us/sample - loss: 0.5707 - accuracy: 0.7458 - val_loss: 0.5505 - val_accuracy: 0.7773\n",
      "Epoch 6/100\n",
      "4508/4508 [==============================] - 1s 215us/sample - loss: 0.5545 - accuracy: 0.7562 - val_loss: 0.5625 - val_accuracy: 0.7764\n",
      "Epoch 7/100\n",
      "4508/4508 [==============================] - 1s 204us/sample - loss: 0.5437 - accuracy: 0.7580 - val_loss: 0.5134 - val_accuracy: 0.7808\n",
      "Epoch 8/100\n",
      "4508/4508 [==============================] - 1s 205us/sample - loss: 0.5392 - accuracy: 0.7569 - val_loss: 0.6010 - val_accuracy: 0.6690\n",
      "Epoch 9/100\n",
      "4508/4508 [==============================] - 1s 216us/sample - loss: 0.5309 - accuracy: 0.7706 - val_loss: 0.6264 - val_accuracy: 0.6335\n",
      "Epoch 10/100\n",
      "4508/4508 [==============================] - 1s 223us/sample - loss: 0.5321 - accuracy: 0.7649 - val_loss: 0.5050 - val_accuracy: 0.7844\n",
      "Epoch 11/100\n",
      "4508/4508 [==============================] - 1s 205us/sample - loss: 0.5294 - accuracy: 0.7611 - val_loss: 0.5370 - val_accuracy: 0.7791\n",
      "Epoch 12/100\n",
      "4508/4508 [==============================] - 1s 215us/sample - loss: 0.5261 - accuracy: 0.7660 - val_loss: 0.5373 - val_accuracy: 0.7782\n",
      "Epoch 13/100\n",
      "4508/4508 [==============================] - 1s 209us/sample - loss: 0.5204 - accuracy: 0.7669 - val_loss: 0.5945 - val_accuracy: 0.6628\n",
      "Epoch 14/100\n",
      "4508/4508 [==============================] - 1s 219us/sample - loss: 0.5111 - accuracy: 0.7717 - val_loss: 0.5358 - val_accuracy: 0.7808\n",
      "Epoch 15/100\n",
      "4508/4508 [==============================] - 1s 203us/sample - loss: 0.5087 - accuracy: 0.7706 - val_loss: 0.5314 - val_accuracy: 0.7835\n",
      "Epoch 16/100\n",
      "4508/4508 [==============================] - 1s 203us/sample - loss: 0.5043 - accuracy: 0.7753 - val_loss: 0.8090 - val_accuracy: 0.5280\n",
      "Epoch 17/100\n",
      "4508/4508 [==============================] - 1s 203us/sample - loss: 0.5034 - accuracy: 0.7724 - val_loss: 0.4883 - val_accuracy: 0.7933\n",
      "Epoch 18/100\n",
      "4508/4508 [==============================] - 1s 209us/sample - loss: 0.5060 - accuracy: 0.7746 - val_loss: 0.5137 - val_accuracy: 0.7870\n",
      "Epoch 19/100\n",
      "4508/4508 [==============================] - 1s 215us/sample - loss: 0.4964 - accuracy: 0.7755 - val_loss: 0.4826 - val_accuracy: 0.7924\n",
      "Epoch 20/100\n",
      "4508/4508 [==============================] - 1s 202us/sample - loss: 0.4987 - accuracy: 0.7848 - val_loss: 0.4906 - val_accuracy: 0.7959\n",
      "Epoch 21/100\n",
      "4508/4508 [==============================] - 1s 201us/sample - loss: 0.4962 - accuracy: 0.7811 - val_loss: 0.4838 - val_accuracy: 0.7879\n",
      "Epoch 22/100\n",
      "4508/4508 [==============================] - 1s 201us/sample - loss: 0.4904 - accuracy: 0.7857 - val_loss: 0.4787 - val_accuracy: 0.7959\n",
      "Epoch 23/100\n",
      "4508/4508 [==============================] - 1s 201us/sample - loss: 0.4873 - accuracy: 0.7870 - val_loss: 0.4767 - val_accuracy: 0.7915\n",
      "Epoch 24/100\n",
      "4508/4508 [==============================] - 1s 200us/sample - loss: 0.4926 - accuracy: 0.7833 - val_loss: 0.4976 - val_accuracy: 0.7915\n",
      "Epoch 25/100\n",
      "4508/4508 [==============================] - 1s 205us/sample - loss: 0.4893 - accuracy: 0.7826 - val_loss: 0.4792 - val_accuracy: 0.7906\n",
      "Epoch 26/100\n",
      "4508/4508 [==============================] - 1s 207us/sample - loss: 0.4938 - accuracy: 0.7786 - val_loss: 0.4781 - val_accuracy: 0.7933\n",
      "Epoch 27/100\n",
      "4508/4508 [==============================] - 1s 203us/sample - loss: 0.4844 - accuracy: 0.7839 - val_loss: 0.5143 - val_accuracy: 0.7915\n",
      "Epoch 28/100\n",
      "4508/4508 [==============================] - 1s 212us/sample - loss: 0.4843 - accuracy: 0.7806 - val_loss: 0.4714 - val_accuracy: 0.7950\n",
      "1408/1408 [==============================] - 0s 100us/sample - loss: 0.4736 - accuracy: 0.7919\n",
      "Train on 4508 samples, validate on 1127 samples\n",
      "Epoch 1/100\n",
      "4508/4508 [==============================] - 2s 384us/sample - loss: 1.0834 - accuracy: 0.7305 - val_loss: 0.5741 - val_accuracy: 0.7613\n",
      "Epoch 2/100\n",
      "4508/4508 [==============================] - 1s 231us/sample - loss: 0.5683 - accuracy: 0.7493 - val_loss: 0.5402 - val_accuracy: 0.7604\n",
      "Epoch 3/100\n",
      "4508/4508 [==============================] - 1s 242us/sample - loss: 0.5541 - accuracy: 0.7575 - val_loss: 0.5561 - val_accuracy: 0.7622\n",
      "Epoch 4/100\n",
      "4508/4508 [==============================] - 1s 243us/sample - loss: 0.5488 - accuracy: 0.7584 - val_loss: 0.5386 - val_accuracy: 0.7604\n",
      "Epoch 5/100\n",
      "4508/4508 [==============================] - 1s 228us/sample - loss: 0.5410 - accuracy: 0.7600 - val_loss: 0.5785 - val_accuracy: 0.7693\n",
      "Epoch 6/100\n",
      "4508/4508 [==============================] - 1s 253us/sample - loss: 0.5371 - accuracy: 0.7604 - val_loss: 0.5248 - val_accuracy: 0.7675\n",
      "Epoch 7/100\n",
      "4508/4508 [==============================] - 1s 217us/sample - loss: 0.5344 - accuracy: 0.7649 - val_loss: 0.5232 - val_accuracy: 0.7684\n",
      "Epoch 8/100\n",
      "4508/4508 [==============================] - 1s 252us/sample - loss: 0.5300 - accuracy: 0.7646 - val_loss: 0.5208 - val_accuracy: 0.7675\n",
      "Epoch 9/100\n",
      "4508/4508 [==============================] - 1s 221us/sample - loss: 0.5315 - accuracy: 0.7649 - val_loss: 0.5229 - val_accuracy: 0.7702\n",
      "Epoch 10/100\n",
      "4508/4508 [==============================] - 1s 211us/sample - loss: 0.5262 - accuracy: 0.7673 - val_loss: 0.5170 - val_accuracy: 0.7702\n",
      "Epoch 11/100\n",
      "4508/4508 [==============================] - 1s 211us/sample - loss: 0.5243 - accuracy: 0.7657 - val_loss: 0.5207 - val_accuracy: 0.7728\n",
      "Epoch 12/100\n",
      "4508/4508 [==============================] - 1s 203us/sample - loss: 0.5206 - accuracy: 0.7680 - val_loss: 0.5158 - val_accuracy: 0.7755\n",
      "Epoch 13/100\n",
      "4508/4508 [==============================] - 1s 209us/sample - loss: 0.5211 - accuracy: 0.7691 - val_loss: 0.5115 - val_accuracy: 0.7728\n",
      "Epoch 14/100\n",
      "4508/4508 [==============================] - 1s 231us/sample - loss: 0.5178 - accuracy: 0.7713 - val_loss: 0.5178 - val_accuracy: 0.7782\n",
      "Epoch 15/100\n",
      "4508/4508 [==============================] - 1s 234us/sample - loss: 0.5165 - accuracy: 0.7713 - val_loss: 0.5095 - val_accuracy: 0.7746\n",
      "Epoch 16/100\n",
      "4508/4508 [==============================] - 1s 236us/sample - loss: 0.5141 - accuracy: 0.7764 - val_loss: 0.5125 - val_accuracy: 0.7737\n",
      "Epoch 17/100\n",
      "4508/4508 [==============================] - 1s 243us/sample - loss: 0.5129 - accuracy: 0.7760 - val_loss: 0.5154 - val_accuracy: 0.7755\n",
      "Epoch 18/100\n",
      "4508/4508 [==============================] - 1s 234us/sample - loss: 0.5122 - accuracy: 0.7777 - val_loss: 0.5043 - val_accuracy: 0.7737\n",
      "Epoch 19/100\n",
      "4508/4508 [==============================] - 1s 214us/sample - loss: 0.5100 - accuracy: 0.7795 - val_loss: 0.5050 - val_accuracy: 0.7764\n",
      "Epoch 20/100\n",
      "4508/4508 [==============================] - 1s 209us/sample - loss: 0.5080 - accuracy: 0.7795 - val_loss: 0.5158 - val_accuracy: 0.7835\n",
      "Epoch 21/100\n",
      "4508/4508 [==============================] - 1s 250us/sample - loss: 0.5054 - accuracy: 0.7784 - val_loss: 0.5130 - val_accuracy: 0.7853\n",
      "Epoch 22/100\n",
      "4508/4508 [==============================] - 1s 210us/sample - loss: 0.5058 - accuracy: 0.7813 - val_loss: 0.5068 - val_accuracy: 0.7773\n",
      "Epoch 23/100\n",
      "4508/4508 [==============================] - 1s 220us/sample - loss: 0.5048 - accuracy: 0.7815 - val_loss: 0.4987 - val_accuracy: 0.7782\n",
      "Epoch 24/100\n",
      "4508/4508 [==============================] - 1s 230us/sample - loss: 0.5034 - accuracy: 0.7797 - val_loss: 0.4982 - val_accuracy: 0.7782\n",
      "Epoch 25/100\n",
      "4508/4508 [==============================] - 1s 210us/sample - loss: 0.5024 - accuracy: 0.7808 - val_loss: 0.4987 - val_accuracy: 0.7799\n",
      "Epoch 26/100\n",
      "4508/4508 [==============================] - 1s 204us/sample - loss: 0.5018 - accuracy: 0.7808 - val_loss: 0.4948 - val_accuracy: 0.7799\n",
      "Epoch 27/100\n",
      "4508/4508 [==============================] - 1s 203us/sample - loss: 0.5007 - accuracy: 0.7802 - val_loss: 0.4963 - val_accuracy: 0.7799\n",
      "1408/1408 [==============================] - 0s 98us/sample - loss: 0.5026 - accuracy: 0.7848\n",
      "Train on 5634 samples, validate on 1409 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:  9.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5634/5634 [==============================] - 2s 324us/sample - loss: 1.1681 - accuracy: 0.7107 - val_loss: 0.5425 - val_accuracy: 0.7573\n",
      "Epoch 2/100\n",
      "5634/5634 [==============================] - 1s 215us/sample - loss: 0.5584 - accuracy: 0.7607 - val_loss: 0.5722 - val_accuracy: 0.7814\n",
      "Epoch 3/100\n",
      "5634/5634 [==============================] - 1s 212us/sample - loss: 0.5175 - accuracy: 0.7698 - val_loss: 0.6774 - val_accuracy: 0.7771\n",
      "Epoch 4/100\n",
      "5634/5634 [==============================] - 1s 211us/sample - loss: 0.4884 - accuracy: 0.7742 - val_loss: 0.4857 - val_accuracy: 0.7871\n",
      "Epoch 5/100\n",
      "5634/5634 [==============================] - 1s 210us/sample - loss: 0.4852 - accuracy: 0.7755 - val_loss: 0.5680 - val_accuracy: 0.7828\n",
      "Epoch 6/100\n",
      "5634/5634 [==============================] - 1s 212us/sample - loss: 0.4767 - accuracy: 0.7840 - val_loss: 0.4916 - val_accuracy: 0.7864\n",
      "Epoch 7/100\n",
      "5634/5634 [==============================] - 1s 212us/sample - loss: 0.4721 - accuracy: 0.7836 - val_loss: 0.4541 - val_accuracy: 0.7928\n",
      "Epoch 8/100\n",
      "5634/5634 [==============================] - 1s 214us/sample - loss: 0.5010 - accuracy: 0.7726 - val_loss: 0.4598 - val_accuracy: 0.7857\n",
      "Epoch 9/100\n",
      "5634/5634 [==============================] - 1s 214us/sample - loss: 0.4801 - accuracy: 0.7767 - val_loss: 0.4557 - val_accuracy: 0.7899\n",
      "Epoch 10/100\n",
      "5634/5634 [==============================] - 1s 215us/sample - loss: 0.4739 - accuracy: 0.7808 - val_loss: 0.4761 - val_accuracy: 0.7835\n",
      "Epoch 11/100\n",
      "5634/5634 [==============================] - 1s 212us/sample - loss: 0.4730 - accuracy: 0.7812 - val_loss: 0.4576 - val_accuracy: 0.7864\n",
      "\n",
      "Best score: 0.7901476621627808\n",
      "Best params: {'additional_layers': 4, 'batch_size': 10, 'epochs': 100, 'nodes_per_layer': 52, 'optimizer': 'adam'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# tune optimizer\n",
    "params = {\n",
    "    'nodes_per_layer': [52],\n",
    "    'additional_layers': [4],\n",
    "    'batch_size': [10],\n",
    "    'epochs': [100],\n",
    "    'optimizer': ['adam', 'adadelta', 'nadam', 'rmsprop', 'ftrl']\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=KerasClassifier(build_fn=create_model),\n",
    "    param_grid=params,\n",
    "    n_jobs=1,\n",
    "    cv=5,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid.fit(X, y, callbacks=[stop], validation_split=0.2)\n",
    "\n",
    "print()\n",
    "print('Best score:', grid.best_score_)\n",
    "print('Best params:', grid.best_params_)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Define and compile the model\n",
    "def create_model(additional_layers=0, nodes_per_layer=26, activation_per_layer='relu',\n",
    "                 loss_function='binary_crossentropy', learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(nodes_per_layer, activation='relu', input_dim=26))\n",
    "    for _ in range(additional_layers):\n",
    "        model.add(Dense(nodes_per_layer, activation=activation_per_layer))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    \n",
    "    model.compile(loss=loss_function, optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4507/4507 [==============================] - 2s 477us/sample - loss: 0.5727 - accuracy: 0.7455 - val_loss: 0.5278 - val_accuracy: 0.7791\n",
      "Epoch 2/10\n",
      "4507/4507 [==============================] - 1s 276us/sample - loss: 0.5303 - accuracy: 0.7715 - val_loss: 0.5242 - val_accuracy: 0.7720\n",
      "Epoch 3/10\n",
      "4507/4507 [==============================] - 1s 271us/sample - loss: 0.5081 - accuracy: 0.7772 - val_loss: 0.5412 - val_accuracy: 0.7356\n",
      "Epoch 4/10\n",
      "4507/4507 [==============================] - 1s 281us/sample - loss: 0.4967 - accuracy: 0.7741 - val_loss: 0.4669 - val_accuracy: 0.7862\n",
      "Epoch 5/10\n",
      "4507/4507 [==============================] - 1s 277us/sample - loss: 0.4830 - accuracy: 0.7726 - val_loss: 0.4573 - val_accuracy: 0.7933\n",
      "Epoch 6/10\n",
      "4507/4507 [==============================] - 1s 272us/sample - loss: 0.4750 - accuracy: 0.7783 - val_loss: 0.4618 - val_accuracy: 0.7977\n",
      "Epoch 7/10\n",
      "4507/4507 [==============================] - 1s 269us/sample - loss: 0.4800 - accuracy: 0.7799 - val_loss: 0.4708 - val_accuracy: 0.7817\n",
      "Epoch 8/10\n",
      "4507/4507 [==============================] - 1s 283us/sample - loss: 0.4766 - accuracy: 0.7792 - val_loss: 0.4510 - val_accuracy: 0.7906\n",
      "Epoch 9/10\n",
      "4507/4507 [==============================] - 1s 267us/sample - loss: 0.4683 - accuracy: 0.7768 - val_loss: 0.4765 - val_accuracy: 0.7941\n",
      "Epoch 10/10\n",
      "4507/4507 [==============================] - 1s 275us/sample - loss: 0.4739 - accuracy: 0.7841 - val_loss: 0.4645 - val_accuracy: 0.7915\n",
      "1409/1409 [==============================] - 0s 120us/sample - loss: 0.4495 - accuracy: 0.7977\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4507/4507 [==============================] - 2s 526us/sample - loss: 0.5583 - accuracy: 0.7544 - val_loss: 0.5223 - val_accuracy: 0.7773\n",
      "Epoch 2/10\n",
      "4507/4507 [==============================] - 1s 269us/sample - loss: 0.5372 - accuracy: 0.7637 - val_loss: 0.5512 - val_accuracy: 0.7338\n",
      "Epoch 3/10\n",
      "4507/4507 [==============================] - 1s 278us/sample - loss: 0.5390 - accuracy: 0.7613 - val_loss: 0.5343 - val_accuracy: 0.7711\n",
      "Epoch 4/10\n",
      "4507/4507 [==============================] - 1s 274us/sample - loss: 0.5241 - accuracy: 0.7666 - val_loss: 0.4930 - val_accuracy: 0.7835\n",
      "Epoch 5/10\n",
      "4507/4507 [==============================] - 1s 280us/sample - loss: 0.5128 - accuracy: 0.7770 - val_loss: 0.5016 - val_accuracy: 0.7817\n",
      "Epoch 6/10\n",
      "4507/4507 [==============================] - 1s 281us/sample - loss: 0.5057 - accuracy: 0.7686 - val_loss: 0.4819 - val_accuracy: 0.7782\n",
      "Epoch 7/10\n",
      "4507/4507 [==============================] - 1s 303us/sample - loss: 0.4904 - accuracy: 0.7761 - val_loss: 0.4637 - val_accuracy: 0.7950\n",
      "Epoch 8/10\n",
      "4507/4507 [==============================] - 1s 282us/sample - loss: 0.4871 - accuracy: 0.7684 - val_loss: 0.4489 - val_accuracy: 0.7915\n",
      "Epoch 9/10\n",
      "4507/4507 [==============================] - 1s 275us/sample - loss: 0.4862 - accuracy: 0.7768 - val_loss: 0.4711 - val_accuracy: 0.7746\n",
      "Epoch 10/10\n",
      "4507/4507 [==============================] - 1s 263us/sample - loss: 0.4676 - accuracy: 0.7852 - val_loss: 0.4611 - val_accuracy: 0.7791\n",
      "1409/1409 [==============================] - 0s 115us/sample - loss: 0.4525 - accuracy: 0.7743\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4507/4507 [==============================] - 2s 484us/sample - loss: 0.5561 - accuracy: 0.7522 - val_loss: 0.5287 - val_accuracy: 0.7906\n",
      "Epoch 2/10\n",
      "4507/4507 [==============================] - 1s 278us/sample - loss: 0.5368 - accuracy: 0.7619 - val_loss: 0.5320 - val_accuracy: 0.7791\n",
      "Epoch 3/10\n",
      "4507/4507 [==============================] - 1s 288us/sample - loss: 0.5171 - accuracy: 0.7704 - val_loss: 0.4909 - val_accuracy: 0.7906\n",
      "Epoch 4/10\n",
      "4507/4507 [==============================] - 1s 286us/sample - loss: 0.5054 - accuracy: 0.7790 - val_loss: 0.4905 - val_accuracy: 0.7897\n",
      "Epoch 5/10\n",
      "4507/4507 [==============================] - 1s 299us/sample - loss: 0.4922 - accuracy: 0.7788 - val_loss: 0.4723 - val_accuracy: 0.7844\n",
      "Epoch 6/10\n",
      "4507/4507 [==============================] - 1s 290us/sample - loss: 0.4830 - accuracy: 0.7823 - val_loss: 0.4721 - val_accuracy: 0.7888\n",
      "Epoch 7/10\n",
      "4507/4507 [==============================] - 1s 309us/sample - loss: 0.4848 - accuracy: 0.7721 - val_loss: 0.4602 - val_accuracy: 0.7950\n",
      "Epoch 8/10\n",
      "4507/4507 [==============================] - 1s 293us/sample - loss: 0.4827 - accuracy: 0.7828 - val_loss: 0.4833 - val_accuracy: 0.7728\n",
      "Epoch 9/10\n",
      "4507/4507 [==============================] - 1s 270us/sample - loss: 0.4735 - accuracy: 0.7863 - val_loss: 0.4647 - val_accuracy: 0.7808\n",
      "Epoch 10/10\n",
      "4507/4507 [==============================] - 1s 300us/sample - loss: 0.4725 - accuracy: 0.7797 - val_loss: 0.4447 - val_accuracy: 0.7986\n",
      "1409/1409 [==============================] - 0s 111us/sample - loss: 0.4466 - accuracy: 0.7800\n",
      "Train on 4508 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4508/4508 [==============================] - 2s 500us/sample - loss: 0.6275 - accuracy: 0.7303 - val_loss: 0.5607 - val_accuracy: 0.7294\n",
      "Epoch 2/10\n",
      "4508/4508 [==============================] - 1s 285us/sample - loss: 0.5474 - accuracy: 0.7429 - val_loss: 0.5472 - val_accuracy: 0.7808\n",
      "Epoch 3/10\n",
      "4508/4508 [==============================] - 1s 295us/sample - loss: 0.5248 - accuracy: 0.7669 - val_loss: 0.4624 - val_accuracy: 0.7915\n",
      "Epoch 4/10\n",
      "4508/4508 [==============================] - 1s 284us/sample - loss: 0.4888 - accuracy: 0.7740 - val_loss: 0.4878 - val_accuracy: 0.7755\n",
      "Epoch 5/10\n",
      "4508/4508 [==============================] - 1s 288us/sample - loss: 0.4972 - accuracy: 0.7717 - val_loss: 0.4844 - val_accuracy: 0.7950\n",
      "Epoch 6/10\n",
      "4508/4508 [==============================] - 1s 300us/sample - loss: 0.4731 - accuracy: 0.7815 - val_loss: 0.4541 - val_accuracy: 0.7924\n",
      "Epoch 7/10\n",
      "4508/4508 [==============================] - 1s 290us/sample - loss: 0.4734 - accuracy: 0.7804 - val_loss: 0.4751 - val_accuracy: 0.7897\n",
      "Epoch 8/10\n",
      "4508/4508 [==============================] - 1s 271us/sample - loss: 0.4724 - accuracy: 0.7811 - val_loss: 0.5829 - val_accuracy: 0.7294\n",
      "Epoch 9/10\n",
      "4508/4508 [==============================] - 1s 273us/sample - loss: 0.4928 - accuracy: 0.7691 - val_loss: 0.4610 - val_accuracy: 0.7888\n",
      "Epoch 10/10\n",
      "4508/4508 [==============================] - 1s 275us/sample - loss: 0.4708 - accuracy: 0.7733 - val_loss: 0.5128 - val_accuracy: 0.7436\n",
      "1408/1408 [==============================] - 0s 112us/sample - loss: 0.5174 - accuracy: 0.7358\n",
      "Train on 4508 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4508/4508 [==============================] - 2s 502us/sample - loss: 0.5600 - accuracy: 0.7476 - val_loss: 0.5330 - val_accuracy: 0.7657\n",
      "Epoch 2/10\n",
      "4508/4508 [==============================] - 2s 336us/sample - loss: 0.5322 - accuracy: 0.7702 - val_loss: 0.5322 - val_accuracy: 0.7657\n",
      "Epoch 3/10\n",
      "4508/4508 [==============================] - 1s 295us/sample - loss: 0.5072 - accuracy: 0.7669 - val_loss: 0.4745 - val_accuracy: 0.7826\n",
      "Epoch 4/10\n",
      "4508/4508 [==============================] - 1s 285us/sample - loss: 0.4799 - accuracy: 0.7815 - val_loss: 0.4621 - val_accuracy: 0.7862\n",
      "Epoch 5/10\n",
      "4508/4508 [==============================] - 1s 294us/sample - loss: 0.4841 - accuracy: 0.7742 - val_loss: 0.4841 - val_accuracy: 0.7853\n",
      "Epoch 6/10\n",
      "4508/4508 [==============================] - 1s 284us/sample - loss: 0.4770 - accuracy: 0.7784 - val_loss: 0.4651 - val_accuracy: 0.7879\n",
      "Epoch 7/10\n",
      "4508/4508 [==============================] - 1s 280us/sample - loss: 0.4606 - accuracy: 0.7888 - val_loss: 0.4559 - val_accuracy: 0.7897\n",
      "Epoch 8/10\n",
      "4508/4508 [==============================] - 1s 283us/sample - loss: 0.4703 - accuracy: 0.7833 - val_loss: 0.5044 - val_accuracy: 0.7471\n",
      "Epoch 9/10\n",
      "4508/4508 [==============================] - 1s 275us/sample - loss: 0.4611 - accuracy: 0.7824 - val_loss: 0.4693 - val_accuracy: 0.7870\n",
      "Epoch 10/10\n",
      "4508/4508 [==============================] - 1s 278us/sample - loss: 0.4598 - accuracy: 0.7868 - val_loss: 0.4889 - val_accuracy: 0.7968\n",
      "1408/1408 [==============================] - 0s 112us/sample - loss: 0.4742 - accuracy: 0.7926\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4507/4507 [==============================] - 2s 552us/sample - loss: 0.6101 - accuracy: 0.7302 - val_loss: 0.5549 - val_accuracy: 0.7294\n",
      "Epoch 2/10\n",
      "4507/4507 [==============================] - 1s 275us/sample - loss: 0.5716 - accuracy: 0.7340 - val_loss: 0.6437 - val_accuracy: 0.6939\n",
      "Epoch 3/10\n",
      "4507/4507 [==============================] - 1s 288us/sample - loss: 0.5606 - accuracy: 0.7431 - val_loss: 0.5766 - val_accuracy: 0.7294\n",
      "Epoch 4/10\n",
      "4507/4507 [==============================] - 1s 276us/sample - loss: 0.5653 - accuracy: 0.7413 - val_loss: 0.5727 - val_accuracy: 0.7294\n",
      "Epoch 5/10\n",
      "4507/4507 [==============================] - 1s 274us/sample - loss: 0.5777 - accuracy: 0.7357 - val_loss: 0.5851 - val_accuracy: 0.7294\n",
      "Epoch 6/10\n",
      "4507/4507 [==============================] - 1s 284us/sample - loss: 0.5781 - accuracy: 0.7357 - val_loss: 0.5875 - val_accuracy: 0.7294\n",
      "Epoch 7/10\n",
      "4507/4507 [==============================] - 1s 269us/sample - loss: 0.5780 - accuracy: 0.7357 - val_loss: 0.5841 - val_accuracy: 0.7294\n",
      "Epoch 8/10\n",
      "4507/4507 [==============================] - 1s 264us/sample - loss: 0.5781 - accuracy: 0.7357 - val_loss: 0.5839 - val_accuracy: 0.7294\n",
      "1409/1409 [==============================] - 0s 111us/sample - loss: 0.5782 - accuracy: 0.7353\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4507/4507 [==============================] - 2s 521us/sample - loss: 0.5885 - accuracy: 0.7326 - val_loss: 0.5771 - val_accuracy: 0.7294\n",
      "Epoch 2/10\n",
      "4507/4507 [==============================] - 1s 272us/sample - loss: 0.5698 - accuracy: 0.7360 - val_loss: 0.5536 - val_accuracy: 0.7418\n",
      "Epoch 3/10\n",
      "4507/4507 [==============================] - 1s 264us/sample - loss: 0.5514 - accuracy: 0.7335 - val_loss: 0.5802 - val_accuracy: 0.7294\n",
      "Epoch 4/10\n",
      "4507/4507 [==============================] - 1s 272us/sample - loss: 0.5595 - accuracy: 0.7337 - val_loss: 0.5844 - val_accuracy: 0.7294\n",
      "Epoch 5/10\n",
      "4507/4507 [==============================] - 1s 284us/sample - loss: 0.5795 - accuracy: 0.7337 - val_loss: 0.5833 - val_accuracy: 0.7294\n",
      "Epoch 6/10\n",
      "4507/4507 [==============================] - 1s 274us/sample - loss: 0.5798 - accuracy: 0.7337 - val_loss: 0.5834 - val_accuracy: 0.7294\n",
      "Epoch 7/10\n",
      "4507/4507 [==============================] - 1s 270us/sample - loss: 0.5797 - accuracy: 0.7337 - val_loss: 0.5833 - val_accuracy: 0.7294\n",
      "1409/1409 [==============================] - 0s 120us/sample - loss: 0.5717 - accuracy: 0.7417\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4507/4507 [==============================] - 2s 535us/sample - loss: 0.5891 - accuracy: 0.7322 - val_loss: 0.5827 - val_accuracy: 0.7294\n",
      "Epoch 2/10\n",
      "4507/4507 [==============================] - 1s 279us/sample - loss: 0.5796 - accuracy: 0.7344 - val_loss: 0.5843 - val_accuracy: 0.7294\n",
      "Epoch 3/10\n",
      "4507/4507 [==============================] - 1s 286us/sample - loss: 0.5792 - accuracy: 0.7351 - val_loss: 0.5842 - val_accuracy: 0.7294\n",
      "Epoch 4/10\n",
      "4507/4507 [==============================] - 1s 273us/sample - loss: 0.5786 - accuracy: 0.7351 - val_loss: 0.5879 - val_accuracy: 0.7294\n",
      "Epoch 5/10\n",
      "4507/4507 [==============================] - 1s 267us/sample - loss: 0.5798 - accuracy: 0.7351 - val_loss: 0.5849 - val_accuracy: 0.7294\n",
      "Epoch 6/10\n",
      "4507/4507 [==============================] - 1s 273us/sample - loss: 0.5793 - accuracy: 0.7351 - val_loss: 0.5844 - val_accuracy: 0.7294\n",
      "Epoch 7/10\n",
      "4507/4507 [==============================] - 1s 282us/sample - loss: 0.5792 - accuracy: 0.7351 - val_loss: 0.5846 - val_accuracy: 0.7294\n",
      "1409/1409 [==============================] - 0s 113us/sample - loss: 0.5760 - accuracy: 0.7374\n",
      "Train on 4508 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4508/4508 [==============================] - 2s 528us/sample - loss: 0.5809 - accuracy: 0.7374 - val_loss: 0.5894 - val_accuracy: 0.7294\n",
      "Epoch 2/10\n",
      "4508/4508 [==============================] - 1s 269us/sample - loss: 0.5778 - accuracy: 0.7376 - val_loss: 0.5839 - val_accuracy: 0.7294\n",
      "Epoch 3/10\n",
      "4508/4508 [==============================] - 1s 283us/sample - loss: 0.5763 - accuracy: 0.7378 - val_loss: 0.5849 - val_accuracy: 0.7294\n",
      "Epoch 4/10\n",
      "4508/4508 [==============================] - 1s 272us/sample - loss: 0.5768 - accuracy: 0.7378 - val_loss: 0.5848 - val_accuracy: 0.7294\n",
      "Epoch 5/10\n",
      "4508/4508 [==============================] - 1s 278us/sample - loss: 0.5767 - accuracy: 0.7378 - val_loss: 0.5842 - val_accuracy: 0.7294\n",
      "Epoch 6/10\n",
      "4508/4508 [==============================] - 1s 291us/sample - loss: 0.5765 - accuracy: 0.7378 - val_loss: 0.5844 - val_accuracy: 0.7294\n",
      "1408/1408 [==============================] - 0s 115us/sample - loss: 0.5851 - accuracy: 0.7287\n",
      "Train on 4508 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4508/4508 [==============================] - 3s 769us/sample - loss: 0.5732 - accuracy: 0.7425 - val_loss: 0.5389 - val_accuracy: 0.7702\n",
      "Epoch 2/10\n",
      "4508/4508 [==============================] - 1s 263us/sample - loss: 0.5474 - accuracy: 0.7391 - val_loss: 0.5486 - val_accuracy: 0.7631\n",
      "Epoch 3/10\n",
      "4508/4508 [==============================] - 1s 276us/sample - loss: 0.5607 - accuracy: 0.7396 - val_loss: 0.5690 - val_accuracy: 0.7267\n",
      "Epoch 4/10\n",
      "4508/4508 [==============================] - 1s 269us/sample - loss: 0.5654 - accuracy: 0.7382 - val_loss: 0.5589 - val_accuracy: 0.7507\n",
      "Epoch 5/10\n",
      "4508/4508 [==============================] - 1s 267us/sample - loss: 0.5661 - accuracy: 0.7354 - val_loss: 0.5867 - val_accuracy: 0.7267\n",
      "Epoch 6/10\n",
      "4508/4508 [==============================] - 1s 289us/sample - loss: 0.5760 - accuracy: 0.7380 - val_loss: 0.5850 - val_accuracy: 0.7267\n",
      "1408/1408 [==============================] - 0s 111us/sample - loss: 0.5817 - accuracy: 0.7301\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4507/4507 [==============================] - 2s 518us/sample - loss: 0.8187 - accuracy: 0.7322 - val_loss: 0.5843 - val_accuracy: 0.7294\n",
      "Epoch 2/10\n",
      "4507/4507 [==============================] - 1s 279us/sample - loss: 0.5793 - accuracy: 0.7357 - val_loss: 0.5851 - val_accuracy: 0.7294\n",
      "Epoch 3/10\n",
      "4507/4507 [==============================] - 1s 278us/sample - loss: 0.5804 - accuracy: 0.7357 - val_loss: 0.5840 - val_accuracy: 0.7294\n",
      "Epoch 4/10\n",
      "4507/4507 [==============================] - 1s 278us/sample - loss: 0.5791 - accuracy: 0.7357 - val_loss: 0.5842 - val_accuracy: 0.7294\n",
      "Epoch 5/10\n",
      "4507/4507 [==============================] - 1s 278us/sample - loss: 0.5801 - accuracy: 0.7357 - val_loss: 0.5839 - val_accuracy: 0.7294\n",
      "Epoch 6/10\n",
      "4507/4507 [==============================] - 1s 283us/sample - loss: 0.5808 - accuracy: 0.7357 - val_loss: 0.5839 - val_accuracy: 0.7294\n",
      "Epoch 7/10\n",
      "4507/4507 [==============================] - 1s 288us/sample - loss: 0.5794 - accuracy: 0.7357 - val_loss: 0.5839 - val_accuracy: 0.7294\n",
      "1409/1409 [==============================] - 0s 122us/sample - loss: 0.5780 - accuracy: 0.7353\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4507/4507 [==============================] - 2s 538us/sample - loss: 0.7622 - accuracy: 0.7331 - val_loss: 0.5846 - val_accuracy: 0.7294\n",
      "Epoch 2/10\n",
      "4507/4507 [==============================] - 1s 328us/sample - loss: 0.5833 - accuracy: 0.7337 - val_loss: 0.5948 - val_accuracy: 0.7294\n",
      "Epoch 3/10\n",
      "4507/4507 [==============================] - 1s 284us/sample - loss: 0.5820 - accuracy: 0.7337 - val_loss: 0.5856 - val_accuracy: 0.7294\n",
      "Epoch 4/10\n",
      "4507/4507 [==============================] - 1s 270us/sample - loss: 0.5820 - accuracy: 0.7337 - val_loss: 0.5863 - val_accuracy: 0.7294\n",
      "Epoch 5/10\n",
      "4507/4507 [==============================] - 1s 270us/sample - loss: 0.5833 - accuracy: 0.7337 - val_loss: 0.5859 - val_accuracy: 0.7294\n",
      "Epoch 6/10\n",
      "4507/4507 [==============================] - 1s 293us/sample - loss: 0.5825 - accuracy: 0.7337 - val_loss: 0.5870 - val_accuracy: 0.7294\n",
      "1409/1409 [==============================] - 0s 112us/sample - loss: 0.5726 - accuracy: 0.7417\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4507/4507 [==============================] - 2s 535us/sample - loss: 0.7095 - accuracy: 0.7346 - val_loss: 0.5929 - val_accuracy: 0.7294\n",
      "Epoch 2/10\n",
      "4507/4507 [==============================] - 1s 267us/sample - loss: 0.5820 - accuracy: 0.7351 - val_loss: 0.5840 - val_accuracy: 0.7294\n",
      "Epoch 3/10\n",
      "4507/4507 [==============================] - 1s 269us/sample - loss: 0.5815 - accuracy: 0.7351 - val_loss: 0.5860 - val_accuracy: 0.7294\n",
      "Epoch 4/10\n",
      "4507/4507 [==============================] - 1s 266us/sample - loss: 0.5813 - accuracy: 0.7351 - val_loss: 0.5852 - val_accuracy: 0.7294\n",
      "Epoch 5/10\n",
      "4507/4507 [==============================] - 1s 267us/sample - loss: 0.5821 - accuracy: 0.7351 - val_loss: 0.5839 - val_accuracy: 0.7294\n",
      "Epoch 6/10\n",
      "4507/4507 [==============================] - 1s 293us/sample - loss: 0.5814 - accuracy: 0.7351 - val_loss: 0.5933 - val_accuracy: 0.7294\n",
      "1409/1409 [==============================] - 0s 119us/sample - loss: 0.5827 - accuracy: 0.7374\n",
      "Train on 4508 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4508/4508 [==============================] - 2s 528us/sample - loss: 0.7175 - accuracy: 0.7343 - val_loss: 0.5843 - val_accuracy: 0.7294\n",
      "Epoch 2/10\n",
      "4508/4508 [==============================] - 1s 280us/sample - loss: 0.5809 - accuracy: 0.7378 - val_loss: 0.5850 - val_accuracy: 0.7294\n",
      "Epoch 3/10\n",
      "4508/4508 [==============================] - 1s 297us/sample - loss: 0.5786 - accuracy: 0.7378 - val_loss: 0.5851 - val_accuracy: 0.7294\n",
      "Epoch 4/10\n",
      "4508/4508 [==============================] - 1s 295us/sample - loss: 0.5797 - accuracy: 0.7378 - val_loss: 0.5846 - val_accuracy: 0.7294\n",
      "Epoch 5/10\n",
      "4508/4508 [==============================] - 1s 304us/sample - loss: 0.5790 - accuracy: 0.7378 - val_loss: 0.5839 - val_accuracy: 0.7294\n",
      "Epoch 6/10\n",
      "4508/4508 [==============================] - 1s 281us/sample - loss: 0.5793 - accuracy: 0.7378 - val_loss: 0.5846 - val_accuracy: 0.7294\n",
      "Epoch 7/10\n",
      "4508/4508 [==============================] - 1s 275us/sample - loss: 0.5799 - accuracy: 0.7378 - val_loss: 0.5861 - val_accuracy: 0.7294\n",
      "1408/1408 [==============================] - 0s 114us/sample - loss: 0.5869 - accuracy: 0.7287\n",
      "Train on 4508 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4508/4508 [==============================] - 2s 507us/sample - loss: 14.0063 - accuracy: 0.7340 - val_loss: 0.5916 - val_accuracy: 0.7267\n",
      "Epoch 2/10\n",
      "4508/4508 [==============================] - 1s 272us/sample - loss: 0.5787 - accuracy: 0.7380 - val_loss: 0.5872 - val_accuracy: 0.7267\n",
      "Epoch 3/10\n",
      "4508/4508 [==============================] - 1s 273us/sample - loss: 0.5770 - accuracy: 0.7380 - val_loss: 0.5968 - val_accuracy: 0.7267\n",
      "Epoch 4/10\n",
      "4508/4508 [==============================] - 1s 270us/sample - loss: 0.5782 - accuracy: 0.7380 - val_loss: 0.5866 - val_accuracy: 0.7267\n",
      "Epoch 5/10\n",
      "4508/4508 [==============================] - 1s 275us/sample - loss: 0.5780 - accuracy: 0.7380 - val_loss: 0.5867 - val_accuracy: 0.7267\n",
      "Epoch 6/10\n",
      "4508/4508 [==============================] - 1s 274us/sample - loss: 0.5793 - accuracy: 0.7380 - val_loss: 0.5954 - val_accuracy: 0.7267\n",
      "Epoch 7/10\n",
      "4508/4508 [==============================] - 1s 276us/sample - loss: 0.5772 - accuracy: 0.7380 - val_loss: 0.5876 - val_accuracy: 0.7267\n",
      "1408/1408 [==============================] - 0s 115us/sample - loss: 0.5846 - accuracy: 0.7301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:  2.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5634 samples, validate on 1409 samples\n",
      "Epoch 1/10\n",
      "5634/5634 [==============================] - 3s 463us/sample - loss: 0.5880 - accuracy: 0.7510 - val_loss: 0.5367 - val_accuracy: 0.7693\n",
      "Epoch 2/10\n",
      "5634/5634 [==============================] - 2s 279us/sample - loss: 0.5394 - accuracy: 0.7636 - val_loss: 0.5423 - val_accuracy: 0.7729\n",
      "Epoch 3/10\n",
      "5634/5634 [==============================] - 2s 280us/sample - loss: 0.5267 - accuracy: 0.7680 - val_loss: 0.5091 - val_accuracy: 0.7800\n",
      "Epoch 4/10\n",
      "5634/5634 [==============================] - 2s 269us/sample - loss: 0.5273 - accuracy: 0.7678 - val_loss: 0.5194 - val_accuracy: 0.7764\n",
      "Epoch 5/10\n",
      "5634/5634 [==============================] - 1s 266us/sample - loss: 0.5173 - accuracy: 0.7707 - val_loss: 0.5024 - val_accuracy: 0.7828\n",
      "Epoch 6/10\n",
      "5634/5634 [==============================] - 2s 283us/sample - loss: 0.4933 - accuracy: 0.7764 - val_loss: 0.4668 - val_accuracy: 0.7771\n",
      "Epoch 7/10\n",
      "5634/5634 [==============================] - 2s 283us/sample - loss: 0.4867 - accuracy: 0.7787 - val_loss: 0.4469 - val_accuracy: 0.7864\n",
      "Epoch 8/10\n",
      "5634/5634 [==============================] - 2s 270us/sample - loss: 0.4862 - accuracy: 0.7753 - val_loss: 0.4736 - val_accuracy: 0.7828\n",
      "Epoch 9/10\n",
      "5634/5634 [==============================] - 2s 268us/sample - loss: 0.4707 - accuracy: 0.7868 - val_loss: 0.4537 - val_accuracy: 0.7892\n",
      "Epoch 10/10\n",
      "5634/5634 [==============================] - 2s 274us/sample - loss: 0.4649 - accuracy: 0.7831 - val_loss: 0.4738 - val_accuracy: 0.7793\n",
      "\n",
      "Best score: 0.7760863542556763\n",
      "Best params: {'additional_layers': 12, 'batch_size': 10, 'epochs': 10, 'learning_rate': 0.001, 'nodes_per_layer': 26}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# tune learning rate for Adam optimizer\n",
    "\n",
    "params = {\n",
    "    'nodes_per_layer': [52],\n",
    "    'additional_layers': [4],\n",
    "    'batch_size': [10],\n",
    "    'epochs': [100],\n",
    "    'learning_rate': [0.001, 0.01, 0.1]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=KerasClassifier(build_fn=create_model),\n",
    "    param_grid=params,\n",
    "    n_jobs=1,\n",
    "    cv=5,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid.fit(X, y, callbacks=[stop], validation_split=0.2)\n",
    "\n",
    "print()\n",
    "print('Best score:', grid.best_score_)\n",
    "print('Best params:', grid.best_params_)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no momentum parameter tio tune for adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Define and compile the model\n",
    "def create_model(additional_layers=0, nodes_per_layer=26, activation_per_layer='relu',\n",
    "                 loss_function='binary_crossentropy', learning_rate=0.001, network_weights_init='uniform'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(nodes_per_layer, activation='relu', input_dim=26, kernel_initializer=network_weights_init))\n",
    "    for _ in range(additional_layers):\n",
    "        model.add(Dense(nodes_per_layer, activation=activation_per_layer, kernel_initializer=network_weights_init))\n",
    "    model.add(Dense(1, activation='sigmoid', kernel_initializer=network_weights_init))\n",
    "\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    \n",
    "    model.compile(loss=loss_function, optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4507/4507 [==============================] - 2s 491us/sample - loss: 0.5825 - accuracy: 0.7357 - val_loss: 0.5522 - val_accuracy: 0.7294\n",
      "Epoch 2/10\n",
      "4507/4507 [==============================] - 1s 295us/sample - loss: 0.5396 - accuracy: 0.7357 - val_loss: 0.5079 - val_accuracy: 0.7294\n",
      "Epoch 3/10\n",
      "4507/4507 [==============================] - 1s 281us/sample - loss: 0.5070 - accuracy: 0.7357 - val_loss: 0.4952 - val_accuracy: 0.7294\n",
      "Epoch 4/10\n",
      "4507/4507 [==============================] - 1s 280us/sample - loss: 0.4862 - accuracy: 0.7548 - val_loss: 0.4807 - val_accuracy: 0.7897\n",
      "Epoch 5/10\n",
      "4507/4507 [==============================] - 1s 300us/sample - loss: 0.4728 - accuracy: 0.7792 - val_loss: 0.4804 - val_accuracy: 0.7915\n",
      "Epoch 6/10\n",
      "4507/4507 [==============================] - 1s 286us/sample - loss: 0.4696 - accuracy: 0.7761 - val_loss: 0.4899 - val_accuracy: 0.7587\n",
      "Epoch 7/10\n",
      "4507/4507 [==============================] - 1s 270us/sample - loss: 0.4611 - accuracy: 0.7795 - val_loss: 0.4607 - val_accuracy: 0.7897\n",
      "Epoch 8/10\n",
      "4507/4507 [==============================] - 1s 278us/sample - loss: 0.4548 - accuracy: 0.7834 - val_loss: 0.4538 - val_accuracy: 0.7835\n",
      "Epoch 9/10\n",
      "4507/4507 [==============================] - 1s 294us/sample - loss: 0.4549 - accuracy: 0.7841 - val_loss: 0.4435 - val_accuracy: 0.7924\n",
      "Epoch 10/10\n",
      "4507/4507 [==============================] - 1s 291us/sample - loss: 0.4531 - accuracy: 0.7857 - val_loss: 0.4399 - val_accuracy: 0.7897\n",
      "1409/1409 [==============================] - 0s 119us/sample - loss: 0.4321 - accuracy: 0.7999\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4507/4507 [==============================] - 2s 515us/sample - loss: 0.5894 - accuracy: 0.7337 - val_loss: 0.5741 - val_accuracy: 0.7294\n",
      "Epoch 2/10\n",
      "4507/4507 [==============================] - 1s 278us/sample - loss: 0.5578 - accuracy: 0.7337 - val_loss: 0.5619 - val_accuracy: 0.7294\n",
      "Epoch 3/10\n",
      "4507/4507 [==============================] - 1s 275us/sample - loss: 0.5413 - accuracy: 0.7337 - val_loss: 0.5488 - val_accuracy: 0.7294\n",
      "Epoch 4/10\n",
      "4507/4507 [==============================] - 1s 278us/sample - loss: 0.5071 - accuracy: 0.7337 - val_loss: 0.4869 - val_accuracy: 0.7294\n",
      "Epoch 5/10\n",
      "4507/4507 [==============================] - 1s 286us/sample - loss: 0.4806 - accuracy: 0.7337 - val_loss: 0.4693 - val_accuracy: 0.7294\n",
      "Epoch 6/10\n",
      "4507/4507 [==============================] - 1s 285us/sample - loss: 0.4716 - accuracy: 0.7721 - val_loss: 0.4597 - val_accuracy: 0.7995\n",
      "Epoch 7/10\n",
      "4507/4507 [==============================] - 1s 277us/sample - loss: 0.4655 - accuracy: 0.7910 - val_loss: 0.4601 - val_accuracy: 0.7995\n",
      "Epoch 8/10\n",
      "4507/4507 [==============================] - 1s 293us/sample - loss: 0.4647 - accuracy: 0.7932 - val_loss: 0.4849 - val_accuracy: 0.7995\n",
      "Epoch 9/10\n",
      "4507/4507 [==============================] - 1s 282us/sample - loss: 0.4638 - accuracy: 0.7872 - val_loss: 0.4493 - val_accuracy: 0.8004\n",
      "Epoch 10/10\n",
      "4507/4507 [==============================] - 1s 277us/sample - loss: 0.4563 - accuracy: 0.7968 - val_loss: 0.4497 - val_accuracy: 0.7950\n",
      "1409/1409 [==============================] - 0s 119us/sample - loss: 0.4334 - accuracy: 0.7885\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4507/4507 [==============================] - 2s 536us/sample - loss: 0.5849 - accuracy: 0.7351 - val_loss: 0.5628 - val_accuracy: 0.7294\n",
      "Epoch 2/10\n",
      "4507/4507 [==============================] - 1s 287us/sample - loss: 0.5481 - accuracy: 0.7351 - val_loss: 0.5521 - val_accuracy: 0.7294\n",
      "Epoch 3/10\n",
      "4507/4507 [==============================] - 1s 270us/sample - loss: 0.5160 - accuracy: 0.7351 - val_loss: 0.5091 - val_accuracy: 0.7294\n",
      "Epoch 4/10\n",
      "4507/4507 [==============================] - 1s 269us/sample - loss: 0.5173 - accuracy: 0.7400 - val_loss: 0.5209 - val_accuracy: 0.7320\n",
      "Epoch 5/10\n",
      "4507/4507 [==============================] - 1s 287us/sample - loss: 0.5066 - accuracy: 0.7417 - val_loss: 0.5123 - val_accuracy: 0.7870\n",
      "Epoch 6/10\n",
      "4507/4507 [==============================] - 1s 278us/sample - loss: 0.4919 - accuracy: 0.7777 - val_loss: 0.5147 - val_accuracy: 0.7924\n",
      "Epoch 7/10\n",
      "4507/4507 [==============================] - 1s 277us/sample - loss: 0.4925 - accuracy: 0.7843 - val_loss: 0.4934 - val_accuracy: 0.7933\n",
      "Epoch 8/10\n",
      "4507/4507 [==============================] - 1s 285us/sample - loss: 0.4812 - accuracy: 0.7770 - val_loss: 0.4887 - val_accuracy: 0.7835\n",
      "Epoch 9/10\n",
      "4507/4507 [==============================] - 1s 270us/sample - loss: 0.4905 - accuracy: 0.7626 - val_loss: 0.4820 - val_accuracy: 0.7728\n",
      "Epoch 10/10\n",
      "4507/4507 [==============================] - 1s 273us/sample - loss: 0.4826 - accuracy: 0.7626 - val_loss: 0.4976 - val_accuracy: 0.7791\n",
      "1409/1409 [==============================] - 0s 116us/sample - loss: 0.5002 - accuracy: 0.7587\n",
      "Train on 4508 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4508/4508 [==============================] - 2s 479us/sample - loss: 0.5773 - accuracy: 0.7378 - val_loss: 0.6196 - val_accuracy: 0.7294\n",
      "Epoch 2/10\n",
      "4508/4508 [==============================] - 1s 271us/sample - loss: 0.5241 - accuracy: 0.7369 - val_loss: 0.5013 - val_accuracy: 0.7294\n",
      "Epoch 3/10\n",
      "4508/4508 [==============================] - 1s 270us/sample - loss: 0.4827 - accuracy: 0.7378 - val_loss: 0.4852 - val_accuracy: 0.7294\n",
      "Epoch 4/10\n",
      "4508/4508 [==============================] - 1s 269us/sample - loss: 0.4767 - accuracy: 0.7555 - val_loss: 0.4832 - val_accuracy: 0.7941\n",
      "Epoch 5/10\n",
      "4508/4508 [==============================] - 1s 272us/sample - loss: 0.4593 - accuracy: 0.7837 - val_loss: 0.4488 - val_accuracy: 0.7888\n",
      "Epoch 6/10\n",
      "4508/4508 [==============================] - 1s 267us/sample - loss: 0.4518 - accuracy: 0.7848 - val_loss: 0.4618 - val_accuracy: 0.7924\n",
      "Epoch 7/10\n",
      "4508/4508 [==============================] - 1s 264us/sample - loss: 0.4487 - accuracy: 0.7813 - val_loss: 0.4538 - val_accuracy: 0.7950\n",
      "Epoch 8/10\n",
      "4508/4508 [==============================] - 1s 268us/sample - loss: 0.4463 - accuracy: 0.7879 - val_loss: 0.4432 - val_accuracy: 0.7933\n",
      "Epoch 9/10\n",
      "4508/4508 [==============================] - 1s 267us/sample - loss: 0.4492 - accuracy: 0.7859 - val_loss: 0.4733 - val_accuracy: 0.7897\n",
      "Epoch 10/10\n",
      "4508/4508 [==============================] - 1s 272us/sample - loss: 0.4439 - accuracy: 0.7850 - val_loss: 0.4823 - val_accuracy: 0.7791\n",
      "1408/1408 [==============================] - 0s 124us/sample - loss: 0.4991 - accuracy: 0.7706\n",
      "Train on 4508 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4508/4508 [==============================] - 2s 502us/sample - loss: 0.5821 - accuracy: 0.7380 - val_loss: 0.5731 - val_accuracy: 0.7267\n",
      "Epoch 2/10\n",
      "4508/4508 [==============================] - 1s 269us/sample - loss: 0.5542 - accuracy: 0.7380 - val_loss: 0.5543 - val_accuracy: 0.7267\n",
      "Epoch 3/10\n",
      "4508/4508 [==============================] - 1s 277us/sample - loss: 0.5293 - accuracy: 0.7380 - val_loss: 0.5302 - val_accuracy: 0.7267\n",
      "Epoch 4/10\n",
      "4508/4508 [==============================] - 1s 284us/sample - loss: 0.4812 - accuracy: 0.7380 - val_loss: 0.4788 - val_accuracy: 0.7267\n",
      "Epoch 5/10\n",
      "4508/4508 [==============================] - 1s 291us/sample - loss: 0.4614 - accuracy: 0.7722 - val_loss: 0.4955 - val_accuracy: 0.7941\n",
      "Epoch 6/10\n",
      "4508/4508 [==============================] - 1s 279us/sample - loss: 0.4528 - accuracy: 0.7948 - val_loss: 0.5386 - val_accuracy: 0.7533\n",
      "Epoch 7/10\n",
      "4508/4508 [==============================] - 1s 270us/sample - loss: 0.4500 - accuracy: 0.7917 - val_loss: 0.4634 - val_accuracy: 0.7941\n",
      "Epoch 8/10\n",
      "4508/4508 [==============================] - 1s 279us/sample - loss: 0.4437 - accuracy: 0.7884 - val_loss: 0.4559 - val_accuracy: 0.7906\n",
      "Epoch 9/10\n",
      "4508/4508 [==============================] - 1s 294us/sample - loss: 0.4358 - accuracy: 0.7946 - val_loss: 0.4554 - val_accuracy: 0.7906\n",
      "Epoch 10/10\n",
      "4508/4508 [==============================] - 1s 281us/sample - loss: 0.4367 - accuracy: 0.7935 - val_loss: 0.4822 - val_accuracy: 0.7959\n",
      "1408/1408 [==============================] - 0s 114us/sample - loss: 0.4793 - accuracy: 0.7976\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4507/4507 [==============================] - 2s 535us/sample - loss: 0.6556 - accuracy: 0.7357 - val_loss: 0.6284 - val_accuracy: 0.7294\n",
      "Epoch 2/10\n",
      "4507/4507 [==============================] - 1s 272us/sample - loss: 0.6097 - accuracy: 0.7357 - val_loss: 0.6007 - val_accuracy: 0.7294\n",
      "Epoch 3/10\n",
      "4507/4507 [==============================] - 1s 279us/sample - loss: 0.5897 - accuracy: 0.7357 - val_loss: 0.5894 - val_accuracy: 0.7294\n",
      "Epoch 4/10\n",
      "4507/4507 [==============================] - 1s 285us/sample - loss: 0.5818 - accuracy: 0.7357 - val_loss: 0.5854 - val_accuracy: 0.7294\n",
      "Epoch 5/10\n",
      "4507/4507 [==============================] - 1s 286us/sample - loss: 0.5790 - accuracy: 0.7357 - val_loss: 0.5842 - val_accuracy: 0.7294\n",
      "Epoch 6/10\n",
      "4507/4507 [==============================] - 1s 299us/sample - loss: 0.5780 - accuracy: 0.7357 - val_loss: 0.5839 - val_accuracy: 0.7294\n",
      "1409/1409 [==============================] - 0s 114us/sample - loss: 0.5782 - accuracy: 0.7353\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4507/4507 [==============================] - 2s 526us/sample - loss: 0.6550 - accuracy: 0.7315 - val_loss: 0.6279 - val_accuracy: 0.7294\n",
      "Epoch 2/10\n",
      "4507/4507 [==============================] - 1s 288us/sample - loss: 0.6100 - accuracy: 0.7337 - val_loss: 0.6003 - val_accuracy: 0.7294\n",
      "Epoch 3/10\n",
      "4507/4507 [==============================] - 1s 269us/sample - loss: 0.5910 - accuracy: 0.7337 - val_loss: 0.5894 - val_accuracy: 0.7294\n",
      "Epoch 4/10\n",
      "4507/4507 [==============================] - 1s 274us/sample - loss: 0.5836 - accuracy: 0.7337 - val_loss: 0.5855 - val_accuracy: 0.7294\n",
      "Epoch 5/10\n",
      "4507/4507 [==============================] - 1s 300us/sample - loss: 0.5810 - accuracy: 0.7337 - val_loss: 0.5843 - val_accuracy: 0.7294\n",
      "Epoch 6/10\n",
      "4507/4507 [==============================] - 1s 290us/sample - loss: 0.5800 - accuracy: 0.7337 - val_loss: 0.5840 - val_accuracy: 0.7294\n",
      "Epoch 7/10\n",
      "4507/4507 [==============================] - 1s 290us/sample - loss: 0.5797 - accuracy: 0.7337 - val_loss: 0.5839 - val_accuracy: 0.7294\n",
      "1409/1409 [==============================] - 0s 113us/sample - loss: 0.5717 - accuracy: 0.7417\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4507/4507 [==============================] - 2s 497us/sample - loss: 0.6558 - accuracy: 0.7351 - val_loss: 0.6292 - val_accuracy: 0.7294\n",
      "Epoch 2/10\n",
      "4507/4507 [==============================] - 1s 275us/sample - loss: 0.6105 - accuracy: 0.7351 - val_loss: 0.6009 - val_accuracy: 0.7294\n",
      "Epoch 3/10\n",
      "4507/4507 [==============================] - 1s 259us/sample - loss: 0.5904 - accuracy: 0.7351 - val_loss: 0.5894 - val_accuracy: 0.7294\n",
      "Epoch 4/10\n",
      "4507/4507 [==============================] - 1s 266us/sample - loss: 0.5824 - accuracy: 0.7351 - val_loss: 0.5854 - val_accuracy: 0.7294\n",
      "Epoch 5/10\n",
      "4507/4507 [==============================] - 1s 288us/sample - loss: 0.5796 - accuracy: 0.7351 - val_loss: 0.5843 - val_accuracy: 0.7294\n",
      "Epoch 6/10\n",
      "4507/4507 [==============================] - 1s 290us/sample - loss: 0.5786 - accuracy: 0.7351 - val_loss: 0.5839 - val_accuracy: 0.7294\n",
      "1409/1409 [==============================] - 0s 117us/sample - loss: 0.5761 - accuracy: 0.7374\n",
      "Train on 4508 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4508/4508 [==============================] - 4s 784us/sample - loss: 0.6550 - accuracy: 0.7378 - val_loss: 0.6285 - val_accuracy: 0.7294\n",
      "Epoch 2/10\n",
      "4508/4508 [==============================] - 1s 291us/sample - loss: 0.6084 - accuracy: 0.7378 - val_loss: 0.6002 - val_accuracy: 0.7294\n",
      "Epoch 3/10\n",
      "4508/4508 [==============================] - 1s 290us/sample - loss: 0.5881 - accuracy: 0.7378 - val_loss: 0.5891 - val_accuracy: 0.7294\n",
      "Epoch 4/10\n",
      "4508/4508 [==============================] - 1s 302us/sample - loss: 0.5799 - accuracy: 0.7378 - val_loss: 0.5853 - val_accuracy: 0.7294\n",
      "Epoch 5/10\n",
      "4508/4508 [==============================] - 1s 291us/sample - loss: 0.5770 - accuracy: 0.7378 - val_loss: 0.5842 - val_accuracy: 0.7294\n",
      "Epoch 6/10\n",
      "4508/4508 [==============================] - 1s 263us/sample - loss: 0.5759 - accuracy: 0.7378 - val_loss: 0.5839 - val_accuracy: 0.7294\n",
      "1408/1408 [==============================] - 0s 112us/sample - loss: 0.5846 - accuracy: 0.7287\n",
      "Train on 4508 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4508/4508 [==============================] - 2s 500us/sample - loss: 0.6550 - accuracy: 0.7380 - val_loss: 0.6293 - val_accuracy: 0.7267\n",
      "Epoch 2/10\n",
      "4508/4508 [==============================] - 1s 270us/sample - loss: 0.6086 - accuracy: 0.7380 - val_loss: 0.6022 - val_accuracy: 0.7267\n",
      "Epoch 3/10\n",
      "4508/4508 [==============================] - 1s 283us/sample - loss: 0.5885 - accuracy: 0.7380 - val_loss: 0.5915 - val_accuracy: 0.7267\n",
      "Epoch 4/10\n",
      "4508/4508 [==============================] - 1s 286us/sample - loss: 0.5800 - accuracy: 0.7380 - val_loss: 0.5876 - val_accuracy: 0.7267\n",
      "Epoch 5/10\n",
      "4508/4508 [==============================] - 1s 283us/sample - loss: 0.5768 - accuracy: 0.7380 - val_loss: 0.5866 - val_accuracy: 0.7267\n",
      "Epoch 6/10\n",
      "4508/4508 [==============================] - 1s 278us/sample - loss: 0.5757 - accuracy: 0.7380 - val_loss: 0.5865 - val_accuracy: 0.7267\n",
      "1408/1408 [==============================] - 0s 123us/sample - loss: 0.5832 - accuracy: 0.7301\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4507/4507 [==============================] - 2s 536us/sample - loss: 0.5498 - accuracy: 0.7484 - val_loss: 0.5294 - val_accuracy: 0.7702\n",
      "Epoch 2/10\n",
      "4507/4507 [==============================] - 1s 281us/sample - loss: 0.5127 - accuracy: 0.7690 - val_loss: 0.4692 - val_accuracy: 0.7835\n",
      "Epoch 3/10\n",
      "4507/4507 [==============================] - 1s 266us/sample - loss: 0.4965 - accuracy: 0.7695 - val_loss: 0.4898 - val_accuracy: 0.7888\n",
      "Epoch 4/10\n",
      "4507/4507 [==============================] - 1s 282us/sample - loss: 0.4870 - accuracy: 0.7757 - val_loss: 0.4741 - val_accuracy: 0.7959\n",
      "Epoch 5/10\n",
      "4507/4507 [==============================] - 1s 271us/sample - loss: 0.4775 - accuracy: 0.7741 - val_loss: 0.4804 - val_accuracy: 0.7791\n",
      "Epoch 6/10\n",
      "4507/4507 [==============================] - 1s 288us/sample - loss: 0.4728 - accuracy: 0.7786 - val_loss: 0.4797 - val_accuracy: 0.7879\n",
      "Epoch 7/10\n",
      "4507/4507 [==============================] - 1s 278us/sample - loss: 0.4680 - accuracy: 0.7775 - val_loss: 0.4555 - val_accuracy: 0.7915\n",
      "Epoch 8/10\n",
      "4507/4507 [==============================] - 1s 276us/sample - loss: 0.4675 - accuracy: 0.7850 - val_loss: 0.4968 - val_accuracy: 0.7720\n",
      "Epoch 9/10\n",
      "4507/4507 [==============================] - 1s 300us/sample - loss: 0.4614 - accuracy: 0.7792 - val_loss: 0.4606 - val_accuracy: 0.7924\n",
      "Epoch 10/10\n",
      "4507/4507 [==============================] - 1s 290us/sample - loss: 0.4680 - accuracy: 0.7783 - val_loss: 0.4563 - val_accuracy: 0.7862\n",
      "1409/1409 [==============================] - 0s 118us/sample - loss: 0.4644 - accuracy: 0.7913\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4507/4507 [==============================] - 2s 539us/sample - loss: 0.5489 - accuracy: 0.7608 - val_loss: 0.5097 - val_accuracy: 0.7933\n",
      "Epoch 2/10\n",
      "4507/4507 [==============================] - 1s 299us/sample - loss: 0.5203 - accuracy: 0.7721 - val_loss: 0.5836 - val_accuracy: 0.6770\n",
      "Epoch 3/10\n",
      "4507/4507 [==============================] - 1s 288us/sample - loss: 0.5188 - accuracy: 0.7690 - val_loss: 0.4815 - val_accuracy: 0.7915\n",
      "Epoch 4/10\n",
      "4507/4507 [==============================] - 1s 279us/sample - loss: 0.5158 - accuracy: 0.7599 - val_loss: 0.5980 - val_accuracy: 0.6327\n",
      "Epoch 5/10\n",
      "4507/4507 [==============================] - 1s 275us/sample - loss: 0.4941 - accuracy: 0.7699 - val_loss: 0.4706 - val_accuracy: 0.7906\n",
      "Epoch 6/10\n",
      "4507/4507 [==============================] - 1s 275us/sample - loss: 0.4770 - accuracy: 0.7854 - val_loss: 0.4791 - val_accuracy: 0.7853\n",
      "Epoch 7/10\n",
      "4507/4507 [==============================] - 1s 267us/sample - loss: 0.4752 - accuracy: 0.7848 - val_loss: 0.4722 - val_accuracy: 0.7782\n",
      "Epoch 8/10\n",
      "4507/4507 [==============================] - 1s 283us/sample - loss: 0.4761 - accuracy: 0.7843 - val_loss: 0.4870 - val_accuracy: 0.7870\n",
      "Epoch 9/10\n",
      "4507/4507 [==============================] - 1s 268us/sample - loss: 0.4855 - accuracy: 0.7688 - val_loss: 0.4443 - val_accuracy: 0.7968\n",
      "Epoch 10/10\n",
      "4507/4507 [==============================] - 1s 284us/sample - loss: 0.4697 - accuracy: 0.7861 - val_loss: 0.4643 - val_accuracy: 0.7968\n",
      "1409/1409 [==============================] - 0s 117us/sample - loss: 0.4581 - accuracy: 0.7878\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4507/4507 [==============================] - 2s 538us/sample - loss: 0.5597 - accuracy: 0.7408 - val_loss: 0.5095 - val_accuracy: 0.7888\n",
      "Epoch 2/10\n",
      "4507/4507 [==============================] - 1s 290us/sample - loss: 0.5248 - accuracy: 0.7664 - val_loss: 0.4976 - val_accuracy: 0.7853\n",
      "Epoch 3/10\n",
      "4507/4507 [==============================] - 1s 281us/sample - loss: 0.5137 - accuracy: 0.7732 - val_loss: 0.4895 - val_accuracy: 0.7879\n",
      "Epoch 4/10\n",
      "4507/4507 [==============================] - 1s 286us/sample - loss: 0.4909 - accuracy: 0.7792 - val_loss: 0.4624 - val_accuracy: 0.7888\n",
      "Epoch 5/10\n",
      "4507/4507 [==============================] - 1s 290us/sample - loss: 0.4757 - accuracy: 0.7790 - val_loss: 0.4698 - val_accuracy: 0.7870\n",
      "Epoch 6/10\n",
      "4507/4507 [==============================] - 1s 274us/sample - loss: 0.4647 - accuracy: 0.7903 - val_loss: 0.4503 - val_accuracy: 0.7941\n",
      "Epoch 7/10\n",
      "4507/4507 [==============================] - 1s 276us/sample - loss: 0.4690 - accuracy: 0.7834 - val_loss: 0.4571 - val_accuracy: 0.7941\n",
      "Epoch 8/10\n",
      "4507/4507 [==============================] - 1s 281us/sample - loss: 0.4618 - accuracy: 0.7903 - val_loss: 0.4849 - val_accuracy: 0.7862\n",
      "Epoch 9/10\n",
      "4507/4507 [==============================] - 1s 276us/sample - loss: 0.4717 - accuracy: 0.7854 - val_loss: 0.4554 - val_accuracy: 0.7897\n",
      "Epoch 10/10\n",
      "4507/4507 [==============================] - 1s 313us/sample - loss: 0.4560 - accuracy: 0.7941 - val_loss: 0.4566 - val_accuracy: 0.7853\n",
      "1409/1409 [==============================] - 0s 121us/sample - loss: 0.4620 - accuracy: 0.7793\n",
      "Train on 4508 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4508/4508 [==============================] - 2s 545us/sample - loss: 0.5580 - accuracy: 0.7620 - val_loss: 0.5443 - val_accuracy: 0.7560\n",
      "Epoch 2/10\n",
      "4508/4508 [==============================] - 1s 277us/sample - loss: 0.5284 - accuracy: 0.7693 - val_loss: 0.5288 - val_accuracy: 0.7755\n",
      "Epoch 3/10\n",
      "4508/4508 [==============================] - 1s 285us/sample - loss: 0.5214 - accuracy: 0.7691 - val_loss: 0.5208 - val_accuracy: 0.7799\n",
      "Epoch 4/10\n",
      "4508/4508 [==============================] - 1s 280us/sample - loss: 0.5052 - accuracy: 0.7737 - val_loss: 0.4935 - val_accuracy: 0.7888\n",
      "Epoch 5/10\n",
      "4508/4508 [==============================] - 1s 296us/sample - loss: 0.4887 - accuracy: 0.7762 - val_loss: 0.4800 - val_accuracy: 0.7906\n",
      "Epoch 6/10\n",
      "4508/4508 [==============================] - 1s 297us/sample - loss: 0.4938 - accuracy: 0.7657 - val_loss: 0.4568 - val_accuracy: 0.7959\n",
      "Epoch 7/10\n",
      "4508/4508 [==============================] - 1s 301us/sample - loss: 0.4808 - accuracy: 0.7819 - val_loss: 0.4813 - val_accuracy: 0.7826\n",
      "Epoch 8/10\n",
      "4508/4508 [==============================] - 1s 301us/sample - loss: 0.4745 - accuracy: 0.7762 - val_loss: 0.4684 - val_accuracy: 0.7782\n",
      "Epoch 9/10\n",
      "4508/4508 [==============================] - 1s 295us/sample - loss: 0.4693 - accuracy: 0.7748 - val_loss: 0.4523 - val_accuracy: 0.7906\n",
      "Epoch 10/10\n",
      "4508/4508 [==============================] - 1s 294us/sample - loss: 0.4622 - accuracy: 0.7850 - val_loss: 0.4517 - val_accuracy: 0.7933\n",
      "1408/1408 [==============================] - 0s 121us/sample - loss: 0.4682 - accuracy: 0.7919\n",
      "Train on 4508 samples, validate on 1127 samples\n",
      "Epoch 1/10\n",
      "4508/4508 [==============================] - 2s 525us/sample - loss: 0.5567 - accuracy: 0.7527 - val_loss: 0.5349 - val_accuracy: 0.7516\n",
      "Epoch 2/10\n",
      "4508/4508 [==============================] - 1s 296us/sample - loss: 0.5216 - accuracy: 0.7664 - val_loss: 0.4949 - val_accuracy: 0.7817\n",
      "Epoch 3/10\n",
      "4508/4508 [==============================] - 1s 301us/sample - loss: 0.4872 - accuracy: 0.7808 - val_loss: 0.4790 - val_accuracy: 0.7870\n",
      "Epoch 4/10\n",
      "4508/4508 [==============================] - 1s 280us/sample - loss: 0.4775 - accuracy: 0.7782 - val_loss: 0.4994 - val_accuracy: 0.7853\n",
      "Epoch 5/10\n",
      "4508/4508 [==============================] - 1s 273us/sample - loss: 0.4820 - accuracy: 0.7748 - val_loss: 0.4955 - val_accuracy: 0.7524\n",
      "Epoch 6/10\n",
      "4508/4508 [==============================] - 1s 281us/sample - loss: 0.4620 - accuracy: 0.7799 - val_loss: 0.4869 - val_accuracy: 0.7711\n",
      "Epoch 7/10\n",
      "4508/4508 [==============================] - 1s 272us/sample - loss: 0.4669 - accuracy: 0.7757 - val_loss: 0.4780 - val_accuracy: 0.7879\n",
      "Epoch 8/10\n",
      "4508/4508 [==============================] - 1s 294us/sample - loss: 0.4610 - accuracy: 0.7828 - val_loss: 0.4685 - val_accuracy: 0.7888\n",
      "Epoch 9/10\n",
      "4508/4508 [==============================] - 1s 284us/sample - loss: 0.4588 - accuracy: 0.7802 - val_loss: 0.4716 - val_accuracy: 0.7915\n",
      "Epoch 10/10\n",
      "4508/4508 [==============================] - 1s 278us/sample - loss: 0.4603 - accuracy: 0.7890 - val_loss: 0.4579 - val_accuracy: 0.7826\n",
      "1408/1408 [==============================] - 0s 120us/sample - loss: 0.4484 - accuracy: 0.7926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:  3.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5634 samples, validate on 1409 samples\n",
      "Epoch 1/10\n",
      "5634/5634 [==============================] - 3s 447us/sample - loss: 0.5482 - accuracy: 0.7515 - val_loss: 0.5432 - val_accuracy: 0.7800\n",
      "Epoch 2/10\n",
      "5634/5634 [==============================] - 2s 276us/sample - loss: 0.5105 - accuracy: 0.7673 - val_loss: 0.4834 - val_accuracy: 0.7857\n",
      "Epoch 3/10\n",
      "5634/5634 [==============================] - 2s 284us/sample - loss: 0.4870 - accuracy: 0.7780 - val_loss: 0.4896 - val_accuracy: 0.7757\n",
      "Epoch 4/10\n",
      "5634/5634 [==============================] - 2s 289us/sample - loss: 0.4745 - accuracy: 0.7787 - val_loss: 0.4607 - val_accuracy: 0.7878\n",
      "Epoch 5/10\n",
      "5634/5634 [==============================] - 2s 310us/sample - loss: 0.4731 - accuracy: 0.7819 - val_loss: 0.4640 - val_accuracy: 0.7878\n",
      "Epoch 6/10\n",
      "5634/5634 [==============================] - 2s 303us/sample - loss: 0.4681 - accuracy: 0.7769 - val_loss: 0.5172 - val_accuracy: 0.7296\n",
      "Epoch 7/10\n",
      "5634/5634 [==============================] - 2s 291us/sample - loss: 0.4614 - accuracy: 0.7874 - val_loss: 0.4637 - val_accuracy: 0.7708\n",
      "Epoch 8/10\n",
      "5634/5634 [==============================] - 2s 280us/sample - loss: 0.4645 - accuracy: 0.7787 - val_loss: 0.5460 - val_accuracy: 0.7296\n",
      "Epoch 9/10\n",
      "5634/5634 [==============================] - 2s 302us/sample - loss: 0.4717 - accuracy: 0.7783 - val_loss: 0.4604 - val_accuracy: 0.7793\n",
      "Epoch 10/10\n",
      "5634/5634 [==============================] - 2s 302us/sample - loss: 0.4951 - accuracy: 0.7627 - val_loss: 0.5419 - val_accuracy: 0.7296\n",
      "\n",
      "Best score: 0.7885854482650757\n",
      "Best params: {'additional_layers': 12, 'batch_size': 10, 'epochs': 10, 'learning_rate': 0.001, 'network_weights_init': 'glorot_normal', 'nodes_per_layer': 26}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# tune network weights initialization\n",
    "\n",
    "params = {\n",
    "    'nodes_per_layer': [52],\n",
    "    'additional_layers': [4],\n",
    "    'batch_size': [10],\n",
    "    'epochs': [100],\n",
    "    'learning_rate': [0.001],\n",
    "    'network_weights_init': ['uniform', 'zero', 'glorot_normal']\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=KerasClassifier(build_fn=create_model),\n",
    "    param_grid=params,\n",
    "    n_jobs=1,\n",
    "    cv=5,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid.fit(X, y, callbacks=[stop], validation_split=0.2)\n",
    "\n",
    "print()\n",
    "print('Best score:', grid.best_score_)\n",
    "print('Best params:', grid.best_params_)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Define and compile the model\n",
    "def create_model(additional_layers=0, nodes_per_layer=26, activation_per_layer='relu',\n",
    "                 loss_function='binary_crossentropy', learning_rate=0.001, network_weights_init='uniform'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(nodes_per_layer, activation=activation_per_layer, input_dim=26, kernel_initializer=network_weights_init))\n",
    "    for _ in range(additional_layers):\n",
    "        model.add(Dense(nodes_per_layer, activation=activation_per_layer, kernel_initializer=network_weights_init))\n",
    "    model.add(Dense(1, activation='sigmoid', kernel_initializer=network_weights_init))\n",
    "\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    \n",
    "    model.compile(loss=loss_function, optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4507/4507 [==============================] - 2s 348us/sample - loss: 1.3580 - accuracy: 0.6982 - val_loss: 0.6246 - val_accuracy: 0.7799\n",
      "Epoch 2/100\n",
      "4507/4507 [==============================] - 1s 218us/sample - loss: 0.6489 - accuracy: 0.7504 - val_loss: 0.5862 - val_accuracy: 0.7835\n",
      "Epoch 3/100\n",
      "4507/4507 [==============================] - 1s 234us/sample - loss: 0.5472 - accuracy: 0.7679 - val_loss: 0.6448 - val_accuracy: 0.6060\n",
      "Epoch 4/100\n",
      "4507/4507 [==============================] - 1s 219us/sample - loss: 0.5653 - accuracy: 0.7597 - val_loss: 0.4702 - val_accuracy: 0.7879\n",
      "Epoch 5/100\n",
      "4507/4507 [==============================] - 1s 220us/sample - loss: 0.4865 - accuracy: 0.7803 - val_loss: 0.4956 - val_accuracy: 0.7773\n",
      "Epoch 6/100\n",
      "4507/4507 [==============================] - 1s 209us/sample - loss: 0.5075 - accuracy: 0.7739 - val_loss: 0.4686 - val_accuracy: 0.7933\n",
      "Epoch 7/100\n",
      "4507/4507 [==============================] - 1s 210us/sample - loss: 0.4872 - accuracy: 0.7817 - val_loss: 0.4651 - val_accuracy: 0.7879\n",
      "Epoch 8/100\n",
      "4507/4507 [==============================] - 1s 213us/sample - loss: 0.4788 - accuracy: 0.7779 - val_loss: 0.4689 - val_accuracy: 0.7897\n",
      "Epoch 9/100\n",
      "4507/4507 [==============================] - 1s 214us/sample - loss: 0.4730 - accuracy: 0.7812 - val_loss: 0.4520 - val_accuracy: 0.7924\n",
      "Epoch 10/100\n",
      "4507/4507 [==============================] - 1s 217us/sample - loss: 0.4678 - accuracy: 0.7852 - val_loss: 0.4636 - val_accuracy: 0.7888\n",
      "Epoch 11/100\n",
      "4507/4507 [==============================] - 1s 229us/sample - loss: 0.4834 - accuracy: 0.7808 - val_loss: 0.4982 - val_accuracy: 0.7773\n",
      "Epoch 12/100\n",
      "4507/4507 [==============================] - 1s 227us/sample - loss: 0.4853 - accuracy: 0.7797 - val_loss: 0.4671 - val_accuracy: 0.7888\n",
      "Epoch 13/100\n",
      "4507/4507 [==============================] - 1s 218us/sample - loss: 0.4703 - accuracy: 0.7894 - val_loss: 0.4694 - val_accuracy: 0.7924\n",
      "Epoch 14/100\n",
      "4507/4507 [==============================] - 1s 219us/sample - loss: 0.4715 - accuracy: 0.7850 - val_loss: 0.4536 - val_accuracy: 0.8012\n",
      "Epoch 15/100\n",
      "4507/4507 [==============================] - 1s 218us/sample - loss: 0.4662 - accuracy: 0.7832 - val_loss: 0.4566 - val_accuracy: 0.7986\n",
      "Epoch 16/100\n",
      "4507/4507 [==============================] - 1s 221us/sample - loss: 0.4688 - accuracy: 0.7872 - val_loss: 0.4580 - val_accuracy: 0.7977\n",
      "Epoch 17/100\n",
      "4507/4507 [==============================] - 1s 216us/sample - loss: 0.4677 - accuracy: 0.7874 - val_loss: 0.4497 - val_accuracy: 0.7959\n",
      "Epoch 18/100\n",
      "4507/4507 [==============================] - 1s 218us/sample - loss: 0.4619 - accuracy: 0.7934 - val_loss: 0.4515 - val_accuracy: 0.7959\n",
      "Epoch 19/100\n",
      "4507/4507 [==============================] - 1s 230us/sample - loss: 0.4598 - accuracy: 0.7868 - val_loss: 0.4567 - val_accuracy: 0.7897\n",
      "Epoch 20/100\n",
      "4507/4507 [==============================] - 1s 217us/sample - loss: 0.4676 - accuracy: 0.7852 - val_loss: 0.4463 - val_accuracy: 0.7959\n",
      "Epoch 21/100\n",
      "4507/4507 [==============================] - 1s 216us/sample - loss: 0.4644 - accuracy: 0.7890 - val_loss: 0.4421 - val_accuracy: 0.8004\n",
      "Epoch 22/100\n",
      "4507/4507 [==============================] - 1s 232us/sample - loss: 0.4552 - accuracy: 0.7877 - val_loss: 0.4590 - val_accuracy: 0.7933\n",
      "Epoch 23/100\n",
      "4507/4507 [==============================] - 1s 232us/sample - loss: 0.4554 - accuracy: 0.7925 - val_loss: 0.4545 - val_accuracy: 0.7959\n",
      "1409/1409 [==============================] - 0s 104us/sample - loss: 0.4671 - accuracy: 0.7793\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/100\n",
      "4507/4507 [==============================] - 2s 367us/sample - loss: 1.2433 - accuracy: 0.6951 - val_loss: 0.5759 - val_accuracy: 0.7755\n",
      "Epoch 2/100\n",
      "4507/4507 [==============================] - 1s 216us/sample - loss: 0.6647 - accuracy: 0.7431 - val_loss: 0.4854 - val_accuracy: 0.7950\n",
      "Epoch 3/100\n",
      "4507/4507 [==============================] - 1s 217us/sample - loss: 0.5436 - accuracy: 0.7673 - val_loss: 0.5371 - val_accuracy: 0.7924\n",
      "Epoch 4/100\n",
      "4507/4507 [==============================] - 1s 226us/sample - loss: 0.5155 - accuracy: 0.7775 - val_loss: 0.5235 - val_accuracy: 0.7853\n",
      "Epoch 5/100\n",
      "4507/4507 [==============================] - 1s 221us/sample - loss: 0.5056 - accuracy: 0.7708 - val_loss: 0.5933 - val_accuracy: 0.7906\n",
      "Epoch 6/100\n",
      "4507/4507 [==============================] - 1s 219us/sample - loss: 0.5013 - accuracy: 0.7768 - val_loss: 0.5327 - val_accuracy: 0.7391\n",
      "Epoch 7/100\n",
      "4507/4507 [==============================] - 1s 217us/sample - loss: 0.4769 - accuracy: 0.7886 - val_loss: 0.4558 - val_accuracy: 0.7870\n",
      "Epoch 8/100\n",
      "4507/4507 [==============================] - 1s 218us/sample - loss: 0.4865 - accuracy: 0.7823 - val_loss: 1.2151 - val_accuracy: 0.4933\n",
      "Epoch 9/100\n",
      "4507/4507 [==============================] - 1s 215us/sample - loss: 0.5154 - accuracy: 0.7717 - val_loss: 0.4665 - val_accuracy: 0.7853\n",
      "Epoch 10/100\n",
      "4507/4507 [==============================] - 1s 215us/sample - loss: 0.4824 - accuracy: 0.7812 - val_loss: 0.4709 - val_accuracy: 0.7915\n",
      "Epoch 11/100\n",
      "4507/4507 [==============================] - 1s 216us/sample - loss: 0.4531 - accuracy: 0.7881 - val_loss: 0.4942 - val_accuracy: 0.7924\n",
      "Epoch 12/100\n",
      "4507/4507 [==============================] - 1s 216us/sample - loss: 0.4542 - accuracy: 0.7908 - val_loss: 0.4980 - val_accuracy: 0.7941\n",
      "Epoch 13/100\n",
      "4507/4507 [==============================] - 1s 223us/sample - loss: 0.4558 - accuracy: 0.7945 - val_loss: 0.4890 - val_accuracy: 0.7835\n",
      "Epoch 14/100\n",
      "4507/4507 [==============================] - 1s 221us/sample - loss: 0.4533 - accuracy: 0.7917 - val_loss: 0.4719 - val_accuracy: 0.7853\n",
      "Epoch 15/100\n",
      "4507/4507 [==============================] - 1s 215us/sample - loss: 0.4580 - accuracy: 0.7877 - val_loss: 0.4438 - val_accuracy: 0.7933\n",
      "Epoch 16/100\n",
      "4507/4507 [==============================] - 1s 218us/sample - loss: 0.4567 - accuracy: 0.7903 - val_loss: 0.5030 - val_accuracy: 0.7897\n",
      "Epoch 17/100\n",
      "4507/4507 [==============================] - 1s 232us/sample - loss: 0.4522 - accuracy: 0.7892 - val_loss: 0.4475 - val_accuracy: 0.7995\n",
      "Epoch 18/100\n",
      "4507/4507 [==============================] - 1s 223us/sample - loss: 0.4557 - accuracy: 0.7886 - val_loss: 0.4391 - val_accuracy: 0.7941\n",
      "1409/1409 [==============================] - 0s 101us/sample - loss: 0.4410 - accuracy: 0.7949\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/100\n",
      "4507/4507 [==============================] - 2s 397us/sample - loss: 1.0917 - accuracy: 0.7080 - val_loss: 0.5171 - val_accuracy: 0.7799\n",
      "Epoch 2/100\n",
      "4507/4507 [==============================] - 1s 226us/sample - loss: 0.6252 - accuracy: 0.7486 - val_loss: 0.5092 - val_accuracy: 0.7764\n",
      "Epoch 3/100\n",
      "4507/4507 [==============================] - 1s 228us/sample - loss: 0.5574 - accuracy: 0.7704 - val_loss: 0.5206 - val_accuracy: 0.7853\n",
      "Epoch 4/100\n",
      "4507/4507 [==============================] - 1s 218us/sample - loss: 0.5233 - accuracy: 0.7715 - val_loss: 0.5270 - val_accuracy: 0.7862\n",
      "Epoch 5/100\n",
      "4507/4507 [==============================] - 1s 229us/sample - loss: 0.5276 - accuracy: 0.7741 - val_loss: 0.4993 - val_accuracy: 0.7853\n",
      "Epoch 6/100\n",
      "4507/4507 [==============================] - 1s 230us/sample - loss: 0.5104 - accuracy: 0.7797 - val_loss: 0.4935 - val_accuracy: 0.7853\n",
      "Epoch 7/100\n",
      "4507/4507 [==============================] - 1s 226us/sample - loss: 0.4960 - accuracy: 0.7819 - val_loss: 0.4809 - val_accuracy: 0.7879\n",
      "Epoch 8/100\n",
      "4507/4507 [==============================] - 1s 220us/sample - loss: 0.5156 - accuracy: 0.7701 - val_loss: 0.4728 - val_accuracy: 0.7870\n",
      "Epoch 9/100\n",
      "4507/4507 [==============================] - 1s 215us/sample - loss: 0.4933 - accuracy: 0.7797 - val_loss: 0.4771 - val_accuracy: 0.7906\n",
      "Epoch 10/100\n",
      "4507/4507 [==============================] - 1s 215us/sample - loss: 0.4916 - accuracy: 0.7810 - val_loss: 0.4746 - val_accuracy: 0.7879\n",
      "Epoch 11/100\n",
      "4507/4507 [==============================] - 1s 214us/sample - loss: 0.5059 - accuracy: 0.7763 - val_loss: 0.4825 - val_accuracy: 0.7870\n",
      "Epoch 12/100\n",
      "4507/4507 [==============================] - 1s 215us/sample - loss: 0.4979 - accuracy: 0.7799 - val_loss: 0.4752 - val_accuracy: 0.7941\n",
      "1409/1409 [==============================] - 0s 98us/sample - loss: 0.4973 - accuracy: 0.7800\n",
      "Train on 4508 samples, validate on 1127 samples\n",
      "Epoch 1/100\n",
      "4508/4508 [==============================] - 2s 381us/sample - loss: 0.8441 - accuracy: 0.7143 - val_loss: 0.5676 - val_accuracy: 0.7853\n",
      "Epoch 2/100\n",
      "4508/4508 [==============================] - 1s 229us/sample - loss: 0.6313 - accuracy: 0.7493 - val_loss: 0.5623 - val_accuracy: 0.7879\n",
      "Epoch 3/100\n",
      "4508/4508 [==============================] - 1s 222us/sample - loss: 0.5242 - accuracy: 0.7702 - val_loss: 0.4572 - val_accuracy: 0.7888\n",
      "Epoch 4/100\n",
      "4508/4508 [==============================] - 1s 217us/sample - loss: 0.4734 - accuracy: 0.7842 - val_loss: 0.4401 - val_accuracy: 0.8004\n",
      "Epoch 5/100\n",
      "4508/4508 [==============================] - 1s 216us/sample - loss: 0.4654 - accuracy: 0.7862 - val_loss: 0.4793 - val_accuracy: 0.7897\n",
      "Epoch 6/100\n",
      "4508/4508 [==============================] - 1s 218us/sample - loss: 0.4707 - accuracy: 0.7795 - val_loss: 0.4944 - val_accuracy: 0.7915\n",
      "Epoch 7/100\n",
      "4508/4508 [==============================] - 1s 217us/sample - loss: 0.4768 - accuracy: 0.7768 - val_loss: 0.5069 - val_accuracy: 0.7933\n",
      "Epoch 8/100\n",
      "4508/4508 [==============================] - 1s 225us/sample - loss: 0.4677 - accuracy: 0.7828 - val_loss: 0.4558 - val_accuracy: 0.7950\n",
      "Epoch 9/100\n",
      "4508/4508 [==============================] - 1s 226us/sample - loss: 0.4509 - accuracy: 0.7850 - val_loss: 0.4621 - val_accuracy: 0.7986\n",
      "Epoch 10/100\n",
      "4508/4508 [==============================] - 1s 233us/sample - loss: 0.4496 - accuracy: 0.7902 - val_loss: 0.4462 - val_accuracy: 0.7959\n",
      "Epoch 11/100\n",
      "4508/4508 [==============================] - 1s 248us/sample - loss: 0.4595 - accuracy: 0.7811 - val_loss: 0.4454 - val_accuracy: 0.7844\n",
      "Epoch 12/100\n",
      "4508/4508 [==============================] - 1s 257us/sample - loss: 0.4475 - accuracy: 0.7870 - val_loss: 0.4672 - val_accuracy: 0.7933\n",
      "Epoch 13/100\n",
      "4508/4508 [==============================] - 1s 250us/sample - loss: 0.4520 - accuracy: 0.7879 - val_loss: 0.4676 - val_accuracy: 0.7906\n",
      "Epoch 14/100\n",
      "4508/4508 [==============================] - 1s 244us/sample - loss: 0.4533 - accuracy: 0.7842 - val_loss: 0.4391 - val_accuracy: 0.7995\n",
      "Epoch 15/100\n",
      "4508/4508 [==============================] - 1s 224us/sample - loss: 0.4452 - accuracy: 0.7919 - val_loss: 0.4304 - val_accuracy: 0.7959\n",
      "Epoch 16/100\n",
      "4508/4508 [==============================] - 1s 218us/sample - loss: 0.4475 - accuracy: 0.7908 - val_loss: 0.4486 - val_accuracy: 0.7968\n",
      "Epoch 17/100\n",
      "4508/4508 [==============================] - 1s 233us/sample - loss: 0.4474 - accuracy: 0.7902 - val_loss: 0.4380 - val_accuracy: 0.7959\n",
      "Epoch 18/100\n",
      "4508/4508 [==============================] - 1s 239us/sample - loss: 0.4469 - accuracy: 0.7897 - val_loss: 0.4569 - val_accuracy: 0.7924\n",
      "Epoch 19/100\n",
      "4508/4508 [==============================] - 1s 247us/sample - loss: 0.4411 - accuracy: 0.7928 - val_loss: 0.4390 - val_accuracy: 0.7941\n",
      "Epoch 20/100\n",
      "4508/4508 [==============================] - 1s 223us/sample - loss: 0.4371 - accuracy: 0.7946 - val_loss: 0.4400 - val_accuracy: 0.7977\n",
      "Epoch 21/100\n",
      "4508/4508 [==============================] - 1s 232us/sample - loss: 0.4397 - accuracy: 0.7972 - val_loss: 0.4410 - val_accuracy: 0.7968\n",
      "Epoch 22/100\n",
      "4508/4508 [==============================] - 1s 244us/sample - loss: 0.4357 - accuracy: 0.7953 - val_loss: 0.4857 - val_accuracy: 0.7950\n",
      "Epoch 23/100\n",
      "4508/4508 [==============================] - 1s 220us/sample - loss: 0.4359 - accuracy: 0.7944 - val_loss: 0.4371 - val_accuracy: 0.7950\n",
      "Epoch 24/100\n",
      "4508/4508 [==============================] - 1s 224us/sample - loss: 0.4324 - accuracy: 0.7953 - val_loss: 0.4475 - val_accuracy: 0.7853\n",
      "Epoch 25/100\n",
      "4508/4508 [==============================] - 1s 218us/sample - loss: 0.4297 - accuracy: 0.8012 - val_loss: 0.4324 - val_accuracy: 0.7959\n",
      "Epoch 26/100\n",
      "4508/4508 [==============================] - 1s 215us/sample - loss: 0.4365 - accuracy: 0.7890 - val_loss: 0.4296 - val_accuracy: 0.7959\n",
      "Epoch 27/100\n",
      "4508/4508 [==============================] - 1s 230us/sample - loss: 0.4375 - accuracy: 0.7928 - val_loss: 0.4544 - val_accuracy: 0.8004\n",
      "Epoch 28/100\n",
      "4508/4508 [==============================] - 1s 226us/sample - loss: 0.4347 - accuracy: 0.7933 - val_loss: 0.4405 - val_accuracy: 0.7959\n",
      "Epoch 29/100\n",
      "4508/4508 [==============================] - 1s 225us/sample - loss: 0.4346 - accuracy: 0.7933 - val_loss: 0.4583 - val_accuracy: 0.7941\n",
      "Epoch 30/100\n",
      "4508/4508 [==============================] - 1s 216us/sample - loss: 0.4339 - accuracy: 0.7924 - val_loss: 0.4287 - val_accuracy: 0.7968\n",
      "1408/1408 [==============================] - 0s 101us/sample - loss: 0.4371 - accuracy: 0.8011\n",
      "Train on 4508 samples, validate on 1127 samples\n",
      "Epoch 1/100\n",
      "4508/4508 [==============================] - 2s 345us/sample - loss: 1.2851 - accuracy: 0.7092 - val_loss: 0.8781 - val_accuracy: 0.7507\n",
      "Epoch 2/100\n",
      "4508/4508 [==============================] - 1s 217us/sample - loss: 0.6680 - accuracy: 0.7409 - val_loss: 0.5130 - val_accuracy: 0.7666\n",
      "Epoch 3/100\n",
      "4508/4508 [==============================] - 1s 215us/sample - loss: 0.6522 - accuracy: 0.7469 - val_loss: 0.8649 - val_accuracy: 0.5102\n",
      "Epoch 4/100\n",
      "4508/4508 [==============================] - 1s 214us/sample - loss: 0.5225 - accuracy: 0.7684 - val_loss: 0.6014 - val_accuracy: 0.7657\n",
      "Epoch 5/100\n",
      "4508/4508 [==============================] - 1s 223us/sample - loss: 0.5441 - accuracy: 0.7695 - val_loss: 0.4838 - val_accuracy: 0.7844\n",
      "Epoch 6/100\n",
      "4508/4508 [==============================] - 1s 219us/sample - loss: 0.5058 - accuracy: 0.7733 - val_loss: 0.5151 - val_accuracy: 0.7808\n",
      "Epoch 7/100\n",
      "4508/4508 [==============================] - 1s 215us/sample - loss: 0.4711 - accuracy: 0.7831 - val_loss: 0.4705 - val_accuracy: 0.7879\n",
      "Epoch 8/100\n",
      "4508/4508 [==============================] - 1s 214us/sample - loss: 0.4863 - accuracy: 0.7822 - val_loss: 0.4993 - val_accuracy: 0.7835\n",
      "Epoch 9/100\n",
      "4508/4508 [==============================] - 1s 214us/sample - loss: 0.4642 - accuracy: 0.7835 - val_loss: 0.4691 - val_accuracy: 0.7853\n",
      "Epoch 10/100\n",
      "4508/4508 [==============================] - 1s 214us/sample - loss: 0.4894 - accuracy: 0.7788 - val_loss: 0.4607 - val_accuracy: 0.7853\n",
      "Epoch 11/100\n",
      "4508/4508 [==============================] - 1s 214us/sample - loss: 0.4711 - accuracy: 0.7862 - val_loss: 0.5534 - val_accuracy: 0.7933\n",
      "Epoch 12/100\n",
      "4508/4508 [==============================] - 1s 217us/sample - loss: 0.5081 - accuracy: 0.7766 - val_loss: 0.4480 - val_accuracy: 0.7853\n",
      "Epoch 13/100\n",
      "4508/4508 [==============================] - 1s 216us/sample - loss: 0.4730 - accuracy: 0.7822 - val_loss: 0.5950 - val_accuracy: 0.7924\n",
      "Epoch 14/100\n",
      "4508/4508 [==============================] - 1s 214us/sample - loss: 0.4879 - accuracy: 0.7782 - val_loss: 0.4902 - val_accuracy: 0.7870\n",
      "Epoch 15/100\n",
      "4508/4508 [==============================] - 1s 217us/sample - loss: 0.4646 - accuracy: 0.7873 - val_loss: 0.4991 - val_accuracy: 0.7737\n",
      "Epoch 16/100\n",
      "4508/4508 [==============================] - 1s 230us/sample - loss: 0.4721 - accuracy: 0.7888 - val_loss: 0.4665 - val_accuracy: 0.7853\n",
      "Epoch 17/100\n",
      "4508/4508 [==============================] - 1s 218us/sample - loss: 0.4625 - accuracy: 0.7873 - val_loss: 0.4745 - val_accuracy: 0.7897\n",
      "Epoch 18/100\n",
      "4508/4508 [==============================] - 1s 223us/sample - loss: 0.4639 - accuracy: 0.7877 - val_loss: 0.4802 - val_accuracy: 0.7906\n",
      "Epoch 19/100\n",
      "4508/4508 [==============================] - 1s 237us/sample - loss: 0.4621 - accuracy: 0.7879 - val_loss: 0.4673 - val_accuracy: 0.7950\n",
      "Epoch 20/100\n",
      "4508/4508 [==============================] - 1s 225us/sample - loss: 0.4663 - accuracy: 0.7882 - val_loss: 0.4583 - val_accuracy: 0.7906\n",
      "Epoch 21/100\n",
      "4508/4508 [==============================] - 1s 222us/sample - loss: 0.4585 - accuracy: 0.7870 - val_loss: 0.4756 - val_accuracy: 0.7897\n",
      "1408/1408 [==============================] - 0s 104us/sample - loss: 0.4510 - accuracy: 0.7848\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/100\n",
      "4507/4507 [==============================] - 2s 378us/sample - loss: 0.5635 - accuracy: 0.7260 - val_loss: 0.5087 - val_accuracy: 0.7294\n",
      "Epoch 2/100\n",
      "4507/4507 [==============================] - 1s 224us/sample - loss: 0.4986 - accuracy: 0.7637 - val_loss: 0.4959 - val_accuracy: 0.7684\n",
      "Epoch 3/100\n",
      "4507/4507 [==============================] - 1s 227us/sample - loss: 0.4919 - accuracy: 0.7728 - val_loss: 0.4722 - val_accuracy: 0.7888\n",
      "Epoch 4/100\n",
      "4507/4507 [==============================] - 1s 223us/sample - loss: 0.4844 - accuracy: 0.7701 - val_loss: 0.4836 - val_accuracy: 0.7702\n",
      "Epoch 5/100\n",
      "4507/4507 [==============================] - 1s 216us/sample - loss: 0.4793 - accuracy: 0.7735 - val_loss: 0.4678 - val_accuracy: 0.7915\n",
      "Epoch 6/100\n",
      "4507/4507 [==============================] - 1s 216us/sample - loss: 0.4864 - accuracy: 0.7704 - val_loss: 0.4731 - val_accuracy: 0.7764\n",
      "Epoch 7/100\n",
      "4507/4507 [==============================] - 1s 222us/sample - loss: 0.4868 - accuracy: 0.7681 - val_loss: 0.4665 - val_accuracy: 0.7950\n",
      "Epoch 8/100\n",
      "4507/4507 [==============================] - 1s 226us/sample - loss: 0.4745 - accuracy: 0.7750 - val_loss: 0.4661 - val_accuracy: 0.7835\n",
      "Epoch 9/100\n",
      "4507/4507 [==============================] - 1s 222us/sample - loss: 0.4819 - accuracy: 0.7741 - val_loss: 0.4705 - val_accuracy: 0.7853\n",
      "Epoch 10/100\n",
      "4507/4507 [==============================] - 1s 216us/sample - loss: 0.4708 - accuracy: 0.7766 - val_loss: 0.4739 - val_accuracy: 0.7782\n",
      "Epoch 11/100\n",
      "4507/4507 [==============================] - 1s 217us/sample - loss: 0.4795 - accuracy: 0.7766 - val_loss: 0.4739 - val_accuracy: 0.7897\n",
      "Epoch 12/100\n",
      "4507/4507 [==============================] - 1s 218us/sample - loss: 0.4928 - accuracy: 0.7624 - val_loss: 0.4885 - val_accuracy: 0.7711\n",
      "Epoch 13/100\n",
      "4507/4507 [==============================] - 1s 219us/sample - loss: 0.4755 - accuracy: 0.7681 - val_loss: 0.4716 - val_accuracy: 0.7862\n",
      "Epoch 14/100\n",
      "4507/4507 [==============================] - 1s 218us/sample - loss: 0.4713 - accuracy: 0.7724 - val_loss: 0.5275 - val_accuracy: 0.7879\n",
      "Epoch 15/100\n",
      "4507/4507 [==============================] - 1s 216us/sample - loss: 0.4823 - accuracy: 0.7677 - val_loss: 0.4667 - val_accuracy: 0.7711\n",
      "1409/1409 [==============================] - 0s 99us/sample - loss: 0.4630 - accuracy: 0.7566\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/100\n",
      "4507/4507 [==============================] - 2s 364us/sample - loss: 0.5475 - accuracy: 0.7373 - val_loss: 0.4965 - val_accuracy: 0.7675\n",
      "Epoch 2/100\n",
      "4507/4507 [==============================] - 1s 231us/sample - loss: 0.4926 - accuracy: 0.7635 - val_loss: 0.4823 - val_accuracy: 0.7870\n",
      "Epoch 3/100\n",
      "4507/4507 [==============================] - 1s 221us/sample - loss: 0.4804 - accuracy: 0.7761 - val_loss: 0.4510 - val_accuracy: 0.7897\n",
      "Epoch 4/100\n",
      "4507/4507 [==============================] - 1s 232us/sample - loss: 0.4843 - accuracy: 0.7808 - val_loss: 0.4697 - val_accuracy: 0.7933\n",
      "Epoch 5/100\n",
      "4507/4507 [==============================] - 1s 241us/sample - loss: 0.4804 - accuracy: 0.7763 - val_loss: 0.4773 - val_accuracy: 0.7906\n",
      "Epoch 6/100\n",
      "4507/4507 [==============================] - 1s 233us/sample - loss: 0.4781 - accuracy: 0.7879 - val_loss: 0.4702 - val_accuracy: 0.7959\n",
      "Epoch 7/100\n",
      "4507/4507 [==============================] - 1s 234us/sample - loss: 0.4798 - accuracy: 0.7848 - val_loss: 0.4598 - val_accuracy: 0.7844\n",
      "Epoch 8/100\n",
      "4507/4507 [==============================] - 1s 234us/sample - loss: 0.4744 - accuracy: 0.7857 - val_loss: 0.4685 - val_accuracy: 0.7888\n",
      "Epoch 9/100\n",
      "4507/4507 [==============================] - 1s 228us/sample - loss: 0.4774 - accuracy: 0.7781 - val_loss: 0.4578 - val_accuracy: 0.7897\n",
      "Epoch 10/100\n",
      "4507/4507 [==============================] - 1s 226us/sample - loss: 0.4709 - accuracy: 0.7823 - val_loss: 0.4649 - val_accuracy: 0.7897\n",
      "Epoch 11/100\n",
      "4507/4507 [==============================] - 1s 237us/sample - loss: 0.4821 - accuracy: 0.7870 - val_loss: 0.4546 - val_accuracy: 0.7844\n",
      "1409/1409 [==============================] - 0s 100us/sample - loss: 0.4565 - accuracy: 0.7835\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/100\n",
      "4507/4507 [==============================] - 2s 385us/sample - loss: 0.5546 - accuracy: 0.7406 - val_loss: 0.5494 - val_accuracy: 0.7702\n",
      "Epoch 2/100\n",
      "4507/4507 [==============================] - 1s 236us/sample - loss: 0.5075 - accuracy: 0.7664 - val_loss: 0.4751 - val_accuracy: 0.7870\n",
      "Epoch 3/100\n",
      "4507/4507 [==============================] - 1s 242us/sample - loss: 0.4907 - accuracy: 0.7710 - val_loss: 0.4733 - val_accuracy: 0.7844\n",
      "Epoch 4/100\n",
      "4507/4507 [==============================] - 1s 233us/sample - loss: 0.4853 - accuracy: 0.7772 - val_loss: 0.5133 - val_accuracy: 0.7897\n",
      "Epoch 5/100\n",
      "4507/4507 [==============================] - 1s 221us/sample - loss: 0.4783 - accuracy: 0.7715 - val_loss: 0.4642 - val_accuracy: 0.7844\n",
      "Epoch 6/100\n",
      "4507/4507 [==============================] - 1s 211us/sample - loss: 0.4773 - accuracy: 0.7761 - val_loss: 0.4667 - val_accuracy: 0.7773\n",
      "Epoch 7/100\n",
      "4507/4507 [==============================] - 1s 213us/sample - loss: 0.4808 - accuracy: 0.7732 - val_loss: 0.4694 - val_accuracy: 0.7968\n",
      "Epoch 8/100\n",
      "4507/4507 [==============================] - 1s 210us/sample - loss: 0.4758 - accuracy: 0.7770 - val_loss: 0.4573 - val_accuracy: 0.7915\n",
      "Epoch 9/100\n",
      "4507/4507 [==============================] - 1s 214us/sample - loss: 0.4782 - accuracy: 0.7755 - val_loss: 0.4742 - val_accuracy: 0.7844\n",
      "1409/1409 [==============================] - 0s 98us/sample - loss: 0.4859 - accuracy: 0.7708\n",
      "Train on 4508 samples, validate on 1127 samples\n",
      "Epoch 1/100\n",
      "4508/4508 [==============================] - 2s 356us/sample - loss: 0.5475 - accuracy: 0.7449 - val_loss: 0.5014 - val_accuracy: 0.7640\n",
      "Epoch 2/100\n",
      "4508/4508 [==============================] - 1s 211us/sample - loss: 0.4961 - accuracy: 0.7615 - val_loss: 0.4759 - val_accuracy: 0.7888\n",
      "Epoch 3/100\n",
      "4508/4508 [==============================] - 1s 212us/sample - loss: 0.4822 - accuracy: 0.7702 - val_loss: 0.4747 - val_accuracy: 0.7746\n",
      "Epoch 4/100\n",
      "4508/4508 [==============================] - 1s 212us/sample - loss: 0.4810 - accuracy: 0.7751 - val_loss: 0.4951 - val_accuracy: 0.7817\n",
      "Epoch 5/100\n",
      "4508/4508 [==============================] - 1s 234us/sample - loss: 0.4777 - accuracy: 0.7806 - val_loss: 0.4648 - val_accuracy: 0.7933\n",
      "Epoch 6/100\n",
      "4508/4508 [==============================] - 1s 216us/sample - loss: 0.4765 - accuracy: 0.7606 - val_loss: 0.4593 - val_accuracy: 0.7933\n",
      "Epoch 7/100\n",
      "4508/4508 [==============================] - 1s 215us/sample - loss: 0.4810 - accuracy: 0.7804 - val_loss: 0.4728 - val_accuracy: 0.7844\n",
      "Epoch 8/100\n",
      "4508/4508 [==============================] - 1s 222us/sample - loss: 0.4710 - accuracy: 0.7760 - val_loss: 0.4604 - val_accuracy: 0.7870\n",
      "Epoch 9/100\n",
      "4508/4508 [==============================] - 1s 235us/sample - loss: 0.4672 - accuracy: 0.7811 - val_loss: 0.4599 - val_accuracy: 0.7950\n",
      "Epoch 10/100\n",
      "4508/4508 [==============================] - 1s 228us/sample - loss: 0.4658 - accuracy: 0.7844 - val_loss: 0.4650 - val_accuracy: 0.7897\n",
      "Epoch 11/100\n",
      "4508/4508 [==============================] - 1s 222us/sample - loss: 0.4705 - accuracy: 0.7766 - val_loss: 0.4655 - val_accuracy: 0.7888\n",
      "Epoch 12/100\n",
      "4508/4508 [==============================] - 1s 217us/sample - loss: 0.4818 - accuracy: 0.7711 - val_loss: 0.4662 - val_accuracy: 0.7764\n",
      "Epoch 13/100\n",
      "4508/4508 [==============================] - 1s 216us/sample - loss: 0.4880 - accuracy: 0.7675 - val_loss: 0.4668 - val_accuracy: 0.7808\n",
      "Epoch 14/100\n",
      "4508/4508 [==============================] - 1s 214us/sample - loss: 0.4788 - accuracy: 0.7666 - val_loss: 0.4749 - val_accuracy: 0.7764\n",
      "Epoch 15/100\n",
      "4508/4508 [==============================] - 1s 215us/sample - loss: 0.4683 - accuracy: 0.7811 - val_loss: 0.5037 - val_accuracy: 0.7924\n",
      "1408/1408 [==============================] - 0s 102us/sample - loss: 0.5124 - accuracy: 0.7962\n",
      "Train on 4508 samples, validate on 1127 samples\n",
      "Epoch 1/100\n",
      "4508/4508 [==============================] - 2s 354us/sample - loss: 0.5584 - accuracy: 0.7347 - val_loss: 0.5035 - val_accuracy: 0.7311\n",
      "Epoch 2/100\n",
      "4508/4508 [==============================] - 1s 215us/sample - loss: 0.5004 - accuracy: 0.7673 - val_loss: 0.5005 - val_accuracy: 0.7587\n",
      "Epoch 3/100\n",
      "4508/4508 [==============================] - 1s 215us/sample - loss: 0.4862 - accuracy: 0.7662 - val_loss: 0.4846 - val_accuracy: 0.7764\n",
      "Epoch 4/100\n",
      "4508/4508 [==============================] - 1s 214us/sample - loss: 0.4780 - accuracy: 0.7715 - val_loss: 0.4982 - val_accuracy: 0.7755\n",
      "Epoch 5/100\n",
      "4508/4508 [==============================] - 1s 214us/sample - loss: 0.4895 - accuracy: 0.7675 - val_loss: 0.5392 - val_accuracy: 0.7498\n",
      "Epoch 6/100\n",
      "4508/4508 [==============================] - 1s 215us/sample - loss: 0.4726 - accuracy: 0.7722 - val_loss: 0.4800 - val_accuracy: 0.7791\n",
      "Epoch 7/100\n",
      "4508/4508 [==============================] - 1s 215us/sample - loss: 0.4656 - accuracy: 0.7815 - val_loss: 0.4729 - val_accuracy: 0.7844\n",
      "Epoch 8/100\n",
      "4508/4508 [==============================] - 1s 214us/sample - loss: 0.4740 - accuracy: 0.7762 - val_loss: 0.4842 - val_accuracy: 0.7870\n",
      "Epoch 9/100\n",
      "4508/4508 [==============================] - 1s 216us/sample - loss: 0.4836 - accuracy: 0.7733 - val_loss: 0.4822 - val_accuracy: 0.7702\n",
      "Epoch 10/100\n",
      "4508/4508 [==============================] - 1s 226us/sample - loss: 0.4776 - accuracy: 0.7682 - val_loss: 0.5023 - val_accuracy: 0.7587\n",
      "Epoch 11/100\n",
      "4508/4508 [==============================] - 1s 217us/sample - loss: 0.4836 - accuracy: 0.7684 - val_loss: 0.5259 - val_accuracy: 0.7542\n",
      "Epoch 12/100\n",
      "4508/4508 [==============================] - 1s 218us/sample - loss: 0.4878 - accuracy: 0.7766 - val_loss: 0.5070 - val_accuracy: 0.7578\n",
      "1408/1408 [==============================] - 0s 101us/sample - loss: 0.4810 - accuracy: 0.7720\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/100\n",
      "4507/4507 [==============================] - 2s 373us/sample - loss: 0.6307 - accuracy: 0.7180 - val_loss: 0.5965 - val_accuracy: 0.7294\n",
      "Epoch 2/100\n",
      "4507/4507 [==============================] - 1s 232us/sample - loss: 0.5833 - accuracy: 0.7357 - val_loss: 0.5845 - val_accuracy: 0.7294\n",
      "Epoch 3/100\n",
      "4507/4507 [==============================] - 1s 230us/sample - loss: 0.5781 - accuracy: 0.7357 - val_loss: 0.5839 - val_accuracy: 0.7294\n",
      "Epoch 4/100\n",
      "4507/4507 [==============================] - 1s 231us/sample - loss: 0.5776 - accuracy: 0.7357 - val_loss: 0.5839 - val_accuracy: 0.7294\n",
      "Epoch 5/100\n",
      "4507/4507 [==============================] - 1s 233us/sample - loss: 0.5776 - accuracy: 0.7357 - val_loss: 0.5839 - val_accuracy: 0.7294\n",
      "Epoch 6/100\n",
      "4507/4507 [==============================] - 1s 235us/sample - loss: 0.5775 - accuracy: 0.7357 - val_loss: 0.5840 - val_accuracy: 0.7294\n",
      "Epoch 7/100\n",
      "4507/4507 [==============================] - 1s 235us/sample - loss: 0.5775 - accuracy: 0.7357 - val_loss: 0.5843 - val_accuracy: 0.7294\n",
      "1409/1409 [==============================] - 0s 104us/sample - loss: 0.5780 - accuracy: 0.7353\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/100\n",
      "4507/4507 [==============================] - 2s 378us/sample - loss: 0.6341 - accuracy: 0.7138 - val_loss: 0.5972 - val_accuracy: 0.7294\n",
      "Epoch 2/100\n",
      "4507/4507 [==============================] - 1s 233us/sample - loss: 0.5853 - accuracy: 0.7337 - val_loss: 0.5847 - val_accuracy: 0.7294\n",
      "Epoch 3/100\n",
      "4507/4507 [==============================] - 1s 236us/sample - loss: 0.5800 - accuracy: 0.7337 - val_loss: 0.5839 - val_accuracy: 0.7294\n",
      "Epoch 4/100\n",
      "4507/4507 [==============================] - 1s 244us/sample - loss: 0.5797 - accuracy: 0.7337 - val_loss: 0.5839 - val_accuracy: 0.7294\n",
      "Epoch 5/100\n",
      "4507/4507 [==============================] - 1s 254us/sample - loss: 0.5797 - accuracy: 0.7337 - val_loss: 0.5839 - val_accuracy: 0.7294\n",
      "Epoch 6/100\n",
      "4507/4507 [==============================] - 1s 249us/sample - loss: 0.5797 - accuracy: 0.7337 - val_loss: 0.5840 - val_accuracy: 0.7294\n",
      "Epoch 7/100\n",
      "4507/4507 [==============================] - 1s 244us/sample - loss: 0.5796 - accuracy: 0.7337 - val_loss: 0.5839 - val_accuracy: 0.7294\n",
      "1409/1409 [==============================] - 0s 108us/sample - loss: 0.5716 - accuracy: 0.7417\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/100\n",
      "4507/4507 [==============================] - 3s 641us/sample - loss: 0.6316 - accuracy: 0.7271 - val_loss: 0.5975 - val_accuracy: 0.7294\n",
      "Epoch 2/100\n",
      "4507/4507 [==============================] - 1s 228us/sample - loss: 0.5840 - accuracy: 0.7351 - val_loss: 0.5846 - val_accuracy: 0.7294\n",
      "Epoch 3/100\n",
      "4507/4507 [==============================] - 1s 229us/sample - loss: 0.5787 - accuracy: 0.7351 - val_loss: 0.5839 - val_accuracy: 0.7294\n",
      "Epoch 4/100\n",
      "4507/4507 [==============================] - 1s 233us/sample - loss: 0.5784 - accuracy: 0.7351 - val_loss: 0.5839 - val_accuracy: 0.7294\n",
      "Epoch 5/100\n",
      "4507/4507 [==============================] - 1s 227us/sample - loss: 0.5783 - accuracy: 0.7351 - val_loss: 0.5839 - val_accuracy: 0.7294\n",
      "Epoch 6/100\n",
      "4507/4507 [==============================] - 1s 234us/sample - loss: 0.5782 - accuracy: 0.7351 - val_loss: 0.5840 - val_accuracy: 0.7294\n",
      "Epoch 7/100\n",
      "4507/4507 [==============================] - 1s 232us/sample - loss: 0.5783 - accuracy: 0.7351 - val_loss: 0.5840 - val_accuracy: 0.7294\n",
      "1409/1409 [==============================] - 0s 101us/sample - loss: 0.5758 - accuracy: 0.7374\n",
      "Train on 4508 samples, validate on 1127 samples\n",
      "Epoch 1/100\n",
      "4508/4508 [==============================] - 2s 393us/sample - loss: 0.6282 - accuracy: 0.7276 - val_loss: 0.5958 - val_accuracy: 0.7294\n",
      "Epoch 2/100\n",
      "4508/4508 [==============================] - 1s 245us/sample - loss: 0.5811 - accuracy: 0.7378 - val_loss: 0.5844 - val_accuracy: 0.7294\n",
      "Epoch 3/100\n",
      "4508/4508 [==============================] - 1s 242us/sample - loss: 0.5760 - accuracy: 0.7378 - val_loss: 0.5839 - val_accuracy: 0.7294\n",
      "Epoch 4/100\n",
      "4508/4508 [==============================] - 1s 234us/sample - loss: 0.5755 - accuracy: 0.7378 - val_loss: 0.5840 - val_accuracy: 0.7294\n",
      "Epoch 5/100\n",
      "4508/4508 [==============================] - 1s 232us/sample - loss: 0.5755 - accuracy: 0.7378 - val_loss: 0.5840 - val_accuracy: 0.7294\n",
      "Epoch 6/100\n",
      "4508/4508 [==============================] - 1s 239us/sample - loss: 0.5755 - accuracy: 0.7378 - val_loss: 0.5840 - val_accuracy: 0.7294\n",
      "Epoch 7/100\n",
      "4508/4508 [==============================] - 1s 232us/sample - loss: 0.5755 - accuracy: 0.7378 - val_loss: 0.5840 - val_accuracy: 0.7294\n",
      "1408/1408 [==============================] - 0s 105us/sample - loss: 0.5847 - accuracy: 0.7287\n",
      "Train on 4508 samples, validate on 1127 samples\n",
      "Epoch 1/100\n",
      "4508/4508 [==============================] - 2s 411us/sample - loss: 0.6248 - accuracy: 0.7380 - val_loss: 0.5966 - val_accuracy: 0.7267\n",
      "Epoch 2/100\n",
      "4508/4508 [==============================] - 1s 240us/sample - loss: 0.5807 - accuracy: 0.7380 - val_loss: 0.5869 - val_accuracy: 0.7267\n",
      "Epoch 3/100\n",
      "4508/4508 [==============================] - 1s 232us/sample - loss: 0.5757 - accuracy: 0.7380 - val_loss: 0.5866 - val_accuracy: 0.7267\n",
      "Epoch 4/100\n",
      "4508/4508 [==============================] - 1s 232us/sample - loss: 0.5753 - accuracy: 0.7380 - val_loss: 0.5867 - val_accuracy: 0.7267\n",
      "Epoch 5/100\n",
      "4508/4508 [==============================] - 1s 232us/sample - loss: 0.5752 - accuracy: 0.7380 - val_loss: 0.5869 - val_accuracy: 0.7267\n",
      "Epoch 6/100\n",
      "4508/4508 [==============================] - 1s 235us/sample - loss: 0.5752 - accuracy: 0.7380 - val_loss: 0.5868 - val_accuracy: 0.7267\n",
      "1408/1408 [==============================] - 0s 105us/sample - loss: 0.5833 - accuracy: 0.7301\n",
      "Train on 5634 samples, validate on 1409 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:  3.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5634/5634 [==============================] - 2s 323us/sample - loss: 1.0873 - accuracy: 0.7164 - val_loss: 0.7469 - val_accuracy: 0.7786\n",
      "Epoch 2/100\n",
      "5634/5634 [==============================] - 1s 214us/sample - loss: 0.5670 - accuracy: 0.7595 - val_loss: 0.5309 - val_accuracy: 0.7764\n",
      "Epoch 3/100\n",
      "5634/5634 [==============================] - 1s 212us/sample - loss: 0.5338 - accuracy: 0.7645 - val_loss: 0.4526 - val_accuracy: 0.7942\n",
      "Epoch 4/100\n",
      "5634/5634 [==============================] - 1s 212us/sample - loss: 0.4827 - accuracy: 0.7808 - val_loss: 0.4469 - val_accuracy: 0.7906\n",
      "Epoch 5/100\n",
      "5634/5634 [==============================] - 1s 214us/sample - loss: 0.4776 - accuracy: 0.7790 - val_loss: 0.4516 - val_accuracy: 0.7899\n",
      "Epoch 6/100\n",
      "5634/5634 [==============================] - 1s 218us/sample - loss: 0.5169 - accuracy: 0.7764 - val_loss: 0.4688 - val_accuracy: 0.7842\n",
      "Epoch 7/100\n",
      "5634/5634 [==============================] - 1s 213us/sample - loss: 0.4667 - accuracy: 0.7827 - val_loss: 0.4520 - val_accuracy: 0.7807\n",
      "Epoch 8/100\n",
      "5634/5634 [==============================] - 1s 211us/sample - loss: 0.4589 - accuracy: 0.7881 - val_loss: 0.4364 - val_accuracy: 0.7949\n",
      "Epoch 9/100\n",
      "5634/5634 [==============================] - 1s 212us/sample - loss: 0.4662 - accuracy: 0.7879 - val_loss: 0.4399 - val_accuracy: 0.7921\n",
      "Epoch 10/100\n",
      "5634/5634 [==============================] - 1s 211us/sample - loss: 0.4627 - accuracy: 0.7897 - val_loss: 0.4352 - val_accuracy: 0.7963\n",
      "Epoch 11/100\n",
      "5634/5634 [==============================] - 1s 214us/sample - loss: 0.4592 - accuracy: 0.7877 - val_loss: 0.4360 - val_accuracy: 0.7913\n",
      "Epoch 12/100\n",
      "5634/5634 [==============================] - 1s 212us/sample - loss: 0.4511 - accuracy: 0.7957 - val_loss: 0.4724 - val_accuracy: 0.7921\n",
      "Epoch 13/100\n",
      "5634/5634 [==============================] - 1s 227us/sample - loss: 0.4520 - accuracy: 0.7886 - val_loss: 0.4589 - val_accuracy: 0.7913\n",
      "Epoch 14/100\n",
      "5634/5634 [==============================] - 1s 224us/sample - loss: 0.4501 - accuracy: 0.7909 - val_loss: 0.4582 - val_accuracy: 0.7913\n",
      "Epoch 15/100\n",
      "5634/5634 [==============================] - 1s 219us/sample - loss: 0.4426 - accuracy: 0.7978 - val_loss: 0.4706 - val_accuracy: 0.7757\n",
      "Epoch 16/100\n",
      "5634/5634 [==============================] - 1s 216us/sample - loss: 0.4494 - accuracy: 0.7918 - val_loss: 0.4831 - val_accuracy: 0.7921\n",
      "Epoch 17/100\n",
      "5634/5634 [==============================] - 1s 225us/sample - loss: 0.4538 - accuracy: 0.7938 - val_loss: 0.4374 - val_accuracy: 0.7906\n",
      "Epoch 18/100\n",
      "5634/5634 [==============================] - 1s 221us/sample - loss: 0.4418 - accuracy: 0.7973 - val_loss: 0.4351 - val_accuracy: 0.7956\n",
      "Epoch 19/100\n",
      "5634/5634 [==============================] - 1s 211us/sample - loss: 0.4431 - accuracy: 0.7966 - val_loss: 0.5347 - val_accuracy: 0.7892\n",
      "Epoch 20/100\n",
      "5634/5634 [==============================] - 1s 211us/sample - loss: 0.4439 - accuracy: 0.7973 - val_loss: 0.4563 - val_accuracy: 0.7871\n",
      "\n",
      "Best score: 0.7880178689956665\n",
      "Best params: {'activation_per_layer': 'relu', 'additional_layers': 4, 'batch_size': 10, 'epochs': 100, 'learning_rate': 0.001, 'network_weights_init': 'glorot_normal', 'nodes_per_layer': 52}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# tune activation functions\n",
    "\n",
    "params = {\n",
    "    'nodes_per_layer': [52],\n",
    "    'additional_layers': [4],\n",
    "    'batch_size': [10],\n",
    "    'epochs': [100],\n",
    "    'learning_rate': [0.001],\n",
    "    'network_weights_init': ['glorot_normal'],\n",
    "    'activation_per_layer': ['relu', 'sigmoid', 'softmax'],\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=KerasClassifier(build_fn=create_model),\n",
    "    param_grid=params,\n",
    "    n_jobs=1,\n",
    "    cv=5,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid.fit(X, y, callbacks=[stop], validation_split=0.2)\n",
    "\n",
    "print()\n",
    "print('Best score:', grid.best_score_)\n",
    "print('Best params:', grid.best_params_)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "# Define and compile the model\n",
    "def create_model(additional_layers=0, nodes_per_layer=26, activation_per_layer='relu',\n",
    "                 loss_function='binary_crossentropy', learning_rate=0.001,\n",
    "                 network_weights_init='uniform', dropout_rate=0.1):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(nodes_per_layer, activation=activation_per_layer, input_dim=26, kernel_initializer=network_weights_init))\n",
    "    for _ in range(additional_layers):\n",
    "        model.add(Dropout(rate=dropout_rate))\n",
    "        model.add(Dense(nodes_per_layer, activation=activation_per_layer, kernel_initializer=network_weights_init))\n",
    "    model.add(Dense(1, activation='sigmoid', kernel_initializer=network_weights_init))\n",
    "\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    \n",
    "    model.compile(loss=loss_function, optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4507/4507 [==============================] - 1s 267us/sample - loss: 54.4153 - accuracy: 0.6576 - val_loss: 1.6594 - val_accuracy: 0.5049\n",
      "Epoch 2/100\n",
      "4507/4507 [==============================] - 1s 185us/sample - loss: 0.8717 - accuracy: 0.6854 - val_loss: 1.3436 - val_accuracy: 0.7737\n",
      "Epoch 3/100\n",
      "4507/4507 [==============================] - 1s 176us/sample - loss: 0.6267 - accuracy: 0.7699 - val_loss: 1.5895 - val_accuracy: 0.5084\n",
      "Epoch 4/100\n",
      "4507/4507 [==============================] - 1s 171us/sample - loss: 0.7285 - accuracy: 0.7533 - val_loss: 1.9144 - val_accuracy: 0.7666\n",
      "Epoch 5/100\n",
      "4507/4507 [==============================] - 1s 178us/sample - loss: 0.7257 - accuracy: 0.7608 - val_loss: 0.8907 - val_accuracy: 0.7844\n",
      "Epoch 6/100\n",
      "4507/4507 [==============================] - 1s 172us/sample - loss: 0.7015 - accuracy: 0.7621 - val_loss: 0.5094 - val_accuracy: 0.7693\n",
      "Epoch 7/100\n",
      "4507/4507 [==============================] - 1s 169us/sample - loss: 0.6007 - accuracy: 0.7695 - val_loss: 1.0534 - val_accuracy: 0.7844\n",
      "Epoch 8/100\n",
      "4507/4507 [==============================] - 1s 169us/sample - loss: 0.7252 - accuracy: 0.7644 - val_loss: 0.5423 - val_accuracy: 0.7968\n",
      "1409/1409 [==============================] - 0s 89us/sample - loss: 0.4823 - accuracy: 0.8112\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/100\n",
      "4507/4507 [==============================] - 1s 270us/sample - loss: 31.1757 - accuracy: 0.6173 - val_loss: 0.7639 - val_accuracy: 0.7622\n",
      "Epoch 2/100\n",
      "4507/4507 [==============================] - 1s 171us/sample - loss: 0.9052 - accuracy: 0.7513 - val_loss: 0.8097 - val_accuracy: 0.7888\n",
      "Epoch 3/100\n",
      "4507/4507 [==============================] - 1s 171us/sample - loss: 0.6438 - accuracy: 0.7615 - val_loss: 0.5687 - val_accuracy: 0.6939\n",
      "Epoch 4/100\n",
      "4507/4507 [==============================] - 1s 171us/sample - loss: 0.8006 - accuracy: 0.7559 - val_loss: 0.4449 - val_accuracy: 0.7950\n",
      "Epoch 5/100\n",
      "4507/4507 [==============================] - 1s 180us/sample - loss: 0.6810 - accuracy: 0.7577 - val_loss: 1.6008 - val_accuracy: 0.7897\n",
      "Epoch 6/100\n",
      "4507/4507 [==============================] - 1s 177us/sample - loss: 0.7477 - accuracy: 0.7566 - val_loss: 0.8357 - val_accuracy: 0.7968\n",
      "Epoch 7/100\n",
      "4507/4507 [==============================] - 1s 184us/sample - loss: 0.6126 - accuracy: 0.7761 - val_loss: 1.1152 - val_accuracy: 0.7906\n",
      "Epoch 8/100\n",
      "4507/4507 [==============================] - 1s 182us/sample - loss: 0.6480 - accuracy: 0.7690 - val_loss: 1.6604 - val_accuracy: 0.7906\n",
      "Epoch 9/100\n",
      "4507/4507 [==============================] - 1s 183us/sample - loss: 0.7180 - accuracy: 0.7617 - val_loss: 0.4563 - val_accuracy: 0.7924\n",
      "Epoch 10/100\n",
      "4507/4507 [==============================] - 1s 180us/sample - loss: 0.5653 - accuracy: 0.7790 - val_loss: 0.6086 - val_accuracy: 0.6779\n",
      "Epoch 11/100\n",
      "4507/4507 [==============================] - 1s 177us/sample - loss: 0.6744 - accuracy: 0.7701 - val_loss: 0.6944 - val_accuracy: 0.7986\n",
      "Epoch 12/100\n",
      "4507/4507 [==============================] - 1s 177us/sample - loss: 0.5366 - accuracy: 0.7741 - val_loss: 0.6046 - val_accuracy: 0.6815\n",
      "Epoch 13/100\n",
      "4507/4507 [==============================] - 1s 170us/sample - loss: 0.6791 - accuracy: 0.7744 - val_loss: 0.5952 - val_accuracy: 0.7977\n",
      "Epoch 14/100\n",
      "4507/4507 [==============================] - 1s 169us/sample - loss: 0.7399 - accuracy: 0.7677 - val_loss: 0.5075 - val_accuracy: 0.7365\n",
      "Epoch 15/100\n",
      "4507/4507 [==============================] - 1s 170us/sample - loss: 0.6382 - accuracy: 0.7730 - val_loss: 0.4436 - val_accuracy: 0.7986\n",
      "1409/1409 [==============================] - 0s 90us/sample - loss: 0.4112 - accuracy: 0.8077\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/100\n",
      "4507/4507 [==============================] - 1s 267us/sample - loss: 48.1831 - accuracy: 0.5028 - val_loss: 0.6202 - val_accuracy: 0.7764\n",
      "Epoch 2/100\n",
      "4507/4507 [==============================] - 1s 170us/sample - loss: 0.6047 - accuracy: 0.7730 - val_loss: 0.5803 - val_accuracy: 0.7853\n",
      "Epoch 3/100\n",
      "4507/4507 [==============================] - 1s 169us/sample - loss: 0.5664 - accuracy: 0.7843 - val_loss: 0.5435 - val_accuracy: 0.7995\n",
      "Epoch 4/100\n",
      "4507/4507 [==============================] - 1s 169us/sample - loss: 0.5335 - accuracy: 0.7890 - val_loss: 0.5188 - val_accuracy: 0.7950\n",
      "Epoch 5/100\n",
      "4507/4507 [==============================] - 1s 170us/sample - loss: 0.5149 - accuracy: 0.7883 - val_loss: 0.5095 - val_accuracy: 0.7817\n",
      "Epoch 6/100\n",
      "4507/4507 [==============================] - 1s 169us/sample - loss: 0.5017 - accuracy: 0.7890 - val_loss: 0.4929 - val_accuracy: 0.7870\n",
      "Epoch 7/100\n",
      "4507/4507 [==============================] - 1s 169us/sample - loss: 0.4895 - accuracy: 0.7921 - val_loss: 0.4853 - val_accuracy: 0.7897\n",
      "Epoch 8/100\n",
      "4507/4507 [==============================] - 1s 170us/sample - loss: 0.4865 - accuracy: 0.7863 - val_loss: 0.4795 - val_accuracy: 0.7924\n",
      "Epoch 9/100\n",
      "4507/4507 [==============================] - 1s 168us/sample - loss: 0.4808 - accuracy: 0.7930 - val_loss: 0.4727 - val_accuracy: 0.7941\n",
      "Epoch 10/100\n",
      "4507/4507 [==============================] - 1s 170us/sample - loss: 0.4774 - accuracy: 0.7877 - val_loss: 0.5021 - val_accuracy: 0.7516\n",
      "Epoch 11/100\n",
      "4507/4507 [==============================] - 1s 170us/sample - loss: 0.4733 - accuracy: 0.7877 - val_loss: 0.4687 - val_accuracy: 0.7977\n",
      "Epoch 12/100\n",
      "4507/4507 [==============================] - 1s 169us/sample - loss: 0.4689 - accuracy: 0.7917 - val_loss: 0.4666 - val_accuracy: 0.7915\n",
      "1409/1409 [==============================] - 0s 90us/sample - loss: 0.4755 - accuracy: 0.7864\n",
      "Train on 4508 samples, validate on 1127 samples\n",
      "Epoch 1/100\n",
      "4508/4508 [==============================] - 1s 266us/sample - loss: 6.2832 - accuracy: 0.5799 - val_loss: 0.7921 - val_accuracy: 0.5874\n",
      "Epoch 2/100\n",
      "4508/4508 [==============================] - 1s 170us/sample - loss: 0.6262 - accuracy: 0.7150 - val_loss: 0.4927 - val_accuracy: 0.7897\n",
      "Epoch 3/100\n",
      "4508/4508 [==============================] - 1s 169us/sample - loss: 0.5450 - accuracy: 0.7740 - val_loss: 0.4639 - val_accuracy: 0.7862\n",
      "Epoch 4/100\n",
      "4508/4508 [==============================] - 1s 169us/sample - loss: 0.5038 - accuracy: 0.7793 - val_loss: 0.7720 - val_accuracy: 0.6122\n",
      "Epoch 5/100\n",
      "4508/4508 [==============================] - 1s 169us/sample - loss: 0.4959 - accuracy: 0.7857 - val_loss: 0.4398 - val_accuracy: 0.7941\n",
      "Epoch 6/100\n",
      "4508/4508 [==============================] - 1s 168us/sample - loss: 0.4868 - accuracy: 0.7926 - val_loss: 0.5435 - val_accuracy: 0.7915\n",
      "Epoch 7/100\n",
      "4508/4508 [==============================] - 1s 168us/sample - loss: 0.4860 - accuracy: 0.7853 - val_loss: 0.4338 - val_accuracy: 0.7977\n",
      "Epoch 8/100\n",
      "4508/4508 [==============================] - 1s 168us/sample - loss: 0.5048 - accuracy: 0.7811 - val_loss: 0.5058 - val_accuracy: 0.7933\n",
      "Epoch 9/100\n",
      "4508/4508 [==============================] - 1s 169us/sample - loss: 0.4928 - accuracy: 0.7802 - val_loss: 0.4371 - val_accuracy: 0.7924\n",
      "Epoch 10/100\n",
      "4508/4508 [==============================] - 1s 168us/sample - loss: 0.5032 - accuracy: 0.7837 - val_loss: 0.5847 - val_accuracy: 0.6770\n",
      "Epoch 11/100\n",
      "4508/4508 [==============================] - 1s 168us/sample - loss: 0.4770 - accuracy: 0.7886 - val_loss: 0.4509 - val_accuracy: 0.7986\n",
      "1408/1408 [==============================] - 0s 88us/sample - loss: 0.4488 - accuracy: 0.8011\n",
      "Train on 4508 samples, validate on 1127 samples\n",
      "Epoch 1/100\n",
      "4508/4508 [==============================] - 1s 269us/sample - loss: 1.3020 - accuracy: 0.6999 - val_loss: 0.6000 - val_accuracy: 0.7267\n",
      "Epoch 2/100\n",
      "4508/4508 [==============================] - 1s 169us/sample - loss: 0.5788 - accuracy: 0.7380 - val_loss: 0.5844 - val_accuracy: 0.7267\n",
      "Epoch 3/100\n",
      "4508/4508 [==============================] - 1s 170us/sample - loss: 0.5622 - accuracy: 0.7380 - val_loss: 0.5684 - val_accuracy: 0.7267\n",
      "Epoch 4/100\n",
      "4508/4508 [==============================] - 1s 169us/sample - loss: 0.5490 - accuracy: 0.7380 - val_loss: 0.5897 - val_accuracy: 0.7267\n",
      "Epoch 5/100\n",
      "4508/4508 [==============================] - 1s 175us/sample - loss: 0.5581 - accuracy: 0.7380 - val_loss: 0.5664 - val_accuracy: 0.7267\n",
      "Epoch 6/100\n",
      "4508/4508 [==============================] - 1s 179us/sample - loss: 0.5710 - accuracy: 0.7380 - val_loss: 0.5871 - val_accuracy: 0.7267\n",
      "Epoch 7/100\n",
      "4508/4508 [==============================] - 1s 178us/sample - loss: 0.5759 - accuracy: 0.7380 - val_loss: 0.5863 - val_accuracy: 0.7267\n",
      "1408/1408 [==============================] - 0s 89us/sample - loss: 0.5828 - accuracy: 0.7301\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/100\n",
      "4507/4507 [==============================] - 1s 270us/sample - loss: 26.5520 - accuracy: 0.4910 - val_loss: 0.6458 - val_accuracy: 0.7276\n",
      "Epoch 2/100\n",
      "4507/4507 [==============================] - 1s 170us/sample - loss: 0.6233 - accuracy: 0.7349 - val_loss: 0.6213 - val_accuracy: 0.7276\n",
      "Epoch 3/100\n",
      "4507/4507 [==============================] - 1s 170us/sample - loss: 0.6033 - accuracy: 0.7349 - val_loss: 0.6041 - val_accuracy: 0.7276\n",
      "Epoch 4/100\n",
      "4507/4507 [==============================] - 1s 170us/sample - loss: 0.5904 - accuracy: 0.7349 - val_loss: 0.5938 - val_accuracy: 0.7276\n",
      "Epoch 5/100\n",
      "4507/4507 [==============================] - 1s 170us/sample - loss: 0.5834 - accuracy: 0.7351 - val_loss: 0.5886 - val_accuracy: 0.7276\n",
      "Epoch 6/100\n",
      "4507/4507 [==============================] - 1s 169us/sample - loss: 0.5800 - accuracy: 0.7357 - val_loss: 0.5861 - val_accuracy: 0.7276\n",
      "Epoch 7/100\n",
      "4507/4507 [==============================] - 1s 171us/sample - loss: 0.5784 - accuracy: 0.7357 - val_loss: 0.5850 - val_accuracy: 0.7276\n",
      "1409/1409 [==============================] - 0s 90us/sample - loss: 0.5797 - accuracy: 0.7331\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/100\n",
      "4507/4507 [==============================] - 1s 269us/sample - loss: 22.0059 - accuracy: 0.5829 - val_loss: 0.6420 - val_accuracy: 0.3727\n",
      "Epoch 2/100\n",
      "4507/4507 [==============================] - 1s 169us/sample - loss: 0.6256 - accuracy: 0.7242 - val_loss: 0.6738 - val_accuracy: 0.7294\n",
      "Epoch 3/100\n",
      "4507/4507 [==============================] - 1s 168us/sample - loss: 0.5897 - accuracy: 0.7337 - val_loss: 0.5711 - val_accuracy: 0.7294\n",
      "Epoch 4/100\n",
      "4507/4507 [==============================] - 1s 167us/sample - loss: 0.5860 - accuracy: 0.7337 - val_loss: 0.5600 - val_accuracy: 0.7294\n",
      "Epoch 5/100\n",
      "4507/4507 [==============================] - 1s 168us/sample - loss: 0.5621 - accuracy: 0.7337 - val_loss: 0.5564 - val_accuracy: 0.7294\n",
      "Epoch 6/100\n",
      "4507/4507 [==============================] - 1s 169us/sample - loss: 0.5598 - accuracy: 0.7337 - val_loss: 0.5601 - val_accuracy: 0.7294\n",
      "Epoch 7/100\n",
      "4507/4507 [==============================] - 1s 168us/sample - loss: 0.5618 - accuracy: 0.7337 - val_loss: 0.5569 - val_accuracy: 0.7294\n",
      "Epoch 8/100\n",
      "4507/4507 [==============================] - 1s 167us/sample - loss: 0.5589 - accuracy: 0.7337 - val_loss: 0.5569 - val_accuracy: 0.7294\n",
      "1409/1409 [==============================] - 0s 88us/sample - loss: 0.5370 - accuracy: 0.7417\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/100\n",
      "4507/4507 [==============================] - 1s 273us/sample - loss: 53.7707 - accuracy: 0.4480 - val_loss: 0.5490 - val_accuracy: 0.7764\n",
      "Epoch 2/100\n",
      "4507/4507 [==============================] - 1s 171us/sample - loss: 0.5484 - accuracy: 0.7692 - val_loss: 0.5492 - val_accuracy: 0.7782\n",
      "Epoch 3/100\n",
      "4507/4507 [==============================] - 1s 170us/sample - loss: 0.5471 - accuracy: 0.7708 - val_loss: 0.5402 - val_accuracy: 0.7773\n",
      "Epoch 4/100\n",
      "4507/4507 [==============================] - 1s 170us/sample - loss: 0.5427 - accuracy: 0.7728 - val_loss: 0.5338 - val_accuracy: 0.7853\n",
      "Epoch 5/100\n",
      "4507/4507 [==============================] - 1s 171us/sample - loss: 0.5381 - accuracy: 0.7770 - val_loss: 0.5378 - val_accuracy: 0.7764\n",
      "Epoch 6/100\n",
      "4507/4507 [==============================] - 1s 170us/sample - loss: 0.5350 - accuracy: 0.7721 - val_loss: 0.5925 - val_accuracy: 0.7453\n",
      "Epoch 7/100\n",
      "4507/4507 [==============================] - 1s 168us/sample - loss: 0.5268 - accuracy: 0.7792 - val_loss: 0.5254 - val_accuracy: 0.7835\n",
      "Epoch 8/100\n",
      "4507/4507 [==============================] - 1s 169us/sample - loss: 0.5267 - accuracy: 0.7828 - val_loss: 0.5173 - val_accuracy: 0.7870\n",
      "Epoch 9/100\n",
      "4507/4507 [==============================] - 1s 169us/sample - loss: 0.5279 - accuracy: 0.7806 - val_loss: 0.5025 - val_accuracy: 0.7897\n",
      "Epoch 10/100\n",
      "4507/4507 [==============================] - 1s 168us/sample - loss: 0.5242 - accuracy: 0.7828 - val_loss: 0.5725 - val_accuracy: 0.7888\n",
      "Epoch 11/100\n",
      "4507/4507 [==============================] - 1s 168us/sample - loss: 0.5155 - accuracy: 0.7837 - val_loss: 0.5048 - val_accuracy: 0.7826\n",
      "Epoch 12/100\n",
      "4507/4507 [==============================] - 1s 168us/sample - loss: 0.5095 - accuracy: 0.7905 - val_loss: 0.4954 - val_accuracy: 0.7808\n",
      "Epoch 13/100\n",
      "4507/4507 [==============================] - 1s 169us/sample - loss: 0.5306 - accuracy: 0.7737 - val_loss: 0.5779 - val_accuracy: 0.7098\n",
      "Epoch 14/100\n",
      "4507/4507 [==============================] - 1s 183us/sample - loss: 0.5167 - accuracy: 0.7843 - val_loss: 0.4953 - val_accuracy: 0.7959\n",
      "Epoch 15/100\n",
      "4507/4507 [==============================] - 1s 178us/sample - loss: 0.5058 - accuracy: 0.7870 - val_loss: 0.4901 - val_accuracy: 0.7924\n",
      "Epoch 16/100\n",
      "4507/4507 [==============================] - 1s 180us/sample - loss: 0.4930 - accuracy: 0.7925 - val_loss: 0.4729 - val_accuracy: 0.7977\n",
      "Epoch 17/100\n",
      "4507/4507 [==============================] - 1s 181us/sample - loss: 0.5045 - accuracy: 0.7846 - val_loss: 0.5016 - val_accuracy: 0.7888\n",
      "Epoch 18/100\n",
      "4507/4507 [==============================] - 1s 179us/sample - loss: 0.4925 - accuracy: 0.7908 - val_loss: 0.4908 - val_accuracy: 0.7915\n",
      "Epoch 19/100\n",
      "4507/4507 [==============================] - 1s 180us/sample - loss: 0.4853 - accuracy: 0.7883 - val_loss: 0.5050 - val_accuracy: 0.7862\n",
      "Epoch 20/100\n",
      "4507/4507 [==============================] - 1s 177us/sample - loss: 0.4909 - accuracy: 0.7892 - val_loss: 0.4723 - val_accuracy: 0.7924\n",
      "Epoch 21/100\n",
      "4507/4507 [==============================] - 1s 177us/sample - loss: 0.4762 - accuracy: 0.7954 - val_loss: 0.4563 - val_accuracy: 0.7906\n",
      "Epoch 22/100\n",
      "4507/4507 [==============================] - 1s 172us/sample - loss: 0.5011 - accuracy: 0.7819 - val_loss: 0.4879 - val_accuracy: 0.7862\n",
      "Epoch 23/100\n",
      "4507/4507 [==============================] - 1s 169us/sample - loss: 0.4736 - accuracy: 0.7963 - val_loss: 0.4699 - val_accuracy: 0.7879\n",
      "Epoch 24/100\n",
      "4507/4507 [==============================] - 1s 169us/sample - loss: 0.4671 - accuracy: 0.7945 - val_loss: 0.4512 - val_accuracy: 0.7915\n",
      "Epoch 25/100\n",
      "4507/4507 [==============================] - 1s 170us/sample - loss: 0.4811 - accuracy: 0.7905 - val_loss: 0.4648 - val_accuracy: 0.7844\n",
      "Epoch 26/100\n",
      "4507/4507 [==============================] - 1s 169us/sample - loss: 0.4623 - accuracy: 0.7948 - val_loss: 0.4650 - val_accuracy: 0.7862\n",
      "1409/1409 [==============================] - 0s 90us/sample - loss: 0.4752 - accuracy: 0.7828\n",
      "Train on 4508 samples, validate on 1127 samples\n",
      "Epoch 1/100\n",
      "4508/4508 [==============================] - 1s 271us/sample - loss: 26.5466 - accuracy: 0.6331 - val_loss: 0.9507 - val_accuracy: 0.7223\n",
      "Epoch 2/100\n",
      "4508/4508 [==============================] - 1s 184us/sample - loss: 0.7565 - accuracy: 0.7400 - val_loss: 0.5934 - val_accuracy: 0.7791\n",
      "Epoch 3/100\n",
      "4508/4508 [==============================] - 1s 172us/sample - loss: 0.6583 - accuracy: 0.7522 - val_loss: 0.5305 - val_accuracy: 0.7835\n",
      "Epoch 4/100\n",
      "4508/4508 [==============================] - 1s 170us/sample - loss: 0.6855 - accuracy: 0.7609 - val_loss: 0.5623 - val_accuracy: 0.7897\n",
      "Epoch 5/100\n",
      "4508/4508 [==============================] - 1s 169us/sample - loss: 0.7094 - accuracy: 0.7624 - val_loss: 0.5458 - val_accuracy: 0.7959\n",
      "Epoch 6/100\n",
      "4508/4508 [==============================] - 1s 169us/sample - loss: 0.6572 - accuracy: 0.7575 - val_loss: 1.1940 - val_accuracy: 0.7897\n",
      "Epoch 7/100\n",
      "4508/4508 [==============================] - 1s 169us/sample - loss: 0.6880 - accuracy: 0.7638 - val_loss: 0.5599 - val_accuracy: 0.7941\n",
      "Epoch 8/100\n",
      "4508/4508 [==============================] - 1s 169us/sample - loss: 0.6336 - accuracy: 0.7684 - val_loss: 1.0399 - val_accuracy: 0.6158\n",
      "Epoch 9/100\n",
      "4508/4508 [==============================] - 1s 169us/sample - loss: 0.6312 - accuracy: 0.7671 - val_loss: 0.7913 - val_accuracy: 0.7968\n",
      "Epoch 10/100\n",
      "4508/4508 [==============================] - 1s 171us/sample - loss: 0.7105 - accuracy: 0.7671 - val_loss: 1.1582 - val_accuracy: 0.6025\n",
      "Epoch 11/100\n",
      "4508/4508 [==============================] - 1s 178us/sample - loss: 0.6256 - accuracy: 0.7724 - val_loss: 0.5400 - val_accuracy: 0.7924\n",
      "Epoch 12/100\n",
      "4508/4508 [==============================] - 1s 170us/sample - loss: 0.6438 - accuracy: 0.7613 - val_loss: 1.3926 - val_accuracy: 0.7959\n",
      "Epoch 13/100\n",
      "4508/4508 [==============================] - 1s 169us/sample - loss: 0.6485 - accuracy: 0.7677 - val_loss: 0.4930 - val_accuracy: 0.8066\n",
      "Epoch 14/100\n",
      "4508/4508 [==============================] - 1s 170us/sample - loss: 0.6242 - accuracy: 0.7731 - val_loss: 0.4500 - val_accuracy: 0.7888\n",
      "Epoch 15/100\n",
      "4508/4508 [==============================] - 1s 169us/sample - loss: 0.5687 - accuracy: 0.7726 - val_loss: 0.5031 - val_accuracy: 0.8092\n",
      "Epoch 16/100\n",
      "4508/4508 [==============================] - 1s 169us/sample - loss: 0.6754 - accuracy: 0.7735 - val_loss: 0.7072 - val_accuracy: 0.8012\n",
      "Epoch 17/100\n",
      "4508/4508 [==============================] - 1s 169us/sample - loss: 0.6248 - accuracy: 0.7655 - val_loss: 0.4754 - val_accuracy: 0.7631\n",
      "Epoch 18/100\n",
      "4508/4508 [==============================] - 1s 170us/sample - loss: 0.7025 - accuracy: 0.7666 - val_loss: 0.5836 - val_accuracy: 0.7986\n",
      "Epoch 19/100\n",
      "4508/4508 [==============================] - 1s 169us/sample - loss: 0.6362 - accuracy: 0.7711 - val_loss: 0.6877 - val_accuracy: 0.7959\n",
      "Epoch 20/100\n",
      "4508/4508 [==============================] - 1s 170us/sample - loss: 0.5932 - accuracy: 0.7704 - val_loss: 0.5191 - val_accuracy: 0.8021\n",
      "Epoch 21/100\n",
      "4508/4508 [==============================] - 1s 169us/sample - loss: 0.6916 - accuracy: 0.7733 - val_loss: 0.5121 - val_accuracy: 0.7409\n",
      "1408/1408 [==============================] - 0s 91us/sample - loss: 0.5421 - accuracy: 0.7429\n",
      "Train on 4508 samples, validate on 1127 samples\n",
      "Epoch 1/100\n",
      "4508/4508 [==============================] - 1s 268us/sample - loss: 5.5366 - accuracy: 0.6375 - val_loss: 1.3917 - val_accuracy: 0.7507\n",
      "Epoch 2/100\n",
      "4508/4508 [==============================] - 1s 170us/sample - loss: 0.7244 - accuracy: 0.7555 - val_loss: 0.7665 - val_accuracy: 0.7862\n",
      "Epoch 3/100\n",
      "4508/4508 [==============================] - 1s 170us/sample - loss: 0.6068 - accuracy: 0.7693 - val_loss: 0.6579 - val_accuracy: 0.7826\n",
      "Epoch 4/100\n",
      "4508/4508 [==============================] - 1s 171us/sample - loss: 0.6550 - accuracy: 0.7606 - val_loss: 0.6848 - val_accuracy: 0.7844\n",
      "Epoch 5/100\n",
      "4508/4508 [==============================] - 1s 170us/sample - loss: 0.6637 - accuracy: 0.7606 - val_loss: 0.4953 - val_accuracy: 0.7755\n",
      "Epoch 6/100\n",
      "4508/4508 [==============================] - 1s 170us/sample - loss: 0.5952 - accuracy: 0.7669 - val_loss: 0.5810 - val_accuracy: 0.7915\n",
      "Epoch 7/100\n",
      "4508/4508 [==============================] - 1s 171us/sample - loss: 0.5278 - accuracy: 0.7755 - val_loss: 0.9121 - val_accuracy: 0.7711\n",
      "Epoch 8/100\n",
      "4508/4508 [==============================] - 1s 171us/sample - loss: 0.5507 - accuracy: 0.7764 - val_loss: 0.6592 - val_accuracy: 0.7791\n",
      "Epoch 9/100\n",
      "4508/4508 [==============================] - 1s 171us/sample - loss: 0.5375 - accuracy: 0.7751 - val_loss: 0.4662 - val_accuracy: 0.7995\n",
      "Epoch 10/100\n",
      "4508/4508 [==============================] - 1s 170us/sample - loss: 0.5221 - accuracy: 0.7815 - val_loss: 0.7027 - val_accuracy: 0.7817\n",
      "Epoch 11/100\n",
      "4508/4508 [==============================] - 1s 171us/sample - loss: 0.5304 - accuracy: 0.7766 - val_loss: 0.4966 - val_accuracy: 0.7507\n",
      "Epoch 12/100\n",
      "4508/4508 [==============================] - 1s 170us/sample - loss: 0.5239 - accuracy: 0.7748 - val_loss: 0.4706 - val_accuracy: 0.8012\n",
      "Epoch 13/100\n",
      "4508/4508 [==============================] - 1s 170us/sample - loss: 0.5701 - accuracy: 0.7751 - val_loss: 1.1577 - val_accuracy: 0.7862\n",
      "Epoch 14/100\n",
      "4508/4508 [==============================] - 1s 170us/sample - loss: 0.5298 - accuracy: 0.7786 - val_loss: 0.5515 - val_accuracy: 0.7897\n",
      "Epoch 15/100\n",
      "4508/4508 [==============================] - 1s 171us/sample - loss: 0.5806 - accuracy: 0.7762 - val_loss: 0.6404 - val_accuracy: 0.7950\n",
      "1408/1408 [==============================] - 0s 90us/sample - loss: 0.6758 - accuracy: 0.7969\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/100\n",
      "4507/4507 [==============================] - 1s 263us/sample - loss: 21.6696 - accuracy: 0.7393 - val_loss: 0.6527 - val_accuracy: 0.7090\n",
      "Epoch 2/100\n",
      "4507/4507 [==============================] - 1s 171us/sample - loss: 0.6121 - accuracy: 0.6852 - val_loss: 0.6595 - val_accuracy: 0.7480\n",
      "Epoch 3/100\n",
      "4507/4507 [==============================] - 1s 172us/sample - loss: 0.5886 - accuracy: 0.7386 - val_loss: 0.6053 - val_accuracy: 0.7649\n",
      "Epoch 4/100\n",
      "4507/4507 [==============================] - 1s 171us/sample - loss: 0.5920 - accuracy: 0.7528 - val_loss: 0.5876 - val_accuracy: 0.7657\n",
      "Epoch 5/100\n",
      "4507/4507 [==============================] - 1s 170us/sample - loss: 0.5778 - accuracy: 0.7559 - val_loss: 0.5981 - val_accuracy: 0.7649\n",
      "Epoch 6/100\n",
      "4507/4507 [==============================] - 1s 171us/sample - loss: 0.5720 - accuracy: 0.7570 - val_loss: 0.6554 - val_accuracy: 0.7604\n",
      "Epoch 7/100\n",
      "4507/4507 [==============================] - 1s 170us/sample - loss: 0.5660 - accuracy: 0.7579 - val_loss: 0.5718 - val_accuracy: 0.7622\n",
      "Epoch 8/100\n",
      "4507/4507 [==============================] - 1s 171us/sample - loss: 0.5671 - accuracy: 0.7586 - val_loss: 0.6670 - val_accuracy: 0.7657\n",
      "Epoch 9/100\n",
      "4507/4507 [==============================] - 1s 170us/sample - loss: 0.5611 - accuracy: 0.7568 - val_loss: 0.5645 - val_accuracy: 0.7640\n",
      "Epoch 10/100\n",
      "4507/4507 [==============================] - 1s 170us/sample - loss: 0.5613 - accuracy: 0.7595 - val_loss: 0.5808 - val_accuracy: 0.7604\n",
      "Epoch 11/100\n",
      "4507/4507 [==============================] - 1s 170us/sample - loss: 0.5566 - accuracy: 0.7599 - val_loss: 0.5573 - val_accuracy: 0.7640\n",
      "Epoch 12/100\n",
      "4507/4507 [==============================] - 1s 170us/sample - loss: 0.5551 - accuracy: 0.7597 - val_loss: 0.6280 - val_accuracy: 0.7267\n",
      "Epoch 13/100\n",
      "4507/4507 [==============================] - 1s 171us/sample - loss: 0.5642 - accuracy: 0.7588 - val_loss: 0.5620 - val_accuracy: 0.7649\n",
      "Epoch 14/100\n",
      "4507/4507 [==============================] - 1s 171us/sample - loss: 0.5519 - accuracy: 0.7590 - val_loss: 0.5653 - val_accuracy: 0.7657\n",
      "Epoch 15/100\n",
      "4507/4507 [==============================] - 1s 170us/sample - loss: 0.5550 - accuracy: 0.7588 - val_loss: 0.5557 - val_accuracy: 0.7631\n",
      "Epoch 16/100\n",
      "4507/4507 [==============================] - 1s 170us/sample - loss: 0.5435 - accuracy: 0.7637 - val_loss: 0.5503 - val_accuracy: 0.7657\n",
      "Epoch 17/100\n",
      "4507/4507 [==============================] - 1s 170us/sample - loss: 0.5390 - accuracy: 0.7650 - val_loss: 0.5554 - val_accuracy: 0.7657\n",
      "Epoch 18/100\n",
      "4507/4507 [==============================] - 1s 170us/sample - loss: 0.5346 - accuracy: 0.7621 - val_loss: 0.5458 - val_accuracy: 0.7675\n",
      "Epoch 19/100\n",
      "4507/4507 [==============================] - 1s 170us/sample - loss: 0.5302 - accuracy: 0.7633 - val_loss: 0.5594 - val_accuracy: 0.7604\n",
      "Epoch 20/100\n",
      "4507/4507 [==============================] - 1s 171us/sample - loss: 0.5214 - accuracy: 0.7626 - val_loss: 0.5335 - val_accuracy: 0.7657\n",
      "Epoch 21/100\n",
      "4507/4507 [==============================] - 1s 170us/sample - loss: 0.5106 - accuracy: 0.7657 - val_loss: 0.5266 - val_accuracy: 0.7666\n",
      "Epoch 22/100\n",
      "4507/4507 [==============================] - 1s 170us/sample - loss: 0.5012 - accuracy: 0.7635 - val_loss: 0.5178 - val_accuracy: 0.7657\n",
      "1409/1409 [==============================] - 0s 90us/sample - loss: 0.5358 - accuracy: 0.7551\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/100\n",
      "4507/4507 [==============================] - 1s 289us/sample - loss: 86.0368 - accuracy: 0.6607 - val_loss: 8.8875 - val_accuracy: 0.5546\n",
      "Epoch 2/100\n",
      "4507/4507 [==============================] - 1s 183us/sample - loss: 4.0520 - accuracy: 0.5744 - val_loss: 1.6008 - val_accuracy: 0.7356\n",
      "Epoch 3/100\n",
      "4507/4507 [==============================] - 1s 178us/sample - loss: 0.9457 - accuracy: 0.7193 - val_loss: 0.5418 - val_accuracy: 0.7489\n",
      "Epoch 4/100\n",
      "4507/4507 [==============================] - 1s 173us/sample - loss: 0.7248 - accuracy: 0.7542 - val_loss: 0.6301 - val_accuracy: 0.7853\n",
      "Epoch 5/100\n",
      "4507/4507 [==============================] - 1s 171us/sample - loss: 0.7375 - accuracy: 0.7606 - val_loss: 0.5309 - val_accuracy: 0.7870\n",
      "Epoch 6/100\n",
      "4507/4507 [==============================] - 1s 171us/sample - loss: 0.7108 - accuracy: 0.7626 - val_loss: 0.7055 - val_accuracy: 0.6531\n",
      "Epoch 7/100\n",
      "4507/4507 [==============================] - 1s 172us/sample - loss: 0.6983 - accuracy: 0.7648 - val_loss: 0.7829 - val_accuracy: 0.7941\n",
      "Epoch 8/100\n",
      "4507/4507 [==============================] - 1s 172us/sample - loss: 0.7150 - accuracy: 0.7608 - val_loss: 0.5197 - val_accuracy: 0.7950\n",
      "Epoch 9/100\n",
      "4507/4507 [==============================] - 1s 172us/sample - loss: 0.6259 - accuracy: 0.7659 - val_loss: 0.4734 - val_accuracy: 0.7888\n",
      "Epoch 10/100\n",
      "4507/4507 [==============================] - 1s 172us/sample - loss: 0.6487 - accuracy: 0.7686 - val_loss: 1.0882 - val_accuracy: 0.7968\n",
      "Epoch 11/100\n",
      "4507/4507 [==============================] - 1s 181us/sample - loss: 0.6460 - accuracy: 0.7708 - val_loss: 0.6273 - val_accuracy: 0.8021\n",
      "Epoch 12/100\n",
      "4507/4507 [==============================] - 1s 178us/sample - loss: 0.7062 - accuracy: 0.7712 - val_loss: 0.5425 - val_accuracy: 0.8030\n",
      "Epoch 13/100\n",
      "4507/4507 [==============================] - 1s 172us/sample - loss: 0.7181 - accuracy: 0.7661 - val_loss: 1.2559 - val_accuracy: 0.7941\n",
      "Epoch 14/100\n",
      "4507/4507 [==============================] - 1s 172us/sample - loss: 0.6562 - accuracy: 0.7719 - val_loss: 0.4500 - val_accuracy: 0.7897\n",
      "Epoch 15/100\n",
      "4507/4507 [==============================] - 1s 174us/sample - loss: 0.6748 - accuracy: 0.7721 - val_loss: 2.7975 - val_accuracy: 0.4658\n",
      "Epoch 16/100\n",
      "4507/4507 [==============================] - 1s 188us/sample - loss: 0.8843 - accuracy: 0.7668 - val_loss: 0.6497 - val_accuracy: 0.7959\n",
      "Epoch 17/100\n",
      "4507/4507 [==============================] - 1s 182us/sample - loss: 0.6832 - accuracy: 0.7701 - val_loss: 0.6789 - val_accuracy: 0.7977\n",
      "Epoch 18/100\n",
      "4507/4507 [==============================] - 1s 188us/sample - loss: 0.6777 - accuracy: 0.7677 - val_loss: 0.6197 - val_accuracy: 0.7995\n",
      "Epoch 19/100\n",
      "4507/4507 [==============================] - 1s 190us/sample - loss: 0.5556 - accuracy: 0.7823 - val_loss: 0.4561 - val_accuracy: 0.7933\n",
      "Epoch 20/100\n",
      "4507/4507 [==============================] - 1s 224us/sample - loss: 0.6764 - accuracy: 0.7712 - val_loss: 0.4590 - val_accuracy: 0.7835\n",
      "Epoch 21/100\n",
      "4507/4507 [==============================] - 1s 211us/sample - loss: 0.7060 - accuracy: 0.7724 - val_loss: 1.2240 - val_accuracy: 0.7924\n",
      "Epoch 22/100\n",
      "4507/4507 [==============================] - 1s 210us/sample - loss: 0.6512 - accuracy: 0.7708 - val_loss: 0.5233 - val_accuracy: 0.7879\n",
      "Epoch 23/100\n",
      "4507/4507 [==============================] - 1s 182us/sample - loss: 0.8099 - accuracy: 0.7641 - val_loss: 0.7080 - val_accuracy: 0.7968\n",
      "Epoch 24/100\n",
      "4507/4507 [==============================] - 1s 177us/sample - loss: 0.7882 - accuracy: 0.7633 - val_loss: 0.8600 - val_accuracy: 0.6291\n",
      "1409/1409 [==============================] - 0s 90us/sample - loss: 0.8291 - accuracy: 0.6586\n",
      "Train on 4507 samples, validate on 1127 samples\n",
      "Epoch 1/100\n",
      "4507/4507 [==============================] - 1s 284us/sample - loss: 7.4029 - accuracy: 0.7231 - val_loss: 0.5519 - val_accuracy: 0.7782\n",
      "Epoch 2/100\n",
      "4507/4507 [==============================] - 1s 171us/sample - loss: 0.6619 - accuracy: 0.7661 - val_loss: 0.7897 - val_accuracy: 0.7950\n",
      "Epoch 3/100\n",
      "4507/4507 [==============================] - 1s 173us/sample - loss: 0.6171 - accuracy: 0.7735 - val_loss: 0.4577 - val_accuracy: 0.8039\n",
      "Epoch 4/100\n",
      "4507/4507 [==============================] - 1s 184us/sample - loss: 0.5418 - accuracy: 0.7721 - val_loss: 0.7497 - val_accuracy: 0.7959\n",
      "Epoch 5/100\n",
      "4507/4507 [==============================] - 1s 214us/sample - loss: 0.6237 - accuracy: 0.7710 - val_loss: 0.4315 - val_accuracy: 0.8066\n",
      "Epoch 6/100\n",
      "4507/4507 [==============================] - 1s 201us/sample - loss: 0.5338 - accuracy: 0.7890 - val_loss: 0.4482 - val_accuracy: 0.8083\n",
      "Epoch 7/100\n",
      "4507/4507 [==============================] - 1s 173us/sample - loss: 0.5519 - accuracy: 0.7808 - val_loss: 0.8504 - val_accuracy: 0.7977\n",
      "Epoch 8/100\n",
      "4507/4507 [==============================] - 1s 175us/sample - loss: 0.5512 - accuracy: 0.7828 - val_loss: 0.7789 - val_accuracy: 0.8004\n",
      "Epoch 9/100\n",
      "4507/4507 [==============================] - 1s 175us/sample - loss: 0.5453 - accuracy: 0.7834 - val_loss: 0.5073 - val_accuracy: 0.8021\n",
      "Epoch 10/100\n",
      "4507/4507 [==============================] - 1s 171us/sample - loss: 0.5600 - accuracy: 0.7850 - val_loss: 0.7124 - val_accuracy: 0.7995\n",
      "Epoch 11/100\n",
      "4507/4507 [==============================] - 1s 175us/sample - loss: 0.5818 - accuracy: 0.7799 - val_loss: 0.5890 - val_accuracy: 0.8030\n",
      "1409/1409 [==============================] - 0s 93us/sample - loss: 0.5380 - accuracy: 0.7850\n",
      "Train on 4508 samples, validate on 1127 samples\n",
      "Epoch 1/100\n",
      "4508/4508 [==============================] - 1s 286us/sample - loss: 0.6618 - accuracy: 0.7362 - val_loss: 0.6325 - val_accuracy: 0.7276\n",
      "Epoch 2/100\n",
      "4508/4508 [==============================] - 1s 185us/sample - loss: 0.6103 - accuracy: 0.7371 - val_loss: 0.6006 - val_accuracy: 0.7294\n",
      "Epoch 3/100\n",
      "4508/4508 [==============================] - 1s 178us/sample - loss: 0.5884 - accuracy: 0.7376 - val_loss: 0.5888 - val_accuracy: 0.7294\n",
      "Epoch 4/100\n",
      "4508/4508 [==============================] - 1s 182us/sample - loss: 0.5798 - accuracy: 0.7378 - val_loss: 0.5847 - val_accuracy: 0.7294\n",
      "Epoch 5/100\n",
      "4508/4508 [==============================] - 1s 170us/sample - loss: 0.5766 - accuracy: 0.7378 - val_loss: 0.5836 - val_accuracy: 0.7294\n",
      "Epoch 6/100\n",
      "4508/4508 [==============================] - 1s 177us/sample - loss: 0.5755 - accuracy: 0.7378 - val_loss: 0.5834 - val_accuracy: 0.7294\n",
      "Epoch 7/100\n",
      "4508/4508 [==============================] - 1s 169us/sample - loss: 0.5752 - accuracy: 0.7378 - val_loss: 0.5834 - val_accuracy: 0.7294\n",
      "Epoch 8/100\n",
      "4508/4508 [==============================] - 1s 176us/sample - loss: 0.5750 - accuracy: 0.7378 - val_loss: 0.5834 - val_accuracy: 0.7294\n",
      "1408/1408 [==============================] - 0s 87us/sample - loss: 0.5843 - accuracy: 0.7287\n",
      "Train on 4508 samples, validate on 1127 samples\n",
      "Epoch 1/100\n",
      "4508/4508 [==============================] - 1s 288us/sample - loss: 4.0393 - accuracy: 0.6801 - val_loss: 1.5943 - val_accuracy: 0.7294\n",
      "Epoch 2/100\n",
      "4508/4508 [==============================] - 1s 178us/sample - loss: 1.3242 - accuracy: 0.7380 - val_loss: 0.8763 - val_accuracy: 0.6690\n",
      "Epoch 3/100\n",
      "4508/4508 [==============================] - 1s 180us/sample - loss: 1.0096 - accuracy: 0.7531 - val_loss: 0.6241 - val_accuracy: 0.7560\n",
      "Epoch 4/100\n",
      "4508/4508 [==============================] - 1s 178us/sample - loss: 0.8316 - accuracy: 0.7571 - val_loss: 0.5586 - val_accuracy: 0.7746\n",
      "Epoch 5/100\n",
      "4508/4508 [==============================] - 1s 179us/sample - loss: 0.9788 - accuracy: 0.7533 - val_loss: 0.6390 - val_accuracy: 0.6948\n",
      "Epoch 6/100\n",
      "4508/4508 [==============================] - 1s 183us/sample - loss: 0.8027 - accuracy: 0.7662 - val_loss: 0.6314 - val_accuracy: 0.7862\n",
      "Epoch 7/100\n",
      "4508/4508 [==============================] - 1s 177us/sample - loss: 0.8926 - accuracy: 0.7642 - val_loss: 0.5404 - val_accuracy: 0.7853\n",
      "Epoch 8/100\n",
      "4508/4508 [==============================] - 1s 172us/sample - loss: 0.8624 - accuracy: 0.7587 - val_loss: 0.7916 - val_accuracy: 0.7853\n",
      "Epoch 9/100\n",
      "4508/4508 [==============================] - 1s 175us/sample - loss: 0.7024 - accuracy: 0.7677 - val_loss: 0.5258 - val_accuracy: 0.7897\n",
      "Epoch 10/100\n",
      "4508/4508 [==============================] - 1s 177us/sample - loss: 0.6631 - accuracy: 0.7713 - val_loss: 1.6667 - val_accuracy: 0.7578\n",
      "Epoch 11/100\n",
      "4508/4508 [==============================] - 1s 175us/sample - loss: 1.0114 - accuracy: 0.7635 - val_loss: 0.9089 - val_accuracy: 0.7773\n",
      "Epoch 12/100\n",
      "4508/4508 [==============================] - 1s 174us/sample - loss: 0.5963 - accuracy: 0.7686 - val_loss: 0.4765 - val_accuracy: 0.7817\n",
      "Epoch 13/100\n",
      "4508/4508 [==============================] - 1s 176us/sample - loss: 0.8403 - accuracy: 0.7691 - val_loss: 1.1604 - val_accuracy: 0.6211\n",
      "Epoch 14/100\n",
      "4508/4508 [==============================] - 1s 179us/sample - loss: 0.7555 - accuracy: 0.7689 - val_loss: 0.8693 - val_accuracy: 0.6557\n",
      "Epoch 15/100\n",
      "4508/4508 [==============================] - 1s 178us/sample - loss: 0.7479 - accuracy: 0.7657 - val_loss: 0.6576 - val_accuracy: 0.8039\n",
      "1408/1408 [==============================] - 0s 91us/sample - loss: 0.6930 - accuracy: 0.7947\n",
      "Train on 5634 samples, validate on 1409 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:  2.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5634/5634 [==============================] - 2s 270us/sample - loss: 30.2095 - accuracy: 0.7265 - val_loss: 0.7516 - val_accuracy: 0.4010\n",
      "Epoch 2/100\n",
      "5634/5634 [==============================] - 1s 174us/sample - loss: 0.6998 - accuracy: 0.4796 - val_loss: 0.6572 - val_accuracy: 0.7296\n",
      "Epoch 3/100\n",
      "5634/5634 [==============================] - 1s 169us/sample - loss: 0.6260 - accuracy: 0.7359 - val_loss: 0.6074 - val_accuracy: 0.7296\n",
      "Epoch 4/100\n",
      "5634/5634 [==============================] - 1s 169us/sample - loss: 0.5935 - accuracy: 0.7359 - val_loss: 0.5905 - val_accuracy: 0.7296\n",
      "Epoch 5/100\n",
      "5634/5634 [==============================] - 1s 169us/sample - loss: 0.5823 - accuracy: 0.7359 - val_loss: 0.5852 - val_accuracy: 0.7296\n",
      "Epoch 6/100\n",
      "5634/5634 [==============================] - 1s 171us/sample - loss: 0.5787 - accuracy: 0.7359 - val_loss: 0.5839 - val_accuracy: 0.7296\n",
      "Epoch 7/100\n",
      "5634/5634 [==============================] - 1s 170us/sample - loss: 0.5777 - accuracy: 0.7359 - val_loss: 0.5837 - val_accuracy: 0.7296\n",
      "Epoch 8/100\n",
      "5634/5634 [==============================] - 1s 178us/sample - loss: 0.5774 - accuracy: 0.7359 - val_loss: 0.5837 - val_accuracy: 0.7296\n",
      "\n",
      "Best score: 0.7873003840446472\n",
      "Best params: {'activation_per_layer': 'relu', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 100, 'learning_rate': 0.001, 'network_weights_init': 'glorot_normal', 'nodes_per_layer': 4}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# tune dropout\n",
    "\n",
    "params = {\n",
    "    'nodes_per_layer': [4],\n",
    "    'batch_size': [10],\n",
    "    'epochs': [100],\n",
    "    'learning_rate': [0.001],\n",
    "    'network_weights_init': ['glorot_normal'],\n",
    "    'activation_per_layer': ['relu'],\n",
    "    'dropout_rate': [0.1, 0.2, 0.3]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=KerasClassifier(build_fn=create_model),\n",
    "    param_grid=params,\n",
    "    n_jobs=1,\n",
    "    cv=5,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid.fit(X, y, callbacks=[stop], validation_split=0.2)\n",
    "\n",
    "print()\n",
    "print('Best score:', grid.best_score_)\n",
    "print('Best params:', grid.best_params_)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FfZRtJ7MCN3x"
   },
   "source": [
    "## Stretch Goals:\n",
    "\n",
    "- Try to implement Random Search Hyperparameter Tuning on this dataset\n",
    "- Try to implement Bayesian Optimiation tuning on this dataset using hyperas or hyperopt (if you're brave)\n",
    "- Practice hyperparameter tuning other datasets that we have looked at. How high can you get MNIST? Above 99%?\n",
    "- Study for the Sprint Challenge\n",
    " - Can you implement both perceptron and MLP models from scratch with forward and backpropagation?\n",
    " - Can you implement both perceptron and MLP models in keras and tune their hyperparameters with cross validation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "LS_DS_434_Hyperparameter_Tuning_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "U4-S2-NN (Python3)",
   "language": "python",
   "name": "u4-s2-nn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
