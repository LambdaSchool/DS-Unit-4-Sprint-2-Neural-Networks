{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LS_DS_434_Hyperparameter_Tuning_Assignment.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShreyasJothish/DS-Unit-4-Sprint-3-Neural-Networks/blob/master/module4-Hyperparameter-Tuning/LS_DS_434_Hyperparameter_Tuning_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "9Ryp-TVm4njD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Your Mission, should you choose to accept it...\n",
        "\n",
        "To hyperparameter tune and extract every ounce of accuracy out of this telecom customer churn dataset: <https://drive.google.com/file/d/1dfbAsM9DwA7tYhInyflIpZnYs7VT-0AQ/view> \n",
        "\n",
        "## Requirements\n",
        "\n",
        "- Load the data\n",
        "- Clean the data if necessary (it will be)\n",
        "- Create and fit a baseline Keras MLP model to the data.\n",
        "- Hyperparameter tune (at least) the following parameters:\n",
        " - batch_size\n",
        " - training epochs\n",
        " - optimizer\n",
        " - learning rate (if applicable to optimizer)\n",
        " - momentum (if applicable to optimizer)\n",
        " - activation functions\n",
        " - network weight initialization\n",
        " - dropout regularization\n",
        " - number of neurons in the hidden layer\n",
        " \n",
        " You must use Grid Search and Cross Validation for your initial pass of the above hyperparameters\n",
        " \n",
        " Try and get the maximum accuracy possible out of this data! You'll save big telecoms millions! Doesn't that sound great?\n"
      ]
    },
    {
      "metadata": {
        "id": "NNJ-tOBs4jM1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##### Your Code Here #####\n",
        "# generic imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F5eINS4LHwDF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#from google.colab import files\n",
        "#files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q5D45ClyIaKv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
        "df.head(20)\n",
        "df.shape\n",
        "\n",
        "# Customer ID is unique across so dropping it\n",
        "df.drop(columns='customerID', inplace=True)\n",
        "df['TotalCharges'] = df['TotalCharges'].apply(lambda x: 0.0 if len(x) < 2 else float(x))\n",
        "\n",
        "# Use the values to get np.arrary instead of passing the dataframe\n",
        "X = df.drop(columns='Churn').values\n",
        "y = df['Churn'].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FabmtsNpPn38",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "outputId": "03ad5409-1f9a-4ce8-a8e1-b613174e3015"
      },
      "cell_type": "code",
      "source": [
        "for column in df.columns:\n",
        "  print(column, df[column].dtype, df[column].nunique())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gender object 2\n",
            "SeniorCitizen int64 2\n",
            "Partner object 2\n",
            "Dependents object 2\n",
            "tenure int64 73\n",
            "PhoneService object 2\n",
            "MultipleLines object 3\n",
            "InternetService object 3\n",
            "OnlineSecurity object 3\n",
            "OnlineBackup object 3\n",
            "DeviceProtection object 3\n",
            "TechSupport object 3\n",
            "StreamingTV object 3\n",
            "StreamingMovies object 3\n",
            "Contract object 3\n",
            "PaperlessBilling object 2\n",
            "PaymentMethod object 4\n",
            "MonthlyCharges float64 1585\n",
            "TotalCharges float64 6531\n",
            "Churn object 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "smBmSmgGKwYZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "outputId": "5913af1b-acfa-4fe9-be97-27574b2b5eb1"
      },
      "cell_type": "code",
      "source": [
        "# Use category encoder to update object columns\n",
        "!pip install category_encoders"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: category_encoders in /usr/local/lib/python3.6/dist-packages (1.3.0)\n",
            "Requirement already satisfied: statsmodels>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.8.0)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.14.6)\n",
            "Requirement already satisfied: scikit-learn>=0.17.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.20.3)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.1.0)\n",
            "Requirement already satisfied: pandas>=0.20.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.22.0)\n",
            "Requirement already satisfied: patsy>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.5.1)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.20.1->category_encoders) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.20.1->category_encoders) (2.5.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from patsy>=0.4.1->category_encoders) (1.11.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fnh7DaAoTTGG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 652
        },
        "outputId": "a31401eb-8e6a-43c6-dfb7-773186c37d0c"
      },
      "cell_type": "code",
      "source": [
        "# Imports for pipeline\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "import category_encoders as ce\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Keras imports\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "\n",
        "# Function to create model, required for KerasClassifier\n",
        "def create_model():\n",
        "\t# create model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(12, input_dim=44, activation='relu'))\n",
        "\tmodel.add(Dense(1, activation='sigmoid'))\n",
        "\t# Compile model\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\treturn model\n",
        "\n",
        "# Create pipeline\n",
        "pipeline = make_pipeline(\\\n",
        "                         ce.BinaryEncoder(),\n",
        "                         RobustScaler(), \n",
        "                         KerasClassifier(build_fn=create_model, verbose=1))\n",
        "\n",
        "# Model validation.\n",
        "param_grid = {\n",
        "}\n",
        "\n",
        "gridsearch = GridSearchCV(pipeline, param_grid=param_grid, cv=3, \n",
        "                         scoring='accuracy', verbose=10)\n",
        "\n",
        "gridsearch.fit(X, y)\n",
        "\n",
        "# Interpret the results.\n",
        "\n",
        "# Best cross validation score\n",
        "print('Cross Validation Score:', gridsearch.best_score_)\n",
        "\n",
        "# Best parameters which resulted in the best score\n",
        "print('Best Parameters:', gridsearch.best_params_)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV]  ................................................................\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/1\n",
            "4695/4695 [==============================] - 0s 58us/step - loss: 0.5069 - acc: 0.7570\n",
            "2348/2348 [==============================] - 0s 16us/step\n",
            "4695/4695 [==============================] - 0s 9us/step\n",
            "[CV] ....................... , score=0.7904599659284497, total=   0.9s\n",
            "[CV]  ................................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.1s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "4695/4695 [==============================] - 0s 59us/step - loss: 0.5120 - acc: 0.7427\n",
            "2348/2348 [==============================] - 0s 21us/step\n",
            "4695/4695 [==============================] - 0s 10us/step\n",
            "[CV] ....................... , score=0.7781090289608177, total=   1.0s\n",
            "[CV]  ................................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    2.3s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "4696/4696 [==============================] - 0s 65us/step - loss: 0.5042 - acc: 0.7566\n",
            "2347/2347 [==============================] - 0s 27us/step\n",
            "4696/4696 [==============================] - 0s 10us/step\n",
            "[CV] ....................... , score=0.7869620792501065, total=   1.0s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    3.4s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    3.4s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "7043/7043 [==============================] - 0s 56us/step - loss: 0.4952 - acc: 0.7470\n",
            "Cross Validation Score: 0.7851767712622462\n",
            "Best Parameters: {}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vwGWiTfQWyUt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Without any hyper parameter tuning:\n",
        "\n",
        "Cross Validation Score: 0.7755217946897629"
      ]
    },
    {
      "metadata": {
        "id": "MNPfXJYoi07K",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " Hyper parameter tuning:\n",
        " - batch_size\n",
        " - training epochs\n",
        " - optimizer\n",
        " - learning rate (if applicable to optimizer)\n",
        " - momentum (if applicable to optimizer)\n",
        " - activation functions\n",
        " - network weight initialization\n",
        " - dropout regularization\n",
        " - number of neurons in the hidden layer"
      ]
    },
    {
      "metadata": {
        "id": "Xsw32W-kXEP4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 7471
        },
        "outputId": "019e5a66-d70a-4a17-800c-9920d031c107"
      },
      "cell_type": "code",
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.layers import advanced_activations\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Function to create model, required for KerasClassifier\n",
        "def create_model(activation_hidden='relu', learning_rate=0.001, rate=0.1,\n",
        "                units=12):\n",
        "                 #optimizer='adam'):\n",
        "  # create model\n",
        "  model = Sequential()\n",
        "  model.add(Dense(units, input_dim=44, activation=activation_hidden))\n",
        "  model.add(Dropout(rate))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  model.add(Dropout(rate))\n",
        "  # Compile model\n",
        "  optimizer = Adam(lr=learning_rate)\n",
        "  model.compile(loss='binary_crossentropy', optimizer=optimizer, \\\n",
        "                metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "# Create pipeline\n",
        "pipeline = make_pipeline(\\\n",
        "                         ce.BinaryEncoder(),\n",
        "                         RobustScaler(), \n",
        "                         KerasClassifier(build_fn=create_model, verbose=1))\n",
        "\n",
        "# Model validation.\n",
        "param_grid = {\n",
        "    'kerasclassifier__batch_size': [80],\n",
        "    'kerasclassifier__epochs': [50],\n",
        "    #'kerasclassifier__optimizer': ['sgd', 'rmsprop', 'adagrad', 'adadelta',\\\n",
        "    #'adam', 'adamax', 'nadam'],\n",
        "    'kerasclassifier__learning_rate': [0.001],\n",
        "    'kerasclassifier__activation_hidden': ['exponential'],\n",
        "    'kerasclassifier__rate': [0.1],\n",
        "    'kerasclassifier__units': [64]\n",
        "}\n",
        "\n",
        "gridsearch = GridSearchCV(pipeline, param_grid=param_grid, cv=3, \n",
        "                         scoring='accuracy', verbose=10)\n",
        "\n",
        "gridsearch.fit(X, y)\n",
        "\n",
        "# Interpret the results.\n",
        "\n",
        "# Best cross validation score\n",
        "print('Cross Validation Score:', gridsearch.best_score_)\n",
        "\n",
        "# Best parameters which resulted in the best score\n",
        "print('Best Parameters:', gridsearch.best_params_)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV] kerasclassifier__activation_hidden=exponential, kerasclassifier__batch_size=80, kerasclassifier__epochs=50, kerasclassifier__learning_rate=0.001, kerasclassifier__rate=0.1, kerasclassifier__units=64 \n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "4695/4695 [==============================] - 0s 71us/step - loss: 0.9200 - acc: 0.7542\n",
            "Epoch 2/50\n",
            "4695/4695 [==============================] - 0s 16us/step - loss: 0.8734 - acc: 0.7742\n",
            "Epoch 3/50\n",
            "4695/4695 [==============================] - 0s 16us/step - loss: 0.7690 - acc: 0.7770\n",
            "Epoch 4/50\n",
            "4695/4695 [==============================] - 0s 15us/step - loss: 0.8802 - acc: 0.7734\n",
            "Epoch 5/50\n",
            "4695/4695 [==============================] - 0s 17us/step - loss: 0.8265 - acc: 0.7804\n",
            "Epoch 6/50\n",
            "4695/4695 [==============================] - 0s 15us/step - loss: 0.8270 - acc: 0.7796\n",
            "Epoch 7/50\n",
            "4695/4695 [==============================] - 0s 15us/step - loss: 0.7593 - acc: 0.7853\n",
            "Epoch 8/50\n",
            "4695/4695 [==============================] - 0s 16us/step - loss: 0.8129 - acc: 0.7804\n",
            "Epoch 9/50\n",
            "4695/4695 [==============================] - 0s 16us/step - loss: 0.8811 - acc: 0.7855\n",
            "Epoch 10/50\n",
            "4695/4695 [==============================] - 0s 16us/step - loss: 0.8515 - acc: 0.7853\n",
            "Epoch 11/50\n",
            "4695/4695 [==============================] - 0s 15us/step - loss: 0.8116 - acc: 0.7874\n",
            "Epoch 12/50\n",
            "4695/4695 [==============================] - 0s 15us/step - loss: 0.7699 - acc: 0.7889\n",
            "Epoch 13/50\n",
            "4695/4695 [==============================] - 0s 14us/step - loss: 0.7701 - acc: 0.7911\n",
            "Epoch 14/50\n",
            "4695/4695 [==============================] - 0s 16us/step - loss: 0.7703 - acc: 0.7845\n",
            "Epoch 15/50\n",
            "4695/4695 [==============================] - 0s 15us/step - loss: 0.7699 - acc: 0.7885\n",
            "Epoch 16/50\n",
            "4695/4695 [==============================] - 0s 15us/step - loss: 0.7905 - acc: 0.7904\n",
            "Epoch 17/50\n",
            "4695/4695 [==============================] - 0s 15us/step - loss: 0.8357 - acc: 0.7896\n",
            "Epoch 18/50\n",
            "4695/4695 [==============================] - 0s 15us/step - loss: 0.8499 - acc: 0.7928\n",
            "Epoch 19/50\n",
            "4695/4695 [==============================] - 0s 16us/step - loss: 0.7716 - acc: 0.7906\n",
            "Epoch 20/50\n",
            "4695/4695 [==============================] - 0s 15us/step - loss: 0.8394 - acc: 0.7923\n",
            "Epoch 21/50\n",
            "4695/4695 [==============================] - 0s 15us/step - loss: 0.7989 - acc: 0.7942\n",
            "Epoch 22/50\n",
            "4695/4695 [==============================] - 0s 15us/step - loss: 0.7887 - acc: 0.7932\n",
            "Epoch 23/50\n",
            "4695/4695 [==============================] - 0s 15us/step - loss: 0.7960 - acc: 0.7900\n",
            "Epoch 24/50\n",
            "4695/4695 [==============================] - 0s 14us/step - loss: 0.8406 - acc: 0.7928\n",
            "Epoch 25/50\n",
            "4695/4695 [==============================] - 0s 14us/step - loss: 0.8357 - acc: 0.7894\n",
            "Epoch 26/50\n",
            "4695/4695 [==============================] - 0s 15us/step - loss: 0.8144 - acc: 0.7913\n",
            "Epoch 27/50\n",
            "4695/4695 [==============================] - 0s 15us/step - loss: 0.7694 - acc: 0.7966\n",
            "Epoch 28/50\n",
            "4695/4695 [==============================] - 0s 16us/step - loss: 0.7830 - acc: 0.7972\n",
            "Epoch 29/50\n",
            "4695/4695 [==============================] - 0s 16us/step - loss: 0.8206 - acc: 0.7894\n",
            "Epoch 30/50\n",
            "4695/4695 [==============================] - 0s 15us/step - loss: 0.7933 - acc: 0.7900\n",
            "Epoch 31/50\n",
            "4695/4695 [==============================] - 0s 16us/step - loss: 0.7736 - acc: 0.7896\n",
            "Epoch 32/50\n",
            "4695/4695 [==============================] - 0s 15us/step - loss: 0.8002 - acc: 0.7894\n",
            "Epoch 33/50\n",
            "4695/4695 [==============================] - 0s 15us/step - loss: 0.8597 - acc: 0.7902\n",
            "Epoch 34/50\n",
            "4695/4695 [==============================] - 0s 15us/step - loss: 0.8321 - acc: 0.7894\n",
            "Epoch 35/50\n",
            "4695/4695 [==============================] - 0s 14us/step - loss: 0.8332 - acc: 0.7945\n",
            "Epoch 36/50\n",
            "4695/4695 [==============================] - 0s 15us/step - loss: 0.7970 - acc: 0.7955\n",
            "Epoch 37/50\n",
            "4695/4695 [==============================] - 0s 15us/step - loss: 0.8457 - acc: 0.7889\n",
            "Epoch 38/50\n",
            "4695/4695 [==============================] - 0s 15us/step - loss: 0.8278 - acc: 0.7934\n",
            "Epoch 39/50\n",
            "4695/4695 [==============================] - 0s 15us/step - loss: 0.7812 - acc: 0.7953\n",
            "Epoch 40/50\n",
            "4695/4695 [==============================] - 0s 15us/step - loss: 0.7596 - acc: 0.7949\n",
            "Epoch 41/50\n",
            "4695/4695 [==============================] - 0s 15us/step - loss: 0.8143 - acc: 0.7966\n",
            "Epoch 42/50\n",
            "4695/4695 [==============================] - 0s 15us/step - loss: 0.7409 - acc: 0.7979\n",
            "Epoch 43/50\n",
            "4695/4695 [==============================] - 0s 15us/step - loss: 0.8556 - acc: 0.7894\n",
            "Epoch 44/50\n",
            "4695/4695 [==============================] - 0s 15us/step - loss: 0.8166 - acc: 0.7925\n",
            "Epoch 45/50\n",
            "4695/4695 [==============================] - 0s 15us/step - loss: 0.8255 - acc: 0.7983\n",
            "Epoch 46/50\n",
            "4695/4695 [==============================] - 0s 15us/step - loss: 0.8036 - acc: 0.7974\n",
            "Epoch 47/50\n",
            "4695/4695 [==============================] - 0s 15us/step - loss: 0.8575 - acc: 0.7947\n",
            "Epoch 48/50\n",
            "4695/4695 [==============================] - 0s 15us/step - loss: 0.8041 - acc: 0.7951\n",
            "Epoch 49/50\n",
            "4695/4695 [==============================] - 0s 15us/step - loss: 0.7937 - acc: 0.7919\n",
            "Epoch 50/50\n",
            "4695/4695 [==============================] - 0s 15us/step - loss: 0.7847 - acc: 0.7970\n",
            "2348/2348 [==============================] - 0s 37us/step\n",
            "4695/4695 [==============================] - 0s 6us/step\n",
            "[CV]  kerasclassifier__activation_hidden=exponential, kerasclassifier__batch_size=80, kerasclassifier__epochs=50, kerasclassifier__learning_rate=0.001, kerasclassifier__rate=0.1, kerasclassifier__units=64, score=0.7977001703577513, total=   4.7s\n",
            "[CV] kerasclassifier__activation_hidden=exponential, kerasclassifier__batch_size=80, kerasclassifier__epochs=50, kerasclassifier__learning_rate=0.001, kerasclassifier__rate=0.1, kerasclassifier__units=64 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.8s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "4695/4695 [==============================] - 0s 79us/step - loss: 1.2014 - acc: 0.6106\n",
            "Epoch 2/50\n",
            "4695/4695 [==============================] - 0s 15us/step - loss: 0.9895 - acc: 0.7308\n",
            "Epoch 3/50\n",
            "4695/4695 [==============================] - 0s 15us/step - loss: 0.8654 - acc: 0.7485\n",
            "Epoch 4/50\n",
            "4695/4695 [==============================] - 0s 15us/step - loss: 0.8421 - acc: 0.7636\n",
            "Epoch 5/50\n",
            "4695/4695 [==============================] - 0s 15us/step - loss: 0.8386 - acc: 0.7693\n",
            "Epoch 6/50\n",
            "4695/4695 [==============================] - 0s 15us/step - loss: 0.8912 - acc: 0.7704\n",
            "Epoch 7/50\n",
            "4695/4695 [==============================] - 0s 15us/step - loss: 0.8470 - acc: 0.7706\n",
            "Epoch 8/50\n",
            "4695/4695 [==============================] - 0s 15us/step - loss: 0.8453 - acc: 0.7749\n",
            "Epoch 9/50\n",
            "4695/4695 [==============================] - 0s 16us/step - loss: 0.8257 - acc: 0.7768\n",
            "Epoch 10/50\n",
            "4695/4695 [==============================] - 0s 15us/step - loss: 0.7799 - acc: 0.7836\n",
            "Epoch 11/50\n",
            "4695/4695 [==============================] - 0s 15us/step - loss: 0.8542 - acc: 0.7879\n",
            "Epoch 12/50\n",
            "4695/4695 [==============================] - 0s 15us/step - loss: 0.8617 - acc: 0.7806\n",
            "Epoch 13/50\n",
            "4695/4695 [==============================] - 0s 15us/step - loss: 0.8813 - acc: 0.7774\n",
            "Epoch 14/50\n",
            "4695/4695 [==============================] - 0s 15us/step - loss: 0.8356 - acc: 0.7845\n",
            "Epoch 15/50\n",
            "4695/4695 [==============================] - 0s 15us/step - loss: 0.8469 - acc: 0.7819\n",
            "Epoch 16/50\n",
            "4695/4695 [==============================] - 0s 15us/step - loss: 0.8983 - acc: 0.7736\n",
            "Epoch 17/50\n",
            "4695/4695 [==============================] - 0s 16us/step - loss: 0.8258 - acc: 0.7857\n",
            "Epoch 18/50\n",
            "4695/4695 [==============================] - 0s 15us/step - loss: 0.8944 - acc: 0.7789\n",
            "Epoch 19/50\n",
            "4695/4695 [==============================] - 0s 16us/step - loss: 0.8370 - acc: 0.7838\n",
            "Epoch 20/50\n",
            "4695/4695 [==============================] - 0s 16us/step - loss: 0.8092 - acc: 0.7808\n",
            "Epoch 21/50\n",
            "4695/4695 [==============================] - 0s 15us/step - loss: 0.8737 - acc: 0.7823\n",
            "Epoch 22/50\n",
            "4695/4695 [==============================] - 0s 15us/step - loss: 0.8641 - acc: 0.7866\n",
            "Epoch 23/50\n",
            "4695/4695 [==============================] - 0s 15us/step - loss: 0.8567 - acc: 0.7789\n",
            "Epoch 24/50\n",
            "4695/4695 [==============================] - 0s 16us/step - loss: 0.8138 - acc: 0.7830\n",
            "Epoch 25/50\n",
            "4695/4695 [==============================] - 0s 15us/step - loss: 0.7984 - acc: 0.7872\n",
            "Epoch 26/50\n",
            "4695/4695 [==============================] - 0s 15us/step - loss: 0.8431 - acc: 0.7896\n",
            "Epoch 27/50\n",
            "4695/4695 [==============================] - 0s 15us/step - loss: 0.7721 - acc: 0.7902\n",
            "Epoch 28/50\n",
            "4695/4695 [==============================] - 0s 15us/step - loss: 0.8209 - acc: 0.7902\n",
            "Epoch 29/50\n",
            "4695/4695 [==============================] - 0s 15us/step - loss: 0.8091 - acc: 0.7891\n",
            "Epoch 30/50\n",
            "4695/4695 [==============================] - 0s 15us/step - loss: 0.7981 - acc: 0.7840\n",
            "Epoch 31/50\n",
            "4695/4695 [==============================] - 0s 16us/step - loss: 0.9109 - acc: 0.7923\n",
            "Epoch 32/50\n",
            "4695/4695 [==============================] - 0s 15us/step - loss: 0.7913 - acc: 0.7930\n",
            "Epoch 33/50\n",
            "4695/4695 [==============================] - 0s 15us/step - loss: 0.8007 - acc: 0.7804\n",
            "Epoch 34/50\n",
            "4695/4695 [==============================] - 0s 14us/step - loss: 0.7468 - acc: 0.7891\n",
            "Epoch 35/50\n",
            "4695/4695 [==============================] - 0s 14us/step - loss: 0.7433 - acc: 0.7945\n",
            "Epoch 36/50\n",
            "4695/4695 [==============================] - 0s 15us/step - loss: 0.8179 - acc: 0.7855\n",
            "Epoch 37/50\n",
            "4695/4695 [==============================] - 0s 15us/step - loss: 0.8549 - acc: 0.7855\n",
            "Epoch 38/50\n",
            "4695/4695 [==============================] - 0s 15us/step - loss: 0.7443 - acc: 0.7923\n",
            "Epoch 39/50\n",
            "4695/4695 [==============================] - 0s 15us/step - loss: 0.7843 - acc: 0.7925\n",
            "Epoch 40/50\n",
            "4695/4695 [==============================] - 0s 14us/step - loss: 0.8022 - acc: 0.7902\n",
            "Epoch 41/50\n",
            "4695/4695 [==============================] - 0s 15us/step - loss: 0.7787 - acc: 0.7866\n",
            "Epoch 42/50\n",
            "4695/4695 [==============================] - 0s 14us/step - loss: 0.7738 - acc: 0.7904\n",
            "Epoch 43/50\n",
            "4695/4695 [==============================] - 0s 14us/step - loss: 0.8147 - acc: 0.7913\n",
            "Epoch 44/50\n",
            "4695/4695 [==============================] - 0s 15us/step - loss: 0.7986 - acc: 0.7908\n",
            "Epoch 45/50\n",
            "4695/4695 [==============================] - 0s 15us/step - loss: 0.7627 - acc: 0.7940\n",
            "Epoch 46/50\n",
            "4695/4695 [==============================] - 0s 14us/step - loss: 0.8958 - acc: 0.7889\n",
            "Epoch 47/50\n",
            "4695/4695 [==============================] - 0s 15us/step - loss: 0.8186 - acc: 0.7859\n",
            "Epoch 48/50\n",
            "4695/4695 [==============================] - 0s 15us/step - loss: 0.8084 - acc: 0.7911\n",
            "Epoch 49/50\n",
            "4695/4695 [==============================] - 0s 16us/step - loss: 0.8106 - acc: 0.7889\n",
            "Epoch 50/50\n",
            "4695/4695 [==============================] - 0s 14us/step - loss: 0.8411 - acc: 0.7842\n",
            "2348/2348 [==============================] - 0s 46us/step\n",
            "4695/4695 [==============================] - 0s 6us/step\n",
            "[CV]  kerasclassifier__activation_hidden=exponential, kerasclassifier__batch_size=80, kerasclassifier__epochs=50, kerasclassifier__learning_rate=0.001, kerasclassifier__rate=0.1, kerasclassifier__units=64, score=0.8019591141396933, total=   4.7s\n",
            "[CV] kerasclassifier__activation_hidden=exponential, kerasclassifier__batch_size=80, kerasclassifier__epochs=50, kerasclassifier__learning_rate=0.001, kerasclassifier__rate=0.1, kerasclassifier__units=64 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    9.8s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "4696/4696 [==============================] - 0s 87us/step - loss: 0.8652 - acc: 0.7287\n",
            "Epoch 2/50\n",
            "4696/4696 [==============================] - 0s 15us/step - loss: 0.8108 - acc: 0.7860\n",
            "Epoch 3/50\n",
            "4696/4696 [==============================] - 0s 15us/step - loss: 0.8806 - acc: 0.7807\n",
            "Epoch 4/50\n",
            "4696/4696 [==============================] - 0s 15us/step - loss: 0.8371 - acc: 0.7828\n",
            "Epoch 5/50\n",
            "4696/4696 [==============================] - 0s 15us/step - loss: 0.8187 - acc: 0.7847\n",
            "Epoch 6/50\n",
            "4696/4696 [==============================] - 0s 14us/step - loss: 0.8660 - acc: 0.7881\n",
            "Epoch 7/50\n",
            "4696/4696 [==============================] - 0s 14us/step - loss: 0.8060 - acc: 0.7875\n",
            "Epoch 8/50\n",
            "4696/4696 [==============================] - 0s 15us/step - loss: 0.8093 - acc: 0.7939\n",
            "Epoch 9/50\n",
            "4696/4696 [==============================] - 0s 15us/step - loss: 0.7923 - acc: 0.7917\n",
            "Epoch 10/50\n",
            "4696/4696 [==============================] - 0s 15us/step - loss: 0.7801 - acc: 0.7922\n",
            "Epoch 11/50\n",
            "4696/4696 [==============================] - 0s 15us/step - loss: 0.7742 - acc: 0.7937\n",
            "Epoch 12/50\n",
            "4696/4696 [==============================] - 0s 15us/step - loss: 0.7607 - acc: 0.7958\n",
            "Epoch 13/50\n",
            "4696/4696 [==============================] - 0s 15us/step - loss: 0.7482 - acc: 0.7975\n",
            "Epoch 14/50\n",
            "4696/4696 [==============================] - 0s 15us/step - loss: 0.7889 - acc: 0.7937\n",
            "Epoch 15/50\n",
            "4696/4696 [==============================] - 0s 15us/step - loss: 0.8167 - acc: 0.7941\n",
            "Epoch 16/50\n",
            "4696/4696 [==============================] - 0s 15us/step - loss: 0.7617 - acc: 0.7994\n",
            "Epoch 17/50\n",
            "4696/4696 [==============================] - 0s 15us/step - loss: 0.7694 - acc: 0.7996\n",
            "Epoch 18/50\n",
            "4696/4696 [==============================] - 0s 15us/step - loss: 0.7178 - acc: 0.7958\n",
            "Epoch 19/50\n",
            "4696/4696 [==============================] - 0s 15us/step - loss: 0.8322 - acc: 0.7990\n",
            "Epoch 20/50\n",
            "4696/4696 [==============================] - 0s 15us/step - loss: 0.8191 - acc: 0.7930\n",
            "Epoch 21/50\n",
            "4696/4696 [==============================] - 0s 15us/step - loss: 0.7609 - acc: 0.8030\n",
            "Epoch 22/50\n",
            "4696/4696 [==============================] - 0s 15us/step - loss: 0.7255 - acc: 0.7954\n",
            "Epoch 23/50\n",
            "4696/4696 [==============================] - 0s 15us/step - loss: 0.8078 - acc: 0.7977\n",
            "Epoch 24/50\n",
            "4696/4696 [==============================] - 0s 15us/step - loss: 0.7408 - acc: 0.7988\n",
            "Epoch 25/50\n",
            "4696/4696 [==============================] - 0s 15us/step - loss: 0.7767 - acc: 0.7954\n",
            "Epoch 26/50\n",
            "4696/4696 [==============================] - 0s 16us/step - loss: 0.7800 - acc: 0.8020\n",
            "Epoch 27/50\n",
            "4696/4696 [==============================] - 0s 14us/step - loss: 0.7942 - acc: 0.7964\n",
            "Epoch 28/50\n",
            "4696/4696 [==============================] - 0s 15us/step - loss: 0.7345 - acc: 0.7981\n",
            "Epoch 29/50\n",
            "4696/4696 [==============================] - 0s 15us/step - loss: 0.7726 - acc: 0.7954\n",
            "Epoch 30/50\n",
            "4696/4696 [==============================] - 0s 15us/step - loss: 0.8511 - acc: 0.7949\n",
            "Epoch 31/50\n",
            "4696/4696 [==============================] - 0s 15us/step - loss: 0.8089 - acc: 0.7939\n",
            "Epoch 32/50\n",
            "4696/4696 [==============================] - 0s 16us/step - loss: 0.7991 - acc: 0.8003\n",
            "Epoch 33/50\n",
            "4696/4696 [==============================] - 0s 15us/step - loss: 0.7596 - acc: 0.8007\n",
            "Epoch 34/50\n",
            "4696/4696 [==============================] - 0s 15us/step - loss: 0.7851 - acc: 0.8049\n",
            "Epoch 35/50\n",
            "4696/4696 [==============================] - 0s 15us/step - loss: 0.8127 - acc: 0.7979\n",
            "Epoch 36/50\n",
            "4696/4696 [==============================] - 0s 15us/step - loss: 0.8365 - acc: 0.7994\n",
            "Epoch 37/50\n",
            "4696/4696 [==============================] - 0s 15us/step - loss: 0.7514 - acc: 0.8054\n",
            "Epoch 38/50\n",
            "4696/4696 [==============================] - 0s 15us/step - loss: 0.7877 - acc: 0.7968\n",
            "Epoch 39/50\n",
            "4696/4696 [==============================] - 0s 16us/step - loss: 0.7656 - acc: 0.8005\n",
            "Epoch 40/50\n",
            "4696/4696 [==============================] - 0s 15us/step - loss: 0.7317 - acc: 0.8007\n",
            "Epoch 41/50\n",
            "4696/4696 [==============================] - 0s 16us/step - loss: 0.8453 - acc: 0.7979\n",
            "Epoch 42/50\n",
            "4696/4696 [==============================] - 0s 15us/step - loss: 0.8474 - acc: 0.7966\n",
            "Epoch 43/50\n",
            "4696/4696 [==============================] - 0s 16us/step - loss: 0.7571 - acc: 0.8013\n",
            "Epoch 44/50\n",
            "4696/4696 [==============================] - 0s 15us/step - loss: 0.8606 - acc: 0.8020\n",
            "Epoch 45/50\n",
            "4696/4696 [==============================] - 0s 15us/step - loss: 0.8066 - acc: 0.8000\n",
            "Epoch 46/50\n",
            "4696/4696 [==============================] - 0s 14us/step - loss: 0.7345 - acc: 0.8030\n",
            "Epoch 47/50\n",
            "4696/4696 [==============================] - 0s 15us/step - loss: 0.7543 - acc: 0.8037\n",
            "Epoch 48/50\n",
            "4696/4696 [==============================] - 0s 16us/step - loss: 0.7812 - acc: 0.7941\n",
            "Epoch 49/50\n",
            "4696/4696 [==============================] - 0s 16us/step - loss: 0.7916 - acc: 0.8030\n",
            "Epoch 50/50\n",
            "4696/4696 [==============================] - 0s 16us/step - loss: 0.7796 - acc: 0.7996\n",
            "2347/2347 [==============================] - 0s 52us/step\n",
            "4696/4696 [==============================] - 0s 6us/step\n",
            "[CV]  kerasclassifier__activation_hidden=exponential, kerasclassifier__batch_size=80, kerasclassifier__epochs=50, kerasclassifier__learning_rate=0.001, kerasclassifier__rate=0.1, kerasclassifier__units=64, score=0.8010225820195995, total=   4.7s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   14.7s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   14.7s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "7043/7043 [==============================] - 0s 69us/step - loss: 0.8878 - acc: 0.7527\n",
            "Epoch 2/50\n",
            "7043/7043 [==============================] - 0s 15us/step - loss: 0.7837 - acc: 0.7767\n",
            "Epoch 3/50\n",
            "7043/7043 [==============================] - 0s 15us/step - loss: 0.7796 - acc: 0.7873\n",
            "Epoch 4/50\n",
            "7043/7043 [==============================] - 0s 14us/step - loss: 0.8540 - acc: 0.7849\n",
            "Epoch 5/50\n",
            "7043/7043 [==============================] - 0s 15us/step - loss: 0.8362 - acc: 0.7865\n",
            "Epoch 6/50\n",
            "7043/7043 [==============================] - 0s 15us/step - loss: 0.8420 - acc: 0.7850\n",
            "Epoch 7/50\n",
            "7043/7043 [==============================] - 0s 14us/step - loss: 0.7742 - acc: 0.7906\n",
            "Epoch 8/50\n",
            "7043/7043 [==============================] - 0s 16us/step - loss: 0.7887 - acc: 0.7863\n",
            "Epoch 9/50\n",
            "7043/7043 [==============================] - 0s 16us/step - loss: 0.7425 - acc: 0.7940\n",
            "Epoch 10/50\n",
            "7043/7043 [==============================] - 0s 14us/step - loss: 0.8407 - acc: 0.7892\n",
            "Epoch 11/50\n",
            "7043/7043 [==============================] - 0s 16us/step - loss: 0.8318 - acc: 0.7883\n",
            "Epoch 12/50\n",
            "7043/7043 [==============================] - 0s 15us/step - loss: 0.8099 - acc: 0.7901\n",
            "Epoch 13/50\n",
            "7043/7043 [==============================] - 0s 16us/step - loss: 0.8090 - acc: 0.7886\n",
            "Epoch 14/50\n",
            "7043/7043 [==============================] - 0s 15us/step - loss: 0.8092 - acc: 0.7953\n",
            "Epoch 15/50\n",
            "7043/7043 [==============================] - 0s 14us/step - loss: 0.7764 - acc: 0.7926\n",
            "Epoch 16/50\n",
            "7043/7043 [==============================] - 0s 15us/step - loss: 0.7576 - acc: 0.7972\n",
            "Epoch 17/50\n",
            "7043/7043 [==============================] - 0s 14us/step - loss: 0.8049 - acc: 0.7944\n",
            "Epoch 18/50\n",
            "7043/7043 [==============================] - 0s 16us/step - loss: 0.7783 - acc: 0.7981\n",
            "Epoch 19/50\n",
            "7043/7043 [==============================] - 0s 15us/step - loss: 0.8428 - acc: 0.7916\n",
            "Epoch 20/50\n",
            "7043/7043 [==============================] - 0s 15us/step - loss: 0.7942 - acc: 0.7911\n",
            "Epoch 21/50\n",
            "7043/7043 [==============================] - 0s 14us/step - loss: 0.7631 - acc: 0.7916\n",
            "Epoch 22/50\n",
            "7043/7043 [==============================] - 0s 14us/step - loss: 0.8001 - acc: 0.7893\n",
            "Epoch 23/50\n",
            "7043/7043 [==============================] - 0s 14us/step - loss: 0.8180 - acc: 0.7937\n",
            "Epoch 24/50\n",
            "7043/7043 [==============================] - 0s 14us/step - loss: 0.8096 - acc: 0.7934\n",
            "Epoch 25/50\n",
            "7043/7043 [==============================] - 0s 14us/step - loss: 0.7918 - acc: 0.7926\n",
            "Epoch 26/50\n",
            "7043/7043 [==============================] - 0s 14us/step - loss: 0.7408 - acc: 0.7978\n",
            "Epoch 27/50\n",
            "7043/7043 [==============================] - 0s 14us/step - loss: 0.8240 - acc: 0.7938\n",
            "Epoch 28/50\n",
            "7043/7043 [==============================] - 0s 15us/step - loss: 0.8290 - acc: 0.7968\n",
            "Epoch 29/50\n",
            "7043/7043 [==============================] - 0s 15us/step - loss: 0.8327 - acc: 0.7953\n",
            "Epoch 30/50\n",
            "7043/7043 [==============================] - 0s 15us/step - loss: 0.8565 - acc: 0.7933\n",
            "Epoch 31/50\n",
            "7043/7043 [==============================] - 0s 16us/step - loss: 0.7465 - acc: 0.7974\n",
            "Epoch 32/50\n",
            "7043/7043 [==============================] - 0s 15us/step - loss: 0.8291 - acc: 0.7930\n",
            "Epoch 33/50\n",
            "7043/7043 [==============================] - 0s 15us/step - loss: 0.7985 - acc: 0.7970\n",
            "Epoch 34/50\n",
            "7043/7043 [==============================] - 0s 14us/step - loss: 0.7639 - acc: 0.7963\n",
            "Epoch 35/50\n",
            "7043/7043 [==============================] - 0s 14us/step - loss: 0.8139 - acc: 0.7961\n",
            "Epoch 36/50\n",
            "7043/7043 [==============================] - 0s 15us/step - loss: 0.8116 - acc: 0.7955\n",
            "Epoch 37/50\n",
            "7043/7043 [==============================] - 0s 15us/step - loss: 0.7985 - acc: 0.7995\n",
            "Epoch 38/50\n",
            "7043/7043 [==============================] - 0s 14us/step - loss: 0.8056 - acc: 0.7953\n",
            "Epoch 39/50\n",
            "7043/7043 [==============================] - 0s 15us/step - loss: 0.8313 - acc: 0.7937\n",
            "Epoch 40/50\n",
            "7043/7043 [==============================] - 0s 14us/step - loss: 0.8161 - acc: 0.7982\n",
            "Epoch 41/50\n",
            "7043/7043 [==============================] - 0s 14us/step - loss: 0.7642 - acc: 0.7988\n",
            "Epoch 42/50\n",
            "7043/7043 [==============================] - 0s 15us/step - loss: 0.7930 - acc: 0.7997\n",
            "Epoch 43/50\n",
            "7043/7043 [==============================] - 0s 14us/step - loss: 0.7870 - acc: 0.7985\n",
            "Epoch 44/50\n",
            "7043/7043 [==============================] - 0s 15us/step - loss: 0.7937 - acc: 0.7991\n",
            "Epoch 45/50\n",
            "7043/7043 [==============================] - 0s 14us/step - loss: 0.7922 - acc: 0.7967\n",
            "Epoch 46/50\n",
            "7043/7043 [==============================] - 0s 14us/step - loss: 0.9220 - acc: 0.7923\n",
            "Epoch 47/50\n",
            "7043/7043 [==============================] - 0s 14us/step - loss: 0.8191 - acc: 0.7981\n",
            "Epoch 48/50\n",
            "7043/7043 [==============================] - 0s 15us/step - loss: 0.8088 - acc: 0.7991\n",
            "Epoch 49/50\n",
            "7043/7043 [==============================] - 0s 15us/step - loss: 0.7727 - acc: 0.7987\n",
            "Epoch 50/50\n",
            "7043/7043 [==============================] - 0s 15us/step - loss: 0.7427 - acc: 0.8008\n",
            "Cross Validation Score: 0.8002271759193526\n",
            "Best Parameters: {'kerasclassifier__activation_hidden': 'exponential', 'kerasclassifier__batch_size': 80, 'kerasclassifier__epochs': 50, 'kerasclassifier__learning_rate': 0.001, 'kerasclassifier__rate': 0.1, 'kerasclassifier__units': 64}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "ABHoZInglKZC"
      },
      "cell_type": "markdown",
      "source": [
        "1:\n",
        "param_grid = {\n",
        "\n",
        "    'kerasclassifier__batch_size': [20, 50, 80, 100, 200],\n",
        "    'kerasclassifier__epochs': [20],\n",
        "}\n",
        "\n",
        "Cross Validation Score: 0.8046287093568082\n",
        "\n",
        "Best Parameters: {'kerasclassifier__batch_size': 80, 'kerasclassifier__epochs': 20}\n",
        "\n",
        "2: param_grid = {\n",
        "\n",
        "    'kerasclassifier__batch_size': [80],\n",
        "    'kerasclassifier__epochs': [20],\n",
        "    'kerasclassifier__optimizer': ['sgd', 'rmsprop', 'adagrad', 'adadelta', 'adam', 'adamax', 'nadam']\n",
        "}\n",
        "\n",
        "\n",
        "Cross Validation Score: 0.8054806190543803\n",
        "\n",
        "Best Parameters: {'kerasclassifier__batch_size': 80, 'kerasclassifier__epochs': 20, 'kerasclassifier__optimizer': 'adam'}\n",
        "\n",
        "3: param_grid = {\n",
        "\n",
        "    'kerasclassifier__batch_size': [80],\n",
        "    'kerasclassifier__epochs': [20],\n",
        "    'kerasclassifier__learning_rate': [0.001, 0.01, 0.1, 0.2, 0.5],\n",
        "}\n",
        "\n",
        "Cross Validation Score: 0.8007951157177339\n",
        "\n",
        "Best Parameters: {'kerasclassifier__batch_size': 80, 'kerasclassifier__epochs': 20, 'kerasclassifier__learning_rate': 0.001}\n",
        "\n",
        "4: param_grid = {\n",
        "\n",
        "    'kerasclassifier__batch_size': [80],\n",
        "    'kerasclassifier__epochs': [20],\n",
        "    'kerasclassifier__learning_rate': [0.001, 0.002, 0.005, 0.01],\n",
        "}\n",
        "\n",
        "\n",
        "Cross Validation Score: 0.8009371006673293\n",
        "\n",
        "Best Parameters: {'kerasclassifier__batch_size': 80, 'kerasclassifier__epochs': 20, 'kerasclassifier__learning_rate': 0.001}\n",
        "\n",
        "5: param_grid = {\n",
        "\n",
        "    'kerasclassifier__batch_size': [80],\n",
        "    'kerasclassifier__epochs': [20],\n",
        "    'kerasclassifier__learning_rate': [0.001],\n",
        "    'kerasclassifier__activation_hidden': ['linear', 'exponential', \n",
        "                                           'hard_sigmoid', 'sigmoid', 'tanh',\n",
        "                                           'relu', 'softsign', 'softplus', \n",
        "                                           'selu', 'elu', 'softmax'],\n",
        "}\n",
        "\n",
        "Cross Validation Score: 0.8039187846088315\n",
        "\n",
        "Best Parameters: {'kerasclassifier__activation_hidden': 'exponential', 'kerasclassifier__batch_size': 80, 'kerasclassifier__epochs': 20, 'kerasclassifier__learning_rate': 0.001}\n",
        "\n",
        "\n",
        "6: param_grid = {\n",
        "\n",
        "    'kerasclassifier__batch_size': [80],\n",
        "    'kerasclassifier__epochs': [20],\n",
        "    'kerasclassifier__learning_rate': [0.001],\n",
        "    'kerasclassifier__activation_hidden': ['exponential'],\n",
        "    'kerasclassifier__rate': [0.1, 0.2, 0.3, 0.4]\n",
        "    \n",
        "}\n",
        "\n",
        "Cross Validation Score: 0.7985233565242085\n",
        "\n",
        "Best Parameters: {'kerasclassifier__activation_hidden': 'exponential', 'kerasclassifier__batch_size': 80, 'kerasclassifier__epochs': 20, 'kerasclassifier__learning_rate': 0.001, 'kerasclassifier__rate': 0.1}\n",
        "\n",
        "7: param_grid = {\n",
        "\n",
        "    'kerasclassifier__batch_size': [80],\n",
        "    'kerasclassifier__epochs': [20],\n",
        "    'kerasclassifier__learning_rate': [0.001],\n",
        "    'kerasclassifier__activation_hidden': ['exponential'],\n",
        "    'kerasclassifier__rate': [0.1],\n",
        "    'kerasclassifier__units': [12, 16, 32, 64]\n",
        "    \n",
        "}\n",
        "\n",
        "Cross Validation Score: 0.802072980264092\n",
        "\n",
        "Best Parameters: {'kerasclassifier__activation_hidden': 'exponential', 'kerasclassifier__batch_size': 80, 'kerasclassifier__epochs': 20, 'kerasclassifier__learning_rate': 0.001, 'kerasclassifier__rate': 0.1, 'kerasclassifier__units': 64}\n",
        "\n",
        "8: param_grid = {\n",
        "\n",
        "    'kerasclassifier__batch_size': [80],\n",
        "    'kerasclassifier__epochs': [20, 50, 100, 200],\n",
        "    'kerasclassifier__learning_rate': [0.001],\n",
        "    'kerasclassifier__activation_hidden': ['exponential'],\n",
        "    'kerasclassifier__rate': [0.1],\n",
        "    'kerasclassifier__units': [64]\n",
        "}\n",
        "\n",
        "Cross Validation Score: 0.80335084481045\n",
        "\n",
        "Best Parameters: {'kerasclassifier__activation_hidden': 'exponential', 'kerasclassifier__batch_size': 80, 'kerasclassifier__epochs': 50, 'kerasclassifier__learning_rate': 0.001, 'kerasclassifier__rate': 0.1, 'kerasclassifier__units': 64}"
      ]
    },
    {
      "metadata": {
        "id": "FfZRtJ7MCN3x",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Stretch Goals:\n",
        "\n",
        "- Try to implement Random Search Hyperparameter Tuning on this dataset\n",
        "- Try to implement Bayesian Optimiation tuning on this dataset\n",
        "- Practice hyperparameter tuning other datasets that we have looked at. How high can you get MNIST? Above 99%?\n",
        "- Study for the Sprint Challenge\n",
        " - Can you implement both perceptron and MLP models from scratch with forward and backpropagation?\n",
        " - Can you implement both perceptron and MLP models in keras and tune their hyperparameters with cross validation?"
      ]
    }
  ]
}