{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Ryp-TVm4njD"
   },
   "source": [
    "# Your Mission, should you choose to accept it...\n",
    "\n",
    "To hyperparameter tune and extract every ounce of accuracy out of this telecom customer churn dataset: <https://drive.google.com/file/d/1dfbAsM9DwA7tYhInyflIpZnYs7VT-0AQ/view> \n",
    "\n",
    "## Requirements\n",
    "\n",
    "- Load the data\n",
    "- Clean the data if necessary (it will be)\n",
    "- Create and fit a baseline Keras MLP model to the data.\n",
    "- Hyperparameter tune (at least) the following parameters:\n",
    " - batch_size\n",
    " - training epochs\n",
    " - optimizer\n",
    " - learning rate (if applicable to optimizer)\n",
    " - momentum (if applicable to optimizer)\n",
    " - activation functions\n",
    " - network weight initialization\n",
    " - dropout regularization\n",
    " - number of neurons in the hidden layer\n",
    " \n",
    " You must use Grid Search and Cross Validation for your initial pass of the above hyperparameters\n",
    " \n",
    " Try and get the maximum accuracy possible out of this data! You'll save big telecoms millions! Doesn't that sound great?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NNJ-tOBs4jM1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "np.random.seed(7)  # fixed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "cust_churn_df = pd.read_csv('WA_Fn-UseC_-Telco-Customer-Churn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect data\n",
    "pd.set_option(\"display.max_columns\", 30)\n",
    "# cust_churn_df.isna().sum().sum(), cust_churn_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop 2 columns; label encode; then define input and target\n",
    "cust_churn_df = cust_churn_df.drop('customerID', axis=1)\n",
    "label_enc = LabelEncoder()\n",
    "cust_churn_df = cust_churn_df.apply(label_enc.fit_transform)\n",
    "X = cust_churn_df.drop('Churn', axis=1)\n",
    "y = cust_churn_df['Churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale input data, if needed\n",
    "# scaler = StandardScaler()\n",
    "# X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jhump\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 24)                480       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                400       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 897\n",
      "Trainable params: 897\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\Users\\jhump\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 5634 samples, validate on 1409 samples\n",
      "Epoch 1/20\n",
      "5634/5634 [==============================] - 1s 167us/step - loss: 0.7358 - acc: 0.2641 - val_loss: 0.7296 - val_acc: 0.2704\n",
      "Epoch 2/20\n",
      "5634/5634 [==============================] - 0s 48us/step - loss: 0.7352 - acc: 0.2645 - val_loss: 0.7337 - val_acc: 0.2633\n",
      "Epoch 3/20\n",
      "5634/5634 [==============================] - 0s 58us/step - loss: 0.3085 - acc: 0.6910 - val_loss: 0.2704 - val_acc: 0.7296\n",
      "Epoch 4/20\n",
      "5634/5634 [==============================] - 0s 57us/step - loss: 0.2641 - acc: 0.7359 - val_loss: 0.2704 - val_acc: 0.7296\n",
      "Epoch 5/20\n",
      "5634/5634 [==============================] - 0s 58us/step - loss: 0.2641 - acc: 0.7359 - val_loss: 0.2704 - val_acc: 0.7296\n",
      "Epoch 6/20\n",
      "5634/5634 [==============================] - 0s 55us/step - loss: 0.2641 - acc: 0.7359 - val_loss: 0.2704 - val_acc: 0.7296\n",
      "Epoch 7/20\n",
      "5634/5634 [==============================] - 0s 58us/step - loss: 0.2641 - acc: 0.7359 - val_loss: 0.2704 - val_acc: 0.7296\n",
      "Epoch 8/20\n",
      "5634/5634 [==============================] - 0s 51us/step - loss: 0.2641 - acc: 0.7359 - val_loss: 0.2704 - val_acc: 0.7296\n",
      "Epoch 9/20\n",
      "5634/5634 [==============================] - 0s 60us/step - loss: 0.2641 - acc: 0.7359 - val_loss: 0.2704 - val_acc: 0.7296\n",
      "Epoch 10/20\n",
      "5634/5634 [==============================] - 0s 65us/step - loss: 0.2641 - acc: 0.7359 - val_loss: 0.2704 - val_acc: 0.7296\n",
      "Epoch 11/20\n",
      "5634/5634 [==============================] - 0s 54us/step - loss: 0.2641 - acc: 0.7359 - val_loss: 0.2704 - val_acc: 0.7296\n",
      "Epoch 12/20\n",
      "5634/5634 [==============================] - 0s 56us/step - loss: 0.2641 - acc: 0.7359 - val_loss: 0.2704 - val_acc: 0.7296\n",
      "Epoch 13/20\n",
      "5634/5634 [==============================] - 0s 55us/step - loss: 0.2641 - acc: 0.7359 - val_loss: 0.2704 - val_acc: 0.7296\n",
      "Epoch 14/20\n",
      "5634/5634 [==============================] - 0s 48us/step - loss: 0.2641 - acc: 0.7359 - val_loss: 0.2704 - val_acc: 0.7296\n",
      "Epoch 15/20\n",
      "5634/5634 [==============================] - 0s 52us/step - loss: 0.2641 - acc: 0.7359 - val_loss: 0.2704 - val_acc: 0.7296\n",
      "Epoch 16/20\n",
      "5634/5634 [==============================] - 0s 54us/step - loss: 0.2641 - acc: 0.7359 - val_loss: 0.2704 - val_acc: 0.7296\n",
      "Epoch 17/20\n",
      "5634/5634 [==============================] - 0s 51us/step - loss: 0.2641 - acc: 0.7359 - val_loss: 0.2704 - val_acc: 0.7296\n",
      "Epoch 18/20\n",
      "5634/5634 [==============================] - 0s 57us/step - loss: 0.2641 - acc: 0.7359 - val_loss: 0.2704 - val_acc: 0.7296\n",
      "Epoch 19/20\n",
      "5634/5634 [==============================] - 0s 54us/step - loss: 0.2641 - acc: 0.7359 - val_loss: 0.2704 - val_acc: 0.7296\n",
      "Epoch 20/20\n",
      "5634/5634 [==============================] - 0s 52us/step - loss: 0.2641 - acc: 0.7359 - val_loss: 0.2704 - val_acc: 0.7296\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x27213f05668>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train baseline model with 24 input nodes, 1 hidden layer of sixteen nodes, and 1 output node\n",
    "\n",
    "# Global hyperparameters\n",
    "inputs = X.shape[1]\n",
    "epochs = 20\n",
    "batch_size = 30\n",
    "# Create model\n",
    "model = Sequential()\n",
    "model.add(Dense(24, activation='relu', input_shape=(inputs,)))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# Compile\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "# Fit model\n",
    "model.summary()\n",
    "model.fit(X, y, validation_split=0.2, epochs=epochs, batch_size=batch_size)\n",
    "# scores = model.evaluate()\n",
    "# print(f'{model.metrics[0]}: {scores[1]*100}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FfZRtJ7MCN3x"
   },
   "source": [
    "## Stretch Goals:\n",
    "\n",
    "- Try to implement Random Search Hyperparameter Tuning on this dataset\n",
    "- Try to implement Bayesian Optimiation tuning on this dataset\n",
    "- Practice hyperparameter tuning other datasets that we have looked at. How high can you get MNIST? Above 99%?\n",
    "- Study for the Sprint Challenge\n",
    " - Can you implement both perceptron and MLP models from scratch with forward and backpropagation?\n",
    " - Can you implement both perceptron and MLP models in keras and tune their hyperparameters with cross validation?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "LS_DS_434_Hyperparameter_Tuning_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
