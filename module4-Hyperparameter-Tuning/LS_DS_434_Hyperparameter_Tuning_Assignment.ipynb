{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Ryp-TVm4njD"
   },
   "source": [
    "# Your Mission, should you choose to accept it...\n",
    "\n",
    "To hyperparameter tune and extract every ounce of accuracy out of this telecom customer churn dataset: <https://drive.google.com/file/d/1dfbAsM9DwA7tYhInyflIpZnYs7VT-0AQ/view> \n",
    "\n",
    "## Requirements\n",
    "\n",
    "- Load the data\n",
    "- Clean the data if necessary (it will be)\n",
    "- Create and fit a baseline Keras MLP model to the data.\n",
    "- Hyperparameter tune (at least) the following parameters:\n",
    " - batch_size\n",
    " - training epochs\n",
    " - optimizer\n",
    " - learning rate (if applicable to optimizer)\n",
    " - momentum (if applicable to optimizer)\n",
    " - activation functions\n",
    " - network weight initialization\n",
    " - dropout regularization\n",
    " - number of neurons in the hidden layer\n",
    " \n",
    " You must use Grid Search and Cross Validation for your initial pass of the above hyperparameters\n",
    " \n",
    " Try and get the maximum accuracy possible out of this data! You'll save big telecoms millions! Doesn't that sound great?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## need to download these each time aws instance is started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install -c conda-forge category_encoders -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/treselle-systems/customer_churn_analysis/master/WA_Fn-UseC_-Telco-Customer-Churn.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: h5py in c:\\users\\cwcol\\anaconda3\\lib\\site-packages (2.9.0)\n",
      "Requirement already satisfied: scikit-optimize in c:\\users\\cwcol\\anaconda3\\lib\\site-packages (0.5.2)\n",
      "Requirement already satisfied: numpy>=1.7 in c:\\users\\cwcol\\anaconda3\\lib\\site-packages (from h5py) (1.16.2)\n",
      "Requirement already satisfied: six in c:\\users\\cwcol\\appdata\\roaming\\python\\python37\\site-packages (from h5py) (1.12.0)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in c:\\users\\cwcol\\anaconda3\\lib\\site-packages (from scikit-optimize) (0.20.3)\n",
      "Requirement already satisfied: scipy>=0.14.0 in c:\\users\\cwcol\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install h5py scikit-optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jupyterthemes\n",
      "  Downloading https://files.pythonhosted.org/packages/8a/08/9dee6dfd7f2aad6c30282d55c8f495b4dc1e4747b4e2bdbeb80572ddf312/jupyterthemes-0.20.0-py2.py3-none-any.whl (7.0MB)\n",
      "Requirement already satisfied, skipping upgrade: jupyter-core in c:\\users\\cwcol\\anaconda3\\lib\\site-packages (from jupyterthemes) (4.4.0)\n",
      "Collecting lesscpy>=0.11.2 (from jupyterthemes)\n",
      "  Downloading https://files.pythonhosted.org/packages/10/d0/fdd9874972e07ae8727a3d26b433891d8605b96999ea99bbf506e756a7b1/lesscpy-0.13.0-py2.py3-none-any.whl (48kB)\n",
      "Requirement already satisfied, skipping upgrade: matplotlib>=1.4.3 in c:\\users\\cwcol\\anaconda3\\lib\\site-packages (from jupyterthemes) (3.0.3)\n",
      "Requirement already satisfied, skipping upgrade: notebook>=5.6.0 in c:\\users\\cwcol\\anaconda3\\lib\\site-packages (from jupyterthemes) (5.7.8)\n",
      "Requirement already satisfied, skipping upgrade: ipython>=5.4.1 in c:\\users\\cwcol\\anaconda3\\lib\\site-packages (from jupyterthemes) (7.4.0)\n",
      "Requirement already satisfied, skipping upgrade: traitlets in c:\\users\\cwcol\\anaconda3\\lib\\site-packages (from jupyter-core->jupyterthemes) (4.3.2)\n",
      "Requirement already satisfied, skipping upgrade: ply in c:\\users\\cwcol\\anaconda3\\lib\\site-packages (from lesscpy>=0.11.2->jupyterthemes) (3.11)\n",
      "Requirement already satisfied, skipping upgrade: six in c:\\users\\cwcol\\appdata\\roaming\\python\\python37\\site-packages (from lesscpy>=0.11.2->jupyterthemes) (1.12.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.10.0 in c:\\users\\cwcol\\anaconda3\\lib\\site-packages (from matplotlib>=1.4.3->jupyterthemes) (1.16.2)\n",
      "Requirement already satisfied, skipping upgrade: cycler>=0.10 in c:\\users\\cwcol\\anaconda3\\lib\\site-packages (from matplotlib>=1.4.3->jupyterthemes) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in c:\\users\\cwcol\\anaconda3\\lib\\site-packages (from matplotlib>=1.4.3->jupyterthemes) (1.0.1)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\cwcol\\anaconda3\\lib\\site-packages (from matplotlib>=1.4.3->jupyterthemes) (2.3.1)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in c:\\users\\cwcol\\anaconda3\\lib\\site-packages (from matplotlib>=1.4.3->jupyterthemes) (2.8.0)\n",
      "Requirement already satisfied, skipping upgrade: pyzmq>=17 in c:\\users\\cwcol\\anaconda3\\lib\\site-packages (from notebook>=5.6.0->jupyterthemes) (18.0.0)\n",
      "Requirement already satisfied, skipping upgrade: nbformat in c:\\users\\cwcol\\anaconda3\\lib\\site-packages (from notebook>=5.6.0->jupyterthemes) (4.4.0)\n",
      "Requirement already satisfied, skipping upgrade: jinja2 in c:\\users\\cwcol\\anaconda3\\lib\\site-packages (from notebook>=5.6.0->jupyterthemes) (2.10)\n",
      "Requirement already satisfied, skipping upgrade: tornado<7,>=4.1 in c:\\users\\cwcol\\anaconda3\\lib\\site-packages (from notebook>=5.6.0->jupyterthemes) (6.0.2)\n",
      "Requirement already satisfied, skipping upgrade: Send2Trash in c:\\users\\cwcol\\anaconda3\\lib\\site-packages (from notebook>=5.6.0->jupyterthemes) (1.5.0)\n",
      "Requirement already satisfied, skipping upgrade: prometheus-client in c:\\users\\cwcol\\anaconda3\\lib\\site-packages (from notebook>=5.6.0->jupyterthemes) (0.6.0)\n",
      "Requirement already satisfied, skipping upgrade: terminado>=0.8.1 in c:\\users\\cwcol\\anaconda3\\lib\\site-packages (from notebook>=5.6.0->jupyterthemes) (0.8.1)\n",
      "Requirement already satisfied, skipping upgrade: ipython-genutils in c:\\users\\cwcol\\anaconda3\\lib\\site-packages (from notebook>=5.6.0->jupyterthemes) (0.2.0)\n",
      "Requirement already satisfied, skipping upgrade: ipykernel in c:\\users\\cwcol\\anaconda3\\lib\\site-packages (from notebook>=5.6.0->jupyterthemes) (5.1.0)\n",
      "Requirement already satisfied, skipping upgrade: jupyter-client>=5.2.0 in c:\\users\\cwcol\\anaconda3\\lib\\site-packages (from notebook>=5.6.0->jupyterthemes) (5.2.4)\n",
      "Requirement already satisfied, skipping upgrade: nbconvert in c:\\users\\cwcol\\anaconda3\\lib\\site-packages (from notebook>=5.6.0->jupyterthemes) (5.4.1)\n",
      "Requirement already satisfied, skipping upgrade: decorator in c:\\users\\cwcol\\anaconda3\\lib\\site-packages (from ipython>=5.4.1->jupyterthemes) (4.4.0)\n",
      "Requirement already satisfied, skipping upgrade: prompt-toolkit<2.1.0,>=2.0.0 in c:\\users\\cwcol\\anaconda3\\lib\\site-packages (from ipython>=5.4.1->jupyterthemes) (2.0.9)\n",
      "Requirement already satisfied, skipping upgrade: pygments in c:\\users\\cwcol\\anaconda3\\lib\\site-packages (from ipython>=5.4.1->jupyterthemes) (2.3.1)\n",
      "Requirement already satisfied, skipping upgrade: jedi>=0.10 in c:\\users\\cwcol\\anaconda3\\lib\\site-packages (from ipython>=5.4.1->jupyterthemes) (0.13.3)\n",
      "Requirement already satisfied, skipping upgrade: pickleshare in c:\\users\\cwcol\\anaconda3\\lib\\site-packages (from ipython>=5.4.1->jupyterthemes) (0.7.5)\n",
      "Requirement already satisfied, skipping upgrade: backcall in c:\\users\\cwcol\\anaconda3\\lib\\site-packages (from ipython>=5.4.1->jupyterthemes) (0.1.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=18.5 in c:\\users\\cwcol\\anaconda3\\lib\\site-packages (from ipython>=5.4.1->jupyterthemes) (40.8.0)\n",
      "Requirement already satisfied, skipping upgrade: colorama; sys_platform == \"win32\" in c:\\users\\cwcol\\appdata\\roaming\\python\\python37\\site-packages (from ipython>=5.4.1->jupyterthemes) (0.4.1)\n",
      "Requirement already satisfied, skipping upgrade: jsonschema!=2.5.0,>=2.4 in c:\\users\\cwcol\\anaconda3\\lib\\site-packages (from nbformat->notebook>=5.6.0->jupyterthemes) (3.0.1)\n",
      "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in c:\\users\\cwcol\\anaconda3\\lib\\site-packages (from jinja2->notebook>=5.6.0->jupyterthemes) (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: mistune>=0.8.1 in c:\\users\\cwcol\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=5.6.0->jupyterthemes) (0.8.4)\n",
      "Requirement already satisfied, skipping upgrade: entrypoints>=0.2.2 in c:\\users\\cwcol\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=5.6.0->jupyterthemes) (0.3)\n",
      "Requirement already satisfied, skipping upgrade: bleach in c:\\users\\cwcol\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=5.6.0->jupyterthemes) (3.1.0)\n",
      "Requirement already satisfied, skipping upgrade: pandocfilters>=1.4.1 in c:\\users\\cwcol\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=5.6.0->jupyterthemes) (1.4.2)\n",
      "Requirement already satisfied, skipping upgrade: testpath in c:\\users\\cwcol\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=5.6.0->jupyterthemes) (0.4.2)\n",
      "Requirement already satisfied, skipping upgrade: defusedxml in c:\\users\\cwcol\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=5.6.0->jupyterthemes) (0.5.0)\n",
      "Requirement already satisfied, skipping upgrade: wcwidth in c:\\users\\cwcol\\anaconda3\\lib\\site-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython>=5.4.1->jupyterthemes) (0.1.7)\n",
      "Requirement already satisfied, skipping upgrade: parso>=0.3.0 in c:\\users\\cwcol\\anaconda3\\lib\\site-packages (from jedi>=0.10->ipython>=5.4.1->jupyterthemes) (0.3.4)\n",
      "Requirement already satisfied, skipping upgrade: attrs>=17.4.0 in c:\\users\\cwcol\\anaconda3\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->notebook>=5.6.0->jupyterthemes) (19.1.0)\n",
      "Requirement already satisfied, skipping upgrade: pyrsistent>=0.14.0 in c:\\users\\cwcol\\anaconda3\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->notebook>=5.6.0->jupyterthemes) (0.14.11)\n",
      "Requirement already satisfied, skipping upgrade: webencodings in c:\\users\\cwcol\\anaconda3\\lib\\site-packages (from bleach->nbconvert->notebook>=5.6.0->jupyterthemes) (0.5.1)\n",
      "Installing collected packages: lesscpy, jupyterthemes\n",
      "Successfully installed jupyterthemes-0.20.0 lesscpy-0.13.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade jupyterthemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jt -t chesterish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install keras "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports I know I'll need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NNJ-tOBs4jM1"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-8b6c696be87a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "import category_encoders as ce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"WA_Fn-UseC_-Telco-Customer-Churn.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " pd.set_option(\"display.max_columns\", 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace(\"No\",0).replace(\"Yes\",1)\n",
    "df = df.replace(\"Male\",1).replace(\"Female\",0)\n",
    "df = df.replace(\" \",0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "pipe=make_pipeline(\n",
    "   ce.BinaryEncoder(cols=[\"Partner\",\"gender\",\"SeniorCitizen\",\"Dependents\",\"PhoneService\",\"PaperlessBilling\"]),\n",
    "   ce.OneHotEncoder(cols=[\"MultipleLines\",\"InternetService\",\"OnlineSecurity\",\"OnlineBackup\",\"DeviceProtection\",\n",
    "                                        \"TechSupport\",\"StreamingTV\",\"StreamingMovies\",\"Contract\",\"PaymentMethod\"])\n",
    ")\n",
    "df_enc = pipe.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enc[\"TotalCharges\"] = pd.to_numeric(df_enc[\"TotalCharges\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_enc.drop(columns =[\"customerID\",\"Churn\"],axis=1)\n",
    "y = df_enc[\"Churn\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train,y_test = train_test_split(X,y,random_state=42,test_size=.15,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skopt\n",
    "import tensorflow\n",
    "from tensorflow.python.keras import backend as K\n",
    "from keras import optimizers\n",
    "from tensorflow.python.keras.models import load_model\n",
    "from skopt import gp_minimize, forest_minimize,gbrt_minimize\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from skopt.plots import plot_convergence\n",
    "from skopt.plots import plot_objective, plot_evaluations\n",
    "from keras.regularizers import l1,l2,l1_l2\n",
    "from skopt.utils import use_named_args\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_learning_rate = Real(low=1e-6, high=1e-2, prior='log-uniform',\n",
    "                         name='learning_rate')\n",
    "dim_num_dense_layers = Integer(low=1, high=5, name='num_dense_layers')\n",
    "dim_num_dense_nodes = Integer(low=16, high=72, name='num_dense_nodes')\n",
    "dim_activation = Categorical(categories=['relu', 'sigmoid'],\n",
    "                             name='activation')\n",
    "dim_batch_size = Integer(low=28, high=128, name='batch_size')\n",
    "dim_adam_decay = Real(low=1e-6,high=1e-2,name=\"adam_decay\")\n",
    "\n",
    "dimensions = [dim_learning_rate,\n",
    "              dim_num_dense_layers,\n",
    "              dim_num_dense_nodes,\n",
    "              dim_activation,\n",
    "              dim_batch_size,\n",
    "              dim_adam_decay\n",
    "             ]\n",
    "default_parameters = [1e-3, 1, 16, 'relu',128, 1e-3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_num_dense_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(learning_rate, num_dense_layers,\n",
    "                 num_dense_nodes, activation,adam_decay\n",
    "                ):\n",
    "    \"\"\"\n",
    "    Hyper-parameters:\n",
    "    learning_rate:     Learning-rate for the optimizer.\n",
    "    num_dense_layers:  Number of dense layers.\n",
    "    num_dense_nodes:   Number of nodes in each dense layer.\n",
    "    activation:        Activation function for all layers.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Start construction of a Keras Sequential model.\n",
    "    model = Sequential()\n",
    "\n",
    "    # Add an input layer which is similar to a feed_dict in TensorFlow.\n",
    "    # Note that the input-shape must be a tuple containing the image-size.\n",
    "    model.add(Dense(num_dense_nodes, activation=activation, input_shape=(input_shape,) ))\n",
    "\n",
    "    \n",
    "\n",
    "    # Add fully-connected / dense layers.\n",
    "    # The number of layers is a hyper-parameter we want to optimize.\n",
    "    for i in range(num_dense_layers):\n",
    "        # Name of the layer. This is not really necessary\n",
    "        # because Keras should give them unique names.\n",
    "        name = 'layer_dense_{0}'.format(i+1)\n",
    "\n",
    "        # Add the dense / fully-connected layer to the model.\n",
    "        # This has two hyper-parameters we want to optimize:\n",
    "        # The number of nodes and the activation function.\n",
    "        model.add(Dense(num_dense_nodes,\n",
    "                        activation=activation,\n",
    "                        name=name,\n",
    "                        ))\n",
    "        \n",
    "\n",
    "    # Last fully-connected / dense layer with softmax-activation\n",
    "    # for use in classification.\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # Use the Adam method for training the network.\n",
    "    # We want to find the best learning-rate for the Adam method.\n",
    "    adam = optimizers.Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=adam_decay, amsgrad=False)\n",
    "    \n",
    "    # In Keras we need to compile the model so it can be trained.\n",
    "    model.compile(optimizer=adam,\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@use_named_args(dimensions=dimensions)\n",
    "def fitness(learning_rate, num_dense_layers,\n",
    "            num_dense_nodes, activation, batch_size, adam_decay\n",
    "           ):\n",
    "    \"\"\"\n",
    "    Hyper-parameters:\n",
    "    learning_rate:     Learning-rate for the optimizer.\n",
    "    num_dense_layers:  Number of dense layers.\n",
    "    num_dense_nodes:   Number of nodes in each dense layer.\n",
    "    activation:        Activation function for all layers.\n",
    "    \"\"\"\n",
    "\n",
    "    # Print the hyper-parameters.\n",
    "    print('learning rate: {0:.1e}'.format(learning_rate))\n",
    "    print('num_dense_layers:', num_dense_layers)\n",
    "    print('num_dense_nodes:', num_dense_nodes)\n",
    "    print('activation:', activation)\n",
    "    print()\n",
    "    \n",
    "    # Create the neural network with these hyper-parameters.\n",
    "    model = create_model(learning_rate=learning_rate,\n",
    "                         num_dense_layers=num_dense_layers,\n",
    "                         num_dense_nodes=num_dense_nodes,\n",
    "                         activation=activation,adam_decay=adam_decay\n",
    "                        )\n",
    "    \n",
    "\n",
    "    # Use Keras to train the model.\n",
    "    history = model.fit(x=X_train,\n",
    "                        y=y_train,\n",
    "                        epochs=3,\n",
    "                        batch_size=batch_size,\n",
    "                        validation_split=0.3,\n",
    "                        )\n",
    "\n",
    "    # Get the classification accuracy on the validation-set\n",
    "    # after the last training-epoch.\n",
    "    accuracy = history.history['val_acc'][-1]\n",
    "\n",
    "    # Print the classification accuracy.\n",
    "    print()\n",
    "    print(\"Accuracy: {0:.2%}\".format(accuracy))\n",
    "    print()\n",
    "\n",
    "\n",
    "    # Delete the Keras model with these hyper-parameters from memory.\n",
    "    del model\n",
    "    \n",
    "    # Clear the Keras session, otherwise it will keep adding new\n",
    "    # models to the same TensorFlow graph each time we create\n",
    "    # a model with a different set of hyper-parameters.\n",
    "    K.clear_session()\n",
    "    tensorflow.reset_default_graph()\n",
    "\n",
    "    \n",
    "    # NOTE: Scikit-optimize does minimization so it tries to\n",
    "    # find a set of hyper-parameters with the LOWEST fitness-value.\n",
    "    # Because we are interested in the HIGHEST classification\n",
    "    # accuracy, we need to negate this number so it can be minimized.\n",
    "    return -accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.isfile('best_model.h5')\n",
    "#os.remove('best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "tensorflow.reset_default_graph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitness(x=default_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_result = gp_minimize(func=fitness,\n",
    "                            dimensions=dimensions,\n",
    "                            acq_func='EI', # Expected Improvement.\n",
    "                            n_calls=40,\n",
    "                            n_jobs=-1,\n",
    "                            x0=default_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(search_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_result.x_iters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FfZRtJ7MCN3x"
   },
   "source": [
    "## Stretch Goals:\n",
    "\n",
    "- Try to implement Random Search Hyperparameter Tuning on this dataset\n",
    "- Try to implement Bayesian Optimiation tuning on this dataset\n",
    "- Practice hyperparameter tuning other datasets that we have looked at. How high can you get MNIST? Above 99%?\n",
    "- Study for the Sprint Challenge\n",
    " - Can you implement both perceptron and MLP models from scratch with forward and backpropagation?\n",
    " - Can you implement both perceptron and MLP models in keras and tune their hyperparameters with cross validation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "LS_DS_434_Hyperparameter_Tuning_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
