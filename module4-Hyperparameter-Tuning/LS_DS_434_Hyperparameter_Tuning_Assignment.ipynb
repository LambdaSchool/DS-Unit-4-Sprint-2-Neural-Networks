{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Ryp-TVm4njD"
   },
   "source": [
    "# Your Mission, should you choose to accept it...\n",
    "\n",
    "To hyperparameter tune and extract every ounce of accuracy out of this telecom customer churn dataset: <https://drive.google.com/file/d/1dfbAsM9DwA7tYhInyflIpZnYs7VT-0AQ/view> \n",
    "\n",
    "## Requirements\n",
    "\n",
    "- Load the data\n",
    "- Clean the data if necessary (it will be)\n",
    "- Create and fit a baseline Keras MLP model to the data.\n",
    "- Hyperparameter tune (at least) the following parameters:\n",
    " - batch_size\n",
    " - training epochs\n",
    " - optimizer\n",
    " - learning rate (if applicable to optimizer)\n",
    " - momentum (if applicable to optimizer)\n",
    " - activation functions\n",
    " - network weight initialization\n",
    " - dropout regularization\n",
    " - number of neurons in the hidden layer\n",
    " \n",
    " You must use Grid Search and Cross Validation for your initial pass of the above hyperparameters\n",
    " \n",
    " Try and get the maximum accuracy possible out of this data! You'll save big telecoms millions! Doesn't that sound great?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NNJ-tOBs4jM1"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import optimizers\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "np.random.seed(7)  # fixed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "cust_churn_df = pd.read_csv('WA_Fn-UseC_-Telco-Customer-Churn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect data\n",
    "pd.set_option(\"display.max_columns\", 30)\n",
    "# cust_churn_df.isna().sum().sum(), cust_churn_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop 2 columns; label encode; then define input and target\n",
    "cust_churn_df = cust_churn_df.drop('customerID', axis=1)\n",
    "label_enc = LabelEncoder()\n",
    "cust_churn_df = cust_churn_df.apply(label_enc.fit_transform)\n",
    "X = cust_churn_df.drop('Churn', axis=1)\n",
    "y = cust_churn_df['Churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale input data, if needed\n",
    "# scaler = StandardScaler()\n",
    "# X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For hyperparameter tuning, eg, optimizers\n",
    "sgd = optimizers.SGD(lr=0.01, momentum=0.0, nesterov=False) \n",
    "# default lr is 0.01; 0.1 did not improve; 0.2 worsened\n",
    "# default momentum is 0.0; 0.1 did not improve; 0.2 did not improve\n",
    "# momentum=0.1, nesterov=True resulted in no change\n",
    "\n",
    "adam = optimizers.Adam(lr=0.001, amsgrad=False)  # default lr=0.001; 0.01 and 0.1 caused no change\n",
    "# amsgrad variant of adam caused no change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_218 (Dense)            (None, 24)                480       \n",
      "_________________________________________________________________\n",
      "dense_219 (Dense)            (None, 16)                400       \n",
      "_________________________________________________________________\n",
      "dense_220 (Dense)            (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 897\n",
      "Trainable params: 897\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 5634 samples, validate on 1409 samples\n",
      "Epoch 1/20\n",
      "5634/5634 [==============================] - 6s 1ms/step - loss: 0.2979 - acc: 0.7015 - val_loss: 0.2863 - val_acc: 0.7126\n",
      "Epoch 2/20\n",
      "5634/5634 [==============================] - 0s 78us/step - loss: 0.2797 - acc: 0.7199 - val_loss: 0.2870 - val_acc: 0.7126\n",
      "Epoch 3/20\n",
      "5634/5634 [==============================] - 0s 80us/step - loss: 0.2689 - acc: 0.7302 - val_loss: 0.2684 - val_acc: 0.7289\n",
      "Epoch 4/20\n",
      "5634/5634 [==============================] - 0s 74us/step - loss: 0.2733 - acc: 0.7258 - val_loss: 0.2865 - val_acc: 0.7133\n",
      "Epoch 5/20\n",
      "5634/5634 [==============================] - 0s 77us/step - loss: 0.2708 - acc: 0.7286 - val_loss: 0.2810 - val_acc: 0.7189\n",
      "Epoch 6/20\n",
      "5634/5634 [==============================] - 0s 78us/step - loss: 0.2706 - acc: 0.7286 - val_loss: 0.2706 - val_acc: 0.7289\n",
      "Epoch 7/20\n",
      "5634/5634 [==============================] - 0s 81us/step - loss: 0.2641 - acc: 0.7359 - val_loss: 0.2704 - val_acc: 0.7296\n",
      "Epoch 8/20\n",
      "5634/5634 [==============================] - 0s 81us/step - loss: 0.2641 - acc: 0.7359 - val_loss: 0.2704 - val_acc: 0.7296\n",
      "Epoch 9/20\n",
      "5634/5634 [==============================] - 0s 75us/step - loss: 0.2641 - acc: 0.7359 - val_loss: 0.2704 - val_acc: 0.7296\n",
      "Epoch 10/20\n",
      "5634/5634 [==============================] - 1s 92us/step - loss: 0.2641 - acc: 0.7359 - val_loss: 0.2704 - val_acc: 0.7296\n",
      "Epoch 11/20\n",
      "5634/5634 [==============================] - 0s 82us/step - loss: 0.2641 - acc: 0.7359 - val_loss: 0.2704 - val_acc: 0.7296\n",
      "Epoch 12/20\n",
      "5634/5634 [==============================] - 0s 85us/step - loss: 0.2641 - acc: 0.7359 - val_loss: 0.2704 - val_acc: 0.7296\n",
      "Epoch 13/20\n",
      "5634/5634 [==============================] - 0s 89us/step - loss: 0.2641 - acc: 0.7359 - val_loss: 0.2704 - val_acc: 0.7296\n",
      "Epoch 14/20\n",
      "5634/5634 [==============================] - 1s 121us/step - loss: 0.2641 - acc: 0.7359 - val_loss: 0.2704 - val_acc: 0.7296\n",
      "Epoch 15/20\n",
      "5634/5634 [==============================] - 0s 82us/step - loss: 0.2641 - acc: 0.7359 - val_loss: 0.2704 - val_acc: 0.7296\n",
      "Epoch 16/20\n",
      "5634/5634 [==============================] - 0s 71us/step - loss: 0.2641 - acc: 0.7359 - val_loss: 0.2704 - val_acc: 0.7296\n",
      "Epoch 17/20\n",
      "5634/5634 [==============================] - 0s 81us/step - loss: 0.2641 - acc: 0.7359 - val_loss: 0.2704 - val_acc: 0.7296\n",
      "Epoch 18/20\n",
      "5634/5634 [==============================] - 0s 79us/step - loss: 0.2641 - acc: 0.7359 - val_loss: 0.2704 - val_acc: 0.7296\n",
      "Epoch 19/20\n",
      "5634/5634 [==============================] - 0s 74us/step - loss: 0.2641 - acc: 0.7359 - val_loss: 0.2704 - val_acc: 0.7296\n",
      "Epoch 20/20\n",
      "5634/5634 [==============================] - 1s 92us/step - loss: 0.2641 - acc: 0.7359 - val_loss: 0.2704 - val_acc: 0.7296\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x27264a34b70>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train baseline model with 24 input nodes, 1 hidden layer of sixteen nodes, and 1 output node\n",
    "# See adjacent comments for manual tuning\n",
    "\n",
    "# Global hyperparameters\n",
    "inputs = X.shape[1]\n",
    "epochs = 20  # increasing to 50 did not improve acc\n",
    "batch_size = 80  # baseline is 30; increase to 64 did not improve acc\n",
    "# Create model\n",
    "model = Sequential()\n",
    "model.add(Dense(24, activation='relu', input_shape=(inputs,)))  # increasing nodes to 30 or 64 did not improve acc\n",
    "# model.add(Dropout(0.2))  # addition of this layer at 0.1 rate caused no change; same for 0.2 rate\n",
    "model.add(Dense(16, activation='relu'))  # 16 nodes: val_loss: 0.2704 - val_acc: 0.7296; not improved w 24 nodes\n",
    "# model.add(Dense(11, activation='relu'))  adding this layer did not improve accuracy, so try increasing prev nodes\n",
    "model.add(Dense(1, activation='sigmoid'))  # softmax dramatically worsened acc; relu caused no change\n",
    "# Compile\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "# binary_crossentropy loss caused no change; sgd optimizer, tuned, caused no improvement\n",
    "# Fit model\n",
    "model.summary()\n",
    "model.fit(X, y, validation_split=0.2, epochs=epochs, batch_size=batch_size)  # val_split at 0.1 caused slight decr\n",
    "# validation_split at 0.33 also caused slight loss of acc\n",
    "# scores = model.evaluate()\n",
    "# print(f'{model.metrics[0]}: {scores[1]*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "5634/5634 [==============================] - 9s 2ms/step - loss: 4.2483 - acc: 0.7346\n",
      "Epoch 2/20\n",
      "5634/5634 [==============================] - 2s 386us/step - loss: 4.2780 - acc: 0.7345\n",
      "Epoch 3/20\n",
      "5634/5634 [==============================] - 2s 386us/step - loss: 4.2772 - acc: 0.7345\n",
      "Epoch 4/20\n",
      "5634/5634 [==============================] - 2s 380us/step - loss: 4.2703 - acc: 0.7334\n",
      "Epoch 5/20\n",
      "5634/5634 [==============================] - 2s 400us/step - loss: 4.2949 - acc: 0.7299\n",
      "Epoch 6/20\n",
      "5634/5634 [==============================] - 3s 450us/step - loss: 4.2596 - acc: 0.7332\n",
      "Epoch 7/20\n",
      "5634/5634 [==============================] - 2s 398us/step - loss: 4.2783 - acc: 0.7345\n",
      "Epoch 8/20\n",
      "5634/5634 [==============================] - 2s 398us/step - loss: 4.2775 - acc: 0.7345\n",
      "Epoch 9/20\n",
      "5634/5634 [==============================] - 2s 404us/step - loss: 4.2768 - acc: 0.7345\n",
      "Epoch 10/20\n",
      "5634/5634 [==============================] - 2s 392us/step - loss: 4.2551 - acc: 0.7330\n",
      "Epoch 11/20\n",
      "5634/5634 [==============================] - 2s 408us/step - loss: 4.2024 - acc: 0.7370\n",
      "Epoch 12/20\n",
      "5634/5634 [==============================] - 2s 383us/step - loss: 4.2259 - acc: 0.7339\n",
      "Epoch 13/20\n",
      "5634/5634 [==============================] - 2s 384us/step - loss: 4.2127 - acc: 0.7357\n",
      "Epoch 14/20\n",
      "5634/5634 [==============================] - 2s 394us/step - loss: 4.2550 - acc: 0.7352\n",
      "Epoch 15/20\n",
      "5634/5634 [==============================] - 2s 430us/step - loss: 4.2781 - acc: 0.7345\n",
      "Epoch 16/20\n",
      "5634/5634 [==============================] - 2s 406us/step - loss: 4.2584 - acc: 0.7350\n",
      "Epoch 17/20\n",
      "5634/5634 [==============================] - 2s 394us/step - loss: 4.2366 - acc: 0.7359\n",
      "Epoch 18/20\n",
      "5634/5634 [==============================] - 2s 415us/step - loss: 4.2780 - acc: 0.7345\n",
      "Epoch 19/20\n",
      "5634/5634 [==============================] - 3s 528us/step - loss: 4.2774 - acc: 0.7345\n",
      "Epoch 20/20\n",
      "5634/5634 [==============================] - 2s 405us/step - loss: 4.2313 - acc: 0.7350\n",
      "1409/1409 [==============================] - 3s 2ms/step\n",
      "5634/5634 [==============================] - 2s 288us/step\n",
      "Epoch 1/20\n",
      "5634/5634 [==============================] - ETA: 0s - loss: 4.0049 - acc: 0.733 - 9s 2ms/step - loss: 4.0151 - acc: 0.7330\n",
      "Epoch 2/20\n",
      "5634/5634 [==============================] - 2s 392us/step - loss: 3.7364 - acc: 0.7300\n",
      "Epoch 3/20\n",
      "5634/5634 [==============================] - 2s 403us/step - loss: 3.1934 - acc: 0.7297\n",
      "Epoch 4/20\n",
      "5634/5634 [==============================] - 2s 407us/step - loss: 3.7949 - acc: 0.7233\n",
      "Epoch 5/20\n",
      "5634/5634 [==============================] - 2s 412us/step - loss: 2.5609 - acc: 0.7215\n",
      "Epoch 6/20\n",
      "5634/5634 [==============================] - 2s 414us/step - loss: 1.2301 - acc: 0.7375\n",
      "Epoch 7/20\n",
      "5634/5634 [==============================] - 3s 494us/step - loss: 0.9593 - acc: 0.7442\n",
      "Epoch 8/20\n",
      "5634/5634 [==============================] - 2s 425us/step - loss: 0.9258 - acc: 0.7286\n",
      "Epoch 9/20\n",
      "5634/5634 [==============================] - 2s 402us/step - loss: 0.7607 - acc: 0.7421\n",
      "Epoch 10/20\n",
      "5634/5634 [==============================] - 2s 404us/step - loss: 0.7642 - acc: 0.7403\n",
      "Epoch 11/20\n",
      "5634/5634 [==============================] - 2s 413us/step - loss: 0.6986 - acc: 0.7492\n",
      "Epoch 12/20\n",
      "5634/5634 [==============================] - 2s 382us/step - loss: 0.6561 - acc: 0.7497\n",
      "Epoch 13/20\n",
      "5634/5634 [==============================] - 2s 374us/step - loss: 0.5257 - acc: 0.7675\n",
      "Epoch 14/20\n",
      "5634/5634 [==============================] - 2s 373us/step - loss: 0.6408 - acc: 0.7517\n",
      "Epoch 15/20\n",
      "5634/5634 [==============================] - 2s 390us/step - loss: 0.6369 - acc: 0.7467\n",
      "Epoch 16/20\n",
      "5634/5634 [==============================] - 2s 403us/step - loss: 0.5754 - acc: 0.7574\n",
      "Epoch 17/20\n",
      "5634/5634 [==============================] - 3s 446us/step - loss: 0.5395 - acc: 0.7622\n",
      "Epoch 18/20\n",
      "5634/5634 [==============================] - 2s 437us/step - loss: 0.5436 - acc: 0.7583\n",
      "Epoch 19/20\n",
      "5634/5634 [==============================] - 3s 546us/step - loss: 0.6460 - acc: 0.7419\n",
      "Epoch 20/20\n",
      "5634/5634 [==============================] - 2s 415us/step - loss: 0.5867 - acc: 0.7600\n",
      "1409/1409 [==============================] - 3s 2ms/step\n",
      "5634/5634 [==============================] - 2s 296us/step\n",
      "Epoch 1/20\n",
      "5634/5634 [==============================] - 9s 2ms/step - loss: 5.3934 - acc: 0.6587\n",
      "Epoch 2/20\n",
      "5634/5634 [==============================] - 2s 395us/step - loss: 4.2840 - acc: 0.7339\n",
      "Epoch 3/20\n",
      "5634/5634 [==============================] - 2s 384us/step - loss: 4.2496 - acc: 0.7327\n",
      "Epoch 4/20\n",
      "5634/5634 [==============================] - 2s 399us/step - loss: 4.0641 - acc: 0.7283\n",
      "Epoch 5/20\n",
      "5634/5634 [==============================] - 2s 412us/step - loss: 3.4562 - acc: 0.7180\n",
      "Epoch 6/20\n",
      "5634/5634 [==============================] - 2s 417us/step - loss: 3.6695 - acc: 0.7245\n",
      "Epoch 7/20\n",
      "5634/5634 [==============================] - 2s 417us/step - loss: 3.9307 - acc: 0.7252\n",
      "Epoch 8/20\n",
      "5634/5634 [==============================] - 2s 413us/step - loss: 3.0589 - acc: 0.7119\n",
      "Epoch 9/20\n",
      "5634/5634 [==============================] - 2s 441us/step - loss: 0.8334 - acc: 0.7268\n",
      "Epoch 10/20\n",
      "5634/5634 [==============================] - 3s 529us/step - loss: 0.6812 - acc: 0.7361\n",
      "Epoch 11/20\n",
      "5634/5634 [==============================] - 3s 446us/step - loss: 0.6716 - acc: 0.7400\n",
      "Epoch 12/20\n",
      "5634/5634 [==============================] - 3s 467us/step - loss: 0.6465 - acc: 0.7449\n",
      "Epoch 13/20\n",
      "5634/5634 [==============================] - 2s 411us/step - loss: 0.6237 - acc: 0.7513\n",
      "Epoch 14/20\n",
      "5634/5634 [==============================] - 2s 406us/step - loss: 0.5732 - acc: 0.7609\n",
      "Epoch 15/20\n",
      "5634/5634 [==============================] - 2s 414us/step - loss: 0.6042 - acc: 0.7556\n",
      "Epoch 16/20\n",
      "5634/5634 [==============================] - 2s 406us/step - loss: 0.5655 - acc: 0.7561\n",
      "Epoch 17/20\n",
      "5634/5634 [==============================] - 2s 397us/step - loss: 0.5483 - acc: 0.7606\n",
      "Epoch 18/20\n",
      "5634/5634 [==============================] - 2s 430us/step - loss: 0.5776 - acc: 0.7593\n",
      "Epoch 19/20\n",
      "5634/5634 [==============================] - 3s 461us/step - loss: 0.6228 - acc: 0.7559\n",
      "Epoch 20/20\n",
      "5634/5634 [==============================] - 2s 433us/step - loss: 0.5883 - acc: 0.7567\n",
      "1409/1409 [==============================] - 3s 2ms/step\n",
      "5634/5634 [==============================] - 2s 353us/step\n",
      "Epoch 1/20\n",
      "5635/5635 [==============================] - 10s 2ms/step - loss: 5.4859 - acc: 0.6539\n",
      "Epoch 2/20\n",
      "5635/5635 [==============================] - 2s 418us/step - loss: 4.2517 - acc: 0.7359\n",
      "Epoch 3/20\n",
      "5635/5635 [==============================] - 3s 464us/step - loss: 4.2511 - acc: 0.7359\n",
      "Epoch 4/20\n",
      "5635/5635 [==============================] - 2s 411us/step - loss: 4.2505 - acc: 0.7358\n",
      "Epoch 5/20\n",
      "5635/5635 [==============================] - 2s 435us/step - loss: 4.2498 - acc: 0.7356\n",
      "Epoch 6/20\n",
      "5635/5635 [==============================] - 3s 453us/step - loss: 4.2487 - acc: 0.7359\n",
      "Epoch 7/20\n",
      "5635/5635 [==============================] - 3s 560us/step - loss: 4.2485 - acc: 0.7356\n",
      "Epoch 8/20\n",
      "5635/5635 [==============================] - 2s 440us/step - loss: 4.2384 - acc: 0.7352\n",
      "Epoch 9/20\n",
      "5635/5635 [==============================] - 2s 438us/step - loss: 4.2103 - acc: 0.7340\n",
      "Epoch 10/20\n",
      "5635/5635 [==============================] - 2s 417us/step - loss: 4.2148 - acc: 0.7365\n",
      "Epoch 11/20\n",
      "5635/5635 [==============================] - 2s 420us/step - loss: 4.2519 - acc: 0.7350\n",
      "Epoch 12/20\n",
      "5635/5635 [==============================] - 2s 423us/step - loss: 4.2154 - acc: 0.7310\n",
      "Epoch 13/20\n",
      "5635/5635 [==============================] - 2s 379us/step - loss: 4.2375 - acc: 0.7317\n",
      "Epoch 14/20\n",
      "5635/5635 [==============================] - 2s 405us/step - loss: 4.2531 - acc: 0.7361\n",
      "Epoch 15/20\n",
      "5635/5635 [==============================] - 2s 419us/step - loss: 4.2529 - acc: 0.7361\n",
      "Epoch 16/20\n",
      "5635/5635 [==============================] - 2s 418us/step - loss: 4.2526 - acc: 0.7361\n",
      "Epoch 17/20\n",
      "5635/5635 [==============================] - 2s 424us/step - loss: 4.2462 - acc: 0.7356\n",
      "Epoch 18/20\n",
      "5635/5635 [==============================] - 3s 453us/step - loss: 4.2502 - acc: 0.7361\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5635/5635 [==============================] - 2s 442us/step - loss: 4.1515 - acc: 0.7381\n",
      "Epoch 20/20\n",
      "5635/5635 [==============================] - 3s 450us/step - loss: 4.2161 - acc: 0.7361\n",
      "1408/1408 [==============================] - 4s 3ms/step\n",
      "5635/5635 [==============================] - 2s 328us/step\n",
      "Epoch 1/20\n",
      "5635/5635 [==============================] - 9s 2ms/step - loss: 4.2196 - acc: 0.7343\n",
      "Epoch 2/20\n",
      "5635/5635 [==============================] - 2s 417us/step - loss: 4.2565 - acc: 0.7358\n",
      "Epoch 3/20\n",
      "5635/5635 [==============================] - 2s 415us/step - loss: 4.2549 - acc: 0.7358\n",
      "Epoch 4/20\n",
      "5635/5635 [==============================] - 2s 413us/step - loss: 4.2540 - acc: 0.7350\n",
      "Epoch 5/20\n",
      "5635/5635 [==============================] - 2s 414us/step - loss: 10.4898 - acc: 0.3382\n",
      "Epoch 6/20\n",
      "5635/5635 [==============================] - 2s 417us/step - loss: 6.1829 - acc: 0.6131\n",
      "Epoch 7/20\n",
      "5635/5635 [==============================] - 2s 433us/step - loss: 4.2591 - acc: 0.7358\n",
      "Epoch 8/20\n",
      "5635/5635 [==============================] - 2s 412us/step - loss: 4.2591 - acc: 0.7358\n",
      "Epoch 9/20\n",
      "5635/5635 [==============================] - 2s 410us/step - loss: 4.2591 - acc: 0.7358\n",
      "Epoch 10/20\n",
      "5635/5635 [==============================] - 2s 412us/step - loss: 4.2591 - acc: 0.7358\n",
      "Epoch 11/20\n",
      "5635/5635 [==============================] - 2s 402us/step - loss: 4.2591 - acc: 0.7358\n",
      "Epoch 12/20\n",
      "5635/5635 [==============================] - 2s 402us/step - loss: 4.2591 - acc: 0.7358\n",
      "Epoch 13/20\n",
      "5635/5635 [==============================] - 2s 406us/step - loss: 4.2591 - acc: 0.7358\n",
      "Epoch 14/20\n",
      "5635/5635 [==============================] - 2s 417us/step - loss: 4.2591 - acc: 0.7358\n",
      "Epoch 15/20\n",
      "5635/5635 [==============================] - 2s 419us/step - loss: 4.2591 - acc: 0.7358\n",
      "Epoch 16/20\n",
      "5635/5635 [==============================] - 2s 406us/step - loss: 4.2591 - acc: 0.7358\n",
      "Epoch 17/20\n",
      "5635/5635 [==============================] - 2s 403us/step - loss: 4.2591 - acc: 0.7358\n",
      "Epoch 18/20\n",
      "5635/5635 [==============================] - 2s 405us/step - loss: 4.2591 - acc: 0.7358\n",
      "Epoch 19/20\n",
      "5635/5635 [==============================] - 2s 410us/step - loss: 4.2591 - acc: 0.7358\n",
      "Epoch 20/20\n",
      "5635/5635 [==============================] - 3s 521us/step - loss: 4.2591 - acc: 0.7358\n",
      "1408/1408 [==============================] - 3s 2ms/step\n",
      "5635/5635 [==============================] - 2s 309us/step\n",
      "Epoch 1/20\n",
      "5634/5634 [==============================] - 8s 2ms/step - loss: 3.6837 - acc: 0.7286\n",
      "Epoch 2/20\n",
      "5634/5634 [==============================] - 1s 203us/step - loss: 3.9407 - acc: 0.7256\n",
      "Epoch 3/20\n",
      "5634/5634 [==============================] - 1s 197us/step - loss: 4.1847 - acc: 0.7334\n",
      "Epoch 4/20\n",
      "5634/5634 [==============================] - 1s 210us/step - loss: 3.5203 - acc: 0.7169\n",
      "Epoch 5/20\n",
      "5634/5634 [==============================] - 1s 211us/step - loss: 1.8093 - acc: 0.7016\n",
      "Epoch 6/20\n",
      "5634/5634 [==============================] - 1s 204us/step - loss: 0.8075 - acc: 0.7375\n",
      "Epoch 7/20\n",
      "5634/5634 [==============================] - 1s 211us/step - loss: 1.6002 - acc: 0.7165\n",
      "Epoch 8/20\n",
      "5634/5634 [==============================] - 1s 210us/step - loss: 0.9068 - acc: 0.7320\n",
      "Epoch 9/20\n",
      "5634/5634 [==============================] - 1s 206us/step - loss: 0.8690 - acc: 0.7355\n",
      "Epoch 10/20\n",
      "5634/5634 [==============================] - 1s 203us/step - loss: 0.6391 - acc: 0.7614\n",
      "Epoch 11/20\n",
      "5634/5634 [==============================] - 1s 207us/step - loss: 0.6317 - acc: 0.7464\n",
      "Epoch 12/20\n",
      "5634/5634 [==============================] - 1s 202us/step - loss: 0.6652 - acc: 0.7439\n",
      "Epoch 13/20\n",
      "5634/5634 [==============================] - 1s 216us/step - loss: 0.7943 - acc: 0.7279\n",
      "Epoch 14/20\n",
      "5634/5634 [==============================] - 1s 217us/step - loss: 0.6758 - acc: 0.7430\n",
      "Epoch 15/20\n",
      "5634/5634 [==============================] - 1s 217us/step - loss: 0.9503 - acc: 0.7240\n",
      "Epoch 16/20\n",
      "5634/5634 [==============================] - 1s 214us/step - loss: 0.8028 - acc: 0.7377\n",
      "Epoch 17/20\n",
      "5634/5634 [==============================] - 1s 196us/step - loss: 0.7080 - acc: 0.7535\n",
      "Epoch 18/20\n",
      "5634/5634 [==============================] - 1s 195us/step - loss: 0.6618 - acc: 0.7512\n",
      "Epoch 19/20\n",
      "5634/5634 [==============================] - 1s 195us/step - loss: 0.7733 - acc: 0.7389\n",
      "Epoch 20/20\n",
      "5634/5634 [==============================] - 1s 198us/step - loss: 0.6995 - acc: 0.7467\n",
      "1409/1409 [==============================] - 3s 2ms/step\n",
      "5634/5634 [==============================] - 1s 157us/step\n",
      "Epoch 1/20\n",
      "5634/5634 [==============================] - 9s 2ms/step - loss: 4.0980 - acc: 0.7265\n",
      "Epoch 2/20\n",
      "5634/5634 [==============================] - 1s 247us/step - loss: 4.0972 - acc: 0.7288\n",
      "Epoch 3/20\n",
      "5634/5634 [==============================] - 1s 204us/step - loss: 3.1265 - acc: 0.7052\n",
      "Epoch 4/20\n",
      "5634/5634 [==============================] - 1s 211us/step - loss: 1.2458 - acc: 0.7244\n",
      "Epoch 5/20\n",
      "5634/5634 [==============================] - 1s 233us/step - loss: 0.8310 - acc: 0.7297\n",
      "Epoch 6/20\n",
      "5634/5634 [==============================] - 1s 221us/step - loss: 0.7275 - acc: 0.7377\n",
      "Epoch 7/20\n",
      "5634/5634 [==============================] - 1s 206us/step - loss: 0.6456 - acc: 0.7506\n",
      "Epoch 8/20\n",
      "5634/5634 [==============================] - 1s 214us/step - loss: 0.6060 - acc: 0.7552\n",
      "Epoch 9/20\n",
      "5634/5634 [==============================] - 1s 201us/step - loss: 0.9139 - acc: 0.7332\n",
      "Epoch 10/20\n",
      "5634/5634 [==============================] - 1s 205us/step - loss: 0.6721 - acc: 0.7451\n",
      "Epoch 11/20\n",
      "5634/5634 [==============================] - 1s 213us/step - loss: 0.6850 - acc: 0.7414\n",
      "Epoch 12/20\n",
      "5634/5634 [==============================] - 1s 214us/step - loss: 0.5517 - acc: 0.7682\n",
      "Epoch 13/20\n",
      "5634/5634 [==============================] - 1s 205us/step - loss: 0.8135 - acc: 0.7291\n",
      "Epoch 14/20\n",
      "5634/5634 [==============================] - 1s 202us/step - loss: 0.6220 - acc: 0.7513\n",
      "Epoch 15/20\n",
      "5634/5634 [==============================] - 1s 205us/step - loss: 0.6734 - acc: 0.7455\n",
      "Epoch 16/20\n",
      "5634/5634 [==============================] - 1s 216us/step - loss: 0.7145 - acc: 0.7396 1s - loss: \n",
      "Epoch 17/20\n",
      "5634/5634 [==============================] - 1s 216us/step - loss: 0.6154 - acc: 0.7586\n",
      "Epoch 18/20\n",
      "5634/5634 [==============================] - 1s 211us/step - loss: 0.6376 - acc: 0.7584\n",
      "Epoch 19/20\n",
      "5634/5634 [==============================] - 1s 195us/step - loss: 0.7997 - acc: 0.7199\n",
      "Epoch 20/20\n",
      "5634/5634 [==============================] - 1s 195us/step - loss: 0.6578 - acc: 0.7457\n",
      "1409/1409 [==============================] - 3s 2ms/step\n",
      "5634/5634 [==============================] - 1s 154us/step\n",
      "Epoch 1/20\n",
      "5634/5634 [==============================] - 9s 2ms/step - loss: 6.7264 - acc: 0.5749\n",
      "Epoch 2/20\n",
      "5634/5634 [==============================] - 1s 200us/step - loss: 4.2851 - acc: 0.7339\n",
      "Epoch 3/20\n",
      "5634/5634 [==============================] - 1s 200us/step - loss: 4.2848 - acc: 0.7339\n",
      "Epoch 4/20\n",
      "5634/5634 [==============================] - 1s 206us/step - loss: 4.2843 - acc: 0.7339\n",
      "Epoch 5/20\n",
      "5634/5634 [==============================] - 1s 202us/step - loss: 4.2839 - acc: 0.7339\n",
      "Epoch 6/20\n",
      "5634/5634 [==============================] - 1s 207us/step - loss: 4.2833 - acc: 0.7339\n",
      "Epoch 7/20\n",
      "5634/5634 [==============================] - 1s 195us/step - loss: 4.2208 - acc: 0.7345\n",
      "Epoch 8/20\n",
      "5634/5634 [==============================] - 1s 203us/step - loss: 3.9474 - acc: 0.7343\n",
      "Epoch 9/20\n",
      "5634/5634 [==============================] - 1s 200us/step - loss: 3.7161 - acc: 0.7229\n",
      "Epoch 10/20\n",
      "5634/5634 [==============================] - 1s 200us/step - loss: 3.7177 - acc: 0.7295\n",
      "Epoch 11/20\n",
      "5634/5634 [==============================] - 1s 206us/step - loss: 2.4621 - acc: 0.7201\n",
      "Epoch 12/20\n",
      "5634/5634 [==============================] - 1s 254us/step - loss: 1.2883 - acc: 0.7309\n",
      "Epoch 13/20\n",
      "5634/5634 [==============================] - 1s 259us/step - loss: 0.8035 - acc: 0.7416\n",
      "Epoch 14/20\n",
      "5634/5634 [==============================] - 1s 223us/step - loss: 0.7613 - acc: 0.7460\n",
      "Epoch 15/20\n",
      "5634/5634 [==============================] - 1s 254us/step - loss: 0.5765 - acc: 0.7634\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5634/5634 [==============================] - 1s 209us/step - loss: 0.5601 - acc: 0.7646\n",
      "Epoch 17/20\n",
      "5634/5634 [==============================] - 1s 244us/step - loss: 0.6778 - acc: 0.7467\n",
      "Epoch 18/20\n",
      "5634/5634 [==============================] - 2s 315us/step - loss: 0.6291 - acc: 0.7529\n",
      "Epoch 19/20\n",
      "5634/5634 [==============================] - 2s 290us/step - loss: 0.6158 - acc: 0.7542\n",
      "Epoch 20/20\n",
      "5634/5634 [==============================] - 1s 244us/step - loss: 0.5056 - acc: 0.7780\n",
      "1409/1409 [==============================] - 3s 2ms/step\n",
      "5634/5634 [==============================] - 1s 190us/step\n",
      "Epoch 1/20\n",
      "5635/5635 [==============================] - 9s 2ms/step - loss: 4.2535 - acc: 0.7356\n",
      "Epoch 2/20\n",
      "5635/5635 [==============================] - 1s 208us/step - loss: 4.2150 - acc: 0.7347\n",
      "Epoch 3/20\n",
      "5635/5635 [==============================] - 1s 228us/step - loss: 4.1803 - acc: 0.7375\n",
      "Epoch 4/20\n",
      "5635/5635 [==============================] - 1s 230us/step - loss: 4.1527 - acc: 0.7363\n",
      "Epoch 5/20\n",
      "5635/5635 [==============================] - 1s 225us/step - loss: 4.1483 - acc: 0.7379\n",
      "Epoch 6/20\n",
      "5635/5635 [==============================] - 1s 215us/step - loss: 4.1574 - acc: 0.7370\n",
      "Epoch 7/20\n",
      "5635/5635 [==============================] - 1s 207us/step - loss: 4.1684 - acc: 0.7374\n",
      "Epoch 8/20\n",
      "5635/5635 [==============================] - 1s 201us/step - loss: 4.1561 - acc: 0.7375\n",
      "Epoch 9/20\n",
      "5635/5635 [==============================] - 1s 265us/step - loss: 4.1409 - acc: 0.7366\n",
      "Epoch 10/20\n",
      "5635/5635 [==============================] - 1s 240us/step - loss: 4.1332 - acc: 0.7388 1s - loss:\n",
      "Epoch 11/20\n",
      "5635/5635 [==============================] - 1s 212us/step - loss: 4.1122 - acc: 0.7397\n",
      "Epoch 12/20\n",
      "5635/5635 [==============================] - 1s 217us/step - loss: 4.2239 - acc: 0.7354\n",
      "Epoch 13/20\n",
      "5635/5635 [==============================] - 1s 207us/step - loss: 4.2504 - acc: 0.7361\n",
      "Epoch 14/20\n",
      "5635/5635 [==============================] - 1s 196us/step - loss: 4.2502 - acc: 0.7361\n",
      "Epoch 15/20\n",
      "5635/5635 [==============================] - 1s 207us/step - loss: 4.2500 - acc: 0.7361\n",
      "Epoch 16/20\n",
      "5635/5635 [==============================] - 1s 206us/step - loss: 4.2522 - acc: 0.7354\n",
      "Epoch 17/20\n",
      "5635/5635 [==============================] - 1s 204us/step - loss: 4.1868 - acc: 0.7350\n",
      "Epoch 18/20\n",
      "5635/5635 [==============================] - 1s 200us/step - loss: 4.1603 - acc: 0.7363\n",
      "Epoch 19/20\n",
      "5635/5635 [==============================] - 1s 202us/step - loss: 4.1721 - acc: 0.7379\n",
      "Epoch 20/20\n",
      "5635/5635 [==============================] - 1s 202us/step - loss: 4.2505 - acc: 0.7361\n",
      "1408/1408 [==============================] - 4s 3ms/step\n",
      "5635/5635 [==============================] - 1s 173us/step\n",
      "Epoch 1/20\n",
      "5635/5635 [==============================] - 9s 2ms/step - loss: 4.2545 - acc: 0.7356\n",
      "Epoch 2/20\n",
      "5635/5635 [==============================] - 1s 224us/step - loss: 4.1284 - acc: 0.7338\n",
      "Epoch 3/20\n",
      "5635/5635 [==============================] - 1s 256us/step - loss: 4.2112 - acc: 0.7239\n",
      "Epoch 4/20\n",
      "5635/5635 [==============================] - 1s 247us/step - loss: 3.8572 - acc: 0.7303\n",
      "Epoch 5/20\n",
      "5635/5635 [==============================] - 1s 209us/step - loss: 3.5979 - acc: 0.7287\n",
      "Epoch 6/20\n",
      "5635/5635 [==============================] - 1s 204us/step - loss: 3.2381 - acc: 0.7338\n",
      "Epoch 7/20\n",
      "5635/5635 [==============================] - 1s 209us/step - loss: 2.3478 - acc: 0.7200\n",
      "Epoch 8/20\n",
      "5635/5635 [==============================] - 1s 214us/step - loss: 0.9550 - acc: 0.7370\n",
      "Epoch 9/20\n",
      "5635/5635 [==============================] - 1s 213us/step - loss: 0.7129 - acc: 0.7386\n",
      "Epoch 10/20\n",
      "5635/5635 [==============================] - 1s 227us/step - loss: 0.9181 - acc: 0.7335\n",
      "Epoch 11/20\n",
      "5635/5635 [==============================] - 1s 243us/step - loss: 0.6620 - acc: 0.7482\n",
      "Epoch 12/20\n",
      "5635/5635 [==============================] - 1s 221us/step - loss: 0.6083 - acc: 0.7510\n",
      "Epoch 13/20\n",
      "5635/5635 [==============================] - 1s 217us/step - loss: 0.5594 - acc: 0.7583\n",
      "Epoch 14/20\n",
      "5635/5635 [==============================] - 1s 221us/step - loss: 0.5566 - acc: 0.7546\n",
      "Epoch 15/20\n",
      "5635/5635 [==============================] - 1s 225us/step - loss: 0.5681 - acc: 0.7551\n",
      "Epoch 16/20\n",
      "5635/5635 [==============================] - 1s 233us/step - loss: 0.6135 - acc: 0.7565\n",
      "Epoch 17/20\n",
      "5635/5635 [==============================] - 1s 200us/step - loss: 0.5612 - acc: 0.7578\n",
      "Epoch 18/20\n",
      "5635/5635 [==============================] - 1s 204us/step - loss: 0.5814 - acc: 0.7524\n",
      "Epoch 19/20\n",
      "5635/5635 [==============================] - 1s 229us/step - loss: 0.5986 - acc: 0.7485\n",
      "Epoch 20/20\n",
      "5635/5635 [==============================] - 1s 245us/step - loss: 0.5594 - acc: 0.7587\n",
      "1408/1408 [==============================] - 3s 2ms/step\n",
      "5635/5635 [==============================] - 1s 189us/step\n",
      "Epoch 1/20\n",
      "5634/5634 [==============================] - 8s 2ms/step - loss: 4.2761 - acc: 0.7345\n",
      "Epoch 2/20\n",
      "5634/5634 [==============================] - 1s 146us/step - loss: 4.1549 - acc: 0.7346\n",
      "Epoch 3/20\n",
      "5634/5634 [==============================] - 1s 153us/step - loss: 3.0787 - acc: 0.7043\n",
      "Epoch 4/20\n",
      "5634/5634 [==============================] - 1s 156us/step - loss: 0.9254 - acc: 0.6997\n",
      "Epoch 5/20\n",
      "5634/5634 [==============================] - 1s 182us/step - loss: 0.5610 - acc: 0.7366\n",
      "Epoch 6/20\n",
      "5634/5634 [==============================] - 1s 157us/step - loss: 0.5366 - acc: 0.7485\n",
      "Epoch 7/20\n",
      "5634/5634 [==============================] - 1s 148us/step - loss: 0.4790 - acc: 0.7650\n",
      "Epoch 8/20\n",
      "5634/5634 [==============================] - 1s 138us/step - loss: 0.4996 - acc: 0.7593\n",
      "Epoch 9/20\n",
      "5634/5634 [==============================] - 1s 173us/step - loss: 0.5197 - acc: 0.7458\n",
      "Epoch 10/20\n",
      "5634/5634 [==============================] - 1s 159us/step - loss: 0.4882 - acc: 0.7620\n",
      "Epoch 11/20\n",
      "5634/5634 [==============================] - 1s 145us/step - loss: 0.4838 - acc: 0.7602 0s - loss: 0.4972 -\n",
      "Epoch 12/20\n",
      "5634/5634 [==============================] - 1s 117us/step - loss: 0.4710 - acc: 0.7691\n",
      "Epoch 13/20\n",
      "5634/5634 [==============================] - 1s 154us/step - loss: 0.4699 - acc: 0.7670 0s - loss: 0.4763 -\n",
      "Epoch 14/20\n",
      "5634/5634 [==============================] - 1s 129us/step - loss: 0.4709 - acc: 0.7694\n",
      "Epoch 15/20\n",
      "5634/5634 [==============================] - 1s 130us/step - loss: 0.4924 - acc: 0.7595\n",
      "Epoch 16/20\n",
      "5634/5634 [==============================] - 1s 140us/step - loss: 0.4855 - acc: 0.7629\n",
      "Epoch 17/20\n",
      "5634/5634 [==============================] - 1s 140us/step - loss: 0.4753 - acc: 0.7655\n",
      "Epoch 18/20\n",
      "5634/5634 [==============================] - 1s 122us/step - loss: 0.4602 - acc: 0.7758\n",
      "Epoch 19/20\n",
      "5634/5634 [==============================] - 1s 134us/step - loss: 0.4694 - acc: 0.7687\n",
      "Epoch 20/20\n",
      "5634/5634 [==============================] - 1s 138us/step - loss: 0.4955 - acc: 0.7602\n",
      "1409/1409 [==============================] - 4s 3ms/step\n",
      "5634/5634 [==============================] - 0s 78us/step\n",
      "Epoch 1/20\n",
      "5634/5634 [==============================] - 8s 1ms/step - loss: 4.3264 - acc: 0.7197\n",
      "Epoch 2/20\n",
      "5634/5634 [==============================] - 1s 102us/step - loss: 3.9933 - acc: 0.7286\n",
      "Epoch 3/20\n",
      "5634/5634 [==============================] - 1s 118us/step - loss: 3.8550 - acc: 0.7354\n",
      "Epoch 4/20\n",
      "5634/5634 [==============================] - 1s 117us/step - loss: 3.7356 - acc: 0.7338\n",
      "Epoch 5/20\n",
      "5634/5634 [==============================] - 1s 110us/step - loss: 3.7942 - acc: 0.7270\n",
      "Epoch 6/20\n",
      "5634/5634 [==============================] - 1s 105us/step - loss: 3.9794 - acc: 0.6816\n",
      "Epoch 7/20\n",
      "5634/5634 [==============================] - 1s 116us/step - loss: 4.0794 - acc: 0.7341\n",
      "Epoch 8/20\n",
      "5634/5634 [==============================] - 1s 122us/step - loss: 3.6779 - acc: 0.7405\n",
      "Epoch 9/20\n",
      "5634/5634 [==============================] - 1s 107us/step - loss: 3.8532 - acc: 0.7258\n",
      "Epoch 10/20\n",
      "5634/5634 [==============================] - 1s 113us/step - loss: 4.1421 - acc: 0.7370\n",
      "Epoch 11/20\n",
      "5634/5634 [==============================] - 1s 114us/step - loss: 4.0938 - acc: 0.7322\n",
      "Epoch 12/20\n",
      "5634/5634 [==============================] - 1s 117us/step - loss: 3.9388 - acc: 0.7306\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5634/5634 [==============================] - 1s 112us/step - loss: 3.6671 - acc: 0.7387\n",
      "Epoch 14/20\n",
      "5634/5634 [==============================] - 1s 105us/step - loss: 3.6594 - acc: 0.7355\n",
      "Epoch 15/20\n",
      "5634/5634 [==============================] - 1s 109us/step - loss: 3.7281 - acc: 0.7133\n",
      "Epoch 16/20\n",
      "5634/5634 [==============================] - 1s 104us/step - loss: 4.1209 - acc: 0.7338\n",
      "Epoch 17/20\n",
      "5634/5634 [==============================] - 1s 103us/step - loss: 3.9726 - acc: 0.7288\n",
      "Epoch 18/20\n",
      "5634/5634 [==============================] - 1s 128us/step - loss: 4.3034 - acc: 0.7329\n",
      "Epoch 19/20\n",
      "5634/5634 [==============================] - 1s 134us/step - loss: 4.3031 - acc: 0.7329\n",
      "Epoch 20/20\n",
      "5634/5634 [==============================] - 1s 114us/step - loss: 4.3025 - acc: 0.7329\n",
      "1409/1409 [==============================] - 4s 3ms/step\n",
      "5634/5634 [==============================] - 1s 99us/step\n",
      "Epoch 1/20\n",
      "5634/5634 [==============================] - 9s 2ms/step - loss: 4.2871 - acc: 0.7339\n",
      "Epoch 2/20\n",
      "5634/5634 [==============================] - 1s 133us/step - loss: 4.2868 - acc: 0.7339\n",
      "Epoch 3/20\n",
      "5634/5634 [==============================] - 1s 123us/step - loss: 4.2865 - acc: 0.7339\n",
      "Epoch 4/20\n",
      "5634/5634 [==============================] - 1s 137us/step - loss: 4.2868 - acc: 0.7339\n",
      "Epoch 5/20\n",
      "5634/5634 [==============================] - 1s 115us/step - loss: 4.2861 - acc: 0.7339\n",
      "Epoch 6/20\n",
      "5634/5634 [==============================] - 1s 116us/step - loss: 4.2862 - acc: 0.7339\n",
      "Epoch 7/20\n",
      "5634/5634 [==============================] - 1s 109us/step - loss: 4.2862 - acc: 0.7339\n",
      "Epoch 8/20\n",
      "5634/5634 [==============================] - 1s 108us/step - loss: 4.2860 - acc: 0.7339\n",
      "Epoch 9/20\n",
      "5634/5634 [==============================] - 1s 116us/step - loss: 4.2864 - acc: 0.7339\n",
      "Epoch 10/20\n",
      "5634/5634 [==============================] - 1s 107us/step - loss: 4.2867 - acc: 0.7338\n",
      "Epoch 11/20\n",
      "5634/5634 [==============================] - 1s 107us/step - loss: 4.2862 - acc: 0.7338\n",
      "Epoch 12/20\n",
      "5634/5634 [==============================] - 1s 107us/step - loss: 4.2860 - acc: 0.7339\n",
      "Epoch 13/20\n",
      "5634/5634 [==============================] - 1s 108us/step - loss: 4.2860 - acc: 0.7339\n",
      "Epoch 14/20\n",
      "5634/5634 [==============================] - 1s 107us/step - loss: 4.2863 - acc: 0.7338\n",
      "Epoch 15/20\n",
      "5634/5634 [==============================] - 1s 110us/step - loss: 4.2860 - acc: 0.7339\n",
      "Epoch 16/20\n",
      "5634/5634 [==============================] - 1s 108us/step - loss: 4.2861 - acc: 0.7338\n",
      "Epoch 17/20\n",
      "5634/5634 [==============================] - 1s 110us/step - loss: 4.2863 - acc: 0.7339\n",
      "Epoch 18/20\n",
      "5634/5634 [==============================] - 1s 128us/step - loss: 4.2859 - acc: 0.7339\n",
      "Epoch 19/20\n",
      "5634/5634 [==============================] - 1s 129us/step - loss: 4.2861 - acc: 0.7339\n",
      "Epoch 20/20\n",
      "5634/5634 [==============================] - 1s 112us/step - loss: 4.2859 - acc: 0.7341\n",
      "1409/1409 [==============================] - 3s 2ms/step\n",
      "5634/5634 [==============================] - 1s 89us/step\n",
      "Epoch 1/20\n",
      "5635/5635 [==============================] - 9s 2ms/step - loss: 4.2533 - acc: 0.7361\n",
      "Epoch 2/20\n",
      "5635/5635 [==============================] - 1s 108us/step - loss: 4.2533 - acc: 0.7361\n",
      "Epoch 3/20\n",
      "5635/5635 [==============================] - 1s 108us/step - loss: 4.2533 - acc: 0.7361\n",
      "Epoch 4/20\n",
      "5635/5635 [==============================] - 1s 104us/step - loss: 4.2533 - acc: 0.7361\n",
      "Epoch 5/20\n",
      "5635/5635 [==============================] - 1s 107us/step - loss: 4.2533 - acc: 0.7361\n",
      "Epoch 6/20\n",
      "5635/5635 [==============================] - 1s 106us/step - loss: 4.2533 - acc: 0.7361\n",
      "Epoch 7/20\n",
      "5635/5635 [==============================] - 1s 106us/step - loss: 4.2533 - acc: 0.7361\n",
      "Epoch 8/20\n",
      "5635/5635 [==============================] - 1s 107us/step - loss: 4.2533 - acc: 0.7361\n",
      "Epoch 9/20\n",
      "5635/5635 [==============================] - 1s 105us/step - loss: 4.2533 - acc: 0.7361\n",
      "Epoch 10/20\n",
      "5635/5635 [==============================] - 1s 113us/step - loss: 4.2533 - acc: 0.7361\n",
      "Epoch 11/20\n",
      "5635/5635 [==============================] - 1s 112us/step - loss: 4.2533 - acc: 0.7361\n",
      "Epoch 12/20\n",
      "5635/5635 [==============================] - 1s 109us/step - loss: 4.2533 - acc: 0.7361\n",
      "Epoch 13/20\n",
      "5635/5635 [==============================] - 1s 113us/step - loss: 4.2533 - acc: 0.7361\n",
      "Epoch 14/20\n",
      "5635/5635 [==============================] - 1s 105us/step - loss: 4.2533 - acc: 0.7361\n",
      "Epoch 15/20\n",
      "5635/5635 [==============================] - 1s 109us/step - loss: 4.2533 - acc: 0.7361\n",
      "Epoch 16/20\n",
      "5635/5635 [==============================] - 1s 104us/step - loss: 4.2533 - acc: 0.7361\n",
      "Epoch 17/20\n",
      "5635/5635 [==============================] - 1s 109us/step - loss: 4.2533 - acc: 0.7361\n",
      "Epoch 18/20\n",
      "5635/5635 [==============================] - 1s 112us/step - loss: 4.2533 - acc: 0.7361\n",
      "Epoch 19/20\n",
      "5635/5635 [==============================] - 1s 121us/step - loss: 4.2533 - acc: 0.7361\n",
      "Epoch 20/20\n",
      "5635/5635 [==============================] - 1s 121us/step - loss: 4.2533 - acc: 0.7361\n",
      "1408/1408 [==============================] - 4s 3ms/step\n",
      "5635/5635 [==============================] - 1s 95us/step\n",
      "Epoch 1/20\n",
      "5635/5635 [==============================] - 9s 2ms/step - loss: 4.2553 - acc: 0.7347\n",
      "Epoch 2/20\n",
      "5635/5635 [==============================] - 1s 108us/step - loss: 4.2517 - acc: 0.7358\n",
      "Epoch 3/20\n",
      "5635/5635 [==============================] - 1s 108us/step - loss: 4.2495 - acc: 0.7354\n",
      "Epoch 4/20\n",
      "5635/5635 [==============================] - 1s 104us/step - loss: 4.2476 - acc: 0.7352\n",
      "Epoch 5/20\n",
      "5635/5635 [==============================] - 1s 108us/step - loss: 4.6328 - acc: 0.7061\n",
      "Epoch 6/20\n",
      "5635/5635 [==============================] - 1s 142us/step - loss: 4.2591 - acc: 0.7358\n",
      "Epoch 7/20\n",
      "5635/5635 [==============================] - 1s 164us/step - loss: 4.2591 - acc: 0.7358\n",
      "Epoch 8/20\n",
      "5635/5635 [==============================] - 1s 129us/step - loss: 4.2591 - acc: 0.7358\n",
      "Epoch 9/20\n",
      "5635/5635 [==============================] - 1s 142us/step - loss: 4.2591 - acc: 0.7358\n",
      "Epoch 10/20\n",
      "5635/5635 [==============================] - 1s 161us/step - loss: 4.2591 - acc: 0.7358 0s - loss: 4.2519 - acc: 0.736\n",
      "Epoch 11/20\n",
      "5635/5635 [==============================] - 1s 190us/step - loss: 4.2591 - acc: 0.7358 0s - loss: 4.1638 - a\n",
      "Epoch 12/20\n",
      "5635/5635 [==============================] - 1s 172us/step - loss: 4.2591 - acc: 0.7358\n",
      "Epoch 13/20\n",
      "5635/5635 [==============================] - 1s 160us/step - loss: 4.2591 - acc: 0.7358\n",
      "Epoch 14/20\n",
      "5635/5635 [==============================] - 1s 164us/step - loss: 4.2591 - acc: 0.7358\n",
      "Epoch 15/20\n",
      "5635/5635 [==============================] - 1s 182us/step - loss: 4.2591 - acc: 0.7358\n",
      "Epoch 16/20\n",
      "5635/5635 [==============================] - 1s 196us/step - loss: 4.2591 - acc: 0.7358\n",
      "Epoch 17/20\n",
      "5635/5635 [==============================] - 1s 166us/step - loss: 4.2591 - acc: 0.7358\n",
      "Epoch 18/20\n",
      "5635/5635 [==============================] - 1s 172us/step - loss: 4.2591 - acc: 0.7358\n",
      "Epoch 19/20\n",
      "5635/5635 [==============================] - 1s 182us/step - loss: 4.2591 - acc: 0.7358\n",
      "Epoch 20/20\n",
      "5635/5635 [==============================] - 1s 181us/step - loss: 4.2591 - acc: 0.7358\n",
      "1408/1408 [==============================] - 5s 3ms/step\n",
      "5635/5635 [==============================] - 1s 166us/step\n",
      "Epoch 1/20\n",
      "5634/5634 [==============================] - 9s 2ms/step - loss: 11.6126 - acc: 0.2678\n",
      "Epoch 2/20\n",
      "5634/5634 [==============================] - 1s 117us/step - loss: 4.6889 - acc: 0.6936\n",
      "Epoch 3/20\n",
      "5634/5634 [==============================] - 1s 118us/step - loss: 4.1481 - acc: 0.7338\n",
      "Epoch 4/20\n",
      "5634/5634 [==============================] - 1s 122us/step - loss: 4.0590 - acc: 0.7272\n",
      "Epoch 5/20\n",
      "5634/5634 [==============================] - 1s 115us/step - loss: 3.8262 - acc: 0.7350\n",
      "Epoch 6/20\n",
      "5634/5634 [==============================] - 1s 120us/step - loss: 3.6281 - acc: 0.7400\n",
      "Epoch 7/20\n",
      "5634/5634 [==============================] - 1s 121us/step - loss: 3.5476 - acc: 0.7359\n",
      "Epoch 8/20\n",
      "5634/5634 [==============================] - 1s 118us/step - loss: 4.1893 - acc: 0.7338\n",
      "Epoch 9/20\n",
      "5634/5634 [==============================] - 1s 118us/step - loss: 3.9479 - acc: 0.7403\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5634/5634 [==============================] - 1s 109us/step - loss: 3.7591 - acc: 0.7364\n",
      "Epoch 11/20\n",
      "5634/5634 [==============================] - 1s 102us/step - loss: 4.2017 - acc: 0.7357\n",
      "Epoch 12/20\n",
      "5634/5634 [==============================] - 1s 111us/step - loss: 4.0942 - acc: 0.7368\n",
      "Epoch 13/20\n",
      "5634/5634 [==============================] - 1s 115us/step - loss: 3.8592 - acc: 0.7330\n",
      "Epoch 14/20\n",
      "5634/5634 [==============================] - 1s 131us/step - loss: 3.8466 - acc: 0.7293\n",
      "Epoch 15/20\n",
      "5634/5634 [==============================] - 1s 131us/step - loss: 3.8705 - acc: 0.7322\n",
      "Epoch 16/20\n",
      "5634/5634 [==============================] - 1s 137us/step - loss: 3.7236 - acc: 0.7345\n",
      "Epoch 17/20\n",
      "5634/5634 [==============================] - 1s 181us/step - loss: 3.7062 - acc: 0.7311\n",
      "Epoch 18/20\n",
      "5634/5634 [==============================] - 1s 162us/step - loss: 4.2749 - acc: 0.7345\n",
      "Epoch 19/20\n",
      "5634/5634 [==============================] - 1s 160us/step - loss: 4.2747 - acc: 0.7345\n",
      "Epoch 20/20\n",
      "5634/5634 [==============================] - 1s 126us/step - loss: 4.2745 - acc: 0.7345\n",
      "1409/1409 [==============================] - 3s 2ms/step\n",
      "5634/5634 [==============================] - 1s 96us/step\n",
      "Epoch 1/20\n",
      "5634/5634 [==============================] - 9s 2ms/step - loss: 4.7860 - acc: 0.6651\n",
      "Epoch 2/20\n",
      "5634/5634 [==============================] - 1s 112us/step - loss: 3.8391 - acc: 0.7247\n",
      "Epoch 3/20\n",
      "5634/5634 [==============================] - 1s 132us/step - loss: 3.6710 - acc: 0.7247\n",
      "Epoch 4/20\n",
      "5634/5634 [==============================] - 1s 129us/step - loss: 2.6251 - acc: 0.6972\n",
      "Epoch 5/20\n",
      "5634/5634 [==============================] - 1s 124us/step - loss: 0.8857 - acc: 0.7247\n",
      "Epoch 6/20\n",
      "5634/5634 [==============================] - 1s 125us/step - loss: 0.8442 - acc: 0.7277 0s - loss: 0.6936 - a\n",
      "Epoch 7/20\n",
      "5634/5634 [==============================] - 1s 134us/step - loss: 0.6898 - acc: 0.7393\n",
      "Epoch 8/20\n",
      "5634/5634 [==============================] - 1s 123us/step - loss: 0.7429 - acc: 0.7291\n",
      "Epoch 9/20\n",
      "5634/5634 [==============================] - 1s 115us/step - loss: 0.5623 - acc: 0.7591\n",
      "Epoch 10/20\n",
      "5634/5634 [==============================] - 1s 152us/step - loss: 0.5716 - acc: 0.7520\n",
      "Epoch 11/20\n",
      "5634/5634 [==============================] - 1s 113us/step - loss: 0.5356 - acc: 0.7575\n",
      "Epoch 12/20\n",
      "5634/5634 [==============================] - 1s 110us/step - loss: 0.6416 - acc: 0.7346\n",
      "Epoch 13/20\n",
      "5634/5634 [==============================] - 1s 110us/step - loss: 0.5175 - acc: 0.7616\n",
      "Epoch 14/20\n",
      "5634/5634 [==============================] - 1s 109us/step - loss: 0.5442 - acc: 0.7611\n",
      "Epoch 15/20\n",
      "5634/5634 [==============================] - 1s 114us/step - loss: 0.5814 - acc: 0.7581\n",
      "Epoch 16/20\n",
      "5634/5634 [==============================] - 1s 111us/step - loss: 0.6201 - acc: 0.7488\n",
      "Epoch 17/20\n",
      "5634/5634 [==============================] - 1s 110us/step - loss: 0.5393 - acc: 0.7623\n",
      "Epoch 18/20\n",
      "5634/5634 [==============================] - 1s 110us/step - loss: 0.5291 - acc: 0.7636\n",
      "Epoch 19/20\n",
      "5634/5634 [==============================] - 1s 112us/step - loss: 0.5413 - acc: 0.7549\n",
      "Epoch 20/20\n",
      "5634/5634 [==============================] - 1s 115us/step - loss: 0.5086 - acc: 0.7654\n",
      "1409/1409 [==============================] - 3s 2ms/step\n",
      "5634/5634 [==============================] - 0s 85us/step\n",
      "Epoch 1/20\n",
      "5634/5634 [==============================] - 9s 2ms/step - loss: 9.4718 - acc: 0.3992\n",
      "Epoch 2/20\n",
      "5634/5634 [==============================] - 1s 134us/step - loss: 4.2867 - acc: 0.7339\n",
      "Epoch 3/20\n",
      "5634/5634 [==============================] - 1s 126us/step - loss: 4.2860 - acc: 0.7339\n",
      "Epoch 4/20\n",
      "5634/5634 [==============================] - 1s 121us/step - loss: 4.2852 - acc: 0.7339\n",
      "Epoch 5/20\n",
      "5634/5634 [==============================] - 1s 120us/step - loss: 4.2844 - acc: 0.7339\n",
      "Epoch 6/20\n",
      "5634/5634 [==============================] - 1s 120us/step - loss: 4.2835 - acc: 0.7339\n",
      "Epoch 7/20\n",
      "5634/5634 [==============================] - 1s 117us/step - loss: 4.2827 - acc: 0.7339\n",
      "Epoch 8/20\n",
      "5634/5634 [==============================] - 1s 112us/step - loss: 4.2817 - acc: 0.7339\n",
      "Epoch 9/20\n",
      "5634/5634 [==============================] - 1s 116us/step - loss: 4.2803 - acc: 0.7339\n",
      "Epoch 10/20\n",
      "5634/5634 [==============================] - 1s 113us/step - loss: 4.2793 - acc: 0.7338\n",
      "Epoch 11/20\n",
      "5634/5634 [==============================] - 1s 116us/step - loss: 4.2785 - acc: 0.7338\n",
      "Epoch 12/20\n",
      "5634/5634 [==============================] - 1s 116us/step - loss: 4.2777 - acc: 0.7338\n",
      "Epoch 13/20\n",
      "5634/5634 [==============================] - 1s 132us/step - loss: 4.2761 - acc: 0.7339\n",
      "Epoch 14/20\n",
      "5634/5634 [==============================] - 1s 114us/step - loss: 4.2740 - acc: 0.7338\n",
      "Epoch 15/20\n",
      "5634/5634 [==============================] - 1s 112us/step - loss: 4.2131 - acc: 0.7341\n",
      "Epoch 16/20\n",
      "5634/5634 [==============================] - 1s 126us/step - loss: 4.2797 - acc: 0.7327\n",
      "Epoch 17/20\n",
      "5634/5634 [==============================] - 1s 114us/step - loss: 4.2788 - acc: 0.7339\n",
      "Epoch 18/20\n",
      "5634/5634 [==============================] - 1s 113us/step - loss: 4.2756 - acc: 0.7338\n",
      "Epoch 19/20\n",
      "5634/5634 [==============================] - 1s 114us/step - loss: 4.2764 - acc: 0.7320\n",
      "Epoch 20/20\n",
      "5634/5634 [==============================] - 1s 117us/step - loss: 4.2854 - acc: 0.7339\n",
      "1409/1409 [==============================] - 4s 3ms/step\n",
      "5634/5634 [==============================] - 1s 96us/step\n",
      "Epoch 1/20\n",
      "5635/5635 [==============================] - 10s 2ms/step - loss: 6.9569 - acc: 0.5505\n",
      "Epoch 2/20\n",
      "5635/5635 [==============================] - 1s 115us/step - loss: 4.2514 - acc: 0.7358\n",
      "Epoch 3/20\n",
      "5635/5635 [==============================] - 1s 117us/step - loss: 4.2508 - acc: 0.7359\n",
      "Epoch 4/20\n",
      "5635/5635 [==============================] - 1s 115us/step - loss: 4.2504 - acc: 0.7361\n",
      "Epoch 5/20\n",
      "5635/5635 [==============================] - 1s 119us/step - loss: 4.2502 - acc: 0.7361\n",
      "Epoch 6/20\n",
      "5635/5635 [==============================] - 1s 118us/step - loss: 4.2503 - acc: 0.7361\n",
      "Epoch 7/20\n",
      "5635/5635 [==============================] - 1s 114us/step - loss: 4.2498 - acc: 0.7361\n",
      "Epoch 8/20\n",
      "5635/5635 [==============================] - 1s 112us/step - loss: 4.2495 - acc: 0.7361\n",
      "Epoch 9/20\n",
      "5635/5635 [==============================] - 1s 113us/step - loss: 4.2488 - acc: 0.7361\n",
      "Epoch 10/20\n",
      "5635/5635 [==============================] - 1s 120us/step - loss: 4.2473 - acc: 0.7361\n",
      "Epoch 11/20\n",
      "5635/5635 [==============================] - 1s 116us/step - loss: 4.1523 - acc: 0.7375\n",
      "Epoch 12/20\n",
      "5635/5635 [==============================] - 1s 114us/step - loss: 4.1512 - acc: 0.7324\n",
      "Epoch 13/20\n",
      "5635/5635 [==============================] - 1s 110us/step - loss: 4.1728 - acc: 0.7358\n",
      "Epoch 14/20\n",
      "5635/5635 [==============================] - 1s 121us/step - loss: 4.1978 - acc: 0.7320\n",
      "Epoch 15/20\n",
      "5635/5635 [==============================] - 1s 126us/step - loss: 4.0796 - acc: 0.7356\n",
      "Epoch 16/20\n",
      "5635/5635 [==============================] - 1s 145us/step - loss: 4.1113 - acc: 0.7379\n",
      "Epoch 17/20\n",
      "5635/5635 [==============================] - 1s 124us/step - loss: 4.0618 - acc: 0.7287\n",
      "Epoch 18/20\n",
      "5635/5635 [==============================] - 1s 117us/step - loss: 3.9414 - acc: 0.7256\n",
      "Epoch 19/20\n",
      "5635/5635 [==============================] - 1s 112us/step - loss: 4.2528 - acc: 0.7361\n",
      "Epoch 20/20\n",
      "5635/5635 [==============================] - 1s 111us/step - loss: 4.2528 - acc: 0.7361\n",
      "1408/1408 [==============================] - 4s 3ms/step\n",
      "5635/5635 [==============================] - 1s 93us/step\n",
      "Epoch 1/20\n",
      "5635/5635 [==============================] - 9s 2ms/step - loss: 7.3894 - acc: 0.5052\n",
      "Epoch 2/20\n",
      "5635/5635 [==============================] - 1s 116us/step - loss: 3.9202 - acc: 0.7322\n",
      "Epoch 3/20\n",
      "5635/5635 [==============================] - 1s 110us/step - loss: 3.2663 - acc: 0.7221\n",
      "Epoch 4/20\n",
      "5635/5635 [==============================] - 1s 139us/step - loss: 2.5903 - acc: 0.7240\n",
      "Epoch 5/20\n",
      "5635/5635 [==============================] - 1s 119us/step - loss: 2.1514 - acc: 0.6905\n",
      "Epoch 6/20\n",
      "5635/5635 [==============================] - 1s 136us/step - loss: 1.8826 - acc: 0.7003\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5635/5635 [==============================] - 1s 118us/step - loss: 0.8331 - acc: 0.7391\n",
      "Epoch 8/20\n",
      "5635/5635 [==============================] - 1s 133us/step - loss: 0.6265 - acc: 0.7505\n",
      "Epoch 9/20\n",
      "5635/5635 [==============================] - 1s 151us/step - loss: 0.6287 - acc: 0.7496\n",
      "Epoch 10/20\n",
      "5635/5635 [==============================] - 1s 119us/step - loss: 0.5876 - acc: 0.7569\n",
      "Epoch 11/20\n",
      "5635/5635 [==============================] - 1s 156us/step - loss: 0.5865 - acc: 0.7542\n",
      "Epoch 12/20\n",
      "5635/5635 [==============================] - 1s 139us/step - loss: 0.6247 - acc: 0.7494\n",
      "Epoch 13/20\n",
      "5635/5635 [==============================] - 1s 147us/step - loss: 0.6066 - acc: 0.7468\n",
      "Epoch 14/20\n",
      "5635/5635 [==============================] - 1s 143us/step - loss: 0.5446 - acc: 0.7650 0s - loss: 0.6093 \n",
      "Epoch 15/20\n",
      "5635/5635 [==============================] - 1s 147us/step - loss: 0.5469 - acc: 0.7512\n",
      "Epoch 16/20\n",
      "5635/5635 [==============================] - 1s 146us/step - loss: 0.5022 - acc: 0.7691\n",
      "Epoch 17/20\n",
      "5635/5635 [==============================] - 1s 140us/step - loss: 0.5815 - acc: 0.7517\n",
      "Epoch 18/20\n",
      "5635/5635 [==============================] - 1s 147us/step - loss: 0.5870 - acc: 0.7492\n",
      "Epoch 19/20\n",
      "5635/5635 [==============================] - 1s 140us/step - loss: 0.5098 - acc: 0.7629 0s - loss: 0.7525\n",
      "Epoch 20/20\n",
      "5635/5635 [==============================] - 1s 130us/step - loss: 0.6003 - acc: 0.7516\n",
      "1408/1408 [==============================] - 4s 3ms/step\n",
      "5635/5635 [==============================] - 1s 111us/step\n",
      "Epoch 1/20\n",
      "7043/7043 [==============================] - 11s 2ms/step - loss: 4.8326 - acc: 0.6794\n",
      "Epoch 2/20\n",
      "7043/7043 [==============================] - 1s 150us/step - loss: 3.6936 - acc: 0.7342\n",
      "Epoch 3/20\n",
      "7043/7043 [==============================] - 1s 176us/step - loss: 3.6597 - acc: 0.7352\n",
      "Epoch 4/20\n",
      "7043/7043 [==============================] - 1s 172us/step - loss: 3.6430 - acc: 0.7341\n",
      "Epoch 5/20\n",
      "7043/7043 [==============================] - 1s 164us/step - loss: 3.5919 - acc: 0.7312\n",
      "Epoch 6/20\n",
      "7043/7043 [==============================] - 1s 170us/step - loss: 3.6844 - acc: 0.7358\n",
      "Epoch 7/20\n",
      "7043/7043 [==============================] - 1s 149us/step - loss: 3.5007 - acc: 0.7318\n",
      "Epoch 8/20\n",
      "7043/7043 [==============================] - 1s 149us/step - loss: 3.4092 - acc: 0.7393\n",
      "Epoch 9/20\n",
      "7043/7043 [==============================] - 1s 149us/step - loss: 3.6201 - acc: 0.7312\n",
      "Epoch 10/20\n",
      "7043/7043 [==============================] - 1s 151us/step - loss: 3.7938 - acc: 0.7353\n",
      "Epoch 11/20\n",
      "7043/7043 [==============================] - 1s 155us/step - loss: 3.3710 - acc: 0.7281\n",
      "Epoch 12/20\n",
      "7043/7043 [==============================] - 1s 159us/step - loss: 2.9946 - acc: 0.7378\n",
      "Epoch 13/20\n",
      "7043/7043 [==============================] - 1s 154us/step - loss: 3.4605 - acc: 0.7419\n",
      "Epoch 14/20\n",
      "7043/7043 [==============================] - 1s 151us/step - loss: 2.6131 - acc: 0.7290\n",
      "Epoch 15/20\n",
      "7043/7043 [==============================] - 1s 152us/step - loss: 2.0130 - acc: 0.7410\n",
      "Epoch 16/20\n",
      "7043/7043 [==============================] - 1s 151us/step - loss: 1.6227 - acc: 0.7446\n",
      "Epoch 17/20\n",
      "7043/7043 [==============================] - 1s 158us/step - loss: 0.9511 - acc: 0.7534\n",
      "Epoch 18/20\n",
      "7043/7043 [==============================] - 1s 163us/step - loss: 1.4982 - acc: 0.7342 1s - loss: \n",
      "Epoch 19/20\n",
      "7043/7043 [==============================] - 1s 163us/step - loss: 1.1189 - acc: 0.7397\n",
      "Epoch 20/20\n",
      "7043/7043 [==============================] - 1s 161us/step - loss: 1.7654 - acc: 0.7301\n",
      "Best: 0.7458469405290029 using {'batch_size': 60, 'epochs': 20}\n",
      "Means: 0.7268209579941157, Stdev: 0.025077169237700394 with: {'batch_size': 20, 'epochs': 20}\n",
      "Means: 0.7127644448782696, Stdev: 0.053220169563693465 with: {'batch_size': 40, 'epochs': 20}\n",
      "Means: 0.7458469405290029, Stdev: 0.023241120521576734 with: {'batch_size': 60, 'epochs': 20}\n",
      "Means: 0.7398835703948504, Stdev: 0.029234299990115408 with: {'batch_size': 80, 'epochs': 20}\n"
     ]
    }
   ],
   "source": [
    "# Bring in GridSearchCV - credit RA/LSDS\n",
    "\n",
    "# Create models\n",
    "# Function to create model, required for KerasClassifier\n",
    "\n",
    "\n",
    "def create_model():\n",
    "    # Create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(24, input_dim=19, activation='relu'))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "kc_model = KerasClassifier(build_fn=create_model, verbose=1)  # default solver=adam\n",
    "\n",
    "# Evaluate using 10-fold cross validation\n",
    "# kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=7)\n",
    "# results = cross_val_score(kc_model, X, y, cv=kfold)\n",
    "# print('Mean of accuracy results after 10-fold cross validation:', results.mean(), '\\n')\n",
    "\n",
    "# Define the grid search parameters\n",
    "# batch_size = [10, 20, 40, 60, 80, 100]\n",
    "# param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "\n",
    "# Define the grid search parameters\n",
    "param_grid = {'batch_size': [20, 40, 60, 80],\n",
    "              'epochs': [20]}\n",
    "params_activation_batch = {'activation': ['relu', 'sigmoid', 'tanh'],  # activation search not an option?\n",
    "                           'batch_size': [20, 40, 60],\n",
    "                           'epochs': [20]}\n",
    "# Create Grid Search\n",
    "grid = GridSearchCV(estimator=kc_model, param_grid=param_grid, n_jobs=1, cv=5)\n",
    "grid_result = grid.fit(X, y)\n",
    "\n",
    "# Report Results\n",
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FfZRtJ7MCN3x"
   },
   "source": [
    "## Stretch Goals:\n",
    "\n",
    "- Try to implement Random Search Hyperparameter Tuning on this dataset\n",
    "- Try to implement Bayesian Optimization tuning on this dataset\n",
    "- Practice hyperparameter tuning other datasets that we have looked at. How high can you get MNIST? Above 99%?\n",
    "- Study for the Sprint Challenge\n",
    " - Can you implement both perceptron and MLP models from scratch with forward and backpropagation?\n",
    " - Can you implement both perceptron and MLP models in keras and tune their hyperparameters with cross validation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "LS_DS_434_Hyperparameter_Tuning_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
