{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Ryp-TVm4njD"
   },
   "source": [
    "# Your Mission, should you choose to accept it...\n",
    "\n",
    "To hyperparameter tune and extract every ounce of accuracy out of this telecom customer churn dataset: <https://drive.google.com/file/d/1dfbAsM9DwA7tYhInyflIpZnYs7VT-0AQ/view> \n",
    "\n",
    "## Requirements\n",
    "\n",
    "- Load the data\n",
    "- Clean the data if necessary (it will be)\n",
    "- Create and fit a baseline Keras MLP model to the data.\n",
    "- Hyperparameter tune (at least) the following parameters:\n",
    " - batch_size\n",
    " - training epochs\n",
    " - optimizer\n",
    " - learning rate (if applicable to optimizer)\n",
    " - momentum (if applicable to optimizer)\n",
    " - activation functions\n",
    " - network weight initialization\n",
    " - dropout regularization\n",
    " - number of neurons in the hidden layer\n",
    " \n",
    " You must use Grid Search and Cross Validation for your initial pass of the above hyperparameters\n",
    " \n",
    " Try and get the maximum accuracy possible out of this data! You'll save big telecoms millions! Doesn't that sound great?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## need to download these each time aws instance is started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install -c conda-forge category_encoders -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://raw.githubusercontent.com/treselle-systems/customer_churn_analysis/master/WA_Fn-UseC_-Telco-Customer-Churn.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install h5py scikit-optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports I know I'll need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NNJ-tOBs4jM1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "import category_encoders as ce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"WA_Fn-UseC_-Telco-Customer-Churn.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    " pd.set_option(\"display.max_columns\", 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerID</th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>OnlineBackup</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7590-VHVEG</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5575-GNVDE</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>34</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.5</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3668-QPYBK</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7795-CFOCW</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>45</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9237-HQITU</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customerID  gender  SeniorCitizen Partner Dependents  tenure PhoneService  \\\n",
       "0  7590-VHVEG  Female              0     Yes         No       1           No   \n",
       "1  5575-GNVDE    Male              0      No         No      34          Yes   \n",
       "2  3668-QPYBK    Male              0      No         No       2          Yes   \n",
       "3  7795-CFOCW    Male              0      No         No      45           No   \n",
       "4  9237-HQITU  Female              0      No         No       2          Yes   \n",
       "\n",
       "      MultipleLines InternetService OnlineSecurity OnlineBackup  \\\n",
       "0  No phone service             DSL             No          Yes   \n",
       "1                No             DSL            Yes           No   \n",
       "2                No             DSL            Yes          Yes   \n",
       "3  No phone service             DSL            Yes           No   \n",
       "4                No     Fiber optic             No           No   \n",
       "\n",
       "  DeviceProtection TechSupport StreamingTV StreamingMovies        Contract  \\\n",
       "0               No          No          No              No  Month-to-month   \n",
       "1              Yes          No          No              No        One year   \n",
       "2               No          No          No              No  Month-to-month   \n",
       "3              Yes         Yes          No              No        One year   \n",
       "4               No          No          No              No  Month-to-month   \n",
       "\n",
       "  PaperlessBilling              PaymentMethod  MonthlyCharges TotalCharges  \\\n",
       "0              Yes           Electronic check           29.85        29.85   \n",
       "1               No               Mailed check           56.95       1889.5   \n",
       "2              Yes               Mailed check           53.85       108.15   \n",
       "3               No  Bank transfer (automatic)           42.30      1840.75   \n",
       "4              Yes           Electronic check           70.70       151.65   \n",
       "\n",
       "  Churn  \n",
       "0    No  \n",
       "1    No  \n",
       "2   Yes  \n",
       "3    No  \n",
       "4   Yes  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace(\"No\",0).replace(\"Yes\",1)\n",
    "df = df.replace(\"Male\",1).replace(\"Female\",0)\n",
    "df = df.replace(\" \",0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "pipe=make_pipeline(\n",
    "   ce.BinaryEncoder(cols=[\"Partner\",\"gender\",\"SeniorCitizen\",\"Dependents\",\"PhoneService\",\"PaperlessBilling\"]),\n",
    "   ce.OneHotEncoder(cols=[\"MultipleLines\",\"InternetService\",\"OnlineSecurity\",\"OnlineBackup\",\"DeviceProtection\",\n",
    "                                        \"TechSupport\",\"StreamingTV\",\"StreamingMovies\",\"Contract\",\"PaymentMethod\"])\n",
    ")\n",
    "df_enc = pipe.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enc[\"TotalCharges\"] = pd.to_numeric(df_enc[\"TotalCharges\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_enc.drop(columns =[\"customerID\",\"Churn\"],axis=1)\n",
    "y = df_enc[\"Churn\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train,y_test = train_test_split(X,y,random_state=42,test_size=.15,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import skopt\n",
    "import tensorflow\n",
    "from tensorflow.python.keras import backend as K\n",
    "from keras import optimizers\n",
    "from tensorflow.python.keras.models import load_model\n",
    "from skopt import gp_minimize, forest_minimize,gbrt_minimize\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from skopt.plots import plot_convergence\n",
    "from skopt.plots import plot_objective, plot_evaluations\n",
    "from keras.regularizers import l1,l2,l1_l2\n",
    "from skopt.utils import use_named_args\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_learning_rate = Real(low=1e-6, high=1e-2, prior='log-uniform',\n",
    "                         name='learning_rate')\n",
    "dim_num_dense_layers = Integer(low=1, high=5, name='num_dense_layers')\n",
    "dim_num_dense_nodes = Integer(low=16, high=72, name='num_dense_nodes')\n",
    "dim_activation = Categorical(categories=['relu', 'sigmoid'],\n",
    "                             name='activation')\n",
    "dim_batch_size = Integer(low=28, high=128, name='batch_size')\n",
    "dim_adam_decay = Real(low=1e-6,high=1e-2,name=\"adam_decay\")\n",
    "\n",
    "dimensions = [dim_learning_rate,\n",
    "              dim_num_dense_layers,\n",
    "              dim_num_dense_nodes,\n",
    "              dim_activation,\n",
    "              dim_batch_size,\n",
    "              dim_adam_decay\n",
    "             ]\n",
    "default_parameters = [1e-3, 1, 16, 'relu',128, 1e-3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Integer(low=16, high=72)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_num_dense_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(learning_rate, num_dense_layers,\n",
    "                 num_dense_nodes, activation,adam_decay\n",
    "                ):\n",
    "    \"\"\"\n",
    "    Hyper-parameters:\n",
    "    learning_rate:     Learning-rate for the optimizer.\n",
    "    num_dense_layers:  Number of dense layers.\n",
    "    num_dense_nodes:   Number of nodes in each dense layer.\n",
    "    activation:        Activation function for all layers.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Start construction of a Keras Sequential model.\n",
    "    model = Sequential()\n",
    "\n",
    "    # Add an input layer which is similar to a feed_dict in TensorFlow.\n",
    "    # Note that the input-shape must be a tuple containing the image-size.\n",
    "    model.add(Dense(num_dense_nodes, activation=activation, input_shape=(input_shape,) ))\n",
    "\n",
    "    \n",
    "\n",
    "    # Add fully-connected / dense layers.\n",
    "    # The number of layers is a hyper-parameter we want to optimize.\n",
    "    for i in range(num_dense_layers):\n",
    "        # Name of the layer. This is not really necessary\n",
    "        # because Keras should give them unique names.\n",
    "        name = 'layer_dense_{0}'.format(i+1)\n",
    "\n",
    "        # Add the dense / fully-connected layer to the model.\n",
    "        # This has two hyper-parameters we want to optimize:\n",
    "        # The number of nodes and the activation function.\n",
    "        model.add(Dense(num_dense_nodes,\n",
    "                        activation=activation,\n",
    "                        name=name,\n",
    "                        ))\n",
    "        \n",
    "\n",
    "    # Last fully-connected / dense layer with softmax-activation\n",
    "    # for use in classification.\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # Use the Adam method for training the network.\n",
    "    # We want to find the best learning-rate for the Adam method.\n",
    "    adam = optimizers.Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=adam_decay, amsgrad=False)\n",
    "    \n",
    "    # In Keras we need to compile the model so it can be trained.\n",
    "    model.compile(optimizer=adam,\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_best_model = 'best_model.h5'\n",
    "best_accuracy = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "@use_named_args(dimensions=dimensions)\n",
    "def fitness(learning_rate, num_dense_layers,\n",
    "            num_dense_nodes, activation, batch_size, adam_decay\n",
    "           ):\n",
    "    \"\"\"\n",
    "    Hyper-parameters:\n",
    "    learning_rate:     Learning-rate for the optimizer.\n",
    "    num_dense_layers:  Number of dense layers.\n",
    "    num_dense_nodes:   Number of nodes in each dense layer.\n",
    "    activation:        Activation function for all layers.\n",
    "    \"\"\"\n",
    "\n",
    "    # Print the hyper-parameters.\n",
    "    print('learning rate: {0:.1e}'.format(learning_rate))\n",
    "    print('num_dense_layers:', num_dense_layers)\n",
    "    print('num_dense_nodes:', num_dense_nodes)\n",
    "    print('activation:', activation)\n",
    "    print()\n",
    "    \n",
    "    # Create the neural network with these hyper-parameters.\n",
    "    model = create_model(learning_rate=learning_rate,\n",
    "                         num_dense_layers=num_dense_layers,\n",
    "                         num_dense_nodes=num_dense_nodes,\n",
    "                         activation=activation,adam_decay=adam_decay\n",
    "                        )\n",
    "    \n",
    "\n",
    "    # Use Keras to train the model.\n",
    "    history = model.fit(x=X_train,\n",
    "                        y=y_train,\n",
    "                        epochs=3,\n",
    "                        batch_size=batch_size,\n",
    "                        validation_split=0.3,\n",
    "                        )\n",
    "\n",
    "    # Get the classification accuracy on the validation-set\n",
    "    # after the last training-epoch.\n",
    "    accuracy = history.history['val_acc'][-1]\n",
    "\n",
    "    # Print the classification accuracy.\n",
    "    print()\n",
    "    print(\"Accuracy: {0:.2%}\".format(accuracy))\n",
    "    print()\n",
    "\n",
    "\n",
    "    # Delete the Keras model with these hyper-parameters from memory.\n",
    "    del model\n",
    "    \n",
    "    # Clear the Keras session, otherwise it will keep adding new\n",
    "    # models to the same TensorFlow graph each time we create\n",
    "    # a model with a different set of hyper-parameters.\n",
    "    K.clear_session()\n",
    "    tensorflow.reset_default_graph()\n",
    "\n",
    "    \n",
    "    # NOTE: Scikit-optimize does minimization so it tries to\n",
    "    # find a set of hyper-parameters with the LOWEST fitness-value.\n",
    "    # Because we are interested in the HIGHEST classification\n",
    "    # accuracy, we need to negate this number so it can be minimized.\n",
    "    return -accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.isfile('best_model.h5')\n",
    "#os.remove('best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "tensorflow.reset_default_graph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitness(x=default_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate: 1.0e-03\n",
      "num_dense_layers: 1\n",
      "num_dense_nodes: 16\n",
      "activation: relu\n",
      "\n",
      "Train on 4190 samples, validate on 1796 samples\n",
      "Epoch 1/3\n",
      "4190/4190 [==============================] - 1s 179us/step - loss: 0.5227 - acc: 0.7663 - val_loss: 0.9512 - val_acc: 0.7684\n",
      "Epoch 2/3\n",
      "4190/4190 [==============================] - 0s 23us/step - loss: 0.6825 - acc: 0.7585 - val_loss: 0.5331 - val_acc: 0.7823\n",
      "Epoch 3/3\n",
      "4190/4190 [==============================] - 0s 23us/step - loss: 0.5014 - acc: 0.7790 - val_loss: 0.4538 - val_acc: 0.7845\n",
      "\n",
      "Accuracy: 78.45%\n",
      "\n",
      "learning rate: 4.5e-04\n",
      "num_dense_layers: 3\n",
      "num_dense_nodes: 56\n",
      "activation: relu\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method BaseSession._Callable.__del__ of <tensorflow.python.client.session.BaseSession._Callable object at 0x7fb1be5333c8>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1455, in __del__\n",
      "    self._session._session, self._handle, status)\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\", line 528, in __exit__\n",
      "    c_api.TF_GetCode(self.status.status))\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: No such callable handle: 94920658202256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4190 samples, validate on 1796 samples\n",
      "Epoch 1/3\n",
      "4190/4190 [==============================] - 1s 193us/step - loss: 0.4999 - acc: 0.7845 - val_loss: 0.4610 - val_acc: 0.7734\n",
      "Epoch 2/3\n",
      "4190/4190 [==============================] - 0s 36us/step - loss: 0.4507 - acc: 0.7912 - val_loss: 0.7011 - val_acc: 0.6002\n",
      "Epoch 3/3\n",
      "4190/4190 [==============================] - 0s 37us/step - loss: 0.4891 - acc: 0.7800 - val_loss: 0.5158 - val_acc: 0.7856\n",
      "\n",
      "Accuracy: 78.56%\n",
      "\n",
      "learning rate: 4.7e-03\n",
      "num_dense_layers: 1\n",
      "num_dense_nodes: 30\n",
      "activation: relu\n",
      "\n",
      "Train on 4190 samples, validate on 1796 samples\n",
      "Epoch 1/3\n",
      "4190/4190 [==============================] - 1s 226us/step - loss: 0.5500 - acc: 0.7831 - val_loss: 0.4671 - val_acc: 0.7884\n",
      "Epoch 2/3\n",
      "4190/4190 [==============================] - 0s 67us/step - loss: 0.6402 - acc: 0.7749 - val_loss: 0.7623 - val_acc: 0.6036\n",
      "Epoch 3/3\n",
      "4190/4190 [==============================] - 0s 68us/step - loss: 0.5967 - acc: 0.7823 - val_loss: 0.5660 - val_acc: 0.7851\n",
      "\n",
      "Accuracy: 78.51%\n",
      "\n",
      "learning rate: 1.9e-05\n",
      "num_dense_layers: 2\n",
      "num_dense_nodes: 63\n",
      "activation: sigmoid\n",
      "\n",
      "Train on 4190 samples, validate on 1796 samples\n",
      "Epoch 1/3\n",
      "4190/4190 [==============================] - 1s 193us/step - loss: 0.4665 - acc: 0.7874 - val_loss: 0.4371 - val_acc: 0.7901\n",
      "Epoch 2/3\n",
      "4190/4190 [==============================] - 0s 37us/step - loss: 0.4518 - acc: 0.7945 - val_loss: 0.6032 - val_acc: 0.6704\n",
      "Epoch 3/3\n",
      "4190/4190 [==============================] - 0s 35us/step - loss: 0.4967 - acc: 0.7878 - val_loss: 0.4556 - val_acc: 0.7979\n",
      "\n",
      "Accuracy: 79.79%\n",
      "\n",
      "learning rate: 5.5e-03\n",
      "num_dense_layers: 3\n",
      "num_dense_nodes: 55\n",
      "activation: relu\n",
      "\n",
      "Train on 4190 samples, validate on 1796 samples\n",
      "Epoch 1/3\n",
      "4190/4190 [==============================] - 1s 185us/step - loss: 0.4695 - acc: 0.7897 - val_loss: 0.5002 - val_acc: 0.7862\n",
      "Epoch 2/3\n",
      "4190/4190 [==============================] - 0s 28us/step - loss: 0.4409 - acc: 0.7926 - val_loss: 0.4349 - val_acc: 0.7929\n",
      "Epoch 3/3\n",
      "4190/4190 [==============================] - 0s 26us/step - loss: 0.4596 - acc: 0.7819 - val_loss: 0.5059 - val_acc: 0.7856\n",
      "\n",
      "Accuracy: 78.56%\n",
      "\n",
      "learning rate: 6.8e-06\n",
      "num_dense_layers: 5\n",
      "num_dense_nodes: 53\n",
      "activation: sigmoid\n",
      "\n",
      "Train on 4190 samples, validate on 1796 samples\n",
      "Epoch 1/3\n",
      "4190/4190 [==============================] - 1s 186us/step - loss: 0.4233 - acc: 0.8000 - val_loss: 0.4341 - val_acc: 0.7940\n",
      "Epoch 2/3\n",
      "4190/4190 [==============================] - 0s 24us/step - loss: 0.4205 - acc: 0.8026 - val_loss: 0.4318 - val_acc: 0.7918\n",
      "Epoch 3/3\n",
      "4190/4190 [==============================] - 0s 24us/step - loss: 0.4253 - acc: 0.8002 - val_loss: 0.4511 - val_acc: 0.7940\n",
      "\n",
      "Accuracy: 79.40%\n",
      "\n",
      "learning rate: 3.2e-06\n",
      "num_dense_layers: 1\n",
      "num_dense_nodes: 55\n",
      "activation: sigmoid\n",
      "\n",
      "Train on 4190 samples, validate on 1796 samples\n",
      "Epoch 1/3\n",
      "4190/4190 [==============================] - 1s 183us/step - loss: 0.4595 - acc: 0.7890 - val_loss: 0.6343 - val_acc: 0.7812\n",
      "Epoch 2/3\n",
      "4190/4190 [==============================] - 0s 25us/step - loss: 0.4341 - acc: 0.7990 - val_loss: 0.4385 - val_acc: 0.7856\n",
      "Epoch 3/3\n",
      "4190/4190 [==============================] - 0s 25us/step - loss: 0.4213 - acc: 0.7981 - val_loss: 0.4320 - val_acc: 0.7890\n",
      "\n",
      "Accuracy: 78.90%\n",
      "\n",
      "learning rate: 2.9e-05\n",
      "num_dense_layers: 1\n",
      "num_dense_nodes: 30\n",
      "activation: relu\n",
      "\n",
      "Train on 4190 samples, validate on 1796 samples\n",
      "Epoch 1/3\n",
      "4190/4190 [==============================] - 1s 241us/step - loss: 0.4517 - acc: 0.7938 - val_loss: 0.4338 - val_acc: 0.7912\n",
      "Epoch 2/3\n",
      "4190/4190 [==============================] - 0s 77us/step - loss: 0.4580 - acc: 0.7931 - val_loss: 0.5317 - val_acc: 0.7244\n",
      "Epoch 3/3\n",
      "4190/4190 [==============================] - 0s 84us/step - loss: 0.4968 - acc: 0.7864 - val_loss: 0.4664 - val_acc: 0.7634\n",
      "\n",
      "Accuracy: 76.34%\n",
      "\n",
      "learning rate: 7.1e-04\n",
      "num_dense_layers: 3\n",
      "num_dense_nodes: 23\n",
      "activation: relu\n",
      "\n",
      "Train on 4190 samples, validate on 1796 samples\n",
      "Epoch 1/3\n",
      "4190/4190 [==============================] - 1s 198us/step - loss: 0.4307 - acc: 0.7995 - val_loss: 0.4367 - val_acc: 0.7856\n",
      "Epoch 2/3\n",
      "4190/4190 [==============================] - 0s 48us/step - loss: 0.4346 - acc: 0.8005 - val_loss: 0.4395 - val_acc: 0.7879\n",
      "Epoch 3/3\n",
      "4190/4190 [==============================] - 0s 45us/step - loss: 0.4288 - acc: 0.7998 - val_loss: 0.4463 - val_acc: 0.7973\n",
      "\n",
      "Accuracy: 79.73%\n",
      "\n",
      "learning rate: 1.6e-04\n",
      "num_dense_layers: 4\n",
      "num_dense_nodes: 36\n",
      "activation: sigmoid\n",
      "\n",
      "Train on 4190 samples, validate on 1796 samples\n",
      "Epoch 1/3\n",
      "4190/4190 [==============================] - 1s 226us/step - loss: 0.4517 - acc: 0.7936 - val_loss: 0.4364 - val_acc: 0.7884\n",
      "Epoch 2/3\n",
      "4190/4190 [==============================] - 0s 67us/step - loss: 0.4668 - acc: 0.7897 - val_loss: 0.4404 - val_acc: 0.7979\n",
      "Epoch 3/3\n",
      "4190/4190 [==============================] - 0s 66us/step - loss: 0.4460 - acc: 0.7957 - val_loss: 0.7861 - val_acc: 0.6214\n",
      "\n",
      "Accuracy: 62.14%\n",
      "\n",
      "learning rate: 4.2e-03\n",
      "num_dense_layers: 3\n",
      "num_dense_nodes: 29\n",
      "activation: sigmoid\n",
      "\n",
      "Train on 4190 samples, validate on 1796 samples\n",
      "Epoch 1/3\n",
      "4190/4190 [==============================] - 1s 202us/step - loss: 0.4363 - acc: 0.7979 - val_loss: 0.4438 - val_acc: 0.7984\n",
      "Epoch 2/3\n",
      "4190/4190 [==============================] - 0s 44us/step - loss: 0.4318 - acc: 0.7998 - val_loss: 0.4303 - val_acc: 0.7990\n",
      "Epoch 3/3\n",
      "4190/4190 [==============================] - 0s 43us/step - loss: 0.4278 - acc: 0.7995 - val_loss: 0.4433 - val_acc: 0.7979\n",
      "\n",
      "Accuracy: 79.79%\n",
      "\n",
      "learning rate: 1.3e-03\n",
      "num_dense_layers: 4\n",
      "num_dense_nodes: 30\n",
      "activation: sigmoid\n",
      "\n",
      "Train on 4190 samples, validate on 1796 samples\n",
      "Epoch 1/3\n",
      "4190/4190 [==============================] - 1s 203us/step - loss: 0.4913 - acc: 0.7850 - val_loss: 0.4563 - val_acc: 0.7717\n",
      "Epoch 2/3\n",
      "4190/4190 [==============================] - 0s 118us/step - loss: 0.4299 - acc: 0.8012 - val_loss: 0.5064 - val_acc: 0.7294\n",
      "Epoch 3/3\n",
      "4190/4190 [==============================] - 1s 127us/step - loss: 0.4235 - acc: 0.8007 - val_loss: 0.4274 - val_acc: 0.7968\n",
      "\n",
      "Accuracy: 79.68%\n",
      "\n",
      "learning rate: 9.7e-06\n",
      "num_dense_layers: 4\n",
      "num_dense_nodes: 71\n",
      "activation: relu\n",
      "\n",
      "Train on 4190 samples, validate on 1796 samples\n",
      "Epoch 1/3\n",
      "4190/4190 [==============================] - 1s 224us/step - loss: 0.4386 - acc: 0.7979 - val_loss: 0.4387 - val_acc: 0.7834\n",
      "Epoch 2/3\n",
      "4190/4190 [==============================] - 0s 68us/step - loss: 0.4461 - acc: 0.7921 - val_loss: 0.5020 - val_acc: 0.7879\n",
      "Epoch 3/3\n",
      "4190/4190 [==============================] - 0s 67us/step - loss: 0.4432 - acc: 0.7983 - val_loss: 0.6729 - val_acc: 0.7801\n",
      "\n",
      "Accuracy: 78.01%\n",
      "\n",
      "learning rate: 7.2e-04\n",
      "num_dense_layers: 4\n",
      "num_dense_nodes: 40\n",
      "activation: relu\n",
      "\n",
      "Train on 4190 samples, validate on 1796 samples\n",
      "Epoch 1/3\n",
      "4190/4190 [==============================] - 1s 230us/step - loss: 0.4760 - acc: 0.7916 - val_loss: 0.4292 - val_acc: 0.7968\n",
      "Epoch 2/3\n",
      "4190/4190 [==============================] - 0s 72us/step - loss: 0.4475 - acc: 0.7938 - val_loss: 0.6166 - val_acc: 0.6720\n",
      "Epoch 3/3\n",
      "4190/4190 [==============================] - 0s 72us/step - loss: 0.4472 - acc: 0.7916 - val_loss: 0.4608 - val_acc: 0.7673\n",
      "\n",
      "Accuracy: 76.73%\n",
      "\n",
      "learning rate: 4.2e-06\n",
      "num_dense_layers: 3\n",
      "num_dense_nodes: 39\n",
      "activation: relu\n",
      "\n",
      "Train on 4190 samples, validate on 1796 samples\n",
      "Epoch 1/3\n",
      "4190/4190 [==============================] - 1s 227us/step - loss: 0.4481 - acc: 0.7947 - val_loss: 0.6050 - val_acc: 0.7851\n",
      "Epoch 2/3\n",
      "4190/4190 [==============================] - 0s 67us/step - loss: 0.4577 - acc: 0.7933 - val_loss: 0.4347 - val_acc: 0.7890\n",
      "Epoch 3/3\n",
      "4190/4190 [==============================] - 0s 68us/step - loss: 0.4326 - acc: 0.7976 - val_loss: 0.5662 - val_acc: 0.7851\n",
      "\n",
      "Accuracy: 78.51%\n",
      "\n",
      "learning rate: 1.8e-04\n",
      "num_dense_layers: 3\n",
      "num_dense_nodes: 16\n",
      "activation: sigmoid\n",
      "\n",
      "Train on 4190 samples, validate on 1796 samples\n",
      "Epoch 1/3\n",
      "4190/4190 [==============================] - 1s 227us/step - loss: 0.4395 - acc: 0.8021 - val_loss: 0.4396 - val_acc: 0.7968\n",
      "Epoch 2/3\n",
      "4190/4190 [==============================] - 0s 70us/step - loss: 0.4395 - acc: 0.7964 - val_loss: 0.4415 - val_acc: 0.7990\n",
      "Epoch 3/3\n",
      "4190/4190 [==============================] - 0s 68us/step - loss: 0.4351 - acc: 0.7926 - val_loss: 0.4291 - val_acc: 0.7918\n",
      "\n",
      "Accuracy: 79.18%\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate: 4.1e-05\n",
      "num_dense_layers: 5\n",
      "num_dense_nodes: 19\n",
      "activation: relu\n",
      "\n",
      "Train on 4190 samples, validate on 1796 samples\n",
      "Epoch 1/3\n",
      "4190/4190 [==============================] - 1s 225us/step - loss: 0.4420 - acc: 0.7936 - val_loss: 0.4746 - val_acc: 0.7890\n",
      "Epoch 2/3\n",
      "4190/4190 [==============================] - 0s 67us/step - loss: 0.4693 - acc: 0.7874 - val_loss: 0.5051 - val_acc: 0.7890\n",
      "Epoch 3/3\n",
      "4190/4190 [==============================] - 0s 68us/step - loss: 0.4630 - acc: 0.7916 - val_loss: 0.4779 - val_acc: 0.7895\n",
      "\n",
      "Accuracy: 78.95%\n",
      "\n",
      "learning rate: 8.3e-03\n",
      "num_dense_layers: 4\n",
      "num_dense_nodes: 52\n",
      "activation: relu\n",
      "\n",
      "Train on 4190 samples, validate on 1796 samples\n",
      "Epoch 1/3\n",
      "4190/4190 [==============================] - 1s 225us/step - loss: 0.4421 - acc: 0.7919 - val_loss: 0.4650 - val_acc: 0.7867\n",
      "Epoch 2/3\n",
      "4190/4190 [==============================] - 0s 69us/step - loss: 0.4295 - acc: 0.7995 - val_loss: 0.4622 - val_acc: 0.7862\n",
      "Epoch 3/3\n",
      "4190/4190 [==============================] - 0s 70us/step - loss: 0.4273 - acc: 0.8014 - val_loss: 0.4274 - val_acc: 0.8001\n",
      "\n",
      "Accuracy: 80.01%\n",
      "\n",
      "learning rate: 3.0e-03\n",
      "num_dense_layers: 5\n",
      "num_dense_nodes: 47\n",
      "activation: sigmoid\n",
      "\n",
      "Train on 4190 samples, validate on 1796 samples\n",
      "Epoch 1/3\n",
      "4190/4190 [==============================] - 1s 230us/step - loss: 0.4284 - acc: 0.7976 - val_loss: 0.4266 - val_acc: 0.7929\n",
      "Epoch 2/3\n",
      "4190/4190 [==============================] - 0s 69us/step - loss: 0.4615 - acc: 0.7919 - val_loss: 0.4407 - val_acc: 0.8007\n",
      "Epoch 3/3\n",
      "4190/4190 [==============================] - 0s 84us/step - loss: 0.4265 - acc: 0.7981 - val_loss: 0.4455 - val_acc: 0.7756\n",
      "\n",
      "Accuracy: 77.56%\n",
      "\n",
      "learning rate: 1.6e-04\n",
      "num_dense_layers: 4\n",
      "num_dense_nodes: 28\n",
      "activation: sigmoid\n",
      "\n",
      "Train on 4190 samples, validate on 1796 samples\n",
      "Epoch 1/3\n",
      "4190/4190 [==============================] - 1s 226us/step - loss: 0.4347 - acc: 0.7969 - val_loss: 0.4602 - val_acc: 0.7884\n",
      "Epoch 2/3\n",
      "4190/4190 [==============================] - 0s 66us/step - loss: 0.4204 - acc: 0.8021 - val_loss: 0.4943 - val_acc: 0.7372\n",
      "Epoch 3/3\n",
      "4190/4190 [==============================] - 0s 66us/step - loss: 0.4297 - acc: 0.7993 - val_loss: 0.4665 - val_acc: 0.7884\n",
      "\n",
      "Accuracy: 78.84%\n",
      "\n",
      "learning rate: 1.5e-06\n",
      "num_dense_layers: 4\n",
      "num_dense_nodes: 26\n",
      "activation: sigmoid\n",
      "\n",
      "Train on 4190 samples, validate on 1796 samples\n",
      "Epoch 1/3\n",
      "4190/4190 [==============================] - 1s 227us/step - loss: 0.4208 - acc: 0.8010 - val_loss: 0.4296 - val_acc: 0.7962\n",
      "Epoch 2/3\n",
      "4190/4190 [==============================] - 0s 67us/step - loss: 0.4295 - acc: 0.7986 - val_loss: 0.4534 - val_acc: 0.7912\n",
      "Epoch 3/3\n",
      "4190/4190 [==============================] - 0s 70us/step - loss: 0.4370 - acc: 0.7979 - val_loss: 0.4659 - val_acc: 0.7606\n",
      "\n",
      "Accuracy: 76.06%\n",
      "\n",
      "learning rate: 9.6e-06\n",
      "num_dense_layers: 1\n",
      "num_dense_nodes: 54\n",
      "activation: sigmoid\n",
      "\n",
      "Train on 4190 samples, validate on 1796 samples\n",
      "Epoch 1/3\n",
      "4190/4190 [==============================] - 1s 231us/step - loss: 0.4321 - acc: 0.7976 - val_loss: 0.4720 - val_acc: 0.7884\n",
      "Epoch 2/3\n",
      "4190/4190 [==============================] - 0s 73us/step - loss: 0.4429 - acc: 0.7959 - val_loss: 0.4268 - val_acc: 0.7979\n",
      "Epoch 3/3\n",
      "4190/4190 [==============================] - 0s 72us/step - loss: 0.4571 - acc: 0.7871 - val_loss: 0.4458 - val_acc: 0.7996\n",
      "\n",
      "Accuracy: 79.96%\n",
      "\n",
      "learning rate: 7.0e-03\n",
      "num_dense_layers: 5\n",
      "num_dense_nodes: 52\n",
      "activation: relu\n",
      "\n",
      "Train on 4190 samples, validate on 1796 samples\n",
      "Epoch 1/3\n",
      "4190/4190 [==============================] - 1s 231us/step - loss: 0.4436 - acc: 0.7976 - val_loss: 0.4399 - val_acc: 0.7984\n",
      "Epoch 2/3\n",
      "4190/4190 [==============================] - 0s 76us/step - loss: 0.4302 - acc: 0.8007 - val_loss: 0.4602 - val_acc: 0.7934\n",
      "Epoch 3/3\n",
      "4190/4190 [==============================] - 0s 74us/step - loss: 0.4412 - acc: 0.7950 - val_loss: 0.4608 - val_acc: 0.7918\n",
      "\n",
      "Accuracy: 79.18%\n",
      "\n",
      "learning rate: 1.4e-06\n",
      "num_dense_layers: 5\n",
      "num_dense_nodes: 20\n",
      "activation: sigmoid\n",
      "\n",
      "Train on 4190 samples, validate on 1796 samples\n",
      "Epoch 1/3\n",
      "4190/4190 [==============================] - 1s 205us/step - loss: 0.4159 - acc: 0.8014 - val_loss: 0.4274 - val_acc: 0.8012\n",
      "Epoch 2/3\n",
      "4190/4190 [==============================] - 0s 47us/step - loss: 0.4116 - acc: 0.8048 - val_loss: 0.4357 - val_acc: 0.7979\n",
      "Epoch 3/3\n",
      "4190/4190 [==============================] - 0s 51us/step - loss: 0.4162 - acc: 0.8019 - val_loss: 0.4461 - val_acc: 0.7951\n",
      "\n",
      "Accuracy: 79.51%\n",
      "\n",
      "learning rate: 2.2e-06\n",
      "num_dense_layers: 2\n",
      "num_dense_nodes: 63\n",
      "activation: sigmoid\n",
      "\n",
      "Train on 4190 samples, validate on 1796 samples\n",
      "Epoch 1/3\n",
      "4190/4190 [==============================] - 1s 219us/step - loss: 0.4161 - acc: 0.8000 - val_loss: 0.4273 - val_acc: 0.8007\n",
      "Epoch 2/3\n",
      "4190/4190 [==============================] - 0s 59us/step - loss: 0.4286 - acc: 0.8000 - val_loss: 0.4365 - val_acc: 0.7962\n",
      "Epoch 3/3\n",
      "4190/4190 [==============================] - 0s 60us/step - loss: 0.4194 - acc: 0.8007 - val_loss: 0.4259 - val_acc: 0.7945\n",
      "\n",
      "Accuracy: 79.45%\n",
      "\n",
      "learning rate: 3.6e-05\n",
      "num_dense_layers: 1\n",
      "num_dense_nodes: 61\n",
      "activation: sigmoid\n",
      "\n",
      "Train on 4190 samples, validate on 1796 samples\n",
      "Epoch 1/3\n",
      "4190/4190 [==============================] - 1s 230us/step - loss: 0.4248 - acc: 0.7967 - val_loss: 0.4263 - val_acc: 0.7951\n",
      "Epoch 2/3\n",
      "4190/4190 [==============================] - 0s 71us/step - loss: 0.4208 - acc: 0.8017 - val_loss: 0.4302 - val_acc: 0.7906\n",
      "Epoch 3/3\n",
      "4190/4190 [==============================] - 0s 75us/step - loss: 0.4290 - acc: 0.8000 - val_loss: 0.4508 - val_acc: 0.7912\n",
      "\n",
      "Accuracy: 79.12%\n",
      "\n",
      "learning rate: 9.7e-03\n",
      "num_dense_layers: 5\n",
      "num_dense_nodes: 37\n",
      "activation: relu\n",
      "\n",
      "Train on 4190 samples, validate on 1796 samples\n",
      "Epoch 1/3\n",
      "4190/4190 [==============================] - 1s 192us/step - loss: 0.4139 - acc: 0.8048 - val_loss: 0.4267 - val_acc: 0.8001\n",
      "Epoch 2/3\n",
      "4190/4190 [==============================] - 0s 32us/step - loss: 0.4093 - acc: 0.8076 - val_loss: 0.4280 - val_acc: 0.7996\n",
      "Epoch 3/3\n",
      "4190/4190 [==============================] - 0s 34us/step - loss: 0.4121 - acc: 0.8041 - val_loss: 0.4259 - val_acc: 0.7990\n",
      "\n",
      "Accuracy: 79.90%\n",
      "\n",
      "learning rate: 3.8e-04\n",
      "num_dense_layers: 3\n",
      "num_dense_nodes: 23\n",
      "activation: sigmoid\n",
      "\n",
      "Train on 4190 samples, validate on 1796 samples\n",
      "Epoch 1/3\n",
      "4190/4190 [==============================] - 1s 221us/step - loss: 0.4144 - acc: 0.8041 - val_loss: 0.4833 - val_acc: 0.7422\n",
      "Epoch 2/3\n",
      "4190/4190 [==============================] - 0s 65us/step - loss: 0.4377 - acc: 0.7943 - val_loss: 0.4810 - val_acc: 0.7455\n",
      "Epoch 3/3\n",
      "4190/4190 [==============================] - 0s 62us/step - loss: 0.4312 - acc: 0.7933 - val_loss: 0.4300 - val_acc: 0.8018\n",
      "\n",
      "Accuracy: 80.18%\n",
      "\n",
      "learning rate: 7.4e-05\n",
      "num_dense_layers: 5\n",
      "num_dense_nodes: 21\n",
      "activation: relu\n",
      "\n",
      "Train on 4190 samples, validate on 1796 samples\n",
      "Epoch 1/3\n",
      "4190/4190 [==============================] - 1s 256us/step - loss: 0.4327 - acc: 0.7914 - val_loss: 0.4477 - val_acc: 0.7745\n",
      "Epoch 2/3\n",
      "4190/4190 [==============================] - 0s 98us/step - loss: 0.4423 - acc: 0.7955 - val_loss: 0.4326 - val_acc: 0.8018\n",
      "Epoch 3/3\n",
      "4190/4190 [==============================] - 0s 97us/step - loss: 0.4209 - acc: 0.8024 - val_loss: 0.4513 - val_acc: 0.7762\n",
      "\n",
      "Accuracy: 77.62%\n",
      "\n",
      "learning rate: 7.8e-03\n",
      "num_dense_layers: 4\n",
      "num_dense_nodes: 35\n",
      "activation: relu\n",
      "\n",
      "Train on 4190 samples, validate on 1796 samples\n",
      "Epoch 1/3\n",
      "4190/4190 [==============================] - 1s 210us/step - loss: 0.4125 - acc: 0.8026 - val_loss: 0.4360 - val_acc: 0.7873\n",
      "Epoch 2/3\n",
      "4190/4190 [==============================] - 0s 52us/step - loss: 0.4266 - acc: 0.7986 - val_loss: 0.4361 - val_acc: 0.7895\n",
      "Epoch 3/3\n",
      "4190/4190 [==============================] - 0s 50us/step - loss: 0.4172 - acc: 0.8033 - val_loss: 0.4354 - val_acc: 0.7890\n",
      "\n",
      "Accuracy: 78.90%\n",
      "\n",
      "learning rate: 1.7e-03\n",
      "num_dense_layers: 2\n",
      "num_dense_nodes: 24\n",
      "activation: sigmoid\n",
      "\n",
      "Train on 4190 samples, validate on 1796 samples\n",
      "Epoch 1/3\n",
      "4190/4190 [==============================] - 1s 190us/step - loss: 0.4177 - acc: 0.8019 - val_loss: 0.4632 - val_acc: 0.7879\n",
      "Epoch 2/3\n",
      "4190/4190 [==============================] - 0s 34us/step - loss: 0.4142 - acc: 0.8005 - val_loss: 0.4281 - val_acc: 0.7940\n",
      "Epoch 3/3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4190/4190 [==============================] - 0s 34us/step - loss: 0.4104 - acc: 0.8021 - val_loss: 0.4322 - val_acc: 0.7901\n",
      "\n",
      "Accuracy: 79.01%\n",
      "\n",
      "learning rate: 1.7e-04\n",
      "num_dense_layers: 2\n",
      "num_dense_nodes: 18\n",
      "activation: sigmoid\n",
      "\n",
      "Train on 4190 samples, validate on 1796 samples\n",
      "Epoch 1/3\n",
      "4190/4190 [==============================] - 1s 207us/step - loss: 0.4165 - acc: 0.8055 - val_loss: 0.4361 - val_acc: 0.7890\n",
      "Epoch 2/3\n",
      "4190/4190 [==============================] - 0s 48us/step - loss: 0.4142 - acc: 0.8005 - val_loss: 0.4265 - val_acc: 0.7996\n",
      "Epoch 3/3\n",
      "4190/4190 [==============================] - 0s 54us/step - loss: 0.4156 - acc: 0.8017 - val_loss: 0.4390 - val_acc: 0.7968\n",
      "\n",
      "Accuracy: 79.68%\n",
      "\n",
      "learning rate: 9.5e-03\n",
      "num_dense_layers: 2\n",
      "num_dense_nodes: 50\n",
      "activation: sigmoid\n",
      "\n",
      "Train on 4190 samples, validate on 1796 samples\n",
      "Epoch 1/3\n",
      "4190/4190 [==============================] - 1s 230us/step - loss: 0.4400 - acc: 0.7952 - val_loss: 0.5174 - val_acc: 0.7867\n",
      "Epoch 2/3\n",
      "4190/4190 [==============================] - 0s 74us/step - loss: 0.4329 - acc: 0.8007 - val_loss: 0.4360 - val_acc: 0.7890\n",
      "Epoch 3/3\n",
      "4190/4190 [==============================] - 0s 74us/step - loss: 0.4257 - acc: 0.7979 - val_loss: 0.4386 - val_acc: 0.7823\n",
      "\n",
      "Accuracy: 78.23%\n",
      "\n",
      "learning rate: 8.4e-04\n",
      "num_dense_layers: 1\n",
      "num_dense_nodes: 23\n",
      "activation: sigmoid\n",
      "\n",
      "Train on 4190 samples, validate on 1796 samples\n",
      "Epoch 1/3\n",
      "4190/4190 [==============================] - 1s 214us/step - loss: 0.4183 - acc: 0.7983 - val_loss: 0.4309 - val_acc: 0.8001\n",
      "Epoch 2/3\n",
      "4190/4190 [==============================] - 0s 47us/step - loss: 0.4211 - acc: 0.7998 - val_loss: 0.4394 - val_acc: 0.7817\n",
      "Epoch 3/3\n",
      "4190/4190 [==============================] - 0s 47us/step - loss: 0.4177 - acc: 0.8017 - val_loss: 0.4540 - val_acc: 0.7890\n",
      "\n",
      "Accuracy: 78.90%\n",
      "\n",
      "learning rate: 1.6e-04\n",
      "num_dense_layers: 4\n",
      "num_dense_nodes: 31\n",
      "activation: sigmoid\n",
      "\n",
      "Train on 4190 samples, validate on 1796 samples\n",
      "Epoch 1/3\n",
      "4190/4190 [==============================] - 1s 211us/step - loss: 0.4395 - acc: 0.7955 - val_loss: 0.4336 - val_acc: 0.7912\n",
      "Epoch 2/3\n",
      "4190/4190 [==============================] - 0s 47us/step - loss: 0.4199 - acc: 0.7993 - val_loss: 0.4379 - val_acc: 0.7984\n",
      "Epoch 3/3\n",
      "4190/4190 [==============================] - 0s 49us/step - loss: 0.4106 - acc: 0.8031 - val_loss: 0.4471 - val_acc: 0.7756\n",
      "\n",
      "Accuracy: 77.56%\n",
      "\n",
      "learning rate: 1.3e-05\n",
      "num_dense_layers: 2\n",
      "num_dense_nodes: 71\n",
      "activation: sigmoid\n",
      "\n",
      "Train on 4190 samples, validate on 1796 samples\n",
      "Epoch 1/3\n",
      "4190/4190 [==============================] - 1s 238us/step - loss: 0.4274 - acc: 0.8017 - val_loss: 0.4275 - val_acc: 0.8018\n",
      "Epoch 2/3\n",
      "4190/4190 [==============================] - 0s 82us/step - loss: 0.4226 - acc: 0.7990 - val_loss: 0.4303 - val_acc: 0.7934\n",
      "Epoch 3/3\n",
      "4190/4190 [==============================] - 0s 79us/step - loss: 0.4169 - acc: 0.8067 - val_loss: 0.4266 - val_acc: 0.7934\n",
      "\n",
      "Accuracy: 79.34%\n",
      "\n",
      "learning rate: 1.7e-04\n",
      "num_dense_layers: 2\n",
      "num_dense_nodes: 32\n",
      "activation: relu\n",
      "\n",
      "Train on 4190 samples, validate on 1796 samples\n",
      "Epoch 1/3\n",
      "4190/4190 [==============================] - 1s 241us/step - loss: 0.4534 - acc: 0.7933 - val_loss: 0.4333 - val_acc: 0.8023\n",
      "Epoch 2/3\n",
      "4190/4190 [==============================] - 0s 84us/step - loss: 0.4485 - acc: 0.7971 - val_loss: 0.5097 - val_acc: 0.7901\n",
      "Epoch 3/3\n",
      "4190/4190 [==============================] - 0s 89us/step - loss: 0.4222 - acc: 0.7964 - val_loss: 0.4268 - val_acc: 0.7957\n",
      "\n",
      "Accuracy: 79.57%\n",
      "\n",
      "learning rate: 8.3e-03\n",
      "num_dense_layers: 4\n",
      "num_dense_nodes: 16\n",
      "activation: relu\n",
      "\n",
      "Train on 4190 samples, validate on 1796 samples\n",
      "Epoch 1/3\n",
      "4190/4190 [==============================] - 1s 226us/step - loss: 0.4195 - acc: 0.8010 - val_loss: 0.4311 - val_acc: 0.8007\n",
      "Epoch 2/3\n",
      "4190/4190 [==============================] - 0s 68us/step - loss: 0.4327 - acc: 0.7995 - val_loss: 0.4856 - val_acc: 0.7433\n",
      "Epoch 3/3\n",
      "4190/4190 [==============================] - 0s 71us/step - loss: 0.4173 - acc: 0.8017 - val_loss: 0.4369 - val_acc: 0.7873\n",
      "\n",
      "Accuracy: 78.73%\n",
      "\n",
      "learning rate: 1.6e-04\n",
      "num_dense_layers: 5\n",
      "num_dense_nodes: 57\n",
      "activation: sigmoid\n",
      "\n",
      "Train on 4190 samples, validate on 1796 samples\n",
      "Epoch 1/3\n",
      "4190/4190 [==============================] - 1s 234us/step - loss: 0.4178 - acc: 0.8036 - val_loss: 0.4331 - val_acc: 0.7996\n",
      "Epoch 2/3\n",
      "4190/4190 [==============================] - 0s 70us/step - loss: 0.4207 - acc: 0.8021 - val_loss: 0.4357 - val_acc: 0.7879\n",
      "Epoch 3/3\n",
      "4190/4190 [==============================] - 0s 68us/step - loss: 0.4170 - acc: 0.8019 - val_loss: 0.4277 - val_acc: 0.7923\n",
      "\n",
      "Accuracy: 79.23%\n",
      "\n",
      "learning rate: 1.0e-06\n",
      "num_dense_layers: 1\n",
      "num_dense_nodes: 30\n",
      "activation: relu\n",
      "\n",
      "Train on 4190 samples, validate on 1796 samples\n",
      "Epoch 1/3\n",
      "4190/4190 [==============================] - 1s 247us/step - loss: 0.4203 - acc: 0.7998 - val_loss: 0.4276 - val_acc: 0.8012\n",
      "Epoch 2/3\n",
      "4190/4190 [==============================] - 0s 85us/step - loss: 0.4137 - acc: 0.8005 - val_loss: 0.4271 - val_acc: 0.7923\n",
      "Epoch 3/3\n",
      "4190/4190 [==============================] - 0s 90us/step - loss: 0.4577 - acc: 0.7936 - val_loss: 0.4710 - val_acc: 0.7533\n",
      "\n",
      "Accuracy: 75.33%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "search_result = gbrt_minimize(func=fitness,\n",
    "                            dimensions=dimensions,\n",
    "                            acq_func='EI', # Expected Improvement.\n",
    "                            n_calls=40,\n",
    "                            n_jobs=-1,\n",
    "                            x0=default_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fun',\n",
       " 'func_vals',\n",
       " 'models',\n",
       " 'random_state',\n",
       " 'space',\n",
       " 'specs',\n",
       " 'x',\n",
       " 'x_iters']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(search_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.001, 1, 16, 'relu', 128, 0.001],\n",
       " [0.0004543790298067931, 3, 56, 'relu', 77, 0.00642928687944211],\n",
       " [0.004682524930126848, 1, 30, 'relu', 39, 0.007556750271075004],\n",
       " [1.9234539726165893e-05, 2, 63, 'sigmoid', 80, 0.000435220567199416],\n",
       " [0.005457179440167175, 3, 55, 'relu', 103, 0.00911446307953481],\n",
       " [6.755465856583113e-06, 5, 53, 'sigmoid', 122, 0.005595517987302317],\n",
       " [3.190267815272856e-06, 1, 55, 'sigmoid', 111, 0.0053740120058309564],\n",
       " [2.943208606262637e-05, 1, 30, 'relu', 34, 0.0035065244736867097],\n",
       " [0.0007143831479586419, 3, 23, 'relu', 70, 0.00869618195525584],\n",
       " [0.00016194786750667762, 4, 36, 'sigmoid', 39, 0.0026077482236392053],\n",
       " [0.0041556010783669025, 3, 29, 'sigmoid', 61, 0.009083405089553798],\n",
       " [0.00128461673929366, 4, 30, 'sigmoid', 63, 0.00039036299893700706],\n",
       " [9.661521077934171e-06, 4, 71, 'relu', 41, 0.0003818069334530619],\n",
       " [0.0007227146510068309, 4, 40, 'relu', 38, 0.002664201608680341],\n",
       " [4.158561456022096e-06, 3, 39, 'relu', 39, 0.0006627428956980823],\n",
       " [0.0001804374330250551, 3, 16, 'sigmoid', 39, 0.00549483251655789],\n",
       " [4.1492521311752286e-05, 5, 19, 'relu', 39, 0.008762176014058603],\n",
       " [0.008310504800398313, 4, 52, 'relu', 39, 0.002398886419221607],\n",
       " [0.0029730746699755395, 5, 47, 'sigmoid', 39, 0.0011124680299093596],\n",
       " [0.00015830543435110854, 4, 28, 'sigmoid', 40, 0.000300572902850303],\n",
       " [1.4741245159074845e-06, 4, 26, 'sigmoid', 39, 0.008847197788601161],\n",
       " [9.61419873592713e-06, 1, 54, 'sigmoid', 39, 0.001583084851693823],\n",
       " [0.006972701038568758, 5, 52, 'relu', 36, 0.0050618528377589095],\n",
       " [1.3999835604536812e-06, 5, 20, 'sigmoid', 59, 0.002525148393913629],\n",
       " [2.151745407469499e-06, 2, 63, 'sigmoid', 46, 0.009401576043362538],\n",
       " [3.5950504639729546e-05, 1, 61, 'sigmoid', 38, 0.001729369028363698],\n",
       " [0.009684721958557657, 5, 37, 'relu', 85, 0.0054233434953301195],\n",
       " [0.00038248296378735257, 3, 23, 'sigmoid', 42, 0.002627261117982011],\n",
       " [7.366480310964464e-05, 5, 21, 'relu', 29, 0.002583383319466421],\n",
       " [0.007846819795105429, 4, 35, 'relu', 52, 0.002615111853589709],\n",
       " [0.0017392712992142618, 2, 24, 'sigmoid', 87, 0.002608143985225748],\n",
       " [0.00016883612024812418, 2, 18, 'sigmoid', 55, 0.0014387523927775266],\n",
       " [0.00948544956864864, 2, 50, 'sigmoid', 36, 0.0036431985062237732],\n",
       " [0.000837446276478234, 1, 23, 'sigmoid', 57, 0.0026074126258194773],\n",
       " [0.0001616667953203442, 4, 31, 'sigmoid', 57, 0.0006333989188510733],\n",
       " [1.2673973500078486e-05, 2, 71, 'sigmoid', 36, 0.0027565524710169587],\n",
       " [0.0001660296183552951, 2, 32, 'relu', 32, 0.0026076792565512936],\n",
       " [0.008304177534891731, 4, 16, 'relu', 39, 5.822319809728691e-06],\n",
       " [0.00016255561331908502, 5, 57, 'sigmoid', 39, 0.007427887060754765],\n",
       " [1.0470596053264857e-06, 1, 30, 'relu', 31, 0.009795843021217462]]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_result.x_iters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FfZRtJ7MCN3x"
   },
   "source": [
    "## Stretch Goals:\n",
    "\n",
    "- Try to implement Random Search Hyperparameter Tuning on this dataset\n",
    "- Try to implement Bayesian Optimiation tuning on this dataset\n",
    "- Practice hyperparameter tuning other datasets that we have looked at. How high can you get MNIST? Above 99%?\n",
    "- Study for the Sprint Challenge\n",
    " - Can you implement both perceptron and MLP models from scratch with forward and backpropagation?\n",
    " - Can you implement both perceptron and MLP models in keras and tune their hyperparameters with cross validation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "LS_DS_434_Hyperparameter_Tuning_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
