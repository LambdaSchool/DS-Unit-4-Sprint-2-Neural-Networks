diff --git a/.DS_Store b/.DS_Store
index c3c8f76..7588680 100644
Binary files a/.DS_Store and b/.DS_Store differ
diff --git a/module2-backpropagation/LS_DS_422_Backprop_Assignment.ipynb b/module2-backpropagation/LS_DS_422_Backprop_Assignment.ipynb
index ff1b656..ea4c886 100644
--- a/module2-backpropagation/LS_DS_422_Backprop_Assignment.ipynb
+++ b/module2-backpropagation/LS_DS_422_Backprop_Assignment.ipynb
@@ -569,21 +569,13 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 1,
+   "execution_count": 3,
    "metadata": {
     "colab": {},
     "colab_type": "code",
     "id": "5MOPtYdk1HgA"
    },
-   "outputs": [
-    {
-     "name": "stderr",
-     "output_type": "stream",
-     "text": [
-      "Using TensorFlow backend.\n"
-     ]
-    }
-   ],
+   "outputs": [],
    "source": [
     "import tensorflow\n",
     "import keras"
@@ -591,23 +583,40 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 21,
+   "execution_count": 13,
    "metadata": {},
    "outputs": [],
-   "source": []
+   "source": [
+    "import keras\n",
+    "from keras.datasets import mnist"
+   ]
   },
   {
    "cell_type": "code",
-   "execution_count": null,
+   "execution_count": 14,
    "metadata": {},
    "outputs": [],
-   "source": []
+   "source": [
+    "X, y = mnist.load_data()"
+   ]
   },
   {
    "cell_type": "code",
-   "execution_count": null,
+   "execution_count": 18,
    "metadata": {},
-   "outputs": [],
+   "outputs": [
+    {
+     "ename": "AttributeError",
+     "evalue": "'tuple' object has no attribute 'shape'",
+     "output_type": "error",
+     "traceback": [
+      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
+      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
+      "\u001b[0;32m<ipython-input-18-bc5f1a0adac8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
+      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'shape'"
+     ]
+    }
+   ],
    "source": []
   },
   {
diff --git a/module4-Hyperparameter-Tuning/LS_DS_424_Hyperparameter_Tuning_Assignment.ipynb b/module4-Hyperparameter-Tuning/LS_DS_424_Hyperparameter_Tuning_Assignment.ipynb
index ca65dc6..cf51878 100644
--- a/module4-Hyperparameter-Tuning/LS_DS_424_Hyperparameter_Tuning_Assignment.ipynb
+++ b/module4-Hyperparameter-Tuning/LS_DS_424_Hyperparameter_Tuning_Assignment.ipynb
@@ -91,9 +91,9 @@
    "name": "python",
    "nbconvert_exporter": "python",
    "pygments_lexer": "ipython3",
-   "version": "3.7.3"
+   "version": "3.7.4"
   }
  },
  "nbformat": 4,
- "nbformat_minor": 2
+ "nbformat_minor": 4
 }
diff --git a/module4-Hyperparameter-Tuning/LS_DS_424_Hyperparameter_Tuning_Lecture.ipynb b/module4-Hyperparameter-Tuning/LS_DS_424_Hyperparameter_Tuning_Lecture.ipynb
index f4baa72..e97869d 100644
--- a/module4-Hyperparameter-Tuning/LS_DS_424_Hyperparameter_Tuning_Lecture.ipynb
+++ b/module4-Hyperparameter-Tuning/LS_DS_424_Hyperparameter_Tuning_Lecture.ipynb
@@ -19,7 +19,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 5,
+   "execution_count": 8,
    "metadata": {
     "colab": {},
     "colab_type": "code",
@@ -36,6 +36,50 @@
     "numpy.random.seed(42)"
    ]
   },
+  {
+   "cell_type": "code",
+   "execution_count": 1,
+   "metadata": {},
+   "outputs": [
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "wandb: WARNING import wandb.keras called before import keras or import tensorflow.keras.  This can lead to a version mismatch, W&B now assumes tensorflow.keras\n"
+     ]
+    },
+    {
+     "data": {
+      "text/html": [
+       "\n",
+       "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/ds5/ds5-hyperparameter-tuning/runs/wfivzbse\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
+       "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
+       "    "
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "data": {
+      "text/plain": [
+       "W&B Run: https://app.wandb.ai/ds5/ds5-hyperparameter-tuning/runs/wfivzbse"
+      ]
+     },
+     "execution_count": 1,
+     "metadata": {},
+     "output_type": "execute_result"
+    }
+   ],
+   "source": [
+    "import wandb\n",
+    "from wandb.keras import WandbCallback\n",
+    "wandb.init(project=\"ds5-hyperparameter-tuning\", entity=\"ds5\")"
+   ]
+  },
   {
    "cell_type": "markdown",
    "metadata": {
@@ -50,7 +94,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 7,
+   "execution_count": 18,
    "metadata": {
     "colab": {
      "base_uri": "https://localhost:8080/",
@@ -211,13 +255,12 @@
        "4     18.7  396.90   5.33  36.2  "
       ]
      },
-     "execution_count": 7,
+     "execution_count": 18,
      "metadata": {},
      "output_type": "execute_result"
     }
    ],
    "source": [
-    "# load dataset\n",
     "from sklearn.datasets import load_boston\n",
     "boston_dataset = load_boston()\n",
     "df = pd.DataFrame(boston_dataset.data, columns=boston_dataset.feature_names)\n",
@@ -242,7 +285,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 8,
+   "execution_count": 19,
    "metadata": {
     "colab": {
      "base_uri": "https://localhost:8080/",
@@ -300,7 +343,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 9,
+   "execution_count": 20,
    "metadata": {
     "colab": {
      "base_uri": "https://localhost:8080/",
@@ -315,10 +358,7 @@
      "name": "stderr",
      "output_type": "stream",
      "text": [
-      "WARNING: Logging before flag parsing goes to stderr.\n",
-      "W0815 10:08:20.955155 4430419392 deprecation.py:506] From /Users/jonathansokoll/anaconda3/envs/U4-S2-NNF/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
-      "Instructions for updating:\n",
-      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
+      "E0912 10:43:10.273770 4373476800 jupyter.py:96] Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n"
      ]
     },
     {
@@ -327,114 +367,114 @@
      "text": [
       "Train on 339 samples, validate on 167 samples\n",
       "Epoch 1/50\n",
-      "339/339 [==============================] - 0s 366us/sample - loss: 625.2513 - mean_squared_error: 625.2513 - val_loss: 279.9214 - val_mean_squared_error: 279.9214\n",
+      "339/339 [==============================] - 2s 6ms/sample - loss: 688.4785 - mean_squared_error: 688.4786 - val_loss: 353.4611 - val_mean_squared_error: 353.4611\n",
       "Epoch 2/50\n",
-      "339/339 [==============================] - 0s 95us/sample - loss: 373.3546 - mean_squared_error: 373.3546 - val_loss: 180.1021 - val_mean_squared_error: 180.1021\n",
+      "339/339 [==============================] - 0s 144us/sample - loss: 662.4076 - mean_squared_error: 662.4076 - val_loss: 334.6408 - val_mean_squared_error: 334.6408\n",
       "Epoch 3/50\n",
-      "339/339 [==============================] - 0s 93us/sample - loss: 101.2103 - mean_squared_error: 101.2103 - val_loss: 137.3386 - val_mean_squared_error: 137.3387\n",
+      "339/339 [==============================] - 0s 145us/sample - loss: 633.5718 - mean_squared_error: 633.5718 - val_loss: 316.2100 - val_mean_squared_error: 316.2100\n",
       "Epoch 4/50\n",
-      "339/339 [==============================] - 0s 84us/sample - loss: 33.7659 - mean_squared_error: 33.7659 - val_loss: 114.6741 - val_mean_squared_error: 114.6741\n",
+      "339/339 [==============================] - 0s 142us/sample - loss: 598.2091 - mean_squared_error: 598.2090 - val_loss: 296.5003 - val_mean_squared_error: 296.5003\n",
       "Epoch 5/50\n",
-      "339/339 [==============================] - 0s 82us/sample - loss: 18.5104 - mean_squared_error: 18.5104 - val_loss: 113.3629 - val_mean_squared_error: 113.3628\n",
+      "339/339 [==============================] - 0s 132us/sample - loss: 554.9742 - mean_squared_error: 554.9741 - val_loss: 275.2837 - val_mean_squared_error: 275.2837\n",
       "Epoch 6/50\n",
-      "339/339 [==============================] - 0s 91us/sample - loss: 14.5301 - mean_squared_error: 14.5301 - val_loss: 117.4675 - val_mean_squared_error: 117.4675\n",
+      "339/339 [==============================] - 0s 141us/sample - loss: 499.7677 - mean_squared_error: 499.7676 - val_loss: 252.4159 - val_mean_squared_error: 252.4159\n",
       "Epoch 7/50\n",
-      "339/339 [==============================] - 0s 92us/sample - loss: 13.1114 - mean_squared_error: 13.1114 - val_loss: 115.7412 - val_mean_squared_error: 115.7412\n",
+      "339/339 [==============================] - 0s 145us/sample - loss: 434.2441 - mean_squared_error: 434.2441 - val_loss: 228.6269 - val_mean_squared_error: 228.6269\n",
       "Epoch 8/50\n",
-      "339/339 [==============================] - 0s 95us/sample - loss: 12.1406 - mean_squared_error: 12.1406 - val_loss: 112.9944 - val_mean_squared_error: 112.9944\n",
+      "339/339 [==============================] - 0s 137us/sample - loss: 360.7517 - mean_squared_error: 360.7517 - val_loss: 205.2509 - val_mean_squared_error: 205.2509\n",
       "Epoch 9/50\n",
-      "339/339 [==============================] - 0s 89us/sample - loss: 11.5139 - mean_squared_error: 11.5139 - val_loss: 110.0447 - val_mean_squared_error: 110.0447\n",
+      "339/339 [==============================] - 0s 132us/sample - loss: 281.7091 - mean_squared_error: 281.7091 - val_loss: 184.3479 - val_mean_squared_error: 184.3479\n",
       "Epoch 10/50\n",
-      "339/339 [==============================] - 0s 88us/sample - loss: 10.9077 - mean_squared_error: 10.9077 - val_loss: 106.9348 - val_mean_squared_error: 106.9348\n",
+      "339/339 [==============================] - 0s 139us/sample - loss: 204.9648 - mean_squared_error: 204.9648 - val_loss: 167.3739 - val_mean_squared_error: 167.3739\n",
       "Epoch 11/50\n",
-      "339/339 [==============================] - 0s 85us/sample - loss: 10.5648 - mean_squared_error: 10.5648 - val_loss: 103.4860 - val_mean_squared_error: 103.4860\n",
+      "339/339 [==============================] - 0s 141us/sample - loss: 144.0901 - mean_squared_error: 144.0901 - val_loss: 155.3057 - val_mean_squared_error: 155.3057\n",
       "Epoch 12/50\n",
-      "339/339 [==============================] - 0s 87us/sample - loss: 9.9297 - mean_squared_error: 9.9297 - val_loss: 100.5036 - val_mean_squared_error: 100.5036\n",
+      "339/339 [==============================] - 0s 136us/sample - loss: 101.7063 - mean_squared_error: 101.7063 - val_loss: 146.0330 - val_mean_squared_error: 146.0330\n",
       "Epoch 13/50\n",
-      "339/339 [==============================] - 0s 87us/sample - loss: 9.4464 - mean_squared_error: 9.4464 - val_loss: 98.4739 - val_mean_squared_error: 98.4739\n",
+      "339/339 [==============================] - 0s 125us/sample - loss: 75.6822 - mean_squared_error: 75.6822 - val_loss: 136.7871 - val_mean_squared_error: 136.7871\n",
       "Epoch 14/50\n",
-      "339/339 [==============================] - 0s 84us/sample - loss: 9.1621 - mean_squared_error: 9.1621 - val_loss: 95.9992 - val_mean_squared_error: 95.9992\n",
+      "339/339 [==============================] - 0s 138us/sample - loss: 60.4601 - mean_squared_error: 60.4601 - val_loss: 127.1887 - val_mean_squared_error: 127.1887\n",
       "Epoch 15/50\n",
-      "339/339 [==============================] - 0s 85us/sample - loss: 8.9122 - mean_squared_error: 8.9122 - val_loss: 91.8091 - val_mean_squared_error: 91.8091\n",
+      "339/339 [==============================] - 0s 137us/sample - loss: 47.6639 - mean_squared_error: 47.6639 - val_loss: 117.7192 - val_mean_squared_error: 117.7193\n",
       "Epoch 16/50\n",
-      "339/339 [==============================] - 0s 86us/sample - loss: 8.5564 - mean_squared_error: 8.5564 - val_loss: 91.1116 - val_mean_squared_error: 91.1116\n",
+      "339/339 [==============================] - 0s 147us/sample - loss: 37.0354 - mean_squared_error: 37.0354 - val_loss: 109.9841 - val_mean_squared_error: 109.9841\n",
       "Epoch 17/50\n",
-      "339/339 [==============================] - 0s 87us/sample - loss: 8.0328 - mean_squared_error: 8.0328 - val_loss: 87.0650 - val_mean_squared_error: 87.0650\n",
+      "339/339 [==============================] - 0s 128us/sample - loss: 29.3442 - mean_squared_error: 29.3442 - val_loss: 104.8597 - val_mean_squared_error: 104.8597\n",
       "Epoch 18/50\n",
-      "339/339 [==============================] - 0s 83us/sample - loss: 7.7535 - mean_squared_error: 7.7535 - val_loss: 86.3742 - val_mean_squared_error: 86.3742\n",
+      "339/339 [==============================] - 0s 139us/sample - loss: 24.3677 - mean_squared_error: 24.3677 - val_loss: 101.7247 - val_mean_squared_error: 101.7247\n",
       "Epoch 19/50\n",
-      "339/339 [==============================] - 0s 86us/sample - loss: 7.5547 - mean_squared_error: 7.5547 - val_loss: 82.6835 - val_mean_squared_error: 82.6835\n",
+      "339/339 [==============================] - 0s 136us/sample - loss: 21.1031 - mean_squared_error: 21.1031 - val_loss: 100.3341 - val_mean_squared_error: 100.3341\n",
       "Epoch 20/50\n",
-      "339/339 [==============================] - 0s 85us/sample - loss: 7.3827 - mean_squared_error: 7.3827 - val_loss: 81.1169 - val_mean_squared_error: 81.1169\n",
+      "339/339 [==============================] - 0s 128us/sample - loss: 18.8217 - mean_squared_error: 18.8217 - val_loss: 99.9759 - val_mean_squared_error: 99.9759\n",
       "Epoch 21/50\n",
-      "339/339 [==============================] - 0s 83us/sample - loss: 7.1717 - mean_squared_error: 7.1717 - val_loss: 78.6616 - val_mean_squared_error: 78.6616\n",
+      "339/339 [==============================] - 0s 83us/sample - loss: 17.2602 - mean_squared_error: 17.2602 - val_loss: 100.4435 - val_mean_squared_error: 100.4435\n",
       "Epoch 22/50\n",
-      "339/339 [==============================] - 0s 84us/sample - loss: 6.9017 - mean_squared_error: 6.9017 - val_loss: 77.7369 - val_mean_squared_error: 77.7369\n",
+      "339/339 [==============================] - 0s 71us/sample - loss: 16.2522 - mean_squared_error: 16.2522 - val_loss: 101.0519 - val_mean_squared_error: 101.0519\n",
       "Epoch 23/50\n",
-      "339/339 [==============================] - 0s 83us/sample - loss: 6.7186 - mean_squared_error: 6.7186 - val_loss: 74.8546 - val_mean_squared_error: 74.8546\n",
+      "339/339 [==============================] - 0s 77us/sample - loss: 15.4179 - mean_squared_error: 15.4179 - val_loss: 101.3478 - val_mean_squared_error: 101.3478\n",
       "Epoch 24/50\n",
-      "339/339 [==============================] - 0s 83us/sample - loss: 6.4259 - mean_squared_error: 6.4259 - val_loss: 72.0877 - val_mean_squared_error: 72.0877\n",
+      "339/339 [==============================] - 0s 74us/sample - loss: 14.8085 - mean_squared_error: 14.8085 - val_loss: 101.6887 - val_mean_squared_error: 101.6887\n",
       "Epoch 25/50\n",
-      "339/339 [==============================] - 0s 86us/sample - loss: 6.5469 - mean_squared_error: 6.5469 - val_loss: 70.2001 - val_mean_squared_error: 70.2001\n",
+      "339/339 [==============================] - 0s 72us/sample - loss: 14.3723 - mean_squared_error: 14.3723 - val_loss: 101.7383 - val_mean_squared_error: 101.7383\n",
       "Epoch 26/50\n",
-      "339/339 [==============================] - 0s 86us/sample - loss: 6.1998 - mean_squared_error: 6.1998 - val_loss: 71.6276 - val_mean_squared_error: 71.6276\n",
+      "339/339 [==============================] - 0s 79us/sample - loss: 13.9871 - mean_squared_error: 13.9871 - val_loss: 101.7234 - val_mean_squared_error: 101.7234\n",
       "Epoch 27/50\n",
-      "339/339 [==============================] - 0s 86us/sample - loss: 6.1886 - mean_squared_error: 6.1886 - val_loss: 66.5151 - val_mean_squared_error: 66.5151\n",
+      "339/339 [==============================] - 0s 77us/sample - loss: 13.5974 - mean_squared_error: 13.5974 - val_loss: 101.4126 - val_mean_squared_error: 101.4126\n",
       "Epoch 28/50\n",
-      "339/339 [==============================] - 0s 86us/sample - loss: 5.9647 - mean_squared_error: 5.9647 - val_loss: 64.1536 - val_mean_squared_error: 64.1536\n",
+      "339/339 [==============================] - 0s 82us/sample - loss: 13.2795 - mean_squared_error: 13.2795 - val_loss: 100.7492 - val_mean_squared_error: 100.7492\n",
       "Epoch 29/50\n",
-      "339/339 [==============================] - 0s 82us/sample - loss: 5.8475 - mean_squared_error: 5.8475 - val_loss: 62.9218 - val_mean_squared_error: 62.9218\n",
+      "339/339 [==============================] - 0s 73us/sample - loss: 13.0271 - mean_squared_error: 13.0271 - val_loss: 100.2037 - val_mean_squared_error: 100.2037\n",
       "Epoch 30/50\n",
-      "339/339 [==============================] - 0s 88us/sample - loss: 5.7472 - mean_squared_error: 5.7472 - val_loss: 61.4670 - val_mean_squared_error: 61.4670\n",
+      "339/339 [==============================] - 0s 140us/sample - loss: 12.6704 - mean_squared_error: 12.6704 - val_loss: 99.6255 - val_mean_squared_error: 99.6255\n",
       "Epoch 31/50\n",
-      "339/339 [==============================] - 0s 88us/sample - loss: 5.6262 - mean_squared_error: 5.6262 - val_loss: 60.4396 - val_mean_squared_error: 60.4396\n",
+      "339/339 [==============================] - 0s 121us/sample - loss: 12.3995 - mean_squared_error: 12.3995 - val_loss: 99.2328 - val_mean_squared_error: 99.2328\n",
       "Epoch 32/50\n",
-      "339/339 [==============================] - 0s 84us/sample - loss: 5.5064 - mean_squared_error: 5.5064 - val_loss: 59.4765 - val_mean_squared_error: 59.4765\n",
+      "339/339 [==============================] - 0s 134us/sample - loss: 12.1399 - mean_squared_error: 12.1399 - val_loss: 98.7262 - val_mean_squared_error: 98.7262\n",
       "Epoch 33/50\n",
-      "339/339 [==============================] - 0s 84us/sample - loss: 5.4368 - mean_squared_error: 5.4368 - val_loss: 57.5645 - val_mean_squared_error: 57.5645\n",
+      "339/339 [==============================] - 0s 130us/sample - loss: 11.8973 - mean_squared_error: 11.8973 - val_loss: 97.8119 - val_mean_squared_error: 97.8119\n",
       "Epoch 34/50\n",
-      "339/339 [==============================] - 0s 84us/sample - loss: 5.3329 - mean_squared_error: 5.3329 - val_loss: 54.6676 - val_mean_squared_error: 54.6676\n",
+      "339/339 [==============================] - 0s 122us/sample - loss: 11.7084 - mean_squared_error: 11.7084 - val_loss: 97.2491 - val_mean_squared_error: 97.2491\n",
       "Epoch 35/50\n",
-      "339/339 [==============================] - 0s 85us/sample - loss: 5.2066 - mean_squared_error: 5.2066 - val_loss: 56.0873 - val_mean_squared_error: 56.0873\n",
+      "339/339 [==============================] - 0s 123us/sample - loss: 11.4242 - mean_squared_error: 11.4242 - val_loss: 96.2748 - val_mean_squared_error: 96.2748\n",
       "Epoch 36/50\n",
-      "339/339 [==============================] - 0s 91us/sample - loss: 5.2098 - mean_squared_error: 5.2098 - val_loss: 53.7955 - val_mean_squared_error: 53.7955\n",
+      "339/339 [==============================] - 0s 127us/sample - loss: 11.1686 - mean_squared_error: 11.1686 - val_loss: 95.6531 - val_mean_squared_error: 95.6531\n",
       "Epoch 37/50\n",
-      "339/339 [==============================] - 0s 87us/sample - loss: 5.4417 - mean_squared_error: 5.4417 - val_loss: 52.4190 - val_mean_squared_error: 52.4189\n",
+      "339/339 [==============================] - 0s 133us/sample - loss: 10.9894 - mean_squared_error: 10.9894 - val_loss: 95.0012 - val_mean_squared_error: 95.0012\n",
       "Epoch 38/50\n",
-      "339/339 [==============================] - 0s 85us/sample - loss: 4.9801 - mean_squared_error: 4.9801 - val_loss: 51.0138 - val_mean_squared_error: 51.0138\n",
+      "339/339 [==============================] - 0s 131us/sample - loss: 10.7452 - mean_squared_error: 10.7452 - val_loss: 94.0028 - val_mean_squared_error: 94.0028\n",
       "Epoch 39/50\n",
-      "339/339 [==============================] - 0s 94us/sample - loss: 5.0640 - mean_squared_error: 5.0640 - val_loss: 50.9198 - val_mean_squared_error: 50.9198\n",
+      "339/339 [==============================] - 0s 136us/sample - loss: 10.5527 - mean_squared_error: 10.5527 - val_loss: 93.1394 - val_mean_squared_error: 93.1394\n",
       "Epoch 40/50\n",
-      "339/339 [==============================] - 0s 97us/sample - loss: 5.0598 - mean_squared_error: 5.0598 - val_loss: 51.4312 - val_mean_squared_error: 51.4312\n",
+      "339/339 [==============================] - 0s 134us/sample - loss: 10.3629 - mean_squared_error: 10.3629 - val_loss: 92.7075 - val_mean_squared_error: 92.7075\n",
       "Epoch 41/50\n",
-      "339/339 [==============================] - 0s 94us/sample - loss: 4.9155 - mean_squared_error: 4.9155 - val_loss: 49.5652 - val_mean_squared_error: 49.5652\n",
+      "339/339 [==============================] - 0s 127us/sample - loss: 10.1668 - mean_squared_error: 10.1668 - val_loss: 92.1459 - val_mean_squared_error: 92.1459\n",
       "Epoch 42/50\n",
-      "339/339 [==============================] - 0s 95us/sample - loss: 4.6731 - mean_squared_error: 4.6731 - val_loss: 47.9462 - val_mean_squared_error: 47.9462\n",
+      "339/339 [==============================] - 0s 128us/sample - loss: 9.9842 - mean_squared_error: 9.9842 - val_loss: 91.7140 - val_mean_squared_error: 91.7140\n",
       "Epoch 43/50\n",
-      "339/339 [==============================] - 0s 93us/sample - loss: 4.7018 - mean_squared_error: 4.7018 - val_loss: 48.1317 - val_mean_squared_error: 48.1317\n",
+      "339/339 [==============================] - 0s 133us/sample - loss: 9.8176 - mean_squared_error: 9.8176 - val_loss: 90.8359 - val_mean_squared_error: 90.8359\n",
       "Epoch 44/50\n",
-      "339/339 [==============================] - 0s 89us/sample - loss: 4.8628 - mean_squared_error: 4.8628 - val_loss: 47.4068 - val_mean_squared_error: 47.4068\n",
+      "339/339 [==============================] - 0s 135us/sample - loss: 9.6540 - mean_squared_error: 9.6540 - val_loss: 90.0071 - val_mean_squared_error: 90.0071\n",
       "Epoch 45/50\n",
-      "339/339 [==============================] - 0s 90us/sample - loss: 4.5611 - mean_squared_error: 4.5611 - val_loss: 47.3415 - val_mean_squared_error: 47.3415\n",
+      "339/339 [==============================] - 0s 128us/sample - loss: 9.4693 - mean_squared_error: 9.4693 - val_loss: 89.2615 - val_mean_squared_error: 89.2615\n",
       "Epoch 46/50\n",
-      "339/339 [==============================] - 0s 98us/sample - loss: 4.6660 - mean_squared_error: 4.6660 - val_loss: 45.0834 - val_mean_squared_error: 45.0834\n",
+      "339/339 [==============================] - 0s 144us/sample - loss: 9.3191 - mean_squared_error: 9.3191 - val_loss: 88.8255 - val_mean_squared_error: 88.8255\n",
       "Epoch 47/50\n",
-      "339/339 [==============================] - 0s 93us/sample - loss: 4.5393 - mean_squared_error: 4.5393 - val_loss: 44.8492 - val_mean_squared_error: 44.8492\n",
+      "339/339 [==============================] - 0s 132us/sample - loss: 9.1592 - mean_squared_error: 9.1592 - val_loss: 88.1205 - val_mean_squared_error: 88.1205\n",
       "Epoch 48/50\n",
-      "339/339 [==============================] - 0s 95us/sample - loss: 4.4971 - mean_squared_error: 4.4971 - val_loss: 44.5613 - val_mean_squared_error: 44.5613\n",
+      "339/339 [==============================] - 0s 124us/sample - loss: 9.0166 - mean_squared_error: 9.0166 - val_loss: 87.5474 - val_mean_squared_error: 87.5474\n",
       "Epoch 49/50\n",
-      "339/339 [==============================] - 0s 94us/sample - loss: 4.5186 - mean_squared_error: 4.5186 - val_loss: 42.3793 - val_mean_squared_error: 42.3793\n",
+      "339/339 [==============================] - 0s 119us/sample - loss: 8.8792 - mean_squared_error: 8.8792 - val_loss: 87.0455 - val_mean_squared_error: 87.0455\n",
       "Epoch 50/50\n",
-      "339/339 [==============================] - 0s 95us/sample - loss: 4.4599 - mean_squared_error: 4.4599 - val_loss: 44.0912 - val_mean_squared_error: 44.0912\n"
+      "339/339 [==============================] - 0s 124us/sample - loss: 8.7379 - mean_squared_error: 8.7379 - val_loss: 86.2059 - val_mean_squared_error: 86.2059\n"
      ]
     },
     {
      "data": {
       "text/plain": [
-       "<tensorflow.python.keras.callbacks.History at 0x1a2c41aa90>"
+       "<tensorflow.python.keras.callbacks.History at 0x1a452b1b00>"
       ]
      },
-     "execution_count": 9,
+     "execution_count": 20,
      "metadata": {},
      "output_type": "execute_result"
     }
@@ -442,8 +482,9 @@
    "source": [
     "# Important Hyperparameters\n",
     "inputs = X.shape[1]\n",
-    "epochs = 50\n",
-    "batch_size = 10\n",
+    "wandb.config.epochs = 50\n",
+    "wandb.config.batch_size = 10\n",
+    "\n",
     "\n",
     "# Create Model\n",
     "model = Sequential()\n",
@@ -452,8 +493,15 @@
     "model.add(Dense(1))\n",
     "# Compile Model\n",
     "model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
+    "\n",
     "# Fit Model\n",
-    "model.fit(X, y, validation_split=0.33, epochs=epochs, batch_size=batch_size)"
+    "\n",
+    "model.fit(X, y, \n",
+    "          validation_split=0.33, \n",
+    "          epochs=wandb.config.epochs, \n",
+    "          batch_size=wandb.config.epochs, \n",
+    "          callbacks=[WandbCallback()]\n",
+    "         )"
    ]
   },
   {
@@ -470,7 +518,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 10,
+   "execution_count": 21,
    "metadata": {
     "colab": {
      "base_uri": "https://localhost:8080/",
@@ -482,121 +530,17 @@
    },
    "outputs": [
     {
-     "name": "stdout",
-     "output_type": "stream",
-     "text": [
-      "Train on 339 samples, validate on 167 samples\n",
-      "Epoch 1/50\n",
-      "339/339 [==============================] - 0s 383us/sample - loss: 496.6472 - mean_squared_error: 496.6472 - val_loss: 325.2020 - val_mean_squared_error: 325.2020\n",
-      "Epoch 2/50\n",
-      "339/339 [==============================] - 0s 103us/sample - loss: 243.5689 - mean_squared_error: 243.5689 - val_loss: 112.0480 - val_mean_squared_error: 112.0480\n",
-      "Epoch 3/50\n",
-      "339/339 [==============================] - 0s 92us/sample - loss: 82.1482 - mean_squared_error: 82.1482 - val_loss: 49.1192 - val_mean_squared_error: 49.1192\n",
-      "Epoch 4/50\n",
-      "339/339 [==============================] - 0s 83us/sample - loss: 44.6474 - mean_squared_error: 44.6474 - val_loss: 33.1579 - val_mean_squared_error: 33.1579\n",
-      "Epoch 5/50\n",
-      "339/339 [==============================] - 0s 86us/sample - loss: 33.9135 - mean_squared_error: 33.9135 - val_loss: 26.5114 - val_mean_squared_error: 26.5114\n",
-      "Epoch 6/50\n",
-      "339/339 [==============================] - 0s 90us/sample - loss: 29.1068 - mean_squared_error: 29.1068 - val_loss: 22.8563 - val_mean_squared_error: 22.8563\n",
-      "Epoch 7/50\n",
-      "339/339 [==============================] - 0s 86us/sample - loss: 26.0441 - mean_squared_error: 26.0441 - val_loss: 21.0577 - val_mean_squared_error: 21.0577\n",
-      "Epoch 8/50\n",
-      "339/339 [==============================] - 0s 83us/sample - loss: 23.8012 - mean_squared_error: 23.8012 - val_loss: 19.6500 - val_mean_squared_error: 19.6500\n",
-      "Epoch 9/50\n",
-      "339/339 [==============================] - 0s 87us/sample - loss: 22.0960 - mean_squared_error: 22.0960 - val_loss: 18.4615 - val_mean_squared_error: 18.4615\n",
-      "Epoch 10/50\n",
-      "339/339 [==============================] - 0s 87us/sample - loss: 20.4015 - mean_squared_error: 20.4015 - val_loss: 16.8798 - val_mean_squared_error: 16.8798\n",
-      "Epoch 11/50\n",
-      "339/339 [==============================] - 0s 87us/sample - loss: 18.8368 - mean_squared_error: 18.8368 - val_loss: 16.0103 - val_mean_squared_error: 16.0103\n",
-      "Epoch 12/50\n",
-      "339/339 [==============================] - 0s 84us/sample - loss: 17.7578 - mean_squared_error: 17.7578 - val_loss: 15.9651 - val_mean_squared_error: 15.9651\n",
-      "Epoch 13/50\n",
-      "339/339 [==============================] - 0s 82us/sample - loss: 16.6941 - mean_squared_error: 16.6941 - val_loss: 17.1631 - val_mean_squared_error: 17.1631\n",
-      "Epoch 14/50\n",
-      "339/339 [==============================] - 0s 85us/sample - loss: 16.4518 - mean_squared_error: 16.4518 - val_loss: 14.2232 - val_mean_squared_error: 14.2232\n",
-      "Epoch 15/50\n",
-      "339/339 [==============================] - 0s 83us/sample - loss: 15.2741 - mean_squared_error: 15.2741 - val_loss: 14.8824 - val_mean_squared_error: 14.8824\n",
-      "Epoch 16/50\n",
-      "339/339 [==============================] - 0s 88us/sample - loss: 15.0555 - mean_squared_error: 15.0555 - val_loss: 13.6472 - val_mean_squared_error: 13.6472\n",
-      "Epoch 17/50\n",
-      "339/339 [==============================] - 0s 87us/sample - loss: 14.4602 - mean_squared_error: 14.4602 - val_loss: 12.9781 - val_mean_squared_error: 12.9781\n",
-      "Epoch 18/50\n",
-      "339/339 [==============================] - 0s 89us/sample - loss: 13.8586 - mean_squared_error: 13.8586 - val_loss: 12.5347 - val_mean_squared_error: 12.5347\n",
-      "Epoch 19/50\n",
-      "339/339 [==============================] - 0s 87us/sample - loss: 13.6874 - mean_squared_error: 13.6874 - val_loss: 12.4062 - val_mean_squared_error: 12.4062\n",
-      "Epoch 20/50\n",
-      "339/339 [==============================] - 0s 89us/sample - loss: 13.1289 - mean_squared_error: 13.1289 - val_loss: 12.8965 - val_mean_squared_error: 12.8965\n",
-      "Epoch 21/50\n",
-      "339/339 [==============================] - 0s 90us/sample - loss: 12.9636 - mean_squared_error: 12.9636 - val_loss: 11.8393 - val_mean_squared_error: 11.8393\n",
-      "Epoch 22/50\n",
-      "339/339 [==============================] - 0s 84us/sample - loss: 12.6905 - mean_squared_error: 12.6905 - val_loss: 11.9046 - val_mean_squared_error: 11.9046\n",
-      "Epoch 23/50\n",
-      "339/339 [==============================] - 0s 84us/sample - loss: 12.3174 - mean_squared_error: 12.3174 - val_loss: 11.7349 - val_mean_squared_error: 11.7349\n",
-      "Epoch 24/50\n",
-      "339/339 [==============================] - 0s 88us/sample - loss: 11.9281 - mean_squared_error: 11.9281 - val_loss: 11.9656 - val_mean_squared_error: 11.9656\n",
-      "Epoch 25/50\n",
-      "339/339 [==============================] - 0s 84us/sample - loss: 11.8962 - mean_squared_error: 11.8962 - val_loss: 12.0452 - val_mean_squared_error: 12.0452\n",
-      "Epoch 26/50\n",
-      "339/339 [==============================] - 0s 83us/sample - loss: 11.5107 - mean_squared_error: 11.5107 - val_loss: 11.4149 - val_mean_squared_error: 11.4149\n",
-      "Epoch 27/50\n",
-      "339/339 [==============================] - 0s 84us/sample - loss: 11.2426 - mean_squared_error: 11.2426 - val_loss: 11.2239 - val_mean_squared_error: 11.2239\n",
-      "Epoch 28/50\n",
-      "339/339 [==============================] - 0s 84us/sample - loss: 11.1747 - mean_squared_error: 11.1747 - val_loss: 11.5999 - val_mean_squared_error: 11.5999\n",
-      "Epoch 29/50\n",
-      "339/339 [==============================] - 0s 89us/sample - loss: 10.8296 - mean_squared_error: 10.8296 - val_loss: 11.1040 - val_mean_squared_error: 11.1040\n",
-      "Epoch 30/50\n",
-      "339/339 [==============================] - 0s 83us/sample - loss: 10.5858 - mean_squared_error: 10.5858 - val_loss: 11.6639 - val_mean_squared_error: 11.6639\n",
-      "Epoch 31/50\n",
-      "339/339 [==============================] - 0s 82us/sample - loss: 10.3166 - mean_squared_error: 10.3166 - val_loss: 11.0816 - val_mean_squared_error: 11.0816\n",
-      "Epoch 32/50\n",
-      "339/339 [==============================] - 0s 83us/sample - loss: 10.3662 - mean_squared_error: 10.3662 - val_loss: 10.9698 - val_mean_squared_error: 10.9698\n",
-      "Epoch 33/50\n",
-      "339/339 [==============================] - 0s 84us/sample - loss: 10.3668 - mean_squared_error: 10.3668 - val_loss: 11.0636 - val_mean_squared_error: 11.0636\n",
-      "Epoch 34/50\n",
-      "339/339 [==============================] - 0s 85us/sample - loss: 10.2008 - mean_squared_error: 10.2008 - val_loss: 11.2904 - val_mean_squared_error: 11.2904\n",
-      "Epoch 35/50\n",
-      "339/339 [==============================] - 0s 85us/sample - loss: 9.7613 - mean_squared_error: 9.7613 - val_loss: 11.9080 - val_mean_squared_error: 11.9080\n",
-      "Epoch 36/50\n",
-      "339/339 [==============================] - 0s 80us/sample - loss: 9.6370 - mean_squared_error: 9.6370 - val_loss: 11.0098 - val_mean_squared_error: 11.0098\n",
-      "Epoch 37/50\n",
-      "339/339 [==============================] - 0s 82us/sample - loss: 9.4705 - mean_squared_error: 9.4705 - val_loss: 10.7119 - val_mean_squared_error: 10.7119\n",
-      "Epoch 38/50\n",
-      "339/339 [==============================] - 0s 85us/sample - loss: 9.6508 - mean_squared_error: 9.6508 - val_loss: 10.7547 - val_mean_squared_error: 10.7547\n",
-      "Epoch 39/50\n",
-      "339/339 [==============================] - 0s 85us/sample - loss: 9.1422 - mean_squared_error: 9.1422 - val_loss: 10.7156 - val_mean_squared_error: 10.7156\n",
-      "Epoch 40/50\n",
-      "339/339 [==============================] - 0s 83us/sample - loss: 9.0300 - mean_squared_error: 9.0300 - val_loss: 10.7564 - val_mean_squared_error: 10.7564\n",
-      "Epoch 41/50\n",
-      "339/339 [==============================] - 0s 87us/sample - loss: 8.8902 - mean_squared_error: 8.8902 - val_loss: 10.4726 - val_mean_squared_error: 10.4726\n",
-      "Epoch 42/50\n",
-      "339/339 [==============================] - 0s 87us/sample - loss: 8.7206 - mean_squared_error: 8.7206 - val_loss: 10.9554 - val_mean_squared_error: 10.9554\n",
-      "Epoch 43/50\n",
-      "339/339 [==============================] - 0s 82us/sample - loss: 8.6436 - mean_squared_error: 8.6436 - val_loss: 10.4429 - val_mean_squared_error: 10.4429\n",
-      "Epoch 44/50\n",
-      "339/339 [==============================] - 0s 83us/sample - loss: 8.7554 - mean_squared_error: 8.7554 - val_loss: 10.3802 - val_mean_squared_error: 10.3802\n",
-      "Epoch 45/50\n",
-      "339/339 [==============================] - 0s 81us/sample - loss: 8.2557 - mean_squared_error: 8.2557 - val_loss: 10.3291 - val_mean_squared_error: 10.3291\n",
-      "Epoch 46/50\n",
-      "339/339 [==============================] - 0s 85us/sample - loss: 8.3303 - mean_squared_error: 8.3303 - val_loss: 10.2898 - val_mean_squared_error: 10.2898\n",
-      "Epoch 47/50\n",
-      "339/339 [==============================] - 0s 90us/sample - loss: 8.1261 - mean_squared_error: 8.1261 - val_loss: 10.8009 - val_mean_squared_error: 10.8009\n",
-      "Epoch 48/50\n",
-      "339/339 [==============================] - 0s 85us/sample - loss: 7.9084 - mean_squared_error: 7.9084 - val_loss: 10.3298 - val_mean_squared_error: 10.3298\n",
-      "Epoch 49/50\n",
-      "339/339 [==============================] - 0s 84us/sample - loss: 7.6370 - mean_squared_error: 7.6370 - val_loss: 10.9119 - val_mean_squared_error: 10.9119\n",
-      "Epoch 50/50\n",
-      "339/339 [==============================] - 0s 93us/sample - loss: 7.9129 - mean_squared_error: 7.9129 - val_loss: 10.5253 - val_mean_squared_error: 10.5253\n"
+     "ename": "TypeError",
+     "evalue": "'NoneType' object is not iterable",
+     "output_type": "error",
+     "traceback": [
+      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
+      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
+      "\u001b[0;32m<ipython-input-21-227d2b8d9d49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rmsprop'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# Fit Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
+      "\u001b[0;32m/anaconda3/envs/U4-S2-NN/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    778\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m           \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m           steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m   def evaluate(self,\n",
+      "\u001b[0;32m/anaconda3/envs/U4-S2-NN/lib/python3.7/site-packages/wandb/keras/__init__.py\u001b[0m in \u001b[0;36mnew_arrays\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;31m# TODO: these could be generators, why index 0?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mval_inputs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mval_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mcbk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcbks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m                 \u001b[0mset_wandb_attrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcbk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mval_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_targets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mold_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
+      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
      ]
-    },
-    {
-     "data": {
-      "text/plain": [
-       "<tensorflow.python.keras.callbacks.History at 0x1a2ce7e3c8>"
-      ]
-     },
-     "execution_count": 10,
-     "metadata": {},
-     "output_type": "execute_result"
     }
    ],
    "source": [
@@ -658,7 +602,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 14,
+   "execution_count": 15,
    "metadata": {
     "colab": {
      "base_uri": "https://localhost:8080/",
@@ -673,7 +617,7 @@
      "name": "stdout",
      "output_type": "stream",
      "text": [
-      "K-fold Cross-Val Results - Mean: 23.24 StDev: 14.49 MSE\n"
+      "K-fold Cross-Val Results - Mean: 20.77 StDev: 12.23 MSE\n"
      ]
     }
    ],
@@ -906,7 +850,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 20,
+   "execution_count": 16,
    "metadata": {
     "colab": {
      "base_uri": "https://localhost:8080/",
@@ -921,8 +865,11 @@
      "name": "stderr",
      "output_type": "stream",
      "text": [
-      "/Users/jonathansokoll/anaconda3/envs/U4-S2-NNF/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
-      "  warnings.warn(CV_WARNING, FutureWarning)\n"
+      "/anaconda3/envs/U4-S2-NN/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
+      "  warnings.warn(CV_WARNING, FutureWarning)\n",
+      "W0912 10:16:09.211765 4373476800 deprecation.py:323] From /anaconda3/envs/U4-S2-NN/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
+      "Instructions for updating:\n",
+      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
      ]
     },
     {
@@ -930,790 +877,790 @@
      "output_type": "stream",
      "text": [
       "Epoch 1/20\n",
-      "512/512 [==============================] - 0s 419us/sample - loss: 15.3302 - acc: 0.6660\n",
+      "512/512 [==============================] - 0s 957us/sample - loss: 6.9721 - acc: 0.6211\n",
       "Epoch 2/20\n",
-      "512/512 [==============================] - 0s 95us/sample - loss: 3.3954 - acc: 0.6348\n",
+      "512/512 [==============================] - 0s 128us/sample - loss: 2.9180 - acc: 0.5703\n",
       "Epoch 3/20\n",
-      "512/512 [==============================] - 0s 88us/sample - loss: 1.5552 - acc: 0.5938\n",
+      "512/512 [==============================] - 0s 128us/sample - loss: 1.7652 - acc: 0.5254\n",
       "Epoch 4/20\n",
-      "512/512 [==============================] - 0s 87us/sample - loss: 1.3141 - acc: 0.5996\n",
+      "512/512 [==============================] - 0s 136us/sample - loss: 1.5626 - acc: 0.5332\n",
       "Epoch 5/20\n",
-      "512/512 [==============================] - 0s 87us/sample - loss: 1.1193 - acc: 0.6016\n",
+      "512/512 [==============================] - 0s 135us/sample - loss: 1.4656 - acc: 0.5762\n",
       "Epoch 6/20\n",
-      "512/512 [==============================] - 0s 89us/sample - loss: 1.0316 - acc: 0.6270\n",
+      "512/512 [==============================] - 0s 126us/sample - loss: 1.3464 - acc: 0.5762\n",
       "Epoch 7/20\n",
-      "512/512 [==============================] - 0s 91us/sample - loss: 0.9822 - acc: 0.6309\n",
+      "512/512 [==============================] - 0s 131us/sample - loss: 1.2134 - acc: 0.5840\n",
       "Epoch 8/20\n",
-      "512/512 [==============================] - 0s 89us/sample - loss: 0.8956 - acc: 0.6426\n",
+      "512/512 [==============================] - 0s 130us/sample - loss: 1.1154 - acc: 0.5859\n",
       "Epoch 9/20\n",
-      "512/512 [==============================] - 0s 87us/sample - loss: 0.8632 - acc: 0.6426\n",
+      "512/512 [==============================] - 0s 123us/sample - loss: 1.1169 - acc: 0.5977\n",
       "Epoch 10/20\n",
-      "512/512 [==============================] - 0s 86us/sample - loss: 0.8722 - acc: 0.6387\n",
+      "512/512 [==============================] - 0s 129us/sample - loss: 0.9688 - acc: 0.6094\n",
       "Epoch 11/20\n",
-      "512/512 [==============================] - 0s 87us/sample - loss: 0.8340 - acc: 0.6426\n",
+      "512/512 [==============================] - 0s 124us/sample - loss: 0.9033 - acc: 0.6289\n",
       "Epoch 12/20\n",
-      "512/512 [==============================] - 0s 88us/sample - loss: 0.7736 - acc: 0.6582\n",
+      "512/512 [==============================] - 0s 129us/sample - loss: 0.8432 - acc: 0.6426\n",
       "Epoch 13/20\n",
-      "512/512 [==============================] - 0s 87us/sample - loss: 0.8033 - acc: 0.6602\n",
+      "512/512 [==============================] - 0s 151us/sample - loss: 0.8650 - acc: 0.6426\n",
       "Epoch 14/20\n",
-      "512/512 [==============================] - 0s 87us/sample - loss: 0.7617 - acc: 0.6387\n",
+      "512/512 [==============================] - 0s 129us/sample - loss: 0.7977 - acc: 0.6328\n",
       "Epoch 15/20\n",
-      "512/512 [==============================] - 0s 83us/sample - loss: 0.7571 - acc: 0.6445\n",
+      "512/512 [==============================] - 0s 138us/sample - loss: 0.7340 - acc: 0.6602\n",
       "Epoch 16/20\n",
-      "512/512 [==============================] - 0s 74us/sample - loss: 0.7398 - acc: 0.6758\n",
+      "512/512 [==============================] - 0s 130us/sample - loss: 0.7206 - acc: 0.6484\n",
       "Epoch 17/20\n",
-      "512/512 [==============================] - 0s 78us/sample - loss: 0.7504 - acc: 0.6816\n",
+      "512/512 [==============================] - 0s 152us/sample - loss: 0.6798 - acc: 0.6660\n",
       "Epoch 18/20\n",
-      "512/512 [==============================] - 0s 76us/sample - loss: 0.7454 - acc: 0.6582\n",
+      "512/512 [==============================] - 0s 154us/sample - loss: 0.6822 - acc: 0.6777\n",
       "Epoch 19/20\n",
-      "512/512 [==============================] - 0s 79us/sample - loss: 0.7731 - acc: 0.6504\n",
+      "512/512 [==============================] - 0s 142us/sample - loss: 0.7605 - acc: 0.6523\n",
       "Epoch 20/20\n",
-      "512/512 [==============================] - 0s 75us/sample - loss: 0.6943 - acc: 0.6758\n",
-      "256/256 [==============================] - 0s 468us/sample - loss: 0.7612 - acc: 0.6992\n",
+      "512/512 [==============================] - 0s 142us/sample - loss: 0.6404 - acc: 0.6895\n",
+      "256/256 [==============================] - 0s 561us/sample - loss: 0.8476 - acc: 0.6250\n",
       "Epoch 1/20\n",
-      "512/512 [==============================] - 0s 390us/sample - loss: 9.1114 - acc: 0.4766\n",
+      "512/512 [==============================] - 0s 822us/sample - loss: 5.6095 - acc: 0.4277\n",
       "Epoch 2/20\n",
-      "512/512 [==============================] - 0s 86us/sample - loss: 5.5282 - acc: 0.5723\n",
+      "512/512 [==============================] - 0s 135us/sample - loss: 3.8286 - acc: 0.4512\n",
       "Epoch 3/20\n",
-      "512/512 [==============================] - 0s 83us/sample - loss: 4.3788 - acc: 0.5723\n",
+      "512/512 [==============================] - 0s 132us/sample - loss: 3.3108 - acc: 0.4668\n",
       "Epoch 4/20\n",
-      "512/512 [==============================] - 0s 82us/sample - loss: 3.4485 - acc: 0.5840\n",
+      "512/512 [==============================] - 0s 138us/sample - loss: 2.7699 - acc: 0.4609\n",
       "Epoch 5/20\n",
-      "512/512 [==============================] - 0s 84us/sample - loss: 2.5568 - acc: 0.5918\n",
+      "512/512 [==============================] - 0s 145us/sample - loss: 2.3866 - acc: 0.4668\n",
       "Epoch 6/20\n",
-      "512/512 [==============================] - 0s 80us/sample - loss: 1.5828 - acc: 0.6230\n",
+      "512/512 [==============================] - 0s 140us/sample - loss: 1.9064 - acc: 0.4746\n",
       "Epoch 7/20\n",
-      "512/512 [==============================] - 0s 74us/sample - loss: 1.0696 - acc: 0.5938\n",
+      "512/512 [==============================] - 0s 137us/sample - loss: 1.4142 - acc: 0.4941\n",
       "Epoch 8/20\n",
-      "512/512 [==============================] - 0s 77us/sample - loss: 1.0402 - acc: 0.6133\n",
+      "512/512 [==============================] - 0s 184us/sample - loss: 1.0510 - acc: 0.5293\n",
       "Epoch 9/20\n",
-      "512/512 [==============================] - 0s 84us/sample - loss: 0.8922 - acc: 0.6289\n",
+      "512/512 [==============================] - 0s 186us/sample - loss: 0.9006 - acc: 0.5586\n",
       "Epoch 10/20\n",
-      "512/512 [==============================] - 0s 87us/sample - loss: 0.9074 - acc: 0.6309\n",
+      "512/512 [==============================] - 0s 172us/sample - loss: 0.8230 - acc: 0.5820\n",
       "Epoch 11/20\n",
-      "512/512 [==============================] - 0s 91us/sample - loss: 0.9143 - acc: 0.5957\n",
+      "512/512 [==============================] - 0s 170us/sample - loss: 0.8209 - acc: 0.5762\n",
       "Epoch 12/20\n",
-      "512/512 [==============================] - 0s 90us/sample - loss: 0.7977 - acc: 0.6309\n",
+      "512/512 [==============================] - 0s 163us/sample - loss: 0.7515 - acc: 0.6387\n",
       "Epoch 13/20\n",
-      "512/512 [==============================] - 0s 87us/sample - loss: 0.7761 - acc: 0.6484\n",
+      "512/512 [==============================] - 0s 170us/sample - loss: 0.7079 - acc: 0.6504\n",
       "Epoch 14/20\n",
-      "512/512 [==============================] - 0s 88us/sample - loss: 0.7725 - acc: 0.6289\n",
+      "512/512 [==============================] - 0s 184us/sample - loss: 0.7179 - acc: 0.6348\n",
       "Epoch 15/20\n",
-      "512/512 [==============================] - 0s 86us/sample - loss: 0.7280 - acc: 0.6406\n",
+      "512/512 [==============================] - 0s 153us/sample - loss: 0.7005 - acc: 0.6504\n",
       "Epoch 16/20\n",
-      "512/512 [==============================] - 0s 85us/sample - loss: 0.7468 - acc: 0.6543\n",
+      "512/512 [==============================] - 0s 173us/sample - loss: 0.6356 - acc: 0.6777\n",
       "Epoch 17/20\n",
-      "512/512 [==============================] - 0s 83us/sample - loss: 0.7334 - acc: 0.6523\n",
+      "512/512 [==============================] - 0s 156us/sample - loss: 0.6868 - acc: 0.6445\n",
       "Epoch 18/20\n",
-      "512/512 [==============================] - 0s 85us/sample - loss: 0.7951 - acc: 0.6367\n",
+      "512/512 [==============================] - 0s 130us/sample - loss: 0.7013 - acc: 0.6328\n",
       "Epoch 19/20\n",
-      "512/512 [==============================] - 0s 84us/sample - loss: 0.6843 - acc: 0.6621\n",
+      "512/512 [==============================] - 0s 130us/sample - loss: 0.6200 - acc: 0.6973\n",
       "Epoch 20/20\n",
-      "512/512 [==============================] - 0s 75us/sample - loss: 0.6816 - acc: 0.6758\n",
-      "256/256 [==============================] - 0s 445us/sample - loss: 0.7719 - acc: 0.6445\n",
+      "512/512 [==============================] - 0s 133us/sample - loss: 0.6330 - acc: 0.6895\n",
+      "256/256 [==============================] - 0s 896us/sample - loss: 0.6552 - acc: 0.6641\n",
       "Epoch 1/20\n",
-      "512/512 [==============================] - 0s 392us/sample - loss: 4.7487 - acc: 0.4531\n",
+      "512/512 [==============================] - 1s 1ms/sample - loss: 10.5498 - acc: 0.5059\n",
       "Epoch 2/20\n",
-      "512/512 [==============================] - 0s 79us/sample - loss: 3.4040 - acc: 0.4473\n",
+      "512/512 [==============================] - 0s 139us/sample - loss: 4.0260 - acc: 0.6074\n",
       "Epoch 3/20\n",
-      "512/512 [==============================] - 0s 77us/sample - loss: 2.3425 - acc: 0.5020\n",
+      "512/512 [==============================] - 0s 133us/sample - loss: 2.0799 - acc: 0.5547\n",
       "Epoch 4/20\n",
-      "512/512 [==============================] - 0s 81us/sample - loss: 1.6176 - acc: 0.5449\n",
+      "512/512 [==============================] - 0s 147us/sample - loss: 1.8483 - acc: 0.5781\n",
       "Epoch 5/20\n",
-      "512/512 [==============================] - 0s 77us/sample - loss: 1.2427 - acc: 0.6035\n",
+      "512/512 [==============================] - 0s 132us/sample - loss: 1.7823 - acc: 0.5820\n",
       "Epoch 6/20\n",
-      "512/512 [==============================] - 0s 81us/sample - loss: 1.0910 - acc: 0.6074\n",
+      "512/512 [==============================] - 0s 135us/sample - loss: 1.7839 - acc: 0.5645\n",
       "Epoch 7/20\n",
-      "512/512 [==============================] - 0s 77us/sample - loss: 0.9770 - acc: 0.6270\n",
+      "512/512 [==============================] - 0s 158us/sample - loss: 1.4907 - acc: 0.5996\n",
       "Epoch 8/20\n",
-      "512/512 [==============================] - 0s 82us/sample - loss: 0.9029 - acc: 0.6328\n",
+      "512/512 [==============================] - 0s 176us/sample - loss: 1.3981 - acc: 0.5957\n",
       "Epoch 9/20\n",
-      "512/512 [==============================] - 0s 79us/sample - loss: 0.8453 - acc: 0.6348\n",
+      "512/512 [==============================] - 0s 163us/sample - loss: 1.3740 - acc: 0.5996\n",
       "Epoch 10/20\n",
-      "512/512 [==============================] - 0s 81us/sample - loss: 0.8189 - acc: 0.6348\n",
+      "512/512 [==============================] - 0s 164us/sample - loss: 1.3266 - acc: 0.5684\n",
       "Epoch 11/20\n",
-      "512/512 [==============================] - 0s 78us/sample - loss: 0.7726 - acc: 0.6309\n",
+      "512/512 [==============================] - 0s 146us/sample - loss: 1.1980 - acc: 0.5801\n",
       "Epoch 12/20\n",
-      "512/512 [==============================] - 0s 77us/sample - loss: 0.7476 - acc: 0.6641\n",
+      "512/512 [==============================] - 0s 145us/sample - loss: 1.1536 - acc: 0.5664\n",
       "Epoch 13/20\n",
-      "512/512 [==============================] - 0s 78us/sample - loss: 0.7287 - acc: 0.6641\n",
+      "512/512 [==============================] - 0s 143us/sample - loss: 1.1112 - acc: 0.6055\n",
       "Epoch 14/20\n",
-      "512/512 [==============================] - 0s 78us/sample - loss: 0.7082 - acc: 0.6641\n",
+      "512/512 [==============================] - 0s 150us/sample - loss: 1.0456 - acc: 0.6152\n",
       "Epoch 15/20\n",
-      "512/512 [==============================] - 0s 78us/sample - loss: 0.6935 - acc: 0.6680\n",
+      "512/512 [==============================] - 0s 154us/sample - loss: 0.9937 - acc: 0.6094\n",
       "Epoch 16/20\n",
-      "512/512 [==============================] - 0s 81us/sample - loss: 0.6797 - acc: 0.6641\n",
+      "512/512 [==============================] - 0s 165us/sample - loss: 0.9776 - acc: 0.5840\n",
       "Epoch 17/20\n",
-      "512/512 [==============================] - 0s 77us/sample - loss: 0.6644 - acc: 0.6582\n",
+      "512/512 [==============================] - 0s 159us/sample - loss: 0.9279 - acc: 0.6113\n",
       "Epoch 18/20\n",
-      "512/512 [==============================] - 0s 80us/sample - loss: 0.6564 - acc: 0.6660\n",
+      "512/512 [==============================] - 0s 153us/sample - loss: 0.9059 - acc: 0.5820\n",
       "Epoch 19/20\n",
-      "512/512 [==============================] - 0s 91us/sample - loss: 0.6543 - acc: 0.6484\n",
+      "512/512 [==============================] - 0s 146us/sample - loss: 0.8642 - acc: 0.6113\n",
       "Epoch 20/20\n",
-      "512/512 [==============================] - 0s 84us/sample - loss: 0.6575 - acc: 0.6621\n",
-      "256/256 [==============================] - 0s 482us/sample - loss: 0.7347 - acc: 0.6562\n",
+      "512/512 [==============================] - 0s 148us/sample - loss: 0.8853 - acc: 0.6270\n",
+      "256/256 [==============================] - 0s 710us/sample - loss: 0.7494 - acc: 0.6328\n",
       "Epoch 1/20\n",
-      "512/512 [==============================] - 0s 373us/sample - loss: 3.6687 - acc: 0.4844\n",
+      "512/512 [==============================] - 1s 1ms/sample - loss: 6.3299 - acc: 0.4902\n",
       "Epoch 2/20\n",
-      "512/512 [==============================] - 0s 53us/sample - loss: 2.1635 - acc: 0.5645\n",
+      "512/512 [==============================] - 0s 87us/sample - loss: 3.1209 - acc: 0.6445\n",
       "Epoch 3/20\n",
-      "512/512 [==============================] - 0s 53us/sample - loss: 1.9848 - acc: 0.5625\n",
+      "512/512 [==============================] - 0s 86us/sample - loss: 2.4535 - acc: 0.5977\n",
       "Epoch 4/20\n",
-      "512/512 [==============================] - 0s 50us/sample - loss: 1.8195 - acc: 0.5586\n",
+      "512/512 [==============================] - 0s 88us/sample - loss: 2.2418 - acc: 0.6074\n",
       "Epoch 5/20\n",
-      "512/512 [==============================] - 0s 49us/sample - loss: 1.7241 - acc: 0.5625\n",
+      "512/512 [==============================] - 0s 89us/sample - loss: 2.0638 - acc: 0.5957\n",
       "Epoch 6/20\n",
-      "512/512 [==============================] - 0s 50us/sample - loss: 1.6064 - acc: 0.5801\n",
+      "512/512 [==============================] - 0s 85us/sample - loss: 1.9032 - acc: 0.6074\n",
       "Epoch 7/20\n",
-      "512/512 [==============================] - 0s 49us/sample - loss: 1.5171 - acc: 0.5801\n",
+      "512/512 [==============================] - 0s 80us/sample - loss: 1.7302 - acc: 0.5938\n",
       "Epoch 8/20\n",
-      "512/512 [==============================] - 0s 49us/sample - loss: 1.4284 - acc: 0.5918\n",
+      "512/512 [==============================] - 0s 80us/sample - loss: 1.6084 - acc: 0.6348\n",
       "Epoch 9/20\n",
-      "512/512 [==============================] - 0s 48us/sample - loss: 1.3014 - acc: 0.5859\n",
+      "512/512 [==============================] - 0s 77us/sample - loss: 1.4932 - acc: 0.6113\n",
       "Epoch 10/20\n",
-      "512/512 [==============================] - 0s 49us/sample - loss: 1.2618 - acc: 0.5918\n",
+      "512/512 [==============================] - 0s 80us/sample - loss: 1.4343 - acc: 0.6133\n",
       "Epoch 11/20\n",
-      "512/512 [==============================] - 0s 49us/sample - loss: 1.1691 - acc: 0.6133\n",
+      "512/512 [==============================] - 0s 65us/sample - loss: 1.2737 - acc: 0.6152\n",
       "Epoch 12/20\n",
-      "512/512 [==============================] - 0s 50us/sample - loss: 1.1232 - acc: 0.6172\n",
+      "512/512 [==============================] - 0s 64us/sample - loss: 1.1936 - acc: 0.6289\n",
       "Epoch 13/20\n",
-      "512/512 [==============================] - 0s 48us/sample - loss: 1.0428 - acc: 0.6309\n",
+      "512/512 [==============================] - 0s 68us/sample - loss: 1.0536 - acc: 0.6270\n",
       "Epoch 14/20\n",
-      "512/512 [==============================] - 0s 49us/sample - loss: 0.9959 - acc: 0.6270\n",
+      "512/512 [==============================] - 0s 69us/sample - loss: 0.9930 - acc: 0.6348\n",
       "Epoch 15/20\n",
-      "512/512 [==============================] - 0s 47us/sample - loss: 0.9482 - acc: 0.6328\n",
+      "512/512 [==============================] - 0s 94us/sample - loss: 0.9505 - acc: 0.6348\n",
       "Epoch 16/20\n",
-      "512/512 [==============================] - 0s 47us/sample - loss: 0.9201 - acc: 0.6426\n",
+      "512/512 [==============================] - 0s 67us/sample - loss: 0.9235 - acc: 0.6445\n",
       "Epoch 17/20\n",
-      "512/512 [==============================] - 0s 47us/sample - loss: 0.8558 - acc: 0.6602\n",
+      "512/512 [==============================] - 0s 68us/sample - loss: 0.8742 - acc: 0.6484\n",
       "Epoch 18/20\n",
-      "512/512 [==============================] - 0s 48us/sample - loss: 0.8373 - acc: 0.6543\n",
+      "512/512 [==============================] - 0s 75us/sample - loss: 0.8460 - acc: 0.6582\n",
       "Epoch 19/20\n",
-      "512/512 [==============================] - 0s 48us/sample - loss: 0.8123 - acc: 0.6562\n",
+      "512/512 [==============================] - 0s 71us/sample - loss: 0.8450 - acc: 0.6562\n",
       "Epoch 20/20\n",
-      "512/512 [==============================] - 0s 49us/sample - loss: 0.7867 - acc: 0.6758\n",
-      "256/256 [==============================] - 0s 486us/sample - loss: 0.8918 - acc: 0.6055\n",
+      "512/512 [==============================] - 0s 68us/sample - loss: 0.8229 - acc: 0.6270\n",
+      "256/256 [==============================] - 0s 547us/sample - loss: 0.9204 - acc: 0.6172\n",
       "Epoch 1/20\n",
-      "512/512 [==============================] - 0s 368us/sample - loss: 30.3564 - acc: 0.6465\n",
+      "512/512 [==============================] - 0s 825us/sample - loss: 12.9047 - acc: 0.3516\n",
       "Epoch 2/20\n",
-      "512/512 [==============================] - 0s 45us/sample - loss: 20.7263 - acc: 0.6465\n",
+      "512/512 [==============================] - 0s 68us/sample - loss: 4.8117 - acc: 0.4941\n",
       "Epoch 3/20\n",
-      "512/512 [==============================] - 0s 51us/sample - loss: 11.9238 - acc: 0.6328\n",
+      "512/512 [==============================] - 0s 85us/sample - loss: 3.2313 - acc: 0.5449\n",
       "Epoch 4/20\n",
-      "512/512 [==============================] - 0s 52us/sample - loss: 6.7630 - acc: 0.6035\n",
+      "512/512 [==============================] - 0s 69us/sample - loss: 2.4370 - acc: 0.5605\n",
       "Epoch 5/20\n",
-      "512/512 [==============================] - 0s 50us/sample - loss: 3.9460 - acc: 0.5703\n",
+      "512/512 [==============================] - 0s 68us/sample - loss: 2.1252 - acc: 0.5566\n",
       "Epoch 6/20\n",
-      "512/512 [==============================] - 0s 50us/sample - loss: 2.4715 - acc: 0.5684\n",
+      "512/512 [==============================] - 0s 68us/sample - loss: 1.9741 - acc: 0.5449\n",
       "Epoch 7/20\n",
-      "512/512 [==============================] - 0s 50us/sample - loss: 1.9508 - acc: 0.6055\n",
+      "512/512 [==============================] - 0s 67us/sample - loss: 1.8531 - acc: 0.5488\n",
       "Epoch 8/20\n",
-      "512/512 [==============================] - 0s 50us/sample - loss: 1.6916 - acc: 0.5977\n",
+      "512/512 [==============================] - 0s 71us/sample - loss: 1.7386 - acc: 0.5547\n",
       "Epoch 9/20\n",
-      "512/512 [==============================] - 0s 48us/sample - loss: 1.5486 - acc: 0.6309\n",
+      "512/512 [==============================] - 0s 65us/sample - loss: 1.6610 - acc: 0.5371\n",
       "Epoch 10/20\n",
-      "512/512 [==============================] - 0s 50us/sample - loss: 1.4506 - acc: 0.6309\n",
+      "512/512 [==============================] - 0s 65us/sample - loss: 1.5684 - acc: 0.5391\n",
       "Epoch 11/20\n",
-      "512/512 [==============================] - 0s 52us/sample - loss: 1.3733 - acc: 0.6328\n",
+      "512/512 [==============================] - 0s 67us/sample - loss: 1.4997 - acc: 0.5332\n",
       "Epoch 12/20\n",
-      "512/512 [==============================] - 0s 47us/sample - loss: 1.3054 - acc: 0.6387\n",
+      "512/512 [==============================] - 0s 66us/sample - loss: 1.4325 - acc: 0.5312\n",
       "Epoch 13/20\n",
-      "512/512 [==============================] - 0s 47us/sample - loss: 1.2617 - acc: 0.6348\n",
+      "512/512 [==============================] - 0s 69us/sample - loss: 1.3605 - acc: 0.5293\n",
       "Epoch 14/20\n",
-      "512/512 [==============================] - 0s 49us/sample - loss: 1.2054 - acc: 0.6387\n",
+      "512/512 [==============================] - 0s 65us/sample - loss: 1.3198 - acc: 0.5215\n",
       "Epoch 15/20\n",
-      "512/512 [==============================] - 0s 50us/sample - loss: 1.1555 - acc: 0.6367\n",
+      "512/512 [==============================] - 0s 64us/sample - loss: 1.2586 - acc: 0.5371\n",
       "Epoch 16/20\n",
-      "512/512 [==============================] - 0s 47us/sample - loss: 1.1334 - acc: 0.6367\n",
+      "512/512 [==============================] - 0s 72us/sample - loss: 1.2318 - acc: 0.5332\n",
       "Epoch 17/20\n",
-      "512/512 [==============================] - 0s 49us/sample - loss: 1.0946 - acc: 0.6309\n",
+      "512/512 [==============================] - 0s 73us/sample - loss: 1.1756 - acc: 0.5527\n",
       "Epoch 18/20\n",
-      "512/512 [==============================] - 0s 46us/sample - loss: 1.0571 - acc: 0.6445\n",
+      "512/512 [==============================] - 0s 75us/sample - loss: 1.1292 - acc: 0.5312\n",
       "Epoch 19/20\n",
-      "512/512 [==============================] - 0s 50us/sample - loss: 1.0119 - acc: 0.6523\n",
+      "512/512 [==============================] - 0s 77us/sample - loss: 1.0660 - acc: 0.5684\n",
       "Epoch 20/20\n",
-      "512/512 [==============================] - 0s 49us/sample - loss: 0.9886 - acc: 0.6543\n",
-      "256/256 [==============================] - 0s 485us/sample - loss: 0.8301 - acc: 0.6641\n",
+      "512/512 [==============================] - 0s 72us/sample - loss: 1.0395 - acc: 0.5566\n",
+      "256/256 [==============================] - 0s 687us/sample - loss: 0.9970 - acc: 0.6055\n",
       "Epoch 1/20\n",
-      "512/512 [==============================] - 0s 372us/sample - loss: 10.0618 - acc: 0.6328\n",
+      "512/512 [==============================] - 0s 825us/sample - loss: 17.2022 - acc: 0.6387\n",
       "Epoch 2/20\n",
-      "512/512 [==============================] - 0s 51us/sample - loss: 3.2820 - acc: 0.4902\n",
+      "512/512 [==============================] - 0s 66us/sample - loss: 10.3778 - acc: 0.6387\n",
       "Epoch 3/20\n",
-      "512/512 [==============================] - 0s 53us/sample - loss: 2.6071 - acc: 0.5117\n",
+      "512/512 [==============================] - 0s 66us/sample - loss: 5.5213 - acc: 0.6543\n",
       "Epoch 4/20\n",
-      "512/512 [==============================] - 0s 52us/sample - loss: 2.1527 - acc: 0.5176\n",
+      "512/512 [==============================] - 0s 64us/sample - loss: 4.1913 - acc: 0.6426\n",
       "Epoch 5/20\n",
-      "512/512 [==============================] - 0s 45us/sample - loss: 1.9088 - acc: 0.5742\n",
+      "512/512 [==============================] - 0s 75us/sample - loss: 3.2633 - acc: 0.6270\n",
       "Epoch 6/20\n",
-      "512/512 [==============================] - 0s 49us/sample - loss: 1.6627 - acc: 0.5742\n",
+      "512/512 [==============================] - 0s 65us/sample - loss: 2.6199 - acc: 0.5957\n",
       "Epoch 7/20\n",
-      "512/512 [==============================] - 0s 51us/sample - loss: 1.6007 - acc: 0.5938\n",
+      "512/512 [==============================] - 0s 72us/sample - loss: 2.1317 - acc: 0.5820\n",
       "Epoch 8/20\n",
-      "512/512 [==============================] - 0s 46us/sample - loss: 1.2936 - acc: 0.6289\n",
+      "512/512 [==============================] - 0s 75us/sample - loss: 1.7929 - acc: 0.5703\n",
       "Epoch 9/20\n",
-      "512/512 [==============================] - 0s 50us/sample - loss: 1.1793 - acc: 0.6348\n",
+      "512/512 [==============================] - 0s 88us/sample - loss: 1.6049 - acc: 0.5645\n",
       "Epoch 10/20\n",
-      "512/512 [==============================] - 0s 46us/sample - loss: 1.0948 - acc: 0.6543\n",
+      "512/512 [==============================] - 0s 70us/sample - loss: 1.5082 - acc: 0.5820\n",
       "Epoch 11/20\n",
-      "512/512 [==============================] - 0s 49us/sample - loss: 1.0196 - acc: 0.6074\n",
+      "512/512 [==============================] - 0s 70us/sample - loss: 1.4099 - acc: 0.5723\n",
       "Epoch 12/20\n",
-      "512/512 [==============================] - 0s 46us/sample - loss: 0.9237 - acc: 0.6562\n",
+      "512/512 [==============================] - 0s 71us/sample - loss: 1.3560 - acc: 0.5898\n",
       "Epoch 13/20\n",
-      "512/512 [==============================] - 0s 47us/sample - loss: 0.8814 - acc: 0.6406\n",
+      "512/512 [==============================] - 0s 69us/sample - loss: 1.2658 - acc: 0.5977\n",
       "Epoch 14/20\n",
-      "512/512 [==============================] - 0s 47us/sample - loss: 0.8317 - acc: 0.6680\n",
+      "512/512 [==============================] - 0s 70us/sample - loss: 1.1916 - acc: 0.5879\n",
       "Epoch 15/20\n",
-      "512/512 [==============================] - 0s 49us/sample - loss: 0.8194 - acc: 0.6660\n",
+      "512/512 [==============================] - 0s 72us/sample - loss: 1.1682 - acc: 0.6191\n",
       "Epoch 16/20\n",
-      "512/512 [==============================] - 0s 53us/sample - loss: 0.7761 - acc: 0.6719\n",
+      "512/512 [==============================] - 0s 91us/sample - loss: 1.0796 - acc: 0.6016\n",
       "Epoch 17/20\n",
-      "512/512 [==============================] - 0s 48us/sample - loss: 0.7750 - acc: 0.6699\n",
+      "512/512 [==============================] - 0s 91us/sample - loss: 0.9982 - acc: 0.6133\n",
       "Epoch 18/20\n",
-      "512/512 [==============================] - 0s 53us/sample - loss: 0.7388 - acc: 0.6660\n",
+      "512/512 [==============================] - 0s 82us/sample - loss: 0.9633 - acc: 0.6367\n",
       "Epoch 19/20\n",
-      "512/512 [==============================] - 0s 49us/sample - loss: 0.7342 - acc: 0.6719\n",
+      "512/512 [==============================] - 0s 93us/sample - loss: 0.9230 - acc: 0.6270\n",
       "Epoch 20/20\n",
-      "512/512 [==============================] - 0s 52us/sample - loss: 0.7102 - acc: 0.6719\n",
-      "256/256 [==============================] - 0s 482us/sample - loss: 0.7346 - acc: 0.6367\n",
+      "512/512 [==============================] - 0s 88us/sample - loss: 0.9258 - acc: 0.6152\n",
+      "256/256 [==============================] - 0s 697us/sample - loss: 0.8751 - acc: 0.6016\n",
       "Epoch 1/20\n",
-      "512/512 [==============================] - 0s 350us/sample - loss: 18.3196 - acc: 0.4590\n",
+      "512/512 [==============================] - 0s 848us/sample - loss: 13.4640 - acc: 0.6777\n",
       "Epoch 2/20\n",
-      "512/512 [==============================] - 0s 30us/sample - loss: 15.5684 - acc: 0.5059\n",
+      "512/512 [==============================] - 0s 39us/sample - loss: 8.1234 - acc: 0.6758\n",
       "Epoch 3/20\n",
-      "512/512 [==============================] - 0s 28us/sample - loss: 13.1114 - acc: 0.5352\n",
+      "512/512 [==============================] - 0s 36us/sample - loss: 4.8303 - acc: 0.6387\n",
       "Epoch 4/20\n",
-      "512/512 [==============================] - 0s 29us/sample - loss: 10.9383 - acc: 0.5273\n",
+      "512/512 [==============================] - 0s 40us/sample - loss: 4.1033 - acc: 0.5859\n",
       "Epoch 5/20\n",
-      "512/512 [==============================] - 0s 26us/sample - loss: 9.0281 - acc: 0.5098\n",
+      "512/512 [==============================] - 0s 39us/sample - loss: 3.5329 - acc: 0.6016\n",
       "Epoch 6/20\n",
-      "512/512 [==============================] - 0s 31us/sample - loss: 7.3093 - acc: 0.4941\n",
+      "512/512 [==============================] - 0s 37us/sample - loss: 3.2705 - acc: 0.6113\n",
       "Epoch 7/20\n",
-      "512/512 [==============================] - 0s 31us/sample - loss: 5.8717 - acc: 0.4746\n",
+      "512/512 [==============================] - 0s 37us/sample - loss: 3.0268 - acc: 0.6152\n",
       "Epoch 8/20\n",
-      "512/512 [==============================] - 0s 27us/sample - loss: 4.7162 - acc: 0.4609\n",
+      "512/512 [==============================] - 0s 39us/sample - loss: 2.8272 - acc: 0.6289\n",
       "Epoch 9/20\n",
-      "512/512 [==============================] - 0s 27us/sample - loss: 3.9802 - acc: 0.4629\n",
+      "512/512 [==============================] - 0s 37us/sample - loss: 2.6663 - acc: 0.6445\n",
       "Epoch 10/20\n",
-      "512/512 [==============================] - 0s 26us/sample - loss: 3.5831 - acc: 0.4766\n",
+      "512/512 [==============================] - 0s 38us/sample - loss: 2.5298 - acc: 0.6426\n",
       "Epoch 11/20\n",
-      "512/512 [==============================] - 0s 25us/sample - loss: 3.3339 - acc: 0.5273\n",
+      "512/512 [==============================] - 0s 46us/sample - loss: 2.3919 - acc: 0.6602\n",
       "Epoch 12/20\n",
-      "512/512 [==============================] - 0s 25us/sample - loss: 3.1003 - acc: 0.5098\n",
+      "512/512 [==============================] - 0s 54us/sample - loss: 2.2705 - acc: 0.6660\n",
       "Epoch 13/20\n",
-      "512/512 [==============================] - 0s 31us/sample - loss: 2.9321 - acc: 0.4824\n",
+      "512/512 [==============================] - 0s 44us/sample - loss: 2.1995 - acc: 0.6582\n",
       "Epoch 14/20\n",
-      "512/512 [==============================] - 0s 25us/sample - loss: 2.7270 - acc: 0.5430\n",
+      "512/512 [==============================] - 0s 52us/sample - loss: 2.0766 - acc: 0.6719\n",
       "Epoch 15/20\n",
-      "512/512 [==============================] - 0s 26us/sample - loss: 2.5706 - acc: 0.5176\n",
+      "512/512 [==============================] - 0s 46us/sample - loss: 1.9480 - acc: 0.6816\n",
       "Epoch 16/20\n",
-      "512/512 [==============================] - 0s 26us/sample - loss: 2.3905 - acc: 0.5000\n",
+      "512/512 [==============================] - 0s 46us/sample - loss: 1.8891 - acc: 0.6719\n",
       "Epoch 17/20\n",
-      "512/512 [==============================] - 0s 28us/sample - loss: 2.3031 - acc: 0.5371\n",
+      "512/512 [==============================] - 0s 47us/sample - loss: 1.7989 - acc: 0.6992\n",
       "Epoch 18/20\n",
-      "512/512 [==============================] - 0s 26us/sample - loss: 2.0744 - acc: 0.5566\n",
+      "512/512 [==============================] - 0s 45us/sample - loss: 1.6701 - acc: 0.6895\n",
       "Epoch 19/20\n",
-      "512/512 [==============================] - 0s 27us/sample - loss: 1.9564 - acc: 0.5566\n",
+      "512/512 [==============================] - 0s 45us/sample - loss: 1.5759 - acc: 0.7070\n",
       "Epoch 20/20\n",
-      "512/512 [==============================] - 0s 25us/sample - loss: 1.8518 - acc: 0.5449\n",
-      "256/256 [==============================] - 0s 513us/sample - loss: 1.8776 - acc: 0.5820\n",
+      "512/512 [==============================] - 0s 44us/sample - loss: 1.4860 - acc: 0.6914\n",
+      "256/256 [==============================] - 0s 609us/sample - loss: 1.7290 - acc: 0.6484\n",
       "Epoch 1/20\n",
-      "512/512 [==============================] - 0s 361us/sample - loss: 26.0958 - acc: 0.6465\n",
+      "512/512 [==============================] - 0s 906us/sample - loss: 19.2049 - acc: 0.6465\n",
       "Epoch 2/20\n",
-      "512/512 [==============================] - 0s 29us/sample - loss: 18.0421 - acc: 0.6348\n",
+      "512/512 [==============================] - 0s 43us/sample - loss: 15.3891 - acc: 0.6465\n",
       "Epoch 3/20\n",
-      "512/512 [==============================] - 0s 26us/sample - loss: 10.6976 - acc: 0.6172\n",
+      "512/512 [==============================] - 0s 40us/sample - loss: 11.9700 - acc: 0.6406\n",
       "Epoch 4/20\n",
-      "512/512 [==============================] - 0s 27us/sample - loss: 6.0661 - acc: 0.5762\n",
+      "512/512 [==============================] - 0s 37us/sample - loss: 9.6356 - acc: 0.5996\n",
       "Epoch 5/20\n",
-      "512/512 [==============================] - 0s 27us/sample - loss: 4.9137 - acc: 0.5801\n",
+      "512/512 [==============================] - 0s 36us/sample - loss: 8.4511 - acc: 0.5977\n",
       "Epoch 6/20\n",
-      "512/512 [==============================] - 0s 25us/sample - loss: 4.5337 - acc: 0.5820\n",
+      "512/512 [==============================] - 0s 36us/sample - loss: 7.2521 - acc: 0.5918\n",
       "Epoch 7/20\n",
-      "512/512 [==============================] - 0s 26us/sample - loss: 4.0811 - acc: 0.6094\n",
+      "512/512 [==============================] - 0s 36us/sample - loss: 6.2126 - acc: 0.5898\n",
       "Epoch 8/20\n",
-      "512/512 [==============================] - 0s 26us/sample - loss: 3.7691 - acc: 0.6094\n",
+      "512/512 [==============================] - 0s 37us/sample - loss: 5.2108 - acc: 0.6016\n",
       "Epoch 9/20\n",
-      "512/512 [==============================] - 0s 24us/sample - loss: 3.4583 - acc: 0.6113\n",
+      "512/512 [==============================] - 0s 36us/sample - loss: 4.3338 - acc: 0.6074\n",
       "Epoch 10/20\n",
-      "512/512 [==============================] - 0s 26us/sample - loss: 3.1552 - acc: 0.6230\n",
+      "512/512 [==============================] - 0s 37us/sample - loss: 3.4514 - acc: 0.6113\n",
       "Epoch 11/20\n",
-      "512/512 [==============================] - 0s 27us/sample - loss: 2.8719 - acc: 0.6113\n",
+      "512/512 [==============================] - 0s 35us/sample - loss: 2.6263 - acc: 0.5898\n",
       "Epoch 12/20\n",
-      "512/512 [==============================] - 0s 26us/sample - loss: 2.6205 - acc: 0.6309\n",
+      "512/512 [==============================] - 0s 37us/sample - loss: 2.0254 - acc: 0.5488\n",
       "Epoch 13/20\n",
-      "512/512 [==============================] - 0s 27us/sample - loss: 2.4389 - acc: 0.6387\n",
+      "512/512 [==============================] - 0s 37us/sample - loss: 1.8169 - acc: 0.5605\n",
       "Epoch 14/20\n",
-      "512/512 [==============================] - 0s 26us/sample - loss: 2.2830 - acc: 0.6445\n",
+      "512/512 [==============================] - 0s 48us/sample - loss: 1.6693 - acc: 0.5781\n",
       "Epoch 15/20\n",
-      "512/512 [==============================] - 0s 25us/sample - loss: 2.1618 - acc: 0.6543\n",
+      "512/512 [==============================] - 0s 57us/sample - loss: 1.5485 - acc: 0.5938\n",
       "Epoch 16/20\n",
-      "512/512 [==============================] - 0s 27us/sample - loss: 2.0703 - acc: 0.6504\n",
+      "512/512 [==============================] - 0s 56us/sample - loss: 1.4942 - acc: 0.5586\n",
       "Epoch 17/20\n",
-      "512/512 [==============================] - 0s 27us/sample - loss: 1.9604 - acc: 0.6465\n",
+      "512/512 [==============================] - 0s 42us/sample - loss: 1.3788 - acc: 0.5879\n",
       "Epoch 18/20\n",
-      "512/512 [==============================] - 0s 24us/sample - loss: 1.8771 - acc: 0.6445\n",
+      "512/512 [==============================] - 0s 42us/sample - loss: 1.3229 - acc: 0.5801\n",
       "Epoch 19/20\n",
-      "512/512 [==============================] - 0s 27us/sample - loss: 1.7951 - acc: 0.6562\n",
+      "512/512 [==============================] - 0s 61us/sample - loss: 1.2718 - acc: 0.6035\n",
       "Epoch 20/20\n",
-      "512/512 [==============================] - 0s 27us/sample - loss: 1.7303 - acc: 0.6602\n",
-      "256/256 [==============================] - 0s 523us/sample - loss: 2.4482 - acc: 0.5508\n",
+      "512/512 [==============================] - 0s 54us/sample - loss: 1.2376 - acc: 0.6152\n",
+      "256/256 [==============================] - 0s 632us/sample - loss: 1.3246 - acc: 0.6328\n",
       "Epoch 1/20\n",
-      "512/512 [==============================] - 0s 380us/sample - loss: 12.3113 - acc: 0.3965\n",
+      "512/512 [==============================] - 0s 874us/sample - loss: 29.4000 - acc: 0.3711\n",
       "Epoch 2/20\n",
-      "512/512 [==============================] - 0s 31us/sample - loss: 7.0328 - acc: 0.5137\n",
+      "512/512 [==============================] - 0s 41us/sample - loss: 21.8332 - acc: 0.4023\n",
       "Epoch 3/20\n",
-      "512/512 [==============================] - 0s 33us/sample - loss: 4.1481 - acc: 0.5742\n",
+      "512/512 [==============================] - 0s 45us/sample - loss: 16.9611 - acc: 0.4727\n",
       "Epoch 4/20\n",
-      "512/512 [==============================] - 0s 31us/sample - loss: 3.0621 - acc: 0.6270\n",
+      "512/512 [==============================] - 0s 66us/sample - loss: 14.5242 - acc: 0.5020\n",
       "Epoch 5/20\n",
-      "512/512 [==============================] - 0s 31us/sample - loss: 2.6765 - acc: 0.6426\n",
+      "512/512 [==============================] - 0s 52us/sample - loss: 12.5374 - acc: 0.5234\n",
       "Epoch 6/20\n",
-      "512/512 [==============================] - 0s 33us/sample - loss: 2.3874 - acc: 0.6406\n",
+      "512/512 [==============================] - 0s 43us/sample - loss: 10.8305 - acc: 0.5430\n",
       "Epoch 7/20\n",
-      "512/512 [==============================] - 0s 32us/sample - loss: 2.2515 - acc: 0.6387\n",
+      "512/512 [==============================] - 0s 42us/sample - loss: 9.1880 - acc: 0.5762\n",
       "Epoch 8/20\n",
-      "512/512 [==============================] - 0s 32us/sample - loss: 2.1568 - acc: 0.6387\n",
+      "512/512 [==============================] - 0s 42us/sample - loss: 7.7198 - acc: 0.5859\n",
       "Epoch 9/20\n",
-      "512/512 [==============================] - 0s 28us/sample - loss: 2.0420 - acc: 0.6484\n",
+      "512/512 [==============================] - 0s 41us/sample - loss: 6.4660 - acc: 0.5996\n",
       "Epoch 10/20\n",
-      "512/512 [==============================] - 0s 30us/sample - loss: 1.9561 - acc: 0.6484\n",
+      "512/512 [==============================] - 0s 42us/sample - loss: 5.4890 - acc: 0.5938\n",
       "Epoch 11/20\n",
-      "512/512 [==============================] - 0s 31us/sample - loss: 1.8576 - acc: 0.6504\n",
+      "512/512 [==============================] - 0s 40us/sample - loss: 4.7852 - acc: 0.6191\n",
       "Epoch 12/20\n",
-      "512/512 [==============================] - 0s 27us/sample - loss: 1.7699 - acc: 0.6543\n",
+      "512/512 [==============================] - 0s 40us/sample - loss: 4.2994 - acc: 0.6172\n",
       "Epoch 13/20\n",
-      "512/512 [==============================] - 0s 27us/sample - loss: 1.6815 - acc: 0.6484\n",
+      "512/512 [==============================] - 0s 42us/sample - loss: 3.9341 - acc: 0.6133\n",
       "Epoch 14/20\n",
-      "512/512 [==============================] - 0s 31us/sample - loss: 1.5927 - acc: 0.6543\n",
+      "512/512 [==============================] - 0s 40us/sample - loss: 3.6891 - acc: 0.6250\n",
       "Epoch 15/20\n",
-      "512/512 [==============================] - 0s 29us/sample - loss: 1.4939 - acc: 0.6523\n",
+      "512/512 [==============================] - 0s 40us/sample - loss: 3.4840 - acc: 0.6250\n",
       "Epoch 16/20\n",
-      "512/512 [==============================] - 0s 26us/sample - loss: 1.4036 - acc: 0.6484\n",
+      "512/512 [==============================] - 0s 39us/sample - loss: 3.2939 - acc: 0.6250\n",
       "Epoch 17/20\n",
-      "512/512 [==============================] - 0s 32us/sample - loss: 1.3243 - acc: 0.6523\n",
+      "512/512 [==============================] - 0s 41us/sample - loss: 3.1306 - acc: 0.6230\n",
       "Epoch 18/20\n",
-      "512/512 [==============================] - 0s 45us/sample - loss: 1.2335 - acc: 0.6387\n",
+      "512/512 [==============================] - 0s 41us/sample - loss: 2.9660 - acc: 0.6172\n",
       "Epoch 19/20\n",
-      "512/512 [==============================] - 0s 33us/sample - loss: 1.1484 - acc: 0.6406\n",
+      "512/512 [==============================] - 0s 47us/sample - loss: 2.8189 - acc: 0.6250\n",
       "Epoch 20/20\n",
-      "512/512 [==============================] - 0s 33us/sample - loss: 1.0805 - acc: 0.6367\n",
-      "256/256 [==============================] - 0s 547us/sample - loss: 0.9339 - acc: 0.6719\n",
+      "512/512 [==============================] - 0s 40us/sample - loss: 2.6720 - acc: 0.6250\n",
+      "256/256 [==============================] - 0s 683us/sample - loss: 2.6516 - acc: 0.5508\n",
       "Epoch 1/20\n",
-      "512/512 [==============================] - 0s 358us/sample - loss: 7.1647 - acc: 0.5996\n",
+      "512/512 [==============================] - 1s 986us/sample - loss: 7.1246 - acc: 0.6582\n",
       "Epoch 2/20\n",
-      "512/512 [==============================] - 0s 24us/sample - loss: 5.7492 - acc: 0.5371\n",
+      "512/512 [==============================] - 0s 46us/sample - loss: 5.8866 - acc: 0.6387\n",
       "Epoch 3/20\n",
-      "512/512 [==============================] - 0s 24us/sample - loss: 5.5667 - acc: 0.4863\n",
+      "512/512 [==============================] - 0s 34us/sample - loss: 4.8704 - acc: 0.6348\n",
       "Epoch 4/20\n",
-      "512/512 [==============================] - 0s 21us/sample - loss: 5.3361 - acc: 0.5039\n",
+      "512/512 [==============================] - 0s 34us/sample - loss: 3.9600 - acc: 0.6289\n",
       "Epoch 5/20\n",
-      "512/512 [==============================] - 0s 19us/sample - loss: 5.1068 - acc: 0.5156\n",
+      "512/512 [==============================] - 0s 32us/sample - loss: 3.1696 - acc: 0.6367\n",
       "Epoch 6/20\n",
-      "512/512 [==============================] - 0s 20us/sample - loss: 4.8999 - acc: 0.5234\n",
+      "512/512 [==============================] - 0s 32us/sample - loss: 2.6395 - acc: 0.6465\n",
       "Epoch 7/20\n",
-      "512/512 [==============================] - 0s 20us/sample - loss: 4.7160 - acc: 0.5176\n",
+      "512/512 [==============================] - 0s 33us/sample - loss: 2.3324 - acc: 0.6426\n",
       "Epoch 8/20\n",
-      "512/512 [==============================] - 0s 21us/sample - loss: 4.5534 - acc: 0.5156\n",
+      "512/512 [==============================] - 0s 35us/sample - loss: 2.2059 - acc: 0.6504\n",
       "Epoch 9/20\n",
-      "512/512 [==============================] - 0s 20us/sample - loss: 4.3618 - acc: 0.5176\n",
+      "512/512 [==============================] - 0s 36us/sample - loss: 2.0936 - acc: 0.6406\n",
       "Epoch 10/20\n",
-      "512/512 [==============================] - 0s 21us/sample - loss: 4.1905 - acc: 0.5195\n",
+      "512/512 [==============================] - 0s 32us/sample - loss: 1.9809 - acc: 0.6484\n",
       "Epoch 11/20\n",
-      "512/512 [==============================] - 0s 21us/sample - loss: 4.0183 - acc: 0.5273\n",
+      "512/512 [==============================] - 0s 31us/sample - loss: 1.8698 - acc: 0.6621\n",
       "Epoch 12/20\n",
-      "512/512 [==============================] - 0s 19us/sample - loss: 3.8485 - acc: 0.5215\n",
+      "512/512 [==============================] - 0s 32us/sample - loss: 1.7739 - acc: 0.6562\n",
       "Epoch 13/20\n",
-      "512/512 [==============================] - 0s 18us/sample - loss: 3.6705 - acc: 0.5234\n",
+      "512/512 [==============================] - 0s 31us/sample - loss: 1.6870 - acc: 0.6602\n",
       "Epoch 14/20\n",
-      "512/512 [==============================] - 0s 21us/sample - loss: 3.5121 - acc: 0.5273\n",
+      "512/512 [==============================] - 0s 34us/sample - loss: 1.6135 - acc: 0.6582\n",
       "Epoch 15/20\n",
-      "512/512 [==============================] - 0s 19us/sample - loss: 3.3385 - acc: 0.5352\n",
+      "512/512 [==============================] - 0s 31us/sample - loss: 1.5495 - acc: 0.6602\n",
       "Epoch 16/20\n",
-      "512/512 [==============================] - 0s 19us/sample - loss: 3.2022 - acc: 0.5352\n",
+      "512/512 [==============================] - 0s 31us/sample - loss: 1.4843 - acc: 0.6562\n",
       "Epoch 17/20\n",
-      "512/512 [==============================] - 0s 18us/sample - loss: 3.0172 - acc: 0.5391\n",
+      "512/512 [==============================] - 0s 29us/sample - loss: 1.3970 - acc: 0.6621\n",
       "Epoch 18/20\n",
-      "512/512 [==============================] - 0s 18us/sample - loss: 2.8784 - acc: 0.5469\n",
+      "512/512 [==============================] - 0s 30us/sample - loss: 1.3580 - acc: 0.6680\n",
       "Epoch 19/20\n",
-      "512/512 [==============================] - 0s 17us/sample - loss: 2.7449 - acc: 0.5391\n",
+      "512/512 [==============================] - ETA: 0s - loss: 1.6018 - acc: 0.666 - 0s 32us/sample - loss: 1.2788 - acc: 0.6641\n",
       "Epoch 20/20\n",
-      "512/512 [==============================] - 0s 20us/sample - loss: 2.6390 - acc: 0.5605\n",
-      "256/256 [==============================] - 0s 531us/sample - loss: 2.5172 - acc: 0.5625\n",
+      "512/512 [==============================] - 0s 30us/sample - loss: 1.2228 - acc: 0.6660\n",
+      "256/256 [==============================] - 0s 698us/sample - loss: 1.6933 - acc: 0.6484\n",
       "Epoch 1/20\n",
-      "512/512 [==============================] - 0s 370us/sample - loss: 17.5559 - acc: 0.6465\n",
+      "512/512 [==============================] - 0s 881us/sample - loss: 39.5788 - acc: 0.6465\n",
       "Epoch 2/20\n",
-      "512/512 [==============================] - 0s 20us/sample - loss: 14.3815 - acc: 0.6445\n",
+      "512/512 [==============================] - 0s 46us/sample - loss: 35.3988 - acc: 0.6465\n",
       "Epoch 3/20\n",
-      "512/512 [==============================] - 0s 19us/sample - loss: 11.0402 - acc: 0.6426\n",
+      "512/512 [==============================] - 0s 40us/sample - loss: 31.1804 - acc: 0.6465\n",
       "Epoch 4/20\n",
-      "512/512 [==============================] - 0s 20us/sample - loss: 7.8189 - acc: 0.6465\n",
+      "512/512 [==============================] - 0s 36us/sample - loss: 27.2698 - acc: 0.6465\n",
       "Epoch 5/20\n",
-      "512/512 [==============================] - 0s 21us/sample - loss: 5.4423 - acc: 0.5645\n",
+      "512/512 [==============================] - 0s 39us/sample - loss: 23.5217 - acc: 0.6465\n",
       "Epoch 6/20\n",
-      "512/512 [==============================] - 0s 20us/sample - loss: 4.6802 - acc: 0.4746\n",
+      "512/512 [==============================] - 0s 42us/sample - loss: 19.8188 - acc: 0.6465\n",
       "Epoch 7/20\n",
-      "512/512 [==============================] - 0s 19us/sample - loss: 4.0641 - acc: 0.4609\n",
+      "512/512 [==============================] - 0s 39us/sample - loss: 16.1592 - acc: 0.6484\n",
       "Epoch 8/20\n",
-      "512/512 [==============================] - 0s 18us/sample - loss: 3.3435 - acc: 0.4766\n",
+      "512/512 [==============================] - 0s 46us/sample - loss: 12.6174 - acc: 0.6348\n",
       "Epoch 9/20\n",
-      "512/512 [==============================] - 0s 19us/sample - loss: 2.9226 - acc: 0.5137\n",
+      "512/512 [==============================] - 0s 34us/sample - loss: 9.9405 - acc: 0.5742\n",
       "Epoch 10/20\n",
-      "512/512 [==============================] - 0s 19us/sample - loss: 2.5432 - acc: 0.5059\n",
+      "512/512 [==============================] - 0s 29us/sample - loss: 8.0699 - acc: 0.5312\n",
       "Epoch 11/20\n",
-      "512/512 [==============================] - 0s 19us/sample - loss: 2.3303 - acc: 0.5195\n",
+      "512/512 [==============================] - 0s 36us/sample - loss: 6.9292 - acc: 0.5039\n",
       "Epoch 12/20\n",
-      "512/512 [==============================] - 0s 20us/sample - loss: 2.1539 - acc: 0.5430\n",
+      "512/512 [==============================] - 0s 30us/sample - loss: 6.3155 - acc: 0.4688\n",
       "Epoch 13/20\n",
-      "512/512 [==============================] - 0s 18us/sample - loss: 2.0320 - acc: 0.5566\n",
+      "512/512 [==============================] - 0s 30us/sample - loss: 5.8522 - acc: 0.4551\n",
       "Epoch 14/20\n",
-      "512/512 [==============================] - 0s 18us/sample - loss: 1.9036 - acc: 0.5645\n",
+      "512/512 [==============================] - 0s 35us/sample - loss: 5.3369 - acc: 0.4590\n",
       "Epoch 15/20\n",
-      "512/512 [==============================] - 0s 17us/sample - loss: 1.8219 - acc: 0.5527\n",
+      "512/512 [==============================] - 0s 29us/sample - loss: 4.7382 - acc: 0.4688\n",
       "Epoch 16/20\n",
-      "512/512 [==============================] - 0s 17us/sample - loss: 1.7142 - acc: 0.5625\n",
+      "512/512 [==============================] - 0s 30us/sample - loss: 4.2481 - acc: 0.5039\n",
       "Epoch 17/20\n",
-      "512/512 [==============================] - 0s 17us/sample - loss: 1.6312 - acc: 0.5664\n",
+      "512/512 [==============================] - 0s 26us/sample - loss: 3.9581 - acc: 0.5156\n",
       "Epoch 18/20\n",
-      "512/512 [==============================] - 0s 17us/sample - loss: 1.5597 - acc: 0.5566\n",
+      "512/512 [==============================] - 0s 37us/sample - loss: 3.6578 - acc: 0.5078\n",
       "Epoch 19/20\n",
-      "512/512 [==============================] - 0s 17us/sample - loss: 1.4839 - acc: 0.5801\n",
+      "512/512 [==============================] - 0s 41us/sample - loss: 3.3900 - acc: 0.5137\n",
       "Epoch 20/20\n",
-      "512/512 [==============================] - 0s 17us/sample - loss: 1.4224 - acc: 0.5938\n",
-      "256/256 [==============================] - 0s 558us/sample - loss: 1.4621 - acc: 0.5430\n",
+      "512/512 [==============================] - 0s 33us/sample - loss: 3.1421 - acc: 0.5215\n",
+      "256/256 [==============================] - 0s 749us/sample - loss: 3.9248 - acc: 0.4336\n",
       "Epoch 1/20\n",
-      "512/512 [==============================] - 0s 390us/sample - loss: 4.0413 - acc: 0.4648\n",
+      "512/512 [==============================] - 0s 926us/sample - loss: 26.3143 - acc: 0.3613\n",
       "Epoch 2/20\n",
-      "512/512 [==============================] - 0s 19us/sample - loss: 3.5925 - acc: 0.4883\n",
+      "512/512 [==============================] - 0s 38us/sample - loss: 20.2482 - acc: 0.3594\n",
       "Epoch 3/20\n",
-      "512/512 [==============================] - 0s 20us/sample - loss: 3.2800 - acc: 0.4941\n",
+      "512/512 [==============================] - 0s 35us/sample - loss: 13.9833 - acc: 0.3652\n",
       "Epoch 4/20\n",
-      "512/512 [==============================] - 0s 20us/sample - loss: 2.9631 - acc: 0.5020\n",
+      "512/512 [==============================] - 0s 38us/sample - loss: 8.3012 - acc: 0.3965\n",
       "Epoch 5/20\n",
-      "512/512 [==============================] - 0s 19us/sample - loss: 2.6506 - acc: 0.5137\n",
+      "512/512 [==============================] - 0s 38us/sample - loss: 6.1802 - acc: 0.4707\n",
       "Epoch 6/20\n",
-      "512/512 [==============================] - 0s 26us/sample - loss: 2.3760 - acc: 0.5293\n",
+      "512/512 [==============================] - 0s 38us/sample - loss: 5.4631 - acc: 0.5176\n",
       "Epoch 7/20\n",
-      "512/512 [==============================] - 0s 22us/sample - loss: 2.1348 - acc: 0.5469\n",
+      "512/512 [==============================] - 0s 35us/sample - loss: 4.7149 - acc: 0.5234\n",
       "Epoch 8/20\n",
-      "512/512 [==============================] - 0s 22us/sample - loss: 1.8958 - acc: 0.5586\n",
+      "512/512 [==============================] - 0s 44us/sample - loss: 3.9111 - acc: 0.5430\n",
       "Epoch 9/20\n",
-      "512/512 [==============================] - 0s 20us/sample - loss: 1.6638 - acc: 0.5684\n",
+      "512/512 [==============================] - 0s 38us/sample - loss: 3.3458 - acc: 0.5391\n",
       "Epoch 10/20\n",
-      "512/512 [==============================] - 0s 20us/sample - loss: 1.4815 - acc: 0.6133\n",
+      "512/512 [==============================] - 0s 39us/sample - loss: 3.0672 - acc: 0.5469\n",
       "Epoch 11/20\n",
-      "512/512 [==============================] - 0s 20us/sample - loss: 1.3476 - acc: 0.6289\n",
+      "512/512 [==============================] - 0s 37us/sample - loss: 2.8408 - acc: 0.5801\n",
       "Epoch 12/20\n",
-      "512/512 [==============================] - 0s 19us/sample - loss: 1.2700 - acc: 0.6367\n",
+      "512/512 [==============================] - 0s 38us/sample - loss: 2.7072 - acc: 0.5840\n",
       "Epoch 13/20\n",
-      "512/512 [==============================] - 0s 18us/sample - loss: 1.2265 - acc: 0.6641\n",
+      "512/512 [==============================] - 0s 47us/sample - loss: 2.5984 - acc: 0.5840\n",
       "Epoch 14/20\n",
-      "512/512 [==============================] - 0s 21us/sample - loss: 1.1924 - acc: 0.6504\n",
+      "512/512 [==============================] - 0s 40us/sample - loss: 2.4996 - acc: 0.5859\n",
       "Epoch 15/20\n",
-      "512/512 [==============================] - 0s 21us/sample - loss: 1.1571 - acc: 0.6602\n",
+      "512/512 [==============================] - 0s 38us/sample - loss: 2.4082 - acc: 0.5859\n",
       "Epoch 16/20\n",
-      "512/512 [==============================] - 0s 21us/sample - loss: 1.1302 - acc: 0.6543\n",
+      "512/512 [==============================] - 0s 34us/sample - loss: 2.3304 - acc: 0.5801\n",
       "Epoch 17/20\n",
-      "512/512 [==============================] - 0s 21us/sample - loss: 1.1063 - acc: 0.6660\n",
+      "512/512 [==============================] - 0s 35us/sample - loss: 2.2404 - acc: 0.5801\n",
       "Epoch 18/20\n",
-      "512/512 [==============================] - 0s 19us/sample - loss: 1.0881 - acc: 0.6699\n",
+      "512/512 [==============================] - 0s 41us/sample - loss: 2.1621 - acc: 0.5781\n",
       "Epoch 19/20\n",
-      "512/512 [==============================] - 0s 18us/sample - loss: 1.0675 - acc: 0.6738\n",
+      "512/512 [==============================] - 0s 39us/sample - loss: 2.0863 - acc: 0.5723\n",
       "Epoch 20/20\n",
-      "512/512 [==============================] - 0s 18us/sample - loss: 1.0410 - acc: 0.6660\n",
-      "256/256 [==============================] - 0s 584us/sample - loss: 0.8851 - acc: 0.6836\n",
+      "512/512 [==============================] - 0s 34us/sample - loss: 2.0106 - acc: 0.5762\n",
+      "256/256 [==============================] - 0s 806us/sample - loss: 2.0127 - acc: 0.6016\n",
       "Epoch 1/20\n",
-      "512/512 [==============================] - 0s 379us/sample - loss: 62.1779 - acc: 0.3320\n",
+      "512/512 [==============================] - 0s 958us/sample - loss: 23.0866 - acc: 0.6699\n",
       "Epoch 2/20\n",
-      "512/512 [==============================] - 0s 16us/sample - loss: 56.5412 - acc: 0.3320\n",
+      "512/512 [==============================] - 0s 38us/sample - loss: 20.4298 - acc: 0.6699\n",
       "Epoch 3/20\n",
-      "512/512 [==============================] - 0s 15us/sample - loss: 50.9339 - acc: 0.3320\n",
+      "512/512 [==============================] - 0s 31us/sample - loss: 17.9348 - acc: 0.6699\n",
       "Epoch 4/20\n",
-      "512/512 [==============================] - 0s 16us/sample - loss: 45.5036 - acc: 0.3320\n",
+      "512/512 [==============================] - 0s 34us/sample - loss: 15.5087 - acc: 0.6660\n",
       "Epoch 5/20\n",
-      "512/512 [==============================] - 0s 16us/sample - loss: 40.1666 - acc: 0.3301\n",
+      "512/512 [==============================] - 0s 33us/sample - loss: 13.2102 - acc: 0.6523\n",
       "Epoch 6/20\n",
-      "512/512 [==============================] - 0s 16us/sample - loss: 34.7788 - acc: 0.3301\n",
+      "512/512 [==============================] - 0s 32us/sample - loss: 11.1374 - acc: 0.6016\n",
       "Epoch 7/20\n",
-      "512/512 [==============================] - 0s 16us/sample - loss: 29.4169 - acc: 0.3301\n",
+      "512/512 [==============================] - 0s 33us/sample - loss: 9.5145 - acc: 0.5625\n",
       "Epoch 8/20\n",
-      "512/512 [==============================] - 0s 16us/sample - loss: 24.1976 - acc: 0.3301\n",
+      "512/512 [==============================] - 0s 34us/sample - loss: 8.0602 - acc: 0.5312\n",
       "Epoch 9/20\n",
-      "512/512 [==============================] - 0s 15us/sample - loss: 18.8560 - acc: 0.3262\n",
+      "512/512 [==============================] - 0s 33us/sample - loss: 7.0816 - acc: 0.4883\n",
       "Epoch 10/20\n",
-      "512/512 [==============================] - 0s 21us/sample - loss: 13.9800 - acc: 0.3359\n",
+      "512/512 [==============================] - 0s 32us/sample - loss: 6.5094 - acc: 0.4629\n",
       "Epoch 11/20\n",
-      "512/512 [==============================] - 0s 19us/sample - loss: 9.9310 - acc: 0.3945\n",
+      "512/512 [==============================] - 0s 31us/sample - loss: 6.1532 - acc: 0.4238\n",
       "Epoch 12/20\n",
-      "512/512 [==============================] - 0s 19us/sample - loss: 7.3205 - acc: 0.4746\n",
+      "512/512 [==============================] - 0s 30us/sample - loss: 5.7670 - acc: 0.4238\n",
       "Epoch 13/20\n",
-      "512/512 [==============================] - 0s 16us/sample - loss: 5.7821 - acc: 0.5273\n",
+      "512/512 [==============================] - 0s 29us/sample - loss: 5.4009 - acc: 0.4277\n",
       "Epoch 14/20\n",
-      "512/512 [==============================] - 0s 17us/sample - loss: 4.8709 - acc: 0.5645\n",
+      "512/512 [==============================] - 0s 34us/sample - loss: 5.0613 - acc: 0.4395\n",
       "Epoch 15/20\n",
-      "512/512 [==============================] - 0s 16us/sample - loss: 4.4978 - acc: 0.6035\n",
+      "512/512 [==============================] - 0s 33us/sample - loss: 4.7539 - acc: 0.4473\n",
       "Epoch 16/20\n",
-      "512/512 [==============================] - 0s 15us/sample - loss: 4.2723 - acc: 0.6172\n",
+      "512/512 [==============================] - 0s 35us/sample - loss: 4.4714 - acc: 0.4414\n",
       "Epoch 17/20\n",
-      "512/512 [==============================] - 0s 17us/sample - loss: 4.0545 - acc: 0.6152\n",
+      "512/512 [==============================] - 0s 34us/sample - loss: 4.2137 - acc: 0.4473\n",
       "Epoch 18/20\n",
-      "512/512 [==============================] - 0s 15us/sample - loss: 3.8891 - acc: 0.6133\n",
+      "512/512 [==============================] - 0s 33us/sample - loss: 3.9846 - acc: 0.4473\n",
       "Epoch 19/20\n",
-      "512/512 [==============================] - 0s 16us/sample - loss: 3.7250 - acc: 0.6172\n",
+      "512/512 [==============================] - 0s 30us/sample - loss: 3.7502 - acc: 0.4512\n",
       "Epoch 20/20\n",
-      "512/512 [==============================] - 0s 15us/sample - loss: 3.6099 - acc: 0.6133\n",
-      "256/256 [==============================] - 0s 602us/sample - loss: 3.7517 - acc: 0.5859\n",
+      "512/512 [==============================] - 0s 30us/sample - loss: 3.5385 - acc: 0.4551\n",
+      "256/256 [==============================] - 0s 813us/sample - loss: 3.3044 - acc: 0.5000\n",
       "Epoch 1/20\n",
-      "512/512 [==============================] - 0s 395us/sample - loss: 5.6183 - acc: 0.6211\n",
+      "512/512 [==============================] - 0s 871us/sample - loss: 17.3195 - acc: 0.3594\n",
       "Epoch 2/20\n",
-      "512/512 [==============================] - 0s 18us/sample - loss: 4.6766 - acc: 0.5918\n",
+      "512/512 [==============================] - 0s 27us/sample - loss: 14.8868 - acc: 0.3652\n",
       "Epoch 3/20\n",
-      "512/512 [==============================] - 0s 16us/sample - loss: 3.9083 - acc: 0.5840\n",
+      "512/512 [==============================] - 0s 28us/sample - loss: 12.6071 - acc: 0.3750\n",
       "Epoch 4/20\n",
-      "512/512 [==============================] - 0s 16us/sample - loss: 3.2536 - acc: 0.5684\n",
+      "512/512 [==============================] - 0s 26us/sample - loss: 10.4688 - acc: 0.3965\n",
       "Epoch 5/20\n",
-      "512/512 [==============================] - 0s 15us/sample - loss: 2.7091 - acc: 0.5566\n",
+      "512/512 [==============================] - 0s 27us/sample - loss: 8.3504 - acc: 0.4355\n",
       "Epoch 6/20\n",
-      "512/512 [==============================] - 0s 16us/sample - loss: 2.2743 - acc: 0.5352\n",
+      "512/512 [==============================] - 0s 28us/sample - loss: 6.3435 - acc: 0.4668\n",
       "Epoch 7/20\n",
-      "512/512 [==============================] - 0s 16us/sample - loss: 1.9757 - acc: 0.5254\n",
+      "512/512 [==============================] - 0s 31us/sample - loss: 4.8125 - acc: 0.5000\n",
       "Epoch 8/20\n",
-      "512/512 [==============================] - 0s 15us/sample - loss: 1.7653 - acc: 0.5352\n",
+      "512/512 [==============================] - 0s 31us/sample - loss: 3.7480 - acc: 0.5352\n",
       "Epoch 9/20\n",
-      "512/512 [==============================] - 0s 16us/sample - loss: 1.5965 - acc: 0.5527\n",
+      "512/512 [==============================] - 0s 28us/sample - loss: 3.2661 - acc: 0.5742\n",
       "Epoch 10/20\n",
-      "512/512 [==============================] - 0s 16us/sample - loss: 1.4451 - acc: 0.5547\n",
+      "512/512 [==============================] - 0s 34us/sample - loss: 3.0035 - acc: 0.5918\n",
       "Epoch 11/20\n",
-      "512/512 [==============================] - 0s 16us/sample - loss: 1.3361 - acc: 0.5684\n",
+      "512/512 [==============================] - 0s 28us/sample - loss: 2.8645 - acc: 0.6016\n",
       "Epoch 12/20\n",
-      "512/512 [==============================] - 0s 15us/sample - loss: 1.2514 - acc: 0.5840\n",
+      "512/512 [==============================] - 0s 30us/sample - loss: 2.7705 - acc: 0.6309\n",
       "Epoch 13/20\n",
-      "512/512 [==============================] - 0s 16us/sample - loss: 1.1764 - acc: 0.5840\n",
+      "512/512 [==============================] - 0s 27us/sample - loss: 2.6734 - acc: 0.6230\n",
       "Epoch 14/20\n",
-      "512/512 [==============================] - 0s 16us/sample - loss: 1.1201 - acc: 0.5742\n",
+      "512/512 [==============================] - 0s 30us/sample - loss: 2.5821 - acc: 0.6250\n",
       "Epoch 15/20\n",
-      "512/512 [==============================] - 0s 15us/sample - loss: 1.0645 - acc: 0.5801\n",
+      "512/512 [==============================] - 0s 31us/sample - loss: 2.5045 - acc: 0.6230\n",
       "Epoch 16/20\n",
-      "512/512 [==============================] - 0s 15us/sample - loss: 1.0178 - acc: 0.5938\n",
+      "512/512 [==============================] - 0s 28us/sample - loss: 2.4225 - acc: 0.6152\n",
       "Epoch 17/20\n",
-      "512/512 [==============================] - 0s 15us/sample - loss: 0.9777 - acc: 0.5938\n",
+      "512/512 [==============================] - 0s 27us/sample - loss: 2.3534 - acc: 0.6191\n",
       "Epoch 18/20\n",
-      "512/512 [==============================] - 0s 15us/sample - loss: 0.9445 - acc: 0.5938\n",
+      "512/512 [==============================] - 0s 25us/sample - loss: 2.2845 - acc: 0.6230\n",
       "Epoch 19/20\n",
-      "512/512 [==============================] - 0s 14us/sample - loss: 0.9170 - acc: 0.6016\n",
+      "512/512 [==============================] - 0s 36us/sample - loss: 2.2207 - acc: 0.6270\n",
       "Epoch 20/20\n",
-      "512/512 [==============================] - 0s 15us/sample - loss: 0.8863 - acc: 0.5996\n",
-      "256/256 [==============================] - 0s 674us/sample - loss: 0.9265 - acc: 0.5781\n",
+      "512/512 [==============================] - 0s 33us/sample - loss: 2.1556 - acc: 0.6270\n",
+      "256/256 [==============================] - 0s 734us/sample - loss: 2.5169 - acc: 0.5938\n",
       "Epoch 1/20\n",
-      "512/512 [==============================] - 0s 407us/sample - loss: 12.6917 - acc: 0.6152\n",
+      "512/512 [==============================] - 0s 931us/sample - loss: 7.8273 - acc: 0.5000\n",
       "Epoch 2/20\n",
-      "512/512 [==============================] - 0s 17us/sample - loss: 10.2044 - acc: 0.5703\n",
+      "512/512 [==============================] - 0s 28us/sample - loss: 6.4171 - acc: 0.5293\n",
       "Epoch 3/20\n",
-      "512/512 [==============================] - 0s 17us/sample - loss: 8.4844 - acc: 0.4941\n",
+      "512/512 [==============================] - 0s 28us/sample - loss: 5.5204 - acc: 0.4922\n",
       "Epoch 4/20\n",
-      "512/512 [==============================] - 0s 19us/sample - loss: 7.8500 - acc: 0.4512\n",
+      "512/512 [==============================] - 0s 27us/sample - loss: 5.0339 - acc: 0.4844\n",
       "Epoch 5/20\n",
-      "512/512 [==============================] - 0s 19us/sample - loss: 7.5967 - acc: 0.4180\n",
+      "512/512 [==============================] - 0s 27us/sample - loss: 4.6009 - acc: 0.4844\n",
       "Epoch 6/20\n",
-      "512/512 [==============================] - 0s 18us/sample - loss: 7.2985 - acc: 0.4141\n",
+      "512/512 [==============================] - 0s 25us/sample - loss: 4.2995 - acc: 0.4824\n",
       "Epoch 7/20\n",
-      "512/512 [==============================] - 0s 18us/sample - loss: 6.9659 - acc: 0.4199\n",
+      "512/512 [==============================] - 0s 28us/sample - loss: 3.9261 - acc: 0.5039\n",
       "Epoch 8/20\n",
-      "512/512 [==============================] - 0s 19us/sample - loss: 6.6614 - acc: 0.4082\n",
+      "512/512 [==============================] - 0s 29us/sample - loss: 3.5742 - acc: 0.5254\n",
       "Epoch 9/20\n",
-      "512/512 [==============================] - 0s 23us/sample - loss: 6.4061 - acc: 0.4062\n",
+      "512/512 [==============================] - 0s 33us/sample - loss: 3.2603 - acc: 0.5527\n",
       "Epoch 10/20\n",
-      "512/512 [==============================] - 0s 23us/sample - loss: 6.1629 - acc: 0.4043\n",
+      "512/512 [==============================] - 0s 23us/sample - loss: 2.9960 - acc: 0.5762\n",
       "Epoch 11/20\n",
-      "512/512 [==============================] - 0s 21us/sample - loss: 5.9091 - acc: 0.3906\n",
+      "512/512 [==============================] - 0s 23us/sample - loss: 2.7904 - acc: 0.5898\n",
       "Epoch 12/20\n",
-      "512/512 [==============================] - 0s 20us/sample - loss: 5.6538 - acc: 0.3828\n",
+      "512/512 [==============================] - 0s 26us/sample - loss: 2.5863 - acc: 0.5977\n",
       "Epoch 13/20\n",
-      "512/512 [==============================] - 0s 22us/sample - loss: 5.4092 - acc: 0.3809\n",
+      "512/512 [==============================] - 0s 37us/sample - loss: 2.3915 - acc: 0.5996\n",
       "Epoch 14/20\n",
-      "512/512 [==============================] - 0s 23us/sample - loss: 5.1579 - acc: 0.3809\n",
+      "512/512 [==============================] - 0s 28us/sample - loss: 2.2487 - acc: 0.6113\n",
       "Epoch 15/20\n",
-      "512/512 [==============================] - 0s 23us/sample - loss: 4.9105 - acc: 0.3945\n",
+      "512/512 [==============================] - 0s 29us/sample - loss: 2.1046 - acc: 0.6152\n",
       "Epoch 16/20\n",
-      "512/512 [==============================] - 0s 20us/sample - loss: 4.6876 - acc: 0.3867\n",
+      "512/512 [==============================] - 0s 24us/sample - loss: 1.9907 - acc: 0.6191\n",
       "Epoch 17/20\n",
-      "512/512 [==============================] - 0s 19us/sample - loss: 4.4418 - acc: 0.3984\n",
+      "512/512 [==============================] - 0s 27us/sample - loss: 1.8784 - acc: 0.6230\n",
       "Epoch 18/20\n",
-      "512/512 [==============================] - 0s 20us/sample - loss: 4.2109 - acc: 0.4082\n",
+      "512/512 [==============================] - 0s 27us/sample - loss: 1.7727 - acc: 0.6406\n",
       "Epoch 19/20\n",
-      "512/512 [==============================] - 0s 21us/sample - loss: 3.9823 - acc: 0.4023\n",
+      "512/512 [==============================] - 0s 27us/sample - loss: 1.6954 - acc: 0.6387\n",
       "Epoch 20/20\n",
-      "512/512 [==============================] - 0s 19us/sample - loss: 3.7777 - acc: 0.4082\n",
-      "256/256 [==============================] - 0s 605us/sample - loss: 3.2759 - acc: 0.4492\n",
+      "512/512 [==============================] - 0s 27us/sample - loss: 1.6179 - acc: 0.6387\n",
+      "256/256 [==============================] - 0s 812us/sample - loss: 1.5142 - acc: 0.6172\n",
       "Epoch 1/20\n",
-      "512/512 [==============================] - 0s 393us/sample - loss: 6.2852 - acc: 0.5938\n",
+      "512/512 [==============================] - 0s 903us/sample - loss: 12.4902 - acc: 0.3516\n",
       "Epoch 2/20\n",
-      "512/512 [==============================] - 0s 15us/sample - loss: 5.6469 - acc: 0.5938\n",
+      "512/512 [==============================] - 0s 23us/sample - loss: 10.3466 - acc: 0.3711\n",
       "Epoch 3/20\n",
-      "512/512 [==============================] - 0s 15us/sample - loss: 5.0258 - acc: 0.5977\n",
+      "512/512 [==============================] - 0s 24us/sample - loss: 8.7121 - acc: 0.4199\n",
       "Epoch 4/20\n",
-      "512/512 [==============================] - 0s 15us/sample - loss: 4.4447 - acc: 0.5918\n",
+      "512/512 [==============================] - 0s 23us/sample - loss: 7.4138 - acc: 0.4727\n",
       "Epoch 5/20\n",
-      "512/512 [==============================] - 0s 15us/sample - loss: 3.8873 - acc: 0.5801\n",
+      "512/512 [==============================] - 0s 25us/sample - loss: 6.1396 - acc: 0.4961\n",
       "Epoch 6/20\n",
-      "512/512 [==============================] - 0s 15us/sample - loss: 3.3620 - acc: 0.5801\n",
+      "512/512 [==============================] - 0s 29us/sample - loss: 5.0133 - acc: 0.5215\n",
       "Epoch 7/20\n",
-      "512/512 [==============================] - 0s 16us/sample - loss: 2.8443 - acc: 0.5879\n",
+      "512/512 [==============================] - 0s 30us/sample - loss: 3.9814 - acc: 0.5488\n",
       "Epoch 8/20\n",
-      "512/512 [==============================] - 0s 15us/sample - loss: 2.3259 - acc: 0.5840\n",
+      "512/512 [==============================] - 0s 18us/sample - loss: 3.0961 - acc: 0.5547\n",
       "Epoch 9/20\n",
-      "512/512 [==============================] - 0s 15us/sample - loss: 1.8459 - acc: 0.5723\n",
+      "512/512 [==============================] - 0s 28us/sample - loss: 2.4227 - acc: 0.5488\n",
       "Epoch 10/20\n",
-      "512/512 [==============================] - 0s 15us/sample - loss: 1.4317 - acc: 0.5645\n",
+      "512/512 [==============================] - 0s 25us/sample - loss: 2.1034 - acc: 0.5215\n",
       "Epoch 11/20\n",
-      "512/512 [==============================] - 0s 15us/sample - loss: 1.1985 - acc: 0.5508\n",
+      "512/512 [==============================] - 0s 21us/sample - loss: 2.0892 - acc: 0.4824\n",
       "Epoch 12/20\n",
-      "512/512 [==============================] - 0s 16us/sample - loss: 1.1470 - acc: 0.5586\n",
+      "512/512 [==============================] - 0s 22us/sample - loss: 2.0680 - acc: 0.5020\n",
       "Epoch 13/20\n",
-      "512/512 [==============================] - 0s 15us/sample - loss: 1.1277 - acc: 0.5664\n",
+      "512/512 [==============================] - 0s 25us/sample - loss: 1.9774 - acc: 0.5293\n",
       "Epoch 14/20\n",
-      "512/512 [==============================] - 0s 15us/sample - loss: 1.0886 - acc: 0.5566\n",
+      "512/512 [==============================] - 0s 26us/sample - loss: 1.8915 - acc: 0.5430\n",
       "Epoch 15/20\n",
-      "512/512 [==============================] - 0s 15us/sample - loss: 1.0419 - acc: 0.5664\n",
+      "512/512 [==============================] - 0s 23us/sample - loss: 1.8060 - acc: 0.5469\n",
       "Epoch 16/20\n",
-      "512/512 [==============================] - 0s 17us/sample - loss: 1.0212 - acc: 0.5898\n",
+      "512/512 [==============================] - 0s 25us/sample - loss: 1.7380 - acc: 0.5547\n",
       "Epoch 17/20\n",
-      "512/512 [==============================] - 0s 16us/sample - loss: 0.9974 - acc: 0.6016\n",
+      "512/512 [==============================] - 0s 24us/sample - loss: 1.6674 - acc: 0.5664\n",
       "Epoch 18/20\n",
-      "512/512 [==============================] - 0s 15us/sample - loss: 0.9661 - acc: 0.5918\n",
+      "512/512 [==============================] - 0s 20us/sample - loss: 1.6082 - acc: 0.5684\n",
       "Epoch 19/20\n",
-      "512/512 [==============================] - 0s 15us/sample - loss: 0.9653 - acc: 0.5664\n",
+      "512/512 [==============================] - 0s 23us/sample - loss: 1.5554 - acc: 0.5820\n",
       "Epoch 20/20\n",
-      "512/512 [==============================] - 0s 14us/sample - loss: 0.9326 - acc: 0.6016\n",
-      "256/256 [==============================] - 0s 631us/sample - loss: 1.1096 - acc: 0.5820\n",
+      "512/512 [==============================] - 0s 23us/sample - loss: 1.4798 - acc: 0.5938\n",
+      "256/256 [==============================] - 0s 746us/sample - loss: 1.6745 - acc: 0.5703\n",
       "Epoch 1/20\n",
-      "512/512 [==============================] - 0s 420us/sample - loss: 89.1233 - acc: 0.6465\n",
+      "512/512 [==============================] - 0s 815us/sample - loss: 19.9897 - acc: 0.3574\n",
       "Epoch 2/20\n",
-      "512/512 [==============================] - 0s 17us/sample - loss: 84.2759 - acc: 0.6465\n",
+      "512/512 [==============================] - 0s 23us/sample - loss: 16.4881 - acc: 0.3789\n",
       "Epoch 3/20\n",
-      "512/512 [==============================] - 0s 15us/sample - loss: 79.6149 - acc: 0.6465\n",
+      "512/512 [==============================] - 0s 26us/sample - loss: 13.6119 - acc: 0.4121\n",
       "Epoch 4/20\n",
-      "512/512 [==============================] - 0s 16us/sample - loss: 74.9714 - acc: 0.6465\n",
+      "512/512 [==============================] - 0s 24us/sample - loss: 11.6211 - acc: 0.4316\n",
       "Epoch 5/20\n",
-      "512/512 [==============================] - 0s 16us/sample - loss: 70.6292 - acc: 0.6465\n",
+      "512/512 [==============================] - 0s 26us/sample - loss: 10.2232 - acc: 0.4473\n",
       "Epoch 6/20\n",
-      "512/512 [==============================] - 0s 16us/sample - loss: 66.3456 - acc: 0.6465\n",
+      "512/512 [==============================] - 0s 25us/sample - loss: 9.0327 - acc: 0.4629\n",
       "Epoch 7/20\n",
-      "512/512 [==============================] - 0s 16us/sample - loss: 62.2570 - acc: 0.6465\n",
+      "512/512 [==============================] - 0s 23us/sample - loss: 7.8808 - acc: 0.4863\n",
       "Epoch 8/20\n",
-      "512/512 [==============================] - 0s 17us/sample - loss: 58.2121 - acc: 0.6465\n",
+      "512/512 [==============================] - 0s 23us/sample - loss: 6.8924 - acc: 0.5117\n",
       "Epoch 9/20\n",
-      "512/512 [==============================] - 0s 16us/sample - loss: 54.3886 - acc: 0.6465\n",
+      "512/512 [==============================] - 0s 24us/sample - loss: 6.0389 - acc: 0.5195\n",
       "Epoch 10/20\n",
-      "512/512 [==============================] - 0s 16us/sample - loss: 50.4206 - acc: 0.6465\n",
+      "512/512 [==============================] - 0s 23us/sample - loss: 5.3314 - acc: 0.5312\n",
       "Epoch 11/20\n",
-      "512/512 [==============================] - 0s 17us/sample - loss: 46.8197 - acc: 0.6465\n",
+      "512/512 [==============================] - 0s 23us/sample - loss: 4.7742 - acc: 0.5312\n",
       "Epoch 12/20\n",
-      "512/512 [==============================] - 0s 17us/sample - loss: 43.0544 - acc: 0.6465\n",
+      "512/512 [==============================] - 0s 26us/sample - loss: 4.2902 - acc: 0.5332\n",
       "Epoch 13/20\n",
-      "512/512 [==============================] - 0s 18us/sample - loss: 39.4615 - acc: 0.6465\n",
+      "512/512 [==============================] - 0s 27us/sample - loss: 3.9545 - acc: 0.5371\n",
       "Epoch 14/20\n",
-      "512/512 [==============================] - 0s 18us/sample - loss: 35.8201 - acc: 0.6465\n",
+      "512/512 [==============================] - 0s 23us/sample - loss: 3.7060 - acc: 0.5605\n",
       "Epoch 15/20\n",
-      "512/512 [==============================] - 0s 17us/sample - loss: 32.2193 - acc: 0.6465\n",
+      "512/512 [==============================] - 0s 21us/sample - loss: 3.5147 - acc: 0.5781\n",
       "Epoch 16/20\n",
-      "512/512 [==============================] - 0s 16us/sample - loss: 28.8101 - acc: 0.6445\n",
+      "512/512 [==============================] - 0s 24us/sample - loss: 3.4010 - acc: 0.5938\n",
       "Epoch 17/20\n",
-      "512/512 [==============================] - 0s 22us/sample - loss: 25.4112 - acc: 0.6445\n",
+      "512/512 [==============================] - 0s 23us/sample - loss: 3.3024 - acc: 0.5840\n",
       "Epoch 18/20\n",
-      "512/512 [==============================] - 0s 19us/sample - loss: 21.9444 - acc: 0.6445\n",
+      "512/512 [==============================] - 0s 21us/sample - loss: 3.2228 - acc: 0.5801\n",
       "Epoch 19/20\n",
-      "512/512 [==============================] - 0s 21us/sample - loss: 18.4608 - acc: 0.6445\n",
+      "512/512 [==============================] - 0s 24us/sample - loss: 3.1621 - acc: 0.5859\n",
       "Epoch 20/20\n",
-      "512/512 [==============================] - 0s 17us/sample - loss: 15.4329 - acc: 0.6406\n",
-      "256/256 [==============================] - 0s 674us/sample - loss: 13.4161 - acc: 0.6328\n",
+      "512/512 [==============================] - 0s 24us/sample - loss: 3.1037 - acc: 0.5879\n",
+      "256/256 [==============================] - 0s 761us/sample - loss: 3.2303 - acc: 0.6289\n",
       "Epoch 1/20\n",
-      "512/512 [==============================] - 0s 420us/sample - loss: 12.7121 - acc: 0.5723\n",
+      "512/512 [==============================] - 0s 939us/sample - loss: 23.6091 - acc: 0.6387\n",
       "Epoch 2/20\n",
-      "512/512 [==============================] - 0s 15us/sample - loss: 11.7563 - acc: 0.5762\n",
+      "512/512 [==============================] - 0s 23us/sample - loss: 21.9262 - acc: 0.6387\n",
       "Epoch 3/20\n",
-      "512/512 [==============================] - 0s 15us/sample - loss: 10.7671 - acc: 0.5820\n",
+      "512/512 [==============================] - 0s 28us/sample - loss: 20.2730 - acc: 0.6387\n",
       "Epoch 4/20\n",
-      "512/512 [==============================] - 0s 15us/sample - loss: 9.8497 - acc: 0.5840\n",
+      "512/512 [==============================] - 0s 24us/sample - loss: 18.7064 - acc: 0.6387\n",
       "Epoch 5/20\n",
-      "512/512 [==============================] - 0s 14us/sample - loss: 8.9775 - acc: 0.5801\n",
+      "512/512 [==============================] - 0s 22us/sample - loss: 17.2034 - acc: 0.6387\n",
       "Epoch 6/20\n",
-      "512/512 [==============================] - 0s 15us/sample - loss: 8.0967 - acc: 0.5801\n",
+      "512/512 [==============================] - 0s 30us/sample - loss: 15.7387 - acc: 0.6387\n",
       "Epoch 7/20\n",
-      "512/512 [==============================] - 0s 15us/sample - loss: 7.1615 - acc: 0.5723\n",
+      "512/512 [==============================] - 0s 24us/sample - loss: 14.2449 - acc: 0.6387\n",
       "Epoch 8/20\n",
-      "512/512 [==============================] - 0s 14us/sample - loss: 6.2291 - acc: 0.5684\n",
+      "512/512 [==============================] - 0s 26us/sample - loss: 12.7180 - acc: 0.6387\n",
       "Epoch 9/20\n",
-      "512/512 [==============================] - 0s 15us/sample - loss: 5.3146 - acc: 0.5703\n",
+      "512/512 [==============================] - 0s 29us/sample - loss: 11.1099 - acc: 0.6387\n",
       "Epoch 10/20\n",
-      "512/512 [==============================] - 0s 15us/sample - loss: 4.4273 - acc: 0.5410\n",
+      "512/512 [==============================] - 0s 25us/sample - loss: 9.4945 - acc: 0.6387\n",
       "Epoch 11/20\n",
-      "512/512 [==============================] - 0s 14us/sample - loss: 3.6744 - acc: 0.5156\n",
+      "512/512 [==============================] - 0s 23us/sample - loss: 7.6443 - acc: 0.6387\n",
       "Epoch 12/20\n",
-      "512/512 [==============================] - 0s 14us/sample - loss: 3.0898 - acc: 0.4473\n",
+      "512/512 [==============================] - 0s 24us/sample - loss: 5.7275 - acc: 0.6406\n",
       "Epoch 13/20\n",
-      "512/512 [==============================] - 0s 16us/sample - loss: 2.6743 - acc: 0.4180\n",
+      "512/512 [==============================] - 0s 26us/sample - loss: 3.8965 - acc: 0.6270\n",
       "Epoch 14/20\n",
-      "512/512 [==============================] - 0s 19us/sample - loss: 2.3861 - acc: 0.4297\n",
+      "512/512 [==============================] - 0s 27us/sample - loss: 2.7501 - acc: 0.5879\n",
       "Epoch 15/20\n",
-      "512/512 [==============================] - 0s 17us/sample - loss: 2.1355 - acc: 0.4551\n",
+      "512/512 [==============================] - 0s 27us/sample - loss: 2.2312 - acc: 0.5684\n",
       "Epoch 16/20\n",
-      "512/512 [==============================] - 0s 17us/sample - loss: 1.9303 - acc: 0.4570\n",
+      "512/512 [==============================] - 0s 25us/sample - loss: 2.2888 - acc: 0.5391\n",
       "Epoch 17/20\n",
-      "512/512 [==============================] - 0s 16us/sample - loss: 1.7551 - acc: 0.4980\n",
+      "512/512 [==============================] - 0s 27us/sample - loss: 2.1547 - acc: 0.5645\n",
       "Epoch 18/20\n",
-      "512/512 [==============================] - 0s 15us/sample - loss: 1.6265 - acc: 0.5293\n",
+      "512/512 [==============================] - 0s 28us/sample - loss: 1.9511 - acc: 0.5762\n",
       "Epoch 19/20\n",
-      "512/512 [==============================] - 0s 14us/sample - loss: 1.5158 - acc: 0.5352\n",
+      "512/512 [==============================] - 0s 23us/sample - loss: 1.9333 - acc: 0.5918\n",
       "Epoch 20/20\n",
-      "512/512 [==============================] - 0s 14us/sample - loss: 1.4232 - acc: 0.5586\n",
-      "256/256 [==============================] - 0s 652us/sample - loss: 1.3057 - acc: 0.5586\n",
+      "512/512 [==============================] - 0s 25us/sample - loss: 1.8936 - acc: 0.6016\n",
+      "256/256 [==============================] - 0s 977us/sample - loss: 1.9187 - acc: 0.5781\n",
       "Epoch 1/20\n",
-      "768/768 [==============================] - 0s 365us/sample - loss: 4.6330 - acc: 0.6055\n",
+      "768/768 [==============================] - 1s 738us/sample - loss: 41.0194 - acc: 0.3464\n",
       "Epoch 2/20\n",
-      "768/768 [==============================] - 0s 85us/sample - loss: 2.2350 - acc: 0.5846\n",
+      "768/768 [==============================] - 0s 149us/sample - loss: 9.9734 - acc: 0.4401\n",
       "Epoch 3/20\n",
-      "768/768 [==============================] - 0s 81us/sample - loss: 1.4406 - acc: 0.6055\n",
+      "768/768 [==============================] - 0s 169us/sample - loss: 4.7974 - acc: 0.4766\n",
       "Epoch 4/20\n",
-      "768/768 [==============================] - 0s 81us/sample - loss: 1.0927 - acc: 0.5938\n",
+      "768/768 [==============================] - 0s 164us/sample - loss: 3.7179 - acc: 0.4766\n",
       "Epoch 5/20\n",
-      "768/768 [==============================] - 0s 80us/sample - loss: 0.8973 - acc: 0.6120\n",
+      "768/768 [==============================] - 0s 195us/sample - loss: 2.8237 - acc: 0.4570\n",
       "Epoch 6/20\n",
-      "768/768 [==============================] - 0s 79us/sample - loss: 0.8137 - acc: 0.6276\n",
+      "768/768 [==============================] - 0s 148us/sample - loss: 2.1446 - acc: 0.4648\n",
       "Epoch 7/20\n",
-      "768/768 [==============================] - 0s 82us/sample - loss: 0.7395 - acc: 0.6445\n",
+      "768/768 [==============================] - 0s 145us/sample - loss: 1.6675 - acc: 0.5091\n",
       "Epoch 8/20\n",
-      "768/768 [==============================] - 0s 85us/sample - loss: 0.7110 - acc: 0.6719\n",
+      "768/768 [==============================] - 0s 174us/sample - loss: 1.3813 - acc: 0.5286\n",
       "Epoch 9/20\n",
-      "768/768 [==============================] - 0s 88us/sample - loss: 0.6842 - acc: 0.6667\n",
+      "768/768 [==============================] - 0s 172us/sample - loss: 1.1563 - acc: 0.5820\n",
       "Epoch 10/20\n",
-      "768/768 [==============================] - 0s 86us/sample - loss: 0.6571 - acc: 0.6680\n",
+      "768/768 [==============================] - 0s 166us/sample - loss: 1.0233 - acc: 0.5951\n",
       "Epoch 11/20\n",
-      "768/768 [==============================] - 0s 97us/sample - loss: 0.6400 - acc: 0.6641\n",
+      "768/768 [==============================] - 0s 183us/sample - loss: 0.9711 - acc: 0.6029\n",
       "Epoch 12/20\n",
-      "768/768 [==============================] - 0s 84us/sample - loss: 0.6599 - acc: 0.6823\n",
+      "768/768 [==============================] - 0s 176us/sample - loss: 0.9193 - acc: 0.6120\n",
       "Epoch 13/20\n",
-      "768/768 [==============================] - 0s 83us/sample - loss: 0.6441 - acc: 0.6693\n",
+      "768/768 [==============================] - 0s 167us/sample - loss: 0.8672 - acc: 0.6276\n",
       "Epoch 14/20\n",
-      "768/768 [==============================] - 0s 81us/sample - loss: 0.6294 - acc: 0.6901\n",
+      "768/768 [==============================] - 0s 163us/sample - loss: 0.8283 - acc: 0.6510\n",
       "Epoch 15/20\n",
-      "768/768 [==============================] - 0s 83us/sample - loss: 0.6212 - acc: 0.6914\n",
+      "768/768 [==============================] - 0s 176us/sample - loss: 0.8177 - acc: 0.6471\n",
       "Epoch 16/20\n",
-      "768/768 [==============================] - 0s 83us/sample - loss: 0.6359 - acc: 0.6719\n",
+      "768/768 [==============================] - 0s 168us/sample - loss: 0.8050 - acc: 0.6523\n",
       "Epoch 17/20\n",
-      "768/768 [==============================] - 0s 87us/sample - loss: 0.6217 - acc: 0.6784\n",
+      "768/768 [==============================] - 0s 158us/sample - loss: 0.7725 - acc: 0.6641\n",
       "Epoch 18/20\n",
-      "768/768 [==============================] - 0s 88us/sample - loss: 0.6410 - acc: 0.6797\n",
+      "768/768 [==============================] - 0s 154us/sample - loss: 0.8087 - acc: 0.6315\n",
       "Epoch 19/20\n",
-      "768/768 [==============================] - 0s 103us/sample - loss: 0.6087 - acc: 0.6888\n",
+      "768/768 [==============================] - 0s 152us/sample - loss: 0.7536 - acc: 0.6510\n",
       "Epoch 20/20\n",
-      "768/768 [==============================] - 0s 85us/sample - loss: 0.6171 - acc: 0.6654\n",
-      "Best: 0.6666666666666666 using {'batch_size': 10, 'epochs': 20}\n",
-      "Means: 0.6666666666666666, Stdev: 0.023509726673525765 with: {'batch_size': 10, 'epochs': 20}\n",
-      "Means: 0.6354166666666666, Stdev: 0.023938510821419574 with: {'batch_size': 20, 'epochs': 20}\n",
-      "Means: 0.6015625, Stdev: 0.05132917537611204 with: {'batch_size': 40, 'epochs': 20}\n",
-      "Means: 0.5963541666666666, Stdev: 0.062200890169250976 with: {'batch_size': 60, 'epochs': 20}\n",
-      "Means: 0.5377604166666666, Stdev: 0.06268959956880585 with: {'batch_size': 80, 'epochs': 20}\n",
-      "Means: 0.5911458333333334, Stdev: 0.03097754493065187 with: {'batch_size': 100, 'epochs': 20}\n"
+      "768/768 [==============================] - 0s 166us/sample - loss: 0.7409 - acc: 0.6628\n",
+      "Best: 0.640625 using {'batch_size': 10, 'epochs': 20}\n",
+      "Means: 0.640625, Stdev: 0.016876928902103804 with: {'batch_size': 10, 'epochs': 20}\n",
+      "Means: 0.6080729166666666, Stdev: 0.006639348324990605 with: {'batch_size': 20, 'epochs': 20}\n",
+      "Means: 0.6106770833333334, Stdev: 0.042830427613016996 with: {'batch_size': 40, 'epochs': 20}\n",
+      "Means: 0.5611979166666666, Stdev: 0.09223677473137935 with: {'batch_size': 60, 'epochs': 20}\n",
+      "Means: 0.5703125, Stdev: 0.05063078670631141 with: {'batch_size': 80, 'epochs': 20}\n",
+      "Means: 0.5924479166666666, Stdev: 0.025976480915703128 with: {'batch_size': 100, 'epochs': 20}\n"
      ]
     }
    ],
@@ -3570,9 +3517,9 @@
    "version": "0.3.2"
   },
   "kernelspec": {
-   "display_name": "U4-S2-NNF (Python 3.7)",
+   "display_name": "U4-S2-NN (Python3)",
    "language": "python",
-   "name": "u4-s2-nnf"
+   "name": "u4-s2-nn"
   },
   "language_info": {
    "codemirror_mode": {
@@ -3588,5 +3535,5 @@
   }
  },
  "nbformat": 4,
- "nbformat_minor": 2
+ "nbformat_minor": 4
 }
