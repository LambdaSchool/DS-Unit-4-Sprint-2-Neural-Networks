diff --git a/module4-Hyperparameter-Tuning/LS_DS_424_Hyperparameter_Tuning_Lecture.ipynb b/module4-Hyperparameter-Tuning/LS_DS_424_Hyperparameter_Tuning_Lecture.ipynb
index f4baa72..8a2add6 100644
--- a/module4-Hyperparameter-Tuning/LS_DS_424_Hyperparameter_Tuning_Lecture.ipynb
+++ b/module4-Hyperparameter-Tuning/LS_DS_424_Hyperparameter_Tuning_Lecture.ipynb
@@ -19,7 +19,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 5,
+   "execution_count": 1,
    "metadata": {
     "colab": {},
     "colab_type": "code",
@@ -37,6 +37,43 @@
    ]
   },
   {
+   "cell_type": "code",
+   "execution_count": 2,
+   "metadata": {},
+   "outputs": [
+    {
+     "data": {
+      "text/html": [
+       "\n",
+       "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/ds5/ds5-hyperparameter-tuning/runs/9xtobhhn\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
+       "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
+       "    "
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "data": {
+      "text/plain": [
+       "W&B Run: https://app.wandb.ai/ds5/ds5-hyperparameter-tuning/runs/9xtobhhn"
+      ]
+     },
+     "execution_count": 2,
+     "metadata": {},
+     "output_type": "execute_result"
+    }
+   ],
+   "source": [
+    "import wandb\n",
+    "from wandb.keras import WandbCallback\n",
+    "wandb.init(project=\"ds5-hyperparameter-tuning\", entity=\"ds5\")"
+   ]
+  },
+  {
    "cell_type": "markdown",
    "metadata": {
     "colab_type": "text",
@@ -50,7 +87,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 7,
+   "execution_count": 3,
    "metadata": {
     "colab": {
      "base_uri": "https://localhost:8080/",
@@ -211,7 +248,7 @@
        "4     18.7  396.90   5.33  36.2  "
       ]
      },
-     "execution_count": 7,
+     "execution_count": 3,
      "metadata": {},
      "output_type": "execute_result"
     }
@@ -242,7 +279,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 8,
+   "execution_count": 4,
    "metadata": {
     "colab": {
      "base_uri": "https://localhost:8080/",
@@ -300,7 +337,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 9,
+   "execution_count": 6,
    "metadata": {
     "colab": {
      "base_uri": "https://localhost:8080/",
@@ -312,129 +349,118 @@
    },
    "outputs": [
     {
-     "name": "stderr",
-     "output_type": "stream",
-     "text": [
-      "WARNING: Logging before flag parsing goes to stderr.\n",
-      "W0815 10:08:20.955155 4430419392 deprecation.py:506] From /Users/jonathansokoll/anaconda3/envs/U4-S2-NNF/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
-      "Instructions for updating:\n",
-      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
-     ]
-    },
-    {
      "name": "stdout",
      "output_type": "stream",
      "text": [
-      "Train on 339 samples, validate on 167 samples\n",
       "Epoch 1/50\n",
-      "339/339 [==============================] - 0s 366us/sample - loss: 625.2513 - mean_squared_error: 625.2513 - val_loss: 279.9214 - val_mean_squared_error: 279.9214\n",
+      "506/506 [==============================] - 0s 421us/sample - loss: 455.6118 - mean_squared_error: 455.6118\n",
       "Epoch 2/50\n",
-      "339/339 [==============================] - 0s 95us/sample - loss: 373.3546 - mean_squared_error: 373.3546 - val_loss: 180.1021 - val_mean_squared_error: 180.1021\n",
+      "506/506 [==============================] - 0s 205us/sample - loss: 130.3582 - mean_squared_error: 130.3582\n",
       "Epoch 3/50\n",
-      "339/339 [==============================] - 0s 93us/sample - loss: 101.2103 - mean_squared_error: 101.2103 - val_loss: 137.3386 - val_mean_squared_error: 137.3387\n",
+      "506/506 [==============================] - 0s 175us/sample - loss: 41.0034 - mean_squared_error: 41.0034\n",
       "Epoch 4/50\n",
-      "339/339 [==============================] - 0s 84us/sample - loss: 33.7659 - mean_squared_error: 33.7659 - val_loss: 114.6741 - val_mean_squared_error: 114.6741\n",
+      "506/506 [==============================] - 0s 221us/sample - loss: 24.9283 - mean_squared_error: 24.9283\n",
       "Epoch 5/50\n",
-      "339/339 [==============================] - 0s 82us/sample - loss: 18.5104 - mean_squared_error: 18.5104 - val_loss: 113.3629 - val_mean_squared_error: 113.3628\n",
+      "506/506 [==============================] - 0s 148us/sample - loss: 20.6888 - mean_squared_error: 20.6888\n",
       "Epoch 6/50\n",
-      "339/339 [==============================] - 0s 91us/sample - loss: 14.5301 - mean_squared_error: 14.5301 - val_loss: 117.4675 - val_mean_squared_error: 117.4675\n",
+      "506/506 [==============================] - 0s 229us/sample - loss: 18.6622 - mean_squared_error: 18.6622\n",
       "Epoch 7/50\n",
-      "339/339 [==============================] - 0s 92us/sample - loss: 13.1114 - mean_squared_error: 13.1114 - val_loss: 115.7412 - val_mean_squared_error: 115.7412\n",
+      "506/506 [==============================] - 0s 182us/sample - loss: 17.3133 - mean_squared_error: 17.3133\n",
       "Epoch 8/50\n",
-      "339/339 [==============================] - 0s 95us/sample - loss: 12.1406 - mean_squared_error: 12.1406 - val_loss: 112.9944 - val_mean_squared_error: 112.9944\n",
+      "506/506 [==============================] - 0s 186us/sample - loss: 16.1071 - mean_squared_error: 16.1071\n",
       "Epoch 9/50\n",
-      "339/339 [==============================] - 0s 89us/sample - loss: 11.5139 - mean_squared_error: 11.5139 - val_loss: 110.0447 - val_mean_squared_error: 110.0447\n",
+      "506/506 [==============================] - 0s 215us/sample - loss: 15.2102 - mean_squared_error: 15.2102\n",
       "Epoch 10/50\n",
-      "339/339 [==============================] - 0s 88us/sample - loss: 10.9077 - mean_squared_error: 10.9077 - val_loss: 106.9348 - val_mean_squared_error: 106.9348\n",
+      "506/506 [==============================] - 0s 145us/sample - loss: 14.3956 - mean_squared_error: 14.3956\n",
       "Epoch 11/50\n",
-      "339/339 [==============================] - 0s 85us/sample - loss: 10.5648 - mean_squared_error: 10.5648 - val_loss: 103.4860 - val_mean_squared_error: 103.4860\n",
+      "506/506 [==============================] - 0s 170us/sample - loss: 13.9170 - mean_squared_error: 13.9170\n",
       "Epoch 12/50\n",
-      "339/339 [==============================] - 0s 87us/sample - loss: 9.9297 - mean_squared_error: 9.9297 - val_loss: 100.5036 - val_mean_squared_error: 100.5036\n",
+      "506/506 [==============================] - 0s 183us/sample - loss: 13.6120 - mean_squared_error: 13.6120\n",
       "Epoch 13/50\n",
-      "339/339 [==============================] - 0s 87us/sample - loss: 9.4464 - mean_squared_error: 9.4464 - val_loss: 98.4739 - val_mean_squared_error: 98.4739\n",
+      "506/506 [==============================] - 0s 178us/sample - loss: 13.1474 - mean_squared_error: 13.1474\n",
       "Epoch 14/50\n",
-      "339/339 [==============================] - 0s 84us/sample - loss: 9.1621 - mean_squared_error: 9.1621 - val_loss: 95.9992 - val_mean_squared_error: 95.9992\n",
+      "506/506 [==============================] - 0s 207us/sample - loss: 12.6562 - mean_squared_error: 12.6562\n",
       "Epoch 15/50\n",
-      "339/339 [==============================] - 0s 85us/sample - loss: 8.9122 - mean_squared_error: 8.9122 - val_loss: 91.8091 - val_mean_squared_error: 91.8091\n",
+      "506/506 [==============================] - 0s 202us/sample - loss: 12.7242 - mean_squared_error: 12.7242\n",
       "Epoch 16/50\n",
-      "339/339 [==============================] - 0s 86us/sample - loss: 8.5564 - mean_squared_error: 8.5564 - val_loss: 91.1116 - val_mean_squared_error: 91.1116\n",
+      "506/506 [==============================] - 0s 153us/sample - loss: 12.1434 - mean_squared_error: 12.1434\n",
       "Epoch 17/50\n",
-      "339/339 [==============================] - 0s 87us/sample - loss: 8.0328 - mean_squared_error: 8.0328 - val_loss: 87.0650 - val_mean_squared_error: 87.0650\n",
+      "506/506 [==============================] - 0s 198us/sample - loss: 11.7676 - mean_squared_error: 11.7676\n",
       "Epoch 18/50\n",
-      "339/339 [==============================] - 0s 83us/sample - loss: 7.7535 - mean_squared_error: 7.7535 - val_loss: 86.3742 - val_mean_squared_error: 86.3742\n",
+      "506/506 [==============================] - 0s 154us/sample - loss: 11.4424 - mean_squared_error: 11.4424\n",
       "Epoch 19/50\n",
-      "339/339 [==============================] - 0s 86us/sample - loss: 7.5547 - mean_squared_error: 7.5547 - val_loss: 82.6835 - val_mean_squared_error: 82.6835\n",
+      "506/506 [==============================] - 0s 195us/sample - loss: 11.1370 - mean_squared_error: 11.1370\n",
       "Epoch 20/50\n",
-      "339/339 [==============================] - 0s 85us/sample - loss: 7.3827 - mean_squared_error: 7.3827 - val_loss: 81.1169 - val_mean_squared_error: 81.1169\n",
+      "506/506 [==============================] - 0s 209us/sample - loss: 10.9864 - mean_squared_error: 10.9864\n",
       "Epoch 21/50\n",
-      "339/339 [==============================] - 0s 83us/sample - loss: 7.1717 - mean_squared_error: 7.1717 - val_loss: 78.6616 - val_mean_squared_error: 78.6616\n",
+      "506/506 [==============================] - 0s 164us/sample - loss: 10.7964 - mean_squared_error: 10.7964\n",
       "Epoch 22/50\n",
-      "339/339 [==============================] - 0s 84us/sample - loss: 6.9017 - mean_squared_error: 6.9017 - val_loss: 77.7369 - val_mean_squared_error: 77.7369\n",
+      "506/506 [==============================] - 0s 193us/sample - loss: 10.6141 - mean_squared_error: 10.6141\n",
       "Epoch 23/50\n",
-      "339/339 [==============================] - 0s 83us/sample - loss: 6.7186 - mean_squared_error: 6.7186 - val_loss: 74.8546 - val_mean_squared_error: 74.8546\n",
+      "506/506 [==============================] - 0s 182us/sample - loss: 10.1870 - mean_squared_error: 10.1870\n",
       "Epoch 24/50\n",
-      "339/339 [==============================] - 0s 83us/sample - loss: 6.4259 - mean_squared_error: 6.4259 - val_loss: 72.0877 - val_mean_squared_error: 72.0877\n",
+      "506/506 [==============================] - 0s 179us/sample - loss: 10.2027 - mean_squared_error: 10.2027\n",
       "Epoch 25/50\n",
-      "339/339 [==============================] - 0s 86us/sample - loss: 6.5469 - mean_squared_error: 6.5469 - val_loss: 70.2001 - val_mean_squared_error: 70.2001\n",
+      "506/506 [==============================] - 0s 246us/sample - loss: 9.9361 - mean_squared_error: 9.9361\n",
       "Epoch 26/50\n",
-      "339/339 [==============================] - 0s 86us/sample - loss: 6.1998 - mean_squared_error: 6.1998 - val_loss: 71.6276 - val_mean_squared_error: 71.6276\n",
+      "506/506 [==============================] - 0s 451us/sample - loss: 9.7415 - mean_squared_error: 9.7415\n",
       "Epoch 27/50\n",
-      "339/339 [==============================] - 0s 86us/sample - loss: 6.1886 - mean_squared_error: 6.1886 - val_loss: 66.5151 - val_mean_squared_error: 66.5151\n",
+      "506/506 [==============================] - 0s 280us/sample - loss: 9.5137 - mean_squared_error: 9.5137\n",
       "Epoch 28/50\n",
-      "339/339 [==============================] - 0s 86us/sample - loss: 5.9647 - mean_squared_error: 5.9647 - val_loss: 64.1536 - val_mean_squared_error: 64.1536\n",
+      "506/506 [==============================] - 0s 162us/sample - loss: 9.2219 - mean_squared_error: 9.2219\n",
       "Epoch 29/50\n",
-      "339/339 [==============================] - 0s 82us/sample - loss: 5.8475 - mean_squared_error: 5.8475 - val_loss: 62.9218 - val_mean_squared_error: 62.9218\n",
+      "506/506 [==============================] - 0s 160us/sample - loss: 9.0675 - mean_squared_error: 9.0675\n",
       "Epoch 30/50\n",
-      "339/339 [==============================] - 0s 88us/sample - loss: 5.7472 - mean_squared_error: 5.7472 - val_loss: 61.4670 - val_mean_squared_error: 61.4670\n",
+      "506/506 [==============================] - 0s 169us/sample - loss: 8.9177 - mean_squared_error: 8.9177\n",
       "Epoch 31/50\n",
-      "339/339 [==============================] - 0s 88us/sample - loss: 5.6262 - mean_squared_error: 5.6262 - val_loss: 60.4396 - val_mean_squared_error: 60.4396\n",
+      "506/506 [==============================] - 0s 170us/sample - loss: 8.8176 - mean_squared_error: 8.8176\n",
       "Epoch 32/50\n",
-      "339/339 [==============================] - 0s 84us/sample - loss: 5.5064 - mean_squared_error: 5.5064 - val_loss: 59.4765 - val_mean_squared_error: 59.4765\n",
+      "506/506 [==============================] - 0s 443us/sample - loss: 8.7709 - mean_squared_error: 8.7709\n",
       "Epoch 33/50\n",
-      "339/339 [==============================] - 0s 84us/sample - loss: 5.4368 - mean_squared_error: 5.4368 - val_loss: 57.5645 - val_mean_squared_error: 57.5645\n",
+      "506/506 [==============================] - 0s 332us/sample - loss: 8.4227 - mean_squared_error: 8.4227\n",
       "Epoch 34/50\n",
-      "339/339 [==============================] - 0s 84us/sample - loss: 5.3329 - mean_squared_error: 5.3329 - val_loss: 54.6676 - val_mean_squared_error: 54.6676\n",
+      "506/506 [==============================] - 0s 395us/sample - loss: 8.5124 - mean_squared_error: 8.5124\n",
       "Epoch 35/50\n",
-      "339/339 [==============================] - 0s 85us/sample - loss: 5.2066 - mean_squared_error: 5.2066 - val_loss: 56.0873 - val_mean_squared_error: 56.0873\n",
+      "506/506 [==============================] - 0s 351us/sample - loss: 8.4745 - mean_squared_error: 8.4745\n",
       "Epoch 36/50\n",
-      "339/339 [==============================] - 0s 91us/sample - loss: 5.2098 - mean_squared_error: 5.2098 - val_loss: 53.7955 - val_mean_squared_error: 53.7955\n",
+      "506/506 [==============================] - 0s 161us/sample - loss: 8.0268 - mean_squared_error: 8.0268\n",
       "Epoch 37/50\n",
-      "339/339 [==============================] - 0s 87us/sample - loss: 5.4417 - mean_squared_error: 5.4417 - val_loss: 52.4190 - val_mean_squared_error: 52.4189\n",
+      "506/506 [==============================] - 0s 167us/sample - loss: 8.0313 - mean_squared_error: 8.0313\n",
       "Epoch 38/50\n",
-      "339/339 [==============================] - 0s 85us/sample - loss: 4.9801 - mean_squared_error: 4.9801 - val_loss: 51.0138 - val_mean_squared_error: 51.0138\n",
+      "506/506 [==============================] - 0s 213us/sample - loss: 7.8154 - mean_squared_error: 7.8154\n",
       "Epoch 39/50\n",
-      "339/339 [==============================] - 0s 94us/sample - loss: 5.0640 - mean_squared_error: 5.0640 - val_loss: 50.9198 - val_mean_squared_error: 50.9198\n",
+      "506/506 [==============================] - 0s 541us/sample - loss: 7.9013 - mean_squared_error: 7.9013\n",
       "Epoch 40/50\n",
-      "339/339 [==============================] - 0s 97us/sample - loss: 5.0598 - mean_squared_error: 5.0598 - val_loss: 51.4312 - val_mean_squared_error: 51.4312\n",
+      "506/506 [==============================] - 0s 290us/sample - loss: 7.6150 - mean_squared_error: 7.6150\n",
       "Epoch 41/50\n",
-      "339/339 [==============================] - 0s 94us/sample - loss: 4.9155 - mean_squared_error: 4.9155 - val_loss: 49.5652 - val_mean_squared_error: 49.5652\n",
+      "506/506 [==============================] - 0s 231us/sample - loss: 7.3843 - mean_squared_error: 7.3843\n",
       "Epoch 42/50\n",
-      "339/339 [==============================] - 0s 95us/sample - loss: 4.6731 - mean_squared_error: 4.6731 - val_loss: 47.9462 - val_mean_squared_error: 47.9462\n",
+      "506/506 [==============================] - 0s 210us/sample - loss: 7.4241 - mean_squared_error: 7.4241\n",
       "Epoch 43/50\n",
-      "339/339 [==============================] - 0s 93us/sample - loss: 4.7018 - mean_squared_error: 4.7018 - val_loss: 48.1317 - val_mean_squared_error: 48.1317\n",
+      "506/506 [==============================] - 0s 319us/sample - loss: 7.2627 - mean_squared_error: 7.2627\n",
       "Epoch 44/50\n",
-      "339/339 [==============================] - 0s 89us/sample - loss: 4.8628 - mean_squared_error: 4.8628 - val_loss: 47.4068 - val_mean_squared_error: 47.4068\n",
+      "506/506 [==============================] - 0s 237us/sample - loss: 7.2931 - mean_squared_error: 7.2931\n",
       "Epoch 45/50\n",
-      "339/339 [==============================] - 0s 90us/sample - loss: 4.5611 - mean_squared_error: 4.5611 - val_loss: 47.3415 - val_mean_squared_error: 47.3415\n",
+      "506/506 [==============================] - 0s 198us/sample - loss: 6.9917 - mean_squared_error: 6.9917\n",
       "Epoch 46/50\n",
-      "339/339 [==============================] - 0s 98us/sample - loss: 4.6660 - mean_squared_error: 4.6660 - val_loss: 45.0834 - val_mean_squared_error: 45.0834\n",
+      "506/506 [==============================] - 0s 165us/sample - loss: 6.9354 - mean_squared_error: 6.9354\n",
       "Epoch 47/50\n",
-      "339/339 [==============================] - 0s 93us/sample - loss: 4.5393 - mean_squared_error: 4.5393 - val_loss: 44.8492 - val_mean_squared_error: 44.8492\n",
+      "506/506 [==============================] - 0s 228us/sample - loss: 7.0254 - mean_squared_error: 7.0254\n",
       "Epoch 48/50\n",
-      "339/339 [==============================] - 0s 95us/sample - loss: 4.4971 - mean_squared_error: 4.4971 - val_loss: 44.5613 - val_mean_squared_error: 44.5613\n",
+      "506/506 [==============================] - 0s 230us/sample - loss: 6.9433 - mean_squared_error: 6.9433\n",
       "Epoch 49/50\n",
-      "339/339 [==============================] - 0s 94us/sample - loss: 4.5186 - mean_squared_error: 4.5186 - val_loss: 42.3793 - val_mean_squared_error: 42.3793\n",
+      "506/506 [==============================] - 0s 450us/sample - loss: 6.5043 - mean_squared_error: 6.5043\n",
       "Epoch 50/50\n",
-      "339/339 [==============================] - 0s 95us/sample - loss: 4.4599 - mean_squared_error: 4.4599 - val_loss: 44.0912 - val_mean_squared_error: 44.0912\n"
+      "506/506 [==============================] - 0s 456us/sample - loss: 6.7050 - mean_squared_error: 6.7050\n"
      ]
     },
     {
      "data": {
       "text/plain": [
-       "<tensorflow.python.keras.callbacks.History at 0x1a2c41aa90>"
+       "<tensorflow.python.keras.callbacks.History at 0x1a3070cc88>"
       ]
      },
-     "execution_count": 9,
+     "execution_count": 6,
      "metadata": {},
      "output_type": "execute_result"
     }
@@ -453,7 +479,7 @@
     "# Compile Model\n",
     "model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
     "# Fit Model\n",
-    "model.fit(X, y, validation_split=0.33, epochs=epochs, batch_size=batch_size)"
+    "model.fit(X, y, epochs=epochs, batch_size=batch_size)"
    ]
   },
   {
@@ -470,7 +496,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 10,
+   "execution_count": 8,
    "metadata": {
     "colab": {
      "base_uri": "https://localhost:8080/",
@@ -485,116 +511,115 @@
      "name": "stdout",
      "output_type": "stream",
      "text": [
-      "Train on 339 samples, validate on 167 samples\n",
       "Epoch 1/50\n",
-      "339/339 [==============================] - 0s 383us/sample - loss: 496.6472 - mean_squared_error: 496.6472 - val_loss: 325.2020 - val_mean_squared_error: 325.2020\n",
+      "339/339 [==============================] - 0s 487us/sample - loss: 480.6018 - mean_squared_error: 480.6018\n",
       "Epoch 2/50\n",
-      "339/339 [==============================] - 0s 103us/sample - loss: 243.5689 - mean_squared_error: 243.5689 - val_loss: 112.0480 - val_mean_squared_error: 112.0480\n",
+      "339/339 [==============================] - 0s 213us/sample - loss: 242.6151 - mean_squared_error: 242.6151\n",
       "Epoch 3/50\n",
-      "339/339 [==============================] - 0s 92us/sample - loss: 82.1482 - mean_squared_error: 82.1482 - val_loss: 49.1192 - val_mean_squared_error: 49.1192\n",
+      "339/339 [==============================] - 0s 199us/sample - loss: 79.3822 - mean_squared_error: 79.3822\n",
       "Epoch 4/50\n",
-      "339/339 [==============================] - 0s 83us/sample - loss: 44.6474 - mean_squared_error: 44.6474 - val_loss: 33.1579 - val_mean_squared_error: 33.1579\n",
+      "339/339 [==============================] - 0s 193us/sample - loss: 38.1895 - mean_squared_error: 38.1895\n",
       "Epoch 5/50\n",
-      "339/339 [==============================] - 0s 86us/sample - loss: 33.9135 - mean_squared_error: 33.9135 - val_loss: 26.5114 - val_mean_squared_error: 26.5114\n",
+      "339/339 [==============================] - 0s 165us/sample - loss: 28.8355 - mean_squared_error: 28.8355\n",
       "Epoch 6/50\n",
-      "339/339 [==============================] - 0s 90us/sample - loss: 29.1068 - mean_squared_error: 29.1068 - val_loss: 22.8563 - val_mean_squared_error: 22.8563\n",
+      "339/339 [==============================] - 0s 200us/sample - loss: 24.9436 - mean_squared_error: 24.9436\n",
       "Epoch 7/50\n",
-      "339/339 [==============================] - 0s 86us/sample - loss: 26.0441 - mean_squared_error: 26.0441 - val_loss: 21.0577 - val_mean_squared_error: 21.0577\n",
+      "339/339 [==============================] - 0s 206us/sample - loss: 21.8509 - mean_squared_error: 21.8509\n",
       "Epoch 8/50\n",
-      "339/339 [==============================] - 0s 83us/sample - loss: 23.8012 - mean_squared_error: 23.8012 - val_loss: 19.6500 - val_mean_squared_error: 19.6500\n",
+      "339/339 [==============================] - 0s 159us/sample - loss: 19.8187 - mean_squared_error: 19.8187\n",
       "Epoch 9/50\n",
-      "339/339 [==============================] - 0s 87us/sample - loss: 22.0960 - mean_squared_error: 22.0960 - val_loss: 18.4615 - val_mean_squared_error: 18.4615\n",
+      "339/339 [==============================] - 0s 202us/sample - loss: 18.9774 - mean_squared_error: 18.9774\n",
       "Epoch 10/50\n",
-      "339/339 [==============================] - 0s 87us/sample - loss: 20.4015 - mean_squared_error: 20.4015 - val_loss: 16.8798 - val_mean_squared_error: 16.8798\n",
+      "339/339 [==============================] - 0s 207us/sample - loss: 17.5820 - mean_squared_error: 17.5820\n",
       "Epoch 11/50\n",
-      "339/339 [==============================] - 0s 87us/sample - loss: 18.8368 - mean_squared_error: 18.8368 - val_loss: 16.0103 - val_mean_squared_error: 16.0103\n",
+      "339/339 [==============================] - 0s 184us/sample - loss: 16.3250 - mean_squared_error: 16.3250\n",
       "Epoch 12/50\n",
-      "339/339 [==============================] - 0s 84us/sample - loss: 17.7578 - mean_squared_error: 17.7578 - val_loss: 15.9651 - val_mean_squared_error: 15.9651\n",
+      "339/339 [==============================] - 0s 147us/sample - loss: 15.9500 - mean_squared_error: 15.9500\n",
       "Epoch 13/50\n",
-      "339/339 [==============================] - 0s 82us/sample - loss: 16.6941 - mean_squared_error: 16.6941 - val_loss: 17.1631 - val_mean_squared_error: 17.1631\n",
+      "339/339 [==============================] - 0s 152us/sample - loss: 14.8417 - mean_squared_error: 14.8417\n",
       "Epoch 14/50\n",
-      "339/339 [==============================] - 0s 85us/sample - loss: 16.4518 - mean_squared_error: 16.4518 - val_loss: 14.2232 - val_mean_squared_error: 14.2232\n",
+      "339/339 [==============================] - 0s 152us/sample - loss: 14.1242 - mean_squared_error: 14.1242\n",
       "Epoch 15/50\n",
-      "339/339 [==============================] - 0s 83us/sample - loss: 15.2741 - mean_squared_error: 15.2741 - val_loss: 14.8824 - val_mean_squared_error: 14.8824\n",
+      "339/339 [==============================] - 0s 239us/sample - loss: 13.7950 - mean_squared_error: 13.7950\n",
       "Epoch 16/50\n",
-      "339/339 [==============================] - 0s 88us/sample - loss: 15.0555 - mean_squared_error: 15.0555 - val_loss: 13.6472 - val_mean_squared_error: 13.6472\n",
+      "339/339 [==============================] - 0s 224us/sample - loss: 13.3128 - mean_squared_error: 13.3128\n",
       "Epoch 17/50\n",
-      "339/339 [==============================] - 0s 87us/sample - loss: 14.4602 - mean_squared_error: 14.4602 - val_loss: 12.9781 - val_mean_squared_error: 12.9781\n",
+      "339/339 [==============================] - 0s 261us/sample - loss: 13.0031 - mean_squared_error: 13.0031\n",
       "Epoch 18/50\n",
-      "339/339 [==============================] - 0s 89us/sample - loss: 13.8586 - mean_squared_error: 13.8586 - val_loss: 12.5347 - val_mean_squared_error: 12.5347\n",
+      "339/339 [==============================] - 0s 197us/sample - loss: 12.6399 - mean_squared_error: 12.6399\n",
       "Epoch 19/50\n",
-      "339/339 [==============================] - 0s 87us/sample - loss: 13.6874 - mean_squared_error: 13.6874 - val_loss: 12.4062 - val_mean_squared_error: 12.4062\n",
+      "339/339 [==============================] - 0s 213us/sample - loss: 12.2348 - mean_squared_error: 12.2348\n",
       "Epoch 20/50\n",
-      "339/339 [==============================] - 0s 89us/sample - loss: 13.1289 - mean_squared_error: 13.1289 - val_loss: 12.8965 - val_mean_squared_error: 12.8965\n",
+      "339/339 [==============================] - 0s 181us/sample - loss: 11.9552 - mean_squared_error: 11.9552\n",
       "Epoch 21/50\n",
-      "339/339 [==============================] - 0s 90us/sample - loss: 12.9636 - mean_squared_error: 12.9636 - val_loss: 11.8393 - val_mean_squared_error: 11.8393\n",
+      "339/339 [==============================] - 0s 148us/sample - loss: 11.5355 - mean_squared_error: 11.5355\n",
       "Epoch 22/50\n",
-      "339/339 [==============================] - 0s 84us/sample - loss: 12.6905 - mean_squared_error: 12.6905 - val_loss: 11.9046 - val_mean_squared_error: 11.9046\n",
+      "339/339 [==============================] - 0s 145us/sample - loss: 11.1547 - mean_squared_error: 11.1547\n",
       "Epoch 23/50\n",
-      "339/339 [==============================] - 0s 84us/sample - loss: 12.3174 - mean_squared_error: 12.3174 - val_loss: 11.7349 - val_mean_squared_error: 11.7349\n",
+      "339/339 [==============================] - 0s 141us/sample - loss: 11.2922 - mean_squared_error: 11.2922\n",
       "Epoch 24/50\n",
-      "339/339 [==============================] - 0s 88us/sample - loss: 11.9281 - mean_squared_error: 11.9281 - val_loss: 11.9656 - val_mean_squared_error: 11.9656\n",
+      "339/339 [==============================] - 0s 138us/sample - loss: 11.1180 - mean_squared_error: 11.1180\n",
       "Epoch 25/50\n",
-      "339/339 [==============================] - 0s 84us/sample - loss: 11.8962 - mean_squared_error: 11.8962 - val_loss: 12.0452 - val_mean_squared_error: 12.0452\n",
+      "339/339 [==============================] - 0s 147us/sample - loss: 10.8883 - mean_squared_error: 10.8883\n",
       "Epoch 26/50\n",
-      "339/339 [==============================] - 0s 83us/sample - loss: 11.5107 - mean_squared_error: 11.5107 - val_loss: 11.4149 - val_mean_squared_error: 11.4149\n",
+      "339/339 [==============================] - 0s 154us/sample - loss: 10.3720 - mean_squared_error: 10.3720\n",
       "Epoch 27/50\n",
-      "339/339 [==============================] - 0s 84us/sample - loss: 11.2426 - mean_squared_error: 11.2426 - val_loss: 11.2239 - val_mean_squared_error: 11.2239\n",
+      "339/339 [==============================] - 0s 165us/sample - loss: 10.5430 - mean_squared_error: 10.5430\n",
       "Epoch 28/50\n",
-      "339/339 [==============================] - 0s 84us/sample - loss: 11.1747 - mean_squared_error: 11.1747 - val_loss: 11.5999 - val_mean_squared_error: 11.5999\n",
+      "339/339 [==============================] - 0s 144us/sample - loss: 9.8333 - mean_squared_error: 9.8333\n",
       "Epoch 29/50\n",
-      "339/339 [==============================] - 0s 89us/sample - loss: 10.8296 - mean_squared_error: 10.8296 - val_loss: 11.1040 - val_mean_squared_error: 11.1040\n",
+      "339/339 [==============================] - 0s 139us/sample - loss: 9.9720 - mean_squared_error: 9.9720\n",
       "Epoch 30/50\n",
-      "339/339 [==============================] - 0s 83us/sample - loss: 10.5858 - mean_squared_error: 10.5858 - val_loss: 11.6639 - val_mean_squared_error: 11.6639\n",
+      "339/339 [==============================] - 0s 140us/sample - loss: 9.9658 - mean_squared_error: 9.9658\n",
       "Epoch 31/50\n",
-      "339/339 [==============================] - 0s 82us/sample - loss: 10.3166 - mean_squared_error: 10.3166 - val_loss: 11.0816 - val_mean_squared_error: 11.0816\n",
+      "339/339 [==============================] - 0s 140us/sample - loss: 9.9668 - mean_squared_error: 9.9668\n",
       "Epoch 32/50\n",
-      "339/339 [==============================] - 0s 83us/sample - loss: 10.3662 - mean_squared_error: 10.3662 - val_loss: 10.9698 - val_mean_squared_error: 10.9698\n",
+      "339/339 [==============================] - 0s 168us/sample - loss: 9.3771 - mean_squared_error: 9.3771\n",
       "Epoch 33/50\n",
-      "339/339 [==============================] - 0s 84us/sample - loss: 10.3668 - mean_squared_error: 10.3668 - val_loss: 11.0636 - val_mean_squared_error: 11.0636\n",
+      "339/339 [==============================] - 0s 186us/sample - loss: 9.5238 - mean_squared_error: 9.5238\n",
       "Epoch 34/50\n",
-      "339/339 [==============================] - 0s 85us/sample - loss: 10.2008 - mean_squared_error: 10.2008 - val_loss: 11.2904 - val_mean_squared_error: 11.2904\n",
+      "339/339 [==============================] - 0s 187us/sample - loss: 9.4644 - mean_squared_error: 9.4644\n",
       "Epoch 35/50\n",
-      "339/339 [==============================] - 0s 85us/sample - loss: 9.7613 - mean_squared_error: 9.7613 - val_loss: 11.9080 - val_mean_squared_error: 11.9080\n",
+      "339/339 [==============================] - 0s 189us/sample - loss: 9.1343 - mean_squared_error: 9.1343\n",
       "Epoch 36/50\n",
-      "339/339 [==============================] - 0s 80us/sample - loss: 9.6370 - mean_squared_error: 9.6370 - val_loss: 11.0098 - val_mean_squared_error: 11.0098\n",
+      "339/339 [==============================] - 0s 189us/sample - loss: 9.0525 - mean_squared_error: 9.0525\n",
       "Epoch 37/50\n",
-      "339/339 [==============================] - 0s 82us/sample - loss: 9.4705 - mean_squared_error: 9.4705 - val_loss: 10.7119 - val_mean_squared_error: 10.7119\n",
+      "339/339 [==============================] - 0s 132us/sample - loss: 8.8340 - mean_squared_error: 8.8340\n",
       "Epoch 38/50\n",
-      "339/339 [==============================] - 0s 85us/sample - loss: 9.6508 - mean_squared_error: 9.6508 - val_loss: 10.7547 - val_mean_squared_error: 10.7547\n",
+      "339/339 [==============================] - 0s 166us/sample - loss: 8.8162 - mean_squared_error: 8.8162\n",
       "Epoch 39/50\n",
-      "339/339 [==============================] - 0s 85us/sample - loss: 9.1422 - mean_squared_error: 9.1422 - val_loss: 10.7156 - val_mean_squared_error: 10.7156\n",
+      "339/339 [==============================] - 0s 149us/sample - loss: 8.6506 - mean_squared_error: 8.6506\n",
       "Epoch 40/50\n",
-      "339/339 [==============================] - 0s 83us/sample - loss: 9.0300 - mean_squared_error: 9.0300 - val_loss: 10.7564 - val_mean_squared_error: 10.7564\n",
+      "339/339 [==============================] - 0s 139us/sample - loss: 8.3543 - mean_squared_error: 8.3543\n",
       "Epoch 41/50\n",
-      "339/339 [==============================] - 0s 87us/sample - loss: 8.8902 - mean_squared_error: 8.8902 - val_loss: 10.4726 - val_mean_squared_error: 10.4726\n",
+      "339/339 [==============================] - 0s 144us/sample - loss: 8.3217 - mean_squared_error: 8.3217\n",
       "Epoch 42/50\n",
-      "339/339 [==============================] - 0s 87us/sample - loss: 8.7206 - mean_squared_error: 8.7206 - val_loss: 10.9554 - val_mean_squared_error: 10.9554\n",
+      "339/339 [==============================] - 0s 153us/sample - loss: 8.2182 - mean_squared_error: 8.2182\n",
       "Epoch 43/50\n",
-      "339/339 [==============================] - 0s 82us/sample - loss: 8.6436 - mean_squared_error: 8.6436 - val_loss: 10.4429 - val_mean_squared_error: 10.4429\n",
+      "339/339 [==============================] - 0s 173us/sample - loss: 7.9426 - mean_squared_error: 7.9426\n",
       "Epoch 44/50\n",
-      "339/339 [==============================] - 0s 83us/sample - loss: 8.7554 - mean_squared_error: 8.7554 - val_loss: 10.3802 - val_mean_squared_error: 10.3802\n",
+      "339/339 [==============================] - 0s 141us/sample - loss: 8.0151 - mean_squared_error: 8.0151\n",
       "Epoch 45/50\n",
-      "339/339 [==============================] - 0s 81us/sample - loss: 8.2557 - mean_squared_error: 8.2557 - val_loss: 10.3291 - val_mean_squared_error: 10.3291\n",
+      "339/339 [==============================] - 0s 142us/sample - loss: 7.9227 - mean_squared_error: 7.9227\n",
       "Epoch 46/50\n",
-      "339/339 [==============================] - 0s 85us/sample - loss: 8.3303 - mean_squared_error: 8.3303 - val_loss: 10.2898 - val_mean_squared_error: 10.2898\n",
+      "339/339 [==============================] - 0s 142us/sample - loss: 7.8698 - mean_squared_error: 7.8698\n",
       "Epoch 47/50\n",
-      "339/339 [==============================] - 0s 90us/sample - loss: 8.1261 - mean_squared_error: 8.1261 - val_loss: 10.8009 - val_mean_squared_error: 10.8009\n",
+      "339/339 [==============================] - 0s 137us/sample - loss: 7.7894 - mean_squared_error: 7.7894\n",
       "Epoch 48/50\n",
-      "339/339 [==============================] - 0s 85us/sample - loss: 7.9084 - mean_squared_error: 7.9084 - val_loss: 10.3298 - val_mean_squared_error: 10.3298\n",
+      "339/339 [==============================] - 0s 145us/sample - loss: 7.5303 - mean_squared_error: 7.5303\n",
       "Epoch 49/50\n",
-      "339/339 [==============================] - 0s 84us/sample - loss: 7.6370 - mean_squared_error: 7.6370 - val_loss: 10.9119 - val_mean_squared_error: 10.9119\n",
+      "339/339 [==============================] - 0s 185us/sample - loss: 7.4390 - mean_squared_error: 7.4390\n",
       "Epoch 50/50\n",
-      "339/339 [==============================] - 0s 93us/sample - loss: 7.9129 - mean_squared_error: 7.9129 - val_loss: 10.5253 - val_mean_squared_error: 10.5253\n"
+      "339/339 [==============================] - 0s 210us/sample - loss: 7.3394 - mean_squared_error: 7.3394\n"
      ]
     },
     {
      "data": {
       "text/plain": [
-       "<tensorflow.python.keras.callbacks.History at 0x1a2ce7e3c8>"
+       "<tensorflow.python.keras.callbacks.History at 0x1a312a3d68>"
       ]
      },
-     "execution_count": 10,
+     "execution_count": 8,
      "metadata": {},
      "output_type": "execute_result"
     }
@@ -636,7 +661,7 @@
     "# Compile Model\n",
     "model.compile(optimizer='rmsprop', loss='mse', metrics=['mse'])\n",
     "# Fit Model\n",
-    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=batch_size)\n"
+    "model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)\n"
    ]
   },
   {
@@ -3570,9 +3595,9 @@
    "version": "0.3.2"
   },
   "kernelspec": {
-   "display_name": "U4-S2-NNF (Python 3.7)",
+   "display_name": "Python 3",
    "language": "python",
-   "name": "u4-s2-nnf"
+   "name": "python3"
   },
   "language_info": {
    "codemirror_mode": {
