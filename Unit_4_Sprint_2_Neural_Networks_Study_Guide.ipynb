{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Unit_4_Sprint_2_Neural_Networks_Study_Guide.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVwDfNcdqlbZ",
        "colab_type": "text"
      },
      "source": [
        "This study guide should reinforce and provide practice for all of the concepts you have seen in the past week. There are a mix of written questions and coding exercises, both are equally important to prepare you for the sprint challenge as well as to be able to speak on these topics comfortably in interviews and on the job.\n",
        "\n",
        "If you get stuck or are unsure of something remember the 20 minute rule. If that doesn't help, then research a solution with google and stackoverflow. Only once you have exausted these methods should you turn to your Team Lead - they won't be there on your SC or during an interview. That being said, don't hesitate to ask for help if you truly are stuck.\n",
        "\n",
        "Have fun studying!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHl_qn9TpggG",
        "colab_type": "text"
      },
      "source": [
        "# Neural Networks by Hand"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3LTw7Csr53V",
        "colab_type": "text"
      },
      "source": [
        "## Definitions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssxAniIZqxxU",
        "colab_type": "text"
      },
      "source": [
        "Define the following terms in your own words, do not simply copy and paste a definition found elsewhere but reword it to be understandable and memorable to you. *Double click the markdown to add your definitions.*\n",
        "\n",
        "**Input Layer:** `Your Answer Here`\n",
        "\n",
        "**Hidden Layer:** `Your Answer Here`\n",
        "\n",
        "**Output Layer:** `Your Answer Here`\n",
        "\n",
        "**Neuron:** `Your Answer Here`\n",
        "\n",
        "**Weight:** `Your Answer Here`\n",
        "\n",
        "**Bias:** `Your Answer Here`\n",
        "\n",
        "**Activation Function:** `Your Answer Here`\n",
        "\n",
        "**Node Map:** `Your Answer Here`\n",
        "\n",
        "**Perceptron:** `Your Answer Here`\n",
        "\n",
        "**Epoch:** `Your Answer Here`\n",
        "\n",
        "**Feed Forward Neural Network:** `Your Answer Here`\n",
        "\n",
        "**Back Propagation:** `Your Answer Here`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgO6aE9br9N9",
        "colab_type": "text"
      },
      "source": [
        "## Questions of Understanding\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwG5JUtEzMGh",
        "colab_type": "text"
      },
      "source": [
        "1. Name 2 activation functions and when they might be used\n",
        " 1. `Your Answer Here`\n",
        " 2. `Your Answer Here`\n",
        "\n",
        "2. What types of machine learning problems are neural networks best suited for?\n",
        "```\n",
        "Your Answer Here\n",
        "```\n",
        "\n",
        "3. In a linear regression problem, we can attempt to account for nonlinear features with polynomial features. What problem do we encounter as our feature size increases? How does a neural network avoid/address this issue?\n",
        "```\n",
        "Your Answer Here\n",
        "```\n",
        "\n",
        "4. What are some of the tradeoffs of using a neural network versus a traditional machine learning algorithm like linear regression or a decision tree?\n",
        "```\n",
        "Your Answer Here\n",
        "```\n",
        "\n",
        "5. What determines the size of the input layer?\n",
        "```\n",
        "Your Answer Here\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QiNp8dSK8rcx",
        "colab_type": "text"
      },
      "source": [
        "## Perceptrons"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDGlUI2A85tS",
        "colab_type": "text"
      },
      "source": [
        "Use the starter code below to build a perceptron, with just numpy, to predict whether a passenger survived or not. You may reduce the number of features for X to fit code you have already worked on throughout the week, but it is recommended that you modify the code instead."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkUhPR-HpieB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "12e62f92-90f5-4ead-d02f-40e4200f662f"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/bundickm/Study-Guides/master/data/titanic.csv')\n",
        "print('Shape:', df.shape, '\\n')\n",
        "df.head()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape: (887, 7) \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>Siblings/Spouses Aboard</th>\n",
              "      <th>Parents/Children Aboard</th>\n",
              "      <th>Fare</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7.2500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>71.2833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.9250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>53.1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.0500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Survived  Pclass  ...  Parents/Children Aboard     Fare\n",
              "0         0       3  ...                        0   7.2500\n",
              "1         1       1  ...                        0  71.2833\n",
              "2         1       3  ...                        0   7.9250\n",
              "3         1       1  ...                        0  53.1000\n",
              "4         0       3  ...                        0   8.0500\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95aCFxje_XD5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = np.array(df.drop(columns='Survived'))\n",
        "y = df['Survived']"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "umUm9VbKHzky",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "1b5dfd9e-3396-4171-957e-c5678bcf8741"
      },
      "source": [
        "df['Survived'].value_counts(normalize=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.614431\n",
              "1    0.385569\n",
              "Name: Survived, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "waTLtf7TQC3N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "251dd7e6-ba5f-4ea1-a35a-ea225af99885"
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Survived                   0\n",
              "Pclass                     0\n",
              "Sex                        0\n",
              "Age                        0\n",
              "Siblings/Spouses Aboard    0\n",
              "Parents/Children Aboard    0\n",
              "Fare                       0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPHva8JJABGZ",
        "colab_type": "text"
      },
      "source": [
        "Create a multilayer perceptron with back propagation, with just numpy, and apply it to the same data set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0CEOwQzH95a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaEElIwfK_BK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Multilayer Perceptron\n",
        "model = Sequential()\n",
        "model.add(Dense(10, input_dim=6, activation = \"relu\"))\n",
        "model.add(Dense(1, activation = \"sigmoid\")) # binary output"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8E-L-ZpK_Y8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer = \"adam\", loss = \"binary_crossentropy\",  metrics = [\"accuracy\"] )"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ksot48KpK_hs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "04602d8f-a20a-4a49-972d-d54755257c0f"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 10)                70        \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                110       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 191\n",
            "Trainable params: 191\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxqrH17HNpMh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YiFtGbs7N518",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y, \n",
        "    test_size = 0.20, \n",
        "    random_state = 42\n",
        ")"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IlQywLMORHq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "af855832-278b-4261-d1e7-933c472325a7"
      },
      "source": [
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((709, 6), (178, 6), (709,), (178,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6fIMsJqK_o8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "16cb5b44-d348-48fa-ea8d-32f3d23c7506"
      },
      "source": [
        "model.fit(X_train, y_train, \n",
        "          validation_data=(X_test, y_test),\n",
        "          epochs = 99, \n",
        "          batch_size = 10)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/99\n",
            "71/71 [==============================] - 0s 4ms/step - loss: 1.1946 - accuracy: 0.6544 - val_loss: 0.7453 - val_accuracy: 0.6461\n",
            "Epoch 2/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.6584 - accuracy: 0.6911 - val_loss: 0.6346 - val_accuracy: 0.6798\n",
            "Epoch 3/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.6059 - accuracy: 0.6953 - val_loss: 0.6289 - val_accuracy: 0.6742\n",
            "Epoch 4/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.5971 - accuracy: 0.7109 - val_loss: 0.6186 - val_accuracy: 0.6798\n",
            "Epoch 5/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.5938 - accuracy: 0.7094 - val_loss: 0.6031 - val_accuracy: 0.6798\n",
            "Epoch 6/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.5805 - accuracy: 0.7137 - val_loss: 0.5991 - val_accuracy: 0.6798\n",
            "Epoch 7/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.5780 - accuracy: 0.7250 - val_loss: 0.5992 - val_accuracy: 0.6798\n",
            "Epoch 8/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.5821 - accuracy: 0.7179 - val_loss: 0.5907 - val_accuracy: 0.6685\n",
            "Epoch 9/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.5659 - accuracy: 0.7221 - val_loss: 0.5883 - val_accuracy: 0.6742\n",
            "Epoch 10/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.5848 - accuracy: 0.7109 - val_loss: 0.5913 - val_accuracy: 0.6798\n",
            "Epoch 11/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.5733 - accuracy: 0.7179 - val_loss: 0.5878 - val_accuracy: 0.6854\n",
            "Epoch 12/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.5629 - accuracy: 0.7193 - val_loss: 0.5897 - val_accuracy: 0.6854\n",
            "Epoch 13/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.5601 - accuracy: 0.7207 - val_loss: 0.5714 - val_accuracy: 0.6742\n",
            "Epoch 14/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.5576 - accuracy: 0.7109 - val_loss: 0.5717 - val_accuracy: 0.6910\n",
            "Epoch 15/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.5539 - accuracy: 0.7123 - val_loss: 0.5713 - val_accuracy: 0.6910\n",
            "Epoch 16/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.5596 - accuracy: 0.7179 - val_loss: 0.5734 - val_accuracy: 0.6910\n",
            "Epoch 17/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.5392 - accuracy: 0.7193 - val_loss: 0.5598 - val_accuracy: 0.6742\n",
            "Epoch 18/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.5373 - accuracy: 0.7221 - val_loss: 0.5567 - val_accuracy: 0.6798\n",
            "Epoch 19/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.5310 - accuracy: 0.7278 - val_loss: 0.5561 - val_accuracy: 0.6966\n",
            "Epoch 20/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.5520 - accuracy: 0.7193 - val_loss: 0.5499 - val_accuracy: 0.6798\n",
            "Epoch 21/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.5426 - accuracy: 0.7264 - val_loss: 0.5475 - val_accuracy: 0.6854\n",
            "Epoch 22/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.5307 - accuracy: 0.7264 - val_loss: 0.5498 - val_accuracy: 0.7191\n",
            "Epoch 23/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.5383 - accuracy: 0.7221 - val_loss: 0.5443 - val_accuracy: 0.7022\n",
            "Epoch 24/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.5109 - accuracy: 0.7405 - val_loss: 0.5339 - val_accuracy: 0.6966\n",
            "Epoch 25/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.5111 - accuracy: 0.7433 - val_loss: 0.5800 - val_accuracy: 0.6742\n",
            "Epoch 26/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.5287 - accuracy: 0.7278 - val_loss: 0.5329 - val_accuracy: 0.6966\n",
            "Epoch 27/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7405 - val_loss: 0.5342 - val_accuracy: 0.6854\n",
            "Epoch 28/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4963 - accuracy: 0.7532 - val_loss: 0.5283 - val_accuracy: 0.6854\n",
            "Epoch 29/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4930 - accuracy: 0.7377 - val_loss: 0.5179 - val_accuracy: 0.7022\n",
            "Epoch 30/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4907 - accuracy: 0.7489 - val_loss: 0.5143 - val_accuracy: 0.6910\n",
            "Epoch 31/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.5017 - accuracy: 0.7546 - val_loss: 0.5259 - val_accuracy: 0.7247\n",
            "Epoch 32/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4783 - accuracy: 0.7687 - val_loss: 0.5121 - val_accuracy: 0.6966\n",
            "Epoch 33/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4831 - accuracy: 0.7715 - val_loss: 0.5242 - val_accuracy: 0.6910\n",
            "Epoch 34/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4837 - accuracy: 0.7588 - val_loss: 0.5114 - val_accuracy: 0.7079\n",
            "Epoch 35/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4688 - accuracy: 0.7757 - val_loss: 0.5064 - val_accuracy: 0.6966\n",
            "Epoch 36/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.7828 - val_loss: 0.5099 - val_accuracy: 0.7247\n",
            "Epoch 37/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.7870 - val_loss: 0.5031 - val_accuracy: 0.7135\n",
            "Epoch 38/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7828 - val_loss: 0.4981 - val_accuracy: 0.7247\n",
            "Epoch 39/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.7913 - val_loss: 0.5062 - val_accuracy: 0.7472\n",
            "Epoch 40/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.7800 - val_loss: 0.5016 - val_accuracy: 0.7303\n",
            "Epoch 41/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4492 - accuracy: 0.8096 - val_loss: 0.4952 - val_accuracy: 0.7528\n",
            "Epoch 42/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4455 - accuracy: 0.8138 - val_loss: 0.4921 - val_accuracy: 0.7247\n",
            "Epoch 43/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4480 - accuracy: 0.8011 - val_loss: 0.4880 - val_accuracy: 0.7528\n",
            "Epoch 44/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4536 - accuracy: 0.7913 - val_loss: 0.4864 - val_accuracy: 0.7247\n",
            "Epoch 45/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4741 - accuracy: 0.7856 - val_loss: 0.4950 - val_accuracy: 0.7416\n",
            "Epoch 46/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4414 - accuracy: 0.8152 - val_loss: 0.4847 - val_accuracy: 0.7360\n",
            "Epoch 47/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4508 - accuracy: 0.8124 - val_loss: 0.5046 - val_accuracy: 0.7640\n",
            "Epoch 48/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4537 - accuracy: 0.8054 - val_loss: 0.4893 - val_accuracy: 0.7416\n",
            "Epoch 49/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4659 - accuracy: 0.7927 - val_loss: 0.4957 - val_accuracy: 0.7360\n",
            "Epoch 50/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.8096 - val_loss: 0.4821 - val_accuracy: 0.7303\n",
            "Epoch 51/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4402 - accuracy: 0.8011 - val_loss: 0.5028 - val_accuracy: 0.7584\n",
            "Epoch 52/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4366 - accuracy: 0.8124 - val_loss: 0.4863 - val_accuracy: 0.7472\n",
            "Epoch 53/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.8082 - val_loss: 0.4997 - val_accuracy: 0.7472\n",
            "Epoch 54/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4417 - accuracy: 0.8223 - val_loss: 0.4811 - val_accuracy: 0.7360\n",
            "Epoch 55/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.8181 - val_loss: 0.4823 - val_accuracy: 0.7472\n",
            "Epoch 56/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.8110 - val_loss: 0.4824 - val_accuracy: 0.7528\n",
            "Epoch 57/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4451 - accuracy: 0.8096 - val_loss: 0.4891 - val_accuracy: 0.7640\n",
            "Epoch 58/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.8039 - val_loss: 0.4947 - val_accuracy: 0.7584\n",
            "Epoch 59/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4454 - accuracy: 0.8054 - val_loss: 0.4923 - val_accuracy: 0.7697\n",
            "Epoch 60/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.7983 - val_loss: 0.4785 - val_accuracy: 0.7697\n",
            "Epoch 61/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4466 - accuracy: 0.8054 - val_loss: 0.4804 - val_accuracy: 0.7584\n",
            "Epoch 62/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4313 - accuracy: 0.7941 - val_loss: 0.4863 - val_accuracy: 0.7416\n",
            "Epoch 63/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.8110 - val_loss: 0.4820 - val_accuracy: 0.7416\n",
            "Epoch 64/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4255 - accuracy: 0.8068 - val_loss: 0.4742 - val_accuracy: 0.7416\n",
            "Epoch 65/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4351 - accuracy: 0.8054 - val_loss: 0.4826 - val_accuracy: 0.7528\n",
            "Epoch 66/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.8068 - val_loss: 0.4787 - val_accuracy: 0.7472\n",
            "Epoch 67/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4303 - accuracy: 0.8039 - val_loss: 0.4763 - val_accuracy: 0.7528\n",
            "Epoch 68/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4264 - accuracy: 0.8082 - val_loss: 0.4818 - val_accuracy: 0.7472\n",
            "Epoch 69/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.8039 - val_loss: 0.4720 - val_accuracy: 0.7472\n",
            "Epoch 70/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.8124 - val_loss: 0.4836 - val_accuracy: 0.7640\n",
            "Epoch 71/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4251 - accuracy: 0.8011 - val_loss: 0.4854 - val_accuracy: 0.7584\n",
            "Epoch 72/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4187 - accuracy: 0.8124 - val_loss: 0.5022 - val_accuracy: 0.7528\n",
            "Epoch 73/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.8054 - val_loss: 0.4797 - val_accuracy: 0.7697\n",
            "Epoch 74/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.8110 - val_loss: 0.4935 - val_accuracy: 0.7472\n",
            "Epoch 75/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.8068 - val_loss: 0.4762 - val_accuracy: 0.7472\n",
            "Epoch 76/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4230 - accuracy: 0.7997 - val_loss: 0.4926 - val_accuracy: 0.7528\n",
            "Epoch 77/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4347 - accuracy: 0.8068 - val_loss: 0.5113 - val_accuracy: 0.7472\n",
            "Epoch 78/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.8181 - val_loss: 0.4858 - val_accuracy: 0.7640\n",
            "Epoch 79/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4324 - accuracy: 0.8068 - val_loss: 0.4728 - val_accuracy: 0.7584\n",
            "Epoch 80/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.8039 - val_loss: 0.4789 - val_accuracy: 0.7472\n",
            "Epoch 81/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4176 - accuracy: 0.8181 - val_loss: 0.4890 - val_accuracy: 0.7584\n",
            "Epoch 82/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4217 - accuracy: 0.8124 - val_loss: 0.4775 - val_accuracy: 0.7584\n",
            "Epoch 83/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.8124 - val_loss: 0.4778 - val_accuracy: 0.7472\n",
            "Epoch 84/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4207 - accuracy: 0.8124 - val_loss: 0.4722 - val_accuracy: 0.7472\n",
            "Epoch 85/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4219 - accuracy: 0.8152 - val_loss: 0.4836 - val_accuracy: 0.7528\n",
            "Epoch 86/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.8054 - val_loss: 0.4880 - val_accuracy: 0.7640\n",
            "Epoch 87/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4129 - accuracy: 0.8068 - val_loss: 0.4943 - val_accuracy: 0.7640\n",
            "Epoch 88/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4250 - accuracy: 0.8124 - val_loss: 0.4771 - val_accuracy: 0.7697\n",
            "Epoch 89/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4165 - accuracy: 0.8166 - val_loss: 0.4836 - val_accuracy: 0.7640\n",
            "Epoch 90/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4176 - accuracy: 0.8152 - val_loss: 0.4729 - val_accuracy: 0.7584\n",
            "Epoch 91/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4511 - accuracy: 0.8054 - val_loss: 0.4846 - val_accuracy: 0.7584\n",
            "Epoch 92/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4236 - accuracy: 0.8068 - val_loss: 0.4768 - val_accuracy: 0.7640\n",
            "Epoch 93/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4121 - accuracy: 0.8039 - val_loss: 0.4858 - val_accuracy: 0.7584\n",
            "Epoch 94/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4227 - accuracy: 0.8054 - val_loss: 0.4684 - val_accuracy: 0.7584\n",
            "Epoch 95/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4147 - accuracy: 0.8138 - val_loss: 0.4734 - val_accuracy: 0.7640\n",
            "Epoch 96/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4209 - accuracy: 0.8068 - val_loss: 0.4769 - val_accuracy: 0.7753\n",
            "Epoch 97/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4130 - accuracy: 0.8124 - val_loss: 0.4819 - val_accuracy: 0.7809\n",
            "Epoch 98/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4146 - accuracy: 0.8166 - val_loss: 0.4736 - val_accuracy: 0.7528\n",
            "Epoch 99/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4151 - accuracy: 0.8068 - val_loss: 0.4740 - val_accuracy: 0.7753\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff987542940>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyxTtBQlRLen",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Single Layer Perceptron with Keras\n",
        "\n",
        "model_single = Sequential()\n",
        "model_single.add(Dense(1, input_dim=6, activation='sigmoid'))"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kI9Tt34pR7UP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer = \"adam\", loss = \"binary_crossentropy\",  metrics = [\"accuracy\"] )"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyrG2kxmSRCX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "999fb2bb-a14d-4bb7-c22d-fbebe16ce7c6"
      },
      "source": [
        "model_single.summary()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_3 (Dense)              (None, 1)                 7         \n",
            "=================================================================\n",
            "Total params: 7\n",
            "Trainable params: 7\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOOQDph9SEX6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c1d20165-24c9-4375-d5db-bf745c619f46"
      },
      "source": [
        "model.fit(X_train, y_train, \n",
        "          validation_data=(X_test, y_test),\n",
        "          epochs = 99, \n",
        "          batch_size = 10)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/99\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 0.4268 - accuracy: 0.8068 - val_loss: 0.4727 - val_accuracy: 0.7584\n",
            "Epoch 2/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4167 - accuracy: 0.8209 - val_loss: 0.4738 - val_accuracy: 0.7584\n",
            "Epoch 3/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.8096 - val_loss: 0.5351 - val_accuracy: 0.7697\n",
            "Epoch 4/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.8068 - val_loss: 0.4748 - val_accuracy: 0.7584\n",
            "Epoch 5/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4140 - accuracy: 0.8110 - val_loss: 0.4728 - val_accuracy: 0.7584\n",
            "Epoch 6/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4091 - accuracy: 0.8209 - val_loss: 0.4701 - val_accuracy: 0.7584\n",
            "Epoch 7/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.8096 - val_loss: 0.4704 - val_accuracy: 0.7584\n",
            "Epoch 8/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4176 - accuracy: 0.8152 - val_loss: 0.4788 - val_accuracy: 0.7753\n",
            "Epoch 9/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4137 - accuracy: 0.8110 - val_loss: 0.4709 - val_accuracy: 0.7640\n",
            "Epoch 10/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4086 - accuracy: 0.8209 - val_loss: 0.4884 - val_accuracy: 0.7697\n",
            "Epoch 11/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4150 - accuracy: 0.8025 - val_loss: 0.4805 - val_accuracy: 0.7865\n",
            "Epoch 12/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4111 - accuracy: 0.8138 - val_loss: 0.4825 - val_accuracy: 0.7809\n",
            "Epoch 13/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4205 - accuracy: 0.8110 - val_loss: 0.4769 - val_accuracy: 0.7753\n",
            "Epoch 14/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4183 - accuracy: 0.8237 - val_loss: 0.4797 - val_accuracy: 0.7809\n",
            "Epoch 15/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4133 - accuracy: 0.8110 - val_loss: 0.4753 - val_accuracy: 0.7697\n",
            "Epoch 16/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4128 - accuracy: 0.8223 - val_loss: 0.4704 - val_accuracy: 0.7753\n",
            "Epoch 17/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4078 - accuracy: 0.8138 - val_loss: 0.4805 - val_accuracy: 0.7809\n",
            "Epoch 18/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4199 - accuracy: 0.8152 - val_loss: 0.4840 - val_accuracy: 0.7640\n",
            "Epoch 19/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4097 - accuracy: 0.8166 - val_loss: 0.4797 - val_accuracy: 0.7809\n",
            "Epoch 20/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4085 - accuracy: 0.8195 - val_loss: 0.4797 - val_accuracy: 0.7921\n",
            "Epoch 21/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4075 - accuracy: 0.8152 - val_loss: 0.4678 - val_accuracy: 0.7865\n",
            "Epoch 22/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4201 - accuracy: 0.8181 - val_loss: 0.4807 - val_accuracy: 0.7640\n",
            "Epoch 23/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4092 - accuracy: 0.8195 - val_loss: 0.4662 - val_accuracy: 0.7865\n",
            "Epoch 24/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4073 - accuracy: 0.8166 - val_loss: 0.4914 - val_accuracy: 0.7640\n",
            "Epoch 25/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4183 - accuracy: 0.8096 - val_loss: 0.4774 - val_accuracy: 0.7697\n",
            "Epoch 26/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4156 - accuracy: 0.8195 - val_loss: 0.4718 - val_accuracy: 0.7921\n",
            "Epoch 27/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4169 - accuracy: 0.8279 - val_loss: 0.4780 - val_accuracy: 0.7921\n",
            "Epoch 28/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4126 - accuracy: 0.8223 - val_loss: 0.4748 - val_accuracy: 0.7753\n",
            "Epoch 29/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4107 - accuracy: 0.8223 - val_loss: 0.4694 - val_accuracy: 0.7809\n",
            "Epoch 30/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4186 - accuracy: 0.8181 - val_loss: 0.4794 - val_accuracy: 0.7809\n",
            "Epoch 31/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4076 - accuracy: 0.8138 - val_loss: 0.4810 - val_accuracy: 0.7640\n",
            "Epoch 32/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4102 - accuracy: 0.8138 - val_loss: 0.4878 - val_accuracy: 0.7753\n",
            "Epoch 33/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4083 - accuracy: 0.8195 - val_loss: 0.4711 - val_accuracy: 0.7640\n",
            "Epoch 34/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4177 - accuracy: 0.8124 - val_loss: 0.4777 - val_accuracy: 0.7697\n",
            "Epoch 35/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4109 - accuracy: 0.8166 - val_loss: 0.4721 - val_accuracy: 0.7809\n",
            "Epoch 36/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4195 - accuracy: 0.8237 - val_loss: 0.4681 - val_accuracy: 0.7978\n",
            "Epoch 37/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4047 - accuracy: 0.8265 - val_loss: 0.4688 - val_accuracy: 0.7865\n",
            "Epoch 38/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4082 - accuracy: 0.8166 - val_loss: 0.4694 - val_accuracy: 0.7809\n",
            "Epoch 39/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4045 - accuracy: 0.8152 - val_loss: 0.4758 - val_accuracy: 0.7921\n",
            "Epoch 40/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4076 - accuracy: 0.8209 - val_loss: 0.4817 - val_accuracy: 0.7809\n",
            "Epoch 41/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4053 - accuracy: 0.8237 - val_loss: 0.4693 - val_accuracy: 0.7865\n",
            "Epoch 42/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4110 - accuracy: 0.8195 - val_loss: 0.4617 - val_accuracy: 0.7809\n",
            "Epoch 43/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4104 - accuracy: 0.8195 - val_loss: 0.4697 - val_accuracy: 0.7753\n",
            "Epoch 44/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4043 - accuracy: 0.8223 - val_loss: 0.4680 - val_accuracy: 0.7809\n",
            "Epoch 45/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4154 - accuracy: 0.8152 - val_loss: 0.4685 - val_accuracy: 0.7865\n",
            "Epoch 46/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4049 - accuracy: 0.8279 - val_loss: 0.4863 - val_accuracy: 0.7640\n",
            "Epoch 47/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4172 - accuracy: 0.8152 - val_loss: 0.4709 - val_accuracy: 0.7978\n",
            "Epoch 48/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4002 - accuracy: 0.8251 - val_loss: 0.4653 - val_accuracy: 0.7753\n",
            "Epoch 49/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4115 - accuracy: 0.8138 - val_loss: 0.4655 - val_accuracy: 0.7809\n",
            "Epoch 50/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4060 - accuracy: 0.8350 - val_loss: 0.4633 - val_accuracy: 0.7584\n",
            "Epoch 51/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4142 - accuracy: 0.8181 - val_loss: 0.5265 - val_accuracy: 0.7809\n",
            "Epoch 52/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4064 - accuracy: 0.8293 - val_loss: 0.4626 - val_accuracy: 0.7697\n",
            "Epoch 53/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.8251 - val_loss: 0.4770 - val_accuracy: 0.7584\n",
            "Epoch 54/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4088 - accuracy: 0.8195 - val_loss: 0.4669 - val_accuracy: 0.7865\n",
            "Epoch 55/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4105 - accuracy: 0.8138 - val_loss: 0.4592 - val_accuracy: 0.7640\n",
            "Epoch 56/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4082 - accuracy: 0.8195 - val_loss: 0.4646 - val_accuracy: 0.7809\n",
            "Epoch 57/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4065 - accuracy: 0.8251 - val_loss: 0.4676 - val_accuracy: 0.7865\n",
            "Epoch 58/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4026 - accuracy: 0.8237 - val_loss: 0.4690 - val_accuracy: 0.7697\n",
            "Epoch 59/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4088 - accuracy: 0.8181 - val_loss: 0.4676 - val_accuracy: 0.7753\n",
            "Epoch 60/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4072 - accuracy: 0.8138 - val_loss: 0.4785 - val_accuracy: 0.7697\n",
            "Epoch 61/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4107 - accuracy: 0.8209 - val_loss: 0.4663 - val_accuracy: 0.7753\n",
            "Epoch 62/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4033 - accuracy: 0.8124 - val_loss: 0.4740 - val_accuracy: 0.7865\n",
            "Epoch 63/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4053 - accuracy: 0.8237 - val_loss: 0.4665 - val_accuracy: 0.7640\n",
            "Epoch 64/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4014 - accuracy: 0.8237 - val_loss: 0.4649 - val_accuracy: 0.7865\n",
            "Epoch 65/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.3990 - accuracy: 0.8293 - val_loss: 0.4679 - val_accuracy: 0.7921\n",
            "Epoch 66/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4031 - accuracy: 0.8223 - val_loss: 0.4635 - val_accuracy: 0.7865\n",
            "Epoch 67/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4089 - accuracy: 0.8293 - val_loss: 0.4637 - val_accuracy: 0.7753\n",
            "Epoch 68/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4060 - accuracy: 0.8223 - val_loss: 0.4818 - val_accuracy: 0.7697\n",
            "Epoch 69/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4084 - accuracy: 0.8195 - val_loss: 0.4747 - val_accuracy: 0.7753\n",
            "Epoch 70/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4017 - accuracy: 0.8237 - val_loss: 0.4620 - val_accuracy: 0.7809\n",
            "Epoch 71/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.3996 - accuracy: 0.8195 - val_loss: 0.4612 - val_accuracy: 0.7753\n",
            "Epoch 72/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.3985 - accuracy: 0.8322 - val_loss: 0.4733 - val_accuracy: 0.7640\n",
            "Epoch 73/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4031 - accuracy: 0.8195 - val_loss: 0.4585 - val_accuracy: 0.7697\n",
            "Epoch 74/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.3985 - accuracy: 0.8279 - val_loss: 0.4747 - val_accuracy: 0.7865\n",
            "Epoch 75/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.3951 - accuracy: 0.8293 - val_loss: 0.4766 - val_accuracy: 0.7865\n",
            "Epoch 76/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4062 - accuracy: 0.8307 - val_loss: 0.4545 - val_accuracy: 0.7753\n",
            "Epoch 77/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.3959 - accuracy: 0.8307 - val_loss: 0.4575 - val_accuracy: 0.7865\n",
            "Epoch 78/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4031 - accuracy: 0.8265 - val_loss: 0.4696 - val_accuracy: 0.7640\n",
            "Epoch 79/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.3957 - accuracy: 0.8279 - val_loss: 0.4645 - val_accuracy: 0.7865\n",
            "Epoch 80/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4010 - accuracy: 0.8209 - val_loss: 0.4618 - val_accuracy: 0.7697\n",
            "Epoch 81/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4057 - accuracy: 0.8209 - val_loss: 0.4777 - val_accuracy: 0.7584\n",
            "Epoch 82/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4050 - accuracy: 0.8265 - val_loss: 0.4676 - val_accuracy: 0.7809\n",
            "Epoch 83/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.3931 - accuracy: 0.8350 - val_loss: 0.4651 - val_accuracy: 0.7921\n",
            "Epoch 84/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.3962 - accuracy: 0.8307 - val_loss: 0.4722 - val_accuracy: 0.7865\n",
            "Epoch 85/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4040 - accuracy: 0.8293 - val_loss: 0.4992 - val_accuracy: 0.7753\n",
            "Epoch 86/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4068 - accuracy: 0.8293 - val_loss: 0.4678 - val_accuracy: 0.7697\n",
            "Epoch 87/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.3982 - accuracy: 0.8293 - val_loss: 0.4664 - val_accuracy: 0.7921\n",
            "Epoch 88/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.3908 - accuracy: 0.8293 - val_loss: 0.4894 - val_accuracy: 0.7584\n",
            "Epoch 89/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4095 - accuracy: 0.8195 - val_loss: 0.4930 - val_accuracy: 0.7753\n",
            "Epoch 90/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.3952 - accuracy: 0.8166 - val_loss: 0.4636 - val_accuracy: 0.7865\n",
            "Epoch 91/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4080 - accuracy: 0.8195 - val_loss: 0.4656 - val_accuracy: 0.7809\n",
            "Epoch 92/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4015 - accuracy: 0.8181 - val_loss: 0.4658 - val_accuracy: 0.7809\n",
            "Epoch 93/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4010 - accuracy: 0.8322 - val_loss: 0.4671 - val_accuracy: 0.7921\n",
            "Epoch 94/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.3980 - accuracy: 0.8265 - val_loss: 0.4733 - val_accuracy: 0.7753\n",
            "Epoch 95/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4023 - accuracy: 0.8265 - val_loss: 0.4602 - val_accuracy: 0.7921\n",
            "Epoch 96/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.3945 - accuracy: 0.8279 - val_loss: 0.4690 - val_accuracy: 0.7753\n",
            "Epoch 97/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4061 - accuracy: 0.8336 - val_loss: 0.4659 - val_accuracy: 0.7584\n",
            "Epoch 98/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.4163 - accuracy: 0.8265 - val_loss: 0.4618 - val_accuracy: 0.7753\n",
            "Epoch 99/99\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 0.3989 - accuracy: 0.8322 - val_loss: 0.4560 - val_accuracy: 0.7753\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff982dbf198>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfZ-6Rh8BGgb",
        "colab_type": "text"
      },
      "source": [
        "*In a short paragraph, answer the following:*\n",
        "\n",
        "Why does the multilayer perceptron perform better than the simple perceptron? What limits the simple perceptron? What aspects of the multilayer perceptron allow it to overcome those limitations?\n",
        "\n",
        "```\n",
        "Your Answer Here\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhki00NLpxtf",
        "colab_type": "text"
      },
      "source": [
        "# Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7njBYhdeLZuk"
      },
      "source": [
        "## Definitions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BwrDo98ALZu1"
      },
      "source": [
        "Define the following terms in your own words, do not simply copy and paste a definition found elsewhere but reword it to be understandable and memorable to you. *Double click the markdown to add your definitions.*\n",
        "\n",
        "**Earl Stopping:** `Your Answer Here`\n",
        "\n",
        "**Weight Decay:** `Your Answer Here`\n",
        "\n",
        "**Dropout:** `Your Answer Here`\n",
        "\n",
        "<br/>\n",
        "The following are hyperparameters:\n",
        "\n",
        "**Activation Functions:** `Your Answer Here`\n",
        "\n",
        "**Optimizer** `Your Answer Here`\n",
        "\n",
        "**Number of Layers** `Your Answer Here`\n",
        "\n",
        "**Number of Neurons** `Your Answer Here`\n",
        "\n",
        "**Batch Size** `Your Answer Here`\n",
        "\n",
        "**Dropout Regularization** `Your Answer Here`\n",
        "\n",
        "**Learning Rate** `Your Answer Here`\n",
        "\n",
        "**Number of Epochs** `Your Answer Here`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QZ_azU3fNlu5"
      },
      "source": [
        "## Questions of Understanding\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KFhdxE3ONlvN"
      },
      "source": [
        "1. Why is it recommended to normalize your input data?\n",
        "```\n",
        "Your Answer Here\n",
        "```\n",
        "\n",
        "2. How do you go about deciding on your neural network's architecture?\n",
        "```\n",
        "Your Answer Here\n",
        "```\n",
        "\n",
        "3. Why is regularization important with neural networks?\n",
        "```\n",
        "Your Answer Here\n",
        "```\n",
        "\n",
        "4. What does `validation.data` do?\n",
        "```\n",
        "Your Answer Here\n",
        "```\n",
        "\n",
        "5. Why is hyperparameter tuning so important with neural networks?\n",
        "```\n",
        "Your Answer Here\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2q0E4XJPmnJ",
        "colab_type": "text"
      },
      "source": [
        "## Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMLs3asmPpkb",
        "colab_type": "text"
      },
      "source": [
        "Using the same dataset as above, use Keras to build a model and find its accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5NVbY1AVNDZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import RandomizedSearchCV"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J93kXczUp6z2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(lr):\n",
        "  adam = Adam(learning_rate=lr)\n",
        "  model = Sequential()\n",
        "  model.add(Dense(32, input_dim = 6, activation = \"relu\"))\n",
        "  model.add(Dense(1, activation =\"sigmoid\"))\n",
        "\n",
        "  #Compile model\n",
        "  model.compile(optimizer=\"adam\", loss = \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "  return model"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3IZHRZrVnA2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hyper_model = KerasClassifier(build_fn=create_model, verbose=0)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7lhqCTsQdTF",
        "colab_type": "text"
      },
      "source": [
        "Build upon the model you created in the cell above by adding hyperparameter tuning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxm_p5MzV2SA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "param_grid = {\n",
        "    'lr': [.001, .01, .1],\n",
        "    'batch_size' : [10, 20, 40],\n",
        "    'epochs' : [25]\n",
        "}"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOvsvP-GV2N6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rand = RandomizedSearchCV(estimator=hyper_model, param_distributions=param_grid, n_jobs=-1) \n",
        "#param_distributions for RandomSearch"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWokh9jZV2LY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "7f7d5637-9461-4b95-8585-85e5d8919cd9"
      },
      "source": [
        "rand_result = rand.fit(X_train, y_train)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:281: UserWarning: The total space of parameters 9 is smaller than n_iter=10. Running 9 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlXgMG6OZTEE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "139d9826-5651-40d9-e427-78e06ff781ef"
      },
      "source": [
        "# Report Results\n",
        "print(f\"Best: {rand_result.best_score_} using {rand_result.best_params_}\")\n",
        "search = rand_result.best_params_\n",
        "means = rand_result.cv_results_['mean_test_score']\n",
        "stds = rand_result.cv_results_['std_test_score']\n",
        "params = rand_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\") "
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best: 0.7983018755912781 using {'lr': 0.001, 'epochs': 25, 'batch_size': 10}\n",
            "Means: 0.7983018755912781, Stdev: 0.04334258986925524 with: {'lr': 0.001, 'epochs': 25, 'batch_size': 10}\n",
            "Means: 0.7729097962379455, Stdev: 0.03898360840933016 with: {'lr': 0.01, 'epochs': 25, 'batch_size': 10}\n",
            "Means: 0.7926480889320373, Stdev: 0.03052511033474625 with: {'lr': 0.1, 'epochs': 25, 'batch_size': 10}\n",
            "Means: 0.7503645896911622, Stdev: 0.037340060711998975 with: {'lr': 0.001, 'epochs': 25, 'batch_size': 20}\n",
            "Means: 0.7559484481811524, Stdev: 0.030157838676970496 with: {'lr': 0.01, 'epochs': 25, 'batch_size': 20}\n",
            "Means: 0.7757067203521728, Stdev: 0.04458786182081137 with: {'lr': 0.1, 'epochs': 25, 'batch_size': 20}\n",
            "Means: 0.7291579246520996, Stdev: 0.023444612913861986 with: {'lr': 0.001, 'epochs': 25, 'batch_size': 40}\n",
            "Means: 0.7220956921577454, Stdev: 0.031201034065029644 with: {'lr': 0.01, 'epochs': 25, 'batch_size': 40}\n",
            "Means: 0.7164818644523621, Stdev: 0.017233620244993975 with: {'lr': 0.1, 'epochs': 25, 'batch_size': 40}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0e8R0RfhZLTZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zfo64uRpa_p3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "3f6e1aca-0560-4407-fef3-f1a641db7e6b"
      },
      "source": [
        "final_results = rand_result.best_estimator_.predict(X_test)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/wrappers/scikit_learn.py:241: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whVu711pQoN3",
        "colab_type": "text"
      },
      "source": [
        "Find the accuracy of the tuned model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDRUFiOHbGnt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c0958dbb-9abc-4674-c040-8e401bc606b1"
      },
      "source": [
        "accuracy_score(final_results, y_test)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7359550561797753"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GQaJEGvQw4W",
        "colab_type": "text"
      },
      "source": [
        "In a short paragraph, explain how the hyperparameters impacted the accuracy of your model.\n",
        "\n",
        "```\n",
        "You Answer Here\n",
        "```"
      ]
    }
  ]
}