{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NGGrt9EYlCqY"
   },
   "source": [
    "# Backpropagation Practice\n",
    "\n",
    "Implement a 3 input, 4 node hidden-layer, 1 output node Multilayer Perceptron on the following dataset:\n",
    "\n",
    "| x1 | x2 | x3 | y |\n",
    "|----|----|----|---|\n",
    "| 0  | 0  | 1  | 0 |\n",
    "| 0  | 1  | 1  | 1 |\n",
    "| 1  | 0  | 1  | 1 |\n",
    "| 0  | 1  | 0  | 1 |\n",
    "| 1  | 0  | 0  | 1 |\n",
    "| 1  | 1  | 1  | 0 |\n",
    "| 0  | 0  | 0  | 0 |\n",
    "\n",
    "If you look at the data you'll notice that the first two columns behave like an XOR gate while the last column is mostly just noise. Remember that creating an XOR gate was what the perceptron was criticized for not being able to learn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nEREYT-3wI1f"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "\n",
    "X = np.array([[0,0,1],\n",
    "                   [0,1,1],\n",
    "                   [1,0,1],\n",
    "                   [0,1,0],\n",
    "                  [1,0,0],\n",
    "                  [1,1,1],\n",
    "                  [0,0,0]])\n",
    "\n",
    "y = np.array([[0],\n",
    "     [1],\n",
    "     [1],\n",
    "     [1],\n",
    "     [1],\n",
    "     [0],\n",
    "     [0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 1)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's create a Neural_network class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neural_Network(object):\n",
    "    def __init__(self):\n",
    "        self.inputs = 3\n",
    "        self.hiddenNodes = 4\n",
    "        self.outputNodes =1\n",
    "        \n",
    "        # Initialize weights\n",
    "        self.L1_weights = np.random.randn(self.inputs, self.hiddenNodes) #(2x3)\n",
    "#       self.L2_weights = np.random.randn(self.hiddenNodes, self.hiddenNodes)\n",
    "        self.L2_weights = np.random.randn(self.hiddenNodes, self.outputNodes)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### let's print th weights we generated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN = Neural_Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1 weights: \n",
      " [[ 1.62434536 -0.61175641 -0.52817175 -1.07296862]\n",
      " [ 0.86540763 -2.3015387   1.74481176 -0.7612069 ]\n",
      " [ 0.3190391  -0.24937038  1.46210794 -2.06014071]]\n",
      "Layer 2 weights: \n",
      " [[-0.3224172 ]\n",
      " [-0.38405435]\n",
      " [ 1.13376944]\n",
      " [-1.09989127]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Layer 1 weights: \\n\", NN.L1_weights)\n",
    "print(\"Layer 2 weights: \\n\", NN.L2_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing Feedforward Functionality "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neural_Network(object):\n",
    "    def __init__(self):\n",
    "        self.inputs = 3\n",
    "        self.hiddenNodes = 4\n",
    "        self.outputNodes =1\n",
    "        \n",
    "        # Initialize weights\n",
    "        self.L1_weights = np.random.randn(self.inputs, self.hiddenNodes) #(2x3)\n",
    "#       self.L2_weights = np.random.randn(self.hiddenNodes, self.hiddenNodes)\n",
    "        self.L2_weights = np.random.randn(self.hiddenNodes, self.outputNodes)\n",
    "    \n",
    "    def feed_forward(self, X):\n",
    "        # Weighted sum between inputs and hidden layer\n",
    "        self.hidden_sum = np.dot(X, self.L1_weights)\n",
    "        # Activations on weighted sum\n",
    "        self.activated_hidden = self.sigmoid(self.hidden_sum)\n",
    "        # Weighted sum between hidden and output\n",
    "        self.output_sum = np.dot(self.activated_hidden, self.L2_weights)\n",
    "        # final activation of output\n",
    "        self.activated_output = self.sigmoid(self.output_sum)\n",
    "        return self.activated_output\n",
    "    \n",
    "    def sigmoid(self, s):\n",
    "        return 1/(1+np.exp(-s))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### let's generate the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output:  [[0.38959854]\n",
      " [0.39520279]\n",
      " [0.35793904]\n",
      " [0.40041658]\n",
      " [0.36021476]\n",
      " [0.35615307]\n",
      " [0.39819936]]\n"
     ]
    }
   ],
   "source": [
    "NN = Neural_Network()\n",
    "output = NN.feed_forward(x)\n",
    "print(\"output: \", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.38959854]\n",
      " [ 0.60479721]\n",
      " [ 0.64206096]\n",
      " [ 0.59958342]\n",
      " [ 0.63978524]\n",
      " [-0.35615307]\n",
      " [-0.39819936]]\n"
     ]
    }
   ],
   "source": [
    "print (y-output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backpropogation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: \n",
      " [[0 0 1]\n",
      " [0 1 1]\n",
      " [1 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 1 1]\n",
      " [0 0 0]]\n",
      "Initial Weights \n",
      " [[-0.17242821 -0.87785842  0.04221375  0.58281521]\n",
      " [-1.10061918  1.14472371  0.90159072  0.50249434]\n",
      " [ 0.90085595 -0.68372786 -0.12289023 -0.93576943]]\n",
      "Weighted Sum 1 \n",
      " [[ 0.90085595 -0.68372786 -0.12289023 -0.93576943]\n",
      " [-0.19976323  0.46099585  0.7787005  -0.4332751 ]\n",
      " [ 0.72842774 -1.56158628 -0.08067648 -0.35295422]\n",
      " [-1.10061918  1.14472371  0.90159072  0.50249434]\n",
      " [-0.17242821 -0.87785842  0.04221375  0.58281521]\n",
      " [-0.37219144 -0.41686257  0.82091424  0.14954012]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "Activations from first layer: \n",
      " [[0.71112537 0.33542979 0.46931605 0.28175569]\n",
      " [0.45022461 0.61325039 0.68539997 0.39334454]\n",
      " [0.67446016 0.17341914 0.47984181 0.41266621]\n",
      " [0.2496239  0.75854586 0.71127629 0.62304533]\n",
      " [0.45699943 0.29362176 0.51055187 0.64171493]\n",
      " [0.4080116  0.39726775 0.69443037 0.53731552]\n",
      " [0.5        0.5        0.5        0.5       ]]\n",
      "Second layer Weights \n",
      " [[-0.26788808]\n",
      " [ 0.53035547]\n",
      " [-0.69166075]\n",
      " [-0.39675353]]\n",
      "Weighted Sum 2 \n",
      " [[-0.44900004]\n",
      " [-0.4254942 ]\n",
      " [-0.58432057]\n",
      " [-0.40372965]\n",
      " [-0.57443214]\n",
      " [-0.59210038]\n",
      " [-0.41297345]]\n",
      "Predictions \n",
      " [[0.38959854]\n",
      " [0.39520279]\n",
      " [0.35793904]\n",
      " [0.40041658]\n",
      " [0.36021476]\n",
      " [0.35615307]\n",
      " [0.39819936]]\n",
      "Correct Output: \n",
      " [[0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n",
      "Error \n",
      " [[-0.38959854]\n",
      " [ 0.60479721]\n",
      " [ 0.64206096]\n",
      " [ 0.59958342]\n",
      " [ 0.63978524]\n",
      " [-0.35615307]\n",
      " [-0.39819936]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Inputs: \\n\", X)\n",
    "print(\"Initial Weights \\n\", NN.L1_weights)\n",
    "print(\"Weighted Sum 1 \\n\", NN.hidden_sum)\n",
    "print(\"Activations from first layer: \\n\", NN.activated_hidden)\n",
    "print(\"Second layer Weights \\n\", NN.L2_weights)\n",
    "print(\"Weighted Sum 2 \\n\", NN.output_sum)\n",
    "print(\"Predictions \\n\", output)\n",
    "print(\"Correct Output: \\n\", y)\n",
    "print(\"Error \\n\", y-output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neural_Network(object):\n",
    "    def __init__(self):\n",
    "        self.inputs = 3\n",
    "        self.hiddenNodes = 4\n",
    "        self.outputNodes =1\n",
    "        \n",
    "        # Initialize weights\n",
    "        self.L1_weights = np.random.randn(self.inputs, self.hiddenNodes) #(2x3)\n",
    "#       self.L2_weights = np.random.randn(self.hiddenNodes, self.hiddenNodes)\n",
    "        self.L2_weights = np.random.randn(self.hiddenNodes, self.outputNodes)\n",
    "    \n",
    "    def feed_forward(self, X):\n",
    "        # Weighted sum between inputs and hidden layer\n",
    "        self.hidden_sum = np.dot(X, self.L1_weights)\n",
    "        # Activations on weighted sum\n",
    "        self.activated_hidden = self.sigmoid(self.hidden_sum)\n",
    "        # Weighted sum between hidden and output\n",
    "        self.output_sum = np.dot(self.activated_hidden, self.L2_weights)\n",
    "        # final activation of output\n",
    "        self.activated_output = self.sigmoid(self.output_sum)\n",
    "        return self.activated_output\n",
    "    \n",
    "    def sigmoid(self, s):\n",
    "        return 1/(1+np.exp(-s))\n",
    "    \n",
    "    def sigmoidPrime(self, s):\n",
    "        return s * (1 - s)\n",
    "    \n",
    "    def backward(self, X, y, o):\n",
    "        #backward propgate through the network\n",
    "        self.o_error = y - o # error in output\n",
    "        self.o_delta = self.o_error*self.sigmoidPrime(o) # applying derivative of sigmoid ot error\n",
    "        \n",
    "        self.z2_error = self.o_delta.dot(self.L2_weights.T) # z2 error: how much our hidden layer weights contributed to output error\n",
    "        self.z2_delta = self.z2_error*self.sigmoidPrime(self.activated_hidden) # applying derivative of sigmoid to z2 error\n",
    "        \n",
    "        self.L1_weights += X.T.dot(self.z2_delta) # adjusting first set (input --> hidden) weights\n",
    "        self.L2_weights += self.activated_hidden.T.dot(self.o_delta) # adjusting second set (hidden --> output) weights\n",
    "        \n",
    "    def train(self, X, y):\n",
    "        o = self.feed_forward(X)\n",
    "        self.backward(X,y,o)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------EPOCH 1 ----------+\n",
      "Input: \n",
      " [[0 0 1]\n",
      " [0 1 1]\n",
      " [1 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 1 1]\n",
      " [0 0 0]]\n",
      "Actual Output: \n",
      " [[0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n",
      "Predicted Output: \n",
      "[[0.84189004]\n",
      " [0.86529986]\n",
      " [0.8489874 ]\n",
      " [0.77557764]\n",
      " [0.71782001]\n",
      " [0.87277068]\n",
      " [0.7010895 ]]\n",
      "Loss: \n",
      "0.30471055257769036\n",
      "\n",
      "\n",
      "+----------EPOCH 2 ----------+\n",
      "Input: \n",
      " [[0 0 1]\n",
      " [0 1 1]\n",
      " [1 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 1 1]\n",
      " [0 0 0]]\n",
      "Actual Output: \n",
      " [[0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n",
      "Predicted Output: \n",
      "[[0.80484792]\n",
      " [0.82891609]\n",
      " [0.82000855]\n",
      " [0.72666681]\n",
      " [0.68345122]\n",
      " [0.84342196]\n",
      " [0.6527522 ]]\n",
      "Loss: \n",
      "0.2888295696524673\n",
      "\n",
      "\n",
      "+----------EPOCH 3 ----------+\n",
      "Input: \n",
      " [[0 0 1]\n",
      " [0 1 1]\n",
      " [1 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 1 1]\n",
      " [0 0 0]]\n",
      "Actual Output: \n",
      " [[0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n",
      "Predicted Output: \n",
      "[[0.7637135 ]\n",
      " [0.78794133]\n",
      " [0.78843784]\n",
      " [0.67601178]\n",
      " [0.64915792]\n",
      " [0.81094442]\n",
      " [0.60428066]]\n",
      "Loss: \n",
      "0.2748328904705085\n",
      "\n",
      "\n",
      "+----------EPOCH 4 ----------+\n",
      "Input: \n",
      " [[0 0 1]\n",
      " [0 1 1]\n",
      " [1 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 1 1]\n",
      " [0 0 0]]\n",
      "Actual Output: \n",
      " [[0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n",
      "Predicted Output: \n",
      "[[0.72246543]\n",
      " [0.74692621]\n",
      " [0.75715204]\n",
      " [0.62972069]\n",
      " [0.61817462]\n",
      " [0.77871352]\n",
      " [0.56053106]]\n",
      "Loss: \n",
      "0.2640664234596523\n",
      "\n",
      "\n",
      "+----------EPOCH 5 ----------+\n",
      "Input: \n",
      " [[0 0 1]\n",
      " [0 1 1]\n",
      " [1 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 1 1]\n",
      " [0 0 0]]\n",
      "Actual Output: \n",
      " [[0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n",
      "Predicted Output: \n",
      "[[0.68533616]\n",
      " [0.71087942]\n",
      " [0.72918531]\n",
      " [0.59276547]\n",
      " [0.59306394]\n",
      " [0.75042504]\n",
      " [0.52505707]]\n",
      "Loss: \n",
      "0.25669664860286956\n",
      "\n",
      "\n",
      "+----------EPOCH 50 ----------+\n",
      "Input: \n",
      " [[0 0 1]\n",
      " [0 1 1]\n",
      " [1 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 1 1]\n",
      " [0 0 0]]\n",
      "Actual Output: \n",
      " [[0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n",
      "Predicted Output: \n",
      "[[0.32154621]\n",
      " [0.7098743 ]\n",
      " [0.67907652]\n",
      " [0.72109517]\n",
      " [0.68467508]\n",
      " [0.81142071]\n",
      " [0.31852018]]\n",
      "Loss: \n",
      "0.17537616438741518\n",
      "\n",
      "\n",
      "+----------EPOCH 100 ----------+\n",
      "Input: \n",
      " [[0 0 1]\n",
      " [0 1 1]\n",
      " [1 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 1 1]\n",
      " [0 0 0]]\n",
      "Actual Output: \n",
      " [[0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n",
      "Predicted Output: \n",
      "[[0.14823628]\n",
      " [0.78692374]\n",
      " [0.7600906 ]\n",
      " [0.82810749]\n",
      " [0.78354537]\n",
      " [0.85356173]\n",
      " [0.18733635]]\n",
      "Loss: \n",
      "0.13785631239999913\n",
      "\n",
      "\n",
      "+----------EPOCH 150 ----------+\n",
      "Input: \n",
      " [[0 0 1]\n",
      " [0 1 1]\n",
      " [1 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 1 1]\n",
      " [0 0 0]]\n",
      "Actual Output: \n",
      " [[0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n",
      "Predicted Output: \n",
      "[[0.10492841]\n",
      " [0.78923404]\n",
      " [0.74623428]\n",
      " [0.85762   ]\n",
      " [0.77479475]\n",
      " [0.81367935]\n",
      " [0.14267239]]\n",
      "Loss: \n",
      "0.12474975149070068\n",
      "\n",
      "\n",
      "+----------EPOCH 200 ----------+\n",
      "Input: \n",
      " [[0 0 1]\n",
      " [0 1 1]\n",
      " [1 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 1 1]\n",
      " [0 0 0]]\n",
      "Actual Output: \n",
      " [[0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n",
      "Predicted Output: \n",
      "[[0.08829421]\n",
      " [0.7825722 ]\n",
      " [0.71733849]\n",
      " [0.88473192]\n",
      " [0.75709403]\n",
      " [0.76977415]\n",
      " [0.12654924]]\n",
      "Loss: \n",
      "0.1165464617369526\n",
      "\n",
      "\n",
      "+----------EPOCH 250 ----------+\n",
      "Input: \n",
      " [[0 0 1]\n",
      " [0 1 1]\n",
      " [1 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 1 1]\n",
      " [0 0 0]]\n",
      "Actual Output: \n",
      " [[0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n",
      "Predicted Output: \n",
      "[[0.07743363]\n",
      " [0.78375834]\n",
      " [0.69796513]\n",
      " [0.90905262]\n",
      " [0.7489753 ]\n",
      " [0.74267369]\n",
      " [0.11675189]]\n",
      "Loss: \n",
      "0.11149450252342448\n",
      "\n",
      "\n",
      "+----------EPOCH 300 ----------+\n",
      "Input: \n",
      " [[0 0 1]\n",
      " [0 1 1]\n",
      " [1 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 1 1]\n",
      " [0 0 0]]\n",
      "Actual Output: \n",
      " [[0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n",
      "Predicted Output: \n",
      "[[0.06892988]\n",
      " [0.78756633]\n",
      " [0.68580753]\n",
      " [0.92682787]\n",
      " [0.74690761]\n",
      " [0.72630008]\n",
      " [0.10862514]]\n",
      "Loss: \n",
      "0.10818820596463627\n",
      "\n",
      "\n",
      "+----------EPOCH 350 ----------+\n",
      "Input: \n",
      " [[0 0 1]\n",
      " [0 1 1]\n",
      " [1 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 1 1]\n",
      " [0 0 0]]\n",
      "Actual Output: \n",
      " [[0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n",
      "Predicted Output: \n",
      "[[0.06228059]\n",
      " [0.79042943]\n",
      " [0.67741206]\n",
      " [0.93919869]\n",
      " [0.74857815]\n",
      " [0.71522042]\n",
      " [0.10187661]]\n",
      "Loss: \n",
      "0.10581292994337729\n",
      "\n",
      "\n",
      "+----------EPOCH 400 ----------+\n",
      "Input: \n",
      " [[0 0 1]\n",
      " [0 1 1]\n",
      " [1 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 1 1]\n",
      " [0 0 0]]\n",
      "Actual Output: \n",
      " [[0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n",
      "Predicted Output: \n",
      "[[0.05712759]\n",
      " [0.79099781]\n",
      " [0.67084927]\n",
      " [0.9476389 ]\n",
      " [0.75341032]\n",
      " [0.7067232 ]\n",
      " [0.09642599]]\n",
      "Loss: \n",
      "0.10394135504302557\n",
      "\n",
      "\n",
      "+----------EPOCH 450 ----------+\n",
      "Input: \n",
      " [[0 0 1]\n",
      " [0 1 1]\n",
      " [1 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 1 1]\n",
      " [0 0 0]]\n",
      "Actual Output: \n",
      " [[0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n",
      "Predicted Output: \n",
      "[[0.05319361]\n",
      " [0.78875464]\n",
      " [0.66513335]\n",
      " [0.95300855]\n",
      " [0.76145957]\n",
      " [0.6993443 ]\n",
      " [0.09209323]]\n",
      "Loss: \n",
      "0.10232331338704607\n",
      "\n",
      "\n",
      "+----------EPOCH 500 ----------+\n",
      "Input: \n",
      " [[0 0 1]\n",
      " [0 1 1]\n",
      " [1 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 1 1]\n",
      " [0 0 0]]\n",
      "Actual Output: \n",
      " [[0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n",
      "Predicted Output: \n",
      "[[0.0503447 ]\n",
      " [0.78369578]\n",
      " [0.6598955 ]\n",
      " [0.95555435]\n",
      " [0.77275964]\n",
      " [0.69213019]\n",
      " [0.08866373]]\n",
      "Loss: \n",
      "0.1007874625365598\n",
      "\n",
      "\n",
      "+----------EPOCH 550 ----------+\n",
      "Input: \n",
      " [[0 0 1]\n",
      " [0 1 1]\n",
      " [1 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 1 1]\n",
      " [0 0 0]]\n",
      "Actual Output: \n",
      " [[0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n",
      "Predicted Output: \n",
      "[[0.04864844]\n",
      " [0.77643498]\n",
      " [0.65540488]\n",
      " [0.95480996]\n",
      " [0.78683166]\n",
      " [0.68432069]\n",
      " [0.08591821]]\n",
      "Loss: \n",
      "0.099179059395435\n",
      "\n",
      "\n",
      "+----------EPOCH 600 ----------+\n",
      "Input: \n",
      " [[0 0 1]\n",
      " [0 1 1]\n",
      " [1 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 1 1]\n",
      " [0 0 0]]\n",
      "Actual Output: \n",
      " [[0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n",
      "Predicted Output: \n",
      "[[0.04856776]\n",
      " [0.76808198]\n",
      " [0.65306085]\n",
      " [0.94885245]\n",
      " [0.80264945]\n",
      " [0.67499607]\n",
      " [0.08362942]]\n",
      "Loss: \n",
      "0.09724120770932433\n",
      "\n",
      "\n",
      "+----------EPOCH 650 ----------+\n",
      "Input: \n",
      " [[0 0 1]\n",
      " [0 1 1]\n",
      " [1 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 1 1]\n",
      " [0 0 0]]\n",
      "Actual Output: \n",
      " [[0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n",
      "Predicted Output: \n",
      "[[0.0518594 ]\n",
      " [0.75928959]\n",
      " [0.65849357]\n",
      " [0.93094965]\n",
      " [0.81923094]\n",
      " [0.66195837]\n",
      " [0.08144089]]\n",
      "Loss: \n",
      "0.0942177787537194\n",
      "\n",
      "\n",
      "+----------EPOCH 700 ----------+\n",
      "Input: \n",
      " [[0 0 1]\n",
      " [0 1 1]\n",
      " [1 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 1 1]\n",
      " [0 0 0]]\n",
      "Actual Output: \n",
      " [[0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n",
      "Predicted Output: \n",
      "[[0.0637272 ]\n",
      " [0.74922774]\n",
      " [0.6951785 ]\n",
      " [0.87954521]\n",
      " [0.83065284]\n",
      " [0.63805199]\n",
      " [0.07863967]]\n",
      "Loss: \n",
      "0.08804948377568758\n",
      "\n",
      "\n",
      "+----------EPOCH 750 ----------+\n",
      "Input: \n",
      " [[0 0 1]\n",
      " [0 1 1]\n",
      " [1 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 1 1]\n",
      " [0 0 0]]\n",
      "Actual Output: \n",
      " [[0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n",
      "Predicted Output: \n",
      "[[0.07200999]\n",
      " [0.75503023]\n",
      " [0.74555651]\n",
      " [0.8195534 ]\n",
      " [0.81390944]\n",
      " [0.600857  ]\n",
      " [0.0799271 ]]\n",
      "Loss: \n",
      "0.08064932296681186\n",
      "\n",
      "\n",
      "+----------EPOCH 800 ----------+\n",
      "Input: \n",
      " [[0 0 1]\n",
      " [0 1 1]\n",
      " [1 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 1 1]\n",
      " [0 0 0]]\n",
      "Actual Output: \n",
      " [[0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n",
      "Predicted Output: \n",
      "[[0.06513577]\n",
      " [0.76982924]\n",
      " [0.76587314]\n",
      " [0.80321273]\n",
      " [0.80072177]\n",
      " [0.56930463]\n",
      " [0.08757595]]\n",
      "Loss: \n",
      "0.07460728476277326\n",
      "\n",
      "\n",
      "+----------EPOCH 850 ----------+\n",
      "Input: \n",
      " [[0 0 1]\n",
      " [0 1 1]\n",
      " [1 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 1 1]\n",
      " [0 0 0]]\n",
      "Actual Output: \n",
      " [[0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n",
      "Predicted Output: \n",
      "[[0.05769091]\n",
      " [0.77886651]\n",
      " [0.77730647]\n",
      " [0.80048147]\n",
      " [0.79828424]\n",
      " [0.54139514]\n",
      " [0.09485036]]\n",
      "Loss: \n",
      "0.06920326365194256\n",
      "\n",
      "\n",
      "+----------EPOCH 900 ----------+\n",
      "Input: \n",
      " [[0 0 1]\n",
      " [0 1 1]\n",
      " [1 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 1 1]\n",
      " [0 0 0]]\n",
      "Actual Output: \n",
      " [[0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n",
      "Predicted Output: \n",
      "[[0.05183782]\n",
      " [0.78552366]\n",
      " [0.78588894]\n",
      " [0.80186174]\n",
      " [0.79961093]\n",
      " [0.51545498]\n",
      " [0.09975051]]\n",
      "Loss: \n",
      "0.06422705098297361\n",
      "\n",
      "\n",
      "+----------EPOCH 950 ----------+\n",
      "Input: \n",
      " [[0 0 1]\n",
      " [0 1 1]\n",
      " [1 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 1 1]\n",
      " [0 0 0]]\n",
      "Actual Output: \n",
      " [[0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n",
      "Predicted Output: \n",
      "[[0.04721401]\n",
      " [0.7912984 ]\n",
      " [0.79354185]\n",
      " [0.80505644]\n",
      " [0.80245517]\n",
      " [0.49096339]\n",
      " [0.10232031]]\n",
      "Loss: \n",
      "0.05956456164843838\n",
      "\n",
      "\n",
      "+----------EPOCH 1000 ----------+\n",
      "Input: \n",
      " [[0 0 1]\n",
      " [0 1 1]\n",
      " [1 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 1 1]\n",
      " [0 0 0]]\n",
      "Actual Output: \n",
      " [[0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n",
      "Predicted Output: \n",
      "[[0.04353628]\n",
      " [0.79662288]\n",
      " [0.80110911]\n",
      " [0.80938735]\n",
      " [0.80606063]\n",
      " [0.46717683]\n",
      " [0.10296342]]\n",
      "Loss: \n",
      "0.05508808057986109\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NN = Neural_Network()\n",
    "for i in range(1000): # trains the NN 1,000 times\n",
    "    if i+1 in [1,2,3,4,5] or (i+1) % 50 == 0:\n",
    "        print('+----------EPOCH', i+1, '----------+')\n",
    "        print(\"Input: \\n\", X)\n",
    "        print(\"Actual Output: \\n\", y)\n",
    "        print(\"Predicted Output: \\n\" + str(NN.feed_forward(X)))\n",
    "        print(\"Loss: \\n\" + str(np.mean(np.square(y - NN.feed_forward(X))))) #mean sum squared loss\n",
    "        print(\"\\n\")\n",
    "    NN.train(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8b-r70o8p2Dm"
   },
   "source": [
    "## Try building/training a more complex MLP on a bigger dataset.\n",
    "\n",
    "Use the [MNIST dataset](http://yann.lecun.com/exdb/mnist/) to build the cannonical handwriting digit recognizer and see what kind of accuracy you can achieve. \n",
    "\n",
    "If you need inspiration, the internet is chalk-full of tutorials, but I want you to see how far you can get on your own first. I've linked to the original MNIST dataset above but it will probably be easier to download data through a neural network library. If you reference outside resources make sure you understand every line of code that you're using from other sources, and share with your fellow students helpful resources that you find.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlxtend\n",
      "  Using cached https://files.pythonhosted.org/packages/16/e6/30e50ed9c053a1530c83149090e1f5fd9fccc8503dca2ecce1bb52f34de0/mlxtend-0.15.0.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: pandas>=0.17.1 in /home/mishraka/anaconda3/lib/python3.6/site-packages (from mlxtend) (0.24.2)\n",
      "Requirement already satisfied: setuptools in /home/mishraka/anaconda3/lib/python3.6/site-packages (from mlxtend) (40.8.0)\n",
      "Requirement already satisfied: scipy>=0.17 in /home/mishraka/anaconda3/lib/python3.6/site-packages (from mlxtend) (1.1.0)\n",
      "Requirement already satisfied: matplotlib>=1.5.1 in /home/mishraka/anaconda3/lib/python3.6/site-packages (from mlxtend) (3.0.2)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in /home/mishraka/anaconda3/lib/python3.6/site-packages (from mlxtend) (0.20.1)\n",
      "Requirement already satisfied: numpy>=1.10.4 in /home/mishraka/anaconda3/lib/python3.6/site-packages (from mlxtend) (1.15.4)\n",
      "Requirement already satisfied: pytz>=2011k in /home/mishraka/anaconda3/lib/python3.6/site-packages (from pandas>=0.17.1->mlxtend) (2018.9)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /home/mishraka/anaconda3/lib/python3.6/site-packages (from pandas>=0.17.1->mlxtend) (2.8.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/mishraka/anaconda3/lib/python3.6/site-packages (from matplotlib>=1.5.1->mlxtend) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/mishraka/anaconda3/lib/python3.6/site-packages (from matplotlib>=1.5.1->mlxtend) (1.0.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/mishraka/anaconda3/lib/python3.6/site-packages (from matplotlib>=1.5.1->mlxtend) (2.3.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/mishraka/anaconda3/lib/python3.6/site-packages (from python-dateutil>=2.5.0->pandas>=0.17.1->mlxtend) (1.12.0)\n",
      "Installing collected packages: mlxtend\n",
      "Successfully installed mlxtend-0.15.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install mlxtend "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5MOPtYdk1HgA",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions: 5000 x 784\n",
      "1st row [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.  51. 159. 253. 159.  50.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  48. 238. 252. 252. 252. 237.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  54.\n",
      " 227. 253. 252. 239. 233. 252.  57.   6.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  10.  60. 224.\n",
      " 252. 253. 252. 202.  84. 252. 253. 122.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 163. 252. 252.\n",
      " 252. 253. 252. 252.  96. 189. 253. 167.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  51. 238. 253. 253.\n",
      " 190. 114. 253. 228.  47.  79. 255. 168.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.  48. 238. 252. 252. 179.\n",
      "  12.  75. 121.  21.   0.   0. 253. 243.  50.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.  38. 165. 253. 233. 208.  84.\n",
      "   0.   0.   0.   0.   0.   0. 253. 252. 165.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   7. 178. 252. 240.  71.  19.  28.\n",
      "   0.   0.   0.   0.   0.   0. 253. 252. 195.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.  57. 252. 252.  63.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0. 253. 252. 195.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0. 198. 253. 190.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0. 255. 253. 196.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.  76. 246. 252. 112.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0. 253. 252. 148.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.  85. 252. 230.  25.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   7. 135. 253. 186.  12.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.  85. 252. 223.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   7. 131. 252. 225.  71.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.  85. 252. 145.   0.   0.   0.   0.   0.\n",
      "   0.   0.  48. 165. 252. 173.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.  86. 253. 225.   0.   0.   0.   0.   0.\n",
      "   0. 114. 238. 253. 162.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.  85. 252. 249. 146.  48.  29.  85. 178.\n",
      " 225. 253. 223. 167.  56.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.  85. 252. 252. 252. 229. 215. 252. 252.\n",
      " 252. 196. 130.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.  28. 199. 252. 252. 253. 252. 252. 233.\n",
      " 145.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.  25. 128. 252. 253. 252. 141.  37.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.data import mnist_data\n",
    "X, y = mnist_data()\n",
    "\n",
    "print('Dimensions: %s x %s' % (X.shape[0], X.shape[1]))\n",
    "print('1st row', X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.reshape(y,(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 1)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_digit(X, y, idx):\n",
    "    img = X[idx].reshape(28,28)\n",
    "    plt.imshow(img, cmap='Greys',  interpolation='nearest')\n",
    "    plt.title('true label: %d' % y[idx])\n",
    "    plt.show()\n",
    "plot_digit(X, y, 4)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neural_Network(object):\n",
    "    def __init__(self):\n",
    "        self.inputs = 784\n",
    "        self.hiddenNodes = 800\n",
    "        self.outputNodes =10\n",
    "        \n",
    "        # Initialize weights\n",
    "        self.L1_weights = np.random.randn(self.inputs, self.hiddenNodes) #(2x3)\n",
    "#       self.L2_weights = np.random.randn(self.hiddenNodes, self.hiddenNodes)\n",
    "        self.L2_weights = np.random.randn(self.hiddenNodes, self.outputNodes)\n",
    "    \n",
    "    def feed_forward(self, X):\n",
    "        # Weighted sum between inputs and hidden layer\n",
    "        self.hidden_sum = np.dot(X, self.L1_weights)\n",
    "        # Activations on weighted sum\n",
    "        self.activated_hidden = self.sigmoid(self.hidden_sum)\n",
    "        # Weighted sum between hidden and output\n",
    "        self.output_sum = np.dot(self.activated_hidden, self.L2_weights)\n",
    "        # final activation of output\n",
    "        self.activated_output = self.sigmoid(self.output_sum)\n",
    "        return self.activated_output\n",
    "    \n",
    "    def sigmoid(self, s):\n",
    "        return 1/(1+np.exp(-s))\n",
    "    \n",
    "    def sigmoidPrime(self, s):\n",
    "        return s * (1 - s)\n",
    "    \n",
    "    def backward(self, X, y, o):\n",
    "        #backward propgate through the network\n",
    "        self.o_error = y - o # error in output\n",
    "        self.o_delta = self.o_error*self.sigmoidPrime(o) # applying derivative of sigmoid ot error\n",
    "        \n",
    "        self.z2_error = self.o_delta.dot(self.L2_weights.T) # z2 error: how much our hidden layer weights contributed to output error\n",
    "        self.z2_delta = self.z2_error*self.sigmoidPrime(self.activated_hidden) # applying derivative of sigmoid to z2 error\n",
    "        \n",
    "        self.L1_weights += X.T.dot(self.z2_delta) # adjusting first set (input --> hidden) weights\n",
    "        self.L2_weights += self.activated_hidden.T.dot(self.o_delta) # adjusting second set (hidden --> output) weights\n",
    "        \n",
    "    def train(self, X, y):\n",
    "        o = self.feed_forward(X)\n",
    "        self.backward(X,y,o)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------EPOCH 1 ----------+\n",
      "Input: \n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Actual Output: \n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [9]\n",
      " [9]\n",
      " [9]]\n",
      "Predicted Output: \n",
      "[[2.86456623e-06 9.99998799e-01 4.63660877e-13 ... 1.77239090e-07\n",
      "  1.00000000e+00 5.73544957e-03]\n",
      " [9.51890757e-01 1.00000000e+00 3.64089547e-05 ... 3.81096781e-12\n",
      "  9.90495419e-01 8.49270966e-04]\n",
      " [1.02010593e-08 1.00000000e+00 1.78140417e-16 ... 1.02006263e-09\n",
      "  8.43579442e-03 1.00000000e+00]\n",
      " ...\n",
      " [1.23062748e-07 9.97963591e-01 1.51596675e-08 ... 9.27507954e-06\n",
      "  9.99999738e-01 9.99999952e-01]\n",
      " [1.18672059e-11 9.99999992e-01 2.41062883e-04 ... 7.68460440e-10\n",
      "  9.80514356e-01 9.99999704e-01]\n",
      " [9.98764375e-01 7.06738243e-01 9.99975248e-01 ... 4.34931027e-02\n",
      "  9.62467461e-01 9.99999999e-01]]\n",
      "Loss: \n",
      "23.943994889982687\n",
      "\n",
      "\n",
      "+----------EPOCH 2 ----------+\n",
      "Input: \n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Actual Output: \n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [9]\n",
      " [9]\n",
      " [9]]\n",
      "Predicted Output: \n",
      "[[1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]]\n",
      "Loss: \n",
      "20.5\n",
      "\n",
      "\n",
      "+----------EPOCH 3 ----------+\n",
      "Input: \n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Actual Output: \n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [9]\n",
      " [9]\n",
      " [9]]\n",
      "Predicted Output: \n",
      "[[1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]]\n",
      "Loss: \n",
      "20.5\n",
      "\n",
      "\n",
      "+----------EPOCH 4 ----------+\n",
      "Input: \n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Actual Output: \n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [9]\n",
      " [9]\n",
      " [9]]\n",
      "Predicted Output: \n",
      "[[1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]]\n",
      "Loss: \n",
      "20.5\n",
      "\n",
      "\n",
      "+----------EPOCH 5 ----------+\n",
      "Input: \n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Actual Output: \n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [9]\n",
      " [9]\n",
      " [9]]\n",
      "Predicted Output: \n",
      "[[1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]]\n",
      "Loss: \n",
      "20.5\n",
      "\n",
      "\n",
      "+----------EPOCH 50 ----------+\n",
      "Input: \n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Actual Output: \n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [9]\n",
      " [9]\n",
      " [9]]\n",
      "Predicted Output: \n",
      "[[1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]]\n",
      "Loss: \n",
      "20.5\n",
      "\n",
      "\n",
      "+----------EPOCH 100 ----------+\n",
      "Input: \n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Actual Output: \n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [9]\n",
      " [9]\n",
      " [9]]\n",
      "Predicted Output: \n",
      "[[1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]]\n",
      "Loss: \n",
      "20.5\n",
      "\n",
      "\n",
      "+----------EPOCH 150 ----------+\n",
      "Input: \n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Actual Output: \n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [9]\n",
      " [9]\n",
      " [9]]\n",
      "Predicted Output: \n",
      "[[1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]]\n",
      "Loss: \n",
      "20.5\n",
      "\n",
      "\n",
      "+----------EPOCH 200 ----------+\n",
      "Input: \n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Actual Output: \n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [9]\n",
      " [9]\n",
      " [9]]\n",
      "Predicted Output: \n",
      "[[1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]]\n",
      "Loss: \n",
      "20.5\n",
      "\n",
      "\n",
      "+----------EPOCH 250 ----------+\n",
      "Input: \n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Actual Output: \n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [9]\n",
      " [9]\n",
      " [9]]\n",
      "Predicted Output: \n",
      "[[1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]]\n",
      "Loss: \n",
      "20.5\n",
      "\n",
      "\n",
      "+----------EPOCH 300 ----------+\n",
      "Input: \n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Actual Output: \n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [9]\n",
      " [9]\n",
      " [9]]\n",
      "Predicted Output: \n",
      "[[1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]]\n",
      "Loss: \n",
      "20.5\n",
      "\n",
      "\n",
      "+----------EPOCH 350 ----------+\n",
      "Input: \n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Actual Output: \n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [9]\n",
      " [9]\n",
      " [9]]\n",
      "Predicted Output: \n",
      "[[1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]]\n",
      "Loss: \n",
      "20.5\n",
      "\n",
      "\n",
      "+----------EPOCH 400 ----------+\n",
      "Input: \n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Actual Output: \n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [9]\n",
      " [9]\n",
      " [9]]\n",
      "Predicted Output: \n",
      "[[1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]]\n",
      "Loss: \n",
      "20.5\n",
      "\n",
      "\n",
      "+----------EPOCH 450 ----------+\n",
      "Input: \n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Actual Output: \n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [9]\n",
      " [9]\n",
      " [9]]\n",
      "Predicted Output: \n",
      "[[1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]]\n",
      "Loss: \n",
      "20.5\n",
      "\n",
      "\n",
      "+----------EPOCH 500 ----------+\n",
      "Input: \n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Actual Output: \n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [9]\n",
      " [9]\n",
      " [9]]\n",
      "Predicted Output: \n",
      "[[1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]]\n",
      "Loss: \n",
      "20.5\n",
      "\n",
      "\n",
      "+----------EPOCH 550 ----------+\n",
      "Input: \n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Actual Output: \n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [9]\n",
      " [9]\n",
      " [9]]\n",
      "Predicted Output: \n",
      "[[1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]]\n",
      "Loss: \n",
      "20.5\n",
      "\n",
      "\n",
      "+----------EPOCH 600 ----------+\n",
      "Input: \n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Actual Output: \n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [9]\n",
      " [9]\n",
      " [9]]\n",
      "Predicted Output: \n",
      "[[1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]]\n",
      "Loss: \n",
      "20.5\n",
      "\n",
      "\n",
      "+----------EPOCH 650 ----------+\n",
      "Input: \n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Actual Output: \n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [9]\n",
      " [9]\n",
      " [9]]\n",
      "Predicted Output: \n",
      "[[1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: \n",
      "20.5\n",
      "\n",
      "\n",
      "+----------EPOCH 700 ----------+\n",
      "Input: \n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Actual Output: \n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [9]\n",
      " [9]\n",
      " [9]]\n",
      "Predicted Output: \n",
      "[[1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]]\n",
      "Loss: \n",
      "20.5\n",
      "\n",
      "\n",
      "+----------EPOCH 750 ----------+\n",
      "Input: \n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Actual Output: \n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [9]\n",
      " [9]\n",
      " [9]]\n",
      "Predicted Output: \n",
      "[[1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]]\n",
      "Loss: \n",
      "20.5\n",
      "\n",
      "\n",
      "+----------EPOCH 800 ----------+\n",
      "Input: \n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Actual Output: \n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [9]\n",
      " [9]\n",
      " [9]]\n",
      "Predicted Output: \n",
      "[[1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]]\n",
      "Loss: \n",
      "20.5\n",
      "\n",
      "\n",
      "+----------EPOCH 850 ----------+\n",
      "Input: \n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Actual Output: \n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [9]\n",
      " [9]\n",
      " [9]]\n",
      "Predicted Output: \n",
      "[[1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]]\n",
      "Loss: \n",
      "20.5\n",
      "\n",
      "\n",
      "+----------EPOCH 900 ----------+\n",
      "Input: \n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Actual Output: \n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [9]\n",
      " [9]\n",
      " [9]]\n",
      "Predicted Output: \n",
      "[[1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]]\n",
      "Loss: \n",
      "20.5\n",
      "\n",
      "\n",
      "+----------EPOCH 950 ----------+\n",
      "Input: \n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Actual Output: \n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [9]\n",
      " [9]\n",
      " [9]]\n",
      "Predicted Output: \n",
      "[[1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]]\n",
      "Loss: \n",
      "20.5\n",
      "\n",
      "\n",
      "+----------EPOCH 1000 ----------+\n",
      "Input: \n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Actual Output: \n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [9]\n",
      " [9]\n",
      " [9]]\n",
      "Predicted Output: \n",
      "[[1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]]\n",
      "Loss: \n",
      "20.5\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NN = Neural_Network()\n",
    "for i in range(1000): # trains the NN 1,000 times\n",
    "    if i+1 in [1,2,3,4,5] or (i+1) % 50 == 0:\n",
    "        print('+----------EPOCH', i+1, '----------+')\n",
    "        print(\"Input: \\n\", X)\n",
    "        print(\"Actual Output: \\n\", y)\n",
    "        print(\"Predicted Output: \\n\" + str(NN.feed_forward(X)))\n",
    "        print(\"Loss: \\n\" + str(np.mean(np.square(y - NN.feed_forward(X))))) #mean sum squared loss\n",
    "        print(\"\\n\")\n",
    "    NN.train(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5000, 784), (5000,))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FwlRJSfBlCvy"
   },
   "source": [
    "## Stretch Goals: \n",
    "\n",
    "- Implement Cross Validation model evaluation on your MNIST implementation \n",
    "- Research different [Gradient Descent Based Optimizers](https://keras.io/optimizers/)\n",
    " - [Siraj Raval the evolution of gradient descent](https://www.youtube.com/watch?v=nhqo0u1a6fw)\n",
    "- Build a housing price estimation model using a neural network. How does its accuracy compare with the regression models that we fit earlier on in class?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "LS_DS_432_Backprop_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
