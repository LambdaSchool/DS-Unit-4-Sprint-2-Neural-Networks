{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2*\n",
    "\n",
    "# Sprint Challenge - Neural Network Foundations\n",
    "\n",
    "Table of Problems\n",
    "\n",
    "1. [Defining Neural Networks](#Q1)\n",
    "2. [Perceptron on XOR Gates](#Q2)\n",
    "3. [Multilayer Perceptron](#Q3)\n",
    "4. [Keras MMP](#Q4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Q1\"></a>\n",
    "## 1. Define the following terms:\n",
    "\n",
    "- **Neuron:**\n",
    "A Neuron is a single node within a neural network, it takes an input has bias and weight values and an activation function. A perceptron can also be considered a Neuron.\n",
    "- **Input Layer:**\n",
    "The Input Layer is where data flows into a neural network, the input layer must have the same dimensions as the data which is being fed in. The input layer passes each \n",
    "- **Hidden Layer:**\n",
    "Hidden Layers are Neurons within a Neural Network which accept input from either the input layer or a previous hidden layer. Like all neurons each neuron in the hidden layer \n",
    "- **Output Layer:**\n",
    "The output layer is the end result of the neural network, it's shape will be the same as the data you're trying to predict.\n",
    "- **Activation:**\n",
    "An activation function takes the result of a node's input * weight + bias as input and if the result is sufficient the node activates.\n",
    "- **Backpropagation:**\n",
    "Backpropagation takes the passes the error (desired output - predicted output) from the output layer back down the network and adjusts the weights of the network based off how much the nodes affected the final result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Perceptron on XOR Gates <a id=\"Q2\"></a>\n",
    "\n",
    "The XOr, or “exclusive or”, problem is a classic problem in ANN research. It is the problem of using a neural network to predict the outputs of XOr logic gates given two binary inputs. An XOr function should return a true value if the two inputs are not equal and a false value if they are equal. Create a perceptron class that can model the behavior of an AND gate. You can use the following table as your training data:\n",
    "\n",
    "|x1\t|x2 | y |\n",
    "|---|---|---|\n",
    "| 0 | 0 | 0 |\n",
    "| 0 | 1 | 1 |\n",
    "| 1 | 1 | 0 |\n",
    "| 1 | 0 | 1 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "X = np.array([[0.0,0.0],\n",
    "             [0.0,1.0],\n",
    "             [1.0,1.0],\n",
    "             [1.0,0.0]])\n",
    "y = np.array([0.0, 1.0, 0.0, 1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, lr=0.01):\n",
    "        self.lr = lr\n",
    "    \n",
    "    def fit(self,X, y, epochs=10):\n",
    "        self.weights = np.zeros(1+X.shape[1])\n",
    "        self.errors = []\n",
    "        for i in range(epochs):\n",
    "            err = 0\n",
    "            for xi, target in zip(X, y):\n",
    "                delta_w = self.lr * (target - self.predict(xi))\n",
    "                self.weights[1:] += delta_w * xi\n",
    "                self.weights[0] += delta_w\n",
    "                err += int(delta_w != 0.0)\n",
    "            self.errors.append(err)\n",
    "        return self\n",
    "    \n",
    "    def net_input(self, X):\n",
    "        return np.dot(X, self.weights[1:]) + self.weights[0]\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.where(self.net_input(X) >= 0.0, 1.0, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Perceptron at 0x7fb1ff390278>"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pn = Perceptron(0.01)\n",
    "pn.fit(X, y, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1.])"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pn.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1, len(pn.errors) + 1), pn.errors, marker='o')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Misclassified')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guess I need to put some more time into this later..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Multilayer Perceptron <a id=\"Q3\"></a>\n",
    "\n",
    "Implement a Neural Network Multilayer Perceptron class that uses backpropagation to update the network's weights.\n",
    "Your network must have one hidden layer.\n",
    "You do not have to update weights via gradient descent. You can use something like the derivative of the sigmoid function to update weights.\n",
    "Train your model on the Heart Disease dataset from UCI:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "class NeuralNet:\n",
    "    def __init__(self, inputs, hiddenNodes, outputNodes):\n",
    "        self.inputs = inputs\n",
    "        self.hiddenNodes = hiddenNodes\n",
    "        self.outputNodes = outputNodes\n",
    "        \n",
    "        self.weights1 = np.random.randn(self.inputs, self.hiddenNodes)\n",
    "        self.weights2 = np.random.randn(self.hiddenNodes, self.outputNodes)\n",
    "        \n",
    "    def sigmoid(self, s):\n",
    "        return 1 / (1 + np.exp(-s))\n",
    "    \n",
    "    def sigmoidPrime(self, s):\n",
    "        return s * (1 - s)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        # multiply inputs by weights of first hidden node\n",
    "        self.hidden_sum = np.dot(X, self.weights1)\n",
    "        # pass values through sigmoid function to decide activation\n",
    "        self.activated_hidden = self.sigmoid(self.hidden_sum)\n",
    "        # multiply hidden output by output layer weights\n",
    "        self.output_sum = np.dot(self.activated_hidden, self.weights2)\n",
    "        # pass output values through sigmoid to determine output\n",
    "        self.activated_output = self.sigmoid(self.output_sum)\n",
    "        \n",
    "        return self.activated_output\n",
    "    \n",
    "    def backward(self, X, y, o):\n",
    "        # Subtract result from feeding foward from\n",
    "        # actual output to determine error rate\n",
    "        self.o_error = y - o\n",
    "        # Use derivative of the output(from sigmoid function)\n",
    "        # multiplied by error\n",
    "        self.o_delta = self.o_error * self.sigmoidPrime(o)\n",
    "        \n",
    "        self.z2_error = self.o_delta.dot(self.weights2.T)\n",
    "        self.z2_delta = self.z2_error * self.sigmoidPrime(self.activated_hidden)\n",
    "        \n",
    "        self.weights2 += self.activated_hidden.T.dot(self.o_delta)\n",
    "        \n",
    "        self.weights1 += X.T.dot(self.z2_delta)\n",
    "        \n",
    "    def train(self, X, y):\n",
    "        o = self.forward(X)\n",
    "        self.backward(X, y, o)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "heartdisease = fetch_openml(data_id=194)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(heartdisease['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.fillna(value=0.0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(303, 13)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(303,)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = heartdisease['target']\n",
    "y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.33, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(203, 13)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.reshape(203, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN = NeuralNet(13, 30, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN.train(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------EPOCH 1---------+\n",
      "Input: \n",
      " [[41.  0.  2. ...  0.  0.  1.]\n",
      " [67.  1.  2. ...  1.  0.  2.]\n",
      " [51.  1.  0. ...  0.  1.  1.]\n",
      " ...\n",
      " [53.  0.  1. ...  0.  0.  1.]\n",
      " [65.  0.  2. ...  0.  1.  1.]\n",
      " [51.  0.  2. ...  0.  0.  1.]]\n",
      "Actual Output: \n",
      " [[1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]]\n",
      "Predicted Output: \n",
      " [[9.98241108e-01 8.24819324e-01 6.88872497e-77 1.01552039e-63\n",
      "  1.04295890e-03]\n",
      " [9.98241108e-01 8.24819324e-01 6.88872497e-77 1.01552039e-63\n",
      "  1.04295890e-03]\n",
      " [9.98241108e-01 8.24819324e-01 6.88872497e-77 1.01552039e-63\n",
      "  1.04295890e-03]\n",
      " ...\n",
      " [9.98241108e-01 8.24819324e-01 6.88872497e-77 1.01552039e-63\n",
      "  1.04295890e-03]\n",
      " [9.98241108e-01 8.24819324e-01 6.88872497e-77 1.01552039e-63\n",
      "  1.04295890e-03]\n",
      " [9.98241108e-01 8.24819324e-01 6.88872497e-77 1.01552039e-63\n",
      "  1.04295890e-03]]\n",
      "Loss: \n",
      " 0.26199639690842735\n",
      "+---------EPOCH 100---------+\n",
      "Input: \n",
      " [[41.  0.  2. ...  0.  0.  1.]\n",
      " [67.  1.  2. ...  1.  0.  2.]\n",
      " [51.  1.  0. ...  0.  1.  1.]\n",
      " ...\n",
      " [53.  0.  1. ...  0.  0.  1.]\n",
      " [65.  0.  2. ...  0.  1.  1.]\n",
      " [51.  0.  2. ...  0.  0.  1.]]\n",
      "Actual Output: \n",
      " [[1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]]\n",
      "Predicted Output: \n",
      " [[1.00000000e+00 1.46349520e-91 6.88872497e-77 1.01552039e-63\n",
      "  4.18876654e-05]\n",
      " [1.00000000e+00 1.46349520e-91 6.88872497e-77 1.01552039e-63\n",
      "  4.18876654e-05]\n",
      " [1.00000000e+00 1.46349520e-91 6.88872497e-77 1.01552039e-63\n",
      "  4.18876654e-05]\n",
      " ...\n",
      " [1.00000000e+00 1.46349520e-91 6.88872497e-77 1.01552039e-63\n",
      "  4.18876654e-05]\n",
      " [1.00000000e+00 1.46349520e-91 6.88872497e-77 1.01552039e-63\n",
      "  4.18876654e-05]\n",
      " [1.00000000e+00 1.46349520e-91 6.88872497e-77 1.01552039e-63\n",
      "  4.18876654e-05]]\n",
      "Loss: \n",
      " 0.18325040652146504\n",
      "+---------EPOCH 200---------+\n",
      "Input: \n",
      " [[41.  0.  2. ...  0.  0.  1.]\n",
      " [67.  1.  2. ...  1.  0.  2.]\n",
      " [51.  1.  0. ...  0.  1.  1.]\n",
      " ...\n",
      " [53.  0.  1. ...  0.  0.  1.]\n",
      " [65.  0.  2. ...  0.  1.  1.]\n",
      " [51.  0.  2. ...  0.  0.  1.]]\n",
      "Actual Output: \n",
      " [[1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]]\n",
      "Predicted Output: \n",
      " [[1.00000000e+00 1.46349520e-91 6.88872497e-77 1.01552039e-63\n",
      "  7.73915504e-05]\n",
      " [1.00000000e+00 1.46349520e-91 6.88872497e-77 1.01552039e-63\n",
      "  7.73915504e-05]\n",
      " [1.00000000e+00 1.46349520e-91 6.88872497e-77 1.01552039e-63\n",
      "  7.73915504e-05]\n",
      " ...\n",
      " [1.00000000e+00 1.46349520e-91 6.88872497e-77 1.01552039e-63\n",
      "  7.73915504e-05]\n",
      " [1.00000000e+00 1.46349520e-91 6.88872497e-77 1.01552039e-63\n",
      "  7.73915504e-05]\n",
      " [1.00000000e+00 1.46349520e-91 6.88872497e-77 1.01552039e-63\n",
      "  7.73915504e-05]]\n",
      "Loss: \n",
      " 0.18324970782352368\n",
      "+---------EPOCH 300---------+\n",
      "Input: \n",
      " [[41.  0.  2. ...  0.  0.  1.]\n",
      " [67.  1.  2. ...  1.  0.  2.]\n",
      " [51.  1.  0. ...  0.  1.  1.]\n",
      " ...\n",
      " [53.  0.  1. ...  0.  0.  1.]\n",
      " [65.  0.  2. ...  0.  1.  1.]\n",
      " [51.  0.  2. ...  0.  0.  1.]]\n",
      "Actual Output: \n",
      " [[1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]]\n",
      "Predicted Output: \n",
      " [[1.00000000e+00 1.46349520e-91 6.88872497e-77 1.01552039e-63\n",
      "  4.84558487e-04]\n",
      " [1.00000000e+00 1.46349520e-91 6.88872497e-77 1.01552039e-63\n",
      "  4.84558487e-04]\n",
      " [1.00000000e+00 1.46349520e-91 6.88872497e-77 1.01552039e-63\n",
      "  4.84558487e-04]\n",
      " ...\n",
      " [1.00000000e+00 1.46349520e-91 6.88872497e-77 1.01552039e-63\n",
      "  4.84558487e-04]\n",
      " [1.00000000e+00 1.46349520e-91 6.88872497e-77 1.01552039e-63\n",
      "  4.84558487e-04]\n",
      " [1.00000000e+00 1.46349520e-91 6.88872497e-77 1.01552039e-63\n",
      "  4.84558487e-04]]\n",
      "Loss: \n",
      " 0.18324173269518987\n",
      "+---------EPOCH 400---------+\n",
      "Input: \n",
      " [[41.  0.  2. ...  0.  0.  1.]\n",
      " [67.  1.  2. ...  1.  0.  2.]\n",
      " [51.  1.  0. ...  0.  1.  1.]\n",
      " ...\n",
      " [53.  0.  1. ...  0.  0.  1.]\n",
      " [65.  0.  2. ...  0.  1.  1.]\n",
      " [51.  0.  2. ...  0.  0.  1.]]\n",
      "Actual Output: \n",
      " [[1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]]\n",
      "Predicted Output: \n",
      " [[1.00000000e+00 1.46349520e-91 6.88872497e-77 1.01552039e-63\n",
      "  9.07425008e-05]\n",
      " [1.00000000e+00 1.46349520e-91 6.88872497e-77 1.01552039e-63\n",
      "  9.07425008e-05]\n",
      " [1.00000000e+00 1.46349520e-91 6.88872497e-77 1.01552039e-63\n",
      "  9.07425008e-05]\n",
      " ...\n",
      " [1.00000000e+00 1.46349520e-91 6.88872497e-77 1.01552039e-63\n",
      "  9.07425008e-05]\n",
      " [1.00000000e+00 1.46349520e-91 6.88872497e-77 1.01552039e-63\n",
      "  9.07425008e-05]\n",
      " [1.00000000e+00 1.46349520e-91 6.88872497e-77 1.01552039e-63\n",
      "  9.07425008e-05]]\n",
      "Loss: \n",
      " 0.1832494452047689\n",
      "+---------EPOCH 500---------+\n",
      "Input: \n",
      " [[41.  0.  2. ...  0.  0.  1.]\n",
      " [67.  1.  2. ...  1.  0.  2.]\n",
      " [51.  1.  0. ...  0.  1.  1.]\n",
      " ...\n",
      " [53.  0.  1. ...  0.  0.  1.]\n",
      " [65.  0.  2. ...  0.  1.  1.]\n",
      " [51.  0.  2. ...  0.  0.  1.]]\n",
      "Actual Output: \n",
      " [[1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]]\n",
      "Predicted Output: \n",
      " [[1.00000000e+00 1.46349520e-91 6.88872497e-77 1.01552039e-63\n",
      "  3.38883634e-03]\n",
      " [1.00000000e+00 1.46349520e-91 6.88872497e-77 1.01552039e-63\n",
      "  3.38883634e-03]\n",
      " [1.00000000e+00 1.46349520e-91 6.88872497e-77 1.01552039e-63\n",
      "  3.38883634e-03]\n",
      " ...\n",
      " [1.00000000e+00 1.46349520e-91 6.88872497e-77 1.01552039e-63\n",
      "  3.38883634e-03]\n",
      " [1.00000000e+00 1.46349520e-91 6.88872497e-77 1.01552039e-63\n",
      "  3.38883634e-03]\n",
      " [1.00000000e+00 1.46349520e-91 6.88872497e-77 1.01552039e-63\n",
      "  3.38883634e-03]]\n",
      "Loss: \n",
      " 0.18318683624026177\n",
      "+---------EPOCH 600---------+\n",
      "Input: \n",
      " [[41.  0.  2. ...  0.  0.  1.]\n",
      " [67.  1.  2. ...  1.  0.  2.]\n",
      " [51.  1.  0. ...  0.  1.  1.]\n",
      " ...\n",
      " [53.  0.  1. ...  0.  0.  1.]\n",
      " [65.  0.  2. ...  0.  1.  1.]\n",
      " [51.  0.  2. ...  0.  0.  1.]]\n",
      "Actual Output: \n",
      " [[1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]]\n",
      "Predicted Output: \n",
      " [[1.00000000e+00 1.46349520e-91 6.88872497e-77 1.01552039e-63\n",
      "  5.74385295e-04]\n",
      " [1.00000000e+00 1.46349520e-91 6.88872497e-77 1.01552039e-63\n",
      "  5.74385295e-04]\n",
      " [1.00000000e+00 1.46349520e-91 6.88872497e-77 1.01552039e-63\n",
      "  5.74385295e-04]\n",
      " ...\n",
      " [1.00000000e+00 1.46349520e-91 6.88872497e-77 1.01552039e-63\n",
      "  5.74385295e-04]\n",
      " [1.00000000e+00 1.46349520e-91 6.88872497e-77 1.01552039e-63\n",
      "  5.74385295e-04]\n",
      " [1.00000000e+00 1.46349520e-91 6.88872497e-77 1.01552039e-63\n",
      "  5.74385295e-04]]\n",
      "Loss: \n",
      " 0.18323998094474614\n",
      "+---------EPOCH 700---------+\n",
      "Input: \n",
      " [[41.  0.  2. ...  0.  0.  1.]\n",
      " [67.  1.  2. ...  1.  0.  2.]\n",
      " [51.  1.  0. ...  0.  1.  1.]\n",
      " ...\n",
      " [53.  0.  1. ...  0.  0.  1.]\n",
      " [65.  0.  2. ...  0.  1.  1.]\n",
      " [51.  0.  2. ...  0.  0.  1.]]\n",
      "Actual Output: \n",
      " [[1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]]\n",
      "Predicted Output: \n",
      " [[1.00000000e+00 1.46349520e-91 6.88872497e-77 1.01552039e-63\n",
      "  1.68244944e-05]\n",
      " [1.00000000e+00 1.46349520e-91 6.88872497e-77 1.01552039e-63\n",
      "  1.68244944e-05]\n",
      " [1.00000000e+00 1.46349520e-91 6.88872497e-77 1.01552039e-63\n",
      "  1.68244944e-05]\n",
      " ...\n",
      " [1.00000000e+00 1.46349520e-91 6.88872497e-77 1.01552039e-63\n",
      "  1.68244944e-05]\n",
      " [1.00000000e+00 1.46349520e-91 6.88872497e-77 1.01552039e-63\n",
      "  1.68244944e-05]\n",
      " [1.00000000e+00 1.46349520e-91 6.88872497e-77 1.01552039e-63\n",
      "  1.68244944e-05]]\n",
      "Loss: \n",
      " 0.18325090006756448\n",
      "+---------EPOCH 800---------+\n",
      "Input: \n",
      " [[41.  0.  2. ...  0.  0.  1.]\n",
      " [67.  1.  2. ...  1.  0.  2.]\n",
      " [51.  1.  0. ...  0.  1.  1.]\n",
      " ...\n",
      " [53.  0.  1. ...  0.  0.  1.]\n",
      " [65.  0.  2. ...  0.  1.  1.]\n",
      " [51.  0.  2. ...  0.  0.  1.]]\n",
      "Actual Output: \n",
      " [[1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]]\n",
      "Predicted Output: \n",
      " [[1.00000000e+00 1.46349520e-91 6.88872497e-77 1.01552039e-63\n",
      "  2.06385542e-05]\n",
      " [1.00000000e+00 1.46349520e-91 6.88872497e-77 1.01552039e-63\n",
      "  2.06385542e-05]\n",
      " [1.00000000e+00 1.46349520e-91 6.88872497e-77 1.01552039e-63\n",
      "  2.06385542e-05]\n",
      " ...\n",
      " [1.00000000e+00 1.46349520e-91 6.88872497e-77 1.01552039e-63\n",
      "  2.06385542e-05]\n",
      " [1.00000000e+00 1.46349520e-91 6.88872497e-77 1.01552039e-63\n",
      "  2.06385542e-05]\n",
      " [1.00000000e+00 1.46349520e-91 6.88872497e-77 1.01552039e-63\n",
      "  2.06385542e-05]]\n",
      "Loss: \n",
      " 0.18325082494275433\n",
      "+---------EPOCH 900---------+\n",
      "Input: \n",
      " [[41.  0.  2. ...  0.  0.  1.]\n",
      " [67.  1.  2. ...  1.  0.  2.]\n",
      " [51.  1.  0. ...  0.  1.  1.]\n",
      " ...\n",
      " [53.  0.  1. ...  0.  0.  1.]\n",
      " [65.  0.  2. ...  0.  1.  1.]\n",
      " [51.  0.  2. ...  0.  0.  1.]]\n",
      "Actual Output: \n",
      " [[1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]]\n",
      "Predicted Output: \n",
      " [[1.00000000e+00 1.46349520e-91 6.88872497e-77 1.01552039e-63\n",
      "  2.66859194e-05]\n",
      " [1.00000000e+00 1.46349520e-91 6.88872497e-77 1.01552039e-63\n",
      "  2.66859194e-05]\n",
      " [1.00000000e+00 1.46349520e-91 6.88872497e-77 1.01552039e-63\n",
      "  2.66859194e-05]\n",
      " ...\n",
      " [1.00000000e+00 1.46349520e-91 6.88872497e-77 1.01552039e-63\n",
      "  2.66859194e-05]\n",
      " [1.00000000e+00 1.46349520e-91 6.88872497e-77 1.01552039e-63\n",
      "  2.66859194e-05]\n",
      " [1.00000000e+00 1.46349520e-91 6.88872497e-77 1.01552039e-63\n",
      "  2.66859194e-05]]\n",
      "Loss: \n",
      " 0.18325070584108646\n",
      "+---------EPOCH 1000---------+\n",
      "Input: \n",
      " [[41.  0.  2. ...  0.  0.  1.]\n",
      " [67.  1.  2. ...  1.  0.  2.]\n",
      " [51.  1.  0. ...  0.  1.  1.]\n",
      " ...\n",
      " [53.  0.  1. ...  0.  0.  1.]\n",
      " [65.  0.  2. ...  0.  1.  1.]\n",
      " [51.  0.  2. ...  0.  0.  1.]]\n",
      "Actual Output: \n",
      " [[1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]]\n",
      "Predicted Output: \n",
      " [[1.00000000e+00 1.46349520e-91 6.88872497e-77 1.01552039e-63\n",
      "  3.77361037e-05]\n",
      " [1.00000000e+00 1.46349520e-91 6.88872497e-77 1.01552039e-63\n",
      "  3.77361037e-05]\n",
      " [1.00000000e+00 1.46349520e-91 6.88872497e-77 1.01552039e-63\n",
      "  3.77361037e-05]\n",
      " ...\n",
      " [1.00000000e+00 1.46349520e-91 6.88872497e-77 1.01552039e-63\n",
      "  3.77361037e-05]\n",
      " [1.00000000e+00 1.46349520e-91 6.88872497e-77 1.01552039e-63\n",
      "  3.77361037e-05]\n",
      " [1.00000000e+00 1.46349520e-91 6.88872497e-77 1.01552039e-63\n",
      "  3.77361037e-05]]\n",
      "Loss: \n",
      " 0.1832504882483281\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    if (i == 0) or ((i+1) % 100 == 0):\n",
    "        print('+' + '---' * 3 + f'EPOCH {i+1}' + '---'*3 + '+')\n",
    "        print('Input: \\n', X_train)\n",
    "        print('Actual Output: \\n', y_train)\n",
    "        print('Predicted Output: \\n', str(NN.forward(X_train)))\n",
    "        print(\"Loss: \\n\", str(np.mean(np.square(y_train - NN.forward(X_train)))))\n",
    "        \n",
    "    NN.train(X_train,y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looks reasonable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Keras MMP <a id=\"Q4\"></a>\n",
    "\n",
    "Implement a Multilayer Perceptron architecture of your choosing using the Keras library. Train your model and report its baseline accuracy. Then hyperparameter tune at least two parameters and report your model's accuracy.\n",
    "Use the Heart Disease Dataset (binary classification)\n",
    "Use an appropriate loss function for a binary classification task\n",
    "Use an appropriate activation function on the final layer of your network.\n",
    "Train your model using verbose output for ease of grading.\n",
    "Use GridSearchCV to hyperparameter tune your model. (for at least two hyperparameters)\n",
    "When hyperparameter tuning, show you work by adding code cells for each new experiment.\n",
    "Report the accuracy for each combination of hyperparameters as you test them so that we can easily see which resulted in the highest accuracy.\n",
    "You must hyperparameter tune at least 5 parameters in order to get a 3 on this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_model(inputs=13):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(30, activation='relu', input_dim=inputs))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(5, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "X = pd.DataFrame(heartdisease['data'])\n",
    "X = X.fillna(value=0.0).values\n",
    "y = heartdisease['target']\n",
    "y = to_categorical(y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.33, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 54. ,   1. ,   1. , 124. , 266. ,   1. ,   0. , 109. ,   1. ,\n",
       "         2.2,   1. ,   1. ,   2. ])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 203 samples\n",
      "Epoch 1/20\n",
      "203/203 [==============================] - 0s 594us/sample - loss: 12.5151 - accuracy: 0.1133\n",
      "Epoch 2/20\n",
      "203/203 [==============================] - 0s 30us/sample - loss: 11.4018 - accuracy: 0.1823\n",
      "Epoch 3/20\n",
      "203/203 [==============================] - 0s 31us/sample - loss: 11.0922 - accuracy: 0.1478\n",
      "Epoch 4/20\n",
      "203/203 [==============================] - 0s 33us/sample - loss: 10.7278 - accuracy: 0.1133\n",
      "Epoch 5/20\n",
      "203/203 [==============================] - 0s 37us/sample - loss: 10.5296 - accuracy: 0.1330\n",
      "Epoch 6/20\n",
      "203/203 [==============================] - 0s 33us/sample - loss: 10.3746 - accuracy: 0.1626\n",
      "Epoch 7/20\n",
      "203/203 [==============================] - 0s 31us/sample - loss: 10.2205 - accuracy: 0.1379\n",
      "Epoch 8/20\n",
      "203/203 [==============================] - 0s 32us/sample - loss: 10.0424 - accuracy: 0.1724\n",
      "Epoch 9/20\n",
      "203/203 [==============================] - 0s 36us/sample - loss: 9.8871 - accuracy: 0.1773\n",
      "Epoch 10/20\n",
      "203/203 [==============================] - 0s 32us/sample - loss: 9.8102 - accuracy: 0.1823\n",
      "Epoch 11/20\n",
      "203/203 [==============================] - 0s 33us/sample - loss: 9.7523 - accuracy: 0.1724\n",
      "Epoch 12/20\n",
      "203/203 [==============================] - 0s 35us/sample - loss: 9.7024 - accuracy: 0.1626\n",
      "Epoch 13/20\n",
      "203/203 [==============================] - 0s 29us/sample - loss: 9.6320 - accuracy: 0.2069\n",
      "Epoch 14/20\n",
      "203/203 [==============================] - 0s 33us/sample - loss: 9.6161 - accuracy: 0.1921\n",
      "Epoch 15/20\n",
      "203/203 [==============================] - 0s 32us/sample - loss: 9.5727 - accuracy: 0.1970\n",
      "Epoch 16/20\n",
      "203/203 [==============================] - 0s 31us/sample - loss: 9.5583 - accuracy: 0.1823\n",
      "Epoch 17/20\n",
      "203/203 [==============================] - 0s 40us/sample - loss: 9.5623 - accuracy: 0.1872\n",
      "Epoch 18/20\n",
      "203/203 [==============================] - 0s 30us/sample - loss: 9.5498 - accuracy: 0.1823\n",
      "Epoch 19/20\n",
      "203/203 [==============================] - 0s 29us/sample - loss: 9.5503 - accuracy: 0.1675\n",
      "Epoch 20/20\n",
      "203/203 [==============================] - 0s 28us/sample - loss: 9.5220 - accuracy: 0.1675\n",
      "100/100 [==============================] - 0s 312us/sample - loss: 9.0580 - accuracy: 0.2000\n",
      "accuracy: 20.000000298023224\n"
     ]
    }
   ],
   "source": [
    "model = base_model()\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=20)\n",
    "scores = model.evaluate(X_val, y_val)\n",
    "print(f'{model.metrics_names[1]}: {scores[1]*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimators = []\n",
    "# estimators.append(('standardize', StandardScaler()))\n",
    "model = KerasClassifier(build_fn=base_model, verbose=0)\n",
    "# pipeline = Pipeline(estimators)\n",
    "param_grid = {'batch_size': [10, 20, 40, 60, 80, 120],\n",
    "          'epochs': [20]}\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1)\n",
    "grid_result = grid.fit(X, y)\n",
    "# kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "# cvscores = []\n",
    "# for train, test in kfold.split(X, y):\n",
    "#     model = base_model(inputs=13)\n",
    "#     model.fit(X[train], y[train], epochs=150, batch_size=20, verbose=0)\n",
    "#     scores = model.evaluate(X[test], y[test], verbose=0)\n",
    "#     print(f'{model.metrics_names[1]}: {(scores[1]*100):.2f}%')\n",
    "#     cvscores.append(scores[1]*100)\n",
    "\n",
    "# print(f'{np.mean(cvscores):.2f}% +/- {np.std(cvscores):.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.41584159930547077 using {'batch_size': 10, 'epochs': 20}\n",
      "Means: 0.41584159930547077, Stdev: 0.1610750489913242 with: {'batch_size': 10, 'epochs': 20}\n",
      "Means: 0.2706270714600881, Stdev: 0.18333920990084213 with: {'batch_size': 20, 'epochs': 20}\n",
      "Means: 0.277227724591891, Stdev: 0.21142729609902622 with: {'batch_size': 40, 'epochs': 20}\n",
      "Means: 0.2805280536413193, Stdev: 0.2096164336235203 with: {'batch_size': 60, 'epochs': 20}\n",
      "Means: 0.26072607934474945, Stdev: 0.18190778532074292 with: {'batch_size': 80, 'epochs': 20}\n",
      "Means: 0.3300330173224211, Stdev: 0.21332492908764966 with: {'batch_size': 120, 'epochs': 20}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.5412541429201762 using {'batch_size': 10, 'epochs': 60}\n",
      "Means: 0.13861386477947235, Stdev: 0.037046113647242716 with: {'batch_size': 10, 'epochs': 20}\n",
      "Means: 0.257425744086504, Stdev: 0.22330336981061608 with: {'batch_size': 10, 'epochs': 40}\n",
      "Means: 0.5412541429201762, Stdev: 0.02333685050997706 with: {'batch_size': 10, 'epochs': 60}\n",
      "Means: 0.30363036692142487, Stdev: 0.19153291541841347 with: {'batch_size': 10, 'epochs': 80}\n",
      "Means: 0.41584159433841705, Stdev: 0.18363601775050853 with: {'batch_size': 10, 'epochs': 100}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'batch_size': [10],\n",
    "          'epochs': [20, 40, 60, 80, 100]}\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1)\n",
    "grid_result = grid.fit(X, y)\n",
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nteract": {
   "version": "0.14.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
