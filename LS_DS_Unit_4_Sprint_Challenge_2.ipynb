{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2*\n",
    "\n",
    "# Sprint Challenge - Neural Network Foundations\n",
    "\n",
    "Table of Problems\n",
    "\n",
    "1. [Defining Neural Networks](#Q1)\n",
    "2. [Chocolate Gummy Bears](#Q2)\n",
    "    - Perceptron\n",
    "    - Multilayer Perceptron\n",
    "4. [Keras MMP](#Q3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Q1\"></a>\n",
    "## 1. Define the following terms:\n",
    "\n",
    "- **Neuron:** The biological unit that allows and uses electrochemical signals to pass information from one part of a system to another (or in the bio case, brain). Has things called dendrites that connect to axon terminals via axons surrounded by myelin sheathes, inside the cell body next to the dendrites is the nucleus which determines whether or not to pass a signal. Remove all the bio stuff and you got the computer stuff ayo\n",
    "\n",
    "- **Input Layer:** Nodes (visible) which consist of received data from a dataset (or whatever input medium we want to use).\n",
    "\n",
    "- **Hidden Layer:** Nodes which are 'invisible' to us. They receive input from input node, or another hidden node's output among maybe more exotic cases. They typically help increase the accuracy of the model by allowing the neural network to adapt to more non-linear problems.\n",
    "\n",
    "- **Output Layer:** Three forms of an output layer: Regression, Binary, Multiclass. All have a special activation function, sometimes called an transfer, to determine if the output should be passed along to affect the outcome or not.\n",
    "\n",
    "- **Activation:** An activation function, or transfer function, can update weights using back propogation to create a better outcome. An activation function at its core is typically the same throughout all layers of the NN. It determines how much signal to 'transfer' to the next layer...doesn't seem to be a 1 or 0 type of situation strictly but instead a _long_ number between two values, ala tan, relu, etc.\n",
    "\n",
    "- **Backpropagation:** when you take the derivatives of the activation functions and somehow use that to influence the weight so that the errors in the model can be minimized. So, it basically 'trains' our model for us.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Chocolate Gummy Bears <a id=\"Q2\"></a>\n",
    "\n",
    "Right now, you're probably thinking, \"yuck, who the hell would eat that?\". Great question. Your candy company wants to know too. And you thought I was kidding about the [Chocolate Gummy Bears](https://nuts.com/chocolatessweets/gummies/gummy-bears/milk-gummy-bears.html?utm_source=google&utm_medium=cpc&adpos=1o1&gclid=Cj0KCQjwrfvsBRD7ARIsAKuDvMOZrysDku3jGuWaDqf9TrV3x5JLXt1eqnVhN0KM6fMcbA1nod3h8AwaAvWwEALw_wcB). \n",
    "\n",
    "Let's assume that a candy company has gone out and collected information on the types of Halloween candy kids ate. Our candy company wants to predict the eating behavior of witches, warlocks, and ghosts -- aka costumed kids. They shared a sample dataset with us. Each row represents a piece of candy that a costumed child was presented with during \"trick\" or \"treat\". We know if the candy was `chocolate` (or not chocolate) or `gummy` (or not gummy). Your goal is to predict if the costumed kid `ate` the piece of candy. \n",
    "\n",
    "If both chocolate and gummy equal one, you've got a chocolate gummy bear on your hands!?!?!\n",
    "![Chocolate Gummy Bear](https://ed910ae2d60f0d25bcb8-80550f96b5feb12604f4f720bfefb46d.ssl.cf1.rackcdn.com/3fb630c04435b7b5-2leZuM7_-zoom.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "candy = pd.read_csv('chocolate_gummy_bears.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chocolate</th>\n",
       "      <th>gummy</th>\n",
       "      <th>ate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   chocolate  gummy  ate\n",
       "0          0      1    1\n",
       "1          1      0    1\n",
       "2          0      1    1\n",
       "3          0      0    0\n",
       "4          1      1    0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron\n",
    "\n",
    "To make predictions on the `candy` dataframe. Build and train a Perceptron using numpy. Your target column is `ate` and your features: `chocolate` and `gummy`. Do not do any feature engineering. :P\n",
    "\n",
    "Once you've trained your model, report your accuracy. Explain why you could not achieve a higher accuracy with a *simple perceptron*. It's possible to achieve ~95% accuracy on this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "# Start your candy perceptron here\n",
    "\n",
    "X = candy[['chocolate', 'gummy']].values\n",
    "y = candy['ate'].values\n",
    "X_tr = X[0:7500]\n",
    "y_tr = y[0:7500]\n",
    "X_tst = X[7500:10000]\n",
    "y_tst = y[7500:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perceptron\n",
    "# TEACHER class\n",
    "class Perceptron(object):\n",
    "  def __init__(self, rate = 0.01, niter = 10):\n",
    "    self.rate = rate\n",
    "    self.niter = niter\n",
    "\n",
    "  def fit(self, X, y):\n",
    "    \"\"\"Fit training data\n",
    "    X : Training vectors, X.shape : [#samples, #features]\n",
    "    y : Target values, y.shape : [#samples]\n",
    "    \"\"\"\n",
    "\n",
    "    # weights\n",
    "    self.weight = np.zeros(1 + X.shape[1])\n",
    "\n",
    "    # Number of misclassifications\n",
    "    self.errors = []  # Number of misclassifications\n",
    "\n",
    "    for i in range(self.niter):\n",
    "      err = 0\n",
    "      for xi, target in zip(X, y):\n",
    "        delta_w = self.rate * (target - self.predict(xi))\n",
    "        self.weight[1:] += delta_w * xi\n",
    "        self.weight[0] += delta_w\n",
    "        err += int(delta_w != 0.0)\n",
    "      self.errors.append(err)\n",
    "    return self\n",
    "\n",
    "  def net_input(self, X):\n",
    "    \"\"\"Calculate net input\"\"\"\n",
    "    return np.dot(X, self.weight[1:]) + self.weight[0]\n",
    "\n",
    "  def predict(self, X):\n",
    "    \"\"\"Return class label after unit step\"\"\"\n",
    "    return np.where(self.net_input(X) >= 0.0, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "pn = Perceptron(0.05, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Perceptron at 0x7f6cbd177630>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pn.fit(X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pn.predict(X_tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5048"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(pred, y_tst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HIghest score w/ single layer is 50.48% it's probably XOR that's why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEGCAYAAACUzrmNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deZgV9Z3v8feHVUSgVUCBRnEhuC/YGhOSqJjEiRBcUTNjEk1yvePkRm8yo4l5ZsbJNuOMNxk1kycTk2jimEQaVFTiGhXNpnIacMEVt3QDSiMCskP39/5R1Xhouk/XgT7n9PJ5Pc95+tSv6lR9+Wn399TvV/UtRQRmZmaF9Kl0AGZm1vU5WZiZWYecLMzMrENOFmZm1iEnCzMz61C/SgdQKsOHD49x48ZVOgwzs26jrq5uRUSMaGtdj00W48aNI5fLVToMM7NuQ9Kb7a3zMJSZmXXIycLMzDrkZGFmZh1ysjAzsw45WZiZWYd67NVQVnqzFyzh2gdeYumqDYyuGsQVp03gzGPHVDqsLsv9VRz3V3FK3V9OFrZTZi9YwlV3PMuGLU0ALFm1gavueBbAv9BtcH8Vx/1VnHL0l5OF7ZRrH3hp2/+YLTZsaeKfZj/Ha41rKxRV13XzH99wfxXB/VWc9vrr2gdecrKwylq6akOb7e9t2soPH11c5mi6vvYeG+P+apv7qzjt9Vd7v6c7w8nCdsroqkEsaeN/xDFVg/jjNyZXIKKubdI1j7i/iuD+Kk57/TW6alCnHcNXQ9lOueK0CUjbtw3q35crTptQmYC6uCtOm8Cg/n23a3N/tc/9VZxy9JfPLGynTNh3CBEwbFA/1mzY6qtVOtDSL766Jxv3V3HK0V/qqc/grqmpCRcSLJ1v3bOIXz3xF5785qnsOXhApcMxs04gqS4iatpa52EoK9qmrU3MXrCETxy2jxOFWS/hZGFF+93zy3l3/RbOO35spUMxszJxsrCizcjVM3rYbnzk4OGVDsXMysTJwoqydNUGfv9KI+ceV03fPur4A2bWIzhZWFFm1TUQAdNrPARl1ps4WVhmzc3BzLp6PnzQ3ozda/dKh2NmZeRkYZk98do71K/cwPme2DbrdZwsLLPaXD1DduvHaYfvW+lQzKzMnCwsk9UbtnDfc29x5jFj2K1VWQEz6/lKniwk9ZW0QNKcdPn3khamr6WSZqftknSDpMWSnpE0sdV+hkpaIum/Sh2z7ejup5eyaWsz53li26xXKkdtqMuBF4ChABHx0ZYVkm4H7koXPwWMT18fBH6c/mzxHeCxMsRrbaidV8+ho4ZyxJihlQ7FzCqgpGcWkqqBKcDP2lg3BJgMzE6bzgBuicQTQJWkUem2xwH7AA+WMl5r2/NL1/DsktWcV1ONWpeaNbNeodTDUNcBVwLNbaw7C3g4Itaky2OA+rz1DcAYSX2A7wNXdHQwSZdIyknKNTY27lrktk1trp4Bfftw5jGu+GnWW5UsWUiaCiyPiLp2NvkM8Jv8j7SxTQB/B9wbEfVtrN9+44gbI6ImImpGjBhRdMy2o01bm5i9cAmfONxFA816s1LOWUwCpkk6HdgNGCrp1oi4UNLewAkkZxctGoD82dNqYCnwIeCjkv4O2AMYIGltRHyjhLFb6qHn32bV+i2c74lts16tZGcWEXFVRFRHxDjgAuCRiLgwXT0dmBMRG/M+cjfwufSqqBOB1RGxLCL+JiL2S/fzDyTzGk4UZTJjXj1jqgYxyUUDzXq1St1ncQHbD0EB3Au8BiwGfkoy/GQVtGTVBv6weAXnuGigWa9XlseqRsRcYG7e8sltbBPAlzvYzy+AX3RmbNa+Wbm0aOBx1ZUOxcwqzHdwW5taigZOOthFA83MycLa8efX3qHh3Q2+Y9vMACcLa0dtrp6hLhpoZiknC9vB6vVp0cBjXTTQzBJOFraDu59ewmYXDTSzPE4WtoMZuXoOGzWUI8YMq3QoZtZFdJgsJB0kaWD6/mRJl0mqKn1oVgmLlq7muSVrOK/Gl8ua2fuynFncDjRJOhj4OXAA8OuSRmUVMzPXwIB+fTjzWBcNNLP3ZUkWzRGxlaSO03UR8VVgVGnDskrYuKWJOxcs4bTD96VqdxcNNLP3ZUkWWyR9Bvg8MCdt61+6kKxSHnr+bVZv2OIhKDPbQZZkcTFJ5dfvRcTrkg4Abi1tWFYJtbm0aOBBLhpoZtvrsDZURDwPXJa3/DpwTSmDsvJreHc9f1i8gssmj6ePiwaaWSsdJgtJk4B/AfZPtxdJ3b8DSxualdOsugYApnsIyszakKXq7M+BrwJ1QFNpw7FKaG4OZuYamHTQcKr3dNFAM9tRlmSxOiLuK3kkVjF/evUdlqzawNc/dUilQzGzLipLsnhU0rXAHcCmlsaImF+yqKysanP1DBvUn08etk+lQzGzLipLsvhg+rMmry2AyZ0fjpXb6vVbuH/RW3zm+LEuGmhm7cpyNdQp5QjEKuOutGjgdBcNNLMCstSGGibpB5Jy6ev7klxhroeYMa+ew0e7aKCZFZblprybgPeA89LXGuDmUgZl5fHcktUsWrqG84/3WYWZFZZlzuKgiDgnb/lbkhaWKiArn5m5egb068MZR7tooJkVluXMYoOkj7QspDfpbShdSFYOG7c0MXvhUv7q8H0ZtrtLfZlZYVnOLC4FfpnOUwhYCVxUyqCs9B7cVjTQQ1Bm1rEsV0MtBI6WNDRdXlPyqKzkauclRQM/fNDelQ7FzLqBdpOFpAsj4lZJX2vVDkBE/CDLAST1BXLAkoiYKun3wJB09UjgqYg4U8mOrwdOB9YDF0XEfEnHAD8GhpKUG/leRMwo5h9p26tfuZ4/vrqCy0910UAzy6bQmcXg9OeQNtZFEce4HHiB5I89EfHRlhWSbgfuShc/BYxPXx8kSRAfJEkcn4uIVySNBuokPRARq4qIwfK0FA089zgXDTSzbNpNFhHxk/Tt7yLij/nr0knuDkmqBqYA3wNan6EMIbkL/OK06QzglogI4AlJVZJGRcTLeTEtlbQcGAE4WeyE5uZgVl0DHznYRQPNLLssV0P9MGNbW64DrgSa21h3FvBw3hzIGKA+b31D2raNpBOAAcCrbR1M0iUtNw82NjZmDLF3+eOrK1iyaoMnts2sKIXmLD4EfBgY0WreYijQYREhSVOB5RFRJ+nkNjb5DPCz/I+0sc224S5Jo4D/AT4fEW0lHyLiRuBGgJqammKGynqN2lwDwwb15xMuGmhmRSh0ZjEA2IMkoQzJe60Bzs2w70nANElvALcBkyXdCiBpb+AE4Ld52zcA+V93q4Gl6fZD023/MSKeyHBsa8Oq9Zt5YNFbnHXsGBcNNLOiFJqzeAx4TNIvIuLNYnccEVcBVwGkZxb/EBEXpqunA3MiYmPeR+4G/o+k20gmtldHxDJJA4A7SeYzZhYbh73vroVL06KBntg2s+JkuSlvffo8i8OB3VoaI2JXSpRfwI7P8b6X5LLZxSRXQLVMfJ8HfAzYW9JFadtF6f0fVoQZ8+o5YsxQDh/tooFmVpwsyeJXwAxgKvC3wOeBomaPI2IuMDdv+eQ2tgngy2203wrcWszxbEfPLVnN88vW8J0zDq90KGbWDWW5GmrviPg5sCUiHouILwAnljgu62S1adHAaS4aaGY7IcuZxZb05zJJU0gmnT3o3Y1s3NLE7AVL+NQRLhpoZjsnS7L4blpE8O9J7q8YCny1pFFZp3pg0Vus2bjV91aY2U7LUkhwTvp2NeBHrHZDtbl6qvccxIcOdNFAM9s5WR6r+ktJVXnLe0q6qbRhWWepX7mePy5+h+nHjXXRQDPbaVkmuI/KL9oXEe8Cx5YuJOtMM+sakOBc31thZrsgS7LoI2nPlgVJe5FtrsMqrKk5mJWr5yMHD2dM1aBKh2Nm3ViWP/rfB/4kaVa6PJ2kiqx1cX9cvIKlqzfyzSmHVjoUM+vmskxw3yIpR1JOXMDZEfF8ySOzXVabq6dqdxcNNLNdV6jq7NCIWJMOO70F/Dpv3V4RsbIcAdrOeXfdZh5c9DZ//cH9GNjPRQPNbNcUOrP4NUmJjzq2fzKe0uUDSxiX7aK7Fi5hc1Oz760ws05RKFm0FPo7tFV1WOviIoIZuQaOHDOMw0YPrXQ4ZtYDFLoa6vr055/KEYh1nkVL1/DCsjWcd7zPKsyscxQ6s9gi6WagWtINrVdGxGWlC8t2xYx59Qzs14dpR4+udChm1kMUShZTgY+TXAVVV55wbFdt3NLE7IVp0cBBLhpoZp2j0JPyVgC3SXohIp4uY0y2Cx5Y9BbvuWigmXWyQpfOXhkR/wF8SVK0Xu9hqK5pxrx6xu41iBNdNNDMOlGhYagX0p+5cgRiu65+5Xr+9Oo7fO0TH3DRQDPrVIWGoe5Jf/6ypU1SH2CPiFhThtisSDNz9UnRwONcNNDMOleWEuW/ljRU0mDgeeAlSVeUPjQrRlNzMKuugY+OH8FoFw00s06WpersYemZxJnAvcB+wGdLGpUV7Q9p0cDzPbFtZiWQJVn0l9SfJFncFRFb2L78h3UBtbl69ty9Px8/bGSlQzGzHihLsvgJ8AYwGHhc0v6A5yy6kHfXbeahRW9z5rFjXDTQzEqiw2QRETdExJiIOD0Sb1LEs7gl9ZW0QNKcdPn3khamr6WSZqftknSDpMWSnpE0MW8fn5f0Svr6/E78O3u02WnRwPNd3sPMSiTLBPfl6QS3JP1c0nySu7qzupz3L8MlIj4aEcdExDHAn4E70lWfAsanr0uAH6fH3wu4GvggcAJwdf6T+3q7iGDGvHqOqh7GIfu6aKCZlUaWYagvpBPcnwRGABfzfkXagiRVA1OAn7WxbghJ0pmdNp0B3JKevTwBVEkaBZwGPBQRK9Pnfz8E/FWW4/cGzy5ZzYtvvec7ts2spLIki5a7u04Hbk5Lf2S94+s64EqguY11ZwEP592zMQaoz1vfkLa1124kE9sD+/Xh0y4aaGYllCVZ1El6kCRZPJCeEbT1x387kqYCyyOivSKEnwF+k/+RNraJAu1tHfMSSTlJucbGxo5C7PY2bmniroVLOf3IUS4aaGYllSVZfBH4BnB8RKwHBpAMRXVkEjBN0hvAbcBkSbcCSNqbZP7ht3nbNwD5YynVwNIC7TuIiBsjoiYiakaMGJEhxO7t/ueSooHTa3zHtpmVVparoZqB14EPSPoYcDhQleFzV0VEdUSMAy4AHomIC9PV04E5rZ7AdzfwuXQi/URgdUQsAx4APilpz3Ri+5NpW683Y149++21Oyce4KKBZlZahQoJAiDpSyRXNFUDC4ETSa5iKuaKqNYuYMdJ8ntJhroWA+tJz14iYqWk7wDz0u2+HRErd+HYPcJf3lnPn197h7930UAzK4MOkwVJojgeeCIiTpF0CPCtYg4SEXOBuXnLJ7exTQBfbufzNwE3FXPMnm5mXVo00ENQZlYGWeYsNrYMF0kaGBEvAhNKG5YV0lI08GPjRzBqmIsGmlnpZUkWDZKqSO6HeEjSXbQzwWzl8ftXGlm2eqPv2DazsulwGCoizkrf/oukR4FhwP0ljcoKmplrYK/BA/j4oftUOhQz6yUKPVZ1rzaan01/7gH0+knmSli5bjMPPv8Wnz1xHAP6ZTkxNDPbdYXOLOrY8aa4luUADixhXNaO2QuWsKUpPARlZmVV6LGqB5QzEOtYRFCbq+fo6mFM2HdIpcMxs14kS9XZsyQNy1uuknRmacOytjzTkBYN9FmFmZVZlkHvqyNidctCRKwiKRluZVabq2e3/i4aaGbllyVZtLVNlpv5rBNt2NzE3QuXcvoRoxi6m4sGmll5ZUkWOUk/kHSQpAMl/SfJ5LeV0f2LlvHepq1M93MrzKwCsiSLrwCbgRnATGAj7ZTlsNKZMa+e/ffenRMPbOuKZjOz0spyU946khLlSOoLDE7brEzefGcdT7y2kn/45AeQXDTQzMovy9VQv06fwT0YWAS8JOmK0odmLWbmGugjOPc4D0GZWWVkGYY6LH306ZkkZcT3Az5b0qhsm5aigSd9YAT7Dtut0uGYWS+VJVn0l9SfJFncFRFbaOexptb5Hn+lkbfWbOQ8T2ybWQVlSRY/Ad4ABgOPS9ofWFPKoOx9M3P17DV4AKe6aKCZVVCWx6reEBFjIuL0SLwJnFKG2Hq9d9Zu4qHn3+asY8e4aKCZVVShqrMXRsStkr7WziY/KFFMlrozLRroISgzq7RCl84OTn+6Yl0FbCsaOLbKRQPNrOIKVZ39SfqzqOdtW+d4umE1L7+9ln8968hKh2Jm1vFNeZIOILmLe1z+9hExrXRhWUvRwKlHj6p0KGZmmQoCzgZ+DtwDNJc2HIOkaOA9C5dy+pEuGmhmXUOWZLExIm4oeSS2zX3PJUUDPbFtZl1FlmRxvaSrgQeBTS2NETG/ZFH1cjPm1TNu79354AEuGmhmXUOWZHEkSXmPybw/DBXpcofS4oM5YElETFVSCe+7wHSgCfhxRNwgaU/gJuAgksq2X4iI59J9fBX4UnrcZ4GLI2Jjtn9i9/LGinU8+fpKrjhtgosGmlmXkSVZnAUcGBGbd/IYlwMvAEPT5YuAscAhEdEsaWTa/k1gYUScJekQ4EfAqZLGAJeR1KjaIKkWuAD4xU7G06XNrKunj+CcidWVDsXMbJsstwU/DVTtzM4lVQNTgJ/lNV8KfDsimgEiYnnafhjwcNr2IjBOUkuNi37AIEn9gN2BpTsTT1fXUjTw5AkjXTTQzLqULMliH+BFSQ9IurvllXH/1wFXsv1VVAcB50vKSbpP0vi0/WngbABJJwD7A9URsQT4f8BfgGXA6oh4MOPxu5XHX27k7TWbOK/GZxVm1rVkGYa6emd2LGkqsDwi6iSdnLdqIMkVVjWSziaZp/gocA3JZPpCknmJBcDWdC7jDOAAYBUws6UUSRvHvAS4BGC//fbbmbArqjZXz96DBzD5EBcNNLOuJcuT8h7byX1PAqZJOh3YDRgq6VagAbg93eZO4Ob0OGuAiwHSSfDX09dpwOsR0ZiuuwP4MLBDsoiIG4EbAWpqarpVGfV31m7idy+8zec/NM5FA82syynZX6WIuCoiqiNiHMmE9CMRcSHJTX4tV1KdBLwMIKlK0oC0/UvA42kC+QtwoqTd0yRyKsmEeY+yrWjg8b63wsy6nizDUJ3tGuBX6eWwa0kSA8ChwC2SmoDngS8CRMSTkmYB84GtJMNTN5Y96hKKCGbMq+eYsVV8YB8XDTSzrqdQifKHI+JUSf8eEV/flYNExFxgbvp+FckVUq23+TMwvnV7uu5qdnLupDtYWL+KV5av5d/OdtFAM+uaCp1ZjJJ0Esm8w23AdneI+Q7uzlOba2BQ/75MPcpFA82sayqULP4Z+AZQzY4POsp8B7cVtn7zVu55OikaOMRFA82siyr0PItZwCxJ/xQR3yljTL3Kfc++xdpNW31vhZl1aVkunf2OpGnAx9KmuRExp7Rh9R4zcvUcMHwwJ7hooJl1YR1eOivp30jqOz2fvi5P22wXvb5iHU+9vpLpNdUuGmhmXVqWS2enAMe01HKS9EuSy1evKmVgvcHMnIsGmln3kPWmvPxCgsNKEUhvs7WpmdvnN3DKhJHsM9RFA82sa8tyZvFvwAJJj5JcPvsxfFaxyx5/JSka+K1pvmPbzLq+LBPcv5E0FzieJFl8PSLeKnVgPV3tvAaG7zGAUw8d2fHGZmYVlqncR0QsA7KWJbcOrEiLBl48aRz9+7pooJl1ff5LVQF3zl/C1ubgvBoPQZlZ9+BkUWYRQW2unmP3q2K8iwaaWTdRMFlI6iPpuXIF0xssSIsGnu+zCjPrRgomi/Teiqcldb/HznVRM3P1DOrflykuGmhm3UiWCe5RwCJJTwHrWhojYlrJouqhkqKBy5hylIsGmln3kiVZfKvkUfQS924rGughKDPrXjI9g1vS/sD4iPidpN2BvqUPreepnVfPgcMHc/y4PSsdiplZUbIUEvxfwCzgJ2nTGJLnaFsRXmtcy1NvrGR6zVgXDTSzbifLpbNfBiYBawAi4hXAtx0XaWZdA337iHMmjql0KGZmRcuSLDZFxOaWBUn9SJ6UZxltbWrm9roGTpkwgpEuGmhm3VCWZPGYpG8CgyR9ApgJ3FPasHqWx15uZPl7m5juiW0z66ayJItvAI3As8D/Bu4F/rGUQfU0M+bVM3yPAUw+xKN3ZtY9Zbkaqjl94NGTJMNPL0WEh6EyanxvE4+8uJwvfOQAFw00s26rw2QhaQrw38CrJCXKD5D0vyPivlIH1xPcuaAhLRrop+GZWfeV5avu94FTIuLkiDgJOAX4z6wHkNRX0gJJc9JlSfqepJclvSDpsrR9T0l3SnpG0lOSjsjbR5WkWZJeTD/zoeL+mZWRFA1sYOJ+VRw80kUDzaz7ypIslkfE4rzl14DlRRzjcuCFvOWLgLHAIRFxKHBb2v5NYGFEHAV8Drg+7zPXA/dHxCHA0a3212XN/8sqFi9fy/nHe2LbzLq3doehJJ2dvl0k6V6glmTOYjowL8vOJVUDU4DvAV9Lmy8F/jotUkhEtCSew0ge4UpEvChpnKR9gA0kj3K9KF23Gdh2KW9XNjNXz+4D+jLlqNGVDsXMbJcUOrP4dPraDXgbOAk4meTKqKz1Kq4DrgSa89oOAs6XlJN0n6TxafvTwNkAkk4A9geqgQPTY96cDmf9TNLgtg4m6ZJ0v7nGxsaMIZbGuk1buefppUw5chR7DMz0QEIzsy6r3b9iEXHxruxY0lSSIaw6SSfnrRoIbIyImvTs5Sbgo8A1wPWSFpJcprsA2Ar0ByYCX4mIJyVdT3I57z+1EfONwI0ANTU1Fb1i695nl7Fuc5OHoMysR8hyNdQBwFeAcfnbZyhRPgmYJul0krOToZJuBRqA29Nt7gRuTve3Brg4PaaA19PX7kBDRDyZfmYWSbLo0mpz9Rw4YjDH7e+igWbW/WWZ4J4NvAH8kOTKqJZXQRFxVURUR8Q44ALgkYi4MN3f5HSzk4CXYdsVTwPS9i8Bj0fEmoh4C6iXNCFddyrwfIa4K+a1xrXMe+NdznPRQDPrIbIMpm+MiBs68ZjXAL+S9FVgLUliADgUuEVSE0ky+GLeZ76SfmYAydVYuzREVmq1uaRo4NkuGmhmPUSWZHG9pKuBB4FNLY0RMT/rQSJiLjA3fb+K5Aqp1tv8GRjfuj1dtxCoyXq8Stra1Mzt8xs4ZcJIRg5x0UAz6xmyJIsjgc+SDB21XNUUvD+UZHnmvtRI43ubfMe2mfUoWZLFWcCB+WXKrX0zcvUM32Mgp7hooJn1IFkmuJ8GqkodSE+w/L2NPPLics6ZOMZFA82sR8lyZrEP8KKkeWw/Z9HRpbO9zp3zl9DUHH5uhZn1OFmSxdUlj6IHSIoG1nPc/nty8Mg9Kh2OmVmnyvI8i8fKEUh3N/8v7/Jq4zr+45yDKh2KmVmny3IH93u8/8ztASTlN9ZFxNBSBtbd1M5rSIsGjqp0KGZmnS7LmcV2D2KQdCZwQski6obWbdrKnGeWMvWoUQx20UAz64GKvmQnIvLLdRjwWxcNNLMeLssw1Nl5i31I7qT2M7jz1M5LigZO3M9FA82sZ8oyZvLpvPdbSYoKnlGSaLqhVxvXknvzXa761CEuGmhmPVaWOYsuXbSv0mpz9fTtI85y0UAz68EKPVb1nwt8LiLiOyWIp1vZ0tTM7XVLmHyIiwaaWc9W6MxiXRttg0lKh+8N9PpkMfelRlas3cR5vmPbzHq4Qo9V3faAI0lDgMtJniNxGxkeftQbzJhXz4ghAzllwohKh2JmVlIFL52VtJek7wLPkCSWiRHx9YhYXpbourDl723k0ZeWc/bEMfRz0UAz6+EKzVlcC5wN3AgcGRFryxZVN3BHWjTQQ1Bm1hsU+kr898Bo4B+BpZLWpK/3JK0pT3hdU0vRwJr99+SgES4aaGY9X6E5C4+ttKPuzXd5rXEdf3uuiwaaWe/ghLATanP1DB7QlylHumigmfUOThZFWrtpK3OeWcbUo0a7aKCZ9RpOFkW695llrN/cxHkuGmhmvYiTRZFm5Oo5aMRgJu7nx5KbWe/hZFGExcvXUvfmu5x//FgXDTSzXqXkyUJSX0kLJM1JlyXpe5JelvSCpMvS9j0l3SnpGUlPSTqi0H4qYWaunn59xFnHVlcqBDOziijHDO3lwAtAy2NYLwLGAodERLOkkWn7N4GFEXGWpEOAHwGnFthPWW1paub2+Q1MPmQkI4YMrEQIZmYVU9IzC0nVwBTgZ3nNlwLfjohmgLzSIYcBD6dtLwLjJO1TYD9l9eiLy1mxdrPv2DazXqnUw1DXAVcCzXltBwHnS8pJuk/S+LT9aZLyIkg6AdgfqC6wnx1IuiTdb66xsbET/xnJvRUjhgzkZBcNNLNeqGTJQtJUYHlE1LVaNRDYGBE1wE+Bm9L2a4A9JS0EvgIsALYW2M8OIuLGiKiJiJoRIzrvj/ryNRt59KVGzplY7aKBZtYrlXLOYhIwTdLpwG7AUEm3Ag3A7ek2dwI3A0TEGpIS6Ci51Oj19HVBW/uJiAtLGPt2bt9WNNAT22bWO5Xsa3JEXBUR1RExjuQP/iPpH/jZwOR0s5OAlwEkVUkakLZ/CXg8ItYU2E9ZRAQzc/WcMG4vDnTRQDPrpSpRr+Ia4FeSvgqsJUkMAIcCt0hqAp4neSJfxeXefJfXVqzj0pNdNNDMeq+yJIuImAvMTd+vIrmyqfU2fwbGt25vbz/lUjsvLRp4lIsGmlnv5dnaAtZu2spvn13Gp48eze4DXDTQzHovJ4sCfvvMUhcNNDPDyaKgGfPqOXjkHhw71kUDzax3c7Jox+Ll7zH/L6s4v8ZFA83MnCzaUZtrSIoGThxT6VDMzCrOyaINW5qauWN+A6ceOpLhe7hooJmZk0UbHnHRQDOz7ThZtKF2Xj0jhwzkpA+4aKCZGThZbGf2giWc+K8P8/CLy1m/uYk5zyyrdEhmZl2C7zRLzV6whKvueJYNW5qA5Ia8q+54FoAzj/Ukt5n1bj6zSF37wEvbEkWLDVuauPaBlyoUkZlZ1+FkkVq6akNR7WZmvYmTRWp01aCi2s3MehMni9QVp01gUP++27UN6ujo+K8AAAZfSURBVN+XK06bUKGIzMy6Dk9wp1omsa994CWWrtrA6KpBXHHaBE9um5nhZLGdM48d4+RgZtYGD0OZmVmHnCzMzKxDThZmZtYhJwszM+uQk4WZmXVIEVHpGEpCUiPw5k5+fDiwohPD6SyOqziOqziOqzg9Ma79I6LNcts9NlnsCkm5iKipdBytOa7iOK7iOK7i9La4PAxlZmYdcrIwM7MOOVm07cZKB9AOx1Ucx1Ucx1WcXhWX5yzMzKxDPrMwM7MOOVmYmVmHem2ykHSTpOWSnmtnvSTdIGmxpGckTewicZ0sabWkhenrn8sU11hJj0p6QdIiSZe3sU3Z+yxjXGXvM0m7SXpK0tNpXN9qY5uBkmak/fWkpHFdJK6LJDXm9deXSh1X3rH7SlogaU4b68reXxnjqkh/SXpD0rPpMXNtrO/c38eI6JUv4GPAROC5dtafDtwHCDgReLKLxHUyMKcC/TUKmJi+HwK8DBxW6T7LGFfZ+yztgz3S9/2BJ4ETW23zd8B/p+8vAGZ0kbguAv6r3P+Ppcf+GvDrtv57VaK/MsZVkf4C3gCGF1jfqb+PvfbMIiIeB1YW2OQM4JZIPAFUSRrVBeKqiIhYFhHz0/fvAS8ArR/+UfY+yxhX2aV9sDZd7J++Wl9Ncgbwy/T9LOBUSeoCcVWEpGpgCvCzdjYpe39ljKur6tTfx16bLDIYA9TnLTfQBf4IpT6UDiPcJ+nwch88Pf0/luRbab6K9lmBuKACfZYOXSwElgMPRUS7/RURW4HVwN5dIC6Ac9Khi1mSxpY6ptR1wJVAczvrK9JfGeKCyvRXAA9KqpN0SRvrO/X30cmifW19Y+kK38Dmk9RvORr4ITC7nAeXtAdwO/B/I2JN69VtfKQsfdZBXBXps4hoiohjgGrgBElHtNqkIv2VIa57gHERcRTwO97/Nl8ykqYCyyOirtBmbbSVtL8yxlX2/kpNioiJwKeAL0v6WKv1ndpfThbtawDyvyFUA0srFMs2EbGmZRghIu4F+ksaXo5jS+pP8gf5VxFxRxubVKTPOoqrkn2WHnMVMBf4q1artvWXpH7AMMo4BNleXBHxTkRsShd/ChxXhnAmAdMkvQHcBkyWdGurbSrRXx3GVaH+IiKWpj+XA3cCJ7TapFN/H50s2nc38Ln0ioITgdURsazSQUnat2WcVtIJJP8N3ynDcQX8HHghIn7QzmZl77MscVWizySNkFSVvh8EfBx4sdVmdwOfT9+fCzwS6cxkJeNqNa49jWQeqKQi4qqIqI6IcSST149ExIWtNit7f2WJqxL9JWmwpCEt74FPAq2voOzU38d+Ox1tNyfpNyRXyQyX1ABcTTLZR0T8N3AvydUEi4H1wMVdJK5zgUslbQU2ABeU+hcmNQn4LPBsOt4N8E1gv7zYKtFnWeKqRJ+NAn4pqS9JcqqNiDmSvg3kIuJukiT3P5IWk3xDvqDEMWWN6zJJ04CtaVwXlSGuNnWB/soSVyX6ax/gzvQ7UD/g1xFxv6S/hdL8Prrch5mZdcjDUGZm1iEnCzMz65CThZmZdcjJwszMOuRkYWZmHXKyMCuCpKa86qILJX2jE/c9Tu1UGzartF57n4XZTtqQlsow61V8ZmHWCdJnC/y7kmdFPCXp4LR9f0kPp0XmHpa0X9q+j6Q70+KGT0v6cLqrvpJ+quRZEw+md1kj6TJJz6f7ua1C/0zrxZwszIozqNUw1Pl569ZExAnAf5FUKiV9f0taZO5XwA1p+w3AY2lxw4nAorR9PPCjiDgcWAWck7Z/Azg23c/fluofZ9Ye38FtVgRJayNijzba3wAmR8RraWHDtyJib0krgFERsSVtXxYRwyU1AtV5BehaSqw/FBHj0+WvA/0j4ruS7gfWklTMnZ33TAqzsvCZhVnniXbet7dNWzblvW/i/XnFKcCPSCqa1qVVV83KxsnCrPOcn/fzz+n7P/F+wbu/Af6Qvn8YuBS2PYxoaHs7ldQHGBsRj5I8hKcK2OHsxqyU/O3ErDiD8qrbAtwfES2Xzw6U9CTJl7DPpG2XATdJugJo5P3Kn5cDN0r6IskZxKVAe+Wj+wK3ShpG8kCb/0yfRWFWNp6zMOsE6ZxFTUSsqHQsZqXgYSgzM+uQzyzMzKxDPrMwM7MOOVmYmVmHnCzMzKxDThZmZtYhJwszM+vQ/wd8ueh8OF7ypQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TEACHER graph\n",
    "plt.plot(range(1, len(pn.errors) + 1), pn.errors, marker='o')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Number of misclassifications')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer Perceptron <a id=\"Q3\"></a>\n",
    "\n",
    "Using the sample candy dataset, implement a Neural Network Multilayer Perceptron class that uses backpropagation to update the network's weights. Your Multilayer Perceptron should be implemented in Numpy. \n",
    "Your network must have one hidden layer.\n",
    "\n",
    "Once you've trained your model, report your accuracy. Explain why your MLP's performance is considerably better than your simple perceptron's on the candy dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teacher's function\n",
    "class NeuralNetwork:\n",
    "    def __init__(self):\n",
    "        # Set up Architecture of Neural Network\n",
    "        self.inputs = 2\n",
    "        self.hiddenNodes = 10\n",
    "        self.outputNodes = 7500\n",
    "\n",
    "        # Initial Weights\n",
    "        # 2x3 Matrix Array for the First Layer\n",
    "        # Arrows in first section\n",
    "        self.weights1 = np.random.rand(self.inputs, self.hiddenNodes)\n",
    "       \n",
    "        # 3x1 Matrix Array for Hidden to Output\n",
    "        # Arrows in second section\n",
    "        self.weights2 = np.random.rand(self.hiddenNodes, self.outputNodes)\n",
    "    \n",
    "    def sigmoid(self, s):\n",
    "        return 1 / (1+np.exp(-s))\n",
    "    \n",
    "    def sigmoidPrime(self, s):\n",
    "        # sigmoid derivative function\n",
    "        return s * (1 - s)\n",
    "    \n",
    "    def feed_forward(self, X):\n",
    "        \"\"\"\n",
    "        Calculate the NN inference using feed forward.\n",
    "        aka \"predict\"\n",
    "        \"\"\"\n",
    "        \n",
    "        # Weighted sum of inputs => hidden layer\n",
    "        self.hidden_sum = np.dot(X, self.weights1)\n",
    "        \n",
    "        # Activations of weighted sum\n",
    "        self.activated_hidden = self.sigmoid(self.hidden_sum)\n",
    "        \n",
    "        # Weight sum between hidden and output\n",
    "        self.output_sum = np.dot(self.activated_hidden, self.weights2)\n",
    "        \n",
    "        # Final activation of output\n",
    "        self.activated_output = self.sigmoid(self.output_sum)\n",
    "        \n",
    "        # Bias term is not here cause who cares lol\n",
    "        return self.activated_output\n",
    "    \n",
    "    def backward(self, X,y,o):\n",
    "        \"\"\"\n",
    "        Backward propagate through the network\n",
    "        \"\"\"\n",
    "        \n",
    "        # Error in Output\n",
    "        # Vector of errors\n",
    "        self.o_error = y - o\n",
    "        \n",
    "        # Apply Derivative of Sigmoid to error\n",
    "        # How far off are we in relation to the Sigmoid f(x) of the output\n",
    "        # ^- aka hidden => output\n",
    "        self.o_delta = self.o_error * self.sigmoidPrime(o)\n",
    "        \n",
    "        # z2 error\n",
    "        self.z2_error = self.o_delta.dot(self.weights2.T)\n",
    "        # How much of that \"far off\" can explained by the input => hidden\n",
    "        self.z2_delta = self.z2_error * self.sigmoidPrime(self.activated_hidden)\n",
    "        \n",
    "        # Adjustment to first set of weights (input => hidden)\n",
    "        self.weights1 += X.T.dot(self.z2_delta)\n",
    "        # Adjustment to second set of weights (hidden => output)\n",
    "        self.weights2 += self.activated_hidden.T.dot(self.o_delta)\n",
    "        \n",
    "\n",
    "    def train(self, X, y):\n",
    "        o = self.feed_forward(X)\n",
    "        self.backward(X,y,o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "nn = NeuralNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "L1|Wgt: \n",
      "[[0.47618984 0.21057162 0.26250326 0.74532633 0.49027424 0.77817953\n",
      "  0.94107578 0.08053633 0.07007087 0.08939121]\n",
      " [0.78572494 0.41812127 0.29058567 0.11690336 0.77262832 0.34304247\n",
      "  0.76056249 0.45170151 0.04291249 0.73172205]]\n",
      "L2|Wgt: \n",
      "[[4.12997515e-01 1.42580545e-01 1.47544230e-01 ... 9.15930307e-01\n",
      "  7.11220351e-01 6.37944479e-01]\n",
      " [3.86448556e-01 4.75286473e-01 9.97615565e-01 ... 3.86462878e-01\n",
      "  4.28835637e-01 4.25883477e-01]\n",
      " [4.42261443e-01 3.10102043e-01 3.91913335e-01 ... 4.99355805e-01\n",
      "  9.40307683e-01 5.25292667e-01]\n",
      " ...\n",
      " [7.67150610e-01 7.19217072e-01 7.52876707e-02 ... 9.90980078e-01\n",
      "  3.03538652e-01 6.33753760e-01]\n",
      " [9.08864611e-01 5.20246660e-01 1.89146661e-04 ... 5.65393614e-02\n",
      "  3.90890984e-01 1.13200522e-01]\n",
      " [4.99215246e-01 5.79640983e-01 2.15267258e-01 ... 1.84370131e-01\n",
      "  7.88135642e-01 7.66290874e-02]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'''\n",
    "L1|Wgt: \\n{nn.weights1}\n",
    "L2|Wgt: \\n{nn.weights2}\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7500, 2), (7500,))"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr.shape, y_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "IN: \n",
      "[[0 1 1]\n",
      " [1 0 1]\n",
      " [0 1 1]\n",
      " ...\n",
      " [0 1 1]\n",
      " [0 1 1]\n",
      " [1 0 1]]\n",
      "OT: \n",
      "[[0.96932843 0.95980153 0.9192316  ... 0.95850409 0.94682412 0.9467478 ]\n",
      " [0.9681264  0.9551512  0.91866282 ... 0.95437672 0.93616931 0.94489696]\n",
      " [0.96932843 0.95980153 0.9192316  ... 0.95850409 0.94682412 0.9467478 ]\n",
      " ...\n",
      " [0.98075077 0.97330078 0.94447797 ... 0.97307485 0.96069395 0.9653896 ]\n",
      " [0.9681264  0.9551512  0.91866282 ... 0.95437672 0.93616931 0.94489696]\n",
      " [0.9681264  0.9551512  0.91866282 ... 0.95437672 0.93616931 0.94489696]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output = nn.feed_forward(X_tr)\n",
    "print(f'''\n",
    "IN: \\n{candy.values}\n",
    "OT: \\n{output}\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------EPOCH 1---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [1 1 1 ... 0 1 1]\n",
      "Predicted Output: \n",
      " [[0.96932843 0.95980153 0.9192316  ... 0.95850409 0.94682412 0.9467478 ]\n",
      " [0.9681264  0.9551512  0.91866282 ... 0.95437672 0.93616931 0.94489696]\n",
      " [0.96932843 0.95980153 0.9192316  ... 0.95850409 0.94682412 0.9467478 ]\n",
      " ...\n",
      " [0.98075077 0.97330078 0.94447797 ... 0.97307485 0.96069395 0.9653896 ]\n",
      " [0.9681264  0.9551512  0.91866282 ... 0.95437672 0.93616931 0.94489696]\n",
      " [0.9681264  0.9551512  0.91866282 ... 0.95437672 0.93616931 0.94489696]]\n",
      "Loss: \n",
      " 0.4492034582068617\n",
      "+---------EPOCH 2---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [1 1 1 ... 0 1 1]\n",
      "Predicted Output: \n",
      " [[0.5 0.5 0.5 ... 0.5 0.5 0.5]\n",
      " [0.5 0.5 0.5 ... 0.5 0.5 0.5]\n",
      " [0.5 0.5 0.5 ... 0.5 0.5 0.5]\n",
      " ...\n",
      " [0.5 0.5 0.5 ... 0.5 0.5 0.5]\n",
      " [0.5 0.5 0.5 ... 0.5 0.5 0.5]\n",
      " [0.5 0.5 0.5 ... 0.5 0.5 0.5]]\n",
      "Loss: \n",
      " 0.18666666726381229\n",
      "+---------EPOCH 3---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [1 1 1 ... 0 1 1]\n",
      "Predicted Output: \n",
      " [[0.5 0.5 0.5 ... 0.5 0.5 0.5]\n",
      " [0.5 0.5 0.5 ... 0.5 0.5 0.5]\n",
      " [0.5 0.5 0.5 ... 0.5 0.5 0.5]\n",
      " ...\n",
      " [0.5 0.5 0.5 ... 0.5 0.5 0.5]\n",
      " [0.5 0.5 0.5 ... 0.5 0.5 0.5]\n",
      " [0.5 0.5 0.5 ... 0.5 0.5 0.5]]\n",
      "Loss: \n",
      " 0.18666666724144648\n",
      "+---------EPOCH 4---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [1 1 1 ... 0 1 1]\n",
      "Predicted Output: \n",
      " [[0.5 0.5 0.5 ... 0.5 0.5 0.5]\n",
      " [0.5 0.5 0.5 ... 0.5 0.5 0.5]\n",
      " [0.5 0.5 0.5 ... 0.5 0.5 0.5]\n",
      " ...\n",
      " [0.5 0.5 0.5 ... 0.5 0.5 0.5]\n",
      " [0.5 0.5 0.5 ... 0.5 0.5 0.5]\n",
      " [0.5 0.5 0.5 ... 0.5 0.5 0.5]]\n",
      "Loss: \n",
      " 0.186666667221093\n",
      "+---------EPOCH 5---------+\n",
      "Input: \n",
      " [[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 0]]\n",
      "Actual Output: \n",
      " [1 1 1 ... 0 1 1]\n",
      "Predicted Output: \n",
      " [[0.5 0.5 0.5 ... 0.5 0.5 0.5]\n",
      " [0.5 0.5 0.5 ... 0.5 0.5 0.5]\n",
      " [0.5 0.5 0.5 ... 0.5 0.5 0.5]\n",
      " ...\n",
      " [0.5 0.5 0.5 ... 0.5 0.5 0.5]\n",
      " [0.5 0.5 0.5 ... 0.5 0.5 0.5]\n",
      " [0.5 0.5 0.5 ... 0.5 0.5 0.5]]\n",
      "Loss: \n",
      " 0.18666666720247696\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-0c7b819e3a8c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Predicted Output: \\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loss: \\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_tr\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_tr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-83-8ec135ba1104>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-83-8ec135ba1104>\u001b[0m in \u001b[0;36mfeed_forward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;31m# Final activation of output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivated_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_sum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;31m# Bias term is not here cause who cares lol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-83-8ec135ba1104>\u001b[0m in \u001b[0;36msigmoid\u001b[0;34m(self, s)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msigmoidPrime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Teacher's loop\n",
    "for i in range(10000):\n",
    "    if (i+1 in [1,2,3,4,5]) or ((i+1) % 1000 ==0):\n",
    "        nice = nn.feed_forward(X_tr)\n",
    "        print('+' + '---' * 3 + f'EPOCH {i+1}' + '---'*3 + '+')\n",
    "        print('Input: \\n', X_tr)\n",
    "        print('Actual Output: \\n', y_tr)\n",
    "        print('Predicted Output: \\n', str(nice))\n",
    "        print(\"Loss: \\n\", str(np.mean(np.square(y_tr - nn.feed_forward(X_tr)))))\n",
    "    nn.train(X_tr,y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \n",
      " [[0 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " ...\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "Predicted Output: \n",
      " [[1.  1.  1.  ... 0.  1.  1. ]\n",
      " [0.5 0.5 0.5 ... 0.5 0.5 0.5]\n",
      " [0.5 0.5 0.5 ... 0.5 0.5 0.5]\n",
      " ...\n",
      " [0.5 0.5 0.5 ... 0.5 0.5 0.5]\n",
      " [0.5 0.5 0.5 ... 0.5 0.5 0.5]\n",
      " [0.5 0.5 0.5 ... 0.5 0.5 0.5]]\n"
     ]
    }
   ],
   "source": [
    "nice = nn.feed_forward(X_tst)\n",
    "print('Input: \\n', X_tst)\n",
    "print('Predicted Output: \\n', str(nice))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P.S. Don't try candy gummy bears. They're disgusting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Keras MMP <a id=\"Q3\"></a>\n",
    "\n",
    "Implement a Multilayer Perceptron architecture of your choosing using the Keras library. Train your model and report its baseline accuracy. Then hyperparameter tune at least two parameters and report your model's accuracy.\n",
    "Use the Heart Disease Dataset (binary classification)\n",
    "Use an appropriate loss function for a binary classification task\n",
    "Use an appropriate activation function on the final layer of your network.\n",
    "Train your model using verbose output for ease of grading.\n",
    "Use GridSearchCV or RandomSearchCV to hyperparameter tune your model. (for at least two hyperparameters)\n",
    "When hyperparameter tuning, show you work by adding code cells for each new experiment.\n",
    "Report the accuracy for each combination of hyperparameters as you test them so that we can easily see which resulted in the highest accuracy.\n",
    "You must hyperparameter tune at least 3 parameters in order to get a 3 on this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(303, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>117</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>120</td>\n",
       "      <td>193</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>162</td>\n",
       "      <td>0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>135</td>\n",
       "      <td>252</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>238</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>304</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>162</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>160</td>\n",
       "      <td>269</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112</td>\n",
       "      <td>1</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>239</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "117   56    1   3       120   193    0        0      162      0      1.9   \n",
       "54    63    0   2       135   252    0        0      172      0      0.0   \n",
       "238   77    1   0       125   304    0        0      162      1      0.0   \n",
       "240   70    1   2       160   269    0        1      112      1      2.9   \n",
       "10    54    1   0       140   239    0        1      160      0      1.2   \n",
       "\n",
       "     slope  ca  thal  target  \n",
       "117      1   0     3       1  \n",
       "54       2   0     2       1  \n",
       "238      2   3     2       0  \n",
       "240      1   1     3       0  \n",
       "10       2   0     2       1  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/ryanleeallred/datasets/master/heart.csv')\n",
    "df = df.sample(frac=1)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup(df):\n",
    "    \n",
    "    # Make all yes and no binary questions 1 and 0\n",
    "    \n",
    "    dfx = df\n",
    "    # Establish target\n",
    "    dfy = dfx['target']\n",
    "    dfx.drop(['target'],axis='columns')\n",
    "\n",
    "    return np.array(dfx), np.array(dfy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = cleanup(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "enc = OrdinalEncoder()\n",
    "scl = MinMaxScaler()\n",
    "\n",
    "X_e = enc.fit_transform(X, y)\n",
    "X_s = scl.fit_transform(X_e, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "t_size = .45\n",
    "rand_s = 444\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_s, y, test_size=t_size, random_state=rand_s\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((166, 14), (166,), (137, 14), (137,))"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/jasonnova/ghsts-r-dangerous/runs/djydgwgq\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
       "            in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "W&B Run: https://app.wandb.ai/jasonnova/ghsts-r-dangerous/runs/djydgwgq"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "wandb.init(project=\"ghsts-r-dangerous\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Hyperparams\n",
    "inputs = X.shape[1]\n",
    "epochs = 25\n",
    "b_size = 250\n",
    "\n",
    "# Create model\n",
    "def c_m():\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(96, input_shape=(inputs,), activation='relu'))\n",
    "    model.add(Dropout(0.05))\n",
    "    model.add(Dense(48, activation='relu'))\n",
    "    model.add(Dropout(0.05))\n",
    "    model.add(Dense(48, activation='relu'))\n",
    "    model.add(Dropout(0.05))\n",
    "    model.add(Dense(48, activation='relu'))\n",
    "    model.add(Dropout(0.05))\n",
    "    model.add(Dense(48, activation='relu'))\n",
    "    model.add(Dropout(0.15))\n",
    "    model.add(Dense(96, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=c_m, verbose=0)\n",
    "\n",
    "param_grid = {'batch_size': [94,95,96,97],\n",
    "              'epochs':[6,7,8,9,10]}\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1, verbose=0)\n",
    "grid_result = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.9819277054574116 using {'batch_size': 97, 'epochs': 9}\n",
      "Means: 0.9277108501957123, Stdev: 0.07709918194130565 with: {'batch_size': 94, 'epochs': 6}\n",
      "Means: 0.8795180841382727, Stdev: 0.10747119545558685 with: {'batch_size': 94, 'epochs': 7}\n",
      "Means: 0.96385542455926, Stdev: 0.025175363467456507 with: {'batch_size': 94, 'epochs': 8}\n",
      "Means: 0.9457831447383007, Stdev: 0.06465227879890036 with: {'batch_size': 94, 'epochs': 9}\n",
      "Means: 0.9638554306633501, Stdev: 0.02960280779074456 with: {'batch_size': 94, 'epochs': 10}\n",
      "Means: 0.8915662668555616, Stdev: 0.09280393197919042 with: {'batch_size': 95, 'epochs': 6}\n",
      "Means: 0.951807235378817, Stdev: 0.06846395526292863 with: {'batch_size': 95, 'epochs': 7}\n",
      "Means: 0.9457831221172609, Stdev: 0.03936071524834895 with: {'batch_size': 95, 'epochs': 8}\n",
      "Means: 0.9156626484480249, Stdev: 0.06095029039828642 with: {'batch_size': 95, 'epochs': 9}\n",
      "Means: 0.8975903603685907, Stdev: 0.08190434776343473 with: {'batch_size': 95, 'epochs': 10}\n",
      "Means: 0.7831325337111231, Stdev: 0.20787638895089242 with: {'batch_size': 96, 'epochs': 6}\n",
      "Means: 0.9277108466050711, Stdev: 0.06352438194568932 with: {'batch_size': 96, 'epochs': 7}\n",
      "Means: 0.9759036288203964, Stdev: 0.022294643675676774 with: {'batch_size': 96, 'epochs': 8}\n",
      "Means: 0.9457831361207617, Stdev: 0.04440422388857996 with: {'batch_size': 96, 'epochs': 9}\n",
      "Means: 0.9759036176894085, Stdev: 0.022686001779579267 with: {'batch_size': 96, 'epochs': 10}\n",
      "Means: 0.9216867398066693, Stdev: 0.043135812643324306 with: {'batch_size': 97, 'epochs': 6}\n",
      "Means: 0.8795180884470423, Stdev: 0.0909183156343961 with: {'batch_size': 97, 'epochs': 7}\n",
      "Means: 0.9216867308300661, Stdev: 0.037326160421921266 with: {'batch_size': 97, 'epochs': 8}\n",
      "Means: 0.9819277054574116, Stdev: 0.014801416097836478 with: {'batch_size': 97, 'epochs': 9}\n",
      "Means: 0.9759036176894085, Stdev: 0.03423197763146431 with: {'batch_size': 97, 'epochs': 10}\n"
     ]
    }
   ],
   "source": [
    "# Teacher's\n",
    "# Report Results\n",
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa825cebe48>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.config.epochs = 7\n",
    "wandb.config.batch_size = 95\n",
    "model.fit(\n",
    "    X_train, y_train, \n",
    "    validation_split=0.45,\n",
    "    batch_size=wandb.config.batch_size,\n",
    "    epochs=wandb.config.epochs,\n",
    "    callbacks=[WandbCallback()]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 166 samples\n",
      "Epoch 1/10\n",
      "166/166 [==============================] - 1s 5ms/sample - loss: 0.6893 - accuracy: 0.5361\n",
      "Epoch 2/10\n",
      "166/166 [==============================] - 0s 56us/sample - loss: 0.6806 - accuracy: 0.7470\n",
      "Epoch 3/10\n",
      "166/166 [==============================] - 0s 59us/sample - loss: 0.6660 - accuracy: 0.8795\n",
      "Epoch 4/10\n",
      "166/166 [==============================] - 0s 63us/sample - loss: 0.6483 - accuracy: 0.8855\n",
      "Epoch 5/10\n",
      "166/166 [==============================] - 0s 53us/sample - loss: 0.6263 - accuracy: 0.9337\n",
      "Epoch 6/10\n",
      "166/166 [==============================] - 0s 57us/sample - loss: 0.5840 - accuracy: 0.9096\n",
      "Epoch 7/10\n",
      "166/166 [==============================] - 0s 62us/sample - loss: 0.5455 - accuracy: 0.9398\n",
      "Epoch 8/10\n",
      "166/166 [==============================] - 0s 58us/sample - loss: 0.4876 - accuracy: 0.9398\n",
      "Epoch 9/10\n",
      "166/166 [==============================] - 0s 51us/sample - loss: 0.4281 - accuracy: 0.9578\n",
      "Epoch 10/10\n",
      "166/166 [==============================] - 0s 53us/sample - loss: 0.3415 - accuracy: 0.9819\n"
     ]
    }
   ],
   "source": [
    "# Fit model\n",
    "wade = model.fit(X_train, y_train,\n",
    "          batch_size=97,\n",
    "          epochs=10,\n",
    "          verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9927007299270073"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "# expecto prediction\n",
    "pred = model.predict(X_test)\n",
    "accuracy_score(pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Can't tell if I did something wrong here to get 99% (my previous score not shown)? I mean...talk about obvious overfitting if not outright wrong, lol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If I make the training data only 25% of the total data and try to predict the other 75%, it gives an accuracy of 71%...which seems reasonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nteract": {
   "version": "0.15.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
