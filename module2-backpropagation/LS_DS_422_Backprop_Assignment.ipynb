{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NGGrt9EYlCqY"
   },
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "\n",
    "# Backpropagation Practice\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2 Assignment 2*\n",
    "\n",
    "Implement a 3 input, 4 node hidden-layer, 1 output node Multilayer Perceptron on the following dataset:\n",
    "\n",
    "| x1 | x2 | x3 | y |\n",
    "|----|----|----|---|\n",
    "| 0  | 0  | 1  | 0 |\n",
    "| 0  | 1  | 1  | 1 |\n",
    "| 1  | 0  | 1  | 1 |\n",
    "| 0  | 1  | 0  | 1 |\n",
    "| 1  | 0  | 0  | 1 |\n",
    "| 1  | 1  | 1  | 0 |\n",
    "| 0  | 0  | 0  | 0 |\n",
    "\n",
    "If you look at the data you'll notice that the first two columns behave like an XOR gate while the last column is mostly just noise. Remember that creating an XOR gate was what the perceptron was criticized for not being able to learn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x1  x2  x3  y\n",
       "0   0   0   1  0\n",
       "1   0   1   1  1\n",
       "2   1   0   1  1\n",
       "3   0   1   0  1\n",
       "4   1   0   0  1\n",
       "5   1   1   1  0\n",
       "6   0   0   0  0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "x1 = [0, 0, 1, 0, 1, 1, 0]\n",
    "x2 = [0, 1, 0, 1, 0, 1, 0]\n",
    "x3 = [1, 1, 1, 0, 0, 1, 0]\n",
    "y = [0, 1, 1, 1, 1, 0, 0]\n",
    "df = pd.DataFrame({'x1': x1, 'x2': x2, 'x3': x3, 'y': y})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['x1','x2','x3']].values.astype(float)\n",
    "y = df[['y']].values.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [0., 1., 1.],\n",
       "       [1., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 1., 1.],\n",
       "       [0., 0., 0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Set up Architecture of Neural Network\n",
    "        self.inputs = 3\n",
    "        self.hiddenNodes =  4\n",
    "        self.outputNodes = 1\n",
    "\n",
    "        # Initial Weights\n",
    "        # 2x3 Matrix Array for the First Layer\n",
    "        self.weights1 = np.random.randn(self.inputs, self.hiddenNodes)\n",
    "       \n",
    "        # 3x1 Matrix Array for Hidden to Output\n",
    "        self.weights2 = np.random.randn(self.hiddenNodes, self.outputNodes)\n",
    "        \n",
    "    def sigmoid(self, s):\n",
    "        return 1 / (1+np.exp(-s))\n",
    "    \n",
    "    def sigmoidPrime(self, s):\n",
    "        return s * (1-s)\n",
    "    \n",
    "    def feed_forward(self, X):\n",
    "        \"\"\"\n",
    "        Calculate the NN inference using feed forward pass.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Weighted sum of inputs and hidden layer\n",
    "        self.hidden_sum = np.dot(X, self.weights1)\n",
    "        \n",
    "        # Activation of the weighted sum\n",
    "        self.activated_hidden = self.sigmoid(self.hidden_sum)\n",
    "        \n",
    "        # Weighted sum of hidden layer to output layer\n",
    "        self.output_sum = np.dot(self.activated_hidden, self.weights2)\n",
    "        \n",
    "        # Final Activation of Output\n",
    "        self.activated_output = self.sigmoid(self.output_sum)\n",
    "        \n",
    "        return self.activated_output\n",
    "    \n",
    "    def backward(self, X, y, o):\n",
    "        \n",
    "        self.o_error = y - o #error in output\n",
    "        \n",
    "        # Size of adjustment from hidden to output\n",
    "        self.o_delta = self.o_error * self.sigmoidPrime(o) #apply derivative of sigmoid to error\n",
    "        \n",
    "        #z2 error: how much our hidden layer to input weights were off\n",
    "        self.z2_error = self.o_delta.dot(self.weights2.T)\n",
    "        self.z2_delta = self.z2_error * self.sigmoidPrime(self.activated_hidden)\n",
    "        \n",
    "        # Adjustment hidden => output weights\n",
    "        self.weights2 += self.activated_hidden.T.dot(self.o_delta)\n",
    "        \n",
    "        #Adjustment input => hidden weights\n",
    "        self.weights1 += X.T.dot(self.z2_delta)\n",
    "        \n",
    "    def train(self, X, y):\n",
    "        o = self.feed_forward(X)\n",
    "        self.backward(X, y, o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------EPOCH 1---------+\n",
      "Predicted Output: \n",
      " [[0.21262879]\n",
      " [0.25431188]\n",
      " [0.33460532]\n",
      " [0.38360835]\n",
      " [0.47587699]\n",
      " [0.41168755]\n",
      " [0.35213694]]\n",
      "Loss: \n",
      " 0.2845917857213064\n",
      "+---------EPOCH 2---------+\n",
      "Predicted Output: \n",
      " [[0.30173972]\n",
      " [0.38979584]\n",
      " [0.45003058]\n",
      " [0.51824923]\n",
      " [0.58070676]\n",
      " [0.55969798]\n",
      " [0.44239271]]\n",
      "Loss: \n",
      " 0.24038944435802764\n",
      "+---------EPOCH 3---------+\n",
      "Predicted Output: \n",
      " [[0.36254332]\n",
      " [0.48202877]\n",
      " [0.5244421 ]\n",
      " [0.59791966]\n",
      " [0.64091118]\n",
      " [0.64614396]\n",
      " [0.49685535]]\n",
      "Loss: \n",
      " 0.22583825853826658\n",
      "+---------EPOCH 4---------+\n",
      "Predicted Output: \n",
      " [[0.38951327]\n",
      " [0.52511593]\n",
      " [0.56041333]\n",
      " [0.63310131]\n",
      " [0.66888268]\n",
      " [0.6853838 ]\n",
      " [0.51965512]]\n",
      "Loss: \n",
      " 0.2220739456154525\n",
      "+---------EPOCH 5---------+\n",
      "Predicted Output: \n",
      " [[0.39891292]\n",
      " [0.54431448]\n",
      " [0.57822374]\n",
      " [0.64873304]\n",
      " [0.68285722]\n",
      " [0.70449882]\n",
      " [0.52747427]]\n",
      "Loss: \n",
      " 0.22045596332814135\n",
      "+---------EPOCH 200---------+\n",
      "Predicted Output: \n",
      " [[0.09085782]\n",
      " [0.73033708]\n",
      " [0.6677216 ]\n",
      " [0.89531081]\n",
      " [0.80466804]\n",
      " [0.70729857]\n",
      " [0.12940791]]\n",
      "Loss: \n",
      " 0.10821632099914133\n",
      "+---------EPOCH 400---------+\n",
      "Predicted Output: \n",
      " [[0.07833238]\n",
      " [0.74481861]\n",
      " [0.73545012]\n",
      " [0.80626927]\n",
      " [0.8030706 ]\n",
      " [0.61138558]\n",
      " [0.0712397 ]]\n",
      "Loss: \n",
      " 0.08520290690029331\n",
      "+---------EPOCH 600---------+\n",
      "Predicted Output: \n",
      " [[0.04481721]\n",
      " [0.78230042]\n",
      " [0.78134007]\n",
      " [0.79403096]\n",
      " [0.79356046]\n",
      " [0.51727925]\n",
      " [0.06080348]]\n",
      "Loss: \n",
      " 0.06478989624098389\n",
      "+---------EPOCH 800---------+\n",
      "Predicted Output: \n",
      " [[0.03165129]\n",
      " [0.80325283]\n",
      " [0.8052576 ]\n",
      " [0.80966675]\n",
      " [0.8080562 ]\n",
      " [0.44604988]\n",
      " [0.05743339]]\n",
      "Loss: \n",
      " 0.050423444925189305\n",
      "+---------EPOCH 1000---------+\n",
      "Predicted Output: \n",
      " [[0.02689906]\n",
      " [0.82104276]\n",
      " [0.83379276]\n",
      " [0.8341223 ]\n",
      " [0.82479857]\n",
      " [0.37874385]\n",
      " [0.06180784]]\n",
      "Loss: \n",
      " 0.0379788807863099\n",
      "+---------EPOCH 1200---------+\n",
      "Predicted Output: \n",
      " [[0.02354817]\n",
      " [0.86386973]\n",
      " [0.90766014]\n",
      " [0.89434402]\n",
      " [0.8843723 ]\n",
      " [0.23421071]\n",
      " [0.07673257]]\n",
      "Loss: \n",
      " 0.0161268729948943\n",
      "+---------EPOCH 1400---------+\n",
      "Predicted Output: \n",
      " [[0.01526571]\n",
      " [0.91463149]\n",
      " [0.94873572]\n",
      " [0.93209856]\n",
      " [0.93956311]\n",
      " [0.12631054]\n",
      " [0.08129599]]\n",
      "Loss: \n",
      " 0.005853637546020329\n",
      "+---------EPOCH 1600---------+\n",
      "Predicted Output: \n",
      " [[0.01118559]\n",
      " [0.93544886]\n",
      " [0.96244906]\n",
      " [0.94704654]\n",
      " [0.95702499]\n",
      " [0.08963873]\n",
      " [0.07268439]]\n",
      "Loss: \n",
      " 0.0033815832938422176\n",
      "+---------EPOCH 1800---------+\n",
      "Predicted Output: \n",
      " [[0.00894405]\n",
      " [0.94616074]\n",
      " [0.96910422]\n",
      " [0.95507594]\n",
      " [0.96519456]\n",
      " [0.07223798]\n",
      " [0.06477785]]\n",
      "Loss: \n",
      " 0.002368185126426253\n",
      "+---------EPOCH 2000---------+\n",
      "Predicted Output: \n",
      " [[0.00755005]\n",
      " [0.95290115]\n",
      " [0.97320229]\n",
      " [0.96029059]\n",
      " [0.97013016]\n",
      " [0.06178123]\n",
      " [0.05870742]]\n",
      "Loss: \n",
      " 0.0018179926888500625\n",
      "+---------EPOCH 2200---------+\n",
      "Predicted Output: \n",
      " [[0.00659675]\n",
      " [0.95763919]\n",
      " [0.9760577 ]\n",
      " [0.96403309]\n",
      " [0.97352422]\n",
      " [0.05464806]\n",
      " [0.05400103]]\n",
      "Loss: \n",
      " 0.001472613763436732\n",
      "+---------EPOCH 2400---------+\n",
      "Predicted Output: \n",
      " [[0.0058997 ]\n",
      " [0.96120405]\n",
      " [0.97819711]\n",
      " [0.96688979]\n",
      " [0.97604186]\n",
      " [0.04939595]\n",
      " [0.05024644]]\n",
      "Loss: \n",
      " 0.0012357486764595065\n",
      "+---------EPOCH 2600---------+\n",
      "Predicted Output: \n",
      " [[0.00536489]\n",
      " [0.96401198]\n",
      " [0.97987819]\n",
      " [0.9691639 ]\n",
      " [0.97800439]\n",
      " [0.04532754]\n",
      " [0.04717035]]\n",
      "Loss: \n",
      " 0.001063301043527944\n",
      "+---------EPOCH 2800---------+\n",
      "Predicted Output: \n",
      " [[0.0049396 ]\n",
      " [0.96629783]\n",
      " [0.98124437]\n",
      " [0.97103037]\n",
      " [0.97958888]\n",
      " [0.04206002]\n",
      " [0.04459362]]\n",
      "Loss: \n",
      " 0.0009322141597018664\n",
      "+---------EPOCH 3000---------+\n",
      "Predicted Output: \n",
      " [[0.00459195]\n",
      " [0.96820555]\n",
      " [0.98238293]\n",
      " [0.9725983 ]\n",
      " [0.98090214]\n",
      " [0.03936366]\n",
      " [0.04239555]]\n",
      "Loss: \n",
      " 0.0008292565977178575\n",
      "+---------EPOCH 3200---------+\n",
      "Predicted Output: \n",
      " [[0.00430152]\n",
      " [0.96982899]\n",
      " [0.98335055]\n",
      " [0.97393976]\n",
      " [0.98201299]\n",
      " [0.03709126]\n",
      " [0.04049217]]\n",
      "Loss: \n",
      " 0.0007462918786604263\n",
      "+---------EPOCH 3400---------+\n",
      "Predicted Output: \n",
      " [[0.00405458]\n",
      " [0.97123229]\n",
      " [0.98418588]\n",
      " [0.97510456]\n",
      " [0.98296807]\n",
      " [0.03514359]\n",
      " [0.03882322]]\n",
      "Loss: \n",
      " 0.0006780416639434967\n",
      "+---------EPOCH 3600---------+\n",
      "Predicted Output: \n",
      " [[0.00384156]\n",
      " [0.97246098]\n",
      " [0.98491633]\n",
      " [0.97612838]\n",
      " [0.98380026]\n",
      " [0.03345102]\n",
      " [0.03734431]]\n",
      "Loss: \n",
      " 0.0006209324308422918\n",
      "+---------EPOCH 3800---------+\n",
      "Predicted Output: \n",
      " [[0.00365555]\n",
      " [0.97354843]\n",
      " [0.98556199]\n",
      " [0.97703754]\n",
      " [0.9845335 ]\n",
      " [0.03196311]\n",
      " [0.03602194]]\n",
      "Loss: \n",
      " 0.0005724589404575958\n",
      "+---------EPOCH 4000---------+\n",
      "Predicted Output: \n",
      " [[0.00349143]\n",
      " [0.9745197 ]\n",
      " [0.98613791]\n",
      " [0.97785197]\n",
      " [0.98518569]\n",
      " [0.03064227]\n",
      " [0.03483031]]\n",
      "Loss: \n",
      " 0.0005308130657305724\n",
      "+---------EPOCH 4200---------+\n",
      "Predicted Output: \n",
      " [[0.00334535]\n",
      " [0.97539405]\n",
      " [0.98665569]\n",
      " [0.97858705]\n",
      " [0.98577052]\n",
      " [0.02945989]\n",
      " [0.0337492 ]]\n",
      "Loss: \n",
      " 0.0004946572910177586\n",
      "+---------EPOCH 4400---------+\n",
      "Predicted Output: \n",
      " [[0.0032143 ]\n",
      " [0.97618654]\n",
      " [0.98712437]\n",
      " [0.97925486]\n",
      " [0.98629865]\n",
      " [0.02839372]\n",
      " [0.03276251]]\n",
      "Loss: \n",
      " 0.0004629811084253888\n",
      "+---------EPOCH 4600---------+\n",
      "Predicted Output: \n",
      " [[0.00309595]\n",
      " [0.97690914]\n",
      " [0.98755116]\n",
      " [0.97986508]\n",
      " [0.98677855]\n",
      " [0.02742621]\n",
      " [0.03185724]]\n",
      "Loss: \n",
      " 0.0004350069520037475\n",
      "+---------EPOCH 4800---------+\n",
      "Predicted Output: \n",
      " [[0.00298842]\n",
      " [0.97757153]\n",
      " [0.98794186]\n",
      " [0.98042551]\n",
      " [0.987217  ]\n",
      " [0.02654327]\n",
      " [0.03102275]]\n",
      "Loss: \n",
      " 0.0004101268194967479\n",
      "+---------EPOCH 5000---------+\n",
      "Predicted Output: \n",
      " [[0.0028902 ]\n",
      " [0.97818159]\n",
      " [0.98830123]\n",
      " [0.98094258]\n",
      " [0.98761954]\n",
      " [0.02573346]\n",
      " [0.03025028]]\n",
      "Loss: \n",
      " 0.00038785850638079514\n"
     ]
    }
   ],
   "source": [
    "nn = NeuralNetwork()\n",
    "\n",
    "for i in range(5000):\n",
    "    if (i+1 in [1,2,3,4,5]) or ((i+1) % 200 ==0):\n",
    "        print('+' + '---' * 3 + f'EPOCH {i+1}' + '---'*3 + '+')\n",
    "        #print('Actual Output: \\n', y)\n",
    "        print('Predicted Output: \\n', str(nn.feed_forward(X)))\n",
    "        print(\"Loss: \\n\", str(np.mean(np.square(y - nn.feed_forward(X)))))\n",
    "    nn.train(X,y)\n",
    "#     if np.array_equal(np.rint(nn.feed_forward(X)), y):\n",
    "#         print(f'Final Predicted Output: \\n{ np.rint(nn.feed_forward(X))}')\n",
    "#         print(f'Epoch: {i+1}')\n",
    "#         break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8b-r70o8p2Dm"
   },
   "source": [
    "## Try building/training a more complex MLP on a bigger dataset.\n",
    "\n",
    "Use the [MNIST dataset](http://yann.lecun.com/exdb/mnist/) to build the cannonical handwriting digit recognizer and see what kind of accuracy you can achieve. \n",
    "\n",
    "If you need inspiration, the internet is chalk-full of tutorials, but I want you to see how far you can get on your own first. I've linked to the original MNIST dataset above but it will probably be easier to download data through a neural network library. If you reference outside resources make sure you understand every line of code that you're using from other sources, and share with your fellow students helpful resources that you find.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5MOPtYdk1HgA"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "((X_train, y_train), (X_test, y_test)) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (10000, 28, 28))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the data into single vectors\n",
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X Variable Types\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize to keep the gradients manageable\n",
    "X_train = X_train/255\n",
    "X_test = X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    s = 1 / (1 + np.exp(-z))\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct encoding of y\n",
    "# What softmax expects = [0,0,0,0,0,1,0,0,0,0]\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNDigit(object:\n",
    "    \n",
    "    def __init__(self, epochs=20, batch_size=None, learning_rate=0.1):\n",
    "        # Set up Architecture of Neural Network\n",
    "        self.lr = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.inputs = 784\n",
    "        self.hiddenNodes =  10\n",
    "        self.outputNodes = 10\n",
    "\n",
    "        # Initial hidden layer\n",
    "        self.weights1 = np.random.randn(self.inputs, self.hiddenNodes)\n",
    "       \n",
    "        # 3x1 Matrix Array for Hidden to Output\n",
    "        self.weights2 = np.random.randn(self.hiddenNodes, self.outputNodes)\n",
    "        self.bias2 = np.zeros((10, 1))\n",
    "        \n",
    "    def sigmoid(self, s):\n",
    "        return 1 / (1+np.exp(-s))\n",
    "    \n",
    "    def sigmoidPrime(self, s):\n",
    "        return s * (1-s)\n",
    "    \n",
    "    def compute_loss(Y, Y-hat):\n",
    "        m = Y.shape[1]\n",
    "        L = -(1./m) * (np.sum( np.multiply(np.log(Y_hat),Y)) + np.sum(np.multiply(np.log(1-Y_hat),(1-Y))))\n",
    "        return L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FwlRJSfBlCvy"
   },
   "source": [
    "## Stretch Goals: \n",
    "\n",
    "- Implement Cross Validation model evaluation on your MNIST implementation \n",
    "- Research different [Gradient Descent Based Optimizers](https://keras.io/optimizers/)\n",
    " - [Siraj Raval the evolution of gradient descent](https://www.youtube.com/watch?v=nhqo0u1a6fw)\n",
    "- Build a housing price estimation model using a neural network. How does its accuracy compare with the regression models that we fit earlier on in class?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "LS_DS_432_Backprop_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
