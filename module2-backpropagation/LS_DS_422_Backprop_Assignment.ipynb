{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NGGrt9EYlCqY"
   },
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "\n",
    "# Backpropagation Practice\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2 Assignment 2*\n",
    "\n",
    "Implement a 3 input, 4 node hidden-layer, 1 output node Multilayer Perceptron on the following dataset:\n",
    "\n",
    "| x1 | x2 | x3 | y |\n",
    "|----|----|----|---|\n",
    "| 0  | 0  | 1  | 0 |\n",
    "| 0  | 1  | 1  | 1 |\n",
    "| 1  | 0  | 1  | 1 |\n",
    "| 0  | 1  | 0  | 1 |\n",
    "| 1  | 0  | 0  | 1 |\n",
    "| 1  | 1  | 1  | 0 |\n",
    "| 0  | 0  | 0  | 0 |\n",
    "\n",
    "If you look at the data you'll notice that the first two columns behave like an XOR gate while the last column is mostly just noise. Remember that creating an XOR gate was what the perceptron was criticized for not being able to learn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nEREYT-3wI1f"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'x1': [0,\n",
    "               0,\n",
    "               1,\n",
    "               0,\n",
    "               1,\n",
    "               1,\n",
    "               0,\n",
    "               1,\n",
    "              ],\n",
    "       'x2': [0,\n",
    "              1,\n",
    "              0,\n",
    "              1,\n",
    "              0,\n",
    "              1,\n",
    "              0,\n",
    "              1,\n",
    "             ],\n",
    "       'x3': [1,\n",
    "              1,\n",
    "              1,\n",
    "              0,\n",
    "              0,\n",
    "              1,\n",
    "              1,\n",
    "              0,\n",
    "             ],\n",
    "       'y': [0,\n",
    "             1,\n",
    "             1,\n",
    "             1,\n",
    "             1,\n",
    "             0,\n",
    "             0,\n",
    "             0,\n",
    "            ]}   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x1  x2  x3  y\n",
       "0   0   0   1  0\n",
       "1   0   1   1  1\n",
       "2   1   0   1  1\n",
       "3   0   1   0  1\n",
       "4   1   0   0  1\n",
       "5   1   1   1  0\n",
       "6   0   0   1  0\n",
       "7   1   1   0  0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(object):\n",
    "    \n",
    "    def __init__(self, epochs=1000, learning_rate=0.01, n_input=3, n_hidden=4, n_out=1):\n",
    "        \n",
    "        # Initialize hyperparameter variables.\n",
    "        self.epochs = epochs\n",
    "        self.lr = learning_rate\n",
    "        self.n_input = n_input\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_out = n_out\n",
    "    \n",
    "        # Initialize weights and biases.\n",
    "        self.hidden_weight = np.random.random(size=(self.n_input + 1, self.n_hidden))\n",
    "        self.output_weight = np.random.random(size=(self.n_hidden + 1, self.n_out))\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def sigmoid_prime(self, x):\n",
    "        return x * (1 - x)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.errors = []\n",
    "        for _ in range(self.epochs):\n",
    "            out = self.predict(X)\n",
    "            self.backpass(X, y, out)\n",
    "        print(f'Training error at final epoch: {self.errors[-1]}')\n",
    "\n",
    "    def backpass(self, X, y, out):\n",
    "        y = y.reshape((y.shape[0], 1))\n",
    "        error = y - out\n",
    "        \n",
    "        self.errors.append(np.sum(error**2))\n",
    "        # Caluculate adjustment from hidden -> output.\n",
    "        delta_output = self.sigmoid_prime(out) * error\n",
    "        \n",
    "        # Calculate error from input -> hidden.\n",
    "        output_error = delta_output.dot(self.output_weight[1:].T)\n",
    "        delta_hidden = output_error * self.sigmoid_prime(out)\n",
    "        \n",
    "        #Adjust hidden -> output weghts.\n",
    "\n",
    "        self.output_weight[1:] += self.activated_hidden.T.dot(delta_output) * self.lr\n",
    "        self.output_weight[0] = np.sum(delta_output)\n",
    "\n",
    "        self.hidden_weight[1:] += X.T.dot(delta_hidden) * self.lr\n",
    "        self.hidden_weight[0] = np.sum(delta_hidden)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        inputs = np.dot(X, self.hidden_weight[1:]) + self.hidden_weight[0]\n",
    "        self.activated_hidden = self.sigmoid(inputs)\n",
    "        output = np.dot(self.activated_hidden, self.output_weight[1:]) + self.output_weight[0]\n",
    "        final = self.sigmoid(output)\n",
    "        return final\n",
    "        \n",
    "    def plot_error(self):\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.title('Training Error')\n",
    "        plt.plot(self.errors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = MLP(epochs=60000, n_hidden=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['x1', 'x2', 'x3']]\n",
    "y = df['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training error at final epoch: 1.732978501399431\n"
     ]
    }
   ],
   "source": [
    "nn.fit(X.values, y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x1  x2  x3  y\n",
       "0   0   0   1  0\n",
       "1   0   1   1  1\n",
       "2   1   0   1  1\n",
       "3   0   1   0  1\n",
       "4   1   0   0  1\n",
       "5   1   1   1  0\n",
       "6   0   0   1  0\n",
       "7   1   1   0  0"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.37072923]\n",
      "[0.34727895]\n",
      "[0.34239998]\n",
      "[0.6004258]\n",
      "[0.61568169]\n",
      "[0.31965806]\n",
      "[0.37072923]\n",
      "[0.46267812]\n"
     ]
    }
   ],
   "source": [
    "for x in X.values:\n",
    "    print(nn.predict(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nn.plot_error()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8b-r70o8p2Dm"
   },
   "source": [
    "## Try building/training a more complex MLP on a bigger dataset.\n",
    "\n",
    "Use the [MNIST dataset](http://yann.lecun.com/exdb/mnist/) to build the cannonical handwriting digit recognizer and see what kind of accuracy you can achieve. \n",
    "\n",
    "If you need inspiration, the internet is chalk-full of tutorials, but I want you to see how far you can get on your own first. I've linked to the original MNIST dataset above but it will probably be easier to download data through a neural network library. If you reference outside resources make sure you understand every line of code that you're using from other sources, and share with your fellow students helpful resources that you find.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5MOPtYdk1HgA"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.datasets import fetch_openml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True)\n",
    "X = X / 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (10000, 784), (60000, 10), (10000, 10))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits = 10\n",
    "examples = y.shape[0]\n",
    "\n",
    "y = y.reshape(1, examples)\n",
    "\n",
    "Y_new = np.eye(digits)[y.astype('int32')]\n",
    "Y_new = Y_new.T.reshape(digits, examples)\n",
    "\n",
    "m = 60000\n",
    "m_test = X.shape[0] - m\n",
    "\n",
    "X_train, X_test = X[:m], X[m:]\n",
    "Y_train, Y_test = Y_new[:, :m].T, Y_new[:, m:].T\n",
    "\n",
    "# shuffle_index = np.random.permutation(m)\n",
    "# X_train, Y_train = X_train[:, shuffle_index], Y_train[:, shuffle_index]\n",
    "# X_train, X_test = X_train.reshape((m, 784)), X_test.reshape((m_test, 784))\n",
    "X_train.shape, X_test.shape, Y_train.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(image, label):\n",
    "    plt.imshow(image.reshape(28, 28), cmap = matplotlib.cm.binary)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[11].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "i = 12\n",
    "show(X_train[i].reshape(1, -1), Y_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNImage(object):\n",
    "    \n",
    "    def __init__(self, epochs=1000, learning_rate=0.01, batch_size=250, n_input=784, n_hidden=128, n_output=10):\n",
    "        self.lr = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.hidden_weight = np.random.random(size=(n_hidden, n_input))\n",
    "        self.hidden_bias = np.zeros((n_hidden, 1))\n",
    "        \n",
    "        self.output_weight = np.random.random(size=(n_output, n_hidden))\n",
    "        self.output_bias = np.zeros((n_output, 1))\n",
    "        \n",
    "        self.losses = []\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def loss(self, y, yhat):\n",
    "        loss_sum = np.sum(np.multiply(np.log(yhat), y))\n",
    "        loss = -(1 / 60000) * loss_sum\n",
    "        return loss\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        for i in range(self.epochs):\n",
    "            for image, label in zip(X, y):\n",
    "                print(f'fit {image.shape}, {label.shape}')\n",
    "                p = self.predict(image)\n",
    "                loss = self.backpass(image, label, p)\n",
    "                if i % 100:\n",
    "                    self.losses.append(loss)\n",
    "   \n",
    "    def predict(self, X):\n",
    "        self.hidden_output = np.matmul(self.hidden_weight, X) + self.hidden_bias\n",
    "        self.activated_hidden = self.sigmoid(self.hidden_output)\n",
    "        \n",
    "        output_output = np.matmul(self.output_weight, self.activated_hidden) + self.output_bias\n",
    "        activated_output = np.exp(output_output) / np.sum(np.exp(output_output), axis=0)\n",
    "        \n",
    "        return activated_output\n",
    "    \n",
    "    def backpass(self, X, y, out):\n",
    "        m = self.batch_size\n",
    "        y = y.reshape(-1, 1)\n",
    "        loss = self.loss(y, out)\n",
    "\n",
    "        delta_output = out - y\n",
    "        delta_output_weight = (1. / m) * np.matmul(delta_output, self.activated_hidden)\n",
    "        delta_output_bais = (1. / m) * np.sum(delta_output, axis=1, keepdims=True)\n",
    "\n",
    "        delta_activation = np.matmul(self.output_weight.T, delta_output)\n",
    "        delta_hidden = delta_activation * self.sigmoid(self.hidden_output) * (1 - self.sigmoid(self.hidden_output))\n",
    "        print(f'back {delta_hidden.shape}, {X.shape}')\n",
    "        delta_hidden_weight = (1. / m) * np.matmul(delta_hidden, X.T)\n",
    "        delta_hidden_bias = (1. / m) * np.sum(delta_hidden, axis=1, keepdims=True)\n",
    "\n",
    "        self.output_weight -= self.lr * delta_output_weight\n",
    "        self.output_bias -= self.lr * delta_output_bias\n",
    "\n",
    "        self.hidden_weight -= self.lr * delta_hidden_weight\n",
    "        self.hidden_bias -= self.lr * delta_hidden_bias\n",
    "        \n",
    "        return loss\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "nni = NNImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit (784,), (60000,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (10,128) (60000,1) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-638b5118fd62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnni\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-79-5a20a647b025>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'fit {image.shape}, {label.shape}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackpass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-79-5a20a647b025>\u001b[0m in \u001b[0;36mbackpass\u001b[0;34m(self, X, y, out)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mdelta_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-79-5a20a647b025>\u001b[0m in \u001b[0;36mloss\u001b[0;34m(self, y, yhat)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myhat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mloss_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m60000\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mloss_sum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (10,128) (60000,1) "
     ]
    }
   ],
   "source": [
    "nni.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPImage(object):\n",
    "    \n",
    "    def __init__(self, epochs=1000, learning_rate=0.001, n_input=784, n_hidden=128, n_out=10):\n",
    "        \n",
    "        # Initialize hyperparameter variables.\n",
    "        self.epochs = epochs\n",
    "        self.lr = learning_rate\n",
    "        self.n_input = n_input\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_out = n_out\n",
    "    \n",
    "        # Initialize weights and biases.\n",
    "        self.hidden_weight = np.random.random(size=(self.n_input + 1, self.n_hidden))\n",
    "        self.output_weight = np.random.random(size=(self.n_hidden + 1, self.n_out))\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def sigmoid_prime(self, x):\n",
    "        return x * (1 - x)\n",
    "\n",
    "    def softmax(self, inputs):\n",
    "        inputs = inputs.flatten()\n",
    "        return np.exp(inputs) / float(sum(np.exp(inputs)))\n",
    "    \n",
    "    def cross_entropy(self, X, y):\n",
    "        \"\"\"\n",
    "        X is the output from fully connected layer (num_examples x num_classes)\n",
    "        y is labels (num_examples x 1)\n",
    "            Note that y is not one-hot encoded vector. \n",
    "            It can be computed as y.argmax(axis=1) from one-hot encoded vectors of labels if required.\n",
    "        \"\"\"\n",
    "        m = y.shape[0]\n",
    "        p = self.softmax(X).reshape((28, 28))\n",
    "        # We use multidimensional array indexing to extract \n",
    "        # softmax probability of the correct label for each sample.\n",
    "        # Refer to https://docs.scipy.org/doc/numpy/user/basics.indexing.html#indexing-multi-dimensional-arrays for understanding multidimensional array indexing.\n",
    "        log_likelihood = -np.log(p[range(m), y])\n",
    "        print(f'cross m {m}, X {log_likelihood.shape}')\n",
    "        loss = np.sum(log_likelihood) / m\n",
    "        return loss\n",
    "\n",
    "    def delta_cross_entropy(self, X, y):\n",
    "        \"\"\"\n",
    "        X is the output from fully connected layer (num_examples x num_classes)\n",
    "        y is labels (num_examples x 1)\n",
    "            Note that y is not one-hot encoded vector. \n",
    "            It can be computed as y.argmax(axis=1) from one-hot encoded vectors of labels if required.\n",
    "        \"\"\"\n",
    "        m = y.shape[0]\n",
    "        grad = self.softmax(X).reshape(1, -1)\n",
    "        print(f'grad {grad.shape}, y {y}')\n",
    "        grad[:, y] -= 1\n",
    "        grad = grad/m\n",
    "        return grad.reshape(- )\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.errors = []\n",
    "        for _ in range(self.epochs):\n",
    "            for image, label in zip(X, y):\n",
    "                image = image.flatten() / 255\n",
    "                out = self.predict(image)\n",
    "                self.backpass(image, label, out)\n",
    "        print(f'Training error at final epoch: {self.errors[-1]}')\n",
    "\n",
    "    def backpass(self, X, y, out):\n",
    "        label = np.zeros((10, 1), dtype=np.int8)\n",
    "        print(f'back {label}')\n",
    "        label[y][0] = 1\n",
    "        error = self.cross_entropy(X, label)        \n",
    "        \n",
    "        self.errors.append(error)\n",
    "        # Caluculate adjustment from hidden -> output.\n",
    "        delta_output = error * self.delta_cross_entropy(X, label)\n",
    "        \n",
    "        # Calculate error from input -> hidden.\n",
    "        output_error = delta_output.dot(self.output_weight[1:].T)\n",
    "        delta_hidden = output_error * self.sigmoid_prime(self.activated_hidden)\n",
    "        \n",
    "        #Adjust hidden -> output weghts.\n",
    "        self.output_weight[1:] += self.activated_hidden.T.dot(delta_output) * self.lr\n",
    "        self.output_weight[0] = np.sum(delta_output)\n",
    "\n",
    "        self.hidden_weight[1:] += X.T.dot(delta_hidden) * self.lr\n",
    "        self.hidden_weight[0] = np.sum(delta_hidden)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        inputs = np.dot(X, self.hidden_weight[1:]) + self.hidden_weight[0]\n",
    "        self.activated_hidden = self.sigmoid(inputs)\n",
    "        output = np.dot(self.activated_hidden, self.output_weight[1:]) + self.output_weight[0]\n",
    "        pred = self.softmax(output)\n",
    "        final = np.argmax(pred)\n",
    "        print(f'pred {pred.shape}, {final}')\n",
    "        return pred\n",
    "        \n",
    "    def plot_error(self):\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.title('Training Error')\n",
    "        plt.plot(self.errors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnimage = MLPImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred (10,), 8\n",
      "back [[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      "cross m 10, X (10, 10)\n",
      "grad (1, 784), y [[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (784,1) and (10,128) not aligned: 1 (dim 1) != 10 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-446-82f68fd539a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnnimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-444-a63f0e4ac49c>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     61\u001b[0m                 \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackpass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Training error at final epoch: {self.errors[-1]}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-444-a63f0e4ac49c>\u001b[0m in \u001b[0;36mbackpass\u001b[0;34m(self, X, y, out)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;31m# Calculate error from input -> hidden.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0moutput_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdelta_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_weight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m         \u001b[0mdelta_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_error\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid_prime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivated_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (784,1) and (10,128) not aligned: 1 (dim 1) != 10 (dim 0)"
     ]
    }
   ],
   "source": [
    "nnimage.fit(x_train[:10000], y_train[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FwlRJSfBlCvy"
   },
   "source": [
    "## Stretch Goals: \n",
    "\n",
    "- Implement Cross Validation model evaluation on your MNIST implementation \n",
    "- Research different [Gradient Descent Based Optimizers](https://keras.io/optimizers/)\n",
    " - [Siraj Raval the evolution of gradient descent](https://www.youtube.com/watch?v=nhqo0u1a6fw)\n",
    "- Build a housing price estimation model using a neural network. How does its accuracy compare with the regression models that we fit earlier on in class?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "LS_DS_432_Backprop_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3.7 (unit4wk2)",
   "language": "python",
   "name": "unit4wk2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
