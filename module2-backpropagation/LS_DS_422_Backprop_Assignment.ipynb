{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LS_DS_432_Backprop_Assignment.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NGGrt9EYlCqY"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "\n",
        "# Backpropagation Practice\n",
        "\n",
        "## *Data Science Unit 4 Sprint 2 Assignment 2*\n",
        "\n",
        "Implement a 3 input, 4 node hidden-layer, 1 output node Multilayer Perceptron on the following dataset:\n",
        "\n",
        "| x1 | x2 | x3 | y |\n",
        "|----|----|----|---|\n",
        "| 0  | 0  | 1  | 0 |\n",
        "| 0  | 1  | 1  | 1 |\n",
        "| 1  | 0  | 1  | 1 |\n",
        "| 0  | 1  | 0  | 1 |\n",
        "| 1  | 0  | 0  | 1 |\n",
        "| 1  | 1  | 1  | 0 |\n",
        "| 0  | 0  | 0  | 0 |\n",
        "\n",
        "If you look at the data you'll notice that the first two columns behave like an XOR gate while the last column is mostly just noise. Remember that creating an XOR gate was what the perceptron was criticized for not being able to learn. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nEREYT-3wI1f",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQ0rbvi7zVLs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NeuralNetwork:\n",
        "    def __init__(self, input_nodes, hidden_nodes, output_nodes):\n",
        "        # Set up Architecture of Neural Network\n",
        "        self.input_nodes = input_nodes\n",
        "        self.hidden_nodes = hidden_nodes\n",
        "        self.output_nodes = output_nodes\n",
        "\n",
        "        self.weights1 = np.random.rand(self.input_nodes, self.hidden_nodes)\n",
        "        self.weights2 = np.random.rand(self.hidden_nodes, self.output_nodes)\n",
        "        \n",
        "    def sigmoid(self, x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "    \n",
        "    def sigmoid_prime(self, x):\n",
        "        return x * (1 - x)\n",
        "    \n",
        "    def feed_forward(self, X):\n",
        "        self.hidden_sum = np.dot(X, self.weights1)\n",
        "        self.hidden_activated = self.sigmoid(self.hidden_sum)\n",
        "\n",
        "        self.output_sum = np.dot(self.hidden_activated, self.weights2)\n",
        "        self.output_activated = self.sigmoid(self.output_sum)\n",
        "        \n",
        "        return self.output_activated\n",
        "        \n",
        "    def backward(self, X, y, output):\n",
        "        self.out_error = y - output\n",
        "        self.out_delta = self.out_error * self.sigmoid_prime(output)\n",
        "        \n",
        "        self.hidden_error = np.dot(self.out_delta, self.weights2.T)\n",
        "        self.hidden_delta = self.hidden_error * self.sigmoid_prime(self.hidden_activated)\n",
        "        \n",
        "        self.weights1 += np.dot(X.T, self.hidden_delta)\n",
        "        self.weights2 += np.dot(self.hidden_activated.T, self.out_delta)\n",
        "\n",
        "    def train(self, X, y):\n",
        "        out = self.feed_forward(X)\n",
        "        self.backward(X, y, out)\n",
        "\n",
        "    def loss(self, X, y):\n",
        "        return np.mean(np.square(y - self.feed_forward(X)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkZWt4cIzcmR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 747
        },
        "outputId": "b7b3a3a1-3945-4569-a8d4-fb107d9879f9"
      },
      "source": [
        "network = NeuralNetwork(3, 4, 1)\n",
        "X = np.array([[0, 0, 1],\n",
        "[0, 1, 1],\n",
        "[1, 0, 1],\n",
        "[0, 1, 0],\n",
        "[1, 0, 0],\n",
        "[1, 1, 1],\n",
        "[0, 0, 0]])\n",
        "y = np.array([[0], [1], [1],[ 1], [1], [0], [0]])\n",
        "\n",
        "losses = []\n",
        "\n",
        "for i in range(1000):\n",
        "    network.train(X,y)\n",
        "    losses.append(network.loss(X, y))\n",
        "\n",
        "print(\"=\"*16 + f\"[ EPOCH {i+1} ]\" + \"=\"*16)\n",
        "print(\"Input:\", np.array2string(X), sep=\"\\n\")\n",
        "print(\"Actual Output:\", np.array2string(y), sep=\"\\n\")\n",
        "print(\"Predicted Output:\", np.array2string(network.feed_forward(X)), sep=\"\\n\")\n",
        "print(\"Loss: \\n\", network.loss(X, y))\n",
        "\n",
        "plt.plot(range(1, len(losses) + 1), losses, marker=\"o\");"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "================[ EPOCH 1000 ]================\n",
            "Input:\n",
            "[[0 0 1]\n",
            " [0 1 1]\n",
            " [1 0 1]\n",
            " [0 1 0]\n",
            " [1 0 0]\n",
            " [1 1 1]\n",
            " [0 0 0]]\n",
            "Actual Output:\n",
            "[[0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]]\n",
            "Predicted Output:\n",
            "[[0.01890926]\n",
            " [0.93784483]\n",
            " [0.94487892]\n",
            " [0.96310725]\n",
            " [0.96433503]\n",
            " [0.06444645]\n",
            " [0.08086715]]\n",
            "Loss: \n",
            " 0.002940723552583\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAYFUlEQVR4nO3df5BV5X3H8fdHCJiYGEE3jllFiCE2\npBg33aCMbco0ohhb2Ey0anRKWkcmnTiJpWMHB6dEg1OtGTWdOqkmsT8iib/qUEajzMZo/3CEsgSC\noqEshCDbREjQ6BiGn9/+cc+ay3L33nPv3l/n3M9rZoe95zz37nP2MJ979nue+zyKCMzMLL+Oa3UH\nzMyssRz0ZmY556A3M8s5B72ZWc456M3Mcm58qzsw0imnnBJTp05tdTfMzDJl/fr1v4qIrlL72i7o\np06dysDAQKu7YWaWKZJ+Pto+l27MzHLOQW9mlnMOejOznEsV9JLmSdoiaVDSkhL7F0t6WdImSc9I\nOrNo32FJG5OvVfXsvJmZVVbxZqykccC9wFxgF7BO0qqIeLmo2QagNyJ+K+mvgX8Erkj27YuIc+vc\nbzMzSynNqJtZwGBEbAeQ9BCwAHgn6CPi2aL2a4Br6tnJNFZuGOLO1Vv4vzf28cGT3s2NF59NX093\ns7thZtZ20pRuuoFXix7vSraN5lrgqaLHx0sakLRGUl+pJ0halLQZ2LNnT4ouHW3lhiFuevxFht7Y\nRwBDb+zjpsdfZOWGoapfy8wsb+p6M1bSNUAvcGfR5jMjohf4PHCPpLNGPi8i7o+I3ojo7eoqOd6/\nrDtXb2HfwcNHbdt38DB3rt5S9WuZmeVNmqAfAs4oenx6su0oki4ElgLzI2L/8PaIGEr+3Q48B/SM\nob+lO/jGvlG3+6rezDpdmqBfB0yXNE3SBOBK4KjRM5J6gPsohPzuou2TJE1Mvj8FuICi2n69qMy+\nGx7eyNQlT3L2zU859M2sI1UM+og4BFwPrAZeAR6JiM2SbpU0P2l2J/Be4NERwyg/CgxI+gnwLHD7\niNE6dZFmjaz9h468E/o3r3yx3l0wM2tbarelBHt7e6PauW6mLnmypp91zflTWN43s6bnmpm1E0nr\nk/uhx8jFJ2MnveddNT3vwTU7Oe+2/jr3xsysveQi6Jf92cdqfu5rbx3gnGVP17E3ZmbtJRdB39fT\nzT1X1P7h2zf3H3bYm1lu5SLooRD2O26/lGvOn1LT89/cf9hlHDPLpdwE/bDlfTPZcful7Lj9Ui44\na3JVz33trQNc/a0XGtQzM7PWyF3QF1tx3Wx23H5pVWWd57ft9fBLM8uVXAf9sGrLOg+u2ekPV5lZ\nbnRE0A8bLuuU+yTtsBsf3djw/piZNUNHBf2wu1OUcg4ewVf1ZpYLHRn0fT3dqco4Nz2+qQm9MTNr\nrI4MeiiUcSqNytl38EiTemNm1jgdG/RQGJUz/QMnlG3jEThmlnUdHfQA/YvnlN3/4JqdzemImVmD\ndHzQA5wwYVzZ/b4pa2ZZ5qAHbvts+amKPdTSzLLMQU9hFM7E8aP/KjzU0syyzEGfuONz55Td/9VV\nm5vUEzOz+nLQJ/p6ust+YvaNfQeb1hczs3py0Be5usYpjs3M2pmDvkil9WNdpzezLHLQV8F1ejPL\nIgf9COUWGned3syyyEE/QqWFxl2+MbOscdCP0NfTXXa/yzdmljUO+hJcvjGzPHHQl+DyjZnliYO+\nBJdvzCxPHPSjcPnGzPLCQT+KSuUbM7OscNCPotLcN67Tm1lWOOjLiDL7XKc3s6xIFfSS5knaImlQ\n0pIS+xdLelnSJknPSDqzaN9CSVuTr4X17HyjdZ/07lH3uU5vZllRMegljQPuBS4BZgBXSZoxotkG\noDcizgEeA/4xee5kYBlwHjALWCZpUv2631g3Xnx2q7tgZjZmaa7oZwGDEbE9Ig4ADwELihtExLMR\n8dvk4Rrg9OT7i4H+iNgbEa8D/cC8+nS98SoNs3Sd3syyIE3QdwOvFj3elWwbzbXAUzU+N1Ncpzez\nLBhfzxeTdA3QC/xxlc9bBCwCmDKlvRb/mPSed/H6b0vX412nN7MsSHNFPwScUfT49GTbUSRdCCwF\n5kfE/mqeGxH3R0RvRPR2dXWl7XtTeDy9mWVdmqBfB0yXNE3SBOBKYFVxA0k9wH0UQn530a7VwEWS\nJiU3YS9KtmWGx9ObWdZVDPqIOARcTyGgXwEeiYjNkm6VND9pdifwXuBRSRslrUqeuxf4GoU3i3XA\nrcm2TPF4ejPLslQ1+oj4AfCDEdv+vuj7C8s89wHggVo72A66T3o3Q2/sK7nPdXoza3f+ZGwKlcbT\nu3xjZu3MQZ+Cpy02syxz0KfkaYvNLKsc9Cl5mKWZZZWDPiVPh2BmWeWgrxPX6c2sXTnoq+A6vZll\nkYO+CpXq9C7fmFk7ctBXwcMszSyLHPRVcvnGzLLGQV8ll2/MLGsc9FVy+cbMssZBXwOXb8wsSxz0\nNXD5xsyyxEFfA5dvzCxLHPQ1cvnGzLLCQV8jT3JmZlnhoK+RJzkzs6xw0DfITY9vanUXzMwAB/2Y\nlKvT7zt4xFf1ZtYWHPRjUKlO79E3ZtYOHPRjUKlO79E3ZtYOHPRjVK58A74pa2at56Afo0rlG9+U\nNbNWc9CPUV9PNydMGDfq/n0HjzSxN2Zmx3LQ18Ftn51Zdr/LN2bWSg76Oqh0U/bGRzc2qSdmZsdy\n0NdJufLNwSO+qjez1nHQ10ml8o2v6s2sVRz0ddLX043K7PdVvZm1ioO+jq4+f0rZ/b6qN7NWcNDX\n0fK+8uUbX9WbWSukCnpJ8yRtkTQoaUmJ/Z+S9GNJhyRdNmLfYUkbk69V9ep4u7qmwlW9P0BlZs1W\nMegljQPuBS4BZgBXSZoxotlO4AvA90q8xL6IODf5mj/G/ra9Slf1/gCVmTVbmiv6WcBgRGyPiAPA\nQ8CC4gYRsSMiNgFOMSpf1d+88sUm9cTMLF3QdwOvFj3elWxL63hJA5LWSOor1UDSoqTNwJ49e6p4\n6fZU6ar+wTU7m9QTM7Pm3Iw9MyJ6gc8D90g6a2SDiLg/Inojorerq6sJXWq8ch+gArj6Wy80qSdm\n1unSBP0QcEbR49OTbalExFDy73bgOaCniv5lVqUPUD2/ba9H4JhZU6QJ+nXAdEnTJE0ArgRSjZ6R\nNEnSxOT7U4ALgJdr7WyW9PV0M3F8+V+vV6Ays2aoGPQRcQi4HlgNvAI8EhGbJd0qaT6ApE9K2gVc\nDtwnaTjBPgoMSPoJ8Cxwe0R0RNAD3PG5c8ru9wpUZtYMiohW9+Eovb29MTAw0Opu1M3ZNz/F/kOj\nD0a64KzJrLhudhN7ZGZ5JGl9cj/0GP5kbINVuqp3rd7MGs1B32CVJjsDz4FjZo3loG+CSpOdeQ4c\nM2skB30TLO+byfjjyl/XL37YV/Vm1hgO+ib5+uUfL7v/CJ4awcwaw0HfJH093Vxw1uSybTw1gpk1\ngoO+idIMo/TUCGZWbw76Jqs0s6WHW5pZvTnom6zSzJbgG7NmVl8O+haodFV/BJdwzKx+HPQtkGa4\npUs4ZlYvDvoWqTTcEvyJWTOrDwd9i6QZbulPzJpZPTjoW2jFdbP9iVkzazgHfYul+cTs3Luea0pf\nzCyfHPQtlmYlqq273/b0CGZWMwd9G6g0Zz14egQzq52Dvg2kuTELHltvZrVx0LeJNDdmPbbezGrh\noG8jacbW3+BROGZWJQd9G0lbwjnvtv4m9MbM8sJB32bSlHBee+uAR+GYWWoO+jaUpoTjUThmlpaD\nvg2lLeH4g1RmloaDvk2tuG42p75vQtk2W3e/7SGXZlaRg76NrV06t2IbD7k0s0oc9G2u0iIl4InP\nzKw8B32bS7NIiVekMrNyHPQZkGYUzvPb9nrIpZmV5KDPgL6e7lQlnAfX7HS93syO4aDPiOV9MytO\nZwyu15vZsVIFvaR5krZIGpS0pMT+T0n6saRDki4bsW+hpK3J18J6dbwTpZnO2PV6MxupYtBLGgfc\nC1wCzACukjRjRLOdwBeA74147mRgGXAeMAtYJmnS2LvdmdKWcDzk0syKpbminwUMRsT2iDgAPAQs\nKG4QETsiYhOFC8piFwP9EbE3Il4H+oF5deh3x1reNzPVp2Y9y6WZDUsT9N3Aq0WPdyXb0kj1XEmL\nJA1IGtizZ0/Kl+5cK66bzfQPnFCxnWe5NDNok5uxEXF/RPRGRG9XV1eru5MJ/YvnVGzz2lsHXK83\ns1RBPwScUfT49GRbGmN5rlWQtl7v8fVmnS1N0K8DpkuaJmkCcCWwKuXrrwYukjQpuQl7UbLN6mB5\n38xUJRyPrzfrbBWDPiIOAddTCOhXgEciYrOkWyXNB5D0SUm7gMuB+yRtTp67F/gahTeLdcCtyTar\nk/7FcyrOcgm+OWvWyRQRre7DUXp7e2NgYKDV3cicqUuerNjmxInj2HSLBz2Z5ZGk9RHRW2pfW9yM\ntbFLU69/c/9hL1Zi1oEc9DmRtl6/dffbvjlr1mEc9DnSv3hO6puzDnuzzuGgz5m0N2c9Esesczjo\nc2jt0rmUX6qkwDNdmnUGB31O3X3FuRXbHAHfnDXrAA76nOrr6U41+dnW3W877M1yzkGfY2knP3PY\nm+Wbgz7n+hfPqbi4OHjYpVmeOeg7QJrFxaEwEsfM8sdB3wHSrkwFcM6ypxvcGzNrNgd9h1jeNzP1\nNAkOe7N8cdB3kGrC3qtTmeWHg77DpF1z9rW3DngkjllOOOg70IrrZqeaJsHDLs3ywUHfodYuncuJ\nE8dVbOewN8s+B30H23TLvFRz4mzd/bYXGTfLMAd9h0szJw54kXGzLHPQd7hqxth7amOzbHLQW+ph\nl+BFxs2yyEFvQHVh7zH2ZtnioLd3eIy9WT456O0ontrYLH8c9HaMtIuMO+zNssFBbyX1L55Dimns\nPcbeLAMc9Daqu/7cY+zN8sBBb6Oqdoy9w96sPTnoraxqhl0+uGanyzhmbchBbxVVE/bPb9vrsDdr\nMw56SyXtGHtwzd6s3TjoLbW0Y+zBNXuzduKgt6qkHWMPngTNrF2kCnpJ8yRtkTQoaUmJ/RMlPZzs\nXytparJ9qqR9kjYmX/9S3+5bK1QT9p4Ezaz1Kga9pHHAvcAlwAzgKkkzRjS7Fng9Ij4M3A3cUbRv\nW0Scm3x9sU79tharJuynLXnSV/ZmLZTmin4WMBgR2yPiAPAQsGBEmwXAvyffPwZ8WlKaxYssw9KG\nfVC4snfN3qw10gR9N/Bq0eNdybaSbSLiEPAb4ORk3zRJGyT9t6Q/KvUDJC2SNCBpYM+ePVUdgLWW\na/Zm7a/RN2N/AUyJiB5gMfA9SSeObBQR90dEb0T0dnV1NbhLVm/9i+dw6vsmpGp7w8MbHfZmTZYm\n6IeAM4oen55sK9lG0njg/cCvI2J/RPwaICLWA9uAj4y109Z+1i6dy4kTx6Vq6zKOWXOlCfp1wHRJ\n0yRNAK4EVo1oswpYmHx/GfCjiAhJXcnNXCR9CJgObK9P163dbLplXuqw9zh7s+apGPRJzf16YDXw\nCvBIRGyWdKuk+Umz7wAnSxqkUKIZHoL5KWCTpI0UbtJ+MSL21vsgrH1sumVe6jKO58Yxaw5FRKv7\ncJTe3t4YGBhodTdsjM67rZ/X3jqQqu2p75vA2qVzG9wjs3yTtD4iekvt8ydjrSGqqdm/9tYBzln2\ndIN7ZNa5HPTWMNWUcd7cf9hhb9YgDnprqLVL51YV9lOXPOmbtGZ15qC3hqsm7KFwk9aLjpvVj4Pe\nmmLt0rmp57OHwqLj593W38AemXUOB701zYrrZnPPFekWHIfCTVqXcszGzkFvTdXX011V2EOhlOOr\ne7PaOeit6WoJe1/dm9XOQW8t0dfTzY7bL63qJi346t6sFg56a6lqb9LC767uPX2CWToOemu5am/S\nDnt+216Xc8xScNBbW6i1lAOFco4D32x0DnprK2uXzuWa86fU9FwHvllpnr3S2lY1M2CWMv0DJ9C/\neE79OmTWxjx7pWXSWK7uofDp2qlLnvRVvnU8X9FbJlz9rRd4ftvY16y54KzJrLhudh16ZNZeyl3R\nO+gtU8Zazinm0Lc8cdBbrqzcMMQND2+s62uOP058/fKP09fTXdfXNWsWB73l0s0rX+TBNTsb8tq+\n2rescdBbrq3cMMSNj27k4JHG/QwHv7U7B711jHrdtE3jmvOnsLxvZlN+llklDnrrOCs3DLH44Y00\n8CK/JF/5W6s46K2jNfMqvxz/BWCN5KA3S7RL6I/kUT82Vg56sxIaOWqnUfyGYKNx0Jul0K5X+2Pl\n+wadwUFvVoO8Bn8t/GbR/hz0ZnXQqpE8ncJvJmPjoDdrIF/5d452HjnloDdrgWZ8YtfyqZY3lHJB\nP74uvTKzY/T1dJcdHZPFUT/WHMP/L+r110OqK3pJ84BvAOOAb0fE7SP2TwT+A/gD4NfAFRGxI9l3\nE3AtcBj4ckSsLvezfEVvdjS/IXSmcRLb/uEzqduP6Ype0jjgXmAusAtYJ2lVRLxc1Oxa4PWI+LCk\nK4E7gCskzQCuBD4GfBD4oaSPRMTh1L0363DL+2ZWfWU3967n2Lr77Qb1yJrhcB3L6mlKN7OAwYjY\nDiDpIWABUBz0C4CvJt8/BvyzJCXbH4qI/cDPJA0mr/dCfbpvZqXUY61c32RurXFS3V4rTdB3A68W\nPd4FnDdam4g4JOk3wMnJ9jUjnntM0VLSImARwJQpta8Ramb104yhjn4zGd1V551Rt9dqi5uxEXE/\ncD8UavQt7o6ZNUm7j5tv1f2Reg/jTBP0Q0DxW8vpybZSbXZJGg+8n8JN2TTPNTNrS7XcH2lHx6Vo\nsw6YLmmapAkUbq6uGtFmFbAw+f4y4EdRGM6zCrhS0kRJ04DpwP/Up+tmZpZGxSv6pOZ+PbCawvDK\nByJis6RbgYGIWAV8B/hucrN1L4U3A5J2j1C4cXsI+JJH3JiZNZc/GWtmlgPlxtGnKd2YmVmGOejN\nzHKu7Uo3kvYAP6/x6acAv6pjd7LAx9wZfMydYSzHfGZEdJXa0XZBPxaSBkarUeWVj7kz+Jg7Q6OO\n2aUbM7Occ9CbmeVc3oL+/lZ3oAV8zJ3Bx9wZGnLMuarRm5nZsfJ2RW9mZiM46M3Mci43QS9pnqQt\nkgYlLWl1f+pF0hmSnpX0sqTNkr6SbJ8sqV/S1uTfScl2Sfqn5PewSdInWnsEtZE0TtIGSU8kj6dJ\nWpsc18PJBHskE+Y9nGxfK2lqK/tdK0knSXpM0k8lvSJpdgec479J/k+/JOn7ko7P43mW9ICk3ZJe\nKtpW9bmVtDBpv1XSwlI/azS5CPqi5Q4vAWYAVyXLGObBIeBvI2IGcD7wpeTYlgDPRMR04JnkMRR+\nB9OTr0XAN5vf5br4CvBK0eM7gLsj4sPA6xSWr4SiZSyBu5N2WfQN4OmI+D3g4xSOPbfnWFI38GWg\nNyJ+n8KEicPLkObtPP8bMG/EtqrOraTJwDIKiz7NApYNvzmkEhGZ/wJmA6uLHt8E3NTqfjXoWP+L\nwvq9W4DTkm2nAVuS7+8Dripq/067rHxRWLfgGeBPgCcAUfi04PiR55vCrKqzk+/HJ+3U6mOo8njf\nD/xsZL9zfo6HV6WbnJy3J4CL83qeganAS7WeW+Aq4L6i7Ue1q/SViyt6Si93eMyShVmX/LnaA6wF\nTo2IXyS7fgmcmnyfh9/FPcDfAUeSxycDb0TEoeRx8TEdtYwlMLyMZZZMA/YA/5qUq74t6QRyfI4j\nYgj4OrAT+AWF87aefJ/nYtWe2zGd87wEfe5Jei/wn8ANEfFm8b4ovMXnYpyspD8FdkfE+lb3pYnG\nA58AvhkRPcDb/O5PeSBf5xggKTssoPAm90HgBI4tb3SEZpzbvAR9rpcslPQuCiG/IiIeTza/Jum0\nZP9pwO5ke9Z/FxcA8yXtAB6iUL75BnBSskwlHH1M7xzviGUss2QXsCsi1iaPH6MQ/Hk9xwAXAj+L\niD0RcRB4nMK5z/N5LlbtuR3TOc9L0KdZ7jCTJInCCl6vRMRdRbuKl29cSKF2P7z9L5K79+cDvyn6\nE7HtRcRNEXF6REylcB5/FBFXA89SWKYSjj3eUstYZkZE/BJ4VdLZyaZPU1iVLZfnOLETOF/Se5L/\n48PHnNvzPEK153Y1cJGkSclfQxcl29Jp9U2KOt7s+Azwv8A2YGmr+1PH4/pDCn/WbQI2Jl+foVCf\nfAbYCvwQmJy0F4URSNuAFymMamj5cdR47HOAJ5LvP0RhveFB4FFgYrL9+OTxYLL/Q63ud43Hei4w\nkJznlcCkvJ9j4Bbgp8BLwHeBiXk8z8D3KdyHOEjhr7drazm3wF8lxz8I/GU1ffAUCGZmOZeX0o2Z\nmY3CQW9mlnMOejOznHPQm5nlnIPezCznHPRmZjnnoDczy7n/B4PDOwbkYgTMAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8b-r70o8p2Dm"
      },
      "source": [
        "## Try building/training a more complex MLP on a bigger dataset.\n",
        "\n",
        "Use the [MNIST dataset](http://yann.lecun.com/exdb/mnist/) to build the cannonical handwriting digit recognizer and see what kind of accuracy you can achieve. \n",
        "\n",
        "If you need inspiration, the internet is chalk-full of tutorials, but I want you to see how far you can get on your own first. I've linked to the original MNIST dataset above but it will probably be easier to download data through a neural network library. If you reference outside resources make sure you understand every line of code that you're using from other sources, and share with your fellow students helpful resources that you find.\n",
        "\n",
        "\n",
        "### Parts\n",
        "1. Gathering & Transforming the Data\n",
        "2. Making MNIST a Binary Problem\n",
        "3. Estimating your Neural Network (the part you focus on)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHHDVbainV_h",
        "colab_type": "text"
      },
      "source": [
        "### Gathering the Data \n",
        "\n",
        "`keras` has a handy method to pull the mnist dataset for you. You'll notice that each observation is a 28x28 arrary which represents an image. Although most Neural Network frameworks can handle higher dimensional data, that is more overhead than necessary for us. We need to flatten the image to one long row which will be 784 values (28X28). Basically, you will be appending each row to one another to make on really long row. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxtdkfJKnV_i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "outputId": "815d28a7-7471-454c-fa14-f5fff2bf58ae"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wO1Jq39ynV_o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bX7vPD2mnV_w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6znWTEqnV_3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = x_train.reshape(x_train.shape[0], img_rows * img_cols)\n",
        "x_test = x_test.reshape(x_test.shape[0], img_rows * img_cols)\n",
        "\n",
        "# Normalize Our Data\n",
        "x_train = x_train / 255\n",
        "x_test = x_test / 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxpEduE4nV_9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0afdbc0c-ffc9-4ea5-ead9-285766a45d25"
      },
      "source": [
        "# Now the data should be in a format you're more familiar with\n",
        "x_train.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIsqH2zsnWAE",
        "colab_type": "text"
      },
      "source": [
        "### Making MNIST a Binary Problem \n",
        "MNIST is multiclass classification problem; however we haven't covered all the necessary techniques to handle this yet. You would need to one-hot encode the target, use a different loss metric, and use softmax activations for the last layer. This is all stuff we'll cover later this week, but let us simply the problem for now: Zero or all else."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aK1Fb-ySnWAG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "y_temp = np.zeros(y_train.shape)\n",
        "y_temp[np.where(y_train == 0.0)[0]] = 1\n",
        "y_train = y_temp\n",
        "\n",
        "y_temp = np.zeros(y_test.shape)\n",
        "y_temp[np.where(y_test == 0.0)[0]] = 1\n",
        "y_test = y_temp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snsoAS9EnWAM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ffa509be-d694-4c58-9bfd-67787f38865a"
      },
      "source": [
        "# A Nice Binary target for ya to work with\n",
        "y_train"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 0., ..., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R68QCaiSgT-l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "b9d897aa-31de-4f99-8362-7d4cc1cb5aa7"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "sample_index = np.random.randint(x_train.shape[0], size=5000)\n",
        "\n",
        "X_sample = x_train[sample_index]\n",
        "y_sample = np.array(pd.DataFrame(data=y_train[sample_index]))\n",
        "y_sample"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       ...,\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfLm8P6HnWAT",
        "colab_type": "text"
      },
      "source": [
        "### Estimating Your `net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdTormcPaAE5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NeuralNetwork2:\n",
        "    def __init__(self, input_nodes=784, hidden_nodes=32, output_nodes=1):\n",
        "        # Set up Architecture of Neural Network\n",
        "        self.input_nodes = input_nodes\n",
        "        self.hidden1_nodes = hidden_nodes\n",
        "        self.hidden2_nodes = hidden_nodes\n",
        "        self.output_nodes = output_nodes\n",
        "\n",
        "        self.weights1 = np.random.rand(self.input_nodes, self.hidden1_nodes)\n",
        "        self.weights2 = np.random.rand(self.hidden1_nodes, self.hidden2_nodes)\n",
        "        self.weights3 = np.random.rand(self.hidden2_nodes, self.output_nodes)\n",
        "        \n",
        "    def sigmoid(self, x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "    \n",
        "    def sigmoid_prime(self, x):\n",
        "        return x * (1 - x)\n",
        "    \n",
        "    def feed_forward(self, X):\n",
        "        self.hidden1_sum = np.dot(X, self.weights1)\n",
        "        self.hidden1_activated = self.sigmoid(self.hidden1_sum)\n",
        "\n",
        "        self.hidden2_sum = np.dot(self.hidden1_activated, self.weights2)\n",
        "        self.hidden2_activated = self.sigmoid(self.hidden2_sum)\n",
        "\n",
        "        self.output_sum = np.dot(self.hidden2_activated, self.weights3)\n",
        "        self.output_activated = self.sigmoid(self.output_sum)\n",
        "        \n",
        "    def backward(self, X, y):\n",
        "        self.out_error = y - self.output_activated\n",
        "        self.out_delta = self.out_error * self.sigmoid_prime(self.output_activated)\n",
        "        \n",
        "        self.hidden2_error = np.dot(self.out_delta, self.weights3.T)\n",
        "        self.hidden2_delta = self.hidden2_error * self.sigmoid_prime(self.hidden2_activated)\n",
        "\n",
        "        self.hidden1_error = np.dot(self.hidden2_delta, self.weights2.T)\n",
        "        self.hidden1_delta = self.hidden1_error * self.sigmoid_prime(self.hidden1_activated)\n",
        "        \n",
        "        self.weights1 += np.dot(X.T, self.hidden1_delta)\n",
        "        self.weights2 += np.dot(self.hidden1_activated.T, self.hidden2_delta)\n",
        "        self.weights3 += np.dot(self.hidden2_activated.T, self.out_delta)\n",
        "\n",
        "    def train(self, X, y):\n",
        "        self.feed_forward(X)\n",
        "        self.backward(X, y)\n",
        "\n",
        "    def loss(self, X, y):\n",
        "        self.feed_forward(X)\n",
        "        return np.mean(np.square(y - self.output_activated))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5MOPtYdk1HgA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        },
        "outputId": "f3728db3-8314-4e04-a1d4-a36c90b0ed3c"
      },
      "source": [
        "##### Your Code Here #####\n",
        "\n",
        "network2 = NeuralNetwork2()\n",
        "\n",
        "losses = []\n",
        "\n",
        "for i in range(100):\n",
        "    network2.train(X_sample, y_sample)\n",
        "    losses.append(network2.loss(X_sample, y_sample))\n",
        "\n",
        "print(\"=\"*16 + f\"[ EPOCH {i+1} ]\" + \"=\"*16)\n",
        "print(\"Input:\", np.array2string(X), sep=\"\\n\")\n",
        "print(\"Actual Output:\", np.array2string(y), sep=\"\\n\")\n",
        "print(\"Predicted Output:\", np.array2string(network2.output_activated), sep=\"\\n\")\n",
        "print(\"Loss: \\n\", network2.loss(X_sample, y_sample))\n",
        "print(\"Weights: \\n\", network2.weights2)\n",
        "\n",
        "plt.plot(range(1, len(losses) + 1), losses, marker=\"o\");\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "================[ EPOCH 100 ]================\n",
            "Input:\n",
            "[[0 0 1]\n",
            " [0 1 1]\n",
            " [1 0 1]\n",
            " [0 1 0]\n",
            " [1 0 0]\n",
            " [1 1 1]\n",
            " [0 0 0]]\n",
            "Actual Output:\n",
            "[[0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]]\n",
            "Predicted Output:\n",
            "[[0.99999998]\n",
            " [0.99999998]\n",
            " [0.99999998]\n",
            " ...\n",
            " [0.99999998]\n",
            " [0.99999998]\n",
            " [0.99999998]]\n",
            "Loss: \n",
            " 0.9031999619916372\n",
            "Weights: \n",
            " [[0.42521573 0.64151572 0.44010847 ... 0.45452647 0.89269294 0.96371713]\n",
            " [0.25981781 0.15829854 0.75720897 ... 0.94025541 0.3634275  0.53752323]\n",
            " [0.56591759 0.90289046 0.79924982 ... 0.65431636 0.94998239 0.43183084]\n",
            " ...\n",
            " [0.81286978 0.88468882 0.03537155 ... 0.57645084 0.4011842  0.64217293]\n",
            " [0.98607503 0.52141208 0.06526268 ... 0.5382251  0.08201568 0.47111267]\n",
            " [0.77845993 0.99826813 0.52855291 ... 0.15642456 0.64027452 0.48938041]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAEDCAYAAAAsr19QAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FwlRJSfBlCvy"
      },
      "source": [
        "## Stretch Goals: \n",
        "\n",
        "- Make MNIST a multiclass problem using cross entropy & soft-max\n",
        "- Implement Cross Validation model evaluation on your MNIST implementation \n",
        "- Research different [Gradient Descent Based Optimizers](https://keras.io/optimizers/)\n",
        " - [Siraj Raval the evolution of gradient descent](https://www.youtube.com/watch?v=nhqo0u1a6fw)\n",
        "- Build a housing price estimation model using a neural network. How does its accuracy compare with the regression models that we fit earlier on in class?"
      ]
    }
  ]
}