{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LS_DS_432_Backprop_Assignment.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "nteract": {
      "version": "0.22.4"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NGGrt9EYlCqY"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "\n",
        "# Backpropagation Practice\n",
        "\n",
        "## *Data Science Unit 4 Sprint 2 Assignment 2*\n",
        "\n",
        "Using TensorFlow Keras, Implement a 3 input, 4 node hidden-layer, 1 output node Multilayer Perceptron on the following dataset:\n",
        "\n",
        "| x1 | x2 | x3 | y |\n",
        "|----|----|----|---|\n",
        "| 0  | 0  | 1  | 0 |\n",
        "| 0  | 1  | 1  | 1 |\n",
        "| 1  | 0  | 1  | 1 |\n",
        "| 0  | 1  | 0  | 1 |\n",
        "| 1  | 0  | 0  | 1 |\n",
        "| 1  | 1  | 1  | 0 |\n",
        "| 0  | 0  | 0  | 0 |\n",
        "\n",
        "If you look at the data you'll notice that the first two columns behave like an XOR gate while the last column is mostly just noise. Remember that creating an XOR gate was what the perceptron was criticized for not being able to learn.\n",
        "\n",
        "This is your \"Hello World!\" of TensorFlow.\n",
        "\n",
        "### Example TensorFlow Starter Code\n",
        "\n",
        "```python \n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(3, activation='sigmoid', input_dim=2),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['acc'])\n",
        "\n",
        "results = model.fit(X,y, epochs=100)\n",
        "\n",
        "```\n",
        "\n",
        "### Additional Written Tasks:\n",
        "1. Investigate the various [loss functions](https://www.tensorflow.org/api_docs/python/tf/keras/losses). Which is best suited for the task at hand (predicting 1 / 0) and why? \n",
        "2. What is the difference between a loss function and a metric? Why might we need both in Keras? \n",
        "3. Investigate the various [optimizers](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers). Stochastic Gradient Descent (`sgd`) is not the learning algorithm dejour anyone. Why is that? What do newer optimizers such as `adam` have to offer? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nEREYT-3wI1f",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(\n",
        "    {\n",
        "        \"x1\": [0, 0, 1, 0, 1, 1, 0],\n",
        "        \"x2\": [0, 1, 0, 1, 0, 1, 0],\n",
        "        \"x3\": [1, 1, 1, 0, 0, 1, 0],\n",
        "        \"y\": [0, 1, 1, 1, 1, 0, 0],\n",
        "    }\n",
        ")"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_yYZOB3-ecL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "class NeuralNetwork:\n",
        "    \n",
        "    def __init__(self):\n",
        "        # inputs, hidden, output per spec above\n",
        "        self.inputs = 3\n",
        "        self.hiddenNodes = 4\n",
        "        self.outputNodes = 1\n",
        "        \n",
        "        # initialize weights for input -> hidden which is 3 x 4 array\n",
        "        self.weights_one = np.random.randn(self.inputs, self.hiddenNodes)\n",
        "        # initialize weights for hidden -> output which is 4 x 1 array\n",
        "        self.weights_two = np.random.randn(self.hiddenNodes, self.outputNodes)\n",
        "        \n",
        "    # sigmoid function \n",
        "    def sigmoid(self, s):\n",
        "        return 1 / (1+np.exp(-s))\n",
        "    \n",
        "    # derivative of sigmoid helper\n",
        "    def derivative(self, s):\n",
        "        sx = self.sigmoid(s)\n",
        "        return sx * (1-sx)\n",
        "    \n",
        "    def feed_forward(self, X):\n",
        "        \"\"\"\n",
        "        Calculate NN inference using feed forward\n",
        "        \"\"\"\n",
        "        # weighted sum\n",
        "        self.hidden_sum = np.dot(X, self.weights_one)\n",
        "        \n",
        "        # activate\n",
        "        self.activated_hidden = self.sigmoid(self.hidden_sum)\n",
        "        \n",
        "        # weighted sum of activated hidden which output will use\n",
        "        self.output_sum = np.dot(self.activated_hidden, self.weights_two)\n",
        "        \n",
        "        # final activation of output (predictions)\n",
        "        self.activated_output = self.sigmoid(self.output_sum)\n",
        "        \n",
        "        return self.activated_output\n",
        "    \n",
        "    def backward(self, X, y, o):\n",
        "        \"\"\"\n",
        "        Back prop thru with errors and make adjustments\n",
        "        \"\"\"\n",
        "        # absolute error\n",
        "        self.o_error = y - o\n",
        "        # partial derivative of error \n",
        "        self.o_delta = self.o_error * self.derivative(o)\n",
        "        # z2 error: amount output layer weights were off by \n",
        "        self.z2_error = self.o_delta.dot(self.weights_two.T)\n",
        "        \n",
        "        # z2 delta\n",
        "        self.z2_delta = self.z2_error*self.derivative(self.activated_hidden)\n",
        "        \n",
        "        # adjust weights by the deltas\n",
        "        self.weights_one += X.T.dot(self.z2_delta)\n",
        "        self.weights_two += self.activated_hidden.T.dot(self.o_delta)\n",
        "    \n",
        "    def train(self, X, y):\n",
        "        o = self.feed_forward(X)\n",
        "        self.backward(X, y, o)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNgYqS8U_tdQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nn = NeuralNetwork()\n",
        "\n",
        "nn.train(X,y)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjCF4fZ4-ecS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nn = NeuralNetwork()\n",
        "\n",
        "# Number of Epochs / Iterations\n",
        "for i in range(10000):\n",
        "    if (i+1 in [1,2,3,4,5]) or ((i+1) % 1000 ==0):\n",
        "        print('+' + '---' * 3 + f'EPOCH {i+1}' + '---'*3 + '+')\n",
        "        print('Input: \\n', X)\n",
        "        print('Actual Output: \\n', y)\n",
        "        print('Predicted Output: \\n', str(nn.feed_forward(X)))\n",
        "        print(\"Loss: \\n\", str(np.mean(np.square(y - nn.feed_forward(X)))))\n",
        "    nn.train(X,y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_J0fhEGw-ecZ",
        "colab_type": "text"
      },
      "source": [
        "### Build a Tensor Keras Perceptron\n",
        "\n",
        "Try to match the architecture we used on Monday - inputs nodes and one output node. Apply this architecture to the XOR-ish dataset above. \n",
        "\n",
        "After fitting your model answer these questions: \n",
        "\n",
        "Are you able to achieve the same results as a bigger architecture from the first part of the assignment? Why is this disparity the case? What properties of the XOR dataset would cause this disparity? \n",
        "\n",
        "Now extrapolate this behavior on a much larger dataset in terms of features. What kind of architecture decisions could we make to avoid the problems the XOR dataset presents at scale? \n",
        "\n",
        "*Note:* The bias term is baked in by default in the Dense layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgyKVtj7CWLf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "dcec951b-9386-439f-a006-3356ff1506c6"
      },
      "source": [
        "X"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 1],\n",
              "       [0, 1, 1],\n",
              "       [1, 0, 1],\n",
              "       [0, 1, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 1, 1],\n",
              "       [0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwbKuy8t-eca",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential([\n",
        "    Dense(1, activation='relu', input_dim=3),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "results = model.fit(X, y, epochs=400, verbose=0)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XthiVqyUE7gj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "c8e2a58a-9df5-4a76-a462-d4039f4d45ae"
      },
      "source": [
        "epochs = pd.DataFrame.from_dict(results.history)\n",
        "epochs"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.600241</td>\n",
              "      <td>0.571429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.600151</td>\n",
              "      <td>0.571429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.599912</td>\n",
              "      <td>0.571429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.599715</td>\n",
              "      <td>0.571429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.599541</td>\n",
              "      <td>0.571429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>395</th>\n",
              "      <td>0.547720</td>\n",
              "      <td>0.714286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>396</th>\n",
              "      <td>0.547612</td>\n",
              "      <td>0.714286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>397</th>\n",
              "      <td>0.547531</td>\n",
              "      <td>0.714286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>398</th>\n",
              "      <td>0.547452</td>\n",
              "      <td>0.714286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399</th>\n",
              "      <td>0.547333</td>\n",
              "      <td>0.714286</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>400 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         loss  accuracy\n",
              "0    0.600241  0.571429\n",
              "1    0.600151  0.571429\n",
              "2    0.599912  0.571429\n",
              "3    0.599715  0.571429\n",
              "4    0.599541  0.571429\n",
              "..        ...       ...\n",
              "395  0.547720  0.714286\n",
              "396  0.547612  0.714286\n",
              "397  0.547531  0.714286\n",
              "398  0.547452  0.714286\n",
              "399  0.547333  0.714286\n",
              "\n",
              "[400 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ab7CkJFFSa1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "7178620e-d9a7-4cb2-9d3b-30b707c328ea"
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "for column in epochs:\n",
        "    fig, ax = plt.subplots()\n",
        "    sns.lineplot(data=epochs_df[column], ax=ax)\n",
        "    plt.title(column.title())"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAYBElEQVR4nO3df5BdZ33f8ffH619ADJawAMcSlgC5QAO1jerQmhBPOjaCFpsOlAqSImYCnv5wQ0KSYk86hopmhmQmgXTiFhwqIGkc0xhKN1TUuAVCh8SgdTDGEhhkgbEUg9eWDSQB/OvbP+5Z6bJZae+92t27z+X9mrmjc55zzt7vHu1+9rnPPfc5qSokSZPrhHEXIElaXga9JE04g16SJpxBL0kTzqCXpAln0EvShDPoJWnCGfSaKEk+leSBJKeMuxZptTDoNTGSbAR+Cijg0hV83hNX6rmkURj0miSvA24G3g9sn2tMsiHJh5PMJrk/ye/2bXtjki8l+W6SvUnO79orybP69nt/kv/YLV+U5ECStyT5JvC+JGuSfLR7jge65fV9x69N8r4kf9lt/0jXfnuSl/ftd1KS+5Kct2xnST9yDHpNktcBf9g9XpLkqUmmgI8CdwEbgbOA6wGS/DPgbd1xT6T3KuD+AZ/racBa4Gzgcnq/S+/r1p8OfA/43b79/wB4PPB3gacA7+zafx/4ub79XgbcU1WfH7AOaVFxrhtNgiQvAj4JnFlV9yX5MvAeej386a79kXnH3AjsqqrfWeDrFbC5qvZ16+8HDlTVv09yEfBx4IlV9f2j1HMu8MmqWpPkTOAg8OSqemDefj8O3AGcVVXfSXID8Lmq+s2RT4Y0jz16TYrtwMer6r5u/bqubQNw1/yQ72wA7hzx+Wb7Qz7J45O8J8ldSb4DfBo4vXtFsQE4ND/kAarqL4HPAK9McjrwUnqvSKQl45tIal6SxwGvBqa6MXOAU4DTgW8BT09y4gJhfzfwzKN82b+hN9Qy52nAgb71+S+Ffxn4O8BPVtU3ux7954F0z7M2yelV9eACz/UB4A30fh//vKoOHv27lYZnj16T4BXAo8BzgXO7x3OA/9dtuwd4R5InJDk1yYXdce8FfiXJC9LzrCRnd9tuBV6bZCrJVuCnF6nhNHrj8g8mWQu8dW5DVd0DfAz4z92bticleXHfsR8BzgfeRG/MXlpSBr0mwXbgfVX1jar65tyD3puhrwFeDjwL+Aa9Xvk/B6iqPwZ+nd4wz3fpBe7a7mu+qTvuQeBnu23H8i7gccB99N4X+N/ztv8L4GHgy8C9wC/Obaiq7wEfAjYBHx7ye5cW5Zux0iqQ5GrgnKr6uUV3lobkGL00Zt1Qz8/T6/VLS86hG2mMkryR3pu1H6uqT4+7Hk0mh24kacLZo5ekCbfqxujPOOOM2rhx47jLkKSm3HLLLfdV1bqFtq26oN+4cSMzMzPjLkOSmpLkrqNtc+hGkiacQS9JE86gl6QJZ9BL0oQz6CVpwhn0kjThDHpJmnCr7jp6teGu+/+aD//FQZxCQ1o6T3vS43jtTz59yb+uQa+RXPe5b/CeP91PMu5KpMlx7obTDXqtHo8+Wjzh5Cn27Ng67lIkLcIxeo3EARupHQa9RlIFcdxGaoJBr5EUhTEvtcGg10iqwKSX2mDQa2TmvNSGgYI+ydYkdyTZl+TKBba/M8mt3eMrSR7s27Y9yVe7x/alLF7jU1WO0UuNWPTyyiRTwDXAxcABYHeS6araO7dPVf1S3/7/FjivW14LvBXYQu9CjVu6Yx9Y0u9CK67Aa+ilRgzSo78A2FdV+6vqIeB64LJj7P8a4I+65ZcAN1XVoS7cbwK88HoCVDl0I7VikKA/C7i7b/1A1/a3JDkb2AR8Yphjk1yeZCbJzOzs7CB1a8wKh26kViz1m7HbgBuq6tFhDqqqa6tqS1VtWbduwXvbapWxRy+1Y5CgPwhs6Ftf37UtZBtHhm2GPVYNcYxeascgQb8b2JxkU5KT6YX59PydkjwbWAP8eV/zjcAlSdYkWQNc0rWpcb1JK016qQWLXnVTVY8kuYJeQE8BO6tqT5IdwExVzYX+NuD66pu3tqoOJXk7vT8WADuq6tDSfgsaj7JHLzVioNkrq2oXsGte29Xz1t92lGN3AjtHrE+rlGP0Ujv8ZKxG0pvUbNxVSBqEQa+R9CY1M+mlFhj0Gok9eqkdBr1G4uSVUjsMeo3EG49I7TDoNZLyZoJSMwx6jcYxeqkZBr1G4hQIUjsMeo2kyssrpVYY9BqJPXqpHQa9RuIUCFI7DHqNpNejN+qlFhj0GklvjF5SCwx6jcTp6KV2GPQajWP0UjMMeo3Em4NL7TDoNRKvupHaYdBrJE5TLLXDoNdIvPGI1A6DXiOxRy+1w6DXSJykWGqHQa+ReOMRqR0GvUbkJ2OlVhj0Golj9FI7DHqNxGmKpXYY9BqJNx6R2jFQ0CfZmuSOJPuSXHmUfV6dZG+SPUmu62t/NMmt3WN6qQrXeNmjl9px4mI7JJkCrgEuBg4Au5NMV9Xevn02A1cBF1bVA0me0vclvldV5y5x3Rozp0CQ2jFIj/4CYF9V7a+qh4Drgcvm7fNG4JqqegCgqu5d2jK12vSmKTbqpRYMEvRnAXf3rR/o2vqdA5yT5DNJbk6ytW/bqUlmuvZXLPQESS7v9pmZnZ0d6hvQeHjjEakdiw7dDPF1NgMXAeuBTyd5XlU9CJxdVQeTPAP4RJIvVtWd/QdX1bXAtQBbtmzxQ5eNsEMvtWGQHv1BYEPf+vqurd8BYLqqHq6qrwFfoRf8VNXB7t/9wKeA846zZq0CjtFL7Rgk6HcDm5NsSnIysA2Yf/XMR+j15klyBr2hnP1J1iQ5pa/9QmAvap43HpHasejQTVU9kuQK4EZgCthZVXuS7ABmqmq623ZJkr3Ao8CvVtX9Sf4h8J4kj9H7o/KO/qt11C579FI7Bhqjr6pdwK55bVf3LRfw5u7Rv8+fAc87/jK12jgFgtQOPxmrkXjjEakdBr1GUoVjN1IjDHqNxJyX2mHQazSO0UvNMOg1EsfopXYY9BqJV91I7TDoNRKnKZbaYdBrJN54RGqHQa+R2KOX2mHQayTlHKNSMwx6jaTXo7dLL7XAoNdovPGI1AyDXiNxjF5qh0GvkThNsdQOg14j8cYjUjsMeo3EHr3UDoNeI3EKBKkdBr1G0ruM3qSXWmDQayRVZY9eaoRBr5GZ81IbDHqNxDF6qR0GvUbijUekdhj0Gok9eqkdBr1G4hQIUjsMeo3EG49I7Rgo6JNsTXJHkn1JrjzKPq9OsjfJniTX9bVvT/LV7rF9qQrXeBV42Y3UiBMX2yHJFHANcDFwANidZLqq9vbtsxm4Criwqh5I8pSufS3wVmALvWy4pTv2gaX/VrSinAJBasYgPfoLgH1Vtb+qHgKuBy6bt88bgWvmAryq7u3aXwLcVFWHum03AVuXpnSNkzcekdoxSNCfBdzdt36ga+t3DnBOks8kuTnJ1iGOJcnlSWaSzMzOzg5evcamvPGI1IylejP2RGAzcBHwGuD3kpw+6MFVdW1VbamqLevWrVuikrScvOpGascgQX8Q2NC3vr5r63cAmK6qh6vqa8BX6AX/IMeqQU5TLLVjkKDfDWxOsinJycA2YHrePh+h15snyRn0hnL2AzcClyRZk2QNcEnXpsZ54xGpHYtedVNVjyS5gl5ATwE7q2pPkh3ATFVNcyTQ9wKPAr9aVfcDJHk7vT8WADuq6tByfCNaWfbopXYsGvQAVbUL2DWv7eq+5QLe3D3mH7sT2Hl8ZWq1qcKklxrhJ2M1Mj8ZK7XBoNdIvPGI1A6DXiNx5EZqh0GvkThNsdQOg14jc4xeaoNBr5H0rqMfdxWSBmHQayQO3UjtMOg1kgJ8O1Zqg0Gvkdijl9ph0GtETlMstcKg10js0UvtMOg1kt4Hpkx6qQUGvUbiFAhSOwaavbIF3/n+w7zlhtvGXcaPhBOnTuCBv3nY/rzUiIkJ+sceK+6c/atxlzHxHn2suHP2rwFvDi61YmKC/vTHn8zHf+mnx13GxPvO9x/m+W/7+LjLkDQEx+g1lBP6evF26KU2GPQaygl94e5VN1IbDHoNxR691B6DXkPJD/XoJbXAoNdQTrAbLzXHoNdQHLqR2mPQayg/9GasSS81waDXUPrD3ZiX2mDQa2iHe/UmvdQEg15Dm+vVex291IaBgj7J1iR3JNmX5MoFtr8+yWySW7vHG/q2PdrXPr2UxWs85nr0DtFLbVh0rpskU8A1wMXAAWB3kumq2jtv1w9W1RULfInvVdW5x1+qVotej947TEmtGKRHfwGwr6r2V9VDwPXAZctbllYze/RSWwYJ+rOAu/vWD3Rt870yyW1Jbkiyoa/91CQzSW5O8oqFniDJ5d0+M7Ozs4NXr7E4wTF6qSlL9WbsnwAbq+r5wE3AB/q2nV1VW4DXAu9K8sz5B1fVtVW1paq2rFu3bolK0nI5HPTmvNSEQYL+INDfQ1/ftR1WVfdX1Q+61fcCL+jbdrD7dz/wKeC846hXq8BcwJvzUhsGCfrdwOYkm5KcDGwDfujqmSRn9q1eCnypa1+T5JRu+QzgQmD+m7hqzOFpEOzSS01Y9KqbqnokyRXAjcAUsLOq9iTZAcxU1TTwC0kuBR4BDgGv7w5/DvCeJI/R+6PyjgWu1lFj7NFLbRnoVoJVtQvYNa/t6r7lq4CrFjjuz4DnHWeNWmUOfzDWpJea4CdjNTQ/GSu1xaDX0OzRS20x6DU0x+ilthj0GoHX0UstMeg1tCNXV5r0UgsMeg3NeJfaYtBraH5eSmqLQa+hzV1W6eWVUhsMeg3NHr3UFoNeQ/OWsVJbDHoNLU5TLDXFoNfIHKOX2mDQa2iO0UttMeg1NANeaotBr6EdvrzSxJeaYNBraE5qJrXFoNfQnKZYaotBr6EdufGIpBYY9BrakR69US+1wKDX8Ly8UmqKQa+hOQWC1BaDXkOLn5iSmmLQa2TGvNQGg15D8/JKqS0GvYZ25ANTJr3UgoGCPsnWJHck2ZfkygW2vz7JbJJbu8cb+rZtT/LV7rF9KYvXeByZAmHMhUgayImL7ZBkCrgGuBg4AOxOMl1Ve+ft+sGqumLesWuBtwJbgAJu6Y59YEmq11g4BYLUlkF69BcA+6pqf1U9BFwPXDbg138JcFNVHerC/SZg62ilarWxRy+1YZCgPwu4u2/9QNc23yuT3JbkhiQbhjk2yeVJZpLMzM7ODli6xuXIFAgmvdSCpXoz9k+AjVX1fHq99g8Mc3BVXVtVW6pqy7p165aoJC2X/K0FSavZIEF/ENjQt76+azusqu6vqh90q+8FXjDosWqPY/RSWwYJ+t3A5iSbkpwMbAOm+3dIcmbf6qXAl7rlG4FLkqxJsga4pGtTw458MNaol1qw6FU3VfVIkivoBfQUsLOq9iTZAcxU1TTwC0kuBR4BDgGv7449lOTt9P5YAOyoqkPL8H1oBR2+vHLMdUgazKJBD1BVu4Bd89qu7lu+CrjqKMfuBHYeR41aZZzqRmqLn4zV0JwCQWqLQa/heXml1BSDXkOzRy+1xaDX0Ax4qS0GvYbmPWOlthj0GtqRKRAktcCg19Aco5faYtBraN54RGqLQa+heeMRqS0GvYbnpGZSUwx6Dc0xeqktBr2GFiekl5pi0GtojtFLbTHoNTRvPCK1xaDX0LzxiNQWg15D88YjUlsMeg3NG49IbTHoNTKDXmqDQa+ROQWC1AaDXkOLl91ITTHoNbTD+V7jrELSoAx6DW2uQ18mvdQEg15Dm+vRlzkvNcGg19DmxugNeqkNBr2GdrhHP9YqJA3KoNfQDo/R26WXmjBQ0CfZmuSOJPuSXHmM/V6ZpJJs6dY3Jvleklu7x7uXqnCNUzd0M+YqJA3mxMV2SDIFXANcDBwAdieZrqq98/Y7DXgT8Nl5X+LOqjp3ierVKnCkRz/eOiQNZpAe/QXAvqraX1UPAdcDly2w39uB3wC+v4T1aRU68jkpk15qwSBBfxZwd9/6ga7tsCTnAxuq6n8tcPymJJ9P8qdJfmqhJ0hyeZKZJDOzs7OD1q4xsUcvteW434xNcgLw28AvL7D5HuDpVXUe8GbguiRPnL9TVV1bVVuqasu6deuOtyQtszhGLzVlkKA/CGzoW1/ftc05DfgJ4FNJvg68EJhOsqWqflBV9wNU1S3AncA5S1G4xscevdSWQYJ+N7A5yaYkJwPbgOm5jVX17ao6o6o2VtVG4Gbg0qqaSbKuezOXJM8ANgP7l/y70IpyCgSpLYtedVNVjyS5ArgRmAJ2VtWeJDuAmaqaPsbhLwZ2JHkYeAz4l1V1aCkK1/gcHrox56UmLBr0AFW1C9g1r+3qo+x7Ud/yh4APHUd9Wo0O9+gltcBPxmpoRyY1M+qlFhj0Glq8h6DUFINeQ3OaYqktBr2G5lU3UlsMeg3NHr3UFoNeQ/PGI1JbDHoNzRuPSG0x6DU8bzwiNcWg19BOPWkKgKkTvMxSasFAn4yV+r1l67M57dQTefnf+/FxlyJpAAa9hvakx53EVS99zrjLkDQgh24kacIZ9JI04Qx6SZpwBr0kTTiDXpImnEEvSRPOoJekCWfQS9KEy2qbryTJLHDXcXyJM4D7lqicpWRdw7Gu4azWumD11jZpdZ1dVesW2rDqgv54JZmpqi3jrmM+6xqOdQ1ntdYFq7e2H6W6HLqRpAln0EvShJvEoL923AUchXUNx7qGs1rrgtVb249MXRM3Ri9J+mGT2KOXJPUx6CVpwk1M0CfZmuSOJPuSXDnmWr6e5ItJbk0y07WtTXJTkq92/65ZoVp2Jrk3ye19bQvWkp7/1J3D25Kcv8J1vS3Jwe683ZrkZX3brurquiPJS5axrg1JPplkb5I9Sd7UtY/1nB2jrrGesySnJvlcki90df2Hrn1Tks92z//BJCd37ad06/u67RtXuK73J/la3/k6t2tfsZ/97vmmknw+yUe79eU9X1XV/AOYAu4EngGcDHwBeO4Y6/k6cMa8tt8EruyWrwR+Y4VqeTFwPnD7YrUALwM+Ru/23y8EPrvCdb0N+JUF9n1u9396CrCp+7+eWqa6zgTO75ZPA77SPf9Yz9kx6hrrOeu+7x/rlk8CPtudh/8ObOva3w38q275XwPv7pa3AR9cpvN1tLreD7xqgf1X7Ge/e743A9cBH+3Wl/V8TUqP/gJgX1Xtr6qHgOuBy8Zc03yXAR/olj8AvGIlnrSqPg0cGrCWy4Dfr56bgdOTnLmCdR3NZcD1VfWDqvoasI/e//ly1HVPVf1Ft/xd4EvAWYz5nB2jrqNZkXPWfd9/1a2e1D0K+Bnghq59/vmaO483AP8oyZLfZf4YdR3Niv3sJ1kP/GPgvd16WObzNSlBfxZwd9/6AY79S7DcCvh4kluSXN61PbWq7umWvwk8dTylHbOW1XAer+heOu/sG94aS13dy+Tz6PUGV805m1cXjPmcdcMQtwL3AjfRe/XwYFU9ssBzH66r2/5t4MkrUVdVzZ2vX+/O1zuTnDK/rgVqXmrvAv4d8Fi3/mSW+XxNStCvNi+qqvOBlwL/JsmL+zdW73XYqriudTXVAvwX4JnAucA9wG+Nq5AkPwZ8CPjFqvpO/7ZxnrMF6hr7OauqR6vqXGA9vVcNz17pGhYyv64kPwFcRa++vw+sBd6ykjUl+SfAvVV1y0o+76QE/UFgQ9/6+q5tLKrqYPfvvcD/oPfD/625l4Ldv/eOq75j1DLW81hV3+p+OR8Dfo8jQw0rWleSk+iF6R9W1Ye75rGfs4XqWi3nrKvlQeCTwD+gN/Rx4gLPfbiubvuTgPtXqK6t3RBYVdUPgPex8ufrQuDSJF+nN8T8M8DvsMzna1KCfjewuXvn+mR6b1pMj6OQJE9IctrcMnAJcHtXz/Zut+3A/xxHfZ2j1TINvK67AuGFwLf7hiuW3bwx0X9K77zN1bWtuwJhE7AZ+Nwy1RDgvwJfqqrf7ts01nN2tLrGfc6SrEtyerf8OOBieu8ffBJ4Vbfb/PM1dx5fBXyie4W0EnV9ue+PdeiNg/efr2X/f6yqq6pqfVVtpJdTn6iqn2W5z9dSvpM8zge9d82/Qm988NfGWMcz6F3t8AVgz1wt9MbV/i/wVeD/AGtXqJ4/oveS/mF6Y38/f7Ra6F1xcE13Dr8IbFnhuv6ge97buh/wM/v2/7WurjuAly5jXS+iNyxzG3Br93jZuM/ZMeoa6zkDng98vnv+24Gr+34PPkfvTeA/Bk7p2k/t1vd125+xwnV9ojtftwP/jSNX5qzYz35fjRdx5KqbZT1fToEgSRNuUoZuJElHYdBL0oQz6CVpwhn0kjThDHpJmnAGvSRNOINekibc/wcmRhGrMlS+dgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8b-r70o8p2Dm"
      },
      "source": [
        "## Try building/training a more complex MLP on a bigger dataset.\n",
        "\n",
        "Use TensorFlow Keras & the [MNIST dataset](http://yann.lecun.com/exdb/mnist/) to build the canonical handwriting digit recognizer and see what kind of accuracy you can achieve. \n",
        "\n",
        "If you need inspiration, the Internet is chalk-full of tutorials, but I want you to see how far you can get on your own first. I've linked to the original MNIST dataset above but it will probably be easier to download data through a neural network library. If you reference outside resources make sure you understand every line of code that you're using from other sources, and share with your fellow students helpful resources that you find.\n",
        "\n",
        "\n",
        "### Parts\n",
        "1. Gathering & Transforming the Data\n",
        "2. Making MNIST a Binary Problem\n",
        "3. Estimating your Neural Network (the part you focus on)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYNGrVVy-ecc",
        "colab_type": "text"
      },
      "source": [
        "### Gathering the Data \n",
        "\n",
        "`keras` has a handy method to pull the mnist dataset for you. You'll notice that each observation is a 28x28 arrary which represents an image. Although most Neural Network frameworks can handle higher dimensional data, that is more overhead than necessary for us. We need to flatten the image to one long row which will be 784 values (28X28). Basically, you will be appending each row to one another to make on really long row. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9ErFfb2-ecd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGf2cATJ-ece",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atd_CE-Q-ecg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tJWpCLA-ecj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = x_train.reshape(x_train.shape[0], img_rows * img_cols)\n",
        "x_test = x_test.reshape(x_test.shape[0], img_rows * img_cols)\n",
        "\n",
        "# Normalize Our Data\n",
        "x_train = x_train / 255\n",
        "x_test = x_test / 255"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eEuXg6T-eck",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "613fb569-43c4-44a7-addc-8f34fbfe48ae"
      },
      "source": [
        "# Now the data should be in a format you're more familiar with\n",
        "x_train.shape"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ln-yY3t-ecm",
        "colab_type": "text"
      },
      "source": [
        "### Making MNIST a Binary Problem \n",
        "MNIST is multiclass classification problem; however we haven't covered all the necessary techniques to handle this yet. You would need to one-hot encode the target, use a different loss metric, and use softmax activations for the last layer. This is all stuff we'll cover later this week, but let us simplify the problem for now: Zero or all else."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1yyXC13-ecm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "y_temp = np.zeros(y_train.shape)\n",
        "y_temp[np.where(y_train == 0.0)[0]] = 1\n",
        "y_train = y_temp\n",
        "\n",
        "y_temp = np.zeros(y_test.shape)\n",
        "y_temp[np.where(y_test == 0.0)[0]] = 1\n",
        "y_test = y_temp"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIWKgLZZ-eco",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "30996573-5b66-40ba-9d10-641da11a9812"
      },
      "source": [
        "# A Nice Binary target for ya to work with\n",
        "y_train"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 0., ..., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdeEg3y_-ecq",
        "colab_type": "text"
      },
      "source": [
        "### Estimating Your `net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5MOPtYdk1HgA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "bbacd567-0a02-4f6f-92f6-ed924f9c2ab7"
      },
      "source": [
        "model = Sequential([\n",
        "    Dense(4, activation='relu', input_dim=784),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "results = model.fit(x_train,y_train, epochs=10)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0617 - accuracy: 0.9810\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0285 - accuracy: 0.9916\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0261 - accuracy: 0.9922\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0251 - accuracy: 0.9924\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0243 - accuracy: 0.9930\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0239 - accuracy: 0.9931\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0236 - accuracy: 0.9930\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0234 - accuracy: 0.9930\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0232 - accuracy: 0.9931\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0228 - accuracy: 0.9932\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FwlRJSfBlCvy"
      },
      "source": [
        "## Stretch Goals: \n",
        "\n",
        "- Make MNIST a multiclass problem using cross entropy & soft-max\n",
        "- Implement Cross Validation model evaluation on your MNIST implementation \n",
        "- Research different [Gradient Descent Based Optimizers](https://keras.io/optimizers/)\n",
        " - [Siraj Raval the evolution of gradient descent](https://www.youtube.com/watch?v=nhqo0u1a6fw)\n",
        "- Build a housing price estimation model using a neural network. How does its accuracy compare with the regression models that we fit earlier on in class?"
      ]
    }
  ]
}