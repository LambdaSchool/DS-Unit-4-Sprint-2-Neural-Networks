{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NGGrt9EYlCqY"
   },
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "\n",
    "# Backpropagation Practice\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2 Assignment 2*\n",
    "\n",
    "Implement a 3 input, 4 node hidden-layer, 1 output node Multilayer Perceptron on the following dataset:\n",
    "\n",
    "| x1 | x2 | x3 | y |\n",
    "|----|----|----|---|\n",
    "| 0  | 0  | 1  | 0 |\n",
    "| 0  | 1  | 1  | 1 |\n",
    "| 1  | 0  | 1  | 1 |\n",
    "| 0  | 1  | 0  | 1 |\n",
    "| 1  | 0  | 0  | 1 |\n",
    "| 1  | 1  | 1  | 0 |\n",
    "| 0  | 0  | 0  | 0 |\n",
    "\n",
    "If you look at the data you'll notice that the first two columns behave like an XOR gate while the last column is mostly just noise. Remember that creating an XOR gate was what the perceptron was criticized for not being able to learn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nEREYT-3wI1f"
   },
   "outputs": [],
   "source": [
    "##### Your Code Here #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8b-r70o8p2Dm"
   },
   "source": [
    "## Try building/training a more complex MLP on a bigger dataset.\n",
    "\n",
    "Use the [MNIST dataset](http://yann.lecun.com/exdb/mnist/) to build the cannonical handwriting digit recognizer and see what kind of accuracy you can achieve. \n",
    "\n",
    "If you need inspiration, the internet is chalk-full of tutorials, but I want you to see how far you can get on your own first. I've linked to the original MNIST dataset above but it will probably be easier to download data through a neural network library. If you reference outside resources make sure you understand every line of code that you're using from other sources, and share with your fellow students helpful resources that you find.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Your Code Here #####\n",
    "import tensorflow\n",
    "import keras\n",
    "\n",
    "from keras.datasets import mnist\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:10000].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = X_train[:10000]\n",
    "y_train = y_train[:10000]\n",
    "X_test = X_test[:2000]\n",
    "y_test = y_test[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_mldata\n",
    "\n",
    "X, y = fetch_mldata('mnist_784')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5MOPtYdk1HgA"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# normalizing to keep gradients manageable\n",
    "\n",
    "X = X / 255\n",
    "\n",
    "# cutting down model size from 70k to 20k\n",
    "\n",
    "X = X[:20000]\n",
    "y = y[:20000]\n",
    "\n",
    "# one hot encoding labels\n",
    "\n",
    "digits = 10\n",
    "examples = y.shape[0]\n",
    "\n",
    "y = y.reshape(1, examples)\n",
    "\n",
    "Y_new = np.eye(digits)[y.astype('int32')]\n",
    "y_new = Y_new.T.reshape(digits, examples)\n",
    "\n",
    "m = 16000\n",
    "m_test = X.shape[0] - m\n",
    "\n",
    "X_train, X_test = X[:m].T, X[m:].T\n",
    "y_train, y_test = y_new[:,:m], y_new[:,m:]\n",
    "\n",
    "shuffle_index = np.random.permutation(m)\n",
    "X_train, y_train = X_train[:, shuffle_index], y_train[:, shuffle_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check to make sure images are correct\n",
    "# looks wrong, but continuing\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "i = 12\n",
    "plt.imshow(X_train.reshape(10000,784), cmap=matplotlib.cm.binary)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def sigmoid(z):\n",
    "    s = 1 / (1 + np.exp(-z))\n",
    "    return s\n",
    "\n",
    "def compute_loss(y, y_hat):\n",
    "    m = y.shape[1]\n",
    "    L = -(1./m) * (np.sum(np.multiply(np.log(y_hat), y)) + np.sum(np.multiply(np.log(1-y_hat), (1-y))))\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 28 is different from 10000)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-5174e3e75fa2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mZ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[0mA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 28 is different from 10000)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "learning_rate = 1\n",
    "\n",
    "X = X_train\n",
    "y = y_train\n",
    "\n",
    "n_x = X.shape[0]\n",
    "m = X.shape[1]\n",
    "\n",
    "W = np.random.randn(n_x, 1) * 0.01\n",
    "b = np.zeros((1,1))\n",
    "\n",
    "for i in range(2000):\n",
    "    Z = np.matmul(W.T, X) + b\n",
    "    A = sigmoid(Z)\n",
    "    \n",
    "    cost = compute_loss(y, A)\n",
    "    \n",
    "    dW = (1 / m) * np.matmul(X, (A-y).T)\n",
    "    db = (1 / m) * np.sum(A - y, axis=1, keepdims=True)\n",
    "    \n",
    "    W = W - learning_rate * dW\n",
    "    b = b - learning_rate * db\n",
    "    \n",
    "    if (i % 100 == 0):\n",
    "        print('epoch', i, 'cost', cost)\n",
    "        \n",
    "print('final cost', cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "Z = np.matmul(W.T, X_test) + b\n",
    "A = sigmoid(Z)\n",
    "\n",
    "predictions = (A>0.5)[0,:]\n",
    "labels = (y_test ==1)[0,:]\n",
    "\n",
    "print(confusion_matrix(predictions, labels))\n",
    "\n",
    "print(classification_report(predictions, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_train\n",
    "Y = y_train\n",
    "\n",
    "n_x = X.shape[0]\n",
    "n_h = 64\n",
    "learning_rate = 1\n",
    "\n",
    "W1 = np.random.randn(n_h, n_x)\n",
    "b1 = np.zeros((n_h, 1))\n",
    "W2 = np.random.randn(1, n_h)\n",
    "b2 = np.zeros((1, 1))\n",
    "\n",
    "for i in range(2000):\n",
    "\n",
    "    Z1 = np.matmul(W1, X) + b1\n",
    "    A1 = sigmoid(Z1)\n",
    "    Z2 = np.matmul(W2, A1) + b2\n",
    "    A2 = sigmoid(Z2)\n",
    "\n",
    "    cost = compute_loss(Y, A2)\n",
    "\n",
    "    dZ2 = A2-Y\n",
    "    dW2 = (1./m) * np.matmul(dZ2, A1.T)\n",
    "    db2 = (1./m) * np.sum(dZ2, axis=1, keepdims=True)\n",
    "\n",
    "    dA1 = np.matmul(W2.T, dZ2)\n",
    "    dZ1 = dA1 * sigmoid(Z1) * (1 - sigmoid(Z1))\n",
    "    dW1 = (1./m) * np.matmul(dZ1, X.T)\n",
    "    db1 = (1./m) * np.sum(dZ1, axis=1, keepdims=True)\n",
    "\n",
    "    W2 = W2 - learning_rate * dW2\n",
    "    b2 = b2 - learning_rate * db2\n",
    "    W1 = W1 - learning_rate * dW1\n",
    "    b1 = b1 - learning_rate * db1\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        print(\"Epoch\", i, \"cost: \", cost)\n",
    "\n",
    "print(\"Final cost:\", cost)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_multiclass_loss(Y, Y_hat):\n",
    "    L_sum = np.sum(np.multiply(Y, np.log(Y_hat)))\n",
    "    m = Y.shape[1]\n",
    "    L = -(1/m) * L_sum\n",
    "    \n",
    "    return L\n",
    "\n",
    "n_x = X_train.shape[0]\n",
    "n_h = 64\n",
    "learning_rate = 1\n",
    "\n",
    "W1 = np.random.randn(n_h, n_x)\n",
    "b1 = np.zeros((n_h, 1))\n",
    "W2 = np.random.randn(digits, n_h)\n",
    "b2 = np.zeros((digits, 1))\n",
    "\n",
    "X = X_train\n",
    "Y = y_train\n",
    "\n",
    "for i in range(2000):\n",
    "    Z1 = np.matmul(W1, X) + b1\n",
    "    A1 = sigmoid(Z1)\n",
    "    Z2 = np.matmul(W2, A1) + b2\n",
    "    A2 = np.exp(Z2) / np.sum(np.exp(Z2), axis=0)\n",
    "    \n",
    "    cost = compute_multiclass_loss(Y, A2)\n",
    "    \n",
    "    dZ2 = A2 - Y\n",
    "    dW2 = (1./m) * np.matmul(dZ2, A1.T)\n",
    "    db2 = (1./m) * np.sum(dZ2, axis=1, keepdims=True)\n",
    "    \n",
    "    dA1 = np.matmul(W2.T, dZ2)\n",
    "    dZ1 = dA1 * sigmoid(Z1) * (1 - sigmoid(Z1))\n",
    "    dW1 = (1./m) * np.matmul(dZ1, X.T)\n",
    "    db1 = (1./m) * np.sum(dZ1, axis=1, keepdims=True)\n",
    "    \n",
    "    W2 = W2 - learning_rate * dW2\n",
    "    b2 = b2 - learning_rate * db2\n",
    "    W1 = W1 - learning_rate * dW1\n",
    "    b1 = b1 - learning_rate * db1\n",
    "    \n",
    "    if (i % 100 == 0):\n",
    "        print('epoch', i, 'cost:', cost)\n",
    "        \n",
    "print('final cost:', cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mhdal\\Anaconda3\\envs\\lambda-neural\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.8002271784243894 using {'batch_size': 60, 'epochs': 20}\n",
      "Means: 0.7961096100029952, Stdev: 0.0013647352184608407 with: {'batch_size': 10, 'epochs': 20}\n",
      "Means: 0.7905722032736838, Stdev: 0.006227957571291364 with: {'batch_size': 20, 'epochs': 20}\n",
      "Means: 0.7978134327410095, Stdev: 0.0004931025843609994 with: {'batch_size': 40, 'epochs': 20}\n",
      "Means: 0.8002271784243894, Stdev: 0.001532294901941202 with: {'batch_size': 60, 'epochs': 20}\n",
      "Means: 0.7990912961364046, Stdev: 0.0012252929240128077 with: {'batch_size': 80, 'epochs': 20}\n",
      "Means: 0.7971035080607364, Stdev: 0.0031924955226660494 with: {'batch_size': 100, 'epochs': 20}\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model():\n",
    "  # create model\n",
    "        model = Sequential()\n",
    "        model.add(Dense(38, input_dim=19, activation='relu'))\n",
    "        model.add(Dense(19, activation='relu'))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "  # Compile model\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "\n",
    "# define the grid search parameters\n",
    "# batch_size = [10, 20, 40, 60, 80, 100]\n",
    "# param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "\n",
    "# define the grid search parameters\n",
    "param_grid = {'batch_size': [10, 20, 40, 60, 80, 100],\n",
    "              'epochs': [20]}\n",
    "\n",
    "# Create Grid Search\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1)\n",
    "grid_result = grid.fit(X, y)\n",
    "\n",
    "# Report Results\n",
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mhdal\\Anaconda3\\envs\\lambda-neural\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.8002271784243894 using {'batch_size': 60, 'epochs': 20}\n",
      "Means: 0.7961096100029952, Stdev: 0.0013647352184608407 with: {'batch_size': 10, 'epochs': 20}\n",
      "Means: 0.7905722032736838, Stdev: 0.006227957571291364 with: {'batch_size': 20, 'epochs': 20}\n",
      "Means: 0.7978134327410095, Stdev: 0.0004931025843609994 with: {'batch_size': 40, 'epochs': 20}\n",
      "Means: 0.8002271784243894, Stdev: 0.001532294901941202 with: {'batch_size': 60, 'epochs': 20}\n",
      "Means: 0.7990912961364046, Stdev: 0.0012252929240128077 with: {'batch_size': 80, 'epochs': 20}\n",
      "Means: 0.7971035080607364, Stdev: 0.0031924955226660494 with: {'batch_size': 100, 'epochs': 20}\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model():\n",
    "  # create model\n",
    "        model = Sequential()\n",
    "        model.add(Dense(38, input_dim=19, activation='relu'))\n",
    "        model.add(Dense(19, activation='relu'))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "  # Compile model\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "\n",
    "# define the grid search parameters\n",
    "# batch_size = [10, 20, 40, 60, 80, 100]\n",
    "# param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "\n",
    "# define the grid search parameters\n",
    "param_grid = {'batch_size': [10, 20, 40, 60, 80, 100],\n",
    "              'epochs': [20]}\n",
    "\n",
    "# Create Grid Search\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1)\n",
    "grid_result = grid.fit(X, y)\n",
    "\n",
    "# Report Results\n",
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FwlRJSfBlCvy"
   },
   "source": [
    "## Stretch Goals: \n",
    "\n",
    "- Implement Cross Validation model evaluation on your MNIST implementation \n",
    "- Research different [Gradient Descent Based Optimizers](https://keras.io/optimizers/)\n",
    " - [Siraj Raval the evolution of gradient descent](https://www.youtube.com/watch?v=nhqo0u1a6fw)\n",
    "- Build a housing price estimation model using a neural network. How does its accuracy compare with the regression models that we fit earlier on in class?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "LS_DS_432_Backprop_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python [conda env:lambda-neural]",
   "language": "python",
   "name": "conda-env-lambda-neural-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
