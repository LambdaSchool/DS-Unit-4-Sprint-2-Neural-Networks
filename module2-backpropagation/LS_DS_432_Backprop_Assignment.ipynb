{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LS_DS_432_Backprop_Assignment.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DimaKav/DS-Unit-4-Sprint-3-Neural-Networks/blob/master/module2-backpropagation/LS_DS_432_Backprop_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGGrt9EYlCqY",
        "colab_type": "text"
      },
      "source": [
        "# Backpropagation Practice\n",
        "\n",
        "Implement a 3 input, 4 node hidden-layer, 1 output node Multilayer Perceptron on the following dataset:\n",
        "\n",
        "| x1 | x2 | x3 | y |\n",
        "|----|----|----|---|\n",
        "| 0  | 0  | 1  | 0 |\n",
        "| 0  | 1  | 1  | 1 |\n",
        "| 1  | 0  | 1  | 1 |\n",
        "| 0  | 1  | 0  | 1 |\n",
        "| 1  | 0  | 0  | 1 |\n",
        "| 1  | 1  | 1  | 0 |\n",
        "| 0  | 0  | 0  | 0 |\n",
        "\n",
        "If you look at the data you'll notice that the first two columns behave like an XOR gate while the last column is mostly just noise. Remember that creating an XOR gate was what the perceptron was criticized for not being able to learn. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vm1TeNCbFUrx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "56bd98a4-b3a6-4409-b325-e51f1c3ca283"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "X = np.array(([0,0,1],\n",
        "              [0,1,1],\n",
        "              [1,0,1],\n",
        "              [0,1,0],\n",
        "              [1,0,0],\n",
        "              [1,1,1],\n",
        "              [0,0,0]))\n",
        "\n",
        "y = np.array(([0],[1],[1],[1],[1],[0],[0]))\n",
        "\n",
        "y"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yikgTQTCOz-L",
        "colab_type": "text"
      },
      "source": [
        "# Backprop without Gradient Descent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtoawjfFORKB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Neural_Network(object):\n",
        "  def __init__(self):\n",
        "    self.inputs = 3\n",
        "    self.hiddenNodes = 4\n",
        "    self.outputNodes = 1\n",
        "\n",
        "    # Initlize Weights\n",
        "    self.L1_weights = np.random.randn(self.inputs, self.hiddenNodes) # (3x2)\n",
        "    self.L2_weights = np.random.randn(self.hiddenNodes, self.outputNodes) # (3x1)\n",
        "\n",
        "  def feed_forward(self, X):\n",
        "    # Weighted sum between inputs and hidden layer\n",
        "    self.hidden_sum = np.dot(X, self.L1_weights)\n",
        "    # Activations of weighted sum\n",
        "    self.activated_hidden = self.sigmoid(self.hidden_sum)\n",
        "    # Weighted sum between hidden and output\n",
        "    self.output_sum = np.dot(self.activated_hidden, self.L2_weights)\n",
        "    # final activation of output\n",
        "    self.activated_output = self.sigmoid(self.output_sum)\n",
        "    return self.activated_output\n",
        "    \n",
        "  def sigmoid(self, s):\n",
        "    return 1/(1+np.exp(-s))\n",
        "  \n",
        "  def sigmoidPrime(self, s):\n",
        "    return s * (1 - s)\n",
        "  \n",
        "  def backward(self, X, y, o):\n",
        "    # backward propgate through the network\n",
        "    self.o_error = y - o # error in output\n",
        "    self.o_delta = self.o_error*self.sigmoidPrime(o) # applying derivative of sigmoid to error\n",
        "\n",
        "    self.z2_error = self.o_delta.dot(self.L2_weights.T) # z2 error: how much our hidden layer weights contributed to output error\n",
        "    self.z2_delta = self.z2_error*self.sigmoidPrime(self.activated_hidden) # applying derivative of sigmoid to z2 error\n",
        "\n",
        "    self.L1_weights += X.T.dot(self.z2_delta) # adjusting first set (input --> hidden) weights\n",
        "    self.L2_weights += self.activated_hidden.T.dot(self.o_delta) # adjusting second set (hidden --> output) weights\n",
        "    \n",
        "  def train (self, X, y):\n",
        "    o = self.feed_forward(X)\n",
        "    self.backward(X, y, o)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnifNr-gOSJS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 12342
        },
        "outputId": "a1f6c61d-4d7c-4867-f99f-ea82eb9352dc"
      },
      "source": [
        "NN = Neural_Network()\n",
        "for i in range(1000): # trains the NN 1,000 times\n",
        "  if i+1 in [1,2,3,4,5] or (i+1) % 50 == 0:\n",
        "    print('+---------- EPOCH', i+1, '-----------+')\n",
        "    print(\"Input: \\n\", X) \n",
        "    print(\"Actual Output: \\n\", y)  \n",
        "    print(\"Predicted Output: \\n\" + str(NN.feed_forward(X))) \n",
        "    print(\"Loss: \\n\" + str(np.mean(np.square(y - NN.feed_forward(X))))) # mean sum squared loss\n",
        "    print(\"\\n\")\n",
        "  NN.train(X, y)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------- EPOCH 1 -----------+\n",
            "Input: \n",
            " [[0 0 1]\n",
            " [0 1 1]\n",
            " [1 0 1]\n",
            " [0 1 0]\n",
            " [1 0 0]\n",
            " [1 1 1]\n",
            " [0 0 0]]\n",
            "Actual Output: \n",
            " [[0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]]\n",
            "Predicted Output: \n",
            "[[0.51634103]\n",
            " [0.56698157]\n",
            " [0.56923644]\n",
            " [0.75437159]\n",
            " [0.75121144]\n",
            " [0.62870169]\n",
            " [0.6888492 ]]\n",
            "Loss: \n",
            "0.23309690827681934\n",
            "\n",
            "\n",
            "+---------- EPOCH 2 -----------+\n",
            "Input: \n",
            " [[0 0 1]\n",
            " [0 1 1]\n",
            " [1 0 1]\n",
            " [0 1 0]\n",
            " [1 0 0]\n",
            " [1 1 1]\n",
            " [0 0 0]]\n",
            "Actual Output: \n",
            " [[0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]]\n",
            "Predicted Output: \n",
            "[[0.50104865]\n",
            " [0.54704001]\n",
            " [0.55533425]\n",
            " [0.73568099]\n",
            " [0.73609144]\n",
            " [0.61090481]\n",
            " [0.67097009]]\n",
            "Loss: \n",
            "0.23098113486669905\n",
            "\n",
            "\n",
            "+---------- EPOCH 3 -----------+\n",
            "Input: \n",
            " [[0 0 1]\n",
            " [0 1 1]\n",
            " [1 0 1]\n",
            " [0 1 0]\n",
            " [1 0 0]\n",
            " [1 1 1]\n",
            " [0 0 0]]\n",
            "Actual Output: \n",
            " [[0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]]\n",
            "Predicted Output: \n",
            "[[0.48900958]\n",
            " [0.53224884]\n",
            " [0.54472288]\n",
            " [0.72203081]\n",
            " [0.72499492]\n",
            " [0.59799877]\n",
            " [0.65758255]]\n",
            "Loss: \n",
            "0.2297301127964901\n",
            "\n",
            "\n",
            "+---------- EPOCH 4 -----------+\n",
            "Input: \n",
            " [[0 0 1]\n",
            " [0 1 1]\n",
            " [1 0 1]\n",
            " [0 1 0]\n",
            " [1 0 0]\n",
            " [1 1 1]\n",
            " [0 0 0]]\n",
            "Actual Output: \n",
            " [[0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]]\n",
            "Predicted Output: \n",
            "[[0.47949347]\n",
            " [0.52146119]\n",
            " [0.53666489]\n",
            " [0.71259486]\n",
            " [0.71720739]\n",
            " [0.58890728]\n",
            " [0.64784897]]\n",
            "Loss: \n",
            "0.22895517773120283\n",
            "\n",
            "\n",
            "+---------- EPOCH 5 -----------+\n",
            "Input: \n",
            " [[0 0 1]\n",
            " [0 1 1]\n",
            " [1 0 1]\n",
            " [0 1 0]\n",
            " [1 0 0]\n",
            " [1 1 1]\n",
            " [0 0 0]]\n",
            "Actual Output: \n",
            " [[0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]]\n",
            "Predicted Output: \n",
            "[[0.47185397]\n",
            " [0.51364372]\n",
            " [0.53050867]\n",
            " [0.70641307]\n",
            " [0.71195369]\n",
            " [0.58265465]\n",
            " [0.64089397]]\n",
            "Loss: \n",
            "0.22842945735884007\n",
            "\n",
            "\n",
            "+---------- EPOCH 50 -----------+\n",
            "Input: \n",
            " [[0 0 1]\n",
            " [0 1 1]\n",
            " [1 0 1]\n",
            " [0 1 0]\n",
            " [1 0 0]\n",
            " [1 1 1]\n",
            " [0 0 0]]\n",
            "Actual Output: \n",
            " [[0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]]\n",
            "Predicted Output: \n",
            "[[0.34885046]\n",
            " [0.51756562]\n",
            " [0.51244215]\n",
            " [0.73343965]\n",
            " [0.71493935]\n",
            " [0.62754513]\n",
            " [0.55773304]]\n",
            "Loss: \n",
            "0.207049322599218\n",
            "\n",
            "\n",
            "+---------- EPOCH 100 -----------+\n",
            "Input: \n",
            " [[0 0 1]\n",
            " [0 1 1]\n",
            " [1 0 1]\n",
            " [0 1 0]\n",
            " [1 0 0]\n",
            " [1 1 1]\n",
            " [0 0 0]]\n",
            "Actual Output: \n",
            " [[0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]]\n",
            "Predicted Output: \n",
            "[[0.1989181 ]\n",
            " [0.59551317]\n",
            " [0.59567826]\n",
            " [0.79912874]\n",
            " [0.78372396]\n",
            " [0.64465426]\n",
            " [0.34661365]]\n",
            "Loss: \n",
            "0.1413569708546602\n",
            "\n",
            "\n",
            "+---------- EPOCH 150 -----------+\n",
            "Input: \n",
            " [[0 0 1]\n",
            " [0 1 1]\n",
            " [1 0 1]\n",
            " [0 1 0]\n",
            " [1 0 0]\n",
            " [1 1 1]\n",
            " [0 0 0]]\n",
            "Actual Output: \n",
            " [[0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]]\n",
            "Predicted Output: \n",
            "[[0.11918021]\n",
            " [0.64694834]\n",
            " [0.67722268]\n",
            " [0.84786578]\n",
            " [0.84761662]\n",
            " [0.62245563]\n",
            " [0.26683089]]\n",
            "Loss: \n",
            "0.10686426417732689\n",
            "\n",
            "\n",
            "+---------- EPOCH 200 -----------+\n",
            "Input: \n",
            " [[0 0 1]\n",
            " [0 1 1]\n",
            " [1 0 1]\n",
            " [0 1 0]\n",
            " [1 0 0]\n",
            " [1 1 1]\n",
            " [0 0 0]]\n",
            "Actual Output: \n",
            " [[0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]]\n",
            "Predicted Output: \n",
            "[[0.0819039 ]\n",
            " [0.70717285]\n",
            " [0.7544865 ]\n",
            " [0.88037249]\n",
            " [0.88125881]\n",
            " [0.59445945]\n",
            " [0.22812177]]\n",
            "Loss: \n",
            "0.08379495177505457\n",
            "\n",
            "\n",
            "+---------- EPOCH 250 -----------+\n",
            "Input: \n",
            " [[0 0 1]\n",
            " [0 1 1]\n",
            " [1 0 1]\n",
            " [0 1 0]\n",
            " [1 0 0]\n",
            " [1 1 1]\n",
            " [0 0 0]]\n",
            "Actual Output: \n",
            " [[0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]]\n",
            "Predicted Output: \n",
            "[[0.06042599]\n",
            " [0.7642794 ]\n",
            " [0.80758743]\n",
            " [0.90218242]\n",
            " [0.9005387 ]\n",
            " [0.57047733]\n",
            " [0.19742471]]\n",
            "Loss: \n",
            "0.06858854572469\n",
            "\n",
            "\n",
            "+---------- EPOCH 300 -----------+\n",
            "Input: \n",
            " [[0 0 1]\n",
            " [0 1 1]\n",
            " [1 0 1]\n",
            " [0 1 0]\n",
            " [1 0 0]\n",
            " [1 1 1]\n",
            " [0 0 0]]\n",
            "Actual Output: \n",
            " [[0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]]\n",
            "Predicted Output: \n",
            "[[0.0471805 ]\n",
            " [0.80737846]\n",
            " [0.84185619]\n",
            " [0.91539085]\n",
            " [0.91398897]\n",
            " [0.55247985]\n",
            " [0.17216725]]\n",
            "Loss: \n",
            "0.05911009548277498\n",
            "\n",
            "\n",
            "+---------- EPOCH 350 -----------+\n",
            "Input: \n",
            " [[0 0 1]\n",
            " [0 1 1]\n",
            " [1 0 1]\n",
            " [0 1 0]\n",
            " [1 0 0]\n",
            " [1 1 1]\n",
            " [0 0 0]]\n",
            "Actual Output: \n",
            " [[0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]]\n",
            "Predicted Output: \n",
            "[[0.03856214]\n",
            " [0.83842617]\n",
            " [0.86495602]\n",
            " [0.92347675]\n",
            " [0.92410436]\n",
            " [0.5398019 ]\n",
            " [0.15207722]]\n",
            "Loss: \n",
            "0.05313707830613639\n",
            "\n",
            "\n",
            "+---------- EPOCH 400 -----------+\n",
            "Input: \n",
            " [[0 0 1]\n",
            " [0 1 1]\n",
            " [1 0 1]\n",
            " [0 1 0]\n",
            " [1 0 0]\n",
            " [1 1 1]\n",
            " [0 0 0]]\n",
            "Actual Output: \n",
            " [[0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]]\n",
            "Predicted Output: \n",
            "[[0.03261809]\n",
            " [0.86125368]\n",
            " [0.88143029]\n",
            " [0.92866542]\n",
            " [0.9319088 ]\n",
            " [0.53086644]\n",
            " [0.13619876]]\n",
            "Loss: \n",
            "0.04920965324499598\n",
            "\n",
            "\n",
            "+---------- EPOCH 450 -----------+\n",
            "Input: \n",
            " [[0 0 1]\n",
            " [0 1 1]\n",
            " [1 0 1]\n",
            " [0 1 0]\n",
            " [1 0 0]\n",
            " [1 1 1]\n",
            " [0 0 0]]\n",
            "Actual Output: \n",
            " [[0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]]\n",
            "Predicted Output: \n",
            "[[0.02829874]\n",
            " [0.87854736]\n",
            " [0.89376756]\n",
            " [0.93213074]\n",
            " [0.93804418]\n",
            " [0.52434084]\n",
            " [0.1235068 ]]\n",
            "Loss: \n",
            "0.04649555726911968\n",
            "\n",
            "\n",
            "+---------- EPOCH 500 -----------+\n",
            "Input: \n",
            " [[0 0 1]\n",
            " [0 1 1]\n",
            " [1 0 1]\n",
            " [0 1 0]\n",
            " [1 0 0]\n",
            " [1 1 1]\n",
            " [0 0 0]]\n",
            "Actual Output: \n",
            " [[0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]]\n",
            "Predicted Output: \n",
            "[[0.02502468]\n",
            " [0.89197349]\n",
            " [0.90338138]\n",
            " [0.93445054]\n",
            " [0.94294292]\n",
            " [0.51927921]\n",
            " [0.11315617]]\n",
            "Loss: \n",
            "0.04451979751473046\n",
            "\n",
            "\n",
            "+---------- EPOCH 550 -----------+\n",
            "Input: \n",
            " [[0 0 1]\n",
            " [0 1 1]\n",
            " [1 0 1]\n",
            " [0 1 0]\n",
            " [1 0 0]\n",
            " [1 1 1]\n",
            " [0 0 0]]\n",
            "Actual Output: \n",
            " [[0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]]\n",
            "Predicted Output: \n",
            "[[0.02246039]\n",
            " [0.90252595]\n",
            " [0.91112604]\n",
            " [0.9358366 ]\n",
            " [0.94688659]\n",
            " [0.51493546]\n",
            " [0.10447839]]\n",
            "Loss: \n",
            "0.04298806846692037\n",
            "\n",
            "\n",
            "+---------- EPOCH 600 -----------+\n",
            "Input: \n",
            " [[0 0 1]\n",
            " [0 1 1]\n",
            " [1 0 1]\n",
            " [0 1 0]\n",
            " [1 0 0]\n",
            " [1 1 1]\n",
            " [0 0 0]]\n",
            "Actual Output: \n",
            " [[0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]]\n",
            "Predicted Output: \n",
            "[[0.02040139]\n",
            " [0.91064053]\n",
            " [0.91755664]\n",
            " [0.93614304]\n",
            " [0.95001983]\n",
            " [0.51037344]\n",
            " [0.09687945]]\n",
            "Loss: \n",
            "0.04166294984440623\n",
            "\n",
            "\n",
            "+---------- EPOCH 650 -----------+\n",
            "Input: \n",
            " [[0 0 1]\n",
            " [0 1 1]\n",
            " [1 0 1]\n",
            " [0 1 0]\n",
            " [1 0 0]\n",
            " [1 1 1]\n",
            " [0 0 0]]\n",
            "Actual Output: \n",
            " [[0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]]\n",
            "Predicted Output: \n",
            "[[0.01871058]\n",
            " [0.91557659]\n",
            " [0.92306817]\n",
            " [0.93433249]\n",
            " [0.95222004]\n",
            " [0.50269711]\n",
            " [0.08953068]]\n",
            "Loss: \n",
            "0.04010159673456567\n",
            "\n",
            "\n",
            "+---------- EPOCH 700 -----------+\n",
            "Input: \n",
            " [[0 0 1]\n",
            " [0 1 1]\n",
            " [1 0 1]\n",
            " [0 1 0]\n",
            " [1 0 0]\n",
            " [1 1 1]\n",
            " [0 0 0]]\n",
            "Actual Output: \n",
            " [[0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]]\n",
            "Predicted Output: \n",
            "[[0.0170781 ]\n",
            " [0.90479534]\n",
            " [0.92756645]\n",
            " [0.922276  ]\n",
            " [0.95090251]\n",
            " [0.4529919 ]\n",
            " [0.07898386]]\n",
            "Loss: \n",
            "0.033499128945301944\n",
            "\n",
            "\n",
            "+---------- EPOCH 750 -----------+\n",
            "Input: \n",
            " [[0 0 1]\n",
            " [0 1 1]\n",
            " [1 0 1]\n",
            " [0 1 0]\n",
            " [1 0 0]\n",
            " [1 1 1]\n",
            " [0 0 0]]\n",
            "Actual Output: \n",
            " [[0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]]\n",
            "Predicted Output: \n",
            "[[0.01704688]\n",
            " [0.88833045]\n",
            " [0.92750954]\n",
            " [0.91317157]\n",
            " [0.93637383]\n",
            " [0.19141261]\n",
            " [0.07693307]]\n",
            "Loss: \n",
            "0.010308642790033877\n",
            "\n",
            "\n",
            "+---------- EPOCH 800 -----------+\n",
            "Input: \n",
            " [[0 0 1]\n",
            " [0 1 1]\n",
            " [1 0 1]\n",
            " [0 1 0]\n",
            " [1 0 0]\n",
            " [1 1 1]\n",
            " [0 0 0]]\n",
            "Actual Output: \n",
            " [[0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]]\n",
            "Predicted Output: \n",
            "[[0.01839961]\n",
            " [0.91134513]\n",
            " [0.93547171]\n",
            " [0.92804479]\n",
            " [0.93764601]\n",
            " [0.14004527]\n",
            " [0.08559432]]\n",
            "Loss: \n",
            "0.006909538429729226\n",
            "\n",
            "\n",
            "+---------- EPOCH 850 -----------+\n",
            "Input: \n",
            " [[0 0 1]\n",
            " [0 1 1]\n",
            " [1 0 1]\n",
            " [0 1 0]\n",
            " [1 0 0]\n",
            " [1 1 1]\n",
            " [0 0 0]]\n",
            "Actual Output: \n",
            " [[0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]]\n",
            "Predicted Output: \n",
            "[[0.01804599]\n",
            " [0.92204428]\n",
            " [0.94209341]\n",
            " [0.93519238]\n",
            " [0.94073962]\n",
            " [0.11721649]\n",
            " [0.08800143]]\n",
            "Loss: \n",
            "0.005564528764707147\n",
            "\n",
            "\n",
            "+---------- EPOCH 900 -----------+\n",
            "Input: \n",
            " [[0 0 1]\n",
            " [0 1 1]\n",
            " [1 0 1]\n",
            " [0 1 0]\n",
            " [1 0 0]\n",
            " [1 1 1]\n",
            " [0 0 0]]\n",
            "Actual Output: \n",
            " [[0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]]\n",
            "Predicted Output: \n",
            "[[0.01702757]\n",
            " [0.92858412]\n",
            " [0.94701133]\n",
            " [0.93971842]\n",
            " [0.94366093]\n",
            " [0.10331065]\n",
            " [0.08738341]]\n",
            "Loss: \n",
            "0.004759267931378002\n",
            "\n",
            "\n",
            "+---------- EPOCH 950 -----------+\n",
            "Input: \n",
            " [[0 0 1]\n",
            " [0 1 1]\n",
            " [1 0 1]\n",
            " [0 1 0]\n",
            " [1 0 0]\n",
            " [1 1 1]\n",
            " [0 0 0]]\n",
            "Actual Output: \n",
            " [[0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]]\n",
            "Predicted Output: \n",
            "[[0.01586217]\n",
            " [0.93330805]\n",
            " [0.95077897]\n",
            " [0.94311629]\n",
            " [0.94626778]\n",
            " [0.09368583]\n",
            " [0.08547152]]\n",
            "Loss: \n",
            "0.004189636742614361\n",
            "\n",
            "\n",
            "+---------- EPOCH 1000 -----------+\n",
            "Input: \n",
            " [[0 0 1]\n",
            " [0 1 1]\n",
            " [1 0 1]\n",
            " [0 1 0]\n",
            " [1 0 0]\n",
            " [1 1 1]\n",
            " [0 0 0]]\n",
            "Actual Output: \n",
            " [[0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]]\n",
            "Predicted Output: \n",
            "[[0.01474252]\n",
            " [0.93703721]\n",
            " [0.95377301]\n",
            " [0.94589803]\n",
            " [0.94859292]\n",
            " [0.08648785]\n",
            " [0.08306217]]\n",
            "Loss: \n",
            "0.0037525389094911856\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3q9sEegORHj",
        "colab_type": "text"
      },
      "source": [
        "# Gradient Descent-Based Implementation\n",
        "Implemented from Welch's Labs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uMyRzTCPJEj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "a3197d61-6236-419d-ea9d-c63de233abdc"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "X = np.array(([0,0,1],\n",
        "              [0,1,1],\n",
        "              [1,0,1],\n",
        "              [0,1,0],\n",
        "              [1,0,0],\n",
        "              [1,1,1],\n",
        "              [0,0,0]))\n",
        "\n",
        "y = np.array(([0],[1],[1],[1],[1],[0],[0]))\n",
        "\n",
        "y"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEREYT-3wI1f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Neural_Network(object):\n",
        "    def __init__(self):        \n",
        "        #Define Hyperparameters\n",
        "        self.inputLayerSize = 3\n",
        "        self.outputLayerSize = 1\n",
        "        self.hiddenLayerSize = 4\n",
        "        \n",
        "        #Weights (parameters)\n",
        "        self.W1 = np.random.randn(self.inputLayerSize,self.hiddenLayerSize)\n",
        "        self.W2 = np.random.randn(self.hiddenLayerSize,self.outputLayerSize)\n",
        "        \n",
        "    def forward(self, X):\n",
        "        #Propogate inputs though network\n",
        "        self.z2 = np.dot(X, self.W1)\n",
        "        self.a2 = self.sigmoid(self.z2)\n",
        "        self.z3 = np.dot(self.a2, self.W2)\n",
        "        yHat = self.sigmoid(self.z3) \n",
        "        return yHat\n",
        "        \n",
        "    def sigmoid(self, z):\n",
        "        #Apply sigmoid activation function to scalar, vector, or matrix\n",
        "        return 1/(1+np.exp(-z))\n",
        "    \n",
        "    def sigmoidPrime(self,z):\n",
        "        #Gradient of sigmoid\n",
        "        return np.exp(-z)/((1+np.exp(-z))**2)\n",
        "    \n",
        "    def costFunction(self, X, y):\n",
        "        #Compute cost for given X,y, use weights already stored in class.\n",
        "        self.yHat = self.forward(X)\n",
        "        J = 0.5*sum((y-self.yHat)**2)\n",
        "        return J\n",
        "        \n",
        "    def costFunctionPrime(self, X, y):\n",
        "        #Compute derivative with respect to W and W2 for a given X and y:\n",
        "        self.yHat = self.forward(X)\n",
        "        \n",
        "        delta3 = np.multiply(-(y-self.yHat), self.sigmoidPrime(self.z3))\n",
        "        dJdW2 = np.dot(self.a2.T, delta3)\n",
        "        \n",
        "        delta2 = np.dot(delta3, self.W2.T)*self.sigmoidPrime(self.z2)\n",
        "        dJdW1 = np.dot(X.T, delta2)  \n",
        "        \n",
        "        return dJdW1, dJdW2\n",
        "    \n",
        "    #Helper Functions for interacting with other classes:\n",
        "    def getParams(self):\n",
        "        #Get W1 and W2 unrolled into vector:\n",
        "        params = np.concatenate((self.W1.ravel(), self.W2.ravel()))\n",
        "        return params\n",
        "    \n",
        "    def setParams(self, params):\n",
        "        #Set W1 and W2 using single paramater vector.\n",
        "        W1_start = 0\n",
        "        W1_end = self.hiddenLayerSize * self.inputLayerSize\n",
        "        self.W1 = np.reshape(params[W1_start:W1_end], (self.inputLayerSize , self.hiddenLayerSize))\n",
        "        W2_end = W1_end + self.hiddenLayerSize*self.outputLayerSize\n",
        "        self.W2 = np.reshape(params[W1_end:W2_end], (self.hiddenLayerSize, self.outputLayerSize))\n",
        "        \n",
        "    def computeGradients(self, X, y):\n",
        "        dJdW1, dJdW2 = self.costFunctionPrime(X, y)\n",
        "        return np.concatenate((dJdW1.ravel(), dJdW2.ravel()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gm2kiFyV-x7W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy import optimize\n",
        "class trainer(object):\n",
        "    def __init__(self, N):\n",
        "        #Make Local reference to network:\n",
        "        self.N = N\n",
        "        \n",
        "    def callbackF(self, params):\n",
        "        self.N.setParams(params)\n",
        "        self.J.append(self.N.costFunction(self.X, self.y))   \n",
        "        \n",
        "    def costFunctionWrapper(self, params, X, y):\n",
        "        self.N.setParams(params)\n",
        "        cost = self.N.costFunction(X, y)\n",
        "        grad = self.N.computeGradients(X,y)\n",
        "        \n",
        "        return cost, grad\n",
        "        \n",
        "    def train(self, X, y):\n",
        "        #Make an internal variable for the callback function:\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "        #Make empty list to store costs:\n",
        "        self.J = []\n",
        "        \n",
        "        params0 = self.N.getParams()\n",
        "\n",
        "        options = {'maxiter': 200, 'disp' : True}\n",
        "        _res = optimize.minimize(self.costFunctionWrapper, params0, jac=True, method='BFGS', \\\n",
        "                                 args=(X, y), options=options, callback=self.callbackF)\n",
        "\n",
        "        self.N.setParams(_res.x)\n",
        "        self.optimizationResults = _res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJ_z01TH-x5b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NN = Neural_Network()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxJ6CQkU-x2n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "T = trainer(NN)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbKD2lZeLpyx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "871ae24e-b85c-4409-a2ac-8899ba0a6a67"
      },
      "source": [
        "T.train(X,y)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Optimization terminated successfully.\n",
            "         Current function value: 0.333324\n",
            "         Iterations: 69\n",
            "         Function evaluations: 91\n",
            "         Gradient evaluations: 91\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCj68lKrPUmh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "5b22dbcc-6427-47fb-9e2b-d851eb2954c3"
      },
      "source": [
        "print(\"Predicted Output: \\n\" + str(NN.forward(X))) \n",
        "print(\"Loss: \\n\" + str(np.mean(np.square(y - NN.forward(X))))) # mean sum squared loss"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted Output: \n",
            "[[1.10124274e-26]\n",
            " [6.66653260e-01]\n",
            " [6.66683011e-01]\n",
            " [9.98642690e-01]\n",
            " [1.00000000e+00]\n",
            " [6.66653259e-01]\n",
            " [2.60038097e-08]]\n",
            "Loss: \n",
            "0.09523552482060789\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "an26x5BcPUj3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "10ef7153-e230-4a5e-92d3-fa20f797a47b"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(T.J)\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylabel('Cost')\n",
        "plt.show()     "
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n1wAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8b-r70o8p2Dm",
        "colab_type": "text"
      },
      "source": [
        "## Try building/training a more complex MLP on a bigger dataset.\n",
        "\n",
        "Use the [MNIST dataset](http://yann.lecun.com/exdb/mnist/) to build the cannonical handwriting digit recognizer and see what kind of accuracy you can achieve. \n",
        "\n",
        "If you need inspiration, the internet is chalk-full of tutorials, but I want you to see how far you can get on your own first. I've linked to the original MNIST dataset above but it will probably be easier to download data through a neural network library. If you reference outside resources make sure you understand every line of code that you're using from other sources, and share with your fellow students helpful resources that you find.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rl5S1BQHu73P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24o-cPe1u--f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.astype('int')\n",
        "y_train = y_train.astype('int')\n",
        "y_test = y_test.astype('int')\n",
        "x_test = x_test.astype('int')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MOPtYdk1HgA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 7058
        },
        "outputId": "3c75507d-3bd2-4b7f-efa8-6f889677a844"
      },
      "source": [
        "feature_cols = tf.contrib.learn.infer_real_valued_columns_from_input(x_train)\n",
        "dnn_clf = tf.contrib.learn.DNNClassifier(hidden_units=[300,100], n_classes=10,\n",
        "                                         feature_columns=feature_cols)\n",
        "dnn_clf = tf.contrib.learn.SKCompat(dnn_clf)  # if TensorFlow >= 1.1\n",
        "dnn_clf.fit(x_train, y_train, batch_size=50, steps=20000)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpfjbt633y\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fcaccdf7b70>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/tmpfjbt633y'}\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpfjbt633y/model.ckpt.\n",
            "INFO:tensorflow:loss = 161.20062, step = 0\n",
            "INFO:tensorflow:global_step/sec: 479.874\n",
            "INFO:tensorflow:loss = 0.9272997, step = 100 (0.213 sec)\n",
            "INFO:tensorflow:global_step/sec: 546.264\n",
            "INFO:tensorflow:loss = 0.99068946, step = 200 (0.183 sec)\n",
            "INFO:tensorflow:global_step/sec: 524.312\n",
            "INFO:tensorflow:loss = 1.6313852, step = 300 (0.193 sec)\n",
            "INFO:tensorflow:global_step/sec: 494.645\n",
            "INFO:tensorflow:loss = 0.7131127, step = 400 (0.200 sec)\n",
            "INFO:tensorflow:global_step/sec: 475.989\n",
            "INFO:tensorflow:loss = 0.70688087, step = 500 (0.210 sec)\n",
            "INFO:tensorflow:global_step/sec: 508.664\n",
            "INFO:tensorflow:loss = 0.69186896, step = 600 (0.197 sec)\n",
            "INFO:tensorflow:global_step/sec: 492.638\n",
            "INFO:tensorflow:loss = 0.5411188, step = 700 (0.202 sec)\n",
            "INFO:tensorflow:global_step/sec: 475.384\n",
            "INFO:tensorflow:loss = 0.9133065, step = 800 (0.209 sec)\n",
            "INFO:tensorflow:global_step/sec: 545.618\n",
            "INFO:tensorflow:loss = 0.46289375, step = 900 (0.184 sec)\n",
            "INFO:tensorflow:global_step/sec: 543.686\n",
            "INFO:tensorflow:loss = 0.42565888, step = 1000 (0.182 sec)\n",
            "INFO:tensorflow:global_step/sec: 540.09\n",
            "INFO:tensorflow:loss = 0.6916927, step = 1100 (0.187 sec)\n",
            "INFO:tensorflow:global_step/sec: 544.076\n",
            "INFO:tensorflow:loss = 0.5267783, step = 1200 (0.181 sec)\n",
            "INFO:tensorflow:global_step/sec: 548.322\n",
            "INFO:tensorflow:loss = 0.6137489, step = 1300 (0.183 sec)\n",
            "INFO:tensorflow:global_step/sec: 520.27\n",
            "INFO:tensorflow:loss = 0.618284, step = 1400 (0.194 sec)\n",
            "INFO:tensorflow:global_step/sec: 546.14\n",
            "INFO:tensorflow:loss = 0.40955475, step = 1500 (0.184 sec)\n",
            "INFO:tensorflow:global_step/sec: 540.468\n",
            "INFO:tensorflow:loss = 0.5723074, step = 1600 (0.182 sec)\n",
            "INFO:tensorflow:global_step/sec: 545.596\n",
            "INFO:tensorflow:loss = 0.5743814, step = 1700 (0.186 sec)\n",
            "INFO:tensorflow:global_step/sec: 542.153\n",
            "INFO:tensorflow:loss = 0.47970504, step = 1800 (0.185 sec)\n",
            "INFO:tensorflow:global_step/sec: 524.557\n",
            "INFO:tensorflow:loss = 0.37072533, step = 1900 (0.190 sec)\n",
            "INFO:tensorflow:global_step/sec: 548.429\n",
            "INFO:tensorflow:loss = 0.44918105, step = 2000 (0.180 sec)\n",
            "INFO:tensorflow:global_step/sec: 554.47\n",
            "INFO:tensorflow:loss = 0.45664346, step = 2100 (0.182 sec)\n",
            "INFO:tensorflow:global_step/sec: 553.755\n",
            "INFO:tensorflow:loss = 0.55476344, step = 2200 (0.179 sec)\n",
            "INFO:tensorflow:global_step/sec: 555.759\n",
            "INFO:tensorflow:loss = 0.4418473, step = 2300 (0.180 sec)\n",
            "INFO:tensorflow:global_step/sec: 538.858\n",
            "INFO:tensorflow:loss = 0.3001337, step = 2400 (0.188 sec)\n",
            "INFO:tensorflow:global_step/sec: 526.983\n",
            "INFO:tensorflow:loss = 0.56792605, step = 2500 (0.187 sec)\n",
            "INFO:tensorflow:global_step/sec: 546.689\n",
            "INFO:tensorflow:loss = 0.4885434, step = 2600 (0.185 sec)\n",
            "INFO:tensorflow:global_step/sec: 546.751\n",
            "INFO:tensorflow:loss = 0.40233186, step = 2700 (0.183 sec)\n",
            "INFO:tensorflow:global_step/sec: 547.274\n",
            "INFO:tensorflow:loss = 0.34600282, step = 2800 (0.183 sec)\n",
            "INFO:tensorflow:global_step/sec: 548.053\n",
            "INFO:tensorflow:loss = 0.31760868, step = 2900 (0.180 sec)\n",
            "INFO:tensorflow:global_step/sec: 527.759\n",
            "INFO:tensorflow:loss = 0.15813161, step = 3000 (0.192 sec)\n",
            "INFO:tensorflow:global_step/sec: 554.069\n",
            "INFO:tensorflow:loss = 0.13647483, step = 3100 (0.179 sec)\n",
            "INFO:tensorflow:global_step/sec: 543.532\n",
            "INFO:tensorflow:loss = 0.48558643, step = 3200 (0.184 sec)\n",
            "INFO:tensorflow:global_step/sec: 554.655\n",
            "INFO:tensorflow:loss = 0.35995528, step = 3300 (0.181 sec)\n",
            "INFO:tensorflow:global_step/sec: 550.284\n",
            "INFO:tensorflow:loss = 0.1421649, step = 3400 (0.182 sec)\n",
            "INFO:tensorflow:global_step/sec: 546.655\n",
            "INFO:tensorflow:loss = 0.26285672, step = 3500 (0.181 sec)\n",
            "INFO:tensorflow:global_step/sec: 498.486\n",
            "INFO:tensorflow:loss = 0.34752706, step = 3600 (0.201 sec)\n",
            "INFO:tensorflow:global_step/sec: 537.158\n",
            "INFO:tensorflow:loss = 0.4500924, step = 3700 (0.188 sec)\n",
            "INFO:tensorflow:global_step/sec: 556.955\n",
            "INFO:tensorflow:loss = 0.25178066, step = 3800 (0.179 sec)\n",
            "INFO:tensorflow:global_step/sec: 548.057\n",
            "INFO:tensorflow:loss = 0.44997773, step = 3900 (0.182 sec)\n",
            "INFO:tensorflow:global_step/sec: 535.778\n",
            "INFO:tensorflow:loss = 0.22586773, step = 4000 (0.188 sec)\n",
            "INFO:tensorflow:global_step/sec: 517.853\n",
            "INFO:tensorflow:loss = 0.42252433, step = 4100 (0.193 sec)\n",
            "INFO:tensorflow:global_step/sec: 549.258\n",
            "INFO:tensorflow:loss = 0.3911125, step = 4200 (0.182 sec)\n",
            "INFO:tensorflow:global_step/sec: 553.177\n",
            "INFO:tensorflow:loss = 0.5819419, step = 4300 (0.181 sec)\n",
            "INFO:tensorflow:global_step/sec: 551.897\n",
            "INFO:tensorflow:loss = 0.16095482, step = 4400 (0.180 sec)\n",
            "INFO:tensorflow:global_step/sec: 552.191\n",
            "INFO:tensorflow:loss = 0.5702197, step = 4500 (0.181 sec)\n",
            "INFO:tensorflow:global_step/sec: 542.2\n",
            "INFO:tensorflow:loss = 0.16562794, step = 4600 (0.186 sec)\n",
            "INFO:tensorflow:global_step/sec: 526.332\n",
            "INFO:tensorflow:loss = 0.42438707, step = 4700 (0.190 sec)\n",
            "INFO:tensorflow:global_step/sec: 552.636\n",
            "INFO:tensorflow:loss = 0.100664556, step = 4800 (0.179 sec)\n",
            "INFO:tensorflow:global_step/sec: 555.541\n",
            "INFO:tensorflow:loss = 0.5667916, step = 4900 (0.183 sec)\n",
            "INFO:tensorflow:global_step/sec: 546.657\n",
            "INFO:tensorflow:loss = 0.3181151, step = 5000 (0.181 sec)\n",
            "INFO:tensorflow:global_step/sec: 545.332\n",
            "INFO:tensorflow:loss = 0.35563678, step = 5100 (0.185 sec)\n",
            "INFO:tensorflow:global_step/sec: 520.214\n",
            "INFO:tensorflow:loss = 0.19493228, step = 5200 (0.193 sec)\n",
            "INFO:tensorflow:global_step/sec: 544.628\n",
            "INFO:tensorflow:loss = 0.22422779, step = 5300 (0.183 sec)\n",
            "INFO:tensorflow:global_step/sec: 545.699\n",
            "INFO:tensorflow:loss = 0.38289183, step = 5400 (0.183 sec)\n",
            "INFO:tensorflow:global_step/sec: 549.978\n",
            "INFO:tensorflow:loss = 0.20438917, step = 5500 (0.181 sec)\n",
            "INFO:tensorflow:global_step/sec: 555.174\n",
            "INFO:tensorflow:loss = 0.081989124, step = 5600 (0.181 sec)\n",
            "INFO:tensorflow:global_step/sec: 556.958\n",
            "INFO:tensorflow:loss = 0.13515317, step = 5700 (0.179 sec)\n",
            "INFO:tensorflow:global_step/sec: 519.634\n",
            "INFO:tensorflow:loss = 0.45510057, step = 5800 (0.194 sec)\n",
            "INFO:tensorflow:global_step/sec: 541.061\n",
            "INFO:tensorflow:loss = 0.42402977, step = 5900 (0.185 sec)\n",
            "INFO:tensorflow:global_step/sec: 545.426\n",
            "INFO:tensorflow:loss = 0.37263784, step = 6000 (0.183 sec)\n",
            "INFO:tensorflow:global_step/sec: 535.567\n",
            "INFO:tensorflow:loss = 0.20619953, step = 6100 (0.187 sec)\n",
            "INFO:tensorflow:global_step/sec: 544.116\n",
            "INFO:tensorflow:loss = 0.39827254, step = 6200 (0.183 sec)\n",
            "INFO:tensorflow:global_step/sec: 532.771\n",
            "INFO:tensorflow:loss = 0.29662853, step = 6300 (0.191 sec)\n",
            "INFO:tensorflow:global_step/sec: 528.259\n",
            "INFO:tensorflow:loss = 0.22498873, step = 6400 (0.187 sec)\n",
            "INFO:tensorflow:global_step/sec: 548.472\n",
            "INFO:tensorflow:loss = 0.10095211, step = 6500 (0.183 sec)\n",
            "INFO:tensorflow:global_step/sec: 545.061\n",
            "INFO:tensorflow:loss = 0.19443347, step = 6600 (0.187 sec)\n",
            "INFO:tensorflow:global_step/sec: 525.81\n",
            "INFO:tensorflow:loss = 0.09827993, step = 6700 (0.185 sec)\n",
            "INFO:tensorflow:global_step/sec: 555.407\n",
            "INFO:tensorflow:loss = 0.39635006, step = 6800 (0.180 sec)\n",
            "INFO:tensorflow:global_step/sec: 531.926\n",
            "INFO:tensorflow:loss = 0.4097324, step = 6900 (0.192 sec)\n",
            "INFO:tensorflow:global_step/sec: 537.802\n",
            "INFO:tensorflow:loss = 0.3416561, step = 7000 (0.183 sec)\n",
            "INFO:tensorflow:global_step/sec: 560.437\n",
            "INFO:tensorflow:loss = 0.42887664, step = 7100 (0.180 sec)\n",
            "INFO:tensorflow:global_step/sec: 550.352\n",
            "INFO:tensorflow:loss = 0.042432483, step = 7200 (0.182 sec)\n",
            "INFO:tensorflow:global_step/sec: 525.574\n",
            "INFO:tensorflow:loss = 0.20996341, step = 7300 (0.190 sec)\n",
            "INFO:tensorflow:global_step/sec: 555.868\n",
            "INFO:tensorflow:loss = 0.5504241, step = 7400 (0.178 sec)\n",
            "INFO:tensorflow:global_step/sec: 522.337\n",
            "INFO:tensorflow:loss = 0.3666404, step = 7500 (0.192 sec)\n",
            "INFO:tensorflow:global_step/sec: 556.321\n",
            "INFO:tensorflow:loss = 0.33353484, step = 7600 (0.184 sec)\n",
            "INFO:tensorflow:global_step/sec: 544.296\n",
            "INFO:tensorflow:loss = 0.059823293, step = 7700 (0.182 sec)\n",
            "INFO:tensorflow:global_step/sec: 549.367\n",
            "INFO:tensorflow:loss = 0.17953826, step = 7800 (0.182 sec)\n",
            "INFO:tensorflow:global_step/sec: 548.676\n",
            "INFO:tensorflow:loss = 0.3702938, step = 7900 (0.183 sec)\n",
            "INFO:tensorflow:global_step/sec: 450.017\n",
            "INFO:tensorflow:loss = 0.2638809, step = 8000 (0.219 sec)\n",
            "INFO:tensorflow:global_step/sec: 478.591\n",
            "INFO:tensorflow:loss = 0.11006094, step = 8100 (0.212 sec)\n",
            "INFO:tensorflow:global_step/sec: 465.389\n",
            "INFO:tensorflow:loss = 0.24962948, step = 8200 (0.214 sec)\n",
            "INFO:tensorflow:global_step/sec: 475.147\n",
            "INFO:tensorflow:loss = 0.058787037, step = 8300 (0.213 sec)\n",
            "INFO:tensorflow:global_step/sec: 467.218\n",
            "INFO:tensorflow:loss = 0.35378602, step = 8400 (0.210 sec)\n",
            "INFO:tensorflow:global_step/sec: 453.383\n",
            "INFO:tensorflow:loss = 0.3746943, step = 8500 (0.220 sec)\n",
            "INFO:tensorflow:global_step/sec: 466.051\n",
            "INFO:tensorflow:loss = 0.5290976, step = 8600 (0.218 sec)\n",
            "INFO:tensorflow:global_step/sec: 474.881\n",
            "INFO:tensorflow:loss = 0.32443088, step = 8700 (0.210 sec)\n",
            "INFO:tensorflow:global_step/sec: 456.526\n",
            "INFO:tensorflow:loss = 0.08809176, step = 8800 (0.220 sec)\n",
            "INFO:tensorflow:global_step/sec: 474.613\n",
            "INFO:tensorflow:loss = 0.22126122, step = 8900 (0.210 sec)\n",
            "INFO:tensorflow:global_step/sec: 446.215\n",
            "INFO:tensorflow:loss = 0.2484323, step = 9000 (0.223 sec)\n",
            "INFO:tensorflow:global_step/sec: 459.924\n",
            "INFO:tensorflow:loss = 0.3718602, step = 9100 (0.216 sec)\n",
            "INFO:tensorflow:global_step/sec: 463.125\n",
            "INFO:tensorflow:loss = 0.26413062, step = 9200 (0.216 sec)\n",
            "INFO:tensorflow:global_step/sec: 472.602\n",
            "INFO:tensorflow:loss = 0.16624504, step = 9300 (0.212 sec)\n",
            "INFO:tensorflow:global_step/sec: 454.084\n",
            "INFO:tensorflow:loss = 0.19167857, step = 9400 (0.224 sec)\n",
            "INFO:tensorflow:global_step/sec: 476.46\n",
            "INFO:tensorflow:loss = 0.1272301, step = 9500 (0.209 sec)\n",
            "INFO:tensorflow:global_step/sec: 467.072\n",
            "INFO:tensorflow:loss = 0.14148131, step = 9600 (0.216 sec)\n",
            "INFO:tensorflow:global_step/sec: 464.63\n",
            "INFO:tensorflow:loss = 0.3041486, step = 9700 (0.213 sec)\n",
            "INFO:tensorflow:global_step/sec: 467.279\n",
            "INFO:tensorflow:loss = 0.22111255, step = 9800 (0.215 sec)\n",
            "INFO:tensorflow:global_step/sec: 456.2\n",
            "INFO:tensorflow:loss = 0.12155847, step = 9900 (0.217 sec)\n",
            "INFO:tensorflow:global_step/sec: 470.022\n",
            "INFO:tensorflow:loss = 0.24423492, step = 10000 (0.211 sec)\n",
            "INFO:tensorflow:global_step/sec: 464.02\n",
            "INFO:tensorflow:loss = 0.15852596, step = 10100 (0.218 sec)\n",
            "INFO:tensorflow:global_step/sec: 454.256\n",
            "INFO:tensorflow:loss = 0.25335854, step = 10200 (0.221 sec)\n",
            "INFO:tensorflow:global_step/sec: 464.577\n",
            "INFO:tensorflow:loss = 0.28753674, step = 10300 (0.213 sec)\n",
            "INFO:tensorflow:global_step/sec: 453.477\n",
            "INFO:tensorflow:loss = 0.10147813, step = 10400 (0.223 sec)\n",
            "INFO:tensorflow:global_step/sec: 461.847\n",
            "INFO:tensorflow:loss = 0.3969032, step = 10500 (0.213 sec)\n",
            "INFO:tensorflow:global_step/sec: 469.231\n",
            "INFO:tensorflow:loss = 0.26000696, step = 10600 (0.213 sec)\n",
            "INFO:tensorflow:global_step/sec: 467.343\n",
            "INFO:tensorflow:loss = 0.20743498, step = 10700 (0.217 sec)\n",
            "INFO:tensorflow:global_step/sec: 472.244\n",
            "INFO:tensorflow:loss = 0.32756624, step = 10800 (0.210 sec)\n",
            "INFO:tensorflow:global_step/sec: 458.531\n",
            "INFO:tensorflow:loss = 0.074853204, step = 10900 (0.221 sec)\n",
            "INFO:tensorflow:global_step/sec: 474.284\n",
            "INFO:tensorflow:loss = 0.28815082, step = 11000 (0.211 sec)\n",
            "INFO:tensorflow:global_step/sec: 474.801\n",
            "INFO:tensorflow:loss = 0.039798647, step = 11100 (0.210 sec)\n",
            "INFO:tensorflow:global_step/sec: 460.673\n",
            "INFO:tensorflow:loss = 0.03000737, step = 11200 (0.218 sec)\n",
            "INFO:tensorflow:global_step/sec: 451.752\n",
            "INFO:tensorflow:loss = 0.16253363, step = 11300 (0.220 sec)\n",
            "INFO:tensorflow:global_step/sec: 460.229\n",
            "INFO:tensorflow:loss = 0.1753576, step = 11400 (0.218 sec)\n",
            "INFO:tensorflow:global_step/sec: 465.988\n",
            "INFO:tensorflow:loss = 0.061164565, step = 11500 (0.213 sec)\n",
            "INFO:tensorflow:global_step/sec: 487.602\n",
            "INFO:tensorflow:loss = 0.24311371, step = 11600 (0.208 sec)\n",
            "INFO:tensorflow:global_step/sec: 454.567\n",
            "INFO:tensorflow:loss = 0.34538043, step = 11700 (0.219 sec)\n",
            "INFO:tensorflow:global_step/sec: 452.793\n",
            "INFO:tensorflow:loss = 0.32519883, step = 11800 (0.217 sec)\n",
            "INFO:tensorflow:global_step/sec: 479.855\n",
            "INFO:tensorflow:loss = 0.12029041, step = 11900 (0.212 sec)\n",
            "INFO:tensorflow:global_step/sec: 463.215\n",
            "INFO:tensorflow:loss = 0.4019061, step = 12000 (0.215 sec)\n",
            "INFO:tensorflow:global_step/sec: 454.07\n",
            "INFO:tensorflow:loss = 0.13611315, step = 12100 (0.220 sec)\n",
            "INFO:tensorflow:global_step/sec: 457.069\n",
            "INFO:tensorflow:loss = 0.25421745, step = 12200 (0.218 sec)\n",
            "INFO:tensorflow:global_step/sec: 450.649\n",
            "INFO:tensorflow:loss = 0.36342037, step = 12300 (0.222 sec)\n",
            "INFO:tensorflow:global_step/sec: 474.007\n",
            "INFO:tensorflow:loss = 0.16022763, step = 12400 (0.210 sec)\n",
            "INFO:tensorflow:global_step/sec: 471.428\n",
            "INFO:tensorflow:loss = 0.11823174, step = 12500 (0.211 sec)\n",
            "INFO:tensorflow:global_step/sec: 482.249\n",
            "INFO:tensorflow:loss = 0.19942665, step = 12600 (0.207 sec)\n",
            "INFO:tensorflow:global_step/sec: 506.855\n",
            "INFO:tensorflow:loss = 0.32178986, step = 12700 (0.200 sec)\n",
            "INFO:tensorflow:global_step/sec: 519.642\n",
            "INFO:tensorflow:loss = 0.07604728, step = 12800 (0.190 sec)\n",
            "INFO:tensorflow:global_step/sec: 542.24\n",
            "INFO:tensorflow:loss = 0.262563, step = 12900 (0.184 sec)\n",
            "INFO:tensorflow:global_step/sec: 544.077\n",
            "INFO:tensorflow:loss = 0.05716821, step = 13000 (0.186 sec)\n",
            "INFO:tensorflow:global_step/sec: 539.741\n",
            "INFO:tensorflow:loss = 0.32646847, step = 13100 (0.185 sec)\n",
            "INFO:tensorflow:global_step/sec: 543.114\n",
            "INFO:tensorflow:loss = 0.2575908, step = 13200 (0.185 sec)\n",
            "INFO:tensorflow:global_step/sec: 520.892\n",
            "INFO:tensorflow:loss = 0.48422977, step = 13300 (0.190 sec)\n",
            "INFO:tensorflow:global_step/sec: 552.397\n",
            "INFO:tensorflow:loss = 0.2159479, step = 13400 (0.183 sec)\n",
            "INFO:tensorflow:global_step/sec: 538.846\n",
            "INFO:tensorflow:loss = 0.19279915, step = 13500 (0.183 sec)\n",
            "INFO:tensorflow:global_step/sec: 542.483\n",
            "INFO:tensorflow:loss = 0.2896776, step = 13600 (0.189 sec)\n",
            "INFO:tensorflow:global_step/sec: 530.499\n",
            "INFO:tensorflow:loss = 0.48411223, step = 13700 (0.187 sec)\n",
            "INFO:tensorflow:global_step/sec: 515.001\n",
            "INFO:tensorflow:loss = 0.26411065, step = 13800 (0.192 sec)\n",
            "INFO:tensorflow:global_step/sec: 489.419\n",
            "INFO:tensorflow:loss = 0.19547445, step = 13900 (0.210 sec)\n",
            "INFO:tensorflow:global_step/sec: 495.162\n",
            "INFO:tensorflow:loss = 0.28393447, step = 14000 (0.200 sec)\n",
            "INFO:tensorflow:global_step/sec: 503.557\n",
            "INFO:tensorflow:loss = 0.2776489, step = 14100 (0.197 sec)\n",
            "INFO:tensorflow:global_step/sec: 504.211\n",
            "INFO:tensorflow:loss = 0.41823757, step = 14200 (0.197 sec)\n",
            "INFO:tensorflow:global_step/sec: 492.92\n",
            "INFO:tensorflow:loss = 0.42719504, step = 14300 (0.203 sec)\n",
            "INFO:tensorflow:global_step/sec: 470.171\n",
            "INFO:tensorflow:loss = 0.120453164, step = 14400 (0.213 sec)\n",
            "INFO:tensorflow:global_step/sec: 499.439\n",
            "INFO:tensorflow:loss = 0.1788724, step = 14500 (0.203 sec)\n",
            "INFO:tensorflow:global_step/sec: 502.217\n",
            "INFO:tensorflow:loss = 0.025927007, step = 14600 (0.200 sec)\n",
            "INFO:tensorflow:global_step/sec: 506.838\n",
            "INFO:tensorflow:loss = 0.18616252, step = 14700 (0.197 sec)\n",
            "INFO:tensorflow:global_step/sec: 501.505\n",
            "INFO:tensorflow:loss = 0.12647508, step = 14800 (0.196 sec)\n",
            "INFO:tensorflow:global_step/sec: 481.058\n",
            "INFO:tensorflow:loss = 0.17287546, step = 14900 (0.211 sec)\n",
            "INFO:tensorflow:global_step/sec: 478.05\n",
            "INFO:tensorflow:loss = 0.10969349, step = 15000 (0.209 sec)\n",
            "INFO:tensorflow:global_step/sec: 510.208\n",
            "INFO:tensorflow:loss = 0.2914251, step = 15100 (0.193 sec)\n",
            "INFO:tensorflow:global_step/sec: 505.106\n",
            "INFO:tensorflow:loss = 0.21642964, step = 15200 (0.200 sec)\n",
            "INFO:tensorflow:global_step/sec: 501.015\n",
            "INFO:tensorflow:loss = 0.13543403, step = 15300 (0.198 sec)\n",
            "INFO:tensorflow:global_step/sec: 482.585\n",
            "INFO:tensorflow:loss = 0.1508105, step = 15400 (0.210 sec)\n",
            "INFO:tensorflow:global_step/sec: 498.171\n",
            "INFO:tensorflow:loss = 0.030294165, step = 15500 (0.203 sec)\n",
            "INFO:tensorflow:global_step/sec: 495.585\n",
            "INFO:tensorflow:loss = 0.32047164, step = 15600 (0.196 sec)\n",
            "INFO:tensorflow:global_step/sec: 513.723\n",
            "INFO:tensorflow:loss = 0.26298293, step = 15700 (0.195 sec)\n",
            "INFO:tensorflow:global_step/sec: 499.862\n",
            "INFO:tensorflow:loss = 0.045463182, step = 15800 (0.201 sec)\n",
            "INFO:tensorflow:global_step/sec: 493.634\n",
            "INFO:tensorflow:loss = 0.3719462, step = 15900 (0.205 sec)\n",
            "INFO:tensorflow:global_step/sec: 495.706\n",
            "INFO:tensorflow:loss = 0.3522478, step = 16000 (0.199 sec)\n",
            "INFO:tensorflow:global_step/sec: 508.025\n",
            "INFO:tensorflow:loss = 0.22508419, step = 16100 (0.198 sec)\n",
            "INFO:tensorflow:global_step/sec: 504.851\n",
            "INFO:tensorflow:loss = 0.1368519, step = 16200 (0.199 sec)\n",
            "INFO:tensorflow:global_step/sec: 492.025\n",
            "INFO:tensorflow:loss = 0.15352124, step = 16300 (0.202 sec)\n",
            "INFO:tensorflow:global_step/sec: 474.24\n",
            "INFO:tensorflow:loss = 0.23077802, step = 16400 (0.212 sec)\n",
            "INFO:tensorflow:global_step/sec: 502.978\n",
            "INFO:tensorflow:loss = 0.165884, step = 16500 (0.199 sec)\n",
            "INFO:tensorflow:global_step/sec: 498.848\n",
            "INFO:tensorflow:loss = 0.17681754, step = 16600 (0.202 sec)\n",
            "INFO:tensorflow:global_step/sec: 504.601\n",
            "INFO:tensorflow:loss = 0.09208887, step = 16700 (0.196 sec)\n",
            "INFO:tensorflow:global_step/sec: 497.795\n",
            "INFO:tensorflow:loss = 0.09184691, step = 16800 (0.201 sec)\n",
            "INFO:tensorflow:global_step/sec: 479.729\n",
            "INFO:tensorflow:loss = 0.3398132, step = 16900 (0.208 sec)\n",
            "INFO:tensorflow:global_step/sec: 506.693\n",
            "INFO:tensorflow:loss = 0.42090413, step = 17000 (0.197 sec)\n",
            "INFO:tensorflow:global_step/sec: 500.017\n",
            "INFO:tensorflow:loss = 0.25678098, step = 17100 (0.201 sec)\n",
            "INFO:tensorflow:global_step/sec: 488.362\n",
            "INFO:tensorflow:loss = 0.034586, step = 17200 (0.206 sec)\n",
            "INFO:tensorflow:global_step/sec: 504.68\n",
            "INFO:tensorflow:loss = 0.07585913, step = 17300 (0.195 sec)\n",
            "INFO:tensorflow:global_step/sec: 479.846\n",
            "INFO:tensorflow:loss = 0.46307158, step = 17400 (0.209 sec)\n",
            "INFO:tensorflow:global_step/sec: 510.274\n",
            "INFO:tensorflow:loss = 0.3519674, step = 17500 (0.198 sec)\n",
            "INFO:tensorflow:global_step/sec: 501.291\n",
            "INFO:tensorflow:loss = 0.11361786, step = 17600 (0.201 sec)\n",
            "INFO:tensorflow:global_step/sec: 494.115\n",
            "INFO:tensorflow:loss = 0.019559775, step = 17700 (0.202 sec)\n",
            "INFO:tensorflow:global_step/sec: 498.099\n",
            "INFO:tensorflow:loss = 0.081707336, step = 17800 (0.202 sec)\n",
            "INFO:tensorflow:global_step/sec: 473.069\n",
            "INFO:tensorflow:loss = 0.2430095, step = 17900 (0.210 sec)\n",
            "INFO:tensorflow:global_step/sec: 490.888\n",
            "INFO:tensorflow:loss = 0.22550917, step = 18000 (0.204 sec)\n",
            "INFO:tensorflow:global_step/sec: 503.078\n",
            "INFO:tensorflow:loss = 0.123918146, step = 18100 (0.198 sec)\n",
            "INFO:tensorflow:global_step/sec: 504.261\n",
            "INFO:tensorflow:loss = 0.08788661, step = 18200 (0.199 sec)\n",
            "INFO:tensorflow:global_step/sec: 508.434\n",
            "INFO:tensorflow:loss = 0.0430863, step = 18300 (0.195 sec)\n",
            "INFO:tensorflow:global_step/sec: 476.294\n",
            "INFO:tensorflow:loss = 0.14721033, step = 18400 (0.211 sec)\n",
            "INFO:tensorflow:global_step/sec: 502.022\n",
            "INFO:tensorflow:loss = 0.048258323, step = 18500 (0.196 sec)\n",
            "INFO:tensorflow:global_step/sec: 508.228\n",
            "INFO:tensorflow:loss = 0.27943993, step = 18600 (0.197 sec)\n",
            "INFO:tensorflow:global_step/sec: 501.804\n",
            "INFO:tensorflow:loss = 0.21028242, step = 18700 (0.199 sec)\n",
            "INFO:tensorflow:global_step/sec: 510.322\n",
            "INFO:tensorflow:loss = 0.4125482, step = 18800 (0.196 sec)\n",
            "INFO:tensorflow:global_step/sec: 553.581\n",
            "INFO:tensorflow:loss = 0.3096015, step = 18900 (0.181 sec)\n",
            "INFO:tensorflow:global_step/sec: 525.897\n",
            "INFO:tensorflow:loss = 0.07879826, step = 19000 (0.190 sec)\n",
            "INFO:tensorflow:global_step/sec: 554.137\n",
            "INFO:tensorflow:loss = 0.09150542, step = 19100 (0.181 sec)\n",
            "INFO:tensorflow:global_step/sec: 550.338\n",
            "INFO:tensorflow:loss = 0.2243756, step = 19200 (0.184 sec)\n",
            "INFO:tensorflow:global_step/sec: 550.096\n",
            "INFO:tensorflow:loss = 0.1779433, step = 19300 (0.181 sec)\n",
            "INFO:tensorflow:global_step/sec: 545.093\n",
            "INFO:tensorflow:loss = 0.13753517, step = 19400 (0.184 sec)\n",
            "INFO:tensorflow:global_step/sec: 530.422\n",
            "INFO:tensorflow:loss = 0.19109738, step = 19500 (0.189 sec)\n",
            "INFO:tensorflow:global_step/sec: 550.154\n",
            "INFO:tensorflow:loss = 0.17944635, step = 19600 (0.180 sec)\n",
            "INFO:tensorflow:global_step/sec: 542.576\n",
            "INFO:tensorflow:loss = 0.18137182, step = 19700 (0.183 sec)\n",
            "INFO:tensorflow:global_step/sec: 550.257\n",
            "INFO:tensorflow:loss = 0.10774671, step = 19800 (0.183 sec)\n",
            "INFO:tensorflow:global_step/sec: 552.518\n",
            "INFO:tensorflow:loss = 0.06627181, step = 19900 (0.179 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 20000 into /tmp/tmpfjbt633y/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.048455585.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SKCompat()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBS9uyqz2C0l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "8c284d65-7d16-4451-815b-1dfcf7305f8f"
      },
      "source": [
        "y_pred = dnn_clf.predict(x_test)\n",
        "accuracy_score(y_test, y_pred['classes'])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpfjbt633y/model.ckpt-20000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9408"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwlRJSfBlCvy",
        "colab_type": "text"
      },
      "source": [
        "## Stretch Goals: \n",
        "\n",
        "- Implement Cross Validation model evaluation on your MNIST implementation \n",
        "- Research different [Gradient Descent Based Optimizers](https://keras.io/optimizers/)\n",
        " - [Siraj Raval the evolution of gradient descent](https://www.youtube.com/watch?v=nhqo0u1a6fw)\n",
        "- Build a housing price estimation model using a neural network. How does its accuracy compare with the regression models that we fit earlier on in class?"
      ]
    }
  ]
}